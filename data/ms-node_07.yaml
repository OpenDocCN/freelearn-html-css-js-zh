- en: Using Multiple Processes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用多个进程
- en: '"It is a very sad thing that nowadays there is so little useless information."'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: “现在很遗憾的是，现在几乎没有多余的信息。”
- en: – Oscar Wilde
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: – 奥斯卡·王尔德
- en: The importance of I/O efficiency is not lost on those witnessing the rapidly
    increasing volume of data being produced within a growing number of applications.
    User-generated content (blogs, videos, tweets, and posts) is becoming the premier
    type of internet content, and this trend has moved in tandem with the rise of
    social software, where mapping the intersections between content generates an
    exponential rise in yet another level of data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 对于目睹着越来越多的应用程序产生的数据量急剧增加的人来说，I/O效率的重要性是不言而喻的。用户生成的内容（博客、视频、推文和帖子）正在成为互联网内容的主要类型，这一趋势与社交软件的兴起同步进行，其中对内容之间的交集进行映射产生了另一层数据的指数级增长。
- en: A number of data silos, such as Google, Facebook, and hundreds of others, expose
    their data to the public through an API, often for free. These networks each gather
    astounding volumes of content, opinions, relationships, and so forth from their
    users, data further augmented by market research and various types of traffic
    and usage analysis. Most of these APIs are two-way, gathering and storing data
    uploaded by their members as well as serving that data.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据储存库，如谷歌、Facebook和其他数百家公司，通过API向公众公开其数据，通常是免费的。这些网络每个都收集了令人惊讶的内容、观点、关系等大量数据，这些数据还通过市场研究和各种类型的流量和使用分析进一步增加。这些API大多是双向的，既收集并储存成员上传的数据，又提供这些数据。
- en: Node has arrived during this period of data expansion. In this chapter, we will
    investigate how Node addresses this need for sorting, merging, searching, and
    otherwise manipulating large amounts of data. Fine-tuning your software so that
    it can process large amounts of data safely and inexpensively is critical when
    building fast and scalable network applications.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Node已经在这一数据扩张期间到来。在本章中，我们将探讨Node如何满足对大量数据进行排序、合并、搜索和其他操作的需求。调整软件，使其能够安全、廉价地处理大量数据，在构建快速和可扩展的网络应用程序时至关重要。
- en: We will deal with specific scaling issues in the next chapter. In this chapter,
    we will study some best practices when designing systems where multiple Node processes
    work together on large volumes of data.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章中处理特定的扩展问题。在本章中，我们将研究在设计多个Node进程共同处理大量数据的系统时的一些最佳实践。
- en: As part of that discussion, we will be investigating strategies for parallelism
    when building data-heavy applications, focusing on how to take advantage of multiple
    CPU environments, use multiple workers, and leverage the OS itself to achieve
    the efficiency of parallelism. The process of assembling applications out of these
    contained and efficient processing units will be demonstrated by example.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '作为讨论的一部分，我们将研究在构建数据密集型应用程序时的并行策略，重点是如何利用多个CPU环境、使用多个工作进程，并利用操作系统本身来实现并行性的效率。通过示例来演示如何将这些独立而高效的处理单元组装成应用程序的过程。 '
- en: As noted in [Chapter 5](ae24c7b4-7661-4041-8108-15fe453bf8c8.xhtml)*, Managing
    Many Simultaneous Client Connections*, concurrency is not the same as parallelism.
    The goal of concurrency is good structure for programs, where modeling the complexities
    inherent in juggling multiple simultaneous processes is simplified. The goal of
    parallelism is to increase application performance by sharing parts of a task
    or computation across many workers. It is useful to recall *Clinger's* vision
    of "…dozens, hundreds or even thousands of independent microprocessors, each with
    its own local memory and communications processor, communicating via a high-performance
    communications network."
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第5章](ae24c7b4-7661-4041-8108-15fe453bf8c8.xhtml)*中所述，管理许多同时的客户端连接*，并发性并不等同于并行性。并发的目标是为程序提供良好的结构，简化模拟处理多个同时进行的进程所固有的复杂性。并行性的目标是通过将任务或计算的部分分配给多个工作进程来提高应用程序的性能。值得回顾的是*Clinger*对“…数十、数百甚至数千个独立微处理器，每个都有自己的本地内存和通信处理器，通过高性能通信网络进行通信”的愿景。
- en: 'We''ve already discussed how Node helps us reason about non-deterministic control
    flow. Let''s also recall how Node''s designers follow the **Rule Of Modularity**,
    which encourages us to write simple parts connected by clean interfaces. This
    rule leads to a preference for simple networked processes communicating with each
    other using a common protocol. An associated rule is the **Rule of Simplicity**,
    stated as follows:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了Node如何帮助我们理解非确定性控制流。让我们还记得Node的设计者遵循**模块化规则**，鼓励我们编写简单的部分，并通过清晰的接口连接起来。这条规则导致了对简单的网络化进程的偏好，这些进程使用共同的协议进行通信。相关的规则是**简单规则**，如下所述：
- en: As [https://en.wikipedia.org/wiki/Unix_philosophy](https://en.wikipedia.org/wiki/Unix_philosophy)
    says, "developers should design for simplicity by looking for ways to break up
    program systems into small, straightforward cooperating pieces. This rule aims
    to discourage developers' affection for writing "intricate and beautiful complexities"
    that are bug prone programs in reality."
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 正如[https://en.wikipedia.org/wiki/Unix_philosophy](https://en.wikipedia.org/wiki/Unix_philosophy)所说，“开发人员应该通过寻找将程序系统分解为小而简单的协作部分的方法来设计简单。这条规则旨在阻止开发人员对编写“错综复杂且美丽的复杂性”产生情感，而这些实际上是容易出错的程序。”
- en: It is good to keep this rule in mind as we proceed through this chapter. To
    tame expanding data volume, we can build enormous, complex, and powerful monoliths
    in the hope that they will remain big and powerful enough. Alternatively, we can
    build small and useful units of processing that can be combined into a single
    processing team of any size, not unlike the way that supercomputers can be built
    out of many thousands or millions of cheap commodity processors.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续阅读本章内容时，记住这条规则是很好的。为了控制不断增长的数据量，我们可以构建庞大、复杂和强大的单体，希望它们能够保持足够的规模和强大。或者，我们可以构建小而有用的处理单元，可以组合成任意大小的单一处理团队，就像超级计算机可以由成千上万甚至数百万台廉价的处理器构建而成一样。
- en: 'A process viewer will be useful while working through this chapter. A good
    one for Unix systems is **htop**, which can be downloaded from: [http://hisham.hm/htop/](http://hisham.hm/htop/).
    This tool provides, among other things, a view into CPU and memory usage; here,
    we see how load is spread across all eight cores:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读本章时，进程查看器将非常有用。Unix系统的一个很好的工具是**htop**，可以从以下网址下载：[http://hisham.hm/htop/](http://hisham.hm/htop/)。该工具提供了CPU和内存使用情况的视图；在这里，我们可以看到负载是如何分布在所有八个核心上的：
- en: '![](img/54113a36-c425-40c0-9f3f-dd1e012b09af.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/54113a36-c425-40c0-9f3f-dd1e012b09af.png)'
- en: Let's get started by looking into threads and processes.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始研究线程和进程。
- en: Node's single-threaded model
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Node的单线程模型
- en: Taken in its entirety, the Node environment usefully demonstrates both the efficiency
    of multithreaded parallelism and an expressive syntax amenable to applications
    featuring high concurrency. Using Node does not constrain the developer, the developer's
    access to system resources, or the types of applications the developer might like
    to build.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Node环境的整体展示了多线程并行性的效率和适用于具有高并发性特征的应用程序的表达语法。使用Node不会限制开发人员、开发人员对系统资源的访问，或者开发人员可能想要构建的应用程序类型。
- en: Nevertheless, a surprising number of persistent criticisms of Node are based
    on this misunderstanding. As we'll see, the belief that Node is not multithreaded
    and is, therefore, slow, or not ready for prime time, simply misses the point.
    JavaScript is single-threaded; the Node stack is not. JavaScript represents the
    language used to coordinate the execution of several multithreaded C++ processes,
    even the bespoke C++ add-ons created by you, the developer. Node provides JavaScript,
    run through V8, primarily as a tool for modeling concurrency. That, additionally,
    where one can write an entire application using just JavaScript is simply another
    benefit of the platform. You are never stuck with JavaScript—you may write the
    bulk of your application in C++ if that is your choice.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，令人惊讶的是，对Node的许多持久批评都是基于这种误解。正如我们将看到的，认为Node不是多线程的，因此慢，或者还没有准备好投入使用，简单地错过了重点。JavaScript是单线程的；Node堆栈不是。JavaScript代表了用于协调执行多个多线程C++进程的语言，甚至是您开发人员创建的定制C++附加组件。Node提供JavaScript，通过V8运行，主要作为建模并发的工具。此外，您可以仅使用JavaScript编写整个应用程序，这只是该平台的另一个好处。您不必一直使用JavaScript-如果您选择，可以在C++中编写大部分应用程序。
- en: 'In this chapter, we will attempt to dismantle these misunderstandings, clearing
    the way for optimistic development with Node. In particular, we will study techniques
    for spreading effort across cores, processes, and threads. For now, this section
    will attempt to clarify how much a single thread is capable of (hint: it''s usually
    all you need).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将尝试解决这些误解，为使用Node进行乐观开发铺平道路。特别是，我们将研究跨核心、进程和线程分配工作的技术。目前，本节将尝试澄清单个线程的能力有多大（提示：通常您所需要的就是这个）。
- en: The benefits of single-threaded programming
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单线程编程的好处
- en: You will be hard-pressed to find any significant number of professional software
    engineers working on enterprise-grade software willing to deny that multithreaded
    software development is painful. However, why is it so hard to do well?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 很难找到任何数量可观的专业软件工程师愿意否认多线程软件开发是痛苦的。然而，为什么做得好这么难呢？
- en: It is not that multithreaded programming is difficult per se—the difficultly
    lies in the complexity of thread synchronization. It is very difficult to build
    high concurrency using the thread model, especially models in which the state
    is shared. Anticipating every way that an action taken in one thread might affect
    all the others is nearly impossible once an application grows beyond the most
    basic of shapes. Entanglements and collisions multiply rapidly, sometimes corrupting
    shared memory, sometimes creating bugs nearly impossible to track down.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 并不是说多线程编程本身很困难-困难在于线程同步的复杂性。使用线程模型构建高并发性非常困难，特别是在状态共享的模型中。一旦应用程序超出最基本的形状，几乎不可能预料到一个线程中的操作可能如何影响其他所有线程。纠缠和冲突迅速增加，有时会破坏共享内存，有时会创建几乎不可能追踪的错误。
- en: 'Node''s designers chose to recognize the speed and parallelization advantages
    of threads without demanding that developers did the same. In particular, Node''s
    designers wanted to save developers from managing the difficulties that accompany
    threaded systems:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Node的设计者选择认识到线程的速度和并行化优势，而不要求开发人员也这样做。特别是，Node的设计者希望免除开发人员管理伴随线程系统的困难。
- en: Shared memory and the locking behavior leads to systems that are very difficult
    to reason about as they grow in complexity.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共享内存和锁定行为导致系统在复杂性增加时变得非常难以理解。
- en: Communication between tasks requires the implementation of a wide range of synchronization
    primitives, such as mutexes and semaphores, condition variables, and so forth.
    An already challenging environment requires highly complex tools, expanding the
    level of expertise necessary to complete even relatively simple systems.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务之间的通信需要实现各种同步原语，如互斥锁和信号量、条件变量等。一个本来就具有挑战性的环境需要高度复杂的工具，扩展了完成甚至相对简单系统所需的专业知识水平。
- en: Race conditions and deadlocks are common pitfalls in these sorts of systems.
    Contemporaneous read and write operations within a shared program space lead to
    problems of sequencing, where two threads may be in an unpredictable *race* for
    the right to influence a state, event, or other key system characteristic.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些系统中常见的竞争条件和死锁是常见的陷阱。在共享程序空间内同时进行读写操作会导致顺序问题，两个线程可能会不可预测地*竞争*影响状态、事件或其他关键系统特征的权利。
- en: As maintaining dependable boundaries between threads and their states is so
    difficult, ensuring that a library (what for Node would be a *module*) is thread-safe
    consumes a great deal of developer time. Can I know that this library will not
    destroy some part of my application? Guaranteeing thread safety requires great
    diligence on the part of a library's developer and these guarantees may be conditional;
    for example, a library may be thread-safe when reading, but not when writing.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于在线程之间和它们的状态之间保持可靠的边界是如此困难，确保一个库（对于Node来说是一个*模块*）是线程安全的需要大量的开发人员时间。我能知道这个库不会破坏我的应用的某个部分吗？保证线程安全需要库开发人员的极大细心，而这些保证可能是有条件的；例如，一个库在读取时可能是线程安全的，但在写入时可能不是。
- en: 'The primary argument for single-threading is that control flow is difficult
    in concurrent environments, and especially so when memory access or code execution
    order is unpredictable:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 单线程的主要论点是，在并发环境中控制流是困难的，特别是当内存访问或代码执行顺序是不可预测的时候：
- en: Instead of concerning themselves with arbitrary locking and other collisions,
    developers can focus on constructing execution chains whose ordering is predictable.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发人员不再需要关注任意锁定和其他冲突，可以专注于构建可预测顺序的执行链。
- en: As parallelization is accomplished through the use of multiple processes, each
    with an individual and distinct memory space, communication between processes
    remains uncomplicated—via the Rule of Simplicity, we achieve not only simple and
    bug-free components, but easier interoperability as well.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于并行化是通过使用多个进程完成的，每个进程都有一个独立和不同的内存空间，进程之间的通信保持简单——通过简单性原则，我们不仅实现了简单和无错的组件，还实现了更容易的互操作性。
- en: As state is not (arbitrarily) shared between individual Node processes; a single
    process is automatically protected from surprise visits from other processes bent
    on memory reallocation or resource monopolization. Communication is through clear
    channels using basic protocols, all of which make it very difficult to write programs
    that make unpredictable changes across processes.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于状态不会（任意地）在单个Node进程之间共享；单个进程会自动受到保护，不会受到其他进程对内存重新分配或资源垄断的意外访问。通信是通过清晰的通道和基本协议进行的，所有这些都使得编写跨进程进行不可预测更改的程序变得非常困难。
- en: 'Thread-safety is one less concern for developers to waste time worrying about.
    As single-threaded concurrency obviates the collisions present in multithreaded
    concurrency, development can proceed more quickly, on surer ground. In the following
    diagram, we see on the left how sharing state across threads requires diligent
    management to guard against collisions while on the right, a "share-nothing" architecture
    avoids collisions and blocking actions:'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程安全是开发人员不再需要浪费时间担心的一个问题。由于单线程并发消除了多线程并发中存在的冲突，开发可以更快地进行，更加稳固。在下图中，我们可以看到左侧如何跨线程共享状态需要细心管理以防止冲突，而右侧的“无共享”架构避免了冲突和阻塞动作：
- en: '![](img/3da79fcb-5688-4fe0-bb98-5a24cd07bf7b.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3da79fcb-5688-4fe0-bb98-5a24cd07bf7b.png)'
- en: A single thread efficiently managed by an event loop brings stability, maintainability,
    readability, and resilience to Node programs. The big news is that Node continues
    to deliver the speed and power of multithreading to its developers—the brilliance
    of Node's design makes such power transparent, reflecting one part of Node's stated
    aim of bringing the most power to the most people with the least difficulty.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 由事件循环高效管理的单个线程为Node程序带来了稳定性、可维护性、可读性和韧性。重要的消息是，Node继续向开发人员提供多线程的速度和能力——Node设计的精华使得这种能力变得透明，反映了Node既定目标的一部分，即为最多的人带来最大的力量，而最少的困难。
- en: 'In the following diagram, the differences between two single-threaded models
    and a multithreaded model are shown:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，展示了两种单线程模型和多线程模型之间的差异：
- en: '![](img/39063bd4-4b00-4411-b0ae-c614baa4aa91.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/39063bd4-4b00-4411-b0ae-c614baa4aa91.png)'
- en: There is no escape from blocking operations—reading from a file, for example,
    will always take some time. A single-threaded synchronous model forces each task
    to wait for others to finish prior to starting, consuming more time. Several tasks
    can be started in parallel using threads, even at different times, where total
    execution time is no longer than that taken by the longest running thread. When
    using threads, the developer becomes responsible for synchronizing the activity
    of each individual thread, using locks or other scheduling tools. This can become
    very complex when the number of threads increases, and in this complexity live
    very subtle and hard-to-find bugs.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 没有逃脱阻塞操作的可能性——例如，从文件中读取始终需要一些时间。单线程同步模型迫使每个任务在开始之前等待其他任务完成，消耗更多时间。使用线程可以并行启动多个任务，甚至在不同的时间，总执行时间不会超过最长运行线程所需的时间。当使用线程时，开发人员需要负责同步每个单独线程的活动，使用锁定或其他调度工具。当线程数量增加时，这可能变得非常复杂，而在这种复杂性中存在非常微妙和难以发现的错误。
- en: Rather than having the developer struggle with this complexity, Node itself
    manages I/O threads. You need not micromanage I/O threading; one simply designs
    an application to establish data availability points (callbacks) and the instructions
    to be executed once the said data is available. Threads provide the same efficiency
    under the hood, and yet their management is exposed to the developer through an
    easily comprehensible interface.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 与其让开发人员为这种复杂性而苦苦挣扎，Node本身管理I/O线程。您无需微观管理I/O线程；只需设计一个应用程序来建立数据可用性点（回调），以及一旦该数据可用就执行的指令。线程在底层提供了相同的效率，但它们的管理通过一个易于理解的接口暴露给开发人员。
- en: Multithreading is already native and transparent
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多线程已经是本地和透明的
- en: Node's I/O thread pool executes within the OS scope, and its work is distributed
    across cores (just as any other job scheduled by the OS would be similarly distributed).
    When you are running Node, you are already taking advantage of its multithreaded
    execution.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Node的I/O线程池在操作系统范围内执行，并且其工作分布在核心之间（就像操作系统安排的任何其他作业一样）。当您运行Node时，您已经利用了其多线程执行。
- en: In the upcoming discussion of child processes and the Cluster module, we will
    see this style of parallelism—of multiple parallel processes—in action. We will
    see how Node is not denied the full power of an OS.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在即将讨论的子进程和集群模块中，我们将看到这种并行性的实现。我们将看到Node并没有被剥夺操作系统的全部功能。
- en: As we saw earlier, when discussing Node's core architecture, the V8 thread in
    which one executes JavaScript programs is bound to `libuv`, which functions as
    the main, system-level, I/O event dispatcher. In this capacity, `libuv` handles
    the timers, filesystem calls, network calls, and other I/O operations requested
    by the relevant JavaScript process or module commands, such as `fs.readFile` and `http.createServer`.
    Therefore, the main V8 event loop is best understood as a control-flow programming
    interface, supported and powered by the highly-efficient, multithreaded, system
    delegate `libuv`.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所看到的，在讨论Node的核心架构时，执行JavaScript程序的V8线程绑定到`libuv`，后者作为主要的系统级I/O事件分发器。在这种情况下，`libuv`处理由相关JavaScript进程或模块命令请求的定时器、文件系统调用、网络调用和其他I/O操作，例如`fs.readFile`和`http.createServer`。因此，主V8事件循环最好被理解为一个控制流编程接口，由高效的、多线程的系统代理`libuv`支持和驱动。
- en: '*Bert Belder*, one of Node''s core contributors, is also one of the core contributors
    to `libuv`. In fact, Node''s development has provoked a simultaneous increase
    in `libuv` development, a feedback loop that has only improved the speed and stability
    of both the projects. It has merged and replaced the `libeo` and `libev` libraries
    that formed the original core of Node''s stack.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*Bert Belder*，Node的核心贡献者之一，也是`libuv`的核心贡献者之一。事实上，Node的发展引发了`libuv`开发的同时增加，这种反馈循环只会提高这两个项目的速度和稳定性。它已经合并并取代了形成Node原始核心的`libeo`和`libev`库。'
- en: 'Consider another of Raymond''s rules, the **Rule of Separation**: "Separate
    policy from mechanism; separate interfaces from engines." The engine that powers
    Node''s asynchronous, event-driven style of programming is `libuv`; the interface
    to that engine is V8''s JavaScript runtime. Continuing with Raymond, look at this:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑雷蒙德的另一条规则，**分离原则**：“分离策略和机制；分离接口和引擎。”驱动Node的异步、事件驱动编程风格的引擎是`libuv`；该引擎的接口是V8的JavaScript运行时。继续看雷蒙德的话：
- en: '"One way to effect that separation is, for example, to write your application
    as a library of C service routines that are driven by an embedded scripting language,
    with the application flow of control written in the scripting language rather
    than C."'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '"实现这种分离的一种方法是，例如，将您的应用程序编写为由嵌入式脚本语言驱动的C服务例程库，其中控制流程由脚本语言而不是C编写。"'
- en: The ability to orchestrate hyper-efficient parallel OS processes within the
    abstraction of a single predictable thread exists by design, not as a concession.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在单个可预测线程的抽象中编排超高效的并行操作系统进程的能力是有意设计的，而不是妥协。
- en: It concludes a pragmatic analysis of how the application development process
    can be improved, and it is certainly not a limitation on what is possible.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 它总结了应用程序开发过程如何改进的务实分析，绝对不是对可能性的限制。
- en: 'A detailed unpacking of libuv can be found at: [https://github.com/nikhilm/uvbook](https://github.com/nikhilm/uvbook).
    **Burt Belder** also gives an in-depth talk on how libuv, and Node, works under
    the hood at: [https://www.youtube.com/watch?v=PNa9OMajw9w](https://www.youtube.com/watch?v=PNa9OMajw9w).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: libuv的详细拆包可以在以下网址找到：[https://github.com/nikhilm/uvbook](https://github.com/nikhilm/uvbook)。**Burt
    Belder**也在以下网址深入讲解了libuv和Node在内部是如何工作的：[https://www.youtube.com/watch?v=PNa9OMajw9w](https://www.youtube.com/watch?v=PNa9OMajw9w)。
- en: Creating child processes
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建子进程
- en: Software development is no longer the realm of monolithic programs. Applications
    running on networks cannot forego interoperability. Modern applications are distributed
    and decoupled. We now build applications that connect users with resources distributed
    across the internet. Many users are accessing shared resources simultaneously.
    A complex system is easier to understand if the whole is understood as a collection
    of interfaces to programs that solve one or a few clearly defined, related problems.
    In such a system, it is expected (and desirable) that processes do not sit idle.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 软件开发不再是单片程序的领域。在网络上运行的应用程序不能放弃互操作性。现代应用程序是分布式和解耦的。我们现在构建连接用户与分布在互联网上的资源的应用程序。许多用户同时访问共享资源。如果整个复杂系统被理解为解决一个或几个明确定义的相关问题的程序接口的集合，那么这样的系统更容易理解。在这样的系统中，预期（并且是可取的）进程不会空闲。
- en: 'An early criticism of Node was that it did not have multicore awareness, that
    is, if a Node server were running on a machine with several cores, it would not
    be able to take advantage of this extra horsepower. Within this seemingly reasonable
    criticism hid an unjustified bias based on a straw man: a program that is unable
    to explicitly allocate memory and execution *threads* in order to implement parallelization
    cannot handle enterprise-grade problems.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Node的早期批评是它没有多核意识，也就是说，如果Node服务器在具有多个核心的机器上运行，它将无法利用这种额外的计算能力。在这个看似合理的批评中隐藏着一种基于草人的不公正偏见：一个程序如果无法显式分配内存和执行*线程*以实现并行化，就无法处理企业级问题。
- en: This criticism is a persistent one. It is also not true.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这种批评是持久的。这也是不正确的。
- en: 'While a single Node process runs on a single core, any number of Node processes
    can be *spun up* through use of the `child_process` module. Basic usage of this
    module is straightforward: we fetch a `ChildProcess` object and listen for data
    events. This example will call the `ls` Unix command, listing the current directory:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然单个Node进程在单个核心上运行，但可以通过`child_process`模块生成任意数量的Node进程。该模块的基本用法很简单：我们获取一个`ChildProcess`对象并监听数据事件。此示例将调用Unix命令`ls`，列出当前目录：
- en: '[PRE0]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here, we spawn the `ls` process (list directory), and read from the resulting
    `readable` Stream, receiving something like this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们生成了`ls`进程（列出目录），并从生成的`readable`流中读取，接收到类似以下内容：
- en: '[PRE1]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Any number of child processes can be spawned in this way. It is important to
    note here that when a child process is spawned, or otherwise created, the OS itself
    assigns the responsibility for that process to a given CPU. Node is not responsible
    for how an OS allocates resources. The upshot is that on a machine with eight
    cores, it is likely that spawning eight processes will result in each being allocated
    to independent processors. In other words, child processes are automatically spread
    by the OS across CPUs, putting the lie to claims that Node cannot take full advantage
    of multicore environments.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 可以以这种方式生成任意数量的子进程。这里需要注意的是，当生成子进程或以其他方式创建子进程时，操作系统本身会将该进程的责任分配给特定的CPU。Node不负责操作系统分配资源的方式。结果是，在具有八个核心的机器上，生成八个进程很可能会导致每个进程分配到独立的处理器。换句话说，操作系统会自动将子进程跨CPU分配，这证明了Node可以充分利用多核环境的说法是错误的。
- en: 'Each new Node process (child) is allocated 10 MB of memory, and represents
    a new V8 instance that will take at least 30 milliseconds to start up. While it
    is unlikely that you will be spawning many thousands of these processes, understanding
    how to query and set OS limits on user-created processes is beneficial; htop or
    top will report the number of processes currently running, or you can use `ps
    aux | wc –l` from the command line. The `ulimit` Unix command ([https://ss64.com/bash/ulimit.html](https://ss64.com/bash/ulimit.html))
    provides important information on user limits on an OS. Passing `ulimit`, the
    –u argument will show the maximum number of user processes that can be spawned.
    Changing the limit is accomplished by passing it as an argument: `ulimit –u 8192`.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 每个新的Node进程（子进程）分配了10MB的内存，并表示一个至少需要30毫秒启动的新V8实例。虽然您不太可能生成成千上万个这样的进程，但了解如何查询和设置用户创建进程的操作系统限制是有益的；htop或top将报告当前运行的进程数量，或者您可以在命令行中使用`ps
    aux | wc –l`。`ulimit` Unix命令（[https://ss64.com/bash/ulimit.html](https://ss64.com/bash/ulimit.html)）提供了有关操作系统上用户限制的重要信息。通过传递`ulimit`，-u参数将显示可以生成的最大用户进程数。通过将其作为参数传递来更改限制：`ulimit
    –u 8192`。
- en: 'The `child_process` module represents a class exposing four main methods: `spawn`,
    `fork`, `exec`, and `execFile`. These methods return a `ChildProcess` object that
    extends `EventEmitter`, exposing an interface to child events and a few functions
    that are helpful in managing child processes. We''ll take a look at its main methods
    and follow up with a discussion of the common `ChildProcess` interface.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`child_process`模块表示一个公开四个主要方法的类：`spawn`、`fork`、`exec`和`execFile`。这些方法返回一个扩展了`EventEmitter`的`ChildProcess`对象，公开了一个用于管理子进程的接口和一些有用的函数。我们将看一下它的主要方法，然后讨论常见的`ChildProcess`接口。'
- en: Spawning processes
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成进程
- en: 'This powerful command allows a Node program to start and interact with processes
    spawned via system commands. In the preceding example, we used spawn to call a
    native OS process, `ls`, passing the `lh` and `.` arguments to that command. In
    this way, any process can be started just as one might start it via a command
    line. The method takes three arguments:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这个强大的命令允许Node程序启动并与通过系统命令生成的进程进行交互。在前面的示例中，我们使用spawn调用了一个本机操作系统进程`ls`，并传递了`lh`和`.`参数给该命令。通过这种方式，任何进程都可以像通过命令行启动一样启动。该方法接受三个参数：
- en: '**command**: A command to be executed by the OS shell'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**命令**：要由操作系统shell执行的命令'
- en: '**arguments (optional)**: These are command-line arguments, sent as an array'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**参数（可选）**：这些是作为数组发送的命令行参数'
- en: '**options**: An optional map of settings for spawn'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选项**：用于`spawn`的可选设置映射'
- en: 'The options for `spawn` allow its behavior to be carefully customized:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`spawn`的选项允许仔细定制其行为：'
- en: '`cwd` (String): By default, the command will understand its current working
    directory to be the same as that of the Node process calling spawn. Change that
    setting using this directive.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cwd`（字符串）：默认情况下，命令将理解其当前工作目录与调用spawn的Node进程相同。使用此指令更改该设置。'
- en: '`env` (Object): This is used to pass environment variables to a child process.
    For instance, consider spawning a child with an environment object, such as the
    following:'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`env`（对象）：用于将环境变量传递给子进程。例如，考虑使用环境对象生成子进程，如下所示：'
- en: '[PRE2]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The child process environment will have access to these values:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 子进程环境将可以访问这些值：
- en: '`detached` (Boolean): When a parent spawns a child, both processes form a group,
    and the parent is normally the leader of that group. To make a child the group
    leader, use detached. This will allow the child to continue running even after
    the parent exits. This is because the parent will wait for the child to exit by
    default. You can call `child.unref()` to tell the parent''s event loop that it
    should not count the child reference, and exit if no other work exists.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`detached`（布尔值）：当父进程生成子进程时，两个进程形成一个组，父进程通常是该组的领导者。使用`detached`可以使子进程成为组的领导者。这将允许子进程在父进程退出后继续运行。这是因为父进程默认会等待子进程退出。您可以调用`child.unref()`告诉父进程的事件循环不应计算子引用，并在没有其他工作存在时退出。'
- en: '`uid` (Number): Set the `uid` (user identity) directive for the child process,
    in terms of standard system permissions, such as a UID that has execute privileges
    on the child process.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`uid`（数字）：设置子进程的`uid`（用户标识）指令，以标准系统权限的形式，例如具有子进程执行权限的UID。'
- en: '`gid` (Number): Set the `gid` (group identity) directive for the child process,
    in terms of standard system permissions, such as a GID that has execute privileges
    on the child process.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: gid（数字）：为子进程设置`gid`（组标识）指令，以标准系统权限的形式，例如具有对子进程执行权限的GID。
- en: '`stdio` (String or Array): Child processes have file descriptors, the first
    three being the `process.stdin`, `process.stdout` and `process.stderr` standard
    I/O descriptors, in order (fds = 0,1,2). This directive allows those descriptors
    to be redefined, inherited, and so forth.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: stdio（字符串或数组）：子进程具有文件描述符，前三个是`process.stdin`，`process.stdout`和`process.stderr`标准I/O描述符，按顺序（fds
    = 0,1,2）。此指令允许重新定义、继承这些描述符等。
- en: 'Consider the output of the following child process program:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下子进程程序的输出：
- en: '[PRE3]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here, a parent would listen on `child.stdout`. Instead, if we want a child
    to inherit its parent''s `stdio`, such that when the child writes to `process.stdout`,
    what is emitted is piped through to the parent''s `process.stdout`, we would pass
    the relevant parent file descriptors to the child, overriding its own:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，父进程将监听`child.stdout`。相反，如果我们希望子进程继承其父进程的`stdio`，这样当子进程写入`process.stdout`时，发出的内容会通过管道传输到父进程的`process.stdout`，我们将传递相关的父进程文件描述符给子进程，覆盖其自己的文件描述符：
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this case, the child's output would pipe straight through to the parent's
    standard output channel. Also, see fork, as follows, for more information on this
    kind of pattern.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，子进程的输出将直接传输到父进程的标准输出通道。此外，有关此类模式的更多信息，请参见fork如下。
- en: 'Each of the three (or more) file descriptors can take one of six values:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 三个（或更多）文件描述符可以取六个值中的一个：
- en: '**pipe**: This creates a pipe between the child and the parent. As the first
    three child file descriptors are already exposed to the parent (`child.stdin`,
    `child.stdout`, and `child.stderr`), this is only necessary in more complex child
    implementations.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管道：这在子进程和父进程之间创建了一个管道。由于前三个子文件描述符已经暴露给了父进程（`child.stdin`，`child.stdout`和`child.stderr`），这只在更复杂的子实现中是必要的。
- en: '**ipc**: This creates an IPC channel for passing messages between a child and
    parent. A child process may have a maximum of one IPC file descriptor. Once this
    connection is established, the parent may communicate with the child via `child.send`.
    If the child sends JSON messages through this file descriptor, those emissions
    can be caught using `child.on("message")`. If running a Node program as a child,
    it is likely a better choice to use `ChildProcess.fork`, which has this messaging
    channel built in.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ipc：这在子进程和父进程之间创建了一个IPC通道，用于传递消息。子进程可能有一个IPC文件描述符。一旦建立了这种连接，父进程可以通过`child.send`与子进程通信。如果子进程通过此文件描述符发送JSON消息，则可以使用`child.on("message")`捕获这些消息。如果作为子进程运行Node程序，可能更好的选择是使用`ChildProcess.fork`，它内置了这个消息通道。
- en: '**ignore**: The file descriptors 0-2 will have `/dev/null` attached to them.
    For others, the referenced file descriptor will not be set on the child.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ignore：文件描述符0-2将附加到`/dev/null`。对于其他文件描述符，将不会在子进程上设置引用的文件描述符。
- en: '**A stream object**: This allows the parent to share a stream with the child.
    For demonstration purposes, given a child that will write the same content to
    any provided `WritableStream`, we can do something like this:'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流对象：这允许父进程与子进程共享流。为了演示目的，假设有一个子进程，它将相同的内容写入任何提供的`WritableStream`，我们可以这样做：
- en: '[PRE5]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The child will now fetch its content and pipe it to whichever output stream
    it has been sent:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 子进程现在将获取其内容并将其传输到已发送的任何输出流：
- en: '[PRE6]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**An integer**: A file descriptor ID.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整数：文件描述符ID。
- en: '**null and undefined**: These are the default values. For file descriptors
    0-2 (`stdin`, `stdout`, and `stderr`), a pipe is created; others default to `ignore`.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: null和undefined：这些是默认值。对于文件描述符0-2（`stdin`，`stdout`和`stderr`），将创建一个管道；其他默认为`ignore`。
- en: In addition to passing `stdio` settings as an array, certain common groupings
    can
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 除了将`stdio`设置作为数组传递之外，还可以将某些常见的分组传递
- en: 'be implemented by passing one of these shortcut string values:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 通过传递以下这些快捷字符串值之一来实现：
- en: '`''ignore'' = [''ignore'', ''ignore'', ''ignore'']`'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''ignore'' = [''ignore'', ''ignore'', ''ignore'']`'
- en: '`''pipe'' = [''pipe'', ''pipe'', ''pipe'']`'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''pipe'' = [''pipe'', ''pipe'', ''pipe'']`'
- en: '`''inherit'' = [process.stdin, process.stdout, process.stderr]`'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`''inherit'' = [process.stdin, process.stdout, process.stderr]`'
- en: '`[0,1,2]`'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`[0,1,2]`'
- en: We have shown some examples of using `spawn` to run Node programs as child processes.
    While this is a perfectly valid usage (and a good way to try out the API options),
    `spawn` is primarily for running system commands. Refer to the discussion of `fork`,
    as follows, for more information on running Node processes as children.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经展示了使用`spawn`来运行Node程序作为子进程的一些示例。虽然这是一个完全有效的用法（也是尝试API选项的好方法），但`spawn`主要用于运行系统命令。有关将Node进程作为子进程运行的更多信息，请参阅fork的讨论如下。
- en: 'It should be noted that the ability to spawn any system process means that
    one can use Node to run other application environments installed on the OS. If
    one had the popular PHP language installed, the following would be possible:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 应该注意的是，生成任何系统进程的能力意味着可以使用Node来运行安装在操作系统上的其他应用程序环境。如果安装了流行的PHP语言，就可以实现以下功能：
- en: '[PRE7]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Running a more interesting, larger program would be just as easy.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 运行一个更有趣、更大的程序同样容易。
- en: 'Apart from the ease with which one might run Java or Ruby or other programs
    through Node using this technique, asynchronously, we also have a good answer
    to a persistent criticism of Node here: JavaScript is not as fast as other languages
    for crunching numbers, or doing other CPU-heavy tasks. This is true, in the sense
    that Node is primarily optimized for I/O efficiency and helping with the management
    of high-concurrency applications, and JavaScript is an interpreted language without
    a strong focus on heavy computation.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 除了通过这种技术异步地运行Java或Ruby或其他程序，我们还对Node的一个持久的批评有了一个很好的回答：JavaScript在处理数字或执行其他CPU密集型任务方面不如其他语言快。这是真的，从这个意义上说，Node主要针对I/O效率进行了优化，并帮助管理高并发应用程序，并且JavaScript是一种解释性语言，没有专注于重型计算。
- en: However, using `spawn`, one can very easily pass off massive computations and
    long-running routines on analytics engines or calculation engines to separate
    processes in other environments. Node's simple event loop will be sure to notify
    the main application when those operations are done, seamlessly integrating the
    resultant data. In the meantime, the main application is free to keep serving
    clients.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用`spawn`，可以很容易地将大量计算和长时间运行的例程传递给其他环境中的独立进程，例如分析引擎或计算引擎。当这些操作完成时，Node的简单事件循环将确保通知主应用程序，无缝地集成产生的数据。与此同时，主应用程序可以继续为客户端提供服务。
- en: Forking processes
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分叉进程
- en: Like `spawn`, `fork` starts a child process, but is designed for running Node
    programs with the added benefit of having a communication channel built in. Rather
    than passing a system command to `fork` as its first argument, one passes the
    path to a Node program. As with `spawn`, command-line options can be sent as a
    second argument, accessible via `process.argv` in the forked child process.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 与`spawn`一样，`fork`启动一个子进程，但设计用于运行Node程序，并具有内置的通信通道的额外好处。与将系统命令作为其第一个参数传递给`fork`不同，可以将路径传递给Node程序。与`spawn`一样，命令行选项可以作为第二个参数发送，并在分叉的子进程中通过`process.argv`访问。
- en: 'An optional options object can be passed as its third argument, with the following
    parameters:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 可选的选项对象可以作为第三个参数传递，具有以下参数：
- en: '`cwd` (String): By default, the command will understand its current working
    directory to be the same as that of the Node process calling `fork`. Change that
    setting using this directive.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cwd`（字符串）：默认情况下，命令将理解其当前工作目录与调用`fork`的Node进程的相同。使用此指令更改该设置。'
- en: '`env` (Object): This is used to pass environment variables to a child process.
    Refer to spawn.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`env`（对象）：这用于将环境变量传递给子进程。参考spawn。'
- en: '`encoding` (String): This sets the encoding of the communication channel.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoding`（字符串）：这设置了通信通道的编码。'
- en: '`execPath` (String): This is the executable used to create the child process.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`execPath`（字符串）：这是用于创建子进程的可执行文件。'
- en: '`silent` (Boolean): By default, a forked child will have its `stdio` associated
    with the parent''s (`child.stdout` is identical to `parent.stdout`, for example).
    Setting this option to true disables this behavior.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`silent`（布尔值）：默认情况下，fork的子进程将与父进程关联（例如，`child.stdout`与`parent.stdout`相同）。将此选项设置为true将禁用此行为。'
- en: An important difference between `fork` and `spawn` is that the former's child
    process does not automatically exit when it is finished. Such a child must explicitly
    exit when it is done, easily accomplished via `process.exit()`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`fork`和`spawn`之间的一个重要区别是，前者的子进程在完成时不会自动退出。这样的子进程在完成时必须显式退出，可以通过`process.exit()`轻松实现。'
- en: 'In the following example, we create a child that emits an incrementing number
    every tenth of a second, which its parent then dumps to the system console. First,
    let''s look at the child program:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的例子中，我们创建一个子进程，每十分之一秒发出一个递增的数字，然后父进程将其转储到系统控制台。首先，让我们看看子程序：
- en: '[PRE8]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Again, this will simply write a steadily increasing number. Remembering that
    with `fork`, a child will inherit the `stdio` of its parent, we only need to create
    the child in order to get output in a Terminal running the parent process:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，这将简单地写入一个不断增加的数字。记住，使用`fork`，子进程将继承其父进程的`stdio`，我们只需要创建子进程即可在运行父进程的终端中获得输出：
- en: '[PRE9]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The silent option can be demonstrated here; `fork(''./emitter.js'', [], { silent:
    true });` turns off any output to the Terminal.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '这里可以演示静默选项；`fork(''./emitter.js'', [], { silent: true });`关闭了对终端的任何输出。'
- en: 'Creating multiple, parallel processes is easy. Let''s multiply the number of
    children created:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 创建多个并行进程很容易。让我们增加创建的子进程数量：
- en: '[PRE10]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: It should be clear at this point that by using `fork`, we are creating many
    parallel execution contexts, spread across all machine cores.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 到这一点应该很清楚，通过使用`fork`，我们正在创建许多并行执行上下文，分布在所有机器核心上。
- en: 'This is straightforward enough, but the `fork` built-in communication channel provides
    makes communicating with forked children even easier, and cleaner. Consider the
    following file, which spawns a child process and communicates with it:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这足够简单，但内置的`fork`通信通道使得与分叉子进程的通信变得更加容易和清晰。考虑以下文件，它生成一个子进程并与其通信：
- en: '[PRE11]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We see that there is a communication channel now available, through which the
    parent can send messages, as well as receiving messages from the child process,
    given below:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到现在有一个通信通道可用，通过它父进程可以发送消息，同时也可以接收来自子进程的消息，如下所示：
- en: '[PRE12]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'By executing the parent script, we will see the following in our console:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 通过执行父脚本，我们将在控制台中看到以下内容：
- en: '[PRE13]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We'll go a little deeper into this important concept of cross-process communication
    shortly.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将很快深入探讨这个重要的跨进程通信概念。
- en: Buffering process output
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缓冲进程输出
- en: 'In cases where the complete buffered output of a child process is sufficient,
    with no need to manage data through events, `child_process` offers the `exec`
    method. The method takes three arguments:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，子进程的完整缓冲输出足够，无需通过事件管理数据，`child_process`提供了`exec`方法。该方法接受三个参数：
- en: '**command:** A command-line string. Unlike `spawn` and `fork`, which pass arguments
    to a command via an array, this first argument accepts a full command string,
    such as `ps aux | grep node`.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**command：**命令行字符串。与`spawn`和`fork`不同，它通过数组将参数传递给命令，这个第一个参数接受一个完整的命令字符串，例如`ps
    aux | grep node`。'
- en: '**options:** This is an optional argument:'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选项：**这是一个可选参数：'
- en: '`cwd` (String): This sets the working directory for the command process.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cwd`（字符串）：这设置了命令进程的工作目录。'
- en: '`env` (Object): This is a map of key-value pairs that will be exposed to the
    child process.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`env`（对象）：这是一个键值对的映射，将被暴露给子进程。'
- en: '`encoding` (String): This is the encoding of the child''s data stream. The
    default value is `''utf8''`.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encoding`（字符串）：这是子进程数据流的编码。默认值为`''utf8''`。'
- en: '`timeout` (Number): This specifies the milliseconds to wait for the process
    to complete, at which point the child process will be sent the `killSignal.maxBuffer`
    value.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timeout`（数字）：这指定等待进程完成的毫秒数，此时子进程将收到`killSignal.maxBuffer`值。'
- en: '`killSignal.maxBuffer` (Number): This is the maximum number of bytes allowed
    on `stdout` or `stderr`. When this number is exceeded, the process is killed.
    This default is 200 KB.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`killSignal.maxBuffer`（数字）：这是`stdout`或`stderr`上允许的最大字节数。当超过这个数字时，进程将被杀死。默认为200
    KB。'
- en: '`killSignal` (String): The child process receives this signal after a timeout.
    This default is `SIGTERM`.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`killSignal`（字符串）：在超时后，子进程接收到此信号。默认为`SIGTERM`。'
- en: '**callback**: This receives three arguments: an `Error` object, if any, `stdout`
    (a `Buffer` object containing the result), `stderr` (a `Buffer` object containing
    error data, if any). If the process was killed, `Error.signal` will contain the
    kill signal.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回调**：这个接收三个参数：一个`Error`对象（如果有的话），`stdout`（包含结果的`Buffer`对象），`stderr`（包含错误数据的`Buffer`对象，如果有的话）。如果进程被杀死，`Error.signal`将包含杀死信号。'
- en: When you want the buffering behavior of `exec` but are targeting a Node file,
    use `execFile`. Importantly, `execFile` does not spawn a new subshell, which makes
    it slightly less expensive to run.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 当您想要`exec`的缓冲行为，但是针对的是一个Node文件时，请使用`execFile`。重要的是，`execFile`不会生成一个新的子shell，这使得它的运行成本稍微降低。
- en: Communicating with your child
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与您的子进程通信
- en: 'All instances of the `ChildProcess` object extend `EventEmitter`, exposing
    events useful for managing child data connections. Additionally, `ChildProcess`
    objects expose some useful methods for interacting with children directly. Let''s
    go through those now, beginning with attributes and methods:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 所有`ChildProcess`对象的实例都扩展了`EventEmitter`，公开了用于管理子数据连接的有用事件。此外，`ChildProcess`对象公开了一些有用的方法，用于直接与子进程交互。现在让我们来看一下这些方法，首先是属性和方法：
- en: '`child.connected`: When a child is disconnected from its parent via `child.disconnect()`,
    this flag will be set to `false`.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`child.connected`: 当子进程通过`child.disconnect()`与其父进程断开连接时，此标志将设置为`false`。'
- en: '`child.stdin`: This is a `WritableStream` corresponding to the child''s standard
    in.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`child.stdin`: 这是一个对应于子进程标准输入的`WritableStream`。'
- en: '`child.stdout`: This is a `ReadableStream` corresponding to the child''s standard
    out.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`child.stdout`: 这是一个对应于子进程标准输出的`ReadableStream`。'
- en: '`child.stderr`: This is a `ReadableStream` corresponding to the child''s standard
    error.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`child.stderr`: 这是一个对应于子进程标准错误的`ReadableStream`。'
- en: '`child.pid`: This is an integer representing the process ID (PID) assigned
    to the child process.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`child.pid`: 这是一个整数，表示分配给子进程的进程ID（PID）。'
- en: '`child.kill`: This tries to terminate a child process, sending it an optional
    signal. If no signal is specified, the default is `SIGTERM` (for more about signals,
    visit: [https://en.wikipedia.org/wiki/Signal_(IPC)](https://en.wikipedia.org/wiki/Signal_(IPC))).
    While the method name sounds terminal, it is not guaranteed to kill a process—it
    only sends a signal to a process. Dangerously, if `kill` is attempted on a process
    that has already exited, it is possible that another process that has been newly
    assigned the PID of the dead process will receive the signal, with indeterminable
    consequences. This method should fire a `close` event, which the signal used to
    close the process.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`child.kill`: 尝试终止子进程，发送一个可选的信号。如果未指定信号，则默认为`SIGTERM`（有关信号的更多信息，请访问：[https://en.wikipedia.org/wiki/Signal_(IPC)](https://en.wikipedia.org/wiki/Signal_(IPC))）。虽然方法名称听起来是终端的，但不能保证杀死进程
    - 它只是向进程发送一个信号。危险的是，如果尝试对已经退出的进程进行`kill`，则可能会导致新分配了死进程的PID的另一个进程接收到信号，后果不可预测。此方法应该触发`close`事件，该事件用于关闭进程的信号。'
- en: '`child.disconnect()`: This command severs the IPC connection between the child
    and its parent. The child will then die gracefully, as it has no IPC channel to
    keep it alive. You may also call `process.disconnect()` from within the child
    itself. Once a child has disconnected, the `connected` flag on that child reference
    will be set to `false`.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`child.disconnect()`: 此命令断开子进程与其父进程之间的IPC连接。然后，子进程将会优雅地死去，因为它没有IPC通道来保持其存活。您也可以在子进程内部调用`process.disconnect()`。一旦子进程断开连接，该子引用上的`connected`标志将被设置为`false`。'
- en: Sending messages to children
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向子进程发送消息
- en: 'As we saw in our discussion of `fork`, and when using the `ipc` option on `spawn`,
    child processes can be sent messages via `child.send`, with the message passed
    as the first argument. A TCP server, or socket handle, can be passed along with
    the message as a second argument. In this way, a TCP server can spread requests
    across multiple child processes. For example, the following server distributes
    socket handling across a number of child processes equaling the total number of
    CPUs available. Each forked child is given a unique ID, which it reports when
    started. Whenever the TCP server receives a socket, that socket is passed as a
    handle to a random child process:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在讨论`fork`时所看到的，并且在`spawn`的`ipc`选项上使用时，子进程可以通过`child.send`发送消息，消息作为第一个参数传递。可以将TCP服务器或套接字句柄作为第二个参数传递。通过这种方式，TCP服务器可以将请求分布到多个子进程。例如，以下服务器将套接字处理分布到等于可用CPU总数的多个子进程。每个分叉的子进程都被赋予一个唯一的ID，在启动时报告。每当TCP服务器接收到一个套接字时，该套接字将作为一个句柄传递给一个随机的子进程：
- en: '[PRE14]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'That child process then sends a unique response, demonstrating that socket
    handling is being distributed:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，该子进程发送一个唯一的响应，证明了套接字处理正在分布式进行：
- en: '[PRE15]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Start the parent server in a Terminal window. In another window, run `telnet
    127.0.0.1 8080`. You should see something similar to the following output, with
    a random child ID being displayed on each connection (assuming that there exist
    multiple cores):'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个终端窗口中启动父服务器。在另一个窗口中，运行`telnet 127.0.0.1 8080`。您应该看到类似以下输出，每次连接都显示一个随机的子ID（假设存在多个核心）：
- en: '[PRE16]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Hit that endpoint a few more times. You should see that your requests are being
    serviced by different child processes.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 多次访问该端点。您应该看到您的请求是由不同的子进程处理的。
- en: Parsing a file using multiple processes
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用多个进程解析文件
- en: One of the tasks many developers will take on is the building of a logfile processor.
    A logfile can be very large and many megabytes long. Any single program working
    on a very large file can easily run into memory problems or simply run much too
    slowly. It makes sense to process a large file in pieces. We'll build a simple
    log processor that breaks up a big file into pieces and assigns one to each of
    several child workers, running them in parallel.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 许多开发人员将承担的任务之一是构建日志文件处理器。日志文件可能非常大，有数兆字节长。任何一个单独处理非常大文件的程序都很容易遇到内存问题，或者运行速度太慢。逐块处理大文件是有意义的。我们将构建一个简单的日志处理器，将大文件分成多个部分，并将每个部分分配给几个子工作进程，以并行运行它们。
- en: 'The entire code for this example can be found in the `logproc` folder of the
    code bundle. We will focus on the main routines:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例的完整代码可以在代码包的`logproc`文件夹中找到。我们将专注于主要例程：
- en: Determining the number of lines in the logfile
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定日志文件中的行数
- en: Breaking those up into equal chunks
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将它们分成相等的块
- en: Creating one child for each chunk and passing it parse instructions
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为每个块创建一个子进程并传递解析指令
- en: Assembling and displaying the results
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组装并显示结果
- en: 'To get the word count of our file, we use the `wc` command with `child.exec`,
    as shown in the following code:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得文件的字数，我们使用`child.exec`和`wc`命令，如下面的代码所示：
- en: '[PRE17]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let''s say that we use `fileChunkLength` of 500,000 lines. This means four
    child processes are to be created, and each will be told to process a range of
    500,000 lines in our file, such as 1 to 500,000:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们使用500,000行的`fileChunkLength`。这意味着将创建四个子进程，并且每个子进程将被告知处理文件中的500,000行的范围，例如1到500,000：
- en: '[PRE18]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Each of these workers will themselves use a child process to grab their allotted
    chunk, employing `sed`, the native Stream Editor for Unix:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工作进程本身将使用子进程来获取它们分配的块，使用`sed`，这是Unix的本地流编辑器：
- en: '[PRE19]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Here, we are executing the `sed –n ''500001,1000001p'' logfile.txt` command, which
    plucks the given range of lines and returns them for processing. Once we''re done
    processing the columns of data (adding them up, and so forth), this child will
    return its data to the master (as described earlier) and the data results will
    be written to a file, otherwise manipulated, or sent to `stdout`, as shown in
    the following output:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们执行`sed –n '500001,1000001p' logfile.txt`命令，该命令会提取给定范围的行并返回它们以进行处理。一旦我们处理完数据的列（将它们相加等），子进程将把数据返回给主进程（如前所述），数据结果将被写入文件，否则将被操作，或者发送到`stdout`，如下图所示：
- en: '![](img/82dec7c0-d77b-4218-9152-3bab484979d4.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](img/82dec7c0-d77b-4218-9152-3bab484979d4.jpg)'
- en: The full file for this example is much longer, but all that extra code is merely
    formatting and other detail—the Node child process management we have described
    suffices to create a parallelized system for number crunching that will process
    many millions of lines of code in seconds. By using more processes spread across
    more cores, the log parsing speed can be reduced even further.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例的完整文件要长得多，但所有额外的代码只是格式和其他细节——我们已经描述的Node子进程管理足以创建一个并行化的系统，用于处理数百万行代码，只需几秒钟。通过使用更多的进程分布在更多的核心上，日志解析速度甚至可以进一步降低。
- en: View  the `README.MD` file in the `/logproc` folder in your code bundle to experiment
    with this example.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的代码包中的`/logproc`文件夹中查看`README.MD`文件，以尝试此示例。
- en: Using the cluster module
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用集群模块
- en: As we saw when processing large logfiles, the pattern of a master parent controller
    for many child processes is just right for vertical scaling in Node. In response
    to this, the Node API has been augmented by a `cluster` module, which formalizes
    this pattern and helps make its achievement easier. Continuing with Node's core
    purpose of helping make scalable network software easier to build, the particular
    goal of cluster is to facilitate the sharing of network ports among many children.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在处理大型日志文件时所看到的，一个主父控制器对多个子进程的模式非常适合Node的垂直扩展。作为对此的回应，Node API已经通过`cluster`模块进行了增强，该模块正式化了这种模式，并有助于更容易地实现它。继续Node的核心目标，帮助构建可扩展的网络软件更容易，`cluster`的特定目标是促进在许多子进程之间共享网络端口。
- en: 'For example, the following code creates a `cluster` of worker processes all
    sharing the same HTTP connection:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下代码创建了一个共享相同HTTP连接的工作进程的`cluster`：
- en: '[PRE20]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We'll dig into the details shortly. For now, note that `cluster.fork` has taken
    zero arguments. What does `fork` without a command or file argument do? Within
    a `cluster`, the default action is to `fork` the current program. We see during
    `cluster.isMaster`, the action is to `fork` children (one for each available CPU).
    When this program is reexecuted in a forking context, `cluster.isWorker` will
    be `true` and a new HTTP server *running on a shared port* is started. Multiple
    processes are sharing the load for a single server.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将很快深入了解细节。现在，请注意`cluster.fork`没有带任何参数。`fork`没有命令或文件参数会做什么？在`cluster`中，默认操作是`fork`当前程序。我们在`cluster.isMaster`期间看到，操作是`fork`子进程（每个可用的CPU一个）。当这个程序在分叉的上下文中重新执行时，`cluster.isWorker`将为`true`，并且将启动一个在共享端口上运行的新HTTP服务器。多个进程共享单个服务器的负载。
- en: Start and connect to this server with a browser. You will see something like
    `Hello from 8`, the integer corresponding to the unique `cluster.worker.id` value
    of the worker that assigned responsibility for handling your request. Balancing
    across all workers is handled automatically, such that refreshing your browser
    a few times will result in different worker IDs being displayed.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 使用浏览器启动并连接到此服务器。您将看到类似`Hello from 8`的内容，这是与负责处理您的请求的唯一`cluster.worker.id`值相对应的整数。自动处理所有工作进程的负载平衡，因此刷新浏览器几次将导致显示不同的工作进程ID。
- en: 'Later on, we''ll go through an example of sharing a socket server across a
    cluster. For now, we''ll lay out the cluster API, which breaks down into two sections:
    the methods, attributes, and events available to the cluster master, and those
    available to the child. As workers in this context are defined using fork, the
    documentation for that method of `child_process` can be applied here as well:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 稍后，我们将通过一个示例来介绍如何在集群中共享套接字服务器。现在，我们将列出集群API，它分为两部分：可用于集群主进程的方法、属性和事件，以及可用于子进程的方法、属性和事件。在这种情况下，使用fork定义工作进程，`child_process`的该方法的文档也可以应用于这里：
- en: '`cluster.isMaster`: This is the Boolean value indicating whether the process
    is a master.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cluster.isMaster`：这是一个布尔值，指示进程是否为主进程。'
- en: '`cluster.isWorker`: This is the Boolean value indicating whether the process
    was forked from a master.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cluster.isWorker`：这是一个布尔值，指示进程是否是从主进程fork出来的。'
- en: '`cluster.worker`: This will bear a reference to the current worker object,
    only available to a child process.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cluster.worker`：这将引用当前工作进程对象，仅对子进程可用。'
- en: '`cluster.workers`: This is a hash containing references to all active worker
    objects, keyed by the worker ID. Use this to loop through all worker objects.
    This only exists within the master process.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cluster.workers`：这是一个哈希，包含对所有活动工作进程对象的引用，以工作进程ID为键。在主进程中使用此方法循环遍历所有工作进程对象。这仅存在于主进程中。'
- en: '`cluster.setupMaster([settings])`: This is a convenient way of passing a map
    of default arguments to be used when a child is forked. If all children will fork
    the same file (as is often the case), you will save time by setting it here. The
    available defaults are as follows:'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cluster.setupMaster([settings])`：这是一种方便的方法，用于传递默认参数映射，以在fork子进程时使用。如果所有子进程都将fork相同的文件（通常情况下），通过在这里设置，可以节省时间。可用的默认值如下：'
- en: '`exec` (String): This is the file path to the process file, defaulting to `__filename`.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`exec`（字符串）：这是进程文件的文件路径，默认为`__filename`。'
- en: '`args` (Array): This contains Strings sent as arguments to the child process.
    The default is to fetch arguments with `process.argv.slice(2)`.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`args`（数组）：这包含作为参数发送到子进程的字符串。默认情况下，使用`process.argv.slice(2)`获取参数。'
- en: '`silent` (Boolean): This specifies whether or not to send output to the master''s
    stdio, defaulting to false.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`silent`（布尔值）：这指定是否将输出发送到主进程的stdio，默认为false。'
- en: '`cluster.fork([env])`: This creates a new worker process. Only the master process
    may call this method. To expose a map of key-value pairs to the child''s process
    environment, send an object to `env`.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cluster.fork([env])`：创建一个新的工作进程。只有主进程可以调用此方法。要将键值对映射暴露给子进程的环境，请发送一个对象到`env`。'
- en: '`cluster.disconnect([callback])`: This is used to terminate all workers in
    a cluster. Once all the workers have died gracefully, the cluster process will
    itself terminate if it has no further events to wait on. To be notified when all
    children have expired, pass `callback`.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cluster.disconnect([callback])`：用于终止集群中的所有工作进程。一旦所有工作进程都已经优雅地死亡，如果集群进程没有更多事件需要等待，它将自行终止。要在所有子进程过期时收到通知，请传递`callback`。'
- en: Cluster events
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群事件
- en: 'The cluster object emits several events, listed as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 集群对象发出几个事件，如下所列：
- en: '`fork`: This is fired when the master tries to fork a new child. This is not
    the same as `online`. This receives a `worker` object.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fork`：当主进程尝试fork一个新的子进程时触发。这与`online`不同。这接收一个`worker`对象。'
- en: '`online`: This is fired when the master receives notification that a child
    is fully bound. This differs from the `fork` event and receives a `worker` object.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`online`：当主进程收到子进程完全绑定的通知时触发。这与`fork`事件不同，并接收一个`worker`对象。'
- en: '`listening`: When the worker performs an action that requires a `listen()`
    call (such as starting an HTTP server), this event will be fired in the master.
    The event emits two arguments: a `worker` object, and the address object containing
    the `address`, `port`, and `addressType` values of the connection.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`listening`：当工作进程执行需要`listen()`调用的操作（例如启动HTTP服务器）时，此事件将在主进程中触发。该事件发出两个参数：一个`worker`对象和包含连接的`address`、`port`和`addressType`值的地址对象。'
- en: '`disconnect`: This is called whenever a child disconnects, which can happen
    either through process exit events or after calling `child.kill()`. This will
    fire prior to the `exit` event—they are not the same. This receives a `worker`
    object.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`disconnect`：每当子进程断开连接时调用，这可能是通过进程退出事件或调用`child.kill()`后发生的。这将在`exit`事件之前触发-它们不是相同的。这接收一个`worker`对象。'
- en: '`exit`: Whenever a child dies, this event is emitted. The event receives three
    arguments: a `worker` object, the exit code number, and the signal string, such
    as `SIGNUP`, which caused the process to be killed.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`exit`：每当子进程死亡时，都会触发此事件。该事件接收三个参数：一个`worker`对象，退出代码数字和导致进程被杀死的信号字符串，如`SIGNUP`。'
- en: '`setup`: This is called after `cluster.setupMaster` has executed.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setup`：在`cluster.setupMaster`执行后调用。'
- en: Worker object properties
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作进程对象属性
- en: 'Workers have the following attributes and methods:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 工作进程具有以下属性和方法：
- en: '`worker.id`: This is the unique ID assigned to a worker, also representing
    the worker''s key in the `cluster.workers` index.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`worker.id`：这是分配给工作进程的唯一ID，也代表`cluster.workers`索引中的工作进程键。'
- en: '`worker.process`: This specifies a `ChildProcess` object referencing a worker.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`worker.process`：这指定了一个引用工作进程的`ChildProcess`对象。'
- en: '`worker.suicide`: The workers that have recently had `kill` or `disconnect`
    called on them will have their `suicide` attribute set to `true`.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`worker.suicide`：最近已经对其进行了`kill`或`disconnect`调用的工作进程将其`suicide`属性设置为`true`。'
- en: '`worker.send(message, [sendHandle])`: Refer to `child_process.fork()`, which
    is previously mentioned.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`worker.send(message, [sendHandle])`：参考之前提到的`child_process.fork()`。'
- en: '`worker.kill([signal])`: This kills a worker. The master can check this worker''s
    suicide property in order to determine whether the death was intentional or accidental.
    The default signal value that is sent is `SIGTERM`.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`worker.kill([signal])`：杀死一个工作进程。主进程可以检查该工作进程的`suicide`属性，以确定死亡是有意还是意外的。发送的默认信号值是`SIGTERM`。'
- en: '`worker.disconnect()`: This instructs a worker to disconnect. Importantly,
    the existing connections to the worker are not immediately terminated (as with
    `kill`), but are allowed to exit normally prior to the worker fully disconnecting.
    This is because the existing connections may stay in existence for a very long
    time. It is a good pattern to regularly check whether the worker has actually
    disconnected, perhaps using timeouts.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`worker.disconnect()`：这指示工作人员断开连接。重要的是，与工作人员的现有连接不会立即终止（与`kill`一样），而是允许它们正常退出，然后工作人员完全断开连接。这是因为现有连接可能存在很长时间。定期检查工作人员是否实际断开连接可能是一个很好的模式，也许可以使用超时。'
- en: Worker events
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作人员事件
- en: 'Workers also emit events, such as the ones mentioned in the following list:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 工作人员也会发出事件，例如以下列表中提到的事件：
- en: '`message`: Refer to `child_process.fork`'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`message`：参考`child_process.fork`'
- en: '`online`: This is identical to `cluster.online`, except that the check is against
    only the specified worker'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`online`：这与`cluster.online`相同，只是检查仅针对指定的工作人员'
- en: '`listening`: This is identical to `cluster.listening`, except that the check
    is against only the specified worker'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`listening`：这与`cluster.listening`相同，只是检查仅针对指定的工作人员'
- en: '`disconnect`: This is identical to `cluster.disconnect`, except that the check
    is against only the specified worker'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`disconnect`：这与`cluster.disconnect`相同，只是检查仅针对指定的工作人员'
- en: '`exit`: Refer to the `exit` event for `child_process`'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`exit`：参考`child_process`的`exit`事件'
- en: '`setup`: This is called after `cluster.setupMaster` has executed'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setup`：在`cluster.setupMaster`执行后调用'
- en: Now, using what we now know about the `cluster` module, let's implement a real-time
    tool for analyzing the streams of data emitted by many users simultaneously interacting
    with an application.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，根据我们现在对`cluster`模块的了解，让我们实现一个实时工具，用于分析许多用户同时与应用程序交互时发出的数据流。
- en: Using PM2 to manage multiple processes
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PM2管理多个进程
- en: PM2 is designed to be an enterprise-level process manager. As discussed elsewhere,
    Node runs within a Unix process, and its child process and cluster modules are
    used to spawn further processes, typically when scaling an application across
    multiple cores. PM2 can be used to instrument deployment and monitoring of your
    Node processes, both via the command line and programmatically. PM2 spares the
    developer the complexity of configuring clustering boilerplate, handles restarts
    automatically, and provides advanced logging and monitoring tools out of the box.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: PM2旨在成为企业级进程管理器。如其他地方所讨论的，Node在Unix进程中运行，其子进程和集群模块用于在跨多个核心扩展应用程序时生成更多进程。PM2可用于通过命令行和以编程方式进行部署和监视Node进程。PM2免除了开发人员配置集群样板的复杂性，自动处理重启，并提供了开箱即用的高级日志记录和监视工具。
- en: 'Install PM2 globally: `npm install pm2 -g`'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 全局安装PM2：`npm install pm2 -g`
- en: 'The most straightforward way to use PM2 is as a simple process runner. The
    following program will increment and log a value every second:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 使用PM2的最简单方法是作为一个简单的进程运行程序。以下程序将每秒递增并记录一个值：
- en: '[PRE21]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Here, we fork a new process from `script.js`, running it in the background
    *forever*, until we stop it. This is a great way to run a daemonized process:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们从`script.js`中派生一个新的进程，在后台*永远*运行，直到我们停止它。这是运行守护进程的绝佳方式：
- en: '[PRE22]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Once the script launches, you should see something like this in your terminal:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本启动后，您应该在终端中看到类似于以下内容：
- en: '![](img/c79e0330-beca-4f40-af85-6c6b84c36df8.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/c79e0330-beca-4f40-af85-6c6b84c36df8.png)
- en: The meaning of most of the values should be clear, such as the amount of memory
    your process is using, whether or not it is online, how long it has been up, and
    so forth (the mode and watching fields will be explained shortly). The process
    will continue to run until it is stopped or deleted.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数值的含义应该是清楚的，例如您的进程使用的内存量，它是否在线，它已经运行了多长时间等（模式和观看字段将很快解释）。进程将继续运行，直到停止或删除。
- en: 'To set a custom name for your process when you start it, pass the `--name`
    argument to PM2: `pm2 start script.js --name ''myProcessName''`.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 要在启动进程时为其设置自定义名称，请将`--name`参数传递给PM2：`pm2 start script.js --name 'myProcessName'`。
- en: This overview of all running PM2 processes can be brought up at any time via
    the command `pm2 list`.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 可以随时通过命令`pm2 list`查看所有正在运行的PM2进程的概述。
- en: 'PM2 offers other straightforward commands:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: PM2提供其他简单的命令：
- en: '`pm2 stop <app_name | id | all>` : Stop a process by name, id or stop all processes.
    A stopped process remains in the process list, and can be later restarted.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pm2 stop <app_name | id | all>`：按名称停止进程，id或停止所有进程。已停止的进程将保留在进程列表中，并且可以稍后重新启动。'
- en: '`pm2 restart <app_name | id | all>` : Restart a process. The number of process
    restarts is displayed under restarted in all process lists. To automatically restart
    a process when it reaches some maximum memory limit (say, 15M) use the command
    `pm2 start script.js --max-memory-restart 15M`.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pm2 restart <app_name | id | all>`：重新启动进程。在所有进程列表中显示了进程重新启动的次数。要在达到某个最大内存限制（比如15M）时自动重新启动进程，请使用命令`pm2
    start script.js --max-memory-restart 15M`。'
- en: '`pm2 delete <app_name | id | all>` : Deletes a process. This process cannot
    be restarted. pm2 delete all deletes all PM2 processes.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pm2 delete <app_name | id | all>`：删除进程。此进程无法重新启动。pm2 delete all删除所有PM2进程。'
- en: '`pm2 info <app_name | id >` : Provides detailed info on a process.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pm2 info <app_name | id>`：提供有关进程的详细信息。'
- en: 'You will be using `pm2 info <processname>` often. Ensure that `script.js` is
    running as a PM2 process using `PM2 list`, then inspect that process info with
    `pm2 info script`:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 您将经常使用`pm2 info <processname>`。确保`script.js`作为PM2进程运行，使用`PM2 list`，然后使用`pm2
    info script`检查该进程信息：
- en: '![](img/480ac271-bf14-4d44-9e8f-bd564a647a33.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/480ac271-bf14-4d44-9e8f-bd564a647a33.png)
- en: 'Note the paths given for error and other logs. Remember that our script increments
    an integer by one every second and logs that count. If you `cat /path/to/script/out/log`
    your terminal will show what has been written to the out log, which should be
    a list of incrementing numbers. Errors are similarly written to a log. Furthermore,
    you can stream the output logs in real time with `pm2 logs`:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 注意为错误和其他日志给出的路径。请记住，我们的脚本每秒递增一个整数并记录该计数。如果您`cat /path/to/script/out/log`，您的终端将显示已写入输出日志的内容，这应该是一个递增的数字列表。错误同样会写入日志。此外，您可以使用`pm2
    logs`实时流式传输输出日志：
- en: '![](img/97391b02-5a37-4577-bcf7-78b0d0b619ad.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![](img/97391b02-5a37-4577-bcf7-78b0d0b619ad.png)'
- en: To clear all logs, use `pm2 flush`.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 要清除所有日志，请使用`pm2 flush`。
- en: 'You can also use PM2 programmatically. To replicate the steps we took to run
    `scripts.js` with PM2, first create the following script, `programmatic.js`:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以以编程方式使用PM2。要复制我们使用PM2运行`scripts.js`的步骤，首先创建以下脚本`programmatic.js`：
- en: '[PRE23]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This script will use the pm2 module to run `script.js` as a process. Go ahead
    and run it with `node programmatic.js`. Executing a `pm2 list` should show that
    programmed script runner is alive:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本将使用pm2模块将`script.js`作为进程运行。继续使用`node programmatic.js`运行它。执行`pm2 list`应该显示编程脚本运行器是活动的：
- en: '![](img/2592f665-3ed5-4929-8a02-b014a68ffe9e.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2592f665-3ed5-4929-8a02-b014a68ffe9e.png)'
- en: To make sure, try `pm2 logs` -- you should see numbers being incremented, just
    as before. You can read about the full set of programmatic options here: [http://pm2.keymetrics.io/docs/usage/pm2-api/](http://pm2.keymetrics.io/docs/usage/pm2-api/).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 要确保，请尝试`pm2 logs`——您应该看到数字正在递增，就像以前一样。您可以在此处阅读有关完整编程选项的信息：[http://pm2.keymetrics.io/docs/usage/pm2-api/](http://pm2.keymetrics.io/docs/usage/pm2-api/)。
- en: Monitoring
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控
- en: 'PM2 makes process monitoring easy. To view real-time statistics on CPU and
    memory usage for your processes, simply enter the command `pm2 monit`:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: PM2使进程监控变得简单。要查看进程的CPU和内存使用情况的实时统计信息，只需输入命令`pm2 monit`：
- en: '![](img/205b443c-55ea-47d0-b1be-1526cedfd881.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![](img/205b443c-55ea-47d0-b1be-1526cedfd881.png)'
- en: Pretty nice, right? On a production server where your Node app is managed via
    PM2, you can use this interface to get a quick look into an application's state,
    including memory usage and a running log.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 相当不错，对吧？在通过PM2管理的生产服务器上，您可以使用此界面快速查看应用程序的状态，包括内存使用情况和运行日志。
- en: 'PM2 also makes it easy to create web-based monitoring interfaces – it’s as
    simple as running `pm2 web`. This command will start a monitored process listening
    on port 9615 -- running `pm2 list` will now list a process named `pm2-http-interface`.
    Run the web command and then navigate to `localhost:9615` in your browser. You
    will see a detailed snapshot of your processes, OS, and so forth, as a JSON object:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: PM2还可以轻松创建基于Web的监控界面——只需运行`pm2 web`即可。此命令将启动一个在端口9615上监听的受监视进程——运行`pm2 list`现在将列出一个名为`pm2-http-interface`的进程。运行web命令，然后在浏览器中导航到`localhost:9615`。您将看到有关您的进程、操作系统等的详细快照，以JSON对象的形式：
- en: '[PRE24]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Creating a web-based UI that polls your server every few seconds, fetches process
    information, and then graphs it is made much simpler due to this built-in feature
    of PM2\. PM2 also has an option to set a watcher on all managed scripts, such
    that any changes on the watched script will cause an automatic process restart.
    This is very useful when developing.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个基于Web的UI，每隔几秒轮询您的服务器，获取进程信息，然后绘制图表，由于PM2的这一内置功能，变得更加简单。PM2还有一个选项，可以在所有管理的脚本上设置一个监视器，这样监视的脚本的任何更改都会导致自动进程重启。这在开发过程中非常有用。
- en: 'As a demonstration, let’s create a simple HTTP server and run it through PM2:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 作为演示，让我们创建一个简单的HTTP服务器并通过PM2运行它：
- en: '[PRE25]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This server will echo “Hello World” whenever `localhost:8080` is hit. Now, lets
    use a PM2 process file to do more involved configuration.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 每当访问`localhost:8080`时，此服务器将回显“Hello World”。现在，让我们使用PM2进程文件进行更多涉及配置。
- en: Process files
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进程文件
- en: 'Go ahead and kill all running PM2 processes with pm2 delete all. Then, create
    the following `process.json` file:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 继续使用`pm2 delete all`杀死所有正在运行的PM2进程。然后，创建以下`process.json`文件：
- en: '[PRE26]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We''re going to use this deployment definition to start our application on
    PM2\. Note that apps is an array, which means you can list several different applications
    with different configurations and start them all at once. We''ll explain the fields
    in a second, but for now, execute this manifest with `pm2 start process.json`.
    You should see something like this:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用此部署定义在PM2上启动我们的应用程序。请注意，apps是一个数组，这意味着您可以列出几个不同的应用程序，并使用不同的配置同时启动它们。我们将在下面解释这些字段，但现在，请使用`pm2
    start process.json`执行此清单。您应该会看到类似于这样的内容：
- en: '![](img/bff9c69a-8e2a-4a83-97ac-6785f5e67314.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bff9c69a-8e2a-4a83-97ac-6785f5e67314.png)'
- en: It was that easy to deploy a multiprocess (clustered) application. PM2 will
    automatically balance load across your instances, set to 4 CPUs in the manifest
    via the `instances` attribute, with `exec_mode` of *cluster* (default mode is
    "fork"). In production, you would likely want to balance across the maximum number
    of cores, which you can flag simply by setting `instances` to `0`. Additionally,
    you see that we've set environment variables via `env:` you can create a *dev*
    and a *prod* (and maybe even a *stage*) configuration for your server, set API
    keys and passwords, and other environment variables here.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 部署多进程（集群）应用程序如此简单。PM2将自动在实例之间平衡负载，在清单中通过`instances`属性设置为4个CPU，`exec_mode`为*cluster*（默认模式为“fork”）。在生产环境中，您可能希望在最大核心数之间平衡负载，只需将`instances`设置为`0`即可。此外，您可以看到我们通过`env:`设置了环境变量，您可以在此处为服务器创建*dev*和*prod*（甚至*stage*）配置，设置API密钥和密码以及其他环境变量。
- en: 'Open a browser and visit `localhost:8080` to see that the server is running.
    Note that we set `watch` to `true` in our JSON manifest. This tells PM2 to automatically
    restart the application, across all cores, whenever any files are changed in your
    repository. Test it by changing the "Hello" message from your server to something
    else. If you then reload `localhost:8080`, you will see the new message, indicating
    that the servers have been restarted. If you list running PM2 processes, you will
    see the number of restarts:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 打开浏览器并访问`localhost:8080`，以查看服务器是否正在运行。请注意，在我们的JSON清单中，我们将`watch`设置为`true`。这告诉PM2在您的存储库中更改任何文件时自动重新启动应用程序，跨所有核心。通过更改服务器上的“Hello”消息为其他内容来测试它。然后重新加载`localhost:8080`，您将看到新消息，表明服务器已重新启动。如果列出正在运行的PM2进程，您将看到重新启动的次数：
- en: '![](img/c0362078-38db-4864-9ce1-1e125a22145d.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c0362078-38db-4864-9ce1-1e125a22145d.png)'
- en: Try it a few times. The restarts are stable, fast, and automatic.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 试着多次尝试。重新启动是稳定的，快速的，自动的。
- en: 'You can also target specific files for the watcher:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以为监视器指定特定的文件：
- en: '[PRE27]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Here, we tell PM2 to watch only `.test` files in `/test`, and the `/app` directory,
    ignoring changes in any .log files. Under the hood PM2 uses Chokidar ([https://github.com/paulmillr/chokidar#api](https://github.com/paulmillr/chokidar#api))
    to watch for file changes, so you can further configure the watcher by setting
    Chokidar options on `watch_options`. Note that you can use glob expressions (and
    regular expressions) in these settings.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们告诉PM2只监视`/test`中的`.test`文件和`/app`目录，忽略任何.log文件的更改。在底层，PM2使用Chokidar ([https://github.com/paulmillr/chokidar#api](https://github.com/paulmillr/chokidar#api))来监视文件更改，因此您可以通过在`watch_options`上设置Chokidar选项来进一步配置监视器。请注意，您可以在这些设置中使用glob表达式（和正则表达式）。
- en: You can read the full list of options for PM2 process files here: [http://pm2.keymetrics.io/docs/usage/application-declaration/](http://pm2.keymetrics.io/docs/usage/application-declaration/).
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此处阅读PM2进程文件的完整选项列表：[http://pm2.keymetrics.io/docs/usage/application-declaration/](http://pm2.keymetrics.io/docs/usage/application-declaration/)。
- en: 'Some to note:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 一些需要注意的地方：
- en: '`max_restarts`: The number of unstable restarts PM2 allows before stopping
    completely.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_restarts`：PM2允许的不稳定重新启动次数。'
- en: '`min_uptime`: The minimum time an app is given to start before being considered
    unstable and triggering a restart.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_uptime`：在被视为不稳定并触发重新启动之前，应用程序被给予启动的最短时间。'
- en: '`autorestart`: Whether to restart at all on a crash.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`autorestart`：是否在崩溃时重新启动。'
- en: '`node_args`: Pass command-line arguments to the Node process itself. For example: `node_args:
    "--harmony"` is equivalent to `node --harmony server.js`.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`node_args`：将命令行参数传递给Node进程本身。例如：`node_args: "--harmony"`相当于`node --harmony
    server.js`。'
- en: '`max_memory_restart`: Restart occurs when memory usage breaks this threshold.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_memory_restart`：当内存使用量超过此阈值时发生重新启动。'
- en: '`restart_delay`: Particularly in `watch` scenarios, you might want to delay
    restarts on file changes, waiting a bit for further edits before reacting.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`restart_delay`：特别是在`watch`场景中，您可能希望在文件更改时延迟重新启动，等待一段时间再做出反应。'
- en: Live development of your server applications just got easier, thanks to PM2.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 由于PM2，服务器应用程序的实时开发变得更加容易。
- en: Real-time activity updates of multiple worker results
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多个工作结果的实时活动更新
- en: 'Using what we''ve learned, we will construct a multiprocess system to track
    the behavior of all visitors to a sample web page. This will be composed of two
    main segments: a WebSocket-powered client library, which will broadcast each time
    a user moves a mouse, and an administration interface visualizing user interaction
    as well as when a user connects and disconnects from the system. Our goal is to
    show how a more complex system might be designed (such as one that tracks and
    graphs every click, swipe, or other interactions a user might make).'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 利用我们所学到的知识，我们将构建一个多进程系统来跟踪所有访问者对示例网页的行为。这将由两个主要部分组成：一个由WebSocket驱动的客户端库，它将在用户移动鼠标时广播每次移动，以及一个管理界面，可视化用户交互以及用户连接和断开系统的时间。我们的目标是展示如何设计一个更复杂的系统（例如跟踪和绘制用户可能进行的每次点击、滑动或其他交互）。
- en: 'The final administration interface will show activity graphs for several users
    and resemble this:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的管理界面将显示几个用户的活动图表，并类似于这样：
- en: '![](img/b44a0606-3afa-4d83-8047-faa9831cc5ea.jpg)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b44a0606-3afa-4d83-8047-faa9831cc5ea.jpg)'
- en: As this system will be tracking the X and Y positions of each mouse motion made
    by all users, we will spread this continuous stream of data across all available
    machine cores using `cluster`, with each worker in the cluster sharing the burden
    of carrying the large amounts of socket data being fed into a single, shared port.
    Go ahead and visit the code bundle for this chapter, and follow the `README.MD`
    instructions in the `/watcher` folder.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 由于该系统将跟踪所有用户所做的每次鼠标移动的X和Y位置，我们将使用`cluster`将这连续的数据流跨越所有可用的机器核心，集群中的每个工作进程都共享承载大量套接字数据的负担，这些数据被馈送到一个共享端口。继续访问本章的代码包，并按照`/watcher`文件夹中的`README.MD`说明进行操作。
- en: 'A good place to start is in designing the mock client page, which is responsible
    solely for catching all mouse movement events and broadcasting them, through a
    `WebSocket`, to our clustered socket server. We are using the native `WebSocket`
    implementation; you may want to use a library to handle older browsers (such as
    `Socket.IO`):'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 一个很好的开始是设计模拟客户端页面，它负责捕获所有鼠标移动事件并通过`WebSocket`将它们广播到我们的集群套接字服务器。我们正在使用本机的`WebSocket`实现；您可能希望使用一个库来处理旧版浏览器（如`Socket.IO`）：
- en: '[PRE28]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Here, we need to simply turn on the basic `mousemove` tracking, which will broadcast
    the position of a user's mouse on each movement to our socket. Additionally, we
    send along a unique user ID, as a tracking client identity will be important to
    us later on. Note that in a production environment, you will want to implement
    a more intelligent unique ID generator, likely though a server-side authentication
    module.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们只需要简单地打开基本的`mousemove`跟踪，它将在每次移动时广播用户鼠标的位置到我们的套接字。此外，我们还发送一个唯一的用户ID，因为跟踪客户端身份对我们来说以后很重要。请注意，在生产环境中，您将希望通过服务器端身份验证模块实现更智能的唯一ID生成器。
- en: 'In order for this information to reach other clients, a centralized socket
    server must be set up. As mentioned, we will want this socket server to be clustered.
    Clustered child processes, each duplicates of the following program, will handle
    mouse data sent by clients:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这些信息传达给其他客户端，必须设置一个集中的套接字服务器。正如前面提到的，我们希望这个套接字服务器是集群的。每个集群子进程，都是以下程序的副本，将处理客户端发送的鼠标数据：
- en: '[PRE29]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'In this demonstration, we are using *Einar Otto Stangvik''s* very fast and
    well-designed socket server library, `ws`, which is hosted on GitHub at: [https://github.com/websockets/ws](https://github.com/websockets/ws)'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个演示中，我们使用了*Einar Otto Stangvik*的非常快速和设计良好的套接字服务器库“ws”，它托管在GitHub上：[https://github.com/websockets/ws](https://github.com/websockets/ws)
- en: Thankfully, our code remains very simple. We have a socket server listening
    for messages (remember that the client is sending an object with mouse *X* and
    *Y* as well as a user ID). Finally, when data is received (the `message` event),
    we parse the received JSON into an object and pass that back to our cluster master
    via `process.send`.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 值得庆幸的是，我们的代码仍然非常简单。我们有一个监听消息的套接字服务器（记住客户端发送的是一个带有鼠标*X*和*Y*以及用户ID的对象）。最后，当接收到数据时（`message`事件），我们将接收到的JSON解析为一个对象，并通过`process.send`将其传递回我们的集群主。
- en: Note as well how we store the last message (`lastMessage`), done for bookkeeping
    reasons, as when a connection terminates, we will need to pass along the last
    user ID seen on this connection to administrators.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意我们如何存储最后一条消息（`lastMessage`），出于簿记原因，当连接终止时，我们将需要将此连接上看到的最后一个用户ID传递给管理员。
- en: The pieces to catch client data broadcasts are now set up. Once this data is
    received, how is it passed to the administration interface previously pictured?
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 现在已经设置好了捕捉客户端数据广播的部分。一旦接收到这些数据，它是如何传递给先前展示的管理界面的？
- en: We've designed this system with scaling in mind, and we want to decouple the
    collection of data from the systems that broadcast data. Our cluster of socket
    servers can accept a constant flow of data from many thousands of clients, and
    should be optimized for doing just that. In other words, the cluster should delegate
    the responsibility for broadcasting mouse activity data to another system, even
    to other servers.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计这个系统时考虑了扩展性，并希望将数据的收集与广播数据的系统分离。我们的套接字服务器集群可以接受来自成千上万客户端的持续数据流，并且应该针对这一点进行优化。换句话说，集群应该将广播鼠标活动数据的责任委托给另一个系统，甚至是其他服务器。
- en: In the next chapter, we will look at more advanced scaling and messaging tools,
    such as message queues and UDP broadcasting. For our purposes here, we will simply
    create an HTTP server responsible for managing connections from administrators
    and broadcasting mouse activity updates to them. We will use SSE for this, as
    the data flow needs to only be one-way, from server to client.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将研究更高级的扩展和消息传递工具，比如消息队列和UDP广播。对于我们在这里的目的，我们将简单地创建一个HTTP服务器，负责管理来自管理员的连接并向他们广播鼠标活动更新。我们将使用SSE来实现这一点，因为数据流只需要单向，从服务器到客户端。
- en: 'The HTTP server will implement a very basic validation system for administrator
    logins, holding on to successful connections in a way that will allow our socket
    cluster to broadcast mouse activity updates to all. It will also serve as a basic
    static file server, sending both the client and administration HTML when requested,
    though we will focus only on how it handles two routes: `admin/adminname;` and
    `/receive/adminname`. Once the server is understood, we will go into how our socket
    cluster connects to it.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP服务器将为管理员登录实现一个非常基本的验证系统，以一种允许我们的套接字集群向所有成功连接广播鼠标活动更新的方式保留成功的连接。它还将作为一个基本的静态文件服务器，当请求时发送客户端和管理HTML，尽管我们只关注它如何处理两个路由：“admin/adminname”和“/receive/adminname”。一旦服务器被理解，我们将进入我们的套接字集群如何连接到它。
- en: 'The first route—`/admin/adminname`—is mostly responsible for validating administrator
    login, also ensuring that this is not a duplicate login. Once that identity is
    established, we can send back an HTML page to the administration interface. The
    specific client code used to draw the graphs previously pictured won''t be discussed
    here. What we do need is an SSE connection to our server such that the interface''s
    graphing tools receive real-time updates of mouse activity. Some JavaScript on
    the returned administrator''s page establishes such a connection:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个路由“/admin/adminname”主要负责验证管理员登录，还要确保这不是重复登录。一旦确认了身份，我们就可以向管理界面发送一个HTML页面。用于绘制先前图片中的图表的特定客户端代码将不在这里讨论。我们需要的是与服务器建立SSE连接，以便界面的图表工具可以实时接收鼠标活动的更新。返回的管理员页面上的一些JavaScript建立了这样的连接：
- en: '[PRE30]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'On our server, we implement the `/receive/adminname` route:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的服务器上，我们实现了“/receive/adminname”路由：
- en: '[PRE31]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The main purpose of this route is to establish an SSE connection and store the
    administrator's connection, so that we can later broadcast to it.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这个路由的主要目的是建立SSE连接并存储管理员的连接，以便我们以后可以向其广播。
- en: We will now add the pieces that will pass mouse activity data along to a visualization
    interface. Scaling this subsystem across cores using the cluster module is our
    next step. The cluster master now simply needs to wait for mouse data from its
    socket-serving children, as described earlier.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将添加一些部分，将鼠标活动数据传递给可视化界面。使用集群模块跨核心扩展这个子系统是我们的下一步。集群主现在只需要等待来自其提供套接字服务的子进程的鼠标数据，就像之前描述的那样。
- en: 'We will use the same ideas presented in the earlier discussion of cluster,
    simply forking the preceding socket server code across all the available CPUs:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用在之前的集群讨论中提出的相同思想，简单地将先前的套接字服务器代码分叉到所有可用的CPU上：
- en: '[PRE32]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Mouse activity data pipes into a cluster worker through a socket and is broadcasted
    via `process.send` to the cluster master described earlier. On each worker message,
    we run through all connected administrators and send mouse data to their visualization
    interfaces using SSE. The administrators can now watch for the arrival and exit
    of clients as well as their individual level of activity.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 鼠标活动数据通过套接字传输到一个集群工作进程，并通过`process.send`广播到之前描述的集群主进程。在每个工作进程的消息中，我们遍历所有连接的管理员，并使用SSE将鼠标数据发送到他们的可视化界面。管理员现在可以观察客户端的到来和离开，以及他们个人的活动水平。
- en: To test the system, first log in as the default admin with `http://localhost:2112/admin/adminname`.
    You should see a turquoise background, empty for now since there are no connected
    clients. Next, create some clients by opening one or more browser windows and
    navigating to `http://localhost:2112`, where you will see a blank screen. Move
    your mouse around on this screen however you'd like. If you return to the admin
    interface you'll see that your mouse movements (one or many clients) are being
    tracked and graphed.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试系统，首先以默认管理员身份登录，网址为`http://localhost:2112/admin/adminname`。你应该会看到一个青绿色的背景，目前为空，因为没有连接的客户端。接下来，通过打开一个或多个浏览器窗口并导航到`http://localhost:2112`来创建一些客户端，你会看到一个空白屏幕。随意在屏幕上移动鼠标。如果你返回管理员界面，你会看到你的鼠标移动（一个或多个客户端）正在被跟踪和绘制成图表。
- en: Summary
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This is the first chapter where we've really begun to test Node's scalability
    goal. Having considered the various arguments for and against different ways of
    thinking about concurrency and parallelism, we arrived at an understanding of
    how Node has successfully maintained the advantages of threading and parallel
    processing while wrapping all that complexity within a concurrency model that
    is both easy to reason about and robust.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们真正开始测试Node可扩展性目标的第一章。在考虑了关于并发和并行思考方式的各种论点之后，我们理解了Node如何成功地在并发模型中包裹了所有这些复杂性，使其易于理解和稳健，同时保持了线程和并行处理的优势。
- en: Having gone deeper into how processes work, and in particular, how child processes
    can communicate with each other, even spawn further children, we looked at some
    use cases. An example of how to combine native Unix command processes seamlessly
    with custom Node processes led us to a performant and straightforward technique
    for processing large files. The cluster module was then applied to the problem
    of how to share responsibility for handling a busy socket between multiple workers,
    this ability to share socket handles between processes demonstrating a powerful
    aspect of Node's design. And we learned about a production-grade process runner,
    PM2, and how it makes managing both single processes and clusters easier.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 深入了解了进程的工作方式，特别是子进程如何相互通信，甚至生成更多的子进程，我们看了一些用例。将原生Unix命令进程与自定义Node进程无缝结合的示例，让我们找到了一种高效且简单的处理大文件的技术。然后，集群模块被应用于如何在多个工作进程之间共享处理繁忙套接字的问题，这种在进程之间共享套接字句柄的能力展示了Node设计的一个强大方面。我们还了解了一个生产级的进程管理器PM2，以及它如何使管理单个进程和集群变得更容易。
- en: Having seen how Node applications might be scaled vertically, we can now look
    into horizontal scaling across many systems and servers. In the next chapter,
    we'll learn how to connect Node with third-party services, such as Amazon and
    Twilio, set up multiple Node servers behind proxies, and more.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在看到了Node应用如何进行垂直扩展之后，我们现在可以研究跨多个系统和服务器的水平扩展。在下一章中，我们将学习如何将Node与亚马逊和Twilio等第三方服务连接，设置多个Node服务器在代理后面，并且更多内容。
