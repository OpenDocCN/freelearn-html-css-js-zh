- en: Chapter 6. Practical Parallelism
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章 实践并行性
- en: In the previous chapter, we walked through the basic capabilities of web workers.
    We used web workers for true parallelism in the browser because they map to real
    threads, which, in turn, map to separate CPUs. This chapter builds on the last,
    providing some motivation for designing parallel code in the first place.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们介绍了web workers的基本功能。我们使用web workers在浏览器中实现真正的并行性，因为它们映射到真实的线程，而这些线程又映射到单独的CPU。本章在此基础上，提供了一些设计并行代码的动机。
- en: We'll start with a brief look at some ideas borrowed from functional programming,
    and how they're a nice fit for concurrency problems. Then, we'll tackle the problem
    of parallel validity by either making the decision to compute in parallel, or
    to simply run on one CPU. Then, we'll go in depth on some concurrency problems
    that would benefit from tasks running in parallel. We'll also address the problem
    of keeping the DOM responsive using workers.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先简要地探讨一些从函数式编程中借鉴的思想，以及它们如何很好地适用于并发问题。然后，我们将通过决定并行计算或简单地在一个CPU上运行来解决并行有效性的问题。接着，我们将深入探讨一些可以从并行运行任务中受益的并发问题。我们还将讨论使用工作者线程保持DOM响应性的问题。
- en: Functional programming
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数式编程
- en: Functions are obviously central to functional programming. But then, so is the
    data that flows through our application. In fact, the data and its movement in
    a program is probably just as important as the implementation of the functions
    themselves, at least as far application design is concerned.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 函数显然是函数式编程的核心。但同样重要的是流经我们应用程序的数据。实际上，程序中的数据和其流动可能和函数本身的实现一样重要，至少从应用程序设计的角度来看。
- en: There's a strong affinity between functional programming and concurrent programming.
    In this section, we'll look at why this is, and how we can apply functional programming
    techniques that can result in stronger concurrent code.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 函数式编程与并发编程之间有着强烈的亲和力。在本节中，我们将探讨这是为什么，以及我们如何应用函数式编程技术，以产生更强的并发代码。
- en: Data in, data out
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据输入，数据输出
- en: Functional programming is just as powerful as other programming paradigms. It's
    a different way of tackling the same problems. We use a different set of tools.
    For example, functions are the building blocks, and we'll use them to build our
    abstractions around data transformations. Imperative programming, on the other
    hand, use constructs, such as classes to build abstractions. The fundamental difference
    is that classes and objects like to encapsulate the state of something, while
    functions are data in, data out.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 函数式编程与其他编程范式一样强大。它是以不同的方式解决相同问题的一种方法。我们使用不同的工具集。例如，函数是构建模块，我们将使用它们来构建围绕数据转换的抽象。另一方面，命令式编程使用诸如类等构造来构建抽象。根本的区别在于类和对象喜欢封装某物的状态，而函数是数据输入，数据输出。
- en: 'For example, let''s say we had a user object with an `enabled` property. The
    idea is that the `enabled` property has a value at any given time, which can change
    at any given time. In other words, the user changes state. If we were to pass
    this object around to different areas of our application, then the state is also
    passed along with it. It''s encapsulated as a property. Any one of these components
    that ends up with a reference to the user object can change it, and then pass
    it somewhere else. And so on, and so on. Here''s an illustration that shows how
    a function can change the state of a user before passing it off to another component:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有一个具有`enabled`属性的`user`对象。这个想法是`enabled`属性在任何给定时间都有一个值，这个值可以随时改变。换句话说，用户改变了状态。如果我们把这个对象传递到我们应用程序的不同区域，那么状态也会随之传递。它被封装为一个属性。任何一个最终获得用户对象引用的组件都可以改变它，然后将其传递到另一个地方。如此等等。以下是一个说明函数如何在一个组件传递之前改变用户状态的图示：
- en: '![Data in, data out](img/B05133_06_01.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![数据输入，数据输出](img/B05133_06_01.jpg)'
- en: 'It''s not like this in functional programming. State isn''t encapsulated inside
    objects and passed around from component to component; not because doing so is
    inherently bad, but because it''s just a different way of addressing the problem.
    Where state encapsulation is a goal of object-oriented programming, getting from
    point A to point B and transforming data along the way is what functional programming
    is all about. There''s no point C—once the function has done its job, it doesn''t
    care about the state of the data. Here''s a functional alternative to the preceding
    diagram:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数式编程中并不像这样。状态不是封装在对象内部并在组件之间传递；这并不是因为这样做本质上不好，而只是解决问题的一种不同方式。在面向对象编程中，状态封装是一个目标，而从A点到B点的转换以及在这个过程中对数据的转换正是函数式编程的全部内容。没有C点——一旦函数完成了它的任务，它就不关心数据的状况。下面是前面图表的函数式替代方案：
- en: '![Data in, data out](img/B05133_06_02.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![数据输入，数据输出](img/B05133_06_02.jpg)'
- en: As we can see, the functional approach creates a new object with the updated
    property value. The function takes data as input and returns new data as output.
    In other words, it doesn't modify the input. It's a simple idea, but one with
    important consequences, such as immutability.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，函数式方法创建了一个具有更新属性值的新对象。函数以数据作为输入，并以新数据作为输出。换句话说，它不修改输入。这是一个简单但具有重大影响的概念，如不可变性。
- en: Immutability
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不可变性
- en: Immutable data is a key functional programming concept and one that fits nicely
    into concurrent programming. JavaScript is a multi-paradigm language. That is,
    it's functional, but it can also be imperative. Some functional programming languages
    strictly enforce immutability—you simply cannot change the state of an object.
    It's actually nice to have the flexibility of choosing when to keep data immutable
    and when it makes sense not to.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 不可变数据是函数式编程的一个关键概念，并且非常适合并发编程。JavaScript是一种多范式语言。也就是说，它是函数式的，但也可以是命令式的。一些函数式编程语言严格强制不可变性——你根本不能改变对象的状态。实际上，选择何时保持数据不可变以及何时不这样做是有益的。
- en: In the last diagram of the previous section, it was shown that the `enable()`
    function actually returns a brand new object with a property value that's different
    from the input value. This is done to avoid mutating the input value. Although,
    this may seem wasteful— constantly creating objects on the fly, but it really
    isn't. Consider all the bookkeeping code that we don't have to write when an object
    never changes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节的最后一个图表中，展示了`enable()`函数实际上返回了一个具有不同属性值的全新对象。这样做是为了避免修改输入值。尽管这看起来可能有些浪费——不断地创建对象，但实际上并不是这样。考虑一下，当对象从不改变时，我们不必编写所有这些记账代码。
- en: 'For example, if the `enabled` property of a user is mutable, then this means
    any component that uses this object needs to constantly check the `enabled` property.
    Here''s an idea of what this looks like:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果用户的`enabled`属性是可变的，那么这意味着任何使用这个对象的组件都需要不断检查`enabled`属性。下面是这个样子的一种想法：
- en: '![Immutability](img/B05133_06_03.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![不可变性](img/B05133_06_03.jpg)'
- en: This check needs to happen whenever a component wants to show the user. We actually
    need to perform this same check using the functional approach. However, the only
    valid starting point with the functional approach is the create path. If something
    else in our system can change the `enabled` property, then we have both the create
    and modify paths to worry about. Eliminating the modify path also eliminates a
    host of other complexities. These are called side-effects.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当组件想要显示用户时，需要发生这种检查。实际上，我们需要使用函数式方法执行相同的检查。然而，使用函数式方法唯一有效的起点是创建路径。如果我们的系统中的其他东西可以改变`enabled`属性，那么我们既要担心创建路径，也要担心修改路径。消除修改路径也消除了许多其他复杂性。这些被称为副作用。
- en: 'Side-effects and concurrency don''t get along well. In fact, it''s the very
    idea that an object can change at all that makes concurrency hard. For example,
    let''s say we have two threads that want to access our user object. They first
    need to acquire access to it, and it might already be locked. Here''s a visualization
    of the idea:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 副作用和并发性并不相容。事实上，一个对象可以改变的想法本身就让并发变得困难。例如，假设我们有两个线程想要访问我们的用户对象。他们首先需要获取对它的访问权限，它可能已经被锁定。下面是这个想法的视觉表示：
- en: '![Immutability](img/B05133_06_04.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![不可变性](img/B05133_06_04.jpg)'
- en: 'Here, we can see that the first thread locks the user object, preventing other
    threads from accessing it. The second thread needs to wait until it''s unlocked
    before it can continue. This is called resource contention, and it diminishes
    the whole purpose of utilizing multiple CPUs. The threads aren''t truly running
    in parallel if they''re waiting for access to some kind of resource. Immutability
    side-steps the resource contention issue because there''s no need to lock resources
    that don''t change. Here''s what the functional approach looks like using two
    threads:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到第一个线程锁定用户对象，阻止其他线程访问它。第二个线程需要等待它被解锁，然后才能继续。这被称为资源竞争，它削弱了利用多个CPU的整个目的。如果线程正在等待访问某种资源，它们实际上并没有真正并行运行。不可变性绕过了资源竞争问题，因为不需要锁定不改变的资源。以下是使用两个线程的函数式方法的样子：
- en: '![Immutability](img/B05133_06_05.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![不可变性](img/B05133_06_05.jpg)'
- en: When objects don't change state, any number of threads can access them concurrently
    without any risk of corrupting the state of an object due to out-of-order operations
    and without wasting valuable CPU time waiting on resources.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当对象不改变状态时，任何数量的线程都可以并发访问它们，而不会因为操作顺序错误而破坏对象状态，也不会浪费宝贵的CPU时间等待资源。
- en: Referential transparency and time
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引用透明性和时间
- en: Functions that take immutable data as input have something called referential
    transparency. This means that given the same object as input, no matter how many
    times it's called, the function will always return the same result. This is a
    useful property because it means that temporal factors are removed from the picture.
    That is, the only factor that can change the result of the function's output,
    is its input—not when it's called relative to other functions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以不可变数据作为输入的函数有一种称为引用透明性的特性。这意味着给定相同的对象作为输入，无论它被调用多少次，函数总是会返回相同的结果。这是一个有用的特性，因为它意味着时间因素被从图中移除。也就是说，唯一可能改变函数输出结果的因素是它的输入——而不是它相对于其他函数被调用的相对时间。
- en: 'Put another way, referentially-transparent functions don''t produce side-effects
    because they work with immutable data. And because of this, the lack of time being
    a factor for function output, they''re well-suited in a concurrent context. Let''s
    take a look at a function that isn''t referentially-transparent:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，引用透明性函数不产生副作用，因为它们与不可变数据一起工作。正因为如此，由于函数输出不受时间因素的影响，它们非常适合并发环境。让我们看看一个不是引用透明的函数：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The way the `getName()` function works depends on the state of the `user` object
    that''s passed to it. If the user object is enabled, we return the name. Otherwise,
    we don''t return anything. This means that the function isn''t referentially transparent
    if it passes mutable data structures, which is the case in the preceding example.
    The `enabled` property changes, and so does the result of the function. Let''s
    fix this situation and make it referentially-transparent with the following code:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`getName()` 函数的工作方式取决于传递给它的 `user` 对象的状态。如果用户对象是启用的，我们返回名称。否则，我们不返回任何内容。这意味着如果函数传递可变数据结构，它就不是引用透明的，这在先前的例子中就是这种情况。`enabled`
    属性会改变，函数的结果也会改变。让我们修复这种情况，并使用以下代码使其具有引用透明性：'
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As we can see, the `updateUserRT()` function doesn't actually change the data.
    It creates a copy that includes the updated property value. This means that we're
    safe to call `updateUser()` with the original user object as input at any time.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，`updateUserRT()` 函数实际上并没有改变数据。它创建了一个包含更新属性值的副本。这意味着我们可以安全地随时使用原始用户对象作为输入调用
    `updateUser()`。
- en: This functional programming technique helps us write concurrent code because
    the order in which we execute operations isn't a factor. Ordering asynchronous
    operations is hard. Immutable data leads to referential transparency, which leads
    to stronger concurrency semantics.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这种函数式编程技术帮助我们编写并发代码，因为执行操作顺序不是一个因素。对异步操作进行排序是困难的。不可变数据导致引用透明性，这导致更强的并发语义。
- en: Do we need to go parallel?
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们需要并行化吗？
- en: Parallelism can be hugely beneficial to us for the right sort of problems. Creating
    workers and synchronizing the communication between them to carry out tasks isn't
    free. For example, we could have this nice, well thought-out parallel code that
    utilizes four CPU cores. But it turns out that the time spent executing the boilerplate
    code to facilitate this parallelism exceeds the cost of simply processing the
    data in a single thread.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于正确类型的问题，并行化可以给我们带来巨大的好处。创建工作者并同步他们之间的通信以执行任务并不是免费的。例如，我们可能有这样一段精心设计的并行代码，它利用了四个CPU核心。但结果是，执行促进这种并行性的样板代码所花费的时间超过了在单个线程中处理数据的成本。
- en: In this section, we'll address the issues associated with validating the data
    that we're processing and determining the hardware capabilities of the system.
    We'll always want to have a synchronous fallback option for the scenarios where
    parallel execution simply doesn't make sense. When we decide to go parallel, our
    next job is to figure out exactly how the work gets distributed to workers. All
    of these checks are performed at runtime.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论与验证我们正在处理的数据以及确定系统硬件能力相关的问题。我们总是希望对于并行执行根本不合理的场景有一个同步回退选项。当我们决定并行处理时，我们的下一个任务是弄清楚工作是如何分配给工作者的。所有这些检查都是在运行时进行的。
- en: How big is the data?
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据有多大？
- en: Sometimes, going parallel just isn't worthwhile. The idea with parallelism is
    to compute more in less time. This gets our results faster, ultimately leading
    to a more responsive user experience. Having said that, there are scenarios where
    the data that we process simply does not justify the use of threads. Even some
    large collections of data may not stand to benefit from parallelization.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，并行处理并不值得。并行处理的想法是在更短的时间内完成更多的计算。这使我们能够更快地得到结果，最终导致更响应的用户体验。尽管如此，有些情况下，我们处理的数据根本无法证明使用线程的合理性。甚至一些大型数据集也可能无法从并行化中获得好处。
- en: The two factors that determine how suitable a given operation is for parallel
    execution are the size of the data and the time complexity of the operation that
    we perform on each item in the collection. Put differently, if we have an array
    with thousands of objects in it, but the computation performed on each object
    is cheap, then there's no real motivation to go parallel. Likewise, we can have
    an array with very few objects, but the operation is expensive. Again, we may
    not benefit from subdividing the work into smaller tasks then distributing them
    to worker threads.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 决定给定操作是否适合并行执行的两个因素是数据的大小和我们对集合中每个项目执行的操作的时间复杂度。换句话说，如果我们有一个包含数千个对象的数组，但每个对象上的计算成本很低，那么实际上没有理由去并行处理。同样，我们可能有一个包含非常少对象的数组，但操作成本很高。再次，我们可能不会从将工作细分到更小的任务并将它们分配给工作线程中受益。
- en: The static factor is the computation that we perform on individual items. At
    design time, we have to have a general idea of whether the code is expensive or
    cheap in terms of CPU cycles. This might require some static analysis, some quick
    benchmarks, or just a glance mixed with know-how and intuition. When we devise
    our criteria for determining whether a given operation is well-suited for parallel
    execution or not, we need to combine the computation itself with the size of the
    data.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 静态因素是我们对单个项目进行的计算。在设计时，我们必须对代码在CPU周期方面的成本有一个大致的了解。这可能需要一些静态分析，一些快速基准测试，或者只是结合经验和直觉的快速浏览。当我们制定判断给定操作是否适合并行执行的标准时，我们需要将计算本身与数据的大小结合起来。
- en: 'Let''s take a look at an example that uses different performance characteristics
    to determine whether or not a given function should be executed in parallel:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个例子，它使用不同的性能特征来确定是否应该并行执行给定的函数：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This function is handy because it's an easy preflight check for us to perform—either
    it's parallel or isn't. If it's not, then we can take the short path of simply
    computing the result and returning it to the caller. If it's parallel, then we'll
    move onto the next stage of figuring out how to subdivide the operation into smaller
    tasks.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数很有用，因为它为我们提供了一个简单的预飞检查——要么是并行，要么不是。如果不是，那么我们可以走捷径，简单地计算结果并将其返回给调用者。如果是并行，那么我们将进入下一个阶段，即弄清楚如何将操作细分成更小的任务。
- en: The `isParallel()` function takes into consideration not only the size of the
    data, but also the cost of performing a computation on any one of data items.
    This lets us fine-tune the concurrency of our application. If there's too much
    overhead, we can increase the parallel processing threshold. If we've made some
    changes to our code that make a previously inexpensive function, expensive. We
    just need to change the `expensiveTask` flag in this scenario.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`isParallel()` 函数不仅考虑了数据的大小，还考虑了在数据项上执行计算的成本。这使得我们可以微调我们应用程序的并发性。如果开销太大，我们可以提高并行处理的阈值。如果我们对代码进行了一些更改，使得之前成本较低的功能变得昂贵。在这种情况下，我们只需更改
    `expensiveTask` 标志。'
- en: Note
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'What happens when our code runs in the main thread just as often as it runs
    in a worker thread? Does this mean that we have to write our task code twice:
    once for sequential code and again for our workers? We obviously want to avoid
    this, so we need to keep our task code modular. It needs to be usable both in
    the main thread and worker threads.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的代码在主线程中运行的频率与在工作线程中运行的频率相同会发生什么？这难道意味着我们必须为我们的任务代码编写两次：一次用于顺序代码，一次用于我们的工作线程？显然，我们希望避免这种情况，因此我们需要使我们的任务代码模块化。它需要在主线程和工作线程中都能使用。
- en: Hardware concurrency capabilities
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 硬件并发能力
- en: Another high-level check that we'll perform in our concurrent applications is
    the concurrency capabilities of the hardware that we're running on. This informs
    us how many web workers to create. For example, there's really nothing for us
    to gain by creating 32 web workers on a system where there are only four CPU cores.
    On this system, four web workers would be more appropriate. So, how do we get
    this number?
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的并发应用程序中，我们还将执行另一个高级别的检查，即我们运行在硬件上的并发能力。这告诉我们应该创建多少个Web工作线程。例如，在一个只有四个CPU核心的系统上创建32个Web工作线程对我们来说实际上没有任何好处。在这种情况下，四个Web工作线程会更合适。那么，我们如何得到这个数字呢？
- en: 'Let''s create a generic function that figures this out for us:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个通用的函数来为我们解决这个问题：
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Since not all browsers implement the `navigator.hardwareConcurrency` property,
    we have to take this into consideration. If we don''t know the exact hardware
    concurrency level, we have to make a guess. Here, we say that four is the most
    common CPU core count that we''re likely to encounter. And since this is a default
    argument value, it is used for both: special-case handling by the caller and easy
    global changes.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于并非所有浏览器都实现了 `navigator.hardwareConcurrency` 属性，我们必须考虑这一点。如果我们不知道确切的硬件并发级别，我们必须做出猜测。在这里，我们说四个是我们最有可能遇到的常见CPU核心数。由于这是一个默认参数值，它既用于调用者的特殊情况处理，也用于简单的全局更改。
- en: Note
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: There are other techniques that attempt to measure the concurrency level by
    spawning worker threads and sampling the rate at which data is returned. This
    is an interesting technique, but not suitable for production applications because
    of the overhead and general uncertainty that's involved. In other words, using
    a static value that covers the majority of our user's systems is good enough.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 有其他技术试图通过生成工作线程并采样数据返回的速率来测量并发级别。这是一个有趣的技术，但由于涉及的开销和一般的不确定性，它不适合生产应用程序。换句话说，使用一个静态值，该值涵盖了大多数用户的系统，就足够了。
- en: Creating tasks and assigning work
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建任务和分配工作
- en: Once we've decided that a given operation should be performed in parallel, and
    we know how many workers to create based on the concurrency level, it's time to
    create some tasks, and assign them to workers. Essentially, this means slicing
    up the input data into smaller chunks and passing these to the workers that apply
    our task to a subset of the data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们决定一个给定的操作应该并行执行，并且我们知道根据并发级别应该创建多少个工作线程，那么就是创建一些任务并将它们分配给工作线程的时候了。本质上，这意味着将输入数据切割成更小的块，并将这些块传递给将任务应用于数据子集的工作线程。
- en: 'In the preceding chapter, we saw our first example of taking input data and
    diving it into tasks. Once the work was divided, we spawned a new worker and terminated
    it when the task was complete. Creating and terminating threads like this may
    not be the ideal approach depending on the type of application we''re building.
    For example, if we occasionally run an expensive operation that would benefit
    from parallel processing, then it might make sense to spawn workers on demand.
    However, if we frequently process things in parallel, then it might make more
    sense to spawn threads when the application starts, and reuse them for processing
    many types of tasks. Here is an illustration of how many operations can share
    the same set of workers for different tasks:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章节中，我们看到了第一个将输入数据分割成任务的例子。一旦工作被分割，我们就创建一个新的工作线程，并在任务完成后终止它。根据我们构建的应用程序类型，创建和终止线程可能不是最佳方法。例如，如果我们偶尔运行一个可以受益于并行处理的高成本操作，那么按需创建工作线程可能是有意义的。然而，如果我们经常并行处理事物，那么在应用程序启动时创建线程，并重复使用它们来处理多种类型的任务可能更有意义。以下是许多操作如何共享同一组工作线程以执行不同任务的示意图：
- en: '![Creating tasks and assigning work](img/B05133_06_06.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![创建任务和分配工作](img/B05133_06_06.jpg)'
- en: This configuration allows operations to send messages to worker threads that
    are already running and get results back. There's no overhead associated with
    spawning new workers and cleaning them up when we're done with them. There is
    still the problem of reconciliation. We've split the operation into smaller tasks,
    each returning their own result. However, the operation is expected to return
    a single result. So when we split work into smaller tasks, we also need a way
    to join the task results back into a cohesive whole.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这种配置允许操作向已运行的工作线程发送消息，并在完成后获取结果。当我们完成操作时，与创建新工作线程和清理它们相关的开销不存在。仍然存在协调的问题。我们已经将操作分割成更小的任务，每个任务都返回自己的结果。然而，操作预期返回单个结果。因此，当我们将工作分割成更小的任务时，我们还需要一种方法将任务结果合并成一个整体。
- en: 'Let''s write a generic function that handles the boilerplate aspects of splitting
    work into tasks and bringing the results together for reconciliation. While we''re
    at it, let''s also have this function determine whether the operation should be
    parallelized, or it should run synchronously in the main thread. First, let''s
    look at the task itself that we''ll want to run in parallel against each chunk
    of our data, as it''s sliced up:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写一个通用函数，该函数处理将工作分割成任务并将结果汇总以进行协调的样板代码。在此过程中，让我们也让这个函数确定操作是否应该并行化，或者它应该在主线程中同步运行。首先，让我们看看我们将在并行运行的数据块上运行的每个任务本身：
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This task is kept separate from our worker code and other parts of our application
    that run in the main thread. The reason is that we''ll want to use this function
    in both: the main thread and the worker threads. Now, we''ll make a worker that
    can import this function, and use it with any data that gets passed to the worker
    in a message:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这个任务与我们的工作线程代码以及运行在主线程中的应用程序的其他部分是分开的。原因是我们将希望在这两个地方使用这个函数：主线程和工作线程。现在，我们将创建一个可以导入这个函数的工作线程，并使用它来处理传递给工作线程的消息中的任何数据：
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Earlier in the chapter, we implemented two utility functions. The `isConcurrent()`
    function determines the utility of running an operation as a set of smaller tasks
    in parallel. The other function, `getConcurrency()`, determines the level of concurrency
    that we should be running at. We''ll use these two functions here, and we''ll
    introduce two new utility functions. In fact, these are generators that will help
    us later on. Let''s take a look at this:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的早期部分，我们实现了两个实用函数。`isConcurrent()` 函数用于确定将操作作为一组并行运行的小任务执行时的效用。另一个函数 `getConcurrency()`
    用于确定我们应该运行在何种并发级别。在这里，我们将使用这两个函数，并介绍两个新的实用函数。实际上，这些是生成器，将帮助我们后续的工作。让我们看一下这个：
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'With these two generators in place—`workers` and `id`—we''re now ready to implement
    our `parallel()` higher-order function. The idea is to take a function as input
    along with some other parameters that allows us to tune the behavior of the parallelization
    and return a new function that we can simply invoke as normal throughout our app.
    Let''s take a look at this function now:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两个生成器——`workers` 和 `id`——到位后，我们现在可以实施我们的 `parallel()` 高阶函数。想法是接受一个函数作为输入，以及一些其他参数，这些参数允许我们调整并行化的行为，并返回一个我们可以简单地正常调用的新函数。现在让我们看看这个函数：
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now we can use the `parallel()` function to build concurrent functions that
    are called all throughout our application. For example, the `sumConcurrent()`
    function can be used whenever we have to compute the sum of large inputs. The
    only thing that's different is the input data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用`parallel()`函数构建在应用程序中所有地方都会调用的并发函数。例如，`sumConcurrent()`函数可以在我们需要计算大型输入的总和时使用。唯一不同的是输入数据。
- en: Note
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: An obvious limitation here is that we only have a single callback function that
    we can specify when the parallelized function completes. This and, well, there's
    a lot of book-keeping to be done here—having IDs to reconcile tasks with their
    operations is kind of painful; this feels as if we're implementing promises. This
    is because that's essentially what we're doing here. The next chapter dives into
    more detail on combining promises with workers to avoid messy abstractions, such
    as the one that we just implemented.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这里一个明显的限制是我们只能指定一个回调函数，当并行化的函数完成时调用。此外，这里还有很多需要做的工作——拥有ID来协调任务与它们的操作有点痛苦；这感觉就像我们正在实现承诺。这是因为这正是我们在做的事情。下一章将更详细地介绍如何将承诺与工作者结合使用，以避免混乱的抽象，就像我们刚刚实现的那样。
- en: Candidate problems
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 候选问题
- en: In the previous section, you learned to create a generic function that will
    decide, on the fly, how to divide and conquer using workers, or whether it's more
    beneficial to simply call the function in the main thread. Now that we have a
    generic parallelization mechanism in place, what kind of problems can we solve?
    In this section, we'll address the most typical concurrency scenarios that will
    benefit from a solid concurrency architecture.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，你学会了创建一个通用函数，该函数可以即时决定如何使用工作者进行分解和征服，或者是否简单地调用主线程中的函数更有利。现在我们已经建立了一个通用的并行化机制，我们可以解决什么类型的问题？在本节中，我们将讨论最典型的并发场景，这些场景将受益于一个坚实的并发架构。
- en: Embarrassingly parallel
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 令人尴尬的并行
- en: A problem is embarrassingly parallel when it's obvious how the larger task can
    be broken down into smaller tasks. These smaller tasks don't depend on one another,
    which makes it even easier to start off a task that takes input and produces output
    without relying on the state of other workers. This again comes back to the functional
    programming, and the idea of referential transparency and no side-effects.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个任务显然可以分解成更小的任务时，它就是一个令人尴尬的并行问题。这些较小的任务彼此不依赖，这使得启动一个任务变得更加容易，该任务接受输入并产生输出，而不依赖于其他工作者的状态。这又回到了函数式编程，以及引用透明性和无副作用的概念。
- en: These are the types of problems we want to solve with concurrency—at least at
    first, during the difficult first implementation of our application. These are
    the low-hanging-fruit as far as concurrency problems go, and they should be easy
    for us to tackle without risking our ability to deliver functionality.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们希望通过并发解决的问题类型——至少最初，在我们应用程序的第一个困难实现期间。这些是并发问题中的低垂之果，我们应该能够轻松解决，而不会影响我们交付功能的能力。
- en: The last example that we implemented in the preceding section was an embarrassingly
    parallel problem, where we simply needed each subtask to add up the input values
    and return them. Global search, when the collection is large and unstructured,
    is another example of something that takes little effort on our part to divide
    into smaller tasks and reconcile them into a result. Searching large text inputs
    is a similar example. Mapping and reducing are yet another example of something
    that takes relatively little effort to parallelize.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中我们实现的最后一个例子是一个令人尴尬的并行问题，其中我们只需要每个子任务将输入值相加并返回。当集合很大且无结构时，全局搜索也是另一个例子，我们只需付出很少的努力就能将其分解成更小的任务并将它们合并成结果。搜索大型文本输入也是一个类似的例子。映射和归约是另一个相对容易并行化的例子。
- en: Searching collections
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 搜索集合
- en: Some collections are sorted. These collections can be searched efficiently because
    binary search algorithms are able to avoid large sections of data simply based
    on the premise that the data is sorted. However, there are other times when we
    work with collections that are largely unstructured or unsorted. In other cases,
    the time complexity is likely to be O(n) because every item in the collection
    needs to be checked as no assumptions can be made.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 有些集合是有序的。这些集合可以有效地进行搜索，因为二分搜索算法能够仅基于数据已排序的前提来避免大量数据。然而，在其他时候，我们处理的是大量无结构或无序的集合。在其他情况下，时间复杂度可能为O(n)，因为集合中的每个项都需要被检查，不能做出任何假设。
- en: 'Large strings of text are a good example of a collection that''s unstructured.
    If we were to search this text for a substring, there''d be no way to avoid searching
    a section of the text based on what we''ve found so far—the whole search space
    needs to be covered. We also need to count the number of substring occurrences
    in a large body of text. This is an embarrassingly parallel problem. Let''s write
    some code that counts the number of substring occurrences in string input. We''ll
    reuse the parallel utilities that we created in the previous section, in particular,
    the `parallel()` function. Here''s the task that we''ll use:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 大量的文本字符串是一个无结构的集合的好例子。如果我们在这个文本中搜索子字符串，就没有办法避免根据我们迄今为止找到的内容搜索文本的一部分——整个搜索空间都需要被覆盖。我们还需要计算大量文本中子字符串出现的次数。这是一个令人尴尬的并行问题。让我们编写一些代码来计算字符串输入中子字符串出现的次数。我们将重用上一节中创建的并行实用工具，特别是`parallel()`函数。我们将使用以下任务：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now let''s create a block of text for us to search and a parallel function
    to search it with:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们创建一个用于搜索的文本块和一个用于搜索的并行函数：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Here, we're splitting the input string into 20 character chunks, and searching
    for the input value `en`. There's 3 results found. Let's see if we can use this
    task, along with our parallel worker utilities and count the number of times an
    item appears in an array.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将输入字符串分割成20个字符的块，并搜索输入值`en`。找到了3个结果。让我们看看我们是否可以使用这个任务，以及我们的并行工作器实用工具来计算一个数组中项出现的次数。
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Since we're generating this 10,000 element array using random integers, the
    output will differ with each run. However, what's nice about our parallel worker
    utilities is that we were able to call `arrayCount()` with a substantially larger
    chunk size.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在使用随机整数生成这个10,000个元素的数组，所以每次运行的结果都会不同。然而，我们并行工作器实用工具的优点是，我们能够以较大的块大小调用`arrayCount()`。
- en: Note
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: You may have noticed that we're *filtering* the input, not *finding* a specific
    item within. This is an example of an embarrassingly parallel problem versus something
    that's a lot more difficult to solve using concurrency. Our worker nodes in the
    previous filtering code don't need to communicate with one another. If we have
    several worker nodes looking for a single item, we would inevitably face an early-termination
    scenario.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到我们正在*过滤*输入，而不是在输入中*查找*特定项。这是一个令人尴尬的并行问题与使用并发解决更困难的问题的例子。在前面的过滤代码中，我们的工作节点不需要相互通信。如果我们有多个工作节点在寻找单个项，我们不可避免地会面临早期终止的场景。
- en: But to handle early termination, we need workers that'd somehow communicate
    with one another. This isn't necessarily a bad thing, just more shared state and
    more concurrency complexity. Its decisions like these that become relevant in
    concurrent programming—do we optimize elsewhere to avoid certain concurrency challenges?
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 但为了处理早期终止，我们需要能够相互通信的工作者。这并不一定是一件坏事，只是更多的共享状态和更多的并发复杂性。这些决策在并发编程中变得相关——我们是否在其他地方进行优化以避免某些并发挑战？
- en: Mapping and reducing
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 映射和归约
- en: The `Array` primitive in JavaScript already has a `map()` method. As we now
    know, there are two key factors that impact the scalability and performance of
    running a given operation against a given set of input data. It's the size of
    the data multiplied by the complexity of any task that's applied to each item
    within this data. These constraints can cause problems for our application if
    we're shoving tons of data into one array, then processing each array item with
    expensive code.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: JavaScript中的`Array`原语已经有一个`map()`方法。正如我们所知，有两个关键因素会影响对给定输入数据运行给定操作的可扩展性和性能。这是数据的大小乘以应用于数据中每个项的任何任务的复杂性。如果我们将大量数据推入一个数组，然后使用昂贵的代码处理每个数组项，这些限制可能会给我们的应用程序带来问题。
- en: 'Let''s see whether the approach that we''ve used for the past couple of code
    examples can help us map one array to another without having to worry about the
    native `Array.map()` method running on a single CPU—a potential bottleneck. We''ll
    also address the issue of reducing large collections. It''s a similar issue to
    mapping, only we use the `Array.reduce()` method. Here are the task functions:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看过去几个代码示例中使用的这种方法是否可以帮助我们将一个数组映射到另一个数组，而无需担心原生的`Array.map()`方法在单个CPU上运行——一个潜在的瓶颈。我们还将解决减少大量集合的问题。这与映射类似，只是我们使用`Array.reduce()`方法。以下是任务函数：
- en: '[PRE11]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now we have generic functions that can be invoked from anywhere—the main thread
    or from within a worker. We won''t look at the worker code again because it uses
    the same pattern as the examples before this one. It figures out which task to
    invoke, and it handles formatting the response that''s sent back to the main thread.
    Let''s go ahead and use the `parallel()` utility to create a concurrent map and
    a concurrent reduce function:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了可以在任何地方调用的通用函数——主线程或从工作线程内部。我们不会再次查看工作线程的代码，因为它使用与之前示例相同的模式。它确定要调用的任务，并处理发送回主线程的响应格式化。让我们使用`parallel()`实用工具来创建一个并发映射和一个并发减少函数：
- en: '[PRE12]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here, we create 75 tasks that are handed out to workers (75000/1000). Depending
    on our concurrency level, this means we'll have several property values being
    plucked from array items simultaneously. The reduce job works the same way; we
    sum the mapped collections concurrently. We still need to perform summation in
    the `sumConcurrent()` callback, but it's very few.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了75个任务，分配给工作线程（75000/1000）。根据我们的并发级别，这意味着我们将同时从数组项中提取多个属性值。减少作业的工作方式相同；我们并发地求和映射的集合。我们仍然需要在`sumConcurrent()`回调中执行求和，但它非常少。
- en: Note
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: We need to exercise caution when performing concurrent reduce jobs. Mapping
    is straightforward because we're creating what amounts to a clone of the original
    array in terms of size and ordering. It's just the values that differ. Reducing
    could be dependent on the result as it currently stands. Put differently, as each
    array item makes its way through the reduce function, the result, as it's being
    built-up, can change the final result outcome. Concurrency makes this difficult,
    but in this previous example, the problem was embarrassingly parallel—not all
    reduce jobs are.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行并发减少作业时，我们需要谨慎行事。映射是直接的，因为我们创建的实际上是对原始数组在大小和顺序上的克隆。只是值不同。减少可能依赖于当前的结果。换句话说，随着每个数组项通过减少函数，正在构建的结果可以改变最终的结果。并发使这变得困难，但在之前的例子中，问题令人尴尬地并行——并不是所有的减少作业都是并行的。
- en: Keeping the DOM responsive
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保持DOM响应性
- en: So far in this chapter, the focus has been data-centric—taking input and transforming
    it by using web workers to divide and conquer. This isn't the only use of worker
    threads; we can also use them to keep the DOM responsive for our users.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本章中，重点是数据驱动的——通过使用Web Workers来分割和征服，以输入和转换数据。这并不是工作线程的唯一用途；我们还可以使用它们来保持DOM对用户响应。
- en: In this section, we'll introduce a concept that's used in Linux kernel development
    to split events into phases for optimal performance. Then, we'll address the challenge
    of communicating between the DOM and our workers and vice-versa.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍一个在Linux内核开发中用于将事件分割成阶段以实现最佳性能的概念。然后，我们将解决DOM和我们的工作线程之间以及反之亦然的通信挑战。
- en: Bottom halves
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 底部半部分
- en: The Linux kernel has the concept of top-halves and bottom-halves. This idea
    is used by the hardware interrupt request machinery. The problem is that hardware
    interrupts happen all the time, and it's this kernel's job to make sure they're
    all captured and processed in a timely-manor. To do this effectively, the kernel
    splits the task of processing a hardware interrupt into two halves—the top and
    bottom half.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Linux内核有顶部半部分和底部半部分的概念。这个想法被硬件中断请求机制所使用。问题是硬件中断始终发生，而这个内核的任务是确保它们都能及时捕获和处理。为了有效地做到这一点，内核将处理硬件中断的任务分为两部分——顶部和底部。
- en: It's the job of the top-half to respond to external stimuli, such as a mouse
    click or a keystroke. However, there are severe limitations imposed on the top-half,
    and this is on purpose. The top-half portion of processing a hardware interrupt
    request can only schedule the real work—the invocation of all the other system
    components—for a later time. This later work is done in the bottom-half. The side-effect
    of this approach is that interrupts are handled swiftly at a low level, allowing
    more flexibility in terms of prioritizing events.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 上半部分的工作是响应外部刺激，比如鼠标点击或按键。然而，对上半部分施加了严格的限制，这是故意的。处理硬件中断请求的上半部分只能安排真正的任务——调用所有其他系统组件——在稍后时间。这项后续工作在下半部分完成。这种方法的副作用是中断在低级别迅速处理，从而在事件优先级方面提供了更大的灵活性。
- en: What does kernel development have to do with JavaScript and concurrency? Well,
    it turns out that we can borrow these ideas, and have our "bottom-half" work be
    delegated to a worker. Our event-handling code that responds to the DOM events
    wouldn't actually do anything except for pass the message to the worker. This
    ensures that the main thread is only doing what it absolutely needs to do without
    any extra processing. This means that if the web worker comes back with something
    to display, it can do so immediately. Remember, the main thread includes the rendering
    engine, which blocks our code from running and vice-versa.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 内核开发与JavaScript和并发性有什么关系？嗯，事实证明我们可以借鉴这些想法，并将我们的“下半部分”工作委托给一个工作线程。我们的事件处理代码，响应DOM事件，实际上不会做任何事情，除了将消息传递给工作线程。这确保了主线程只做它绝对需要做的事情，没有任何额外的处理。这意味着如果Web工作线程返回一些要显示的内容，它可以立即这样做。记住，主线程包括渲染引擎，它会阻止我们的代码运行，反之亦然。
- en: 'Here''s a visualization of top and bottom halves processing external stimuli:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是上半部分和下半部分处理外部刺激的可视化：
- en: '![Bottom halves](img/B05133_06_07.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![下半部分](img/B05133_06_07.jpg)'
- en: JavaScript is run-to-completion, which we're well aware at this point. This
    means that the less time spent in the top-half is time that's spent responding
    to users by updating the screen. At the same time, JavaScript is also run-to-completion
    within the web worker where our bottom-halves run. This means that the same limitation
    applies here; if our worker gets 100 messages sent to it in a short period of
    time, they're processed in **first** **in** **first** **out** (**FIFO)** order.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: JavaScript是运行到完成的，这一点我们现在已经很清楚。这意味着在上半部分花费的时间越少，我们就越有时间通过更新屏幕来响应用户。同时，JavaScript也在Web工作线程中运行到完成，其中我们的下半部分运行。这意味着同样的限制也适用于这里；如果我们的工作线程在短时间内收到了100条消息，它们将按照**先进先出**（**FIFO**）的顺序进行处理。
- en: The difference is that since this code isn't running in the main thread, the
    UI components still respond when the user interacts with them. This is such a
    crucial factor in the perception of a quality product that it's worth the time
    investigating top-halves and bottom-halves. We now just need to figure out an
    implementation.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 不同之处在于，由于这段代码没有在主线程中运行，当用户与之交互时，UI组件仍然会做出响应。这是对高质量产品感知的一个如此关键的因素，以至于值得花时间去研究上半部分和下半部分。我们现在只需要找出一种实现方法。
- en: Translating DOM manipulation
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 翻译DOM操作
- en: If we treat web workers as the bottom-halves of our application, then we need
    a way to manipulate the DOM while spending as little time as possible in the top-half.
    That is, it's up to the worker to figure out what needs to change in the DOM tree
    and then to notify the main thread. Then, all that the main thread has to do is
    translate between the posted message and the required DOM API call. There's no
    fiddling around with data between receiving these messages and handing control
    off to the DOM; milliseconds are precious in the main thread.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将Web工作线程视为我们应用程序的下半部分，那么我们需要一种方法来操作DOM，同时尽可能少地在上半部分花费时间。也就是说，由工作线程来确定DOM树中需要改变什么，然后通知主线程。然后，主线程需要做的就是将发布的消息和所需的DOM
    API调用之间进行转换。在接收这些消息并将控制权交给DOM之间，没有对数据进行任何操作；毫秒在主线程中是宝贵的。
- en: 'Let''s see how easy this is to implement. We''ll start with the worker implementation
    that sends the DOM manipulation messages to the main thread when it wants to update
    something in the UI:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这有多容易实现。我们将从工作线程实现开始，当它想要在UI中更新某些内容时，它会将DOM操作消息发送到主线程：
- en: '[PRE13]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This work posts three messages back to the main thread. They''re timed using
    `setTimeout()`, so we can expect to see a new list item be rendered every second
    until all three are displayed. Now, let''s take a look at how the main thread
    code makes sense of these messages:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作向主线程发送了三条消息。它们使用`setTimeout()`进行计时，因此我们可以预期每秒渲染一个新的列表项，直到所有三个都显示出来。现在，让我们看看主线程代码是如何理解这些消息的：
- en: '[PRE14]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As we can see, we're giving the top-half (the main thread) very little opportunity
    to bottleneck, causing the user interactions to freeze. It's quite simple—the
    only code that's executed here is the DOM manipulation code. This drastically
    increases the likelihood of completing quickly, allowing the screen to visibly
    update for the user.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我们给上半部分（主线程）提供了很少的机会来形成瓶颈，这导致用户交互冻结。这很简单——这里执行的唯一代码就是DOM操作代码。这极大地增加了快速完成的可能性，使得屏幕能够对用户可见地更新。
- en: What about the other direction, getting external events into the system without
    interfering with the main thread? We'll look at this next.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，关于另一个方向，如何将外部事件引入系统而不干扰主线程呢？我们将在下一节探讨这个问题。
- en: Translating DOM events
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 翻译DOM事件
- en: As soon as a DOM event is triggered, we want to hand off control to our web
    worker. This way, the main thread can continue as if nothing else is happening—everyone
    is happy. There's a little more to it than this unfortunately. For instance, we
    can't simply listen to every single event on every single element, forwarding
    each to the worker that would defeat the purpose of not running code in the main
    thread if it's constantly responding to events.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦DOM事件被触发，我们希望将控制权交给我们的Web工作线程。这样，主线程可以继续像什么都没发生一样——每个人都满意。不幸的是，这比这还要复杂一些。例如，我们不能简单地监听每个元素上的每个事件，并将每个事件转发给工作线程，这会违背不在主线程中运行代码的目的，如果它不断地对事件做出响应。
- en: 'Instead, we only want to listen to the DOM events that the worker cares about.
    This really is no different from how we would implement any other web application;
    our components listen to events they''re interested in. To implement this with
    workers, we need a mechanism that tells the main thread to setup a DOM event listener
    on a particular element. Then, the worker can simply listen to incoming DOM events
    and react accordingly. Let''s take a look at the worker implementation first:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们只想监听工作线程关心的DOM事件。这实际上与我们实现任何其他Web应用的方式没有太大区别；我们的组件监听它们感兴趣的事件。为了使用工作线程实现这一点，我们需要一个机制来告诉主线程在特定元素上设置一个DOM事件监听器。然后，工作线程可以简单地监听传入的DOM事件并相应地做出反应。让我们首先看看工作线程的实现：
- en: '[PRE15]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This worker asks the main thread, who has access to the DOM, to setup two event
    listeners. It then sets up its own event listener for the DOM events that eventually
    make their way to the worker. Let''s take a look at the DOM code responsible for
    setting up handlers and forwarding events to the worker:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这个工作线程请求主线程（它有权访问DOM）设置两个事件监听器。然后，它为自己设置一个监听器，用于监听最终到达工作线程的DOM事件。让我们看看负责设置处理程序并将事件转发到工作线程的DOM代码：
- en: '[PRE16]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For the sake of brevity, there's only a couple of event properties sent back
    to the worker. We can't send the event object as it is due to serialization limitations
    in web worker messages. In practice, this same pattern can be used, but we'll
    probably add more event properties to this, such as `clientX` and `clientY`.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁起见，我们只向工作线程发送了几个事件属性。由于Web工作线程消息中的序列化限制，我们不能发送原始的事件对象。实际上，这个相同的模式可以被使用，但我们可能会添加更多的事件属性，例如`clientX`和`clientY`。
- en: Summary
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: The previous chapter introduced us to web workers, highlighting the powerful
    capabilities of these components. This chapter shifted gears and focused on the
    "why" aspect of parallelism. We kicked things off by looking at some aspects of
    functional programming, and how they lend themselves to concurrent programming
    in JavaScript.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章介绍了Web工作线程，突出了这些组件的强大功能。本章转换了方向，专注于并行性的“为什么”方面。我们通过查看函数式编程的一些方面以及它们如何适合JavaScript中的并发编程来开始。
- en: We looked at the factors involved in determining the viability of executing
    a given operation concurrently across workers. Sometimes, there's a lot of overhead
    involved with taking apart a large task and distributing it to workers as smaller
    tasks. We implemented some generic utilities that can help us with the implementation
    of concurrent functions, encapsulating some of the associated concurrency boilerplate.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究了涉及确定在工作者之间并发执行给定操作可行性的因素。有时，将一个大任务拆分并分配给工作者作为更小的任务，会涉及大量的开销。我们实现了一些通用的实用工具，可以帮助我们实现并发函数，封装了一些相关的并发模板代码。
- en: Not all problems are well-suited for a concurrent solution. The best approach
    is to work top-down, seeking out the embarrassingly-parallel problems as they're
    the low-hanging fruit. We then applied this principle to a number of map-reduce
    problems.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有问题都适合并发解决方案。最佳方法是自上而下地工作，寻找那些显而易见的并行问题，因为它们是低垂的果实。然后我们将这一原则应用于多个map-reduce问题。
- en: We wrapped up the chapter with a brief foray into the concept of top and bottom
    halves. This is a strategy that keeps the main thread clear of pending JavaScript
    code in an effort to keep the user interface responsive. While we were busy thinking
    about the types of concurrency problems that we're most likely to encounter, and
    the best way to solve them, our code complexity went up a notch. The next chapter
    is about bringing together our three concurrency principles together in a way
    that puts concurrency first without sacrificing code readability.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在章节的最后简要探讨了上下半部分的概念。这是一种策略，旨在使主线代码清晰，避免在保持用户界面响应性时引入待处理的JavaScript代码。当我们忙于思考我们最有可能遇到哪些并发问题以及解决这些问题的最佳方法时，我们的代码复杂性又上升了一个等级。下一章将介绍如何将我们的三个并发原则结合起来，以并发优先的方式，而不牺牲代码的可读性。
