- en: Scaling Your Application
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展您的应用程序
- en: '"Evolution is a process of constant branching and expansion."'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: “进化是一个不断分支和扩张的过程。”
- en: '- Stephen Jay Gould'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '- Stephen Jay Gould'
- en: 'Scalability and performance are not the same things:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性和性能并不是相同的东西：
- en: '"The terms "performance" and "scalability" are commonly used interchangeably,'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: “‘性能’和‘可扩展性’这两个术语通常可以互换使用，
- en: 'but the two are distinct: performance measures the speed with which a single
    request can be executed, while scalability measures the ability of a request to
    maintain its performance under increasing load. For example, the performance of
    a request may be reported as generating a valid response within three seconds,
    but the scalability of the request measures the request''s ability to maintain
    that three-second response time as the user load increases."'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 但这两者是不同的：性能衡量的是单个请求执行的速度，而可扩展性衡量的是请求在负载增加时保持其性能的能力。例如，一个请求的性能可能被报告为在三秒内生成有效响应，但请求的可扩展性衡量的是请求在用户负载增加时保持这三秒的响应时间的能力。”
- en: '- Steven Haines, "Pro Java EE 5"'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '- Steven Haines，《Pro Java EE 5》'
- en: In the last chapter, we looked at how Node clusters might be used to increase
    the performance of an application. Through the use of clusters of processes and
    workers, we learned how to efficiently deliver results in the face of many simultaneous
    requests. We learned to scale Node *vertically*, keeping the same footprint (a
    single server) and increasing throughput by piling on the power of the available
    CPUs.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们看到了Node集群如何用于提高应用程序的性能。通过使用进程和工作进程的集群，我们学会了如何在面对许多同时请求时高效地交付结果。我们学会了垂直扩展Node，通过堆叠可用CPU的性能来增加吞吐量，保持相同的占用空间（单个服务器）。
- en: In this chapter, we will focus on *horizontal* scalability; the idea is that
    an application composed of self-sufficient and independent units (servers) can
    be scaled by adding more units without altering the application's code.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将专注于*横向*可扩展性；其思想是由自给自足和独立的单元（服务器）组成的应用程序可以通过添加更多单元而无需改变应用程序的代码来进行扩展。
- en: We want to create an architecture within which any number of optimized and encapsulated
    Node-powered servers can be added or subtracted in response to changing demands,
    dynamically scaling without ever requiring a system rewrite. We want to share
    work across different systems, pushing requests to the OS, to another server,
    to a third-party service, while coordinating those I/O operations intelligently
    using Node's evented approach to concurrency.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望创建一个架构，其中任意数量的优化和封装的Node驱动服务器可以根据不断变化的需求进行添加或减少，动态扩展而无需进行系统重写。我们希望在不同系统之间共享工作，将请求推送到操作系统、另一个服务器、第三方服务，同时使用Node的事件驱动并发方式智能地协调这些I/O操作。
- en: Through architectural parallelism, our systems can manage increased data volume
    more efficiently. Specialized systems can be isolated when necessary, even independently
    scaled or otherwise clustered.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 通过架构的并行性，我们的系统可以更有效地管理增加的数据量。必要时，专门的系统可以被隔离，甚至可以独立扩展或以其他方式进行集群化。
- en: Node is particularly well-suited to handle two key aspects of horizontally-scaled
    architectures.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Node特别适合处理横向扩展架构的两个关键方面。
- en: Firstly, Node enforces non-blocking I/O, such that the seizing up of any one
    unit will not cause a cascade of locking that brings down an entire application.
    As no single I/O operation will block the entire system, integrating third-party
    services can be done with confidence, encouraging a decoupled architecture.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，Node强制执行非阻塞I/O，这样任何一个单元的卡住都不会导致整个应用程序崩溃。由于没有任何单一的I/O操作会阻塞整个系统，因此可以放心地集成第三方服务，鼓励解耦的架构。
- en: Secondly, Node places great importance on supporting as many fast network communication
    protocols as possible. Whether through a shared database, a shared filesystem,
    or a message queue, Node's efficient network and `Stream` layers allow many servers
    to synchronize their efforts in balancing load. Being able to efficiently manage
    shared socket connections, for instance, helps when scaling out a cluster of servers
    as much as it does a cluster of processes.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，Node非常重视支持尽可能多的快速网络通信协议。无论是通过共享数据库、共享文件系统还是消息队列，Node的高效网络和“Stream”层允许许多服务器在平衡负载方面同步它们的努力。例如，能够高效地管理共享套接字连接有助于在扩展服务器集群和进程集群时使用。
- en: In this chapter, we will look at how to balance traffic between many servers
    running Node, how these distinct servers can communicate, and how these clusters
    can bind to and benefit from specialized cloud services.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨如何在运行Node的许多服务器之间平衡流量，这些不同的服务器如何进行通信，以及这些集群如何绑定并从专门的云服务中获益。
- en: When to scale?
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时进行扩展？
- en: The theory around application scaling is a complex and interesting topic that
    continues to be refined and expanded. A comprehensive discussion of the topic
    will require several books, curated for different environments and needs. For
    our purposes, we will simply learn how to recognize when scaling up (or even scaling
    down) is necessary.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 关于应用程序扩展的理论是一个复杂而有趣的话题，它不断得到完善和扩展。对于不同的环境和需求，全面讨论这个话题将需要几本书。对于我们的目的，我们只需学会如何识别何时需要进行扩展（甚至缩减）。
- en: Having a flexible architecture that can add and subtract resources as needed
    is essential to a resilient scaling strategy. A vertical scaling solution does
    not always suffice (simply adding memory or CPUs will not deliver the necessary
    improvements). When should horizontal scaling be considered?
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个灵活的架构，可以根据需要添加和减少资源，对于一个具有弹性的扩展策略至关重要。垂直扩展的解决方案并不总是足够（简单地添加内存或CPU不会带来必要的改进）。何时应考虑横向扩展？
- en: It is essential that you are able to monitor your servers. One simple but useful
    way to check the CPU and memory usage commanded by Node processes running on a
    server is to use the Unix `ps` (*process status*) command, for example, `ps aux
    | grep node`. A more robust solution is to install an interactive process manager,
    such as HTOP ([http://hisham.hm/htop/](http://hisham.hm/htop/)) for Unix systems,
    or Process Explorer for Windows-based systems ([https://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer](https://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer)).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 监控服务器是至关重要的。检查服务器上运行的Node进程所占用的CPU和内存使用情况的一个简单但有用的方法是使用Unix的`ps`（*进程状态*）命令，例如，`ps
    aux | grep node`。更健壮的解决方案是安装一个交互式进程管理器，比如Unix系统的HTOP（[http://hisham.hm/htop/](http://hisham.hm/htop/)）或基于Windows的系统的Process
    Explorer（[https://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer](https://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer)）。
- en: Network latency
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络延迟
- en: When network response times are exceeding some threshold, such as each request
    taking several seconds, it is likely that the system has gone well past a stable
    state.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当网络响应时间超过某个阈值时，比如每个请求花费几秒钟，很可能系统已经远远超过了稳定状态。
- en: While the easiest way to discover this problem is to wait for customer complaints
    about slow websites, it is better to create controlled stress tests against an
    equivalent application environment or server.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然发现这个问题最简单的方法是等待客户对网站速度慢的投诉，但最好是针对等效的应用环境或服务器创建受控的压力测试。
- en: '**AB** (**Apache Bench**) is a simple and straightforward way to do blunt stress
    tests against a server. This tool can be configured in many ways, but the kind
    of test you would do for measuring the network response times for your server
    is generally straightforward.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**AB**（**Apache Bench**）是一种对服务器进行粗略压力测试的简单直接的方式。这个工具可以以多种方式进行配置，但通常用于测量服务器的网络响应时间的测试是比较直接的。'
- en: 'For example, let''s test the response times for this simple Node server:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们测试一下这个简单的Node服务器的响应时间：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here''s how one might test running 10,000 requests against that server, with
    a concurrency of 100 (the number of simultaneous requests):'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何对该服务器运行10,000个请求进行测试，并发数为100（即同时请求的数量）：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If all goes well, you will receive a report similar to this:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，您将收到类似于这样的报告：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: There is a lot of useful information contained in this report. In particular,
    one should be looking for failed requests and the percentage of long-running requests.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这份报告中包含了很多有用的信息。特别是，应该寻找失败的请求和长时间运行的请求的百分比。
- en: Much more sophisticated testing systems exist, but `ab` is a good quick-and-dirty
    snapshot of performance. Get in the habit of creating testing environments that
    mirror your production systems and test them.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 存在更复杂的测试系统，但`ab`是性能的一个快速脏快照。养成创建与生产系统相似的测试环境并对其进行测试的习惯。
- en: 'Running `ab` on the same server running the Node process you are testing will,
    of course, impact the test speeds. The test runner itself uses a lot of server
    resources, so your results will be misleading. Full documentation for ab can be
    found at: [https://httpd.apache.org/docs/2.4/programs/ab.html](https://httpd.apache.org/docs/2.4/programs/ab.html).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行Node进程的同一台服务器上运行`ab`，当然会影响测试速度。测试运行程序本身会占用大量服务器资源，因此您的结果将是误导性的。`ab`的完整文档可以在此找到：[https://httpd.apache.org/docs/2.4/programs/ab.html](https://httpd.apache.org/docs/2.4/programs/ab.html)。
- en: Hot CPUs
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 热CPU
- en: When CPU usage begins to nudge maximums, start to think about increasing the
    number of units processing client requests. Remember that while adding one new
    CPU to a single-CPU machine will bring immediate and enormous improvements, adding
    another CPU to a 32-core machine will not necessarily bring an equal improvement.
    Slowdowns are not always about slow calculations.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当CPU使用率开始接近最大值时，开始考虑增加处理客户端请求的单位数量。请记住，虽然在单CPU机器上添加一个新的CPU会带来立即和巨大的改进，但在32核机器上添加另一个CPU不一定会带来同等的改进。减速并不总是由于计算速度慢造成的。
- en: 'As mentioned earlier, `htop` is a great way to get a quick overview of your
    server''s performance. As it visualizes the load being put on each core in real
    time, it is a great way to get an idea of what is happening. Additionally, the
    load average of your server is nicely summarized with three values. This is a
    happy server:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`htop`是了解服务器性能的一个很好的方式。它实时可视化了每个核心所承受的负载，这是了解发生了什么的一个很好的方式。此外，服务器的负载平均值以三个值的形式得到了很好的总结。这是一个良好的服务器：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: What do these values mean? What is a "good" or a "bad" load average?
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值代表什么？什么是“好”的或“坏”的负载平均值？
- en: All three numbers are measuring CPU usage, presenting measurements taken at
    one, five, and fifteen-minute intervals. Generally, it can be expected that short-term
    load will be higher than long-term load. If, on an average, your server is not
    overly stressed over time, it is likely that clients are having a good experience.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个数字都是在衡量CPU使用率，呈现了一分钟、五分钟和十五分钟间隔的测量值。通常情况下，短期负载会比长期负载更高。如果平均而言，您的服务器随着时间的推移并没有过度紧张，那么客户很可能会有良好的体验。
- en: On a single-core machine, load average should remain between 0.00 and 1.00\.
    Any request will take *some* time—the question is whether the request is taking
    *more time than necessary*—and whether there are delays due to excessive load.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在单核机器上，负载平均值应保持在0.00和1.00之间。任何请求都会花费一些时间，问题是请求是否花费了比必要更多的时间，以及是否由于负载过大而出现了延迟。
- en: If a CPU can be thought of as a pipe, a measurement of 0.00 means that there
    is no excessive friction, or delay, in pushing through a drop of water. A measurement
    of 1.00 indicates that our pipe is at its capacity; water is flowing smoothly,
    but any additional attempts to push water through will be faced with delays, or
    backpressure. This translates into latency on the network, with new requests joining
    an ever-growing queue.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将CPU视为管道，测量值为0.00意味着推送一滴水时没有过多的摩擦或延迟。测量值为1.00表示我们的管道已经达到容量；水流畅地流动，但任何额外的推送水的尝试都将面临延迟或背压。这会转化为网络上的延迟，新请求加入不断增长的队列。
- en: A multicore machine simply multiplies the measurement boundary. A machine with
    four cores is at its capacity when load average reaches 4.00.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 多核机器只是将测量边界乘以。当负载平均值达到4.00时，拥有四个核心的机器已经达到容量。
- en: How you choose to react to load averages depends on the specifics of an application.
    It is not unusual for servers running mathematical models to see their CPU averages
    hit maximum capacity; in such cases, you want *all* available resources dedicated
    to performing calculations. A file server running at capacity, on the other hand,
    is likely worth investigating.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 您选择如何对负载平均值做出反应取决于应用程序的具体情况。对于运行数学模型的服务器来说，看到它们的CPU平均值达到最大容量并不罕见；在这种情况下，您希望*所有*可用资源都专门用于执行计算。另一方面，运行在容量上限的文件服务器可能值得调查。
- en: Generally, a load average above 0.60 should be investigated. Things are not
    urgent, but there may be a problem around the corner. A server that regularly
    reaches 1.00 after all known optimizations have been made is a clear candidate
    for scaling, as of course is any server exceeding that average.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，负载平均值超过0.60应该进行调查。事情并不紧急，但可能会有问题。一个经过所有已知优化后仍经常达到1.00的服务器显然是扩展的候选者，当然，任何超过这个平均值的服务器也是如此。
- en: 'Node also offers native process information via the `os` module:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Node还通过`os`模块提供本机进程信息：
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Socket usage
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 套接字使用
- en: 'When the number of persistent socket connections begins to grow past the capacity
    of any single Node server, however optimized, it will be necessary to think about
    spreading out the servers handling user sockets. Using `socket.io`, it is possible
    to check the number of connected clients at any time using the following command:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当持久套接字连接的数量开始超过任何单个Node服务器的容量时，无论优化多少，都需要考虑将处理用户套接字的服务器分散开来。使用`socket.io`，可以使用以下命令随时检查连接的客户端数量：
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In general, it is best to track web socket connection counts within the application,
    via some sort of tracking/logging system.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，最好通过应用程序内的某种跟踪/日志系统来跟踪Web套接字连接计数。
- en: Many file descriptors
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 许多文件描述符
- en: When the number of file descriptors opened in an OS hovers close to its limit,
    it is likely that an excessive number of Node processes are active, files are
    open, or other file descriptors (such as sockets or named pipes) are in play.
    If these high numbers are not due to bugs or a bad design, it is time to add a
    new server.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当操作系统打开的文件描述符数量接近其限制时，很可能有过多的Node进程活动，文件已打开，或者其他文件描述符（如套接字或命名管道）正在使用中。如果这些高数字不是由于错误或糟糕的设计，那么是时候添加一个新的服务器了。
- en: 'Checking the number of open file descriptors of any kind can be accomplished
    using `lsof`:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`lsof`来检查任何类型的打开文件描述符的数量：
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Data creep
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据蔓延
- en: When the amount of data being managed by a single database server begins to
    exceed many millions of rows or many gigabytes of memory, it is time to think
    about scaling. Here, you might choose to simply dedicate a single server to your
    database, begin to share databases, or even move into a managed cloud storage
    solution earlier rather than later. Recovering from a data layer failure is rarely
    a quick fix, and in general, it is dangerous to have a single point of failure
    for something as important as *all of your data*.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当单个数据库服务器管理的数据量开始超过数百万行或数千兆字节的内存时，就是考虑扩展的时候了。在这里，您可以选择简单地将单个服务器专用于您的数据库，开始共享数据库，甚至在早期而不是晚期转移到托管的云存储解决方案。从数据层故障中恢复很少是一个快速的修复，一般来说，对于像*所有您的数据*这样重要的事情，有一个单一的故障点是危险的。
- en: 'If you''re using Redis, the `info` command will provide most of the data you
    will need, to make these decisions. Consider the following example:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用Redis，`info`命令将提供大部分您需要的数据，以做出这些决定。考虑以下示例：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'More information on `INFO` can be found at: [https://redis.io/commands/INFO](https://redis.io/commands/INFO).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`INFO`的更多信息，请参阅：[https://redis.io/commands/INFO](https://redis.io/commands/INFO)。
- en: 'For MongoDB, you might use the `db.stats()` command:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于MongoDB，您可以使用`db.stats()`命令：
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Passing the argument `1024` flags `stats` to display all values in kilobytes.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 传递参数`1024`标记`stats`以以千字节显示所有值。
- en: 'More information can be found at: [https://docs.mongodb.com/v3.4/reference/method/db.stats/](https://docs.mongodb.com/v3.4/reference/method/db.stats/)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息请参阅：[https://docs.mongodb.com/v3.4/reference/method/db.stats/](https://docs.mongodb.com/v3.4/reference/method/db.stats/)
- en: Tools for monitoring servers
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务器监控工具
- en: There are several tools available for monitoring servers, but few designed specifically
    for Node. One strong candidate is **N|Solid** ([https://nodesource.com/products/nsolid](https://nodesource.com/products/nsolid)),
    a company staffed by many key contributors to Node's core. This cloud service
    is easily integrated with a Node app, offering a useful dashboard visualizing
    CPU usage, average response times, and more.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种可用于监控服务器的工具，但很少有专门为Node设计的。一个强有力的候选者是**N|Solid** ([https://nodesource.com/products/nsolid](https://nodesource.com/products/nsolid))，这是一个由许多Node核心的关键贡献者组成的公司。这个云服务很容易与Node应用集成，提供一个有用的仪表板，可视化CPU使用情况、平均响应时间等。
- en: 'Other good monitoring tools to consider are listed in the following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 其他值得考虑的监控工具列在以下：
- en: '**Nagios**: [https://www.nagios.org](https://www.nagios.org)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Nagios**: [https://www.nagios.org](https://www.nagios.org)'
- en: '**Munin**: [http://munin-monitoring.org/](http://munin-monitoring.org/)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Munin**: [http://munin-monitoring.org/](http://munin-monitoring.org/)'
- en: '**Monit**: [https://mmonit.com/](https://mmonit.com/)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Monit**: [https://mmonit.com/](https://mmonit.com/)'
- en: '**NewRelic**: [https://newrelic.com/nodejs](https://newrelic.com/nodejs)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NewRelic**: [https://newrelic.com/nodejs](https://newrelic.com/nodejs)'
- en: '**Keymetrics**: [https://keymetrics.io/](https://keymetrics.io/)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Keymetrics**: [https://keymetrics.io/](https://keymetrics.io/)'
- en: Running multiple Node servers
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行多个Node服务器
- en: It is easy to purchase several servers and then to run some Node processes on
    them. However, how can those distinct servers be coordinated such that they form
    part of a single application? One aspect of this problem concerns clustering multiple
    identical servers around a single entry point. How can client connections be shared
    across a pool of servers?
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 购买几台服务器然后在它们上面运行一些Node进程是很容易的。然而，如何协调这些不同的服务器，使它们成为单个应用程序的一部分呢？这个问题的一个方面涉及将多个相同的服务器集群在一个入口点周围。客户端连接如何在一组服务器之间共享？
- en: '**Horizontal scaling** is the process of splitting up your architecture into
    network-distinct nodes and coordinating them. *Cloud computing* relates here,
    and simply means locating some of the functionality an application running on
    a server somewhere on a remote server, running somewhere else. Without a single
    point of failure (so the theory goes) the general system is more robust. The *parking
    lot problem* is another consideration that Walmart likely faces—during shopping
    holidays, you will need many thousands of parking spots, but during the rest of
    the year, this investment in empty space is hard to justify. In terms of servers,
    the ability to dynamically scale both up and down argues against building fixed
    vertical silos. Adding hardware to a running server is also a more complicated
    process than spinning up and seamlessly linking another virtual machine to your
    application.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**水平扩展**是将架构分割成网络不同节点并协调它们的过程。*云计算*在这里相关，简单地意味着将应用程序的一些功能定位到远程服务器上，而不是在其他地方运行的服务器上。没有单点故障（理论上如此），整个系统更加健壮。*停车场问题*是沃尔玛可能面临的另一个考虑因素——在购物节日期间，您将需要成千上万个停车位，但在一年的其他时间，很难证明这种对空间的投资是合理的。就服务器而言，动态扩展的能力既支持向上扩展也支持向下扩展，这与构建固定的垂直存储单元相矛盾。向正在运行的服务器添加硬件也比启动并无缝链接另一个虚拟机到您的应用程序更复杂。'
- en: File serving speeds are, of course, not the only reason you might use a proxy
    server like NGINX. It is often true that network topology characteristics make
    a reverse proxy the better choice, especially when the centralization of common
    services, such as compression, makes sense. The point is simply that Node should
    not be excluded solely due to outdated biases about its ability to efficiently
    serve files.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，文件服务速度并不是您可能使用像NGINX这样的代理服务器的唯一原因。通常情况下，网络拓扑特性使得反向代理成为更好的选择，特别是当集中常见服务（如压缩）时。关键是Node不应该仅仅因为其有效地提供文件的能力而被排除在外。
- en: Forward and reverse proxies
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正向和反向代理
- en: A **proxy** is someone or something acting on behalf of another.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**代理**是代表另一个人或事物行事的人或事物。'
- en: A **forward proxy** normally works on behalf of clients in a private network,
    brokering requests to an outside network, such as retrieving data from the internet.
    Earlier in this book, we looked at how one might set up a proxy server using Node,
    where the Node server functioned as an intermediary, forwarding requests from
    clients to other network servers, usually via the internet.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**正向代理**通常代表私有网络中的客户端，代理对外部网络的请求，例如从互联网检索数据。在本书的前面，我们看了如何使用Node设置代理服务器，其中Node服务器充当中间人，将客户端的请求转发到其他网络服务器，通常是通过互联网。'
- en: 'Early web providers such as AOL functioned in the following way:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 早期的网络提供商如AOL的功能如下：
- en: '![](img/fc316c7a-de5c-4f91-a7ea-6f9c909a5543.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fc316c7a-de5c-4f91-a7ea-6f9c909a5543.png)'
- en: Network administrators use forward proxies when they must restrict access to
    the outside world, that is, the internet. If network users are downloading malware
    from `somebadwebsite.com` via an email attachment, the administrator can block
    access to that location. Restrictions on access to social networking sites might
    be imposed on an office network. Some countries even restrict access to public
    websites in this way.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 网络管理员在必须限制对外部世界（即互联网）的访问时使用正向代理。如果网络用户通过电子邮件附件从`somebadwebsite.com`下载恶意软件，管理员可以阻止对该位置的访问。对办公网络施加对社交网络网站的访问限制也是可能的。一些国家甚至以这种方式限制对公共网站的访问。
- en: 'A **reverse proxy**, not surprisingly, works in the opposite way, accepting
    requests from a public network and servicing those requests within a private network
    the client has little much visibility into. Direct access to servers by clients
    is first delegated to a reverse proxy:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**反向代理**，并不奇怪，以相反的方式工作，接受来自公共网络的请求，并在客户端几乎看不到的私有网络中处理这些请求。客户端对服务器的直接访问首先委托给反向代理：'
- en: '![](img/e27712db-31b9-4716-ad25-1e40a6ae8e44.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e27712db-31b9-4716-ad25-1e40a6ae8e44.png)'
- en: This is the type of proxy we might use to balance requests from clients across
    many Node servers. Client *X* does not communicate with any given server directly.
    A broker *Y* is the point of first contact, able to direct *X* to a server that
    is under less load, or that is located closer to *X*, or is in some other way
    the best server for *X* to access at this time.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们可能使用的代理类型，用于在许多Node服务器之间平衡客户端的请求。客户端*X*不直接与任何给定的服务器通信。代理*Y*是第一次接触点，能够将*X*引导到负载较小的服务器，或者距离*X*更近的服务器，或者在某种程度上是*X*在此时访问的最佳服务器。
- en: We will now take a look at how to implement reverse proxies when scaling Node,
    discussing implementations that use **NGINX** (pronounced as **Engine X**), a
    popular choice when load balancing Node servers, and those using native Node modules.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将看一下如何在扩展Node时实现反向代理，讨论使用**NGINX**（发音为**Engine X**）的负载均衡Node服务器的实现，以及使用本机Node模块的实现。
- en: Using the http-proxy module
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用http-proxy模块
- en: For many years, it was recommended that a web server (such as NGINX) be placed
    in front of Node servers. The claim was that mature web servers handle static
    file transfers more efficiently. While this may have been true for earlier Node
    versions (which also suffered from the bugs that new technologies face), it is
    no longer necessarily true in terms of pure speed. More importantly, using **Content
    Delivery Networks** (**CDN**) and other *edge* services the static files your
    application might need will already be cached—your server won't be serving these
    files, to begin with.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，人们建议在Node服务器前面放置一个Web服务器（如NGINX）。理由是成熟的Web服务器能更有效地处理静态文件传输。虽然这对于早期的Node版本可能是真的（这些版本也受到新技术面临的错误的影响），但从纯速度来说，这不一定再是真的。更重要的是，使用内容交付网络（CDN）和其他边缘服务，你的应用程序可能需要的静态文件已经被缓存了，你的服务器本来就不会提供这些文件。
- en: Node is designed to facilitate the creation of network software, so it comes
    as no surprise that several proxying modules have been developed. A popular production-grade
    Node proxy is **http-proxy**. Let's take a look at how we would use it to balance
    requests to different Node servers.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Node旨在促进网络软件的创建，因此并不奇怪会开发出几个代理模块。一个受欢迎的生产级Node代理是http-proxy。让我们看看如何使用它来平衡对不同Node服务器的请求。
- en: 'The entirety of our routing stack will be provided by Node. One Node server
    will be running our proxy, listening on port `80`. We''ll cover the following
    three scenarios:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的整个路由堆栈将由Node提供。一个Node服务器将运行我们的代理，监听端口`80`。我们将涵盖以下三种情况：
- en: Running multiple Node servers on separate ports on the same machine
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在同一台机器上运行多个不同端口的Node服务器
- en: Using one box as a pure router, proxying to external URLs
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用一个盒子作为纯路由器，代理到外部URL
- en: Creating a basic round-robin load balancer
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个基本的轮询负载均衡器
- en: 'As an initial example, let''s look at how to use this module to redirect requests:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个初始示例，让我们看看如何使用这个模块来重定向请求：
- en: '[PRE9]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: By starting this server on port `80` of our local machine, we are able redirect the
    user to another URL.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在本地机器的端口`80`上启动此服务器，我们能够将用户重定向到另一个URL。
- en: 'To run several distinct Node servers, each responding to a different URL, on
    a single machine, one simply has to define a router:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要在单台机器上运行几个不同的Node服务器，每个服务器响应不同的URL，只需定义一个路由器：
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: For each of your distinct websites, you can now point your DNS name servers
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 对于你的不同网站，现在可以指向你的DNS名称服务器
- en: '(via ANAME or CNAME records) to the same endpoint (wherever this Node program
    is running), and they will resolve to different Node servers. This is handy when
    you want to run several websites but don''t want to create a new physical server
    for each one. Another strategy is to handle different paths within the same website
    on different Node servers:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: （通过ANAME或CNAME记录）到相同的端点（无论这个Node程序在哪里运行），它们将解析到不同的Node服务器。当你想运行几个网站但不想为每个网站创建一个新的物理服务器时，这很方便。另一种策略是在同一个网站中处理不同路径在不同的Node服务器上：
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This allows specialized functionality in your application to be handled by uniquely
    configured servers.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许你的应用程序中的专门功能由独特配置的服务器处理。
- en: 'Setting up a load balancer is also straightforward. As we''ll see later with
    NGINX''s **upstream** directive, we simply provide a list of servers to be balanced:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 设置负载均衡器也很简单。正如我们稍后将在NGINX的upstream指令中看到的那样，我们只需提供要平衡的服务器列表：
- en: '[PRE12]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this example, we treat servers equally, cycling through them in order. After
    the selected server is proxied, it is returned to the *rear* of the list.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们平等对待服务器，按顺序循环使用它们。选择的服务器被代理后，它将返回到列表的末尾。
- en: It should be clear that this example can be easily extended to accommodate other
    directives, such as NGINX's **weight**.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，这个例子可以很容易地扩展到适应其他指令，比如NGINX的weight。
- en: 'The `redbird` module is an extremely advanced reverse proxy built on top of **http-proxy**.
    Among other things, it has built-in support for automatic SSL certificate generation
    and HTTP/2 support. Learn more at: [https://github.com/OptimalBits/redbird](https://github.com/OptimalBits/redbird).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: redbird模块是建立在http-proxy之上的一个非常先进的反向代理。除其他功能外，它还内置了自动SSL证书生成和HTTP/2支持。了解更多信息：[https://github.com/OptimalBits/redbird](https://github.com/OptimalBits/redbird)。
- en: Deploying a NGINX load balancer on Digital Ocean
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Digital Ocean上部署NGINX负载均衡器
- en: As Node is so efficient, most websites or applications can accommodate all of
    their scaling needs in the vertical dimension. Node can handle enormous levels
    of traffic using only a few CPUs and an unexceptional volume of memory.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Node非常高效，大多数网站或应用程序可以在垂直维度上满足其所有扩展需求。Node可以使用少量CPU和普通内存处理大量流量。
- en: 'NGINX is a very popular high-performance web server that is often used as a
    proxy server. There is some serendipity in the fact that NGINX is a popular choice with Node
    developers, given its design:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: NGINX是一个非常受欢迎的高性能Web服务器，通常用作代理服务器。NGINX与Node开发人员的设计非常相似，这是一种巧合：
- en: As mentioned on [http://www.linuxjournal.com/magazine/nginx-high-performance-web-server-and-reverse-proxy](http://www.linuxjournal.com/magazine/nginx-high-performance-web-server-and-reverse-proxy),
    "NGINX is able to serve more requests per second with [fewer] resources because
    of its architecture. It consists of a master process, which delegates work to
    one or more worker processes. Each worker handles multiple requests in an event-driven
    or asynchronous manner using special functionality from the Linux kernel (epoll/select/poll).
    This allows NGINX to handle a large number of concurrent requests quickly with
    very little overhead."
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如[http://www.linuxjournal.com/magazine/nginx-high-performance-web-server-and-reverse-proxy](http://www.linuxjournal.com/magazine/nginx-high-performance-web-server-and-reverse-proxy)所述，“NGINX能够以更少的资源处理更多的请求，因为它的架构。它由一个主进程组成，将工作委托给一个或多个工作进程。每个工作进程使用Linux内核的特殊功能（epoll/select/poll）以事件驱动或异步方式处理多个请求。这使得NGINX能够快速处理大量并发请求，几乎没有额外开销。”
- en: NGINX also makes load balancing very easy. In the following examples, we will
    see how proxying through NGINX comes with load balancing *out of the box.*
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: NGINX还使负载均衡变得非常容易。在以下示例中，我们将看到通过NGINX代理自带负载均衡功能。
- en: Digital Ocean is a cloud hosting provider that is inexpensive and easy to set
    up. We will build an NGINX load balancer on this service.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Digital Ocean是一个价格便宜且易于设置的云托管提供商。我们将在该服务上构建一个NGINX负载均衡器。
- en: 'To sign up, visit: [https://www.digitalocean.com](https://www.digitalocean.com).
    The basic package (at the time of this writing) incurs a five dollar fee, but
    promotion codes are regularly made available; a simple web search should result
    in a usable code. Create and verify an account to get started.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要注册，请访问：[https://www.digitalocean.com](https://www.digitalocean.com)。基本套餐（在撰写本文时）需要支付五美元的费用，但经常提供促销代码；简单的网络搜索应该能找到可用的代码。创建并验证一个帐户以开始使用。
- en: Digital Ocean packages are described as droplets, with certain characteristics—amount
    of storage space, transfer limits, and so on. A basic package is sufficient for
    our needs. Also, you will indicate a hosting region as well as the OS to install
    in your droplet (in this example, we’ll use the latest version of Ubuntu). Create
    a droplet, and check your email for login instructions. You’re done!
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Digital Ocean的套餐被描述为滴，具有特定的特征-存储空间量、传输限制等。我们的需求足够一个基本套餐。此外，您还将指定托管区域以及要在滴中安装的操作系统（在本例中，我们将使用最新版本的Ubuntu）。创建一个滴，并检查您的电子邮件以获取登录说明。完成！
- en: You will receive full login information for your instance. You can now open
    a Terminal and SSH into your box using those login credentials.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 您将收到实例的完整登录信息。现在，您可以打开终端并使用这些登录凭据通过SSH登录到您的主机。
- en: On your initial login, you might want to update your packages. For Ubuntu, you
    would run `apt-get update` and `apt-get upgrade`. Other package managers have
    similar commands (such as `yum update` for RHEL/CentOs).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在您初始登录时，您可能希望更新您的软件包。对于Ubuntu，您将运行`apt-get update`和`apt-get upgrade`。其他软件包管理器有类似的命令（例如，RHEL/CentOs的`yum
    update`）。
- en: Before we begin to install, let’s change our root password and create a non-root
    user (it is unsafe to expose root to external logins and software installs). To
    change your root password, type `passwd` and follow the instructions in your Terminal.
    To create a new user, enter `adduser <new user name>` (for example, `adduser john`).
    Follow the instructions.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始安装之前，让我们更改根密码并创建一个非根用户（将根暴露给外部登录和软件安装是不安全的）。要更改根密码，请输入`passwd`并按照终端中的说明操作。要创建一个新用户，请输入`adduser
    <新用户名>`（例如，`adduser john`）。按照说明操作。
- en: 'One more step: we want to give some administrative privileges to our new user,
    as we’ll be installing software as that user. In Unix parlance, you want to give
    `sudo` access to this new user. Instructions on how to do this are easy to find
    for whichever OS you’ve chosen. Essentially, you will want to change the `/etc/sudoers`
    file. Remember to do this using a command such as `lvisudo`; do not edit the sudoers
    file by hand! You may also want to restrict root logins and do other SSH access
    management at this point.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一步：我们希望为我们的新用户提供一些管理权限，因为我们将以该用户身份安装软件。在Unix术语中，您希望为这个新用户提供`sudo`访问权限。无论您选择哪个操作系统，都很容易找到如何执行此操作的说明。基本上，您需要更改`/etc/sudoers`文件。记住要使用`lvisudo`这样的命令来执行此操作；不要手动编辑sudoers文件！您可能还希望在这一点上限制根登录并进行其他SSH访问管理。
- en: After successfully executing ` sudo -i` in your Terminal, you will be able to
    enter commands without prefixing each one with `sudo`. The following examples
    assume that you’ve done this.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端成功执行`sudo -i`后，您将能够在不用每个命令都加上`sudo`前缀的情况下输入命令。以下示例假定您已经执行了此操作。
- en: 'We’ll now create a NGINX load balancer frontend for two Node servers. This
    means we will create three droplets: one for the balancer, and an additional two
    droplets to serve as Node servers. At the end, we will end up with an architecture
    that looks something like this:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将为两个Node服务器创建一个NGINX负载均衡器前端。这意味着我们将创建三个滴：一个用于负载均衡器，另外两个用作Node服务器。最后，我们将得到一个类似于这样的架构：
- en: '![](img/a7b32bd5-9ec9-49f2-92b2-3ebc005f8a39.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a7b32bd5-9ec9-49f2-92b2-3ebc005f8a39.png)'
- en: Installing and configuring NGINX
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装和配置NGINX
- en: 'Let’s install NGINX and Node/npm. If you''re still logged in as root, log out
    and reauthenticate as the new user you’ve just created. To install NGINX (on Ubuntu),
    simply type this:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们安装NGINX和Node/npm。如果您仍然以root用户登录，请注销并重新验证您刚刚创建的新用户。要安装NGINX（在Ubuntu上），只需输入以下命令：
- en: '[PRE13]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Most other Unix package managers will have NGINX installers.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数其他Unix软件包管理器都有NGINX安装程序。
- en: 'To start NGINX, use this:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动NGINX，请使用以下命令：
- en: '[PRE14]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Full documentation for NGINX can be found at: [https://www.nginx.com/resources/wiki/start/](https://www.nginx.com/resources/wiki/start/).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: NGINX的完整文档可以在此处找到：[https://www.nginx.com/resources/wiki/start/](https://www.nginx.com/resources/wiki/start/)。
- en: 'You should now be able to point your browser to the IP you were assigned (check
    your inbox if you''ve forgotten) and see something like this:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您应该能够将浏览器指向您分配的IP（如果您忘记了，请检查您的收件箱），并看到类似于这样的内容：
- en: '![](img/0c104d17-f129-4b82-8901-142c313ab105.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0c104d17-f129-4b82-8901-142c313ab105.png)'
- en: Now, let's set up the two servers that NGINX will balance.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们设置NGINX将平衡的两个服务器。
- en: 'Create an additional two droplets in Digital Ocean. You will *not* install
    NGINX on these severs. Configure permissions on these servers as we did earlier,
    and install Node in both droplets. An easy way to manage your Node installation
    is using *Tim Caswell''s* **NVM** (Node Version Manager). NVM is essentially a
    bash script that provides a set of command-line tools facilitating Node version
    management, allowing you to easily switch between versions. To install it, run
    the following command in your Terminal:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在Digital Ocean中创建另外两个滴。您*不*需要在这些服务器上安装NGINX。像之前一样在这些服务器上配置权限，并在两个滴中安装Node。管理Node安装的简单方法是使用*Tim
    Caswell的* **NVM**（Node Version Manager）。NVM本质上是一个bash脚本，提供一组命令行工具，便于管理Node版本，允许您轻松切换版本。要安装它，请在终端中运行以下命令：
- en: '[PRE15]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, install your preferred Node version:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，安装您首选的Node版本：
- en: '[PRE16]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You might want to add a command to your `.bashrc` or `.profile` file to ensure
    that a certain node version is used each time you start a shell:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能希望在`.bashrc`或`.profile`文件中添加一个命令，以确保每次启动shell时都使用某个特定的node版本：
- en: '[PRE17]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To test our system, we need to set up Node servers on both of these machines.
    Create the following program file on each server, changing `**` to something unique
    on each (such as *one* and *two*):'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试我们的系统，我们需要在这两台机器上设置Node服务器。在每台服务器上创建以下程序文件，将`**`更改为每个服务器上的唯一内容（例如*one*和*two*）：
- en: '[PRE18]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Start this file on each server (`node serverfile.js`). Each server will now
    answer on port `8080`. You should now be able to reach this server by pointing
    a browser to each droplet’s IP:8080\. Once you have two servers responding with
    distinct messages, we can set up the NGINX load balancer.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在每台服务器上启动此文件（`node serverfile.js`）。每台服务器现在将在端口`8080`上回答。您现在应该能够通过将浏览器指向每个Droplet的IP:8080\来访问此服务器。一旦有两台服务器响应不同的消息，我们就可以设置NGINX负载均衡器。
- en: 'Load balancing across servers is straightforward with NGINX. You need simply
    indicate, in the NGINX configuration script, which upstream servers should be
    balanced. The two Node servers we''ve just created will be the upstream servers.
    NGINX will be configured to balance requests to each:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 使用NGINX进行服务器之间的负载均衡非常简单。您只需在NGINX配置脚本中指示应该平衡的上游服务器。我们刚刚创建的两个Node服务器将成为上游服务器。NGINX将被配置为平衡对每个请求：
- en: '![](img/59ceb3dd-08f4-42e3-9c88-19ae3e47824c.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/59ceb3dd-08f4-42e3-9c88-19ae3e47824c.png)'
- en: Each request will be handled first by NGINX, which will check its *upstream*
    configuration, and based on how it is configured, will (reverse) proxy requests
    to upstream servers that will actually handle the request.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 每个请求将首先由NGINX处理，NGINX将检查其*上游*配置，并根据其配置方式，将请求（反向）代理到实际处理请求的上游服务器。
- en: You will find the default NGINX server configuration file on your balancer droplet
    at `/etc/nginx/sites-available/default`.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在负载均衡器Droplet上的`/etc/nginx/sites-available/default`找到默认的NGINX服务器配置文件。
- en: In production, you'll likely want to create a custom directory and configuration
    file, but for our purposes, we'll simply modify the default configuration file
    (you might want to make a backup before you start modifying it).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中，您可能希望创建一个自定义目录和配置文件，但出于我们的目的，我们将简单地修改默认配置文件（在开始修改之前，您可能需要备份）。
- en: 'At the top of the NGINX configuration file, we want to define some *upstream*
    servers that will be candidates for redirection. This is simply a map with the
    `lb-servers` arbitrary key, to be referenced in the server definition that follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在NGINX配置文件的顶部，我们希望定义一些*上游*服务器，这些服务器将成为重定向的候选者。这只是一个带有`lb-servers`任意键的映射，将在随后的服务器定义中引用：
- en: '[PRE19]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now that we''ve established the candidate map, we need to configure NGINX such
    that it will forward requests in a balanced way to each of the members of lb-servers:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了候选映射，我们需要配置NGINX，以便它以平衡的方式将请求转发到lb-servers的每个成员：
- en: '[PRE20]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The key line is this one:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 关键一行是这一行：
- en: '[PRE21]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Note how the name `lb-servers` matches the name of our upstream definition.
    This should make what is happening clear: an NGINX server listening on port `80`
    will pass the request on to a server definition as contained in lb-servers. If
    the upstream definition has only one server in it, that server gets all the traffic.
    If several servers are defined, NGINX attempts to distribute traffic evenly among
    them.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意名称`lb-servers`与我们上游定义的名称匹配。这应该清楚地说明正在发生的事情：监听端口`80`的NGINX服务器将将请求传递给包含在lb-servers中的服务器定义。如果上游定义中只有一个服务器，则该服务器将获得所有流量。如果定义了多个服务器，NGINX将尝试在它们之间均匀分配流量。
- en: It is also possible to balance load across several *local servers* using the
    same technique. One would simple run different Node servers on different ports,
    such as `server 127.0.0.1:8001` and `server 127.0.0.1:8002`.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以使用相同的技术在几个*本地服务器*之间平衡负载。可以在不同的端口上运行不同的Node服务器，例如`server 127.0.0.1:8001`和`server
    127.0.0.1:8002`。
- en: 'Go ahead and change the NGINX configuration (consulting the `nginx.config`
    file in the code bundle for this book if you get stuck). Once you''ve changed
    it, restart NGINX with the following command:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 继续更改NGINX配置（如果遇到困难，请查阅本书代码包中的`nginx.config`文件）。更改后，使用以下命令重新启动NGINX：
- en: '[PRE22]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Alternatively, if you prefer, use this:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果您愿意，可以使用此方法：
- en: '[PRE23]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Assuming that the other two droplets running Node servers are active, you should
    now be able to point your browser to your NGINX-enabled droplet and see messages
    from those servers!
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 假设另外两个运行Node服务器的Droplet处于活动状态，您现在应该能够将浏览器指向启用了NGINX的Droplet，并查看来自这些服务器的消息！
- en: As we will likely want more precise control over how traffic is distributed
    across our upstream servers, there are further directives that can be applied
    to upstream server definitions.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们可能希望更精确地控制流量如何分布到上游服务器，因此有进一步的指令可以应用于上游服务器定义。
- en: 'NGINX balances load using a weighted round-robin algorithm. In order to control
    the relative weighting of traffic distribution, we use the weight directive:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: NGINX使用加权轮询算法进行负载平衡。为了控制流量分布的相对权重，我们使用权重指令：
- en: '[PRE24]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This definition tells NGINX to distribute twice as much load to the second server
    as to the first. Servers with more memory or CPUs might be favored, for example.
    Another way to use this system is to create an A/B testing scenario, where one
    server containing a proposed new design receives some small fraction of total
    traffic, such that metrics on the testing server (sales, downloads, engagement
    length, and so forth) can be compared against the wider average.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 该定义告诉NGINX将负载分配给第二个服务器的量是第一个服务器的两倍。例如，具有更多内存或CPU的服务器可能会受到青睐。使用此系统的另一种方法是创建A/B测试场景，其中包含建议的新设计的一个服务器接收总流量的一小部分，以便可以将测试服务器的指标（销售额、下载量、参与时长等）与更广泛的平均值进行比较。
- en: 'Three other useful directives are available, which work together to manage
    connection failures:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他三个有用的指令，它们一起工作以管理连接故障：
- en: '`max_fails`: The number of times communication with a server fails prior to
    marking that server as inoperative. The period of time within which these failures
    must occur is defined by `fail_timeout`.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_fails`：与服务器通信失败多少次之前将该服务器标记为无法运行。这些失败必须发生的时间段由`fail_timeout`定义。'
- en: '`fail_timeout`: The time slice during which `max_fails` must occur, indicating
    that a server is inoperative. This number also indicates the amount of time after
    a server is marked inoperative that NGINX will again attempt to reach the flagged
    server.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fail_timeout`：服务器无法运行时必须发生`max_fails`的时间片。这个数字还表示在标记服务器无法运行后，NGINX再次尝试到达被标记的服务器之前的时间。'
- en: 'Consider this example:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下例子：
- en: '[PRE25]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '`backup`: A server marked with this directive will only be called when and
    if *all* the other listed servers are unavailable.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`backup`：带有这个指令的服务器只有在*所有*其他列出的服务器不可用时才会被调用。'
- en: 'Additionally, there are some directives for the upstream definition that add
    some control over how clients are directed to upstream servers:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，有一些用于上游定义的指令，可以对客户端如何被引导到上游服务器进行一些控制：
- en: '`least_conn`: Pass a request to the server with the least connections. This
    provides a slightly smarter balancing, taking into consideration server load as
    well as weighting.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`least_conn`：将请求传递给连接最少的服务器。这提供了稍微更智能的负载均衡，考虑了服务器负载以及权重。'
- en: '`ip_hash`: The idea here is to create a hash of each connecting IP, and to
    ensure that requests from a given client are always passed to the same server.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ip_hash`：这里的想法是为每个连接的IP创建一个哈希，并确保来自给定客户端的请求始终传递到同一台服务器。'
- en: 'Another commonly used tool for balancing Node servers is the dedicated load
    balancer HAProxy, available at: [http://www.haproxy.org](http://www.haproxy.org).'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 用于平衡Node服务器的另一个常用工具是专用负载均衡器HAProxy，网址为：[http://www.haproxy.org](http://www.haproxy.org)。
- en: Message queues – RabbitMQ
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消息队列-RabbitMQ
- en: One of the best ways to ensure that distributed servers maintain a dependable
    communication channel is to bundle the complexity of remote procedure calls into
    a distinct unit-a messaging queue. When one process wishes to send a message to
    another process, the message can simply be placed on this queue-like a to-do list
    for your application, with the queue service doing the work of ensuring that messages
    get delivered as well as delivering any important replies back to the original
    sender.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 确保分布式服务器保持可靠的通信渠道的最佳方法之一是将远程过程调用的复杂性捆绑到一个独立的单元中-一个消息队列。当一个进程希望向另一个进程发送消息时，消息可以简单地放在这个队列上-就像应用程序的待办事项列表一样，队列服务负责确保消息被传递以及将任何重要的回复传递回原始发送者。
- en: There are a few enterprise-grade message queues available, many of them deploying
    **AMQP** **(Advanced Message Queueing Protocol)**. We will focus on a very stable
    and well-known implementation—RabbitMQ.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些企业级消息队列可用，其中许多部署了**AMQP** **(高级消息队列协议)**。我们将专注于一个非常稳定和知名的实现-RabbitMQ。
- en: 'To install RabbitMQ in your environment, follow the instructions found at:
    [https://www.rabbitmq.com/download.html](https://www.rabbitmq.com/download.html).'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 要在您的环境中安装RabbitMQ，请按照以下网址找到的说明进行操作：[https://www.rabbitmq.com/download.html](https://www.rabbitmq.com/download.html)。
- en: 'Once installed, you will start the RabbitMQ server with this command:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，您可以使用以下命令启动RabbitMQ服务器：
- en: '[PRE26]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To interact with RabbitMQ using Node, we will use the `node-amqp` module created
    by *Theo Schlossnagle*:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Node与RabbitMQ进行交互，我们将使用*Theo Schlossnagle*创建的`node-amqp`模块：
- en: '[PRE27]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'To use a message queue, one must first create a consumer—a binding to RabbitMQ
    that will listen for messages published to the queue. The most basic consumer
    will listen for all messages:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用消息队列，必须首先创建一个消费者-一个绑定到RabbitMQ的监听发布到队列的消息。最基本的消费者将监听所有消息：
- en: '[PRE28]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We are now listening for messages from the RabbitMQ server bound to port `5672`.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在正在监听来自绑定到端口`5672`的RabbitMQ服务器的消息。
- en: Once this consumer establishes a connection, it will establish the name of the
    queue it will listen to, and should `bind` to an `exchange`. In this example,
    we create a topic `exchange` (the default), giving it a unique name. We also indicate
    that we would like to listen for *all* messages via `#`. All that is left to do
    is subscribe to the queue, receiving a message object. We will learn more about
    the message object as we progress. For now, note the important `data` property,
    containing sent messages.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这个消费者建立了连接，它将建立它将要监听的队列的名称，并且应该`绑定`到一个`交换机`。在这个例子中，我们创建了一个主题`交换机`（默认），给它一个唯一的名称。我们还指示我们想要通过`#`监听*所有*消息。剩下要做的就是订阅队列，接收一个消息对象。随着我们的进展，我们会了解更多关于消息对象的信息。现在，注意重要的`data`属性，其中包含发送的消息。
- en: 'Now that we have established a consumer, let''s publish a message to the exchange.
    If all goes well, we will see the sent message appear in our console:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了一个消费者，让我们向交换机发布一条消息。如果一切顺利，我们将在控制台中看到发送的消息：
- en: '[PRE29]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We have already learned enough to implement useful scaling tools. If we have
    a number of distributed Node processes, even on different physical servers, each
    can reliably send messages to one another via RabbitMQ. Each process simply needs
    to implement an **exchange queue subscriber** to receive messages, and an **exchange
    publisher** to send messages.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经学到足够的知识来实现有用的扩展工具。如果我们有多个分布式的Node进程，甚至在不同的物理服务器上，每个进程都可以通过RabbitMQ可靠地向彼此发送消息。每个进程只需要实现一个**交换队列订阅者**来接收消息，以及一个**交换发布者**来发送消息。
- en: Types of exchanges
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交换机的类型
- en: 'RabbitMQ provides three types of exchanges: **direct**, **fanout**, and **topic**.
    The differences appear in the way each type of exchange processes **routing keys**—the
    first argument sent to `exchange.publish`.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ提供三种类型的交换机：**直连**，**扇出**和**主题**。这些差异体现在每种类型的交换机如何处理**路由键**-发送到`exchange.publish`的第一个参数。
- en: 'A direct exchange matches routing keys directly. A queue binding like the following
    one matches *only* messages sent to `''room-1''`:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 直连交换机直接匹配路由键。像下面这样的队列绑定*只*匹配发送到`'room-1'`的消息：
- en: '[PRE30]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: As no parsing is necessary, direct exchanges are able to process more messages
    than topic exchanges in a set period of time.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 由于不需要解析，直接交换能够在一段时间内处理比主题交换更多的消息。
- en: A fanout exchange is indiscriminate; it routes messages to all the queues bound
    to it, ignoring routing keys. This type of exchange is used for wide broadcasts.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 扇出交换是不加区别的；它将消息路由到所有绑定到它的队列，忽略路由键。这种类型的交换用于广播。
- en: A topic exchange matches routing keys based on the wildcards `#` and `*`. Unlike
    other types, routing keys for topic exchanges *must* be composed of words separated
    by dots, `"animals.dogs.poodle"`, for example. A `#` matches zero or more words;
    it will match every message (as we saw in the previous example), just like a fanout
    exchange. The other wildcard is *, and this matches *exactly* one word.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 主题交换根据通配符`#`和`*`匹配路由键。与其他类型不同，主题交换的路由键*必须*由点分隔的单词组成，例如`"animals.dogs.poodle"`。`#`匹配零个或多个单词；它将匹配每条消息（就像我们在上一个示例中看到的那样），就像扇出交换一样。另一个通配符是`*`，它*精确地*匹配一个单词。
- en: Direct and fanout exchanges can be implemented using nearly the same code as
    the given topic exchange example, requiring only that the exchange type be changed,
    and bind operations be aware of how they will be associated with routing keys
    (fanout subscribers receive all messages, regardless of the key; for direct, the
    routing key must match directly).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 直接和扇出交换可以使用几乎与给定主题交换示例相同的代码实现，只需要更改交换类型，并且绑定操作需要知道它们将如何与路由键关联（扇出订阅者接收所有消息，而不考虑键；对于直接交换，路由键必须直接匹配）。
- en: 'This last example should drive home how topic exchanges work. We will create
    three queues with different matching rules, filtering the messages each queue
    receives from the exchange:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这个最后的例子应该说明主题交换是如何工作的。我们将创建三个具有不同匹配规则的队列，过滤每个队列从交换接收的消息：
- en: '[PRE31]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The `node-amqp` module contains further methods for controlling connections,
    queues, and exchanges; in particular, it contains methods for removing queues
    from exchanges, and subscribers from queues. Generally, changing the makeup of
    a running queue on the fly can lead to unexpected errors, so use these with caution.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '`node-amqp`模块包含进一步控制连接、队列和交换的方法；特别是，它包含从交换中删除队列和从队列中删除订阅者的方法。通常，在运行时更改队列的组成可能会导致意外错误，因此请谨慎使用这些方法。'
- en: 'To learn more about the AMQP (and the options available when setting up with
    `node-amqp`), visit: [http://www.rabbitmq.com/tutorials/amqp-concepts.html](http://www.rabbitmq.com/tutorials/amqp-concepts.html).'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关AMQP（以及在使用`node-amqp`进行设置时可用的选项），请访问：[http://www.rabbitmq.com/tutorials/amqp-concepts.html](http://www.rabbitmq.com/tutorials/amqp-concepts.html)。
- en: Using Node's UDP module
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Node的UDP模块
- en: '**UDP** **(User Datagram Protocol)** is a lightweight core internet messaging
    protocol, enabling servers to pass around concise **datagrams**. UDP was designed
    with a minimum of protocol overhead, forgoing delivery, ordering, and duplication
    prevention mechanisms in favor of ensuring high performance. UDP is a good choice
    when perfect reliability is not required and high-speed transmission is, such
    as what is found in networked video games and videoconferencing applications.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '**UDP**（用户数据报协议）是一种轻量级的核心互联网消息传递协议，使服务器能够传递简洁的**数据报**。UDP设计时考虑了最小的协议开销，放弃了交付、排序和重复预防机制，而是更注重确保高性能。当不需要完美的可靠性而需要高速传输时，比如在网络游戏和视频会议应用中，UDP是一个不错的选择。'
- en: This is not to say that UDP is normally unreliable. In most applications, it
    delivers messages with high probability. It is simply not suitable when *perfect*
    reliability is needed, such as in a banking application. It is an excellent candidate
    for monitoring and logging applications, and for non-critical messaging services.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是说UDP通常不可靠。在大多数应用程序中，它以高概率传递消息。当需要*完美*可靠性时，比如在银行应用程序中，它就不合适了。它是监控和日志应用程序以及非关键消息服务的绝佳选择。
- en: 'Creating a UDP server with Node is straightforward:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Node创建UDP服务器很简单：
- en: '[PRE32]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The `bind` command takes three arguments, which are as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '`bind`命令需要三个参数，如下所示：'
- en: '**port**: The `Integer` port number.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端口**：整数端口号。'
- en: '**address**: This is an optional address. If this is not specified, the OS
    will try to listen on all addresses (which is often what you want). You might
    also try using `0.0.0.0` explicitly.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**地址**：这是一个可选地址。如果未指定，操作系统将尝试监听所有地址（这通常是您想要的）。您也可以尝试明确使用`0.0.0.0`。'
- en: '**callback**: This is an optional callback, which receives no arguments.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回调**：这是一个可选的回调，不接收任何参数。'
- en: 'This socket will now emit a `message` event whenever it receives a datagram
    via the `41234` port. The event callback receives the message itself as a first
    parameter, and a map of packet information as the second:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这个套接字现在将在通过`41234`端口接收数据报时发出`message`事件。事件回调将数据报本身作为第一个参数接收，并将数据包信息映射作为第二个参数接收：
- en: '**address**: The originating IP'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**地址**：源IP'
- en: '**family**: One of IPv4 or IPv6'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**家族**：IPv4或IPv6之一'
- en: '**port**: The originating port'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端口**：源端口'
- en: '**size**: The size of the message in bytes'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大小**：消息的大小（以字节为单位）'
- en: This map is similar to the map returned when calling `socket.address()`.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这个映射类似于调用`socket.address()`时返回的映射。
- en: In addition to the message and listening events, a UDP socket also emits a **close**
    and **error** event, the latter receiving an `Error` object whenever an error
    occurs. To close a UDP socket (and trigger the close event), use `server.close()`.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 除了消息和监听事件之外，UDP套接字还会发出**close**和**error**事件，当发生错误时，后者会接收一个`Error`对象。要关闭UDP套接字（并触发关闭事件），请使用`server.close()`。
- en: 'Sending a message is even easier:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 发送消息甚至更容易：
- en: '[PRE33]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The `send` method takes the `client.send(buffer, offset, length, port, host,
    callback)` form:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`send`方法采用`client.send(buffer, offset, length, port, host, callback)`形式：'
- en: '`buffer`: A Buffer containing the datagram to be sent.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`buffer`：包含要发送的数据报的缓冲区。'
- en: '`offset`: An Integer indicating the position in buffer where the datagram begins.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`offset`：一个整数，指示数据报在缓冲区中的位置。'
- en: '`length`: The number of bytes in a datagram. In combination with **offset**,
    this value identifies the full datagram within buffer.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`length`：数据报中的字节数。与**offset**结合使用，此值标识缓冲区中的完整数据报。'
- en: '`port`: An Integer identifying the destination port.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`port`：标识目标端口的整数。'
- en: '`address`: A String indicating the destination IP for the datagram.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`address`：一个指示数据报目标IP的字符串。'
- en: '`callback`: An optional callback function, called after the send has taken
    place.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback`：一个可选的回调函数，在发送完成后调用。'
- en: The size of a datagram cannot exceed 65507 bytes, which is equal to *2^16-1*
    (65535) bytes, minus the 8 bytes used by the UDP header minus the 20 bytes used
    by the IP header.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 数据报的大小不能超过65507字节，这相当于*2^16-1*（65535）字节，减去UDP头部使用的8字节，减去IP头部使用的20字节。
- en: We now have another candidate for inter-process messaging. It will be rather
    easy to set up a monitoring server for our node application, listening on a UDP
    socket for program updates and stats sent from other processes. The protocol speed
    is fast enough for real-time systems, and any packet loss or other UDP hiccups
    will be insignificant taken as a percentage of total volume over time.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有另一个进程间通信的候选者。为我们的节点应用程序设置一个监视服务器将会相当容易，它监听一个UDP套接字，接收来自其他进程发送的程序更新和统计信息。协议速度足够快，适用于实时系统，任何数据包丢失或其他UDP故障都将在总体数据量中占比不足。
- en: 'Taking the idea of broadcasting further, we can also use the `dgram` module
    to create a multicast server. A **multicast** is simply a one-to-many server broadcast.
    We can broadcast to a range of IPs that have been permanently reserved as multicast
    addresses:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步扩展广播的想法，我们还可以使用`dgram`模块创建一个多播服务器。**多播**只是一对多的服务器广播。我们可以广播到一系列已永久保留为多播地址的IP地址：
- en: As can be found on [http://www.iana.org/assignments/multicast-addresses/multicast-addresses.xhtml](http://www.iana.org/assignments/multicast-addresses/multicast-addresses.xhtml),
    "Host Extensions for IP Multicasting [RFC1112] specifies the extensions required
    of a host implementation of the Internet Protocol (IP) to support multicasting.
    The multicast addresses are in the range 224.0.0.0 through 239.255.255.255."
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 正如可以在[http://www.iana.org/assignments/multicast-addresses/multicast-addresses.xhtml](http://www.iana.org/assignments/multicast-addresses/multicast-addresses.xhtml)找到的那样，“IP多播的主机扩展[RFC1112]指定了Internet协议（IP）的主机实现支持多播所需的扩展。多播地址在224.0.0.0到239.255.255.255的范围内。”
- en: 'Additionally, the range between `224.0.0.0` and `224.0.0.255` is further reserved
    for special routing protocols. Also, certain port numbers are allocated for use
    by UDP (and TCP), a list of which can be found at: [https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers](https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers).'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`224.0.0.0`和`224.0.0.255`之间的范围进一步保留用于特殊路由协议。此外，某些端口号被分配用于UDP（和TCP），可以在[https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers](https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers)找到列表。
- en: The upshot of all this fascinating information is the knowledge that there is
    a block of IPs and ports reserved for UDP and/or multicasting, and we will use
    some of them to implement multicasting over UDP with Node.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些令人着迷的信息的要点是，有一块IP和端口保留给UDP和/或多播使用，我们将使用其中一些来实现Node上的UDP多播。
- en: UDP multicasting with Node
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Node进行UDP多播
- en: 'The only difference between setting up a multicasting UDP server and a *standard*
    one is binding to a special UDP port for sending, and indicating that we''d like
    to listen to *all* available network adapters. Our multicasting server initialization
    looks like the following code snippet:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 设置多播UDP服务器和*标准*服务器之间唯一的区别是绑定到一个特殊的UDP端口进行发送，并指示我们希望监听*所有*可用的网络适配器。我们的多播服务器初始化看起来像以下代码片段：
- en: '[PRE34]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Once we've decided on a multicast port and an address and have bound, we catch
    the `listenng` event and configure our server. The most important command is `socket.addMembership`,
    which tells the kernel to join the multicast group at `multicastAddress`. Other
    UDP sockets can now subscribe to the multicast group at this address.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们决定了多播端口和地址并绑定了，我们就会捕获`listening`事件并配置我们的服务器。最重要的命令是`socket.addMembership`，它告诉内核加入`multicastAddress`的多播组。其他UDP套接字现在可以订阅这个地址的多播组。
- en: Datagrams hop through networks just like any network packet. The `setMulticastTTL`
    method is used to set the maximum number of hops (Time To Live) a datagram is
    allowed to make before it is abandoned, and not delivered. The acceptable range
    is 0-255, with the default being one (1) on most systems. This is not normally
    a setting one needs to worry about, but it is available when precise limits make
    sense, such as when packets are cheap and hops are costly.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 数据报像任何网络数据包一样在网络中跳跃。`setMulticastTTL`方法用于设置数据报在被放弃之前允许跳转的最大次数（生存时间）。可接受的范围是0-255，在大多数系统上默认为1。这通常不是一个需要担心的设置，但在精确的限制有意义的情况下是可用的，比如数据包廉价而跳数昂贵的情况。
- en: If you'd like to also allow listening on the local interface, use `socket.setBroadcast(true)`
    and `socket.setMulticastLoopback(true)`. This is normally not necessary.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望还允许在本地接口上监听，可以使用`socket.setBroadcast(true)`和`socket.setMulticastLoopback(true)`。这通常是不必要的。
- en: 'We will eventually use this server to broadcast messages to all UDP listeners
    on `multicastAddress`. For now, let''s create two clients that will listen for
    multicasts:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终将使用这个服务器向`multicastAddress`上的所有UDP监听者广播消息。现在，让我们创建两个将监听多播的客户端：
- en: '[PRE35]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We now have two clients listening to the same multicast port. All that is left
    to do is the multicasting. In this example, we will use `setTimeout` to send a
    counter value every second:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有两个客户端监听相同的多播端口。剩下的就是多播。在这个例子中，我们将使用`setTimeout`每秒发送一个计数器值：
- en: '[PRE36]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The counter values will produce something like the following:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 计数器值将产生类似以下的内容：
- en: '[PRE37]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We have two clients listening to broadcasts from a specific group. Let''s add
    another client, listening on a different group, let''s say at multicast address
    `230.3.2.1`:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有两个客户端监听特定组的广播。让我们再添加另一个客户端，监听不同的组，比如说多播地址`230.3.2.1`：
- en: '[PRE38]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'As our server currently broadcasts messages to a different address, we will
    need to change our server configuration and add this new address with another
    `addMembership` call:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的服务器当前正在向不同的地址广播消息，我们需要更改服务器配置并使用另一个`addMembership`调用添加这个新地址：
- en: '[PRE39]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We can now send to *both* addresses:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以发送到*两个*地址：
- en: '[PRE40]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Nothing stops the client from broadcasting to others in the group, or even
    members of another group:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 没有什么能阻止客户端向组中的其他成员广播，甚至向另一个组的成员广播：
- en: '[PRE41]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Any node process that has an address on our network interface can now listen
    on a UDP multicast address for messages, providing a fast and elegant inter-process
    communication system.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，任何具有网络接口上地址的节点进程都可以监听UDP多播地址以获取消息，提供快速而优雅的进程间通信系统。
- en: Using Amazon Web Services in your application
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在您的应用程序中使用亚马逊网络服务
- en: As a few thousand users become a few million users, as databases scale to terabytes
    of data, the cost and complexity of maintaining an application begins to overwhelm
    teams with insufficient experience, funding, and/or time. When faced with rapid
    growth, it is sometimes useful to delegate responsibilities for one or more aspects
    of your application to cloud-based service providers. **AWS****(Amazon Web Services)**
    is just such a suite of cloud-computing services, offered by [amazon.com](http://amazon.com).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 当几千个用户变成几百万个用户，当数据库扩展到几TB的数据时，维护应用程序的成本和复杂性开始压倒那些经验、资金和/或时间不足的团队。面对快速增长时，有时将应用程序的一个或多个方面的责任委托给基于云的服务提供商是很有用的。**AWS**（亚马逊网络服务）就是这样一套云计算服务，由[amazon.com](http://amazon.com)提供。
- en: You will need an AWS account in order to use these examples. All the services
    we will explore are free or nearly free for low-volume development uses. To create
    an account on AWS, visit the following link: [https://aws.amazon.com/](https://aws.amazon.com/).
    Once you have created an account, you will be able to manage all of your services
    via the AWS console: [https://aws.amazon.com/console/](https://aws.amazon.com/console/)
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要一个AWS账户才能使用这些示例。我们将要探索的所有服务对于低容量开发用途都是免费或几乎免费的。要在AWS上创建一个账户，请访问以下链接：[https://aws.amazon.com/](https://aws.amazon.com/)。创建账户后，您将能够通过AWS控制台管理所有服务：[https://aws.amazon.com/console/](https://aws.amazon.com/console/)
- en: 'In this section we will learn how to use three popular AWS services:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何使用三种流行的AWS服务：
- en: For storing documents and files we will connect with Amazon **S3**
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了存储文档和文件，我们将连接到亚马逊**S3**
- en: '**(Simple Storage Service)**'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: （简单存储服务）
- en: Amazon's Key/Value database, **DynamoDB**
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊的键/值数据库，**DynamoDB**
- en: To manage a large volume of e-mail, we will leverage Amazon's **SES**
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了管理大量的电子邮件，我们将利用亚马逊的**SES**
- en: '**(Simple Email Service)**'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: （简单电子邮件服务）
- en: To access these services we will use the AWS SDK for Node, which can be found
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 为了访问这些服务，我们将使用Node的AWS SDK，可以在以下位置找到
- en: at the following link: [https://github.com/aws/aws-sdk-js](https://github.com/aws/aws-sdk-js)
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下链接：[https://github.com/aws/aws-sdk-js](https://github.com/aws/aws-sdk-js)
- en: 'To install the module run the following command:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装模块，请运行以下命令：
- en: '[PRE42]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Full documentation for the `aws-sdk` module can be found at: [https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/index.html](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/index.html).'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '`aws-sdk`模块的完整文档可以在以下网址找到：[https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/index.html](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/index.html)。'
- en: Authenticating
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 身份验证
- en: 'Developers registered with AWS are assigned two identifiers:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 注册AWS的开发人员被分配了两个标识符：
- en: A public **Access Key ID** (a 20-character, alphanumeric sequence).
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个公共**Access Key ID**（一个20个字符的字母数字序列）。
- en: A **Secret Access Key** (a 40-character sequence). It is very important to keep
    your Secret Key private.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个**Secret Access Key**（一个40个字符的序列）。保持您的Secret Key私密非常重要。
- en: Amazon also provides developers with the ability to identify the region with
    which to communicate, such as `"us-east-1"`. This allows developers to target
    the closest servers (regional endpoint) for their requests.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊还为开发人员提供了识别要通信的区域的能力，比如`"us-east-1"`。这使开发人员能够针对最近的服务器（区域端点）发出请求。
- en: The regional endpoint and both authentication keys are necessary to make requests.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 区域端点和两个身份验证密钥对于发出请求是必要的。
- en: 'For a breakdown of regional endpoints, visit: [https://docs.aws.amazon.com/general/latest/gr/rande.html](https://docs.aws.amazon.com/general/latest/gr/rande.html).'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 有关区域端点的详细信息，请访问：[https://docs.aws.amazon.com/general/latest/gr/rande.html](https://docs.aws.amazon.com/general/latest/gr/rande.html)。
- en: 'As we will be using the same credentials in each of the following examples,
    let''s create a single `config.json` file that is reused:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将在接下来的每个示例中使用相同的凭据，让我们创建一个可重用的`config.json`文件：
- en: '[PRE43]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We also configure the specific API versions we will use for services. Should
    Amazon's services API change, this will ensure that our code will continue to
    work.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还会配置我们将用于服务的特定API版本。如果亚马逊的服务API发生变化，这将确保我们的代码将继续工作。
- en: 'An AWS session can now be initialized with just two lines of code. Assume that
    these two lines exist prior to any of the example code that follows:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在可以用两行代码初始化AWS会话。假设这两行代码存在于接下来的任何示例代码之前：
- en: '[PRE44]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Errors
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 错误
- en: 'When experimenting with these services, it is likely that error codes will
    appear on occasion. Due to their complexity, and the nature of cloud computing,
    these services can sometimes emit surprising or unexpected errors. For example,
    because S3 can only promise eventual consistency in some regions and situations,
    attempting to read a key that has just been written to may not always succeed.
    We will be exploring the complete list of error codes for each service, and they
    can be found at the following locations:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试这些服务时，可能会偶尔出现错误代码。由于其复杂性和云计算的性质，这些服务有时会发出令人惊讶或意外的错误。例如，因为S3在某些区域和情况下只能保证最终一致性，尝试读取刚写入的密钥可能并不总是成功。我们将探索每个服务的完整错误代码列表，它们可以在以下位置找到：
- en: '**S3:**[ https://docs.aws.amazon.com/AmazonS3/latest/API/ErrorResponses.html](https://docs.aws.amazon.com/AmazonS3/latest/API/ErrorResponses.html)'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**S3:** [https://docs.aws.amazon.com/AmazonS3/latest/API/ErrorResponses.html](https://docs.aws.amazon.com/AmazonS3/latest/API/ErrorResponses.html)'
- en: '**DynamoDB: **[http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html](http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html)'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DynamoDB:** [http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html](http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Programming.Errors.html)'
- en: '**SES: **[https://docs.aws.amazon.com/ses/latest/DeveloperGuide/api-error-codes.html](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/api-error-codes.html)
    and [https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-response-codes.html](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-response-codes.html)'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SES:** [https://docs.aws.amazon.com/ses/latest/DeveloperGuide/api-error-codes.html](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/api-error-codes.html)
    和 [https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-response-codes.html](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-response-codes.html)'
- en: As it will be difficult in the beginning to predict where errors might arise,
    it is important to employ the `domain` module or other error-checking code as
    you proceed.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在开始阶段很难预测错误可能出现的位置，因此在进行操作时使用`domain`模块或其他错误检查代码是很重要的。
- en: 'Additionally, a subtle but fundamental aspect of Amazon''s security and consistency
    model is the strict synchronization of its web server time and time as understood
    by a server making requests. A discrepancy of 15 minutes is the maximum allowed.
    While this seems like a long time, in fact time drift is very common. When developing
    watch out for 403: Forbidden errors that resemble one of the following:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，亚马逊安全和一致性模型的一个微妙但基本的方面是其Web服务器时间和发出请求的服务器理解的时间的严格同步。最大允许的差异为15分钟。虽然这似乎是一个很长的时间，但事实上时间漂移是非常常见的。在开发过程中要注意类似以下的403：禁止错误：
- en: '`SignatureDoesNotMatch`: This error means that the signature has expired'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SignatureDoesNotMatch`：这个错误意味着签名已经过期'
- en: '`RequestTimeTooSkewed`: The difference between the request time and the current
    time is too large'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RequestTimeTooSkewed`：请求时间与当前时间的差异太大'
- en: 'If such errors are encountered, the internal time of the server making requests
    may have drifted. If so, that server''s time will need to be synchronized. On
    Unix, one can use the **NTP****(Network Time Protocol)** to achieve synchrony.
    One solution is to use the following commands:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 如果遇到此类错误，发出请求的服务器的内部时间可能已经偏移。如果是这样，那么该服务器的时间将需要同步。在Unix上，可以使用**NTP**（网络时间协议）来实现同步。一个解决方案是使用以下命令：
- en: '[PRE45]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'For more information on NTP and time synchronization, visit: [http://www.pool.ntp.org/en/use.html](http://www.pool.ntp.org/en/use.html).'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 有关NTP和时间同步的更多信息，请访问：[http://www.pool.ntp.org/en/use.html](http://www.pool.ntp.org/en/use.html)。
- en: Let's start using AWS services, beginning with the distributed file service,
    S3.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始使用AWS服务，从分布式文件服务S3开始。
- en: Using S3 to store files
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用S3存储文件
- en: S3 can be used to store any file one expects to be able to store on a filesystem.
    Most commonly, it is used to store media files such as images and videos. S3 is
    an excellent document storage system as well, especially well-suited for storing
    small JSON objects or similar data objects.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: S3可用于存储任何人们期望能够存储在文件系统上的文件。最常见的用途是存储媒体文件，如图像和视频。S3也是一个非常优秀的文档存储系统，特别适合存储小型JSON对象或类似的数据对象。
- en: Also, S3 objects are accessible via HTTP, which makes retrieval very natural,
    and REST methods such as PUT/DELETE/UPDATE are supported. S3 works very much like
    one would expect a typical file server to work, is spread across servers that
    span the globe, and offers storage capacity that is, for all practical purposes,
    limitless.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，S3对象可以通过HTTP访问，这使得检索非常自然，并且支持REST方法，如PUT/DELETE/UPDATE。S3的工作方式非常类似于人们对典型文件服务器的期望，它分布在遍布全球的服务器上，并提供了在实际上无限的存储容量。
- en: S3 uses the concept of a **bucket** as a sort of corollary to *hard drive*.
    Each S3 account can contain 100 buckets (this is a hard limit), with no limits
    on the number of files contained in each bucket.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: S3使用**存储桶**的概念作为*硬盘*的一种类比。每个S3帐户最多可以包含100个存储桶（这是一个硬性限制），每个存储桶中的文件数量没有限制。
- en: Working with buckets
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理存储桶
- en: 'Creating a bucket is easy:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 创建存储桶很容易：
- en: '[PRE46]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We will receive a data map containing the `Location` bucket, and a `RequestId`:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将收到一个包含`Location`存储桶和`RequestId`的数据映射：
- en: '[PRE47]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'It is likely that many different operations will be made against a bucket.
    As a convenience, the `aws-sdk` allows a bucket name to be automatically defined
    in the parameter list for all further operations:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能会对一个存储桶进行许多不同的操作。为了方便起见，`aws-sdk`允许在所有后续操作的参数列表中自动定义存储桶名称：
- en: '[PRE48]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Use `listBuckets` to fetch an array of the existing buckets:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`listBuckets`获取现有存储桶的数组：
- en: '[PRE49]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Bucket names are global to all S3 users. No single user of S3 can use a bucket
    name that another user has claimed. If I have a bucket named `foo`, no other S3
    user can ever use that bucket name. This is a gotcha that many miss.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 存储桶名称对所有S3用户都是全局的。S3的单个用户不能使用另一个用户已经声明的存储桶名称。如果我有一个名为`foo`的存储桶，其他S3用户就永远不能使用那个存储桶名称。这是许多人忽视的一个陷阱。
- en: Working with objects
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理对象
- en: 'Let''s add a document to the `nodejs-book` bucket on S3:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在S3的`nodejs-book`存储桶中添加一个文档：
- en: '[PRE50]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'If the PUT is successful, its callback will receive an object similar to the
    following:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 如果PUT成功，它的回调将收到类似以下内容的对象：
- en: '[PRE51]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'You are encouraged to consult the SDK documentation and experiment with all
    the parameters that `putObject` accepts. Here, we focus on the only two required
    fields, and a few useful and common ones:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓励您查阅SDK文档并尝试`putObject`接受的所有参数。在这里，我们专注于唯一的两个必填字段，以及一些有用和常见的字段：
- en: '`Key`: A name to uniquely identify your file within this bucket.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Key`：用于在此存储桶中唯一标识您的文件的名称。'
- en: '`Body`: A Buffer, String, or Stream comprising the file body.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Body`：包含文件主体的缓冲区、字符串或流。'
- en: '`ServerSideEncryption`: Whether to encrypt the file within S3\. The only current
    option is AES256 (which is a good one!).'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ServerSideEncryption`：是否在S3内加密文件。目前唯一的选项是AES256（这是一个很好的选项！）。'
- en: '`ContentType`: Standard MIME type.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ContentType`：标准MIME类型。'
- en: '`ContentLength`: A String indicating the destination IP for the datagram.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ContentLength`：指示数据报的目标IP的字符串。'
- en: '`ACL`: Canned access permissions, such as `private` or `public-read-write`.
    Consult the S3 documentation.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ACL`：预定义的访问权限，例如`private`或`public-read-write`。请参阅S3文档。'
- en: 'It is a good idea to have the `Key` object resemble a filesystem path, helping
    with sorting and retrieval later on. In fact, Amazon''s S3 console reflects this
    pattern in its UI:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 让`Key`对象类似于文件系统路径是一个好主意，有助于以后进行排序和检索。事实上，亚马逊的S3控制台在其UI中反映了这种模式：
- en: '![](img/1d16565b-7ef5-48cb-b02b-7e7548a362b8.png)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1d16565b-7ef5-48cb-b02b-7e7548a362b8.png)'
- en: 'Let''s stream an image up to S3:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将图像流式传输到S3：
- en: '[PRE52]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'As we gave this image `public-read` permissions, it will be accessible at:
    [https://s3.amazonaws.com/nodejs-book/demos/putObject/testimage.jpg](https://s3.amazonaws.com/nodejs-book/demos/putObject/testimage.jpg).'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们给了这张图片`public-read`权限，因此可以在以下位置访问：[https://s3.amazonaws.com/nodejs-book/demos/putObject/testimage.jpg](https://s3.amazonaws.com/nodejs-book/demos/putObject/testimage.jpg)。
- en: 'Fetching an object from S3 and streaming it onto a local filesystem is even
    easier:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 从S3获取对象并将其流式传输到本地文件系统甚至更容易：
- en: '[PRE53]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Alternatively, we can catch data events on the HTTP chunked transfer:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以在HTTP分块传输上捕获数据事件：
- en: '[PRE54]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'To delete an object, do this:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 删除对象时，请执行以下操作：
- en: '[PRE55]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'To delete multiple objects, pass an Array (to a maximum of 1,000 objects):'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除多个对象，请传递一个数组（最多1,000个对象）：
- en: '[PRE56]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Using AWS with a Node server
  id: totrans-328
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Node服务器的AWS
- en: 'Putting together what we know about Node servers, streaming file data through
    pipes, and HTTP, it should be clear how to mount S3 as a filesystem in just a
    few lines of code:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 整合我们对Node服务器、通过管道流式传输文件数据和HTTP的了解，就可以清楚地知道如何在几行代码中将S3挂载为文件系统：
- en: '[PRE57]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'A standard Node HTTP server receives a request URL. We first attempt a HEAD
    operation using the `aws-sdk` method `headObject`, accomplishing two things:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 标准的Node HTTP服务器接收请求URL。我们首先尝试使用`aws-sdk`方法`headObject`进行HEAD操作，完成两件事：
- en: We'll determine whther the file is available
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将确定文件是否可用
- en: We will have the header information necessary to build a response
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将拥有构建响应所需的标头信息
- en: After handling any non-200 status code errors, we only need to set our response
    headers and stream the file back to the requester, as previously demonstrated.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理任何非200状态代码错误后，我们只需要设置响应标头并将文件流式传输回请求者，就像之前演示的那样。
- en: Such a system can also operate as a **fail-safe**, in both directions; should
    S3, or the file, be unavailable, we might bind to another filesystem, streaming
    from there. Conversely, if our preferred local filesystem fails, we might fall
    through to our backup S3 filesystem.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的系统也可以作为**故障安全**，在两个方向上操作；如果S3或文件不可用，我们可以绑定到另一个文件系统，从那里流式传输。相反，如果我们首选的本地文件系统失败，我们可以切换到备用的S3文件系统。
- en: Refer to the `amazon/s3-redirect.js` file in the code bundle available at the
    Packt website for an example of using 302 redirects to similarly mount an AWS
    filesystem.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 有关使用302重定向类似地挂载AWS文件系统的示例，请参考Packt网站提供的代码包中的`amazon/s3-redirect.js`文件。
- en: S3 is a powerful data storage system with even more advanced features than those
    we've covered, such as object versioning, download payment management, and setting
    up objects as torrent files. With its support for streams, the `aws-sdk` module
    makes it easy for Node developers to work with S3 as if it was a local filesystem.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: S3是一个功能强大的数据存储系统，具有比我们所涵盖的更高级的功能，例如对象版本控制、下载支付管理和将对象设置为种子文件。有了对流的支持，`aws-sdk`模块使Node开发人员可以轻松地像使用本地文件系统一样使用S3。
- en: Getting and setting data with DynamoDB
  id: totrans-338
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用DynamoDB获取和设置数据
- en: '**DynamoDB** (**DDB**) is a NoSQL database providing very high throughput and
    predictability that can be easily scaled. DDB is designed for **data-intensive**
    applications, performing massive map/reduce and other analytical queries with
    low latency and reliably. That being said, it is also an excellent database solution
    for general web applications.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '**DynamoDB**（**DDB**）是一个NoSQL数据库，提供非常高的吞吐量和可预测性，可以轻松扩展。DDB专为**数据密集型**应用程序设计，执行大规模的map/reduce和其他分析查询，延迟低且可靠。也就是说，它也是一种出色的通用Web应用程序数据库解决方案。'
- en: 'The whitepaper announcing DynamoDB was highly influential, sparking a real
    interest in NoSQL databases, and inspiring many, including **Apache** **Cassandra**.
    The paper deals with advanced concepts, but rewards careful study; it is available
    at: [http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf](http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf).'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 宣布DynamoDB的白皮书产生了很大的影响，引发了对NoSQL数据库的真正兴趣，并激发了许多人，包括**Apache** **Cassandra**。该白皮书涉及高级概念，但值得仔细研究；可在以下位置找到：[http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf](http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf)。
- en: A Dynamo database is a collection of tables, which is a collection of items,
    which are a collection of attributes. Each item in a table (or row, if you prefer)
    must have a primary key, functioning as an index for the table. Each item can
    have any number of attributes (up to a limit of 65 KB) in addition to the primary
    key.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: Dynamo数据库是表的集合，表是项目的集合，项目是属性的集合。表中的每个项目（或者您更喜欢的行）必须具有作为表索引的主键。除了主键外，每个项目可以具有任意数量的属性（最多65
    KB）。
- en: 'This is an item with five attributes, one attribute serving as the primary
    key (`Id`):'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个具有五个属性的项目，其中一个属性作为主键（`Id`）：
- en: '[PRE58]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Let''s create a table with both a primary and a secondary key:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个具有主键和辅助键的表：
- en: '[PRE59]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The callback will receive an object similar to this:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 回调将接收类似于此的对象：
- en: '[PRE60]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Table creation/deletion is not immediate; you are essentially queueing up the
    creation of a table (note `TableStatus`). At some point in the (near) future,
    the table will exist. As DDB table definitions cannot be changed without deleting
    the table and rebuilding it, in practice, this delay is not something that should
    impact your application—build once, and then work with items.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 表的创建/删除不是立即的；实质上，您正在排队创建表（请注意`TableStatus`）。在（近）将来的某个时候，表将存在。由于DDB表定义不能在不删除表并重建它的情况下更改，因此在实践中，这种延迟不应影响您的应用程序——只需构建一次，然后使用项目。
- en: DDB tables must be given a schema indicating the item attributes that will function
    as keys, defined by `KeySchema`. Each attribute in `KeySchema` can be either a
    `RANGE` or a `HASH`. There must be one such index; there can be at most two. Each
    added item must contain any defined keys, with as many additional attributes as
    desired.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: DDB表必须具有模式，指示将作为键的项目属性，由`KeySchema`定义。`KeySchema`中的每个属性可以是`RANGE`或`HASH`。必须有一个这样的索引；最多可以有两个。每个添加的项目必须包含任何定义的键，以及所需的任意数量的其他属性。
- en: Each item in `KeySchema` must be matched in count by the items in `AttributeDefinitions`.
    In `AttributeDefinitions`, each attribute can be either a number (`"N"`) or a
    string (`"S"`). When adding or modifying attributes, it is always necessary to
    identify attributes by its type as well as by the name.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '`KeySchema`中的每个项目必须与`AttributeDefinitions`中的项目数量匹配。在`AttributeDefinitions`中，每个属性可以是数字（`"N"`）或字符串（`"S"`）。在添加或修改属性时，始终需要通过类型和名称来标识属性。'
- en: 'To add an item, use the following:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加项目，请使用以下内容：
- en: '[PRE61]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'In addition to our primary and (optional) secondary keys, we want to add other
    attributes to our item. Each must be given one of the following types:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们的主键和（可选的）辅助键之外，我们还想为我们的项目添加其他属性。每个属性必须属于以下类型之一：
- en: '`S`: A String'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`S`：字符串'
- en: '`N`: A Number'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`N`：数字'
- en: '`B`: A Base64-encoded string'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`B`：Base64编码的字符串'
- en: '`SS`: An Array of Strings (String set)'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SS`：字符串数组（字符串集）'
- en: '`NS`: An Array of Numbers (Number set)'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NS`：数字数组（数字集）'
- en: '`BS`: An Array of Base64-encoded strings (Base64 set)'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BS`：Base64编码字符串数组（Base64集）'
- en: All items will need to have the same number of columns; again, dynamic schemas
    are *not* a feature of DDB.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 所有项目都需要具有相同数量的列；再次强调，动态模式*不*是DDB的特性。
- en: 'Assume that we''ve created a table that looks like the following table:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们创建了一个如下表所示的表：
- en: '| **Id** | **Date** | **Action** | **Cart** | **UserId** |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| **Id** | **Date** | **Action** | **Cart** | **UserId** |'
- en: '| 123 | 1375314738466 | buy | { "song1", "song2" } | DD9DDD8892 |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| 123 | 1375314738466 | 购买 | { "song1", "song2" } | DD9DDD8892 |'
- en: '| 124 | 1375314738467 | buy | { "song2", "song4" } | DD9EDD8892 |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| 124 | 1375314738467 | 购买 | { "song2", "song4" } | DD9EDD8892 |'
- en: '| 125 | 1375314738468 | buy | { "song12", "song6" } | DD9EDD8890 |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| 125 | 1375314738468 | 购买 | { "song12", "song6" } | DD9EDD8890 |'
- en: Now, let's perform some search operations.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们执行一些搜索操作。
- en: Searching the database
  id: totrans-367
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 搜索数据库
- en: 'There are two types of search operations available: **query** and **scan**.
    A scan on a table with a single primary key will, without exception, search every
    item in a table, returning those matching your search criteria. This can be very
    slow on anything but small databases. A query is a direct key lookup. We''ll look
    at queries first. Note that in this example, we will assume that this table has
    only one primary key.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种类型的搜索操作可用：**查询**和**扫描**。对于具有单个主键的表进行扫描将无一例外地搜索表中的每个项目，并返回与您的搜索条件匹配的项目。这在除小型数据库外的任何情况下都可能非常慢。查询是直接的键查找。我们将首先查看查询。请注意，在此示例中，我们将假设此表只有一个主键。
- en: 'To fetch the `Action` and `Cart` attributes for item `124`, we use the following
    code:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取项目`124`的`Action`和`Cart`属性，我们使用以下代码：
- en: '[PRE62]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'This will return the following:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回以下内容：
- en: '[PRE63]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: To select all attributes, simply omit the `AttributesToGet` definition.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 要选择所有属性，只需省略`AttributesToGet`的定义。
- en: A scan is more expensive, but allows more involved searches. The usefulness
    of secondary keys is particularly pronounced when doing scans, allowing us to
    avoid the overhead of scanning the entire table. In our first example of scan,
    we will work as if there is only a primary key. Then, we will show how to filter
    the scan using the secondary key.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 扫描更昂贵，但允许更复杂的搜索。在进行扫描时，辅助键的实用性特别明显，可以避免扫描整个表的开销。在我们的第一个扫描示例中，我们将假设只有一个主键。然后，我们将展示如何使用辅助键过滤扫描。
- en: 'To get all the records whose `Cart` attribute contains `song2`, use the following
    code:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取所有`Cart`属性包含`song2`的记录，请使用以下代码：
- en: '[PRE64]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: This will return all attribute values for items with `Id` 123 and 124.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回`Id`为123和124的项目的所有属性值。
- en: 'Let''s now use our secondary key to filter this further:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用我们的辅助键进一步过滤：
- en: '[PRE65]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: This new filter limits results to item 124.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 此新过滤器将结果限制为项目124。
- en: Sending mail via SES
  id: totrans-381
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过SES发送邮件
- en: 'Amazon describes the problems SES is designed to solve in this way:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊以这种方式描述SES旨在解决的问题：
- en: '"Building large-scale email solutions to send marketing and transactional messages
    is often a complex and costly challenge for businesses. To optimize the percentage
    of emails that are successfully delivered, businesses must deal with hassles such
    as email server management, network configuration, and meeting rigorous Internet
    Service Provider (ISP) standards for email content."'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: “为发送营销和交易消息构建大规模的电子邮件解决方案通常是企业面临的一个复杂且昂贵的挑战。为了优化成功交付的电子邮件百分比，企业必须处理诸如电子邮件服务器管理、网络配置以及满足严格的互联网服务提供商（ISP）标准等麻烦。”
- en: Apart from the typical network scaling problems inherent in growing any system,
    providing email services is made particularly difficult due to the prevalence
    of spam. It is very hard to send a large number of unsolicited emails without
    ending up blacklisted, even when the recipients are amenable to receiving them.
    Spam control systems are automated; your service must be listed in the *whitelists*,
    which is used by various email providers and spam trackers in order to avoid having
    a low percentage of your emails end up somewhere other than your customer's inbox.
    A mail service must have a good reputation with the right people or it becomes
    nearly useless.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 除了任何系统增长中固有的典型网络扩展问题之外，由于垃圾邮件的普遍存在，提供电子邮件服务变得特别困难。很难发送大量的未经请求的电子邮件而不被列入黑名单，即使收件人愿意接收它们。垃圾邮件控制系统是自动化的；您的服务必须被列入*白名单*，这是各种电子邮件提供商和垃圾邮件跟踪器使用的，以避免您的电子邮件低于客户收件箱以外的地方的百分比。邮件服务必须在正确的人群中有良好的声誉，否则它几乎没有用处。
- en: Amazon's SES service has the necessary reputation, providing application developers
    with cloud-based e-mail service which is reliable and able to handle a nearly
    infinite volume of e-mail. In this section we will learn how SES can be used by
    a Node application as a reliable mail delivery service.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊的SES服务具有必要的声誉，为应用程序开发人员提供可靠的基于云的电子邮件服务，能够处理几乎无限量的电子邮件。在本节中，我们将学习SES如何被Node应用程序用作可靠的邮件投递服务。
- en: Ensure that you have SES access by visiting your developer console. When you
    first sign up with SES, you will be given *Sandbox* access. When in this mode,
    you are limited to using only Amazon's mailbox simulator, or sending email to
    address you have verified (such as one's own). You may request production access,
    but for our purposes, you will only need to verify an email address to test with.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您通过访问您的开发者控制台获得SES访问权限。当您首次注册SES时，您将获得*沙箱*访问权限。在此模式下，您只能使用亚马逊的邮箱模拟器，或者发送邮件到您已验证的地址（例如您自己的地址）。您可以申请生产访问权限，但出于我们的目的，您只需要验证一个电子邮件地址进行测试。
- en: 'As the cost of using a service such as SES will increase as your mail volume
    increases, you might want to periodically check your quotas:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 使用诸如SES之类的服务的成本会随着邮件量的增加而增加，您可能需要定期检查您的配额：
- en: '[PRE66]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'To send a message, do this:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 要发送消息，请执行以下操作：
- en: '[PRE67]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The callback will receive something like the following output:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 回调将接收类似以下输出：
- en: '[PRE68]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Multiple recipients, HTML body contents, and all the other features one would
    expect from a mail service are available.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 多个收件人、HTML正文内容以及邮件服务中所期望的所有其他功能都是可用的。
- en: Using Twilio to create an SMS bot on Heroku
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Twilio在Heroku上创建一个短信机器人
- en: We are going to be building an application that works as a customer service
    application, whereby customer service agents can field SMS requests from customers
    and respond to them. There will be two parts to the system.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将构建一个作为客户服务应用程序的应用程序，客户服务代理可以处理来自客户的短信请求并回复它们。系统将有两个部分。
- en: 'Part 1 : A client application, running on your local machine, which spins up
    a React-powered web interface that displays incoming SMS messages, indicates the
    sentiment of the message (is the customer angry? Happy?) and allows you to respond
    to the message. Note that even though this server is running on a local machine,
    it could just as well be deployed to Heroku, or somewhere else -- the goal is
    to demonstrate how many servers in different locations can intelligently communicate
    with each other.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一部分：一个客户端应用程序，在您的本地计算机上运行，它会启动一个由React驱动的Web界面，显示传入的短信消息，指示消息的情绪（客户生气了吗？开心吗？），并允许您回复消息。请注意，即使这个服务器在本地计算机上运行，它也可以部署到Heroku或其他地方--目标是演示不同位置的多台服务器如何智能地相互通信。
- en: 'Part 2 : A *switchboard* that fields messages arriving via the Twilio SMS gateway,
    processes them, and distributes messages across any number of client servers --
    if you have 10 customer service representatives connected to the switchboard using
    the client application, messages the switchboard receives will be spread across
    these clients evenly. This second application will be deployed on Heroku.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二部分：一个*交换机*，通过Twilio短信网关接收到的消息，处理它们，并将消息分发到任意数量的客户端服务器--如果您有10名客户服务代表使用客户端应用程序连接到交换机，交换机接收到的消息将均匀分布到这些客户端上。这第二个应用程序将部署在Heroku上。
- en: 'You will first need to get an account on **Heroku**, a cloud server provider
    similar to Digital Ocean: [http://www.heroku.com](http://www.heroku.com)'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 您首先需要在**Heroku**上注册一个帐户，这是一个类似于Digital Ocean的云服务器提供商：[http://www.heroku.com](http://www.heroku.com)
- en: Heroku provides free accounts, so you will be able to build out the following
    application without any cost to you.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: Heroku提供免费帐户，因此您将能够构建以下应用程序而无需任何费用。
- en: Once you have your account, log in and download the Heroku CLI for your system: [https://devcenter.heroku.com/articles/getting-started-with-nodejs#set-up](https://devcenter.heroku.com/articles/getting-started-with-nodejs#set-up).
    Follow the steps on that page to log in to the command line toolbelt for Heroku.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有了帐户，请登录并下载适用于您的系统的Heroku CLI：[https://devcenter.heroku.com/articles/getting-started-with-nodejs#set-up](https://devcenter.heroku.com/articles/getting-started-with-nodejs#set-up)。按照该页面上的步骤登录Heroku的命令行工具。
- en: Make sure you have Git installed ([https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)).
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您已安装Git（[https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)）。
- en: 'Create a directory on your local file system, and clone the following two repositories
    into that folder:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地文件系统上创建一个目录，并将以下两个存储库克隆到该文件夹中：
- en: '[https://github.com/sandro-pasquali/thankyou](https://github.com/sandro-pasquali/thankyou)'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/sandro-pasquali/thankyou](https://github.com/sandro-pasquali/thankyou)'
- en: '[https://github.com/sandro-pasquali/switchboard](https://github.com/sandro-pasquali/switchboard)'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/sandro-pasquali/switchboard](https://github.com/sandro-pasquali/switchboard)'
- en: The *thankyou *repository is the client application. You will now deploy the *switchboard*
    repository to Heroku.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '*thankyou*存储库是客户端应用程序。现在，您将部署*switchboard*存储库到Heroku。'
- en: 'Using your Terminal navigate to the *switchboard* repository and deploy a copy
    to Heroku:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 使用您的终端导航到*switchboard*存储库并将副本部署到Heroku：
- en: '[PRE69]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'You should see something like the following displayed in your Terminal:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该在终端中看到类似以下内容的显示：
- en: '![](img/3742c243-35e8-497b-8b4f-cc12e582c705.png)'
  id: totrans-409
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3742c243-35e8-497b-8b4f-cc12e582c705.png)'
- en: 'Heroku has established a Git endpoint on your server. Now, run the following
    command:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: Heroku在您的服务器上建立了一个Git端点。现在，运行以下命令：
- en: '[PRE70]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'You will see a list of two elements returned: *heroku* and *origin*. These
    are the two remote branches that your local *switchboard* repository is tracking,
    the one on Heroku and the one you originally cloned from.'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到返回的两个元素列表：*heroku*和*origin*。这些是您的本地*switchboard*存储库正在跟踪的两个远程分支，一个在Heroku上，一个是您最初克隆的。
- en: 'The next step is to push your local repository into the Heroku repository:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将本地存储库推送到Heroku存储库：
- en: '[PRE71]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'You should see a lot of installation instructions. When everything completes
    successfully navigate to your application URL. You should see that there is an
    *Application Error*. Heroku provides complete logs for your application. Let''s
    access them now to discover what went wrong:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到很多安装说明。当一切顺利完成后，导航到您的应用程序URL。您应该看到有一个*应用程序错误*。Heroku为您的应用程序提供完整的日志。现在让我们访问它们，以发现出了什么问题：
- en: '[PRE72]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'To keep a running tail of log activity on your Heroku server, use:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Heroku服务器上保持日志活动的运行尾部，请使用：
- en: '**` > heroku logs --tail`**'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: '**` > heroku logs --tail`**'
- en: You should see several errors around the absence of environment variables, especially
    for Twilio. The application expects these to be set in the application environment,
    and they haven't been. Let's do that now.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到关于环境变量缺失的几个错误，特别是对于Twilio。应用程序期望这些在应用程序环境中设置，并且它们还没有被设置。让我们现在来做。
- en: Using Twilio webhooks to receive and send SMS messages
  id: totrans-420
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Twilio Webhooks接收和发送短信
- en: The switchboard application ultimately provides a single service—to set up a
    REST-enabled endpoint that Twilio can call with SMS messages received on the number
    you've registered. It stores a log of those messages on a per-phone-number basis
    in LevelDB (a very fast key/value storage library), broadcasting new messages
    to clients connected to the switchboard.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: switchboard应用程序最终提供了一个单一的服务——建立一个REST启用的端点，Twilio可以通过该端点调用接收到的短信。它在LevelDB（一个非常快速的键/值存储库）中按电话号码存储这些消息的日志，并向连接到switchboard的客户端广播新消息。
- en: 'The logical flow of the entire application will look like this:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 整个应用程序的逻辑流程将如下所示：
- en: '![](img/41dc79a2-620b-464c-911c-cf54e2030a86.png)'
  id: totrans-423
  prefs: []
  type: TYPE_IMG
  zh: '![](img/41dc79a2-620b-464c-911c-cf54e2030a86.png)'
- en: We can see that the logic of our application begins with an SMS from Twilio,
    and supports responses from clients. This is the basic pattern for constructing
    a *NoUI*, or pure SMS application. This pattern is growing in popularity, often
    seen in the form of chat bots, AI-enabled assistants, and so on. We'll dig deeper
    into the application soon.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到我们的应用程序的逻辑是从Twilio收到的短信开始，并支持客户端的响应。这是构建*NoUI*或纯短信应用程序的基本模式。这种模式越来越受欢迎，通常以聊天机器人、AI助手等形式出现。我们将很快深入了解应用程序。
- en: Right now, we need to enable the Twilio bridge.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要启用Twilio桥接。
- en: To start, you will need to create a test account on Twilio to get some API variables.
    Go to [https://www.twilio.com](https://www.twilio.com) and sign up for a test
    account. Ensure that you set up a test phone number; we'll be sending SMS messages
    to that number.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您需要在Twilio上创建一个测试帐户以获取一些API变量。转到[https://www.twilio.com](https://www.twilio.com)并注册一个测试帐户。确保设置一个测试电话号码；我们将向该号码发送短信。
- en: 'Once you''ve done that, grab your Twilio API keys from the account Dashboard,
    your phone number, and your phone number SID. Now you''ll need to add that information
    to the environment variables for Heroku, along with some other keys. Go to your
    Heroku dashboard, find your instance, click on it, and navigate to Settings |
    Reveal Config Vars:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，从帐户仪表板获取Twilio API密钥、电话号码和电话号码SID。现在，您需要将该信息添加到Heroku的环境变量中，以及其他一些密钥。转到您的Heroku仪表板，找到您的实例，点击它，然后导航到设置
    | 显示配置变量：
- en: '![](img/04197e4a-5fa5-470a-9412-e5172e94c99f.png)'
  id: totrans-428
  prefs: []
  type: TYPE_IMG
  zh: '![](img/04197e4a-5fa5-470a-9412-e5172e94c99f.png)'
- en: 'This is where you add key/value pairs to `process.env` in your running Node
    process. Add the following key/value pairs:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 这是您在运行的Node进程中向`process.env`添加键/值对的地方。添加以下键/值对：
- en: '`TWILIO_AUTH_TOKEN` / <your auth token>'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TWILIO_AUTH_TOKEN` / <您的auth令牌>'
- en: '`TWILIO_SID` / <your sid>'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TWILIO_SID` / <您的sid>'
- en: '`TWILIO_PHONE_NUMBER_SID` / <your phone # sid>'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TWILIO_PHONE_NUMBER_SID` / <您的电话号码sid>'
- en: '`TWILIO_DEFAULT_FROM` / <your assigned phone number>'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TWILIO_DEFAULT_FROM` / <您分配的电话号码>'
- en: '`SOCK_PORT` / `8080`'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SOCK_PORT` / `8080`'
- en: '`URL` / <your server URL (with no trailing slash)'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`URL` / <您的服务器URL（没有尾随斜杠）'
- en: Once you've saved these new environment variables, your application will automatically
    restart on Heroku. Try your application URL again. If everything is working, you
    should see a message like Switchboard is active.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 保存这些新的环境变量后，您的应用程序将在Heroku上自动重新启动。再次尝试您的应用程序URL。如果一切正常，您应该看到一个消息，如Switchboard
    is active。
- en: You can quickly load your application into a browser from the command line with **`> heroku open`**.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用命令行快速将应用程序加载到浏览器中，方法是**`> heroku open`**。
- en: While we will not be using the shell, you can log in to your Heroku box via
    your Terminal with `> heroku run bash`.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们不会使用shell，但您可以通过终端登录到Heroku服务器，方法是`> heroku run bash`。
- en: 'To communicate with Twilio, we''ll be using the official Node library at: [https://github.com/twilio/twilio-node](https://github.com/twilio/twilio-node).
    The important code can be found in the `router/sms/` folder of the switchboard
    repository. This module will allow us to register a webhook to receive messages, and
    to respond to those messages.'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 要与Twilio进行通信，我们将使用官方的Node库：[https://github.com/twilio/twilio-node](https://github.com/twilio/twilio-node)。重要的代码可以在switchboard存储库的`router/sms/`文件夹中找到。该模块将允许我们注册一个webhook来接收消息，并对这些消息进行响应。
- en: Now, let's build the switchboard.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们构建switchboard。
- en: The switchboard
  id: totrans-441
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: switchboard
- en: The switchboard will have a single responsibility—to communicate with Twilio.
    Since we're using webhooks, we'll need to create a server that can catch POST
    data from Twilio. For the web server, we'll use the `restify` package ([http://www.restify.com](http://www.restify.com)).
    This is a very fast Node server implementation that is designed specifically for
    fast, high-load REST-based APIs. Since the switchboard is solely focused on handling
    incoming messages from Twilio, and its outbound traffic is through WebSockets,
    there is no need for a *higher-level* server like Express, which is designed to
    facilitate the presentation of views through templates, sessions, and so forth.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: switchboard将有一个单一的责任——与Twilio进行通信。由于我们使用webhooks，我们需要创建一个服务器，可以接收来自Twilio的POST数据。对于web服务器，我们将使用`restify`包（[http://www.restify.com](http://www.restify.com)）。这是一个非常快速的Node服务器实现，专门设计用于快速、高负载的基于REST的API。由于switchboard专注于处理来自Twilio的传入消息，并且其出站流量是通过WebSockets，因此不需要像Express这样的*更高级*服务器，后者旨在通过模板、会话等来促进视图的呈现。
- en: 'Let''s look at the code instantiating a restify server that accepts POST messages
    from Twilio containing SMS message data, and the socket server to bind clients
    to the switchboard:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下实例化一个接受包含短信消息数据的Twilio POST消息的restify服务器的代码，以及将客户端绑定到switchboard的套接字服务器：
- en: '[PRE73]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'With very little code, we''ve set up a web server and extended it with a socket
    server (using the excellent `ws` module, which you can grab at: [https://github.com/websockets/ws](https://github.com/websockets/ws)).
    You are encouraged to look at the code in the switchboard repository, where the
    details of how client connections are managed should be easy to follow. In particular,
    investigate the `router/Db/index.js` file, where a `levelDB` connection is established
    and an API for storing message histories (`api.addToNumberHistory`) is defined.
    For our purposes, note the `server.get` method, which establishes a handler for
    GET requests used simply as a *ping* service should we need to check whether the
    switchboard is available. We''ll add the important webhook route next.'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 通过非常少的代码，我们已经建立了一个Web服务器，并使用了一个套接字服务器（使用了优秀的`ws`模块，您可以在[https://github.com/websockets/ws](https://github.com/websockets/ws)获取）。鼓励您查看switchboard存储库中的代码，那里应该很容易理解客户端连接管理的细节。特别是要调查`router/Db/index.js`文件，其中建立了一个`levelDB`连接，并定义了用于存储消息历史记录的API（`api.addToNumberHistory`）。对于我们的目的，请注意`server.get`方法，它为简单的*ping*服务建立了一个GET请求的处理程序，以便我们需要检查switchboard是否可用。接下来，我们将添加重要的webhook路由。
- en: 'The Twilio webhook code is presented with the following line:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: Twilio webhook代码如下：
- en: '[PRE74]'
  id: totrans-447
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'The code in that file looks like this:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 该文件中的代码如下：
- en: '[PRE75]'
  id: totrans-449
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Given that we''re connecting to and using a global SMS gateway, the code is
    surprisingly simple. After instantiating an instance of the Twilio API using the
    environment variables we set earlier on Heroku, we can conveniently use this API
    to programmatically establish a webhook, avoiding the manual process of logging
    into a Twilio dashboard:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到我们正在连接和使用全球短信网关，代码非常简单。在使用我们之前在Heroku上设置的环境变量实例化Twilio API之后，我们可以方便地使用此API来以编程方式建立webhook，避免手动登录Twilio仪表板的过程：
- en: '[PRE76]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: More importantly, this technique allows us to dynamically reconfigure the Twilio
    endpoint Twilio; it is always nice to be able to *hot swap* handlers should naming,
    or something else, change.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，这种技术使我们能够动态重新配置Twilio端点；能够随时更改处理程序的名称或其他内容总是很好的。
- en: 'The body that Twilio POSTs and we will be receiving looks something like this:'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: Twilio POST的主体和我们将要接收的内容如下：
- en: '[PRE77]'
  id: totrans-454
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: In the hook handler, we grab the key info—the number of the sender and the message—storing
    them in `levelDB` via the `api.addToNumberHistory` method (which returns a Promise).
    Now we are ready to inform a client of the message. How do we do that?
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 在hook处理程序中，我们获取关键信息——发送者的号码和消息——并通过`api.addToNumberHistory`方法将它们存储在`levelDB`中（返回一个Promise）。现在我们准备通知客户端消息。我们该如何做？
- en: Clients are connected via a websocket. We can, after writing to the DB, simply
    send the message to the client in the same function body. However, now our code
    is starting to become complex, taking on two responsibilities (receiving and sending)
    rather than just one (receiving). It may seem like a small matter, but this is
    the sort of place where feature creep appears—maybe next we add logging in this
    function, and so on. Also, if we are responsible for notifying clients of new
    messages, we'll also be required to confirm that a database write was successful;
    this is often not clear cut, false positives not being out of the ordinary.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端通过websocket连接。在写入数据库后，我们可以在同一个函数体中简单地将消息发送给客户端。然而，现在我们的代码开始变得复杂，承担了两个责任（接收和发送），而不仅仅是一个（接收）。这可能看起来像一个小问题，但这是功能蔓延出现的地方——也许接下来我们在这个函数中添加日志记录等。此外，如果我们负责通知客户端有新消息，我们还需要确认数据库写入是否成功；这通常并不明确，假阳性并不罕见。
- en: 'Instead of doing that, let''s create a notification system that broadcasts
    changesets. Whenever a new message is written to the DB—a confirmed write—announce
    that update event, and register an event handler. In our intial server code, this
    functionality is bound using the following line:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个通知系统，用于广播变更集。每当向数据库写入新消息时——确认写入——宣布更新事件，并注册事件处理程序。在我们的初始服务器代码中，使用以下行绑定了此功能：
- en: '[PRE78]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The code to catch changesets and broadcast them uses *Domenic Tarr''s* `level-live-stream`
    package:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 捕获更改集并广播它们的代码使用了*Domenic Tarr*的`level-live-stream`包：
- en: '[PRE79]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: Using `level-live-stream`, we are able to concentrate our logic on the right
    event—a confirmed write to the database—leaving this *microservice* responsible
    solely for finding an available client and sending them the updated message history.
    Note that the way clients are stored and referenced in this example is not at
    all definitive. You might want to continue with the *do one thing well* philosophy
    and create another small service solely responsible for brokering connections.
    For example, we might remove all the client code from this example and create
    another service exposing a `getNextAvailableClient` method. This type of compositional
    strategy orchestrating microservices will be discussed further in the next chapter.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`level-live-stream`，我们能够将逻辑集中在正确的事件上——确认写入数据库——使得这个*微服务*仅负责查找可用的客户并向他们发送更新的消息历史。请注意，这个示例中存储和引用客户的方式并不是最终确定的。您可能希望继续遵循*做好一件事*的理念，并创建另一个负责经纪连接的小型服务。例如，我们可以从这个示例中删除所有客户端代码，并创建另一个服务，暴露一个`getNextAvailableClient`方法。这种编排微服务的组合策略将在下一章中进一步讨论。
- en: 'We can now receive, store, and broadcast incoming SMS messages. There is only
    one bit of functionality left—sending client responses back to Twilio, continuing
    the SMS conversation. The composition of these responses is performed by the *thankyou*
    application we''ll be discussing next. Ultimately, however, those responses are
    directed by the switchboard (recall the preceding sequence diagram), and the following
    is the very short code that you can use to send SMS messages through the Twilio
    gateway:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以接收、存储和广播传入的短信消息。只剩下一个功能——将客户端响应发送回Twilio，继续短信对话。这些响应的组成由我们接下来将讨论的*thankyou*应用程序执行。然而，这些响应最终是由交换机指导的（回想一下前面的序列图），以下是您可以使用的非常简短的代码，通过Twilio网关发送短信消息：
- en: '[PRE80]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'You should recall an *on message* listener for the websocket registered in
    our base server code, which uses the preceding functionality to respond to callers.
    We can now expand that listener:'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该回想一下在我们的基本服务器代码中注册的websocket的*on message*监听器，它使用前面的功能来响应调用者。我们现在可以扩展该监听器：
- en: '[PRE81]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: We see `addToNumberHistory` here again since responses are of course part of
    the conversation history. Once the outgoing message is added to the database record,
    send it along via Twilio. Did you note something? That's only one of the things
    we have to do. The other is send the updated message history *back to the client*
    so that this response can appear in their view of the history. Typically, this
    is done using some client JavaScript that, when the client types a response and
    clicks on *send*, it optimistically updates the client state in the hope the message
    makes it to the switchboard. What does it not, though?
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次看到了`addToNumberHistory`，因为响应当然是对话历史的一部分。一旦传出消息被添加到数据库记录中，通过Twilio发送它。您注意到了什么吗？这只是我们要做的事情之一。另一个是将更新的消息历史*发送回客户端*，以便这个响应可以出现在他们的历史视图中。通常，这是使用一些客户端JavaScript来完成的，当客户端输入响应并点击*发送*时，它会乐观地更新客户端状态，希望消息能够到达交换机。但如果没有呢？
- en: We see how the changeset approach helps here. If the client message fails to
    reach the switchboard or otherwise fails, the `levelDB` will never be updated
    and the client's history state will not be out of sync with the canonical history
    represented by the data layer. While this may not matter so much in a trivial
    application like this one, it will matter if you're building transactional software.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到了这里改变集方法如何帮助。如果客户端消息未能到达交换机或以其他方式失败，`levelDB`将永远不会更新，并且客户端的历史状态将不会与数据层表示的规范历史不同步。虽然在这种微不足道的应用程序中可能并不重要，但如果您正在构建事务性软件，这将很重要。
- en: Now, let's walk through the other half of the application—the *thankyou* client.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看应用程序的另一半——*thankyou*客户端。
- en: The ThankYou interface
  id: totrans-469
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感谢界面
- en: 'To recap, we want to create a system whereby a switchboard receives SMS messages
    and passes them along to *service representatives* running a conversational interface
    on their local laptop or similar. This client is defined in the `thankyou` repository,
    and will look like this:'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们希望创建一个系统，其中交换机接收短信消息并将其传递给在本地笔记本电脑或类似设备上运行的*服务代表*的对话界面。这个客户端在`thankyou`存储库中定义，看起来像这样：
- en: '![](img/a0f0409d-094e-4e6d-8361-8d3ea78df642.png)'
  id: totrans-471
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a0f0409d-094e-4e6d-8361-8d3ea78df642.png)'
- en: Here, we see the message history the switchboard manages, and the interface
    for sending back responses. Importantly, there are icons indicating the sentiment
    (the winking happiness, the sad anger), of the messages as well as their timestamp
    in a human readable format (*a few seconds ago*). The goal for `thankyou` will
    be to catch incoming (and outgoing) messages, run sentiment analysis on the message
    stream, and display the results. We'll use React to build the UI.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到了交换机管理的消息历史，以及发送响应的界面。重要的是，消息中有表示情绪（眨眼的快乐，悲伤的愤怒）的图标，以及以人类可读的格式（*几秒钟前*）的时间戳。`thankyou`的目标将是捕获传入（和传出）的消息，对消息流进行情感分析，并显示结果。我们将使用React来构建UI。
- en: React requires a build system, and we're using **Browserify**, **Gulp**, and
    **BrowserSync**. How those technologies work is beyond the scope of this chapter.
    Go over the contents of `gulpfile.js` and the `/source` directory of the `thankyou`
    repository. There are many online tutorials for these popular technologies.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: React需要一个构建系统，我们正在使用**Browserify**，**Gulp**和**BrowserSync**。这些技术的工作原理超出了本章的范围。查看`gulpfile.js`和`thankyou`存储库的`/source`目录的内容。有许多关于这些流行技术的在线教程。
- en: 'As we are serving a real UI, for this project, we will use Express to build
    our Node server. Still, the server is very simple. It is only responsible for
    serving the single view just pictured, which is contained in a single `index.html`
    file:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在为一个真实的UI提供服务，因此在这个项目中，我们将使用Express来构建我们的Node服务器。不过，服务器非常简单。它只负责提供单个视图，该视图包含在一个名为`index.html`的文件中。
- en: '[PRE82]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: React components are bundled by the build system into `components.js`; JavaScript
    files are similarly bundled into `app.js`, as stylesheets are into `app.css`.
    The jQuery DOM manipulation library is used for simple element effects and for
    managing the message composer. As mentioned, we won't be going deep into client
    JavaScript. It will be useful to take a brief look at the React component used
    to construct the timeline, as this component is ultimately what will be receiving
    new messages from the switchboard.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: React组件由构建系统捆绑到`components.js`中；JavaScript文件类似地捆绑到`app.js`中，样式表捆绑到`app.css`中。jQuery
    DOM操作库用于简单的元素效果和管理消息撰写器。正如前面提到的，我们不会深入研究客户端JavaScript。但是，简要查看用于构建时间线的React组件将会很有用，因为这个组件最终将接收来自交换机的新消息。
- en: 'This is the main UI component powering `thankyou`:'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 这是支持`thankyou`的主要UI组件：
- en: '[PRE83]'
  id: totrans-478
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: Even if you don't know React, you should be able to see that the `MessageHistory`
    component extends the `Timeline` component. The `Timeline` component is responsible
    for maintaining the application state, or in our case, the current message history.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您不了解React，您也应该能够看到`MessageHistory`组件扩展了`Timeline`组件。`Timeline`组件负责维护应用程序状态，或者在我们的情况下，当前的消息历史记录。
- en: 'This is the key UI code in `MessageHistory`:'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`MessageHistory`中的关键UI代码：
- en: '[PRE84]'
  id: totrans-481
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'You may recall the message history that switchboard works with:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还记得交换机处理的消息历史记录：
- en: '[PRE85]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'This is the section in the `MessageHistory` where that data is rendered into
    UI views. We won''t go too much farther into the UI code, but you should note
    a property that switchboard did not generate: `it.sentiment`. Keep that in mind
    that as we go over how thankyou communicates data with switchboard.'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`MessageHistory`中渲染数据到UI视图的部分。我们不会深入研究UI代码，但您应该注意到交换机没有生成的一个属性：`it.sentiment`。在我们讨论`thankyou`如何与交换机通信时，请记住这一点。
- en: 'Since the switchboard receives and sends messages over WebSockets, `Timeline`
    has such a reference:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 由于交换机通过WebSockets接收和发送消息，`Timeline`有这样一个引用：
- en: '[PRE86]'
  id: totrans-486
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'The socket code was included in our `index.html` file:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 套接字代码包含在我们的`index.html`文件中：
- en: '[PRE87]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Also, it looks like this:'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 也是这样的：
- en: '[PRE88]'
  id: totrans-490
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'This code puts the `ws` reference in the browser global scope on the client
    (`window.ws`). While generally not the best practice, for our simple UI, this
    makes it easy for React components to grab the same socket reference. This reference
    is also used in the `MessageComposer` component, which accepts responses from
    the client:'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将`ws`引用放在客户端的全局范围内（`window.ws`）。虽然通常不是最佳做法，但对于我们简单的UI来说，这使得React组件可以轻松获取相同的套接字引用。这个引用也在`MessageComposer`组件中使用，该组件接受来自客户端的响应：
- en: '[PRE89]'
  id: totrans-492
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: This component renders a text area, into which responses can be composed and
    sent, via socket, to the switchboard.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 该组件呈现一个文本区域，可以在其中撰写并通过套接字发送响应到交换机。
- en: Now, let's look at how the client server communicates with the client UI, brokering
    communication with the switchboard.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看客户端服务器如何与客户端UI通信，通过与交换机的通信进行协调。
- en: 'The client server is defined in `router/index.js`:'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端服务器在`router/index.js`中定义：
- en: '[PRE90]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'This is a standard Express setup. Note the following line:'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个标准的Express设置。请注意以下行：
- en: '[PRE91]'
  id: totrans-498
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'This is the main broker logic. Recalling the application sequence diagram,
    here is where switchboard messages are received and passed along, through another
    socket, to the UI and ultimately, the React renderer. Similarly, the server listens
    for messages from the UI and passes those along to the switchboard:'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 这是主要的经纪人逻辑。回想一下应用程序顺序图，这里是接收和传递交换机消息的地方，通过另一个套接字，最终传递给UI和React渲染器。同样，服务器监听来自UI的消息，并将其传递给交换机：
- en: '[PRE92]'
  id: totrans-500
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: This should make sense now, given the *switchboard* design. Starting at the
    bottom, we see that when the client socket server `localClientSS` receives a message,
    it validates and passes the message along to the *switchboard*, where it will
    be added to the message history for the phone number this client is handling.
    More interesting is the code to receive messages from the switchboard, which performs
    sentiment analysis and converts timestamps into human readable sentences.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑到*交换机*的设计，这应该是有意义的。从底部开始，我们看到当客户端套接字服务器`localClientSS`接收到消息时，它会验证并将消息传递给*交换机*，其中消息将被添加到此客户端处理的电话号码的消息历史记录中。更有趣的是接收来自交换机的消息的代码，它执行情感分析并将时间戳转换为可读的句子。
- en: 'To perform these transformations, the payload received from the *switchboard*
    (an Array in JSON format) is converted into an object stream using the `arrayToStream.js`
    module. Streams are covered in [Chapter 3](c7665bc9-3f44-4d7c-8318-61f9dfe962b3.xhtml), *Streaming
    Data Across Nodes and Clients*; we''re simply creating a `Readable` Stream that
    pipes each element in the array as a distinct object. The real fun begins when
    we apply transformations. Let''s look at the code to do sentiment analysis (which
    processes the `''message''` property of the history object), using the `through2`
    module ([https://github.com/rvagg/through2](https://github.com/rvagg/through2))
    to simplify the creation and design of a transform stream, and of course, the
    sentiment module ([https://github.com/thisandagain/sentiment](https://github.com/thisandagain/sentiment))
    to gauge the mood of the message:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行这些转换，从*交换机*（以JSON格式的数组）接收到的有效负载被转换为对象流，使用`arrayToStream.js`模块。流在[第3章](c7665bc9-3f44-4d7c-8318-61f9dfe962b3.xhtml)中有介绍，*在节点和客户端之间传输数据*；我们只是创建一个`Readable`流，将数组中的每个元素作为一个独立的对象传输。当我们应用转换时，真正的乐趣开始了。让我们看一下情感分析的代码（处理历史对象的`'message'`属性），使用`through2`模块（[https://github.com/rvagg/through2](https://github.com/rvagg/through2)）简化转换流的创建和设计，当然还有情感模块（[https://github.com/thisandagain/sentiment](https://github.com/thisandagain/sentiment)）来评估消息的情绪：
- en: '[PRE93]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: The functionality is straightforward; for each object in the history array sent
    from the switchboard, determine the sentiment score for the message. Negative
    scores are *bad*, along the range from very bad (*devil*) to *unhappy*. We similarly
    score positive sentiments along a range from very good (*wink*) to *happy*. A
    new `sentiment` property is added to the message object, and as we saw earlier
    when considering the `MessageHistory` component, this will set which icon the
    message receives in the UI.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 功能很简单；对于从交换机发送的历史数组中的每个对象，确定消息的情感分数。负分数是*不好的*，范围从非常糟糕（*魔鬼*）到*不开心*。我们同样对正面情感进行评分，范围从非常好（*眨眼*）到*开心*。一个新的`sentiment`属性被添加到消息对象中，正如我们之前在考虑`MessageHistory`组件时看到的那样，这将设置消息在UI中接收的图标。
- en: If you want to continue development of this application on your own, you should
    fork the repositories onto your own GitHub account, and repeat the process with
    these personal repositories. This will allow you to push changes and otherwise
    modify the application to suit your own needs.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想自己继续开发这个应用程序，你应该将存储库fork到你自己的GitHub账户上，并使用这些个人存储库重复这个过程。这将允许你推送更改，或者以其他方式修改应用程序以满足你自己的需求。
- en: The coordination of *switchboard* and *thankyou* should give you some ideas
    on how to use services, sockets, REST endpoints, and third-party APIs to distribute
    functionality, helping you scale through adding (or removing) components, across
    the stack. By using transform streams, you can apply "on the fly" stream data
    transformations without blocking, managing data models on your servers, and leaving
    layout to the UI itself.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: '*交换机*和*感谢*的协调应该给你一些关于如何使用服务、套接字、REST端点和第三方API来分发功能的想法，帮助你通过添加（或删除）组件来扩展整个堆栈。通过使用转换流，你可以在不阻塞的情况下应用“即时”流数据转换，管理服务器上的数据模型，并将布局留给UI本身。'
- en: Summary
  id: totrans-507
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Big data applications have placed significant responsibility on developers of
    network applications to prepare for scale. Node has offered help in creating a
    network-friendly application development environment that can easily connect to
    other devices on a network, such as cloud services and, in particular, other Node
    servers.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据应用程序已经给网络应用程序的开发者带来了重大责任，需要为规模做好准备。Node在创建一个网络友好的应用程序开发环境方面提供了帮助，可以轻松连接到网络上的其他设备，比如云服务，特别是其他Node服务器。
- en: In this chapter, we learned some good strategies for scaling Node servers, from
    analyzing CPU usage to communicating across processes. With our new knowledge
    of message queues and UDP, we can build networks of Node servers scaling horizontally,
    letting us handle more and more traffic by simply replicating the existing nodes.
    Having investigated load balancing and proxying with both Node and NGINX, we can
    confidently add capacity to our applications. When matched with the cloud services
    provided by Digital Ocean, AWS, and Twilio, we can attempt enterprise-scale development,
    data storage, and broadcast at a low cost and without adding much complexity to
    our application.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了一些扩展Node服务器的好策略，从分析CPU使用率到跨进程通信。有了我们对消息队列和UDP的新知识，我们可以构建水平扩展的Node服务器网络，通过简单复制现有节点来处理越来越多的流量。通过使用Node和NGINX进行负载均衡和代理，我们可以自信地为我们的应用程序增加容量。当与Digital
    Ocean、AWS和Twilio提供的云服务配合使用时，我们可以尝试进行企业规模的开发、数据存储和广播，而成本低廉，而且不会给我们的应用程序增加太多复杂性。
- en: As our applications grow, we will need to maintain continuous awareness of how
    each part as well as the whole is behaving. As we keep adding new components and
    functionality, some local, some through the cloud, some maybe even written in
    another language, how do we, as developers, intelligently track and plan additions
    and other changes? In the next chapter, we will learn about microservices, a way
    of developing one application out of many, small, cooperating horizontally-distributed
    network services.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们的应用程序不断增长，我们需要持续关注每个部分以及整体的行为。随着我们不断添加新的组件和功能，一些是本地的，一些是通过云端的，甚至可能是用另一种语言编写的，作为开发者，我们如何智能地跟踪和规划添加和其他变化？在下一章中，我们将学习微服务，一种通过许多小的、协作的水平分布的网络服务来开发一个应用程序的方式。
