- en: Edge Services
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 边缘服务
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下食谱：
- en: Controlling access to your service with an edge proxy server
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用边缘代理服务器控制对您的服务的访问
- en: Extending your services with sidecars
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用边车扩展您的服务
- en: Using API Gateway to route requests to services
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用API网关将请求路由到服务
- en: Rate limiting with an edge proxy server
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用边缘代理服务器进行速率限制
- en: Stopping cascading failure with Hystrix
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Hystrix停止级联故障
- en: Using a service mesh to factor out shared concerns
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用服务网格来提取共享关注点
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: Now that you've had some experience breaking a monolith into microservices,
    you've seen that many of the challenges exist outside the monolith or service
    code bases themselves. Exposing your service to the internet, controlling routing,
    and building in resiliency are all concerns that can be addressed by what are commonly
    called **edge services**. These are services that exist at the edge of our architecture,
    generally handling requests from the public internet. Luckily, because many of
    these challenges are so common, open source projects exist to handle most of them
    for us. We'll use a lot of great open source software in this chapter.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经有一些将单体分解为微服务的经验，您已经看到许多挑战存在于单体或服务代码库之外。将服务公开到互联网、控制路由和构建弹性都是可以通过通常称为**边缘服务**来解决的问题。这些服务存在于我们架构的边缘，通常处理来自公共互联网的请求。幸运的是，由于许多这些挑战非常普遍，因此存在开源项目来为我们处理其中大部分。在本章中，我们将使用大量的开源软件。
- en: With the recipes in this chapter, you'll learn how to use open source software
    to expose your services to the public internet, control routing, extend your service's
    functionality, and handle a number of common challenges when deploying and scaling
    microservices. You'll also learn about techniques for making client development
    against services easier and how to standardize the monitoring and observability
    of your microservice architecture.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章中的食谱，您将学习如何使用开源软件将您的服务公开到公共互联网，控制路由，扩展您服务的功能，并在部署和扩展微服务时处理许多常见挑战。您还将了解使客户端开发对服务更容易的技术以及如何标准化您微服务架构的监控和可观察性。
- en: Controlling access to your service with an edge proxy server
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用边缘代理服务器控制对您的服务的访问
- en: In [Chapter 1](d5b36f18-79eb-4c0a-bbde-3e94733ef97c.xhtml), *Breaking the Monolith*,
    we modified a monolith code base to provide easy routing to our microservices.
    This approach works and requires little effort, making it an ideal intermediary
    step. Eventually, your monolith will become a bottleneck in the development and
    resiliency of your architecture. As you try to scale your service and build more
    microservices, your monolith will need to be updated and deployed every time you
    make an API change to your service. Additionally, your monolith will have to handle
    connections to your services and is probably not well-configured to handle edge
    concerns such as load shedding or circuit breaking. In the *Routing requests to
    services* recipe of [Chapter 1](d5b36f18-79eb-4c0a-bbde-3e94733ef97c.xhtml), *Breaking
    the Monolith*, we introduced the concept of edge proxies. Using an edge proxy
    server to expose your service to the public internet allows you to factor out
    most of the shared concerns a publicly exposed service must address. Requirements
    such as request routing, load shedding, back pressure, and authentication can
    all be handled in a single edge proxy layer instead of being duplicated by every
    service you need to have exposed to the internet.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](d5b36f18-79eb-4c0a-bbde-3e94733ef97c.xhtml)《打破单体》中，我们修改了单体代码库以提供对微服务的简单路由。这种方法是可行的，并且需要很少的努力，使其成为一个理想的中间步骤。最终，您的单体将成为您架构开发和弹性的瓶颈。当您尝试扩展服务并构建更多微服务时，您的单体需要在您对服务进行API更改时每次都进行更新和部署。此外，您的单体还需要处理对服务的连接，并且可能没有很好地配置来处理边缘关注点，例如负载减轻或断路器。在[第1章](d5b36f18-79eb-4c0a-bbde-3e94733ef97c.xhtml)《打破单体》的“将请求路由到服务”食谱中，我们介绍了边缘代理的概念。使用边缘代理服务器将您的服务公开到公共互联网允许您提取出公开暴露的服务必须解决的许多共享关注点。如请求路由、负载减轻、背压和身份验证等需求都可以在一个单一的边缘代理层中处理，而不是由每个需要公开到互联网的服务重复处理。
- en: An edge proxy is a proxy server that sits on the edge of your infrastructure,
    providing access to internal services. You can think of an edge proxy as the “front
    door” to your internal service architecture—it allows clients on the internet
    to make requests to internal services you deploy. There are multiple open source
    edge proxies that have a robust feature set and community, so we don't have to
    write and maintain our own edge proxy server. One of the most popular open source
    edge proxy servers is called **Zuul** and is built by Netflix. Zuul is an edge
    service that provides dynamic routing, monitoring, resiliency, security, and more.
    Zuul is packaged as a Java library. Services written in the Java framework Spring
    Boot can use an embedded Zuul service to provide edge-proxy functionality. In
    this recipe, we'll walk through building a small Zuul edge proxy and configuring
    it to route requests to our services.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘代理是一种位于您基础设施边缘的代理服务器，提供对内部服务的访问。您可以将边缘代理视为内部服务架构的“前门”——它允许互联网上的客户端向您部署的内部服务发出请求。有多个开源边缘代理具有强大的功能集和社区，因此我们不必编写和维护自己的边缘代理服务器。最受欢迎的开源边缘代理服务器之一是名为**Zuul**的，由Netflix构建。Zuul是一个边缘服务，提供动态路由、监控、弹性、安全等功能。Zuul被打包成一个Java库。使用Java框架Spring
    Boot编写的服务可以使用内嵌的Zuul服务来提供边缘代理功能。在本食谱中，我们将逐步构建一个小型Zuul边缘代理，并配置它将请求路由到我们的服务。
- en: Operational notes
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运营笔记
- en: Continuing with our example application from the previous chapter, imagine that
    our photo-messaging application (we'll call it `pichat` from now on) was originally
    implemented as a Ruby on Rails monolithic code base. When the product first launched,
    we deployed the application to Amazon Web Services behind a single **Elastic Load
    Balancer** (**ELB**). We created a single **Auto Scale Group** (**ASG**) for the
    monolith, called `pichat-asg`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 继续我们上一章的示例应用程序，想象一下我们的照片消息应用（从现在起我们将称之为`pichat`）最初是作为一个Ruby on Rails单体代码库实现的。当产品首次推出时，我们将应用程序部署到了位于单一**弹性负载均衡器**（**ELB**）后面的亚马逊网络服务。我们为单体创建了一个单一的**自动扩展组**（**ASG**），命名为`pichat-asg`。
- en: Each EC2 instance in our ASG is running NGINX, which handles requests for static
    files (images, JavaScript, CSS) and proxies requests to unicorns running on the
    same host that is serving our Rails application. SSL is terminated at the ELB,
    and HTTP requests are forwarded to NGINX. The ELB is accessed through the DNS `monolith.pichat-int.me` name
    from within the **Virtual Private Cloud** (**VPC**).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们ASG中的每个EC2实例都在运行NGINX，它处理静态文件（图像、JavaScript、CSS）的请求，并将请求代理到同一主机上运行的、为我们Rails应用程序提供服务的独角兽。SSL在ELB处终止，HTTP请求被转发到NGINX。ELB通过**虚拟私有云**（**VPC**）内部的DNS名称`monolith.pichat-int.me`进行访问。
- en: We've now created a single `attachment-service`, which handles videos and images
    attached to messages being sent through the platform. The `attachment-service`
    is written in Java, using the Spring Boot platform and is deployed in its own
    ASG, called `attachment-service-asg`, that has its own ELB. We've created a private
    DNS record, called `attachment-service.pichat-int.me`, that points to this ELB.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在创建了一个单一的`attachment-service`，该服务处理通过平台发送的消息中附加的视频和图像。`attachment-service`是用Java编写的，使用Spring
    Boot平台，并部署在其自己的ASG中，命名为`attachment-service-asg`，该ASG有自己的ELB。我们创建了一个私有DNS记录，命名为`attachment-service.pichat-int.me`，它指向这个ELB。
- en: With this architecture and topology in mind, we now want to route requests from
    the public internet to our Rails application or our newly created attachment service,
    depending on the path.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑了这种架构和拓扑之后，我们现在希望根据路径将来自公共互联网的请求路由到我们的Rails应用程序或我们新创建的附件服务。
- en: How to do it...
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'To demonstrate using Zuul to route requests to services, we''ll first create
    a basic Java application that will serve as our edge proxy service. The Java project
    Spring Cloud provides an embedded Zuul service, making it pretty simple to create
    a service that uses the `zuul` library. We''ll start by creating a basic Java
    application. Create the `build.gradle` file with the following content:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了展示如何使用Zuul将请求路由到服务，我们首先将创建一个基本的Java应用程序，该应用程序将作为我们的边缘代理服务。Spring Cloud Java项目提供了一个内嵌的Zuul服务，这使得创建使用`zuul`库的服务变得非常简单。我们将首先创建一个基本的Java应用程序。创建`build.gradle`文件，内容如下：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Create a single class called `EdgeProxyApplication`. This will serve as the
    entry point to our application:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`EdgeProxyApplication`的单个类。这将是我们的应用程序的入口点：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Create a file called `application.yml` in the `src/main/resources` directory
    of your application. This file will specify your route configurations. In this
    example, we''ll imagine that our monolith application can be accessed on the `monolith.pichat-int.me` internal
    host and we want to expose the `/signup` and `/auth/login` paths to the public
    internet:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的应用程序的`src/main/resources`目录中创建一个名为`application.yml`的文件。此文件将指定你的路由配置。在这个例子中，我们将假设我们的单体应用程序可以通过`monolith.pichat-int.me`内部主机访问，并且我们希望将`/signup`和`/auth/login`路径暴露给公共互联网：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Start the project with `./gradlew bootRun` and you should be able to access
    the `/signup` and `/auth/login` URLs, which will be proxied to our monolith application.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`./gradlew bootRun`启动项目，你应该能够访问`/signup`和`/auth/login` URL，这些将通过代理转发到我们的单体应用程序。
- en: 'We want to expose the `attachment-service` URLs to the internet. The attachment
    service exposes the following endpoints:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们希望将`attachment-service` URL暴露给互联网。附件服务公开以下端点：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We''ll need to decide which paths we want to use in our public API. Modify
    `application.properties` to add the following entries:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要决定我们想在公共API中使用哪些路径。修改`application.properties`以添加以下条目：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now all requests to `/attachments/*` will be forwarded to the attachment service
    and signup, and `auth/login` will continue to be served by our monolith application.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，所有对`/attachments/*`的请求都将被转发到附件服务以及注册，而`auth/login`将继续由我们的单体应用程序提供服务。
- en: 'We can test this by running our service locally and sending requests to `localhost:8080/signup,
    localhost:8080/auth/login`, and `localhost:8080/attachments/foo`. You should be
    able to see that requests are routed to the respected services. Of course, the
    service will respond with an error because `attachment-service.pichat-int.me`
    cannot be resolved, but this shows that the routing is working as expected:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过在本地运行我们的服务并向`localhost:8080/signup`、`localhost:8080/auth/login`和`localhost:8080/attachments/foo`发送请求来测试这一点。你应该能够看到请求被路由到相应的服务。当然，服务将返回错误，因为`attachment-service.pichat-int.me`无法解析，但这表明路由按预期工作：
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Extending your services with sidecars
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过旁路扩展你的服务
- en: When you start developing microservices, it's common to embed a certain amount
    of boilerplate into each service. Logging, metrics, and configuration are all
    functionalities that are commonly copied from service to service, resulting in
    a large amount of boilerplate and copied and pasted code. As your architecture
    grows and you develop more services, this kind of setup becomes harder and harder
    to maintain. The usual result is that you end up with a bunch of different ways
    of doing logging, metrics, service discovery, and so on, which results in systems
    that are hard to debug and maintain. Changing something as simple as a metrics
    namespace or adding a feature to your service discovery clients can require the
    coordination of multiple teams and code bases. More realistically, your microservices
    architecture will continue to grow with inconsistent logging, metrics, and service
    discovery conventions, making it harder for developers to operate, contributing
    to overall operational pain.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始开发微服务时，通常会在每个服务中嵌入一定量的样板代码。日志记录、指标和配置等都是常见地从服务复制到服务的功能，导致大量样板代码和复制粘贴的代码。随着你的架构增长和服务的增加，这种设置变得越来越难以维护。通常的结果是，你最终会有一堆不同的日志记录、指标、服务发现等方法，这使得系统难以调试和维护。更改像指标命名空间或向服务发现客户端添加功能这样简单的事情可能需要多个团队和代码库的协调。更现实的是，你的微服务架构将继续在不一致的日志记录、指标和服务发现约定中增长，这使得开发者更难操作，从而增加了整体运营的痛苦。
- en: The sidecar pattern describes a pattern whereby you extend the functionality
    of a service with a separate process or container running on the same machine.
    Common functionalities, such as metrics, logging, service discovery, configuration,
    or even network RPC, can be factored out of your application and handled by a
    sidecar service running alongside it. This pattern makes it easy to standardize
    shared concerns within your architecture by implementing them in a separate process
    that can be used by all of your services.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 旁路模式描述了一种模式，即通过在同一台机器上运行一个单独的进程或容器来扩展服务的功能。常见的功能，如指标、日志记录、服务发现、配置，甚至网络RPC，都可以从你的应用程序中提取出来，并由与之并行的旁路服务处理。这种模式通过实现一个可以由所有服务使用的单独进程来标准化架构中的共享关注点，使其变得容易。
- en: A common method for implementing a sidecar is to build a small, separate process
    that exposes some functionality over a commonly used protocol, such as HTTP. Imagine,
    for instance, that you want all of your services to use a centralized service-discovery
    service instead of relying on DNS hosts and ports to be set in each application's
    configuration. To accomplish this, you'd need to have up-to-date client libraries
    for your service-discovery service available in all of the languages that your
    services and monolith are written in. A better way would be to run a sidecar parallel
    to each service that runs a service-discovery client. Your services could then
    proxy requests to the sidecar and have it determine where to send them. As an
    added benefit, you could configure the sidecar to emit consistent metrics around
    network RPC requests made between services.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 实现边车的一个常见方法是构建一个小的、独立的进程，通过常用的协议（如 HTTP）公开一些功能。例如，假设您希望所有服务都使用一个集中的服务发现服务，而不是依赖于在应用程序配置中设置
    DNS 主机和端口。为了实现这一点，您需要确保您的服务发现服务在所有用您的服务和单体编写的语言中都有最新的客户端库。更好的方法是在每个运行服务发现客户端的服务旁边运行一个边车。然后，您的服务可以将请求代理到边车，并让它确定将它们发送到何处。作为额外的优势，您可以配置边车以发出关于服务之间网络
    RPC 请求的一致度量。
- en: This is such a common pattern that there are multiple open source solutions
    available for it. In this recipe, we'll use `spring-cloud-netflix-sidecar`, a
    project that includes a simple HTTP API that allows non-JVM applications to use
    JVM client libraries. The Netflix sidecar assumes you are using Eureka, a service
    registry designed to support the service-discovery needs of clients. We'll discuss
    service discovery in more detail in later chapters. The sidecar also assumes your
    non-JVM application is serving a health-check endpoint and will use this to advertise
    its health to Eureka. Our Rails application exposes such an endpoint, /health,
    which, when running normally, will return a small JSON payload with a key status
    and the `UP` value.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个如此常见的模式，以至于有多个开源解决方案可供选择。在本食谱中，我们将使用 `spring-cloud-netflix-sidecar` 项目，该项目包含一个简单的
    HTTP API，允许非 JVM 应用程序使用 JVM 客户端库。Netflix 边车假定您正在使用 Eureka，这是一个旨在支持客户端服务发现需求的服务注册表。我们将在后面的章节中更详细地讨论服务发现。边车还假定您的非
    JVM 应用程序正在提供健康检查端点，并将使用此端点向 Eureka 宣告其健康状态。我们的 Rails 应用程序公开了一个这样的端点，/health，当正常运行时，将返回一个包含键
    status 和 `UP` 值的小 JSON 有效负载。
- en: How to do it...
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Start by creating a basic Spring Boot service. Include the Spring Boot Gradle
    plugin and add dependencies for Spring Boot and the Spring Cloud Netflix sidecar
    project:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先创建一个基本的 Spring Boot 服务。包括 Spring Boot Gradle 插件，并为 Spring Boot 和 Spring Cloud
    Netflix 边车项目添加依赖项：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We''re ready to create a simple Spring Boot application. We''ll use the `@EnableSidecar`
    annotation, which also includes the `@EnableZuulProxy`, `@EnableCircuitBreaker`,
    and `@EnableDiscoveryClient` annotations:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们准备创建一个简单的 Spring Boot 应用程序。我们将使用 `@EnableSidecar` 注解，它还包括 `@EnableZuulProxy`、`@EnableCircuitBreaker`
    和 `@EnableDiscoveryClient` 注解：
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The Netflix sidecar application requires a few configuration settings to be
    present. Create a new file called `application.yml` with the following content:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Netflix 边车应用程序需要一些配置设置。创建一个名为 `application.yml` 的新文件，并包含以下内容：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The sidecar will now expose an API that allows non-JVM applications to locate
    services registered with Eureka. If our `attachment-service` is registered with
    Eureka, the sidecar will proxy requests to `http://localhost:5678/attachment/1234`
    to `http://attachment-service.pichat-int.me/1234`.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 边车现在将公开一个 API，允许非 JVM 应用程序定位已注册到 Eureka 的服务。如果我们的 `attachment-service` 已注册到
    Eureka，边车将代理请求从 `http://localhost:5678/attachment/1234` 到 `http://attachment-service.pichat-int.me/1234`。
- en: Using API Gateways for routing requests to services
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 API 网关路由请求到服务
- en: As we've seen in other recipes, microservices should provide a specific business
    capability and should be designed around one or more domain concepts, surrounded
    by a bounded context. This approach to designing service boundaries works well
    to guide you toward simple, independently-scalable services that can be managed
    and deployed by a single team dedicated to a certain area of your application
    or business.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在其他食谱中看到的，微服务应该提供特定的业务能力，并且应该围绕一个或多个领域概念进行设计，周围是边界上下文。这种设计服务边界的方法可以很好地引导您走向简单、独立可扩展的服务，这些服务可以由一个团队管理并部署，该团队专注于您的应用程序或业务的一个特定领域。
- en: When designing user interfaces, clients often aggregate related but distinct
    entities from various backend microservices. In our fictional messaging application,
    for instance, the screen that shows an actual message might have information from
    a message service, a media service, a likes service, a comments service, and so
    on. All of this information can be cumbersome to collect and can result in a large
    number of round-trip requests to the backend.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计用户界面时，客户端通常会从各种后端微服务中聚合相关但不同的实体。在我们的虚构消息应用中，例如，显示实际消息的屏幕可能包含来自消息服务、媒体服务、赞服务、评论服务等信息。所有这些信息可能很麻烦去收集，并可能导致大量往返后端请求。
- en: 'Porting a web application from a monolith with server-side-rendered HTML to
    a single-page JavaScript application, for example, can easily result in hundreds
    of `XMLHttpRequests` for a single page load:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，将Web应用程序从具有服务器端渲染HTML的单体应用迁移到单页JavaScript应用，很容易导致单个页面加载时产生数百个`XMLHttpRequests`：
- en: '![](img/cfb729cb-f3d8-473f-affc-652421565438.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cfb729cb-f3d8-473f-affc-652421565438.png)'
- en: To reduce the amount of round-trip requests to the backend services, consider
    creating one or more API Gateways that provide an API that is catered to the client's
    needs. API Gateways can be used to present a single view of backend entities in
    a way that makes it easier for clients who use the API. In the preceding example,
    a request to a single message endpoint could return information about the message
    itself, media included in the message, likes and comments, and other information.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少往返后端服务的请求数量，考虑创建一个或多个API网关，提供满足客户端需求的API。API网关可用于以使API用户更容易使用的方式呈现后端实体。在前面的示例中，对单个消息端点的请求可以返回有关消息本身、消息中包含的媒体、赞和评论以及其他信息。
- en: 'These entities can be concurrently collected from various backend services
    using a fan-out request pattern:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这些实体可以使用扇出请求模式从各种后端服务并发收集：
- en: '![](img/58af6302-bb02-46c3-860f-7385c987080a.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/58af6302-bb02-46c3-860f-7385c987080a.png)'
- en: Design considerations
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计考虑因素
- en: One of the benefits of using an API Gateway to provide access to microservices
    is that you can create a single, cohesive API for a specific client. In most cases,
    you'll want to create a specific API for mobile clients, perhaps even one API
    for iOS and one for Android. This implementation of API Gateways is commonly referred
    to as the **Backend for Frontend** (**BFF**) because it provides a single logical
    backend for each frontend application. A web application has very different needs
    than a mobile device.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 使用API网关提供对微服务的访问的好处之一是，您可以为一个特定的客户端创建一个单一、统一的API。在大多数情况下，您可能希望为移动客户端创建一个特定的API，甚至可能为iOS和Android分别创建一个API。这种API网关的实现通常被称为**后端前端（BFF**），因为它为每个前端应用程序提供了一个单一的逻辑后端。Web应用程序与移动设备的需求非常不同。
- en: 'In our situation, we''ll focus on creating one endpoint that provides all the
    data needed by the message-view screen. This includes the message itself as well
    as the attachment(s), the user details of the sender, and any additional recipients
    of the message. If the message is public, it can also have likes and comments,
    which we''ll imagine are served by a separate service. Our endpoint could look
    something like this:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们将专注于创建一个端点，该端点提供消息查看屏幕所需的所有数据。这包括消息本身以及附件（如果有）、发送者的用户详情以及任何额外的消息接收者。如果消息是公开的，它还可以有赞和评论，我们假设这些由一个独立的服务提供。我们的端点可能看起来像这样：
- en: '[PRE9]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The endpoint will return a response similar to the following:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 该端点将返回类似于以下内容的响应：
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This response should have everything a client needs to show our message-view
    screen. The data itself comes from a variety of services, but, as we'll see, our
    API Gateway does the hard work of making those requests and aggregating the responses.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 此响应应包含客户端显示我们的消息查看屏幕所需的所有内容。数据本身来自各种服务，但正如我们将看到的，我们的API网关完成了这些请求并汇总了响应。
- en: How to do it...
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'An API Gateway is responsible for exposing an API, making multiple service
    calls, aggregating the results, and returning them to the client. The **Finagle Scala**
    framework makes this natural by representing service calls as futures, which can
    be composed to represent dependencies. To stay consistent with other examples
    in this book, we''ll build a small example gateway service in Java using the Spring
    Boot framework:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: API 网关负责公开 API，进行多次服务调用，聚合结果，并将它们返回给客户端。**Finagle Scala** 框架通过将服务调用表示为可以组合表示依赖关系的
    futures 来使这变得自然。为了与其他本书中的示例保持一致，我们将使用 Spring Boot 框架在 Java 中构建一个小型的示例网关服务：
- en: 'Create the project skeleton. Create a new Java project and add the following
    dependencies and plugins to the Gradle build file. We''ll be using Spring Boot
    and Hystrix in this recipe:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建项目骨架。创建一个新的 Java 项目，并在 Gradle 构建文件中添加以下依赖项和插件。在本菜谱中，我们将使用 Spring Boot 和 Hystrix：
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Looking at the JSON example in the previous section, it's clear that we are
    collecting and aggregating some distinct domain concepts. For the purposes of
    this example, we'll imagine that we have a message service that retrieves information
    about messages, including likes, comments, and attachments, and a user service.
    Our gateway service will be making a call to the message service to retrieve the
    message itself, then calls to the other services to get the associated data, which
    we'll stitch together in a single response. For the purposes of this recipe, imagine
    the message service is running on port `4567` and the user service on port `4568`.
    We'll create some stub services to mock out the data for these hypothetical microservices.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中的 JSON 示例中，我们可以清楚地看到我们正在收集和聚合一些独特的领域概念。为了本例的目的，我们将假设我们有一个消息服务，它可以检索有关消息的信息，包括点赞、评论和附件，以及一个用户服务。我们的网关服务将调用消息服务以检索消息本身，然后调用其他服务以获取相关数据，我们将这些数据在一个单独的响应中拼接起来。为了本菜谱的目的，假设消息服务运行在端口
    `4567` 上，而用户服务运行在端口 `4568` 上。我们将创建一些存根服务来模拟这些假设的微服务的数据。
- en: 'Create a model to represent our `Message` data:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个模型来表示我们的 `Message` 数据：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: It's important that non-dependent service calls be done in a non-blocking, asynchronous
    manner. Luckily, Hystrix has an option to execute commands asynchronously, returning
    `Future<T>`.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，非依赖性服务调用应以非阻塞、异步的方式进行。幸运的是，Hystrix 有一个选项可以异步执行命令，返回 `Future<T>`。
- en: 'Create a new package, say, `com.packtpub.microservices.gateway.commands` with
    the following classes:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的包，例如 `com.packtpub.microservices.gateway.commands`，并包含以下类：
- en: 'Create the `AttachmentCommand` class with the following content:'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建名为 `AttachmentCommand` 的类，内容如下：
- en: '[PRE13]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Create the `CommentCommand` class with the following content:'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建名为 `CommentCommand` 的类，内容如下：
- en: '[PRE14]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Create the `LikeCommand` class with the following content:'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建名为 `LikeCommand` 的类，内容如下：
- en: '[PRE15]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Our `MessageClient` class is a bit different than the previous examples—instead
    of returning the JSON string from the service response, it''ll return an object
    representation, in this case, an instance of our `Message` class:'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的 `MessageClient` 类与之前的示例略有不同——它不会返回服务响应中的 JSON 字符串，而是会返回一个对象表示，在这种情况下，是我们的
    `Message` 类的一个实例：
- en: '[PRE16]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Create the `UserCommand` class with the following content:'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建名为 `UserCommand` 的类，内容如下：
- en: '[PRE17]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Stitch together the execution of these Hystrix commands in a single controller
    that exposes our API as the `/message_details/:message_id` endpoint:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在单个控制器中拼接这些 Hystrix 命令的执行，该控制器将我们的 API 作为 `/message_details/:message_id` 端点公开：
- en: '[PRE18]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'There you have it. Run the service with `./gradlew bootRun` and test it by
    making a request to:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这就是了。使用 `./gradlew bootRun` 运行服务，并通过以下请求进行测试：
- en: '[PRE19]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Stopping cascading failures with Hystrix
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Hystrix 阻止级联故障
- en: Failures in a complex system can be hard to diagnose. Often, the symptom can
    appear far away from the cause. Users might start experiencing higher-than-normal
    error rates during login because of some downstream service that manages profile
    pictures or something else tangentially related to user profiles. An error in
    one service can often propagate needlessly to a user request and adversely impact
    user experience and therefore trust in your application. Additionally, a failing
    service can have cascading effects, turning a small system outage into a high-severity,
    customer-impacting incident. It's important when designing microservices to consider
    failure isolation and decide how you want to handle different failure scenarios.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在复杂系统中，故障诊断可能很困难。通常，症状可能出现在原因很远的地方。用户可能会因为一些管理个人资料图片或与用户资料间接相关的下游服务而导致登录时出现高于正常的错误率。一个服务的错误往往无谓地传播到用户请求，并负面影响用户体验和因此对您应用程序的信任。此外，一个失败的服务可能会产生级联效应，将小系统故障变成高严重性、影响客户的突发事件。在设计微服务时，考虑故障隔离并决定如何处理不同的故障场景是很重要的。
- en: A number of patterns can be used to improve the resiliency of distributed systems.
    Circuit breakers are a common pattern used to back off from making requests to
    a temporarily overwhelmed service. Circuit breakers were first described in Michael
    Nygard's book *Release It!*. A calling service defaults to a closed state, meaning
    requests are sent to the downstream service.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用多种模式来提高分布式系统的弹性。断路器是常用的模式，用于从向暂时过载的服务发送请求中退避。断路器最初在Michael Nygard的书籍《Release
    It!》中描述。调用服务默认处于关闭状态，意味着请求被发送到下游服务。
- en: If the calling service receives too many failures too quickly, it can change
    the state of its circuit breaker to open, and start failing fast. Instead of waiting
    for the downstream service to fail again and adding to the load of the failing
    service, it just sends an error to upstream services, giving the overwhelmed service
    time to recover. After a certain amount of time has passed, the circuit is closed
    again and requests start flowing to the downstream service.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果调用服务在很短的时间内收到过多的失败，它可以将其断路器的状态更改为打开，并开始快速失败。而不是等待下游服务再次失败并增加失败服务的负载，它只是向上游服务发送错误，给过载的服务恢复的时间。经过一段时间后，断路器再次关闭，请求开始流向下游服务。
- en: There are many available frameworks and libraries that implement circuit breakers.
    Some frameworks, such as Twitter's Finagle, automatically wrap every RPC call
    in a circuit breaker. In our example, we'll use the popular Netflix library, `hystrix`.
    Hystrix is a general-purpose, fault-tolerance library that structures isolated
    code as commands. When a command is executed, it checks the state of a circuit
    breaker to decide whether to issue or short circuit the request.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多可用的框架和库实现了断路器。一些框架，如Twitter的Finagle，会自动将每个RPC调用包装在断路器中。在我们的例子中，我们将使用流行的Netflix库`hystrix`。Hystrix是一个通用、容错库，它将隔离的代码结构化为命令。当执行命令时，它会检查断路器的状态以决定是否发出或短路请求。
- en: How to do it...
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Hystrix is made available as a Java library, so we''ll demonstrate its use
    by building a small Java Spring Boot application:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Hystrix作为一个Java库提供，我们将通过构建一个小型的Java Spring Boot应用程序来演示其使用：
- en: 'Create a new Java application and add the dependencies to your `build.gradle`
    file:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的Java应用程序，并将依赖项添加到您的`build.gradle`文件中：
- en: '[PRE20]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We''ll create a simple `MainController` that returns a simple message. This
    is a contrived example, but it demonstrates an upstream service making downstream
    calls. At first, our application will just return a hardcoded `Hello, World!`
    message. Next, we''ll move the string out to a Hystrix command. Finally, we''ll
    move the message to a service call wrapped in a Hystrix command:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将创建一个简单的`MainController`，它返回一个简单的消息。这是一个虚构的例子，但它演示了上游服务对下游服务的调用。最初，我们的应用程序将只返回硬编码的`Hello,
    World!`消息。接下来，我们将字符串移动到Hystrix命令中。最后，我们将消息移动到由Hystrix命令包装的服务调用中：
- en: '[PRE21]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Move the message out to `HystrixCommand`:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将消息移动到`HystrixCommand`：
- en: '[PRE22]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Replace the method in `MainController` to use `HystrixCommand`:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`MainController`中的方法替换为使用`HystrixCommand`：
- en: '[PRE23]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Move the message generation to another service. We''re hardcoding the hypothetical
    message service URL here, which is not a good practice but will do for demonstration
    purposes:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将消息生成移动到另一个服务。在这里，我们硬编码假设的消息服务URL，这不是一个好的实践，但为了演示目的可以这样做：
- en: '[PRE24]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Update the `MainController` class to contain the following:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新`MainController`类以包含以下内容：
- en: '[PRE25]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Our `MainController` class now makes a service call, wrapped in a Hystrix command,
    to generate a message to send back to the client. You can test this by creating
    a very simple service that generates a message string. `sinatra` is a simple-to-use
    Ruby library ideal for creating test services. Create a new file called `message-service.rb`:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的 `MainController` 类现在通过一个 Hystrix 命令封装了对服务的调用，以生成要发送给客户端的消息。你可以通过创建一个非常简单的生成消息字符串的服务来测试这一点。`sinatra`
    是一个简单易用的 Ruby 库，非常适合创建测试服务。创建一个名为 `message-service.rb` 的新文件：
- en: '[PRE26]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Run the service by running `ruby message-service.rb` and then make a few sample
    requests to your Hystrix-enabled service. You can simulate a failure by modifying
    the service to return a `503`, indicating that it is temporarily overwhelmed:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行 `ruby message-service.rb` 来启动服务，然后向你的 Hystrix 启用的服务发送几个示例请求。你可以通过修改服务以返回
    `503` 来模拟失败，这表示它暂时过载：
- en: '[PRE27]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Your Spring service should now attempt to reach the service but use the value
    in the fallback when it encounters a `503`. Furthermore, after a number of attempts,
    the command's circuit breaker will be tripped and the service will start defaulting
    to the fallback for a period of time.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 你的 Spring 服务现在应该尝试连接到服务，但在遇到 `503` 时使用回退值。此外，在尝试了多次之后，命令的断路器将被触发，服务将开始默认使用回退一段时间。
- en: Rate limiting
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 速率限制
- en: In addition to techniques such as circuit breaking, rate limiting can be an
    effective way to prevent cascading failures in a distributed system. Rate limiting
    can be effective at preventing spam, protecting against **Denial of Service**
    (**DoS**) attacks, and protecting parts of a system from becoming overloaded by
    too many simultaneous requests. Typically implemented as either a global or per-client
    limit, rate limiting is usually part of a proxy or load balancer. In this recipe,
    we'll use NGINX, a popular open source load balancer, web server, and reverse
    proxy.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 除了断路器等技术之外，速率限制还可以是防止分布式系统级联故障的有效方法。速率限制可以有效地防止垃圾邮件，抵御 **拒绝服务** (**DoS**) 攻击，并保护系统的一部分不会因为过多的并发请求而过载。通常作为全局或按客户端限制实现，速率限制通常是代理或负载均衡器的一部分。在这个配方中，我们将使用
    NGINX，这是一个流行的开源负载均衡器、Web 服务器和反向代理。
- en: Most rate-limiting implementations use the *leaky-bucket algorithm*—an algorithm
    that originated in computer network switches and telecommunications networks.
    As the name suggests, the leaky-bucket algorithm is based on the metaphor of a
    bucket with a small leak in it that controls a constant rate. Water is poured
    into the bucket in bursts, but the leak guarantees that water exists in the bucket
    at a steady, fixed rate. If the water is poured in faster than the water exits
    the bucket, eventually the bucket will overflow. In this case, the overflow represents
    requests that are dropped.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数速率限制实现都使用 *漏桶算法*——一个起源于计算机网络交换机和电信网络的算法。正如其名所示，漏桶算法基于一个隐喻，即桶中有一个小漏洞，它控制着一个恒定的速率。水以脉冲的形式倒入桶中，但漏洞保证了水在桶中以稳定、固定的速率存在。如果水的流入速度超过水从桶中流出，最终桶会溢出。在这种情况下，溢出代表被丢弃的请求。
- en: It's certainly possible to implement your own rate-limiting solution; there
    are even implementations of the algorithms out there that are open source and
    available to use. It's a lot easier, however, to use a product such as NGINX to
    do rate limiting for you. In this recipe, we'll configure NGINX to proxy requests
    to our microservice.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当然可以实施自己的速率限制解决方案；甚至有一些算法的实现是开源的，可供使用。然而，使用像 NGINX 这样的产品来为你进行速率限制要容易得多。在这个配方中，我们将配置
    NGINX 来代理对我们的微服务的请求。
- en: How to do it...
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Install NGINX by running the following command:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令来安装 NGINX：
- en: '[PRE28]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '`nginx` has a `config` file, `nginx.conf`. On an Ubuntu-based Linux system,
    this will probably be in the `/etc/nginx/nginx.conf` directory. Open the file
    and look for the `http` block and add the following content:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`nginx` 有一个 `config` 文件，`nginx.conf`。在基于 Ubuntu 的 Linux 系统上，这可能会在 `/etc/nginx/nginx.conf`
    目录中。打开文件，查找 `http` 块并添加以下内容：'
- en: '[PRE29]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: As you can see from the preceding code, rate limiting is implemented with two
    configuration directives. The `limit_req_zone` directive defines the parameters
    for rate limiting. In this example, we're implementing a rate limit, based on
    the client's IP address, of 10 requests per second. The `limit_req` directive
    applies our rate limiting to a specific path or location. In this case, we're
    applying it to all requests to `/auth/signin`, presumably because we don't want
    bots scripting the creation of accounts!
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述代码所示，速率限制是通过两个配置指令实现的。`limit_req_zone`指令定义了速率限制的参数。在这个例子中，我们根据客户端的IP地址实现了每秒10个请求的速率限制。`limit_req`指令将我们的速率限制应用于特定的路径或位置。在这种情况下，我们将其应用于对`/auth/signin`的所有请求，可能是因为我们不希望机器人编写创建账户的脚本！
- en: Using service mesh for shared concerns
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用服务网格处理共享关注点
- en: As web services' frameworks and standards evolve, the amount of boilerplate
    or shared application concerns is reduced. This is because, collectively, we figure
    out what parts of our applications are universal and therefore shouldn't need
    to be re-implemented by every programmer or team. When people first started networking
    computers, programmers writing network-aware applications had to worry about a
    lot of low-level details that are now abstracted out by the operating system's
    networking stack. Similarly, there are certain universal concerns that all microservices
    share. Frameworks such as Twitter's Finagle wrap all network calls in a circuit
    breaker, increasing fault tolerance and isolating failures in systems. Finagle
    and Spring Boot, the Java framework we've been using for most of these recipes,
    both support exposing a standard metrics endpoint that standardizes basic network,
    JVM, and application metrics collected for microservices.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 随着Web服务框架和标准的演变，样板代码或共享应用程序关注点的数量减少了。这是因为，集体地，我们确定了我们应用程序的哪些部分是通用的，因此不需要每个程序员或团队重新实现。当人们刚开始联网计算机时，编写网络感知应用程序的程序员必须担心许多现在由操作系统网络堆栈抽象出的底层细节。同样，所有微服务共享某些通用关注点。例如，Twitter的Finagle框架将所有网络调用封装在断路器中，增加了容错性并隔离了系统中的故障。Finagle和Spring
    Boot，这是我们一直在使用的大多数这些食谱的Java框架，都支持暴露一个标准的指标端点，该端点标准化了为微服务收集的基本网络、JVM和应用指标。
- en: Every microservice should consider a number of shared application concerns.
    From an observability perspective, services should strive to emit consistent metrics
    and structured logs. To improve the reliability of our systems, services should
    wrap network calls in circuit breakers and implement consistent retry and back-off
    logic. To support changes in network and service topology, services should consider
    implementing client-side load balancing and use centralized service discovery.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 每个微服务都应该考虑一些共享的应用程序关注点。从可观察性的角度来看，服务应该努力输出一致的指标和结构化日志。为了提高我们系统的可靠性，服务应该将网络调用封装在断路器中，并实现一致的重试和退避逻辑。为了支持网络和服务拓扑的变化，服务应该考虑实现客户端负载均衡并使用集中式服务发现。
- en: Instead of implementing all of these features in each of our services, it would
    be ideal to abstract them out to something outside our application code that could
    be maintained and operated separately. Like the features of our operating systems
    network stack, if each of these features is implemented by something our application
    could rely on being present, we would not have to worry about them being available.
    This is the idea behind a service mesh.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是在每个服务中实现所有这些功能，理想的做法是将它们抽象出来，使其位于我们的应用程序代码之外，这样就可以单独维护和操作。就像我们操作系统网络堆栈的功能一样，如果每个这些功能都是由我们的应用程序可以依赖的某个部分实现的，我们就无需担心它们是否可用。这就是服务网格背后的理念。
- en: Running a service mesh configuration involves running each microservice in your
    system behind a network proxy. Instead of services speaking directly to one another,
    they communicate via their respective proxies, which are installed as sidecars.
    Practically speaking, your service would communicate with its own proxy running
    on localhost. As network requests are sent through a services proxy, the proxy
    can control what metrics are emitted and what log messages are output. The proxy
    can also integrate directly with your service registry and distribute requests
    evenly among active nodes, keeping track of failures and opting to fail fast when
    a certain threshold has been reached. Running your system in this kind of configuration
    can ease the operational complexity of your system while improving the reliability
    and observability of your architecture.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 运行服务网格配置涉及在每个微服务后面运行一个网络代理。服务之间不是直接通信，而是通过各自的代理进行通信，这些代理作为边车安装。实际上，你的服务将与运行在本地主机的自己的代理进行通信。当网络请求通过服务代理发送时，代理可以控制要发出的指标和输出的日志消息。代理还可以直接与你的服务注册表集成，并在活动节点之间均匀分配请求，跟踪故障并在达到一定阈值时快速失败。以这种方式运行系统可以减轻系统的操作复杂性，同时提高架构的可靠性和可观察性。
- en: Like most of the recipes discussed in this chapter, there are numerous open
    source solutions for running a service mesh. We'll focus on **Linkerd**, an open
    source proxy server built and maintained by buoyant. The original authors of Linkerd
    worked at Twitter before forming buoyant and as such, Linkerd incorporates many
    of the lessons learned by teams at Twitter. It shares many features with the Finagle
    Scala framework, but can be used with services written in any language. In this
    recipe, we'll walk through installing and configuring Linkerd and discuss how
    we can use it to control communication between our Ruby on Rails monolith API
    and our newly developed media service.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 与本章讨论的大多数食谱一样，运行服务网格有众多开源解决方案。我们将重点关注 **Linkerd**，这是一个由 buoyant 构建和维护的开源代理服务器。Linkerd
    的原始作者在 Twitter 工作过，之后成立了 buoyant，因此 Linkerd 集成了 Twitter 团队学到的许多经验教训。它与 Finagle
    Scala 框架共享许多功能，但可以与任何语言编写的服务一起使用。在本食谱中，我们将介绍安装和配置 Linkerd，并讨论我们如何使用它来控制 Ruby on
    Rails 单体 API 和我们新开发的媒体服务之间的通信。
- en: How to do it...
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'To demonstrate running a service behind a proxy, we''ll install and run an
    instance of Linkerd and configure it to handle requests to and from your service.
    There are instructions on the Linkerd website for running it in Docker, Kubernetes,
    and other options. To keep things simple, we''ll focus on running Linkerd and
    our service locally:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示在代理后面运行服务，我们将安装并运行一个 Linkerd 实例，并配置它来处理对你的服务发出的请求。Linkerd 网站上有关于在 Docker、Kubernetes
    和其他选项中运行它的说明。为了简化，我们将专注于在本地运行 Linkerd 和我们的服务：
- en: Download the latest Linkerd release at [https://github.com/linkerd/linkerd/releases](https://github.com/linkerd/linkerd/releases).
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 [https://github.com/linkerd/linkerd/releases](https://github.com/linkerd/linkerd/releases)
    下载最新的 Linkerd 版本。
- en: 'Extract the tarball by executing the following command:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下命令提取 tarball：
- en: '[PRE30]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'By default, `linkerd` ships with a configuration that uses file-based service
    discovery. We''ll discuss alternatives to this approach next, but, for now, create
    a new file called `disco/media-service` with the following contents:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认情况下，`linkerd` 随附一个使用基于文件的服务的发现配置。我们将在下一节讨论此方法的替代方案，但现在，创建一个名为 `disco/media-service`
    的新文件，并包含以下内容：
- en: '[PRE31]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: This maps the hostname and port to a service called `media-service`. Linkerd
    uses this file to look up services by name and determines the hostname and port
    mappings.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将主机名和端口映射到名为 `media-service` 的服务。Linkerd 使用此文件通过名称查找服务，并确定主机名和端口的映射。
- en: 'Run Linkerd as follows:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下方式运行 Linkerd：
- en: '[PRE32]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Start the service on port `8080`. Change into the `media-service` directory
    and run the service:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在端口 `8080` 上启动服务。切换到 `media-service` 目录并运行服务：
- en: '[PRE33]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Linkerd is running on port `4140`. Test that proxying is working with the following
    request:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Linkerd 正在端口 `4140` 上运行。使用以下请求测试代理是否工作：
- en: '[PRE34]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
