- en: Chapter 4. CPU Profiling
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章。CPU性能分析
- en: Profiling is boring, but it's a good form of software analysis where you measure
    resource usage. This usage is measured over time and sometimes under specific
    workloads. Resources can mean anything the application is using, be it memory,
    disk, network, or processor. More specifically, CPU profiling allows you to analyze
    how and how much your functions use the processor. You can also analyze the opposite—the
    non-usage of the processor, or the idle time.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 性能分析可能很无聊，但它是一种很好的软件分析形式，你可以在其中测量资源使用情况。这种使用是随时间测量的，有时是在特定的工作负载下。资源可以指应用程序正在使用的任何东西，无论是内存、磁盘、网络还是处理器。更具体地说，CPU性能分析允许你分析你的函数如何以及多少使用处理器。你还可以分析相反的情况——处理器的非使用，或者空闲时间。
- en: Node.js is not primarily meant for continuous CPU-intensive tasks, and sometimes,
    for profiling, it is important to identify the methods of the intensive task that
    are holding to the processor and keeping other tasks from performing better. You
    may find huge call stacks continuously occupying the processor or repetitive and
    recursive tasks not ending as you expected. There are several techniques, such
    as splitting and scheduling tasks instead of continuously running them as they
    block the event loop.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Node.js并不主要用于连续的CPU密集型任务，有时，为了进行性能分析，重要的是要识别占用处理器的密集任务的方法，并阻止其他任务表现更好。你可能会发现持续占用处理器的大型调用堆栈，或者重复和递归任务没有如你所期望的那样结束。有几种技术，比如分割和调度任务，而不是连续运行它们，因为它们会阻塞事件循环。
- en: You may ask why these tasks are so horrible. The answer is simple; Node.js runs
    around an event loop, which means that when your code ends a specific task, the
    loop restarts and pending events get dispatched. If your code does not end, the
    rest of the application will be kept in standby until the task finishes. You need
    to be able to split a big task into smaller ones for your application to perform
    well.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这些任务如此可怕，你可能会问。答案很简单；Node.js围绕着一个事件循环运行，这意味着当你的代码结束特定任务时，循环重新启动并且待处理的事件被分发。如果你的代码没有结束，应用程序的其余部分将被保持在待机状态，直到任务完成。你需要能够将一个大任务分解成较小的任务，以使你的应用程序表现良好。
- en: The main goal of an application should be to use the least resources possible,
    so using the least processor time possible would be ideal. This is equivalent
    to be running most of the time idle in the main thread. This is when the call
    stack is the smallest possible. From a basic Node.js perspective, that should
    be level zero.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序的主要目标应该是尽可能地使用最少的资源，因此尽可能地使用最少的处理器时间将是理想的。这相当于在主线程中大部分时间处于空闲状态。这时调用堆栈是可能的最小。从基本的Node.js角度来看，应该是零级。
- en: When profiling the processor, we usually take samples of the call stack at a
    certain frequency and analyze how the stack changes (increases or decreases) over
    the sampling period. If you use profilers from the operating system, you'll have
    more items in the stack than you probably expect, as you'll get internal calls
    of Node.js and V8.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在对处理器进行性能分析时，我们通常以一定频率对调用堆栈进行采样，并分析堆栈在采样期间的变化（增加或减少）。如果你使用操作系统的分析器，你会发现堆栈中有比你预期的更多的项目，因为你会得到Node.js和V8的内部调用。
- en: 'In the chapter, the following topics will be covered:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，将涵盖以下主题：
- en: The I/O library
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: I/O库
- en: Fibonacci
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 斐波那契
- en: Flame graphs
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 火焰图
- en: Profiling alternatives
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能分析替代方案
- en: The I/O library
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: I/O库
- en: The library used by Node.js to be able to perform asynchronous I/O operations
    across multiple platform environments is **libuv**. This is an open source library.
    Actually, It is used by platforms to provide similar functionality to other languages
    such as Luvit and Lua. **Libuv** is a cross-platform library that uses the best
    possible methods for each platform to achieve the best I/O performance and still
    exposes a common API.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Node.js用于在多个平台环境中执行异步I/O操作的库是**libuv**。这是一个开源库。实际上，它被平台用来提供类似于Luvit和Lua等其他语言的功能。**Libuv**是一个跨平台库，它使用每个平台的最佳方法来实现最佳的I/O性能，并且仍然暴露一个通用的API。
- en: 'This library is responsible for network tasks (TCP and UDP sockets), DNS requests,
    filesystem operations, and much more. It''s the library that accesses files, lists
    directory contents, listens for socket connections, and executes child processes.
    The following image shows how Node.js uses V8 and libuv at the same level:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这个库负责网络任务（TCP和UDP套接字）、DNS请求、文件系统操作等等。它是访问文件、列出目录内容、监听套接字连接和执行子进程的库。下面的图片显示了Node.js如何在相同级别上使用V8和libuv：
- en: '![The I/O library](img/4183_04_01.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![I/O库](img/4183_04_01.jpg)'
- en: 'You can see that libuv does not depend on V8 to interact with I/O. It''s a
    C library with its own thread pool. This thread pool is designed to be fast and
    avoid creating and destroying task threads too often, as they''re very expensive.
    The library handles many I/O tasks from the network to the filesystem. It''s responsible
    for Node.js exposing `fs`, `net`, `dns`, and many more APIs. During an event loop,
    your code can request I/O data. This is processed, and when ready (that is, all
    or part of your request is ready for you), it triggers an event that will hopefully
    be handled in the next event loop. The following image describes how the thread
    pool works. Your code runs in the event loop (green), libuv runs in separate threads
    (blue) and triggers events to your code (orange) that get triggered before each
    cycle:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到libuv不依赖于V8来进行I/O交互。它是一个带有自己线程池的C库。这个线程池被设计得非常快速，并且尽量避免频繁创建和销毁任务线程，因为它们非常昂贵。该库处理从网络到文件系统的许多I/O任务。它负责Node.js暴露`fs`、`net`、`dns`等许多API。在事件循环期间，你的代码可以请求I/O数据。这些数据被处理，当准备就绪（也就是说，你的请求全部或部分准备好了），它会触发一个事件，希望在下一个事件循环中处理。下面的图片描述了线程池的工作原理。你的代码在事件循环中运行（绿色），libuv在单独的线程中运行（蓝色），并触发事件到你的代码（橙色），这些事件在每个周期之前被触发：
- en: '![The I/O library](img/4183_04_02.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![I/O库](img/4183_04_02.jpg)'
- en: This means that if you request a file's content and start performing a lot of
    intensive operations, it doesn't affect the file operation since it's done outside
    your scope. So, although Node.js is single threaded, there are several operations
    that are done in separate threads (from a pool). This is important to remember
    as we profile our code so as to differentiate what a Node.js bottleneck, a libuv
    (I/O) bottleneck, and just a system bottleneck are.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着如果你请求一个文件的内容并开始执行大量的密集操作，它不会影响文件操作，因为它是在你的范围之外完成的。因此，尽管Node.js是单线程的，但有一些操作是在单独的线程（来自一个池）中完成的。这对我们在对代码进行性能分析时进行区分Node.js瓶颈、libuv（I/O）瓶颈和系统瓶颈非常重要。
- en: Fibonacci
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 斐波那契
- en: 'Let''s dive into an example. Take it with a grain of salt. It''s actually a
    very common and criticized example, involving the Fibonacci sequence. Let''s create
    a simple HTTP server file called `fib.js` that will answer every request with
    a response based on the sum of the numbers of a Fibonacci sequence of a specific
    length. There are no dependencies here, just plain Node.js. Additionally, we''ll
    use the `ab` command (Apache Benchmark) to make a few requests to our server.
    If you have a Debian-based machine, you just need to install `apache2-utils` to
    be able to use this command:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入一个例子。带着一点怀疑的态度来看待它。这实际上是一个非常常见且备受批评的例子，涉及到斐波那契数列。让我们创建一个简单的HTTP服务器文件，名为`fib.js`，它将根据特定长度的斐波那契数列的数字之和来回答每个请求。这里没有依赖，只是纯粹的Node.js。此外，我们将使用`ab`命令（Apache
    Benchmark）向我们的服务器发出一些请求。如果你有一个基于Debian的机器，你只需要安装`apache2-utils`就可以使用这个命令了：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'As you can see, the `fibonacci` function is recursive (as it should be), and
    is called every time a new request comes in. It should not be a surprise to see
    that this won''t perform that well. Let''s start it and tell V8 that we want a
    profile log:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，`fibonacci`函数是递归的（应该是的），每次有新的请求进来时都会被调用。看到它表现不太好应该不会让人感到意外。让我们开始并告诉V8我们想要一个配置文件日志：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now let''s benchmark it with just 10 requests with two concurrency connections.
    The following output has been truncated for clearer understanding:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们用只有10个请求和两个并发连接的方式进行基准测试。以下输出已经被截断以便更清楚地理解：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can see that it took 2 seconds for each request (half a request per second).
    That doesn't look good, does it? Let's stop the server. You should see an `isolate*.log`
    file in the same folder. You can open it with V8 Tick Processor. There's an online
    version ([http://v8.googlecode.com/svn/trunk/tools/tick-processor.html](http://v8.googlecode.com/svn/trunk/tools/tick-processor.html)),
    if you want; or if you have the node source as I do, you will find it in `deps/v8/tools/tick-processor.html`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到每个请求花费了2秒的时间（每秒半个请求）。这看起来不太好，对吧？让我们停止服务器。你应该会在同一个文件夹中看到一个`isolate*.log`文件。你可以用V8
    Tick Processor打开它。有一个在线版本（[http://v8.googlecode.com/svn/trunk/tools/tick-processor.html](http://v8.googlecode.com/svn/trunk/tools/tick-processor.html)），如果你想要的话；或者如果你像我一样有node源码，你可以在`deps/v8/tools/tick-processor.html`中找到它。
- en: '![Fibonacci](img/4183_04_03.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![Fibonacci](img/4183_04_03.jpg)'
- en: 'Click on **Choose File** and pick your log. The tool will chew like process,
    throw like return output similar to the following. Once more, some of the output
    has been removed:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**选择文件**，选择你的日志。该工具将进行处理，返回类似以下的输出。再次强调，一些输出已被删除：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Our `fibonacci` function is really using our processor all the time. You can
    notice the recursive pattern in the `Bottom up (heavy) profile` section. You can
    see different levels (indentations) because of the recursiveness of the function.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`fibonacci`函数真的一直在使用我们的处理器。你可以在`Bottom up (heavy) profile`部分看到递归模式。你可以看到不同的级别（缩进）是因为函数的递归性。
- en: Tip
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Please note that when running your own test, you should restrict running the
    server to only the time of the benchmark (as in this example). If you leave the
    server running more than that, the use of your function will get mixed with the
    idle time.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在运行自己的测试时，应该限制服务器运行的时间只在基准测试的时间内（就像这个例子中一样）。如果让服务器运行的时间超过这个时间，你的函数的使用将会与空闲时间混合在一起。
- en: In our example, it's not easy or even better to split the code because the operation
    is really simple (adding two numbers). In other use cases, you may be able to
    optimize some operations by modifying your code using, for example, some of the
    techniques shown in [Chapter 2](ch02.html "Chapter 2. Development Patterns"),
    *Development Patterns*.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，将代码拆分并不容易，甚至不是更好的选择，因为操作非常简单（只是两个数字相加）。在其他用例中，你可能可以通过修改代码来优化一些操作，例如使用[第2章](ch02.html
    "第2章.开发模式")中展示的一些技术，*开发模式*。
- en: 'Another way of improving performance in this case is by using a technique called
    **memoizing**. What this does is wrap a function and cache its return value based
    on the arguments. This means that a function, for a specific set of parameters,
    will only be called once, and then the return value will be cached and used repeatedly.
    Of course, this does not apply to every situation. Let''s try it on our server:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下提高性能的另一种方法是使用一种称为**memoizing**的技术。它的作用是包装一个函数并根据参数缓存其返回值。这意味着对于特定的参数集，函数只会被调用一次，然后返回值将被缓存并重复使用。当然，并非所有情况都适用。让我们在服务器上尝试一下：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: There are modules that help you achieve this result. In our case, we're adding
    a `memoizing` function and actually overwriting the function with itself—`memoized`.
    This is important because the function calls itself recursively, and so it really
    needs to be overwritten.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些模块可以帮助你实现这个结果。在我们的例子中，我们添加了一个`memoizing`函数，并实际上用自身重写了这个函数—`memoized`。这很重要，因为函数会递归调用自身，所以真的需要被重写。
- en: 'This will cache every call to it, so only the first `fibonacci(40)` call will
    not use the cache. Moreover, since the function calls itself with *n-1* and *n-2*,
    half of the calls will be cached, so the first call will be even faster. Running
    an `ab` test will get you very different results:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这将缓存对它的每次调用，所以只有第一次的`fibonacci(40)`调用不会使用缓存。此外，由于函数调用自身使用*n-1*和*n-2*，一半的调用将被缓存，所以第一次调用甚至会更快。运行`ab`测试将得到非常不同的结果：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This is much better at more than 250 requests per second. This is obviously
    a bad benchmark because if you increase the number of requests to a couple of
    thousands, the number will be even better (a couple of thousands). If you use
    V8 Tick Processor, you will notice that the function call is no longer there:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这在每秒超过250个请求时要好得多。这显然是一个糟糕的基准，因为如果您将请求的数量增加到几千个，数字会更好（几千个）。如果您使用V8 Tick Processor，您会注意到函数调用不再存在：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This is obviously a bad and very simple example. Every application is different
    and analyzing it will involve knowing more about it. Using development platforms
    helps centralize your knowledge of the subject and helps you improve more easily
    overtime.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这显然是一个糟糕而非常简单的例子。每个应用程序都是不同的，分析它将涉及更多了解它。使用开发平台有助于集中您对主题的知识，并有助于您随着时间的推移更容易地改进。
- en: '![Fibonacci](img/4183_04_04.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![Fibonacci](img/4183_04_04.jpg)'
- en: Flame graphs
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 火焰图
- en: Flame graphs are a visualization technique used to profile an application and
    rapidly and more precisely spot the most frequently used functions. These graphs
    replace or complement the previous log text output, as they give a more pleasant
    and simple way of profiling.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 火焰图是一种用于对应用程序进行概要分析并快速、更精确地找出最常用函数的可视化技术。这些图形取代或补充了以前的日志文本输出，因为它们提供了一种更愉快和简单的概要分析方式。
- en: A flame graph is composed of several stacked blocks, each representing a function
    call. It usually shows usage times horizontally (not necessarily in an order).
    When a function is called by another function, the first function is displayed
    on top of the former one. Using this rule, you can figure out that the blocks
    at the top will definitely be smaller (horizontally) than the ones at the bottom.
    This creates a graph that visually resembles a flame. Moreover, the blocks normally
    use warm colors (such as red and orange), so the graph really looks like flames.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 火焰图由几个堆叠的块组成，每个块代表一个函数调用。它通常水平显示使用时间（不一定按顺序）。当一个函数被另一个函数调用时，第一个函数显示在前一个函数的顶部。使用这个规则，您可以想象出顶部的块肯定会比底部的块小（水平）。这创建了一个在视觉上类似火焰的图形。此外，这些块通常使用暖色（如红色和橙色），因此图形看起来真的像火焰。
- en: These can be used with different objectives, such as seeing memory usage and
    leaks. For example, you can create a flame graph to see how the CPU is being used
    (A busy CPU is one that is working hard, nonstop. An idle CPU is one that is doing
    nothing). Another good use is to see when your application is idle and I/O is
    very slow compared to CPU and memory, it's normal when applications block (stop)
    waiting for a file from disk or from the network. This is called off-CPU. This
    is better seen in cold colors (blue and green). A mix of the two CPU flame graphs
    can also give you a good understanding of how your application behaves.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可以用于不同的目标，比如查看内存使用和泄漏。例如，您可以创建一个火焰图来查看CPU的使用情况（繁忙的CPU是一直在工作的，空闲的CPU是什么都不做的）。另一个很好的用途是查看应用程序何时处于空闲状态，I/O与CPU和内存相比非常慢，这在应用程序阻塞（停止）等待来自磁盘或网络的文件时是正常的。这称为CPU外。这在冷色（蓝色和绿色）中更容易看到。两个CPU火焰图的混合也可以让您更好地了解应用程序的行为。
- en: 'Creating flame graphs is not easy on Node.js yet, and it depends on your system.
    Since V8 has `perf_events` support ([https://codereview.chromium.org/70013002](https://codereview.chromium.org/70013002)),
    I currently find it much easier to do it on a Linux box using the `perf` command
    and `perf_events`, but you have alternatives, such as DTrace ([http://www.brendangregg.com/flamegraphs.html](http://www.brendangregg.com/flamegraphs.html)).
    Let''s try it right now. Get yourself an Ubuntu machine (or a virtual machine)
    and install some dependencies. Note that some of them depend on your current kernel
    version:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在Node.js上创建火焰图并不容易，这取决于您的系统。由于V8支持`perf_events`（[https://codereview.chromium.org/70013002](https://codereview.chromium.org/70013002)），我发现在Linux上使用`perf`命令和`perf_events`要容易得多，但您也可以选择其他方法，比如DTrace（[http://www.brendangregg.com/flamegraphs.html](http://www.brendangregg.com/flamegraphs.html)）。让我们现在尝试一下。获取一个Ubuntu机器（或虚拟机）并安装一些依赖项。请注意，其中一些依赖于您当前的内核版本：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now let''s run our node server telling V8 that we want the `perf_events` output.
    This time, let''s run it in the background so that we can see its PID more easily,
    and run `perf` afterwards:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们运行我们的node服务器，告诉V8我们想要`perf_events`输出。这次，让我们在后台运行它，以便更容易看到其PID，并在之后运行`perf`：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'There''s the PID we need—`30462`. Then let''s run `perf` to collect events
    for about a minute. The command will not return until it finishes (listening for
    events for a minute), so you need to open another console to run the benchmark
    command:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要的PID是`30462`。然后让我们运行`perf`来收集大约一分钟的事件。该命令在完成之前不会返回（监听一分钟的事件），因此您需要打开另一个控制台来运行基准测试命令：
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We're telling perf to record events with a frequency of `99` Hz for the `30462`
    process, enabling call graphs (`-g`), and do this for `60` seconds. After that
    time, this command should end. The first version of code is so slow that will
    take longer than 60 seconds to finish so the user can stop it after a minute.
    The second version is much faster and there's no need to do it.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们告诉perf以`99` Hz的频率记录`30462`进程的事件，启用调用图（`-g`），并持续`60`秒。之后，此命令应该结束。第一个版本的代码非常慢，需要超过60秒才能完成，因此用户可以在一分钟后停止它。第二个版本要快得多，不需要这样做。
- en: 'You can look at the directory and notice that there''s a `perf.data` file.
    Now we need to tell `perf` to read this file and display the trace output. We''ll
    use it and convert it into a flame graph. For this, we''ll use a stack trace visualizer
    created by Brendan Gregg. This output will be converted into an SVG file. You
    can then open it in your favorite browser. First let''s get this stack output:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以查看目录并注意到有一个`perf.data`文件。现在我们需要告诉`perf`读取此文件并显示跟踪输出。我们将使用它并将其转换为火焰图。为此，我们将使用Brendan
    Gregg创建的堆栈跟踪可视化器。此输出将转换为SVG文件。然后您可以在您喜欢的浏览器中打开它。首先让我们获取此堆栈输出：
- en: '[PRE10]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now let''s download the stack trace visualizer and use it to convert this file.
    You''ll need `git` to get this command:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们下载堆栈跟踪可视化工具，并使用它来转换这个文件。你需要使用`git`来获取这个命令：
- en: '[PRE11]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You should now have a `stack01.svg` file that you can interact with. You can
    click on a horizontal block to zoom into that level or click on the lowest block
    to reset zoom. For the first version of your server, you should get something
    similar to this graph:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你应该有一个`stack01.svg`文件，你可以与之交互。你可以点击水平块来放大到该级别，或者点击最低的块来重置放大。对于你的服务器的第一个版本，你应该得到类似于这个图表：
- en: '![Flame graphs](img/4183_04_05.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![火焰图](img/4183_04_05.jpg)'
- en: 'You can clearly see the recursive pattern that is pushing the flames higher.
    There''s an initial big flame and there are others next to it. If you click on
    the base of the second flame, you''ll see something similar to the following:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以清楚地看到推动火焰变高的递归模式。有一个初始的大火焰，旁边还有其他火焰。如果你点击第二个火焰的底部，你会看到类似于以下的内容：
- en: '![Flame graphs](img/4183_04_06.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![火焰图](img/4183_04_06.jpg)'
- en: Now you can clearly see your processor being exhausted by this inefficient and
    recursive function. When inspecting the flame graph, take a look at the bottom
    line. It will display the information we saw in the initial outputs of the log
    processor, such as usage percentage.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以清楚地看到你的处理器被这个低效和递归的函数耗尽了。在检查火焰图时，看看底部的线条。它会显示我们在日志处理器的初始输出中看到的信息，比如使用百分比。
- en: 'If we are using the second server version, we''ll need to increase the benchmark
    load if we want to see anything useful. Try creating the flame graph for the second
    server version using the following steps:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用第二个服务器版本，如果我们想要看到有用的东西，我们需要增加基准负载。尝试使用以下步骤为第二个服务器版本创建火焰图：
- en: '[PRE12]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now open this new SVG in your browser and see how the flames are thinner. This
    means that although the stack size may be large, the duration of that stack size
    is short. Something similar to this is more normal:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在浏览器中打开这个新的SVG文件，看看火焰是不是更细了。这意味着虽然堆栈大小可能很大，但堆栈大小的持续时间很短。类似于这样的情况更正常：
- en: '![Flame graphs](img/4183_04_07.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![火焰图](img/4183_04_07.jpg)'
- en: At the bottom of the graph, you'll always see `node` or `main` as Node.js spends
    most of the time on the main thread. On top of the node or main, you'll see other
    lines. Every stacked line means a call by the line below. As you reach the top
    of the flame, you'll start seeing actual JavaScript code. You'll find many calls
    to the internal functions of Node.js related to events and the `libuv` tasks.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在图表的底部，你总是会看到`node`或`main`，因为Node.js大部分时间都在主线程上。在node或main的上面，你会看到其他线条。每一条堆叠的线条代表下面一行的调用。当你到达火焰的顶部时，你会开始看到实际的JavaScript代码。你会发现很多调用与Node.js的内部函数相关，涉及事件和`libuv`任务。
- en: Tip
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: As a rule of thumb, a flame graph with a huge and wide flame means excessive
    CPU usage. A flame graph with high but thinner flames means low CPU usage.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个经验法则，一个有着巨大而宽阔火焰的火焰图意味着CPU使用过多。一个有着高但较细火焰的火焰图意味着CPU使用较低。
- en: Profiling alternatives
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能分析的替代方案
- en: There are other alternatives for profiling your application's processor usage
    depending on the operating system. You can try DTrace if you use a supported system.
    I won't recommend using it just yet on a Linux box. Moreover, if you're not using
    an Illumos-based system, you might just forget it, at least for Node.js. Linux
    has more call stack debugging tools that you can use to log stacks and then produce
    a flame graph.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 根据操作系统，还有其他用于分析应用程序处理器使用情况的替代方案。如果你使用的是支持的系统，可以尝试使用DTrace。我不建议在Linux系统上立即使用它。此外，如果你没有使用基于Illumos的系统，至少对于Node.js来说，你可能会忘记它。Linux有更多的调用堆栈调试工具，你可以使用它们来记录堆栈，然后生成火焰图。
- en: Node.js has profiling modules and even call stack trace modules, but I recommend
    that you avoid debugging them at the language level and go for the operating system
    level. It's much faster, is less intrusive to your code, and usually gives you
    a bigger picture of the behavior, or bad behavior, that you're trying to profile.
    Remember that the system is not just your application and there can be other factors
    outside your stack scope that influence your performance.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Node.js有性能分析模块，甚至有调用堆栈跟踪模块，但我建议你避免在语言级别上调试它们，而是选择操作系统级别。这样做速度更快，对你的代码干扰更小，通常可以更全面地了解你尝试分析的行为或不良行为。记住，系统不仅仅是你的应用程序，可能还有其他因素在你的性能范围之外影响着你的性能。
- en: You can use flame graphs for other types of data. For example, you can trace
    device I/O `calls` or `syscalls`. You can filter a trace to specific function
    calls to see when and for how long a function is used. You can trace memory allocations,
    and instead of gathering allocation calls, you can gather the allocation size
    in bytes. There are many uses for this type of graph, as it can be really handy
    for visually analyzing your application behavior.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用火焰图来分析其他类型的数据。例如，你可以跟踪设备I/O调用或系统调用。你可以将跟踪结果过滤到特定的函数调用，以查看函数何时以及多长时间被使用。你可以跟踪内存分配，而不是收集分配调用，你可以收集分配大小（以字节为单位）。这种类型的图表有很多用途，因为它对于直观分析你的应用程序行为非常方便。
- en: Summary
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In environments seen nowadays, it's very important to be able to profile an
    application to identify bottlenecks, especially at the processor and memory levels.
    Systems are complex and divided into several layers, so analyzing processor usage
    using call stacks can be really hard without some tools and visualization techniques,
    such as flame graphs. Overall, you should focus on your code quality before going
    for profiling.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今的环境中，能够对应用程序进行性能分析以识别瓶颈是非常重要的，特别是在处理器和内存级别。系统是复杂的，分为几个层次，因此使用调用堆栈来分析处理器使用情况可能非常困难，如果没有一些工具和可视化技术，比如火焰图。总的来说，你应该在进行性能分析之前专注于你的代码质量。
- en: As you saw in our example, a simple and effective solution for our server was
    to cache the results. Caching is a very important technique and is usually crucial
    in balancing resource usage. Normally, you have available memory and it's better
    to cache a result for a small period of time than to process it every time, specially
    when the result is imutable.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在我们的示例中看到的，对于我们的服务器来说，一个简单而有效的解决方案是缓存结果。缓存是一种非常重要的技术，通常在平衡资源使用方面至关重要。通常情况下，您有可用的内存，最好将结果缓存一小段时间，而不是每次都处理它，特别是当结果是不可变的时候。
- en: Next, we'll look at how you should use and store your data and how, when, and
    for how long you should cache it. We'll take a look at the pros and cons of some
    cache methodologies so that you can be more prepared to choose your own path to
    making your application the most performant application possible.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看看您应该如何使用和存储数据，以及何时以及多长时间应该对其进行缓存。我们将研究一些缓存方法论的利弊，这样您就可以更好地选择自己的路径，使您的应用程序成为可能的最高性能应用程序。
- en: 'Prepared for Bentham Chang, Safari ID bentham@gmail.com User number: 2843974
    © 2015 Safari Books Online, LLC. This download file is made available for personal
    use only and is subject to the Terms of Service. Any other use requires prior
    written consent from the copyright owner. Unauthorized use, reproduction and/or
    distribution are strictly prohibited and violate applicable laws. All rights reserved.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为Bentham Chang准备，Safari ID为bentham@gmail.com 用户编号：2843974 © 2015 Safari Books
    Online，LLC。此下载文件仅供个人使用，并受到服务条款的约束。任何其他用途均需版权所有者的事先书面同意。未经授权的使用、复制和/或分发严格禁止，并违反适用法律。保留所有权利。
