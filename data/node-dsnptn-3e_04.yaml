- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Asynchronous Control Flow Patterns with Callbacks
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用回调的异步控制流模式
- en: Moving from a synchronous programming style to a platform such as Node.js, where
    **continuation-passing style** (**CPS**) and asynchronous APIs are the norm, can
    be frustrating. Asynchronous code can make it hard to predict the order in which
    statements are executed. Simple problems such as iterating over a set of files,
    executing tasks in sequence, or waiting for a set of operations to complete require
    the developer to take on new approaches and techniques just to avoid ending up
    writing inefficient and unreadable code. When using callbacks to deal with asynchronous
    control flow, the most common mistake is to fall into the trap of callback hell
    and see the code growing horizontally, rather than vertically, with a nesting
    that makes even simple routines hard to read and maintain.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 从同步编程风格迁移到Node.js这样的平台，其中**传值调用风格**（**CPS**）和异步API是常态，可能会令人沮丧。异步代码可能会使预测语句执行的顺序变得困难。简单的问题，如遍历一组文件、按顺序执行任务或等待一组操作完成，都需要开发者采用新的方法和技巧，以避免编写低效且难以阅读的代码。当使用回调处理异步控制流时，最常见的错误是陷入回调地狱的陷阱，看到代码水平增长，而不是垂直增长，这种嵌套使得即使是简单的程序也难以阅读和维护。
- en: In this chapter, you will see how it's actually possible to tame callbacks and
    write clean, manageable asynchronous code by using some discipline and with the
    aid of some patterns. Knowing how to properly deal with callbacks will pave the
    way for adopting modern approaches such as promises and async/await.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将看到如何通过一些纪律和一些模式，实际上可以驯服回调并编写干净、可管理的异步代码。知道如何正确处理回调将为采用现代方法如promises和async/await铺平道路。
- en: 'In short, in this chapter, you will learn about:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，在本章中，你将学习以下内容：
- en: The challenges of asynchronous programming.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异步编程的挑战。
- en: Avoiding callback hell and other callback best practices.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免回调地狱和其他回调最佳实践。
- en: Common asynchronous patterns such as sequential execution, sequential iteration,
    parallel execution, and limited parallel execution.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见的异步模式，如顺序执行、顺序迭代、并行执行和有限并行执行。
- en: The difficulties of asynchronous programming
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异步编程的困难之处
- en: Losing control of asynchronous code in JavaScript is undoubtedly easy. Closures
    and in-place definitions of anonymous functions allow for a smooth programming
    experience that doesn't require the developer to jump to other points in the codebase.
    This is perfectly in line with the **KISS** principle (**Keep It Simple, Stupid**);
    it's simple, it keeps the code flowing, and we get it working in less time. Unfortunately,
    sacrificing qualities such as modularity, reusability, and maintainability will,
    sooner or later, lead to the uncontrolled proliferation of callback nesting, functions
    growing in size, and poor code organization. Most of the time, creating callbacks
    as in-place functions is not strictly required, so it's more a matter of discipline
    than a problem related to asynchronous programming. Recognizing that our code
    is becoming unwieldy or, even better, knowing in advance that it might become
    unwieldy and then acting accordingly with the most adequate solution, is what
    differentiates a novice from an expert.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在JavaScript中失去对异步代码的控制无疑是容易的。闭包和匿名函数的现场定义允许开发者拥有流畅的编程体验，无需在代码库的其他点跳转。这完全符合**KISS**原则（**Keep
    It Simple, Stupid**）；它简单，保持了代码的流畅性，并且我们能在更短的时间内完成任务。不幸的是，牺牲诸如模块化、可重用性和可维护性等品质，迟早会导致回调嵌套的无序增长、函数尺寸的增大和代码组织不良。大多数情况下，创建现场函数作为回调并不是严格必要的，所以这更多是一个纪律问题，而不是与异步编程相关的问题。认识到我们的代码变得难以管理，或者更好的是，事先知道它可能会变得难以管理，然后采取最合适的解决方案，这是新手和专家之间的区别。
- en: Creating a simple web spider
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建一个简单的网络爬虫
- en: 'To explain this problem, we will create a little web spider, a command-line
    application that takes in a web URL as input and downloads its contents locally
    into a file. In the code presented in this chapter, we are going to use a couple
    of npm dependencies:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解释这个问题，我们将创建一个小型的网络爬虫，这是一个命令行应用程序，它接受一个网页URL作为输入，并将其内容下载到本地文件中。在本章展示的代码中，我们将使用几个npm依赖项：
- en: '`superagent`: A library to streamline HTTP calls ([nodejsdp.link/superagent](http://nodejsdp.link/superagent))'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`superagent`：一个用于简化HTTP调用的库 ([nodejsdp.link/superagent](http://nodejsdp.link/superagent))'
- en: '`mkdirp`: A small utility to create directories recursively ([nodejsdp.link/mkdirp](http://nodejsdp.link/mkdirp))'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mkdirp`：一个用于递归创建目录的小工具 ([nodejsdp.link/mkdirp](http://nodejsdp.link/mkdirp))'
- en: Also, we will often refer to a local module named `./utils.js`, which contains
    some helpers that we will be using in our application. We will omit the contents
    of this file for brevity, but you can find the full implementation, along with
    a `package.json` file containing the full list of dependencies, in the official
    repository at [nodejsdp.link/repo](http://nodejsdp.link/repo).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还将经常提到一个名为`./utils.js`的本地模块，它包含我们将要在应用程序中使用的一些辅助工具。为了简洁起见，我们将省略此文件的详细内容，但你可以在官方仓库中找到完整的实现，以及包含完整依赖列表的`package.json`文件，网址为[nodejsdp.link/repo](http://nodejsdp.link/repo)。
- en: 'The core functionality of our application is contained inside a module named `spider.js`.
    Let''s see how it looks. To start with, let''s load all the dependencies that
    we are going to use:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用程序的核心功能包含在一个名为`spider.js`的模块中。让我们看看它的样子。首先，让我们加载所有将要使用的依赖项：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, let''s create a new function named `spider()`, which takes in the URL
    to download and a callback function that will be invoked when the download process
    completes:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们创建一个名为`spider()`的新函数，它接受要下载的URL和一个在下载过程完成后将被调用的回调函数：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'There is a lot going on here, so let''s discuss in more detail what happens
    in every step:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有很多事情在进行中，所以让我们更详细地讨论每一步发生的情况：
- en: 'The code checks whether the URL was already downloaded by verifying that the
    corresponding file was not already created. If `err` is defined and has type `ENOENT`,
    then the file does not exist and it''s safe to create it:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码检查URL是否已经被下载，通过验证相应的文件是否尚未创建。如果`err`已定义且类型为`ENOENT`，则文件不存在，可以安全地创建它：
- en: '[PRE2]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If the file is not found, the URL is downloaded using the following line of
    code:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果找不到文件，将使用以下代码行下载URL：
- en: '[PRE3]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, we make sure that the directory that will contain the file exists:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们确保将要包含文件的目录存在：
- en: '[PRE4]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, we write the body of the HTTP response to the filesystem:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将HTTP响应体写入文件系统：
- en: '[PRE5]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To complete our web spider application, we just need to invoke the `spider()` function
    by providing a URL as an input (in our case, we read it from the command-line
    arguments). The `spider()` function is exported from the file we defined previously.
    Let''s now create a new file called `spider-cli.js` that can be directly invoked
    from the command line:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成我们的网页爬虫应用程序，我们只需要提供一个URL作为输入来调用`spider()`函数（在我们的例子中，我们从命令行参数中读取它）。`spider()`函数是从我们之前定义的文件中导出的。现在，让我们创建一个名为`spider-cli.js`的新文件，该文件可以从命令行直接调用：
- en: '[PRE6]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, we are ready to try our web spider application, but first, make sure you
    have the `utils.js` module and the `package.json` file containing the full list
    of dependencies in your `project` directory. Then, install all the dependencies
    by running the following command:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好尝试我们的网页爬虫应用程序，但首先，请确保你已经在`project`目录中有了`utils.js`模块和包含完整依赖列表的`package.json`文件。然后，通过运行以下命令安装所有依赖项：
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, let''s execute the `spider-cli.js` module to download the contents of
    a web page with a command like this:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们执行`spider-cli.js`模块，使用如下命令下载网页内容：
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Our web spider application requires that we always include the protocol (for
    example, `http://`) in the URL we provide. Also, do not expect HTML links to be
    rewritten or resources such as images to be downloaded, as this is just a simple
    example to demonstrate how asynchronous programming works.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的网页爬虫应用程序要求我们始终在提供的URL中包含协议（例如，`http://`）。此外，不要期望HTML链接会被重写或资源（如图片）会被下载，因为这只是一个简单的示例，用于演示异步编程的工作原理。
- en: In the next section, you will learn how to improve the readability of this code
    and, in general, how to keep callback-based code as clean and readable as possible.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将学习如何提高代码的可读性，以及通常如何使基于回调的代码尽可能干净和易于阅读。
- en: Callback hell
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回调地狱
- en: Looking at the `spider()` function we defined earlier, you will likely notice
    that even though the algorithm we implemented is really straightforward, the resulting
    code has several levels of indentation and is very hard to read. Implementing
    a similar function with a direct style blocking API would be straightforward,
    and most likely, the code would be much more readable. However, using asynchronous
    CPS is another story, and making bad use of in-place callback definitions can
    lead to incredibly bad code.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 看看我们之前定义的`spider()`函数，你可能会注意到，尽管我们实现的算法非常直接，但生成的代码有多个缩进级别，非常难以阅读。使用直接风格的阻塞API实现类似的函数将是直接的，而且代码很可能更容易阅读。然而，使用异步CPS则是另一回事，不当使用原地回调定义可能会导致极其糟糕的代码。
- en: 'The situation where the abundance of closures and in-place callback definitions
    transforms the code into an unreadable and unmanageable blob is known as **callback
    hell**. It''s one of the most widely recognized and severe anti-patterns in Node.js
    and JavaScript in general. The typical structure of code affected by this problem
    looks as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当闭包和原地回调定义的过度使用将代码变成难以阅读和管理的大块时，这种情况被称为“回调地狱”。这是Node.js和JavaScript中广泛认可且最严重的反模式之一。受此问题影响的代码的典型结构如下：
- en: '[PRE9]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You can see how code written in this way assumes the shape of a pyramid due
    to deep nesting, and that's why it is also colloquially known as the **pyramid
    of doom**.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，以这种方式编写的代码由于深层次的嵌套而呈现出金字塔形状，这也是为什么它也被俗称为“末日金字塔”。
- en: The most evident problem with code such as the preceding snippet is its poor
    readability. Due to the nesting being so deep, it's almost impossible to keep
    track of where a function ends and where another one begins.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 前述代码片段中最明显的问题是它的可读性差。由于嵌套太深，几乎不可能跟踪函数的结束和开始。
- en: Another issue is caused by the overlapping of the variable names used in each
    scope. Often, we have to use similar or even identical names to describe the content
    of a variable. The best example is the error argument received by each callback.
    Some people often try to use variations of the same name to differentiate the
    object in each scope, for example, `err`, `error`, `err1`, `err2`, and so on.
    Others prefer to just shadow the variable defined in the upper scope by always
    using the same name, for example, `err`. Both alternatives are far from perfect,
    and cause confusion and increase the probability of introducing defects.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是由每个作用域中使用的变量名重叠引起的。通常，我们必须使用相似甚至相同的名称来描述变量的内容。最好的例子是每个回调接收到的错误参数。有些人经常尝试使用同一名称的不同变体来区分每个作用域中的对象，例如，`err`、`error`、`err1`、`err2`等等。其他人则更喜欢通过始终使用相同的名称来隐藏上层作用域中定义的变量，例如，`err`。这两种选择都远非完美，会导致混淆并增加引入缺陷的可能性。
- en: Also, we have to keep in mind that closures come at a small price in terms of
    performance and memory consumption. In addition, they can create memory leaks
    that are not very easy to identify. In fact, we shouldn't forget that any context
    referenced by an active closure is retained from garbage collection.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还需要记住，闭包在性能和内存消耗方面会付出一定的代价。此外，它们可能会创建不易识别的内存泄漏。实际上，我们不应该忘记，任何由活动闭包引用的上下文都会被垃圾回收保留。
- en: For a great introduction to how closures work in V8, you can refer to the following
    blog post by Vyacheslav Egorov, a software engineer at Google working on V8, which
    you can read at [nodejsdp.link/v8-closures](http://nodejsdp.link/v8-closures).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于V8中闭包如何工作的详细介绍，你可以参考Google V8工程师Vyacheslav Egorov撰写的一篇博客文章，你可以在这里阅读：[nodejsdp.link/v8-closures](http://nodejsdp.link/v8-closures)。
- en: If you look at our `spider()` function, you will notice that it clearly represents
    a callback hell situation and has all the problems just described. That's exactly
    what we are going to fix with the patterns and techniques that are covered in
    the following sections of this chapter.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你看看我们定义的`spider()`函数，你会注意到它清楚地代表了一个回调地狱的情况，并且具有前面描述的所有问题。这正是我们将在本章后续部分介绍的模式和技巧要解决的问题。
- en: Callback best practices and control flow patterns
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回调最佳实践和控制流模式
- en: Now that you have met your first example of callback hell, you know what you
    should definitely avoid; however, that's not the only concern when writing asynchronous
    code. In fact, there are several situations where controlling the flow of a set
    of asynchronous tasks requires the use of specific patterns and techniques, especially
    if we are only using plain JavaScript without the aid of any external library.
    For example, iterating over a collection by applying an asynchronous operation
    in sequence is not as easy as invoking `forEach()` over an array; it actually
    requires a technique similar to recursion.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经遇到了回调地狱的第一个例子，你知道你绝对应该避免什么；然而，在编写异步代码时，这并不是唯一的问题。事实上，有几个情况需要使用特定的模式和技巧来控制一系列异步任务，特别是如果我们只使用纯JavaScript而不借助任何外部库。例如，通过按顺序应用异步操作来迭代一个集合并不像在数组上调用`forEach()`那样简单；实际上，它需要一个类似于递归的技术。
- en: In this section, you will learn not only about how to avoid callback hell, but
    also how to implement some of the most common control flow patterns, using only
    simple and plain JavaScript.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你不仅将学习如何避免回调地狱，还将学习如何仅使用简单和纯JavaScript实现一些最常见的控制流模式。
- en: Callback discipline
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回调纪律
- en: When writing asynchronous code, the first rule to keep in mind is to not abuse
    in-place function definitions when defining callbacks. It can be tempting to do
    so, because it does not require any additional thinking for problems such as modularization
    and reusability; however, you have seen how this can have more disadvantages than
    advantages. Most of the time, fixing the callback hell problem does not require
    any libraries, fancy techniques, or changes of paradigm; you just need some common
    sense.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写异步代码时，要记住的第一条规则是在定义回调时不要滥用原地函数定义。这样做可能很有吸引力，因为它不需要额外的思考来解决模块化和重用等问题；然而，你已经看到了这可能会带来比优势更多的缺点。大多数时候，修复回调地狱问题不需要任何库、花哨的技术或范式转变；你只需要一些常识。
- en: 'These are some basic principles that can help us keep the nesting level low
    and improve the organization of our code in general:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是一些基本的原则，可以帮助我们降低嵌套级别，并总体上提高我们代码的组织性：
- en: Exit as soon as possible. Use `return`, `continue`, or `break`, depending on
    the context, to immediately exit the current statement instead of writing (and nesting)
    complete `if...else` statements. This will help to keep our code shallow.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽快退出。根据上下文，使用`return`、`continue`或`break`立即退出当前语句，而不是编写（和嵌套）完整的`if...else`语句。这将有助于保持我们的代码浅层。
- en: Create named functions for callbacks, keeping them out of closures and passing
    intermediate results as arguments. Naming our functions will also make them look
    better in stack traces.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为回调创建命名函数，将它们从闭包中分离出来，并将中间结果作为参数传递。命名我们的函数也将使它们在堆栈跟踪中看起来更好。
- en: Modularize the code. Split the code into smaller, reusable functions whenever
    possible.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模块化代码。尽可能将代码拆分为更小、可重用的函数。
- en: Now, let's put these principles into practice.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将这些原则付诸实践。
- en: Applying the callback discipline
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用回调纪律
- en: To demonstrate the power of the ideas mentioned in the previous section, let's
    apply them to fix the callback hell in our web spider application.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示上一节中提到的想法的力量，让我们将它们应用到修复我们的网络爬虫应用程序中的回调地狱。
- en: 'For the first step, we can refactor our error-checking pattern by removing
    the `else` statement. This is made possible by returning from the function immediately
    after we receive an error. So, instead of having code such as the following:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一步，我们可以通过在收到错误后立即从函数返回来重构我们的错误检查模式，移除`else`语句。这使得成为可能，因此，而不是有如下代码：
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can improve the organization of our code by writing the following instead:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过编写以下内容来改进我们代码的组织性：
- en: '[PRE11]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This is often referred to as the **early return principle**. With this simple
    trick, we immediately have a reduction in the nesting level of our functions.
    It is easy and doesn't require any complex refactoring.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常被称为**早期返回原则**。通过这个简单的技巧，我们立即降低了函数的嵌套级别。这很容易，而且不需要任何复杂的重构。
- en: 'A common mistake when executing the optimization just described is forgetting
    to terminate the function after the callback is invoked. For an error-handling
    scenario, the following code is a typical source of defects:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行上述优化时，一个常见的错误是忘记在回调调用后终止函数。对于错误处理场景，以下代码是典型的缺陷来源：
- en: '[PRE12]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We should never forget that the execution of our function will continue even
    after we invoke the callback. It is then important to insert a `return` instruction
    to block the execution of the rest of the function. Also, note that it doesn''t
    really matter what value is returned by the function; the real result (or error)
    is produced asynchronously and passed to the callback. The return value of the
    asynchronous function is usually ignored. This property allows us to write shortcuts
    such as the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们永远不应该忘记，即使我们调用了回调，函数的执行也会继续。因此，插入一个`return`指令来阻止函数其余部分的执行是很重要的。此外，请注意，函数返回的值实际上并不重要；真正的结果（或错误）是异步产生的，并通过回调传递。异步函数的返回值通常被忽略。这个特性允许我们编写如下简短的代码：
- en: '[PRE13]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Otherwise, we''d have to write slightly more verbose code, such as the following:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，我们不得不编写稍微冗长的代码，如下所示：
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'As a second optimization for our `spider()` function, we can try to identify
    reusable pieces of code. For example, the functionality that writes a given string
    to a file can be easily factored out into a separate function, as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 作为对`spider()`函数的第二次优化，我们可以尝试识别可重用的代码片段。例如，将给定的字符串写入文件的功能可以很容易地分解成一个单独的函数，如下所示：
- en: '[PRE15]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Following the same principle, we can create a generic function named `download()` that
    takes a URL and a filename as input, and downloads the URL into the given file.
    Internally, we can use the `saveFile()` function we created earlier:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 按照同样的原则，我们可以创建一个名为`download()`的通用函数，它接受一个URL和一个文件名作为输入，并将URL下载到指定的文件中。内部，我们可以使用我们之前创建的`saveFile()`函数：
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'For the last step, we modify the `spider()` function, which, thanks to our
    changes, will now look like the following:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对于最后一步，我们修改了`spider()`函数，由于我们的改动，它现在看起来如下所示：
- en: '[PRE17]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The functionality and the interface of the `spider()` function remained exactly
    the same; what changed was the way the code was organized. One important detail
    to notice (1) is that we inverted the check for the file's existence so that we
    could apply the *early return principle* discussed previously.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`spider()`函数的功能和接口保持完全相同；改变的是代码的组织方式。一个重要的细节（1）是我们反转了对文件存在性的检查，这样我们就可以应用之前讨论过的*早期返回原则*。'
- en: By applying the early return principle and the other callback discipline principles,
    we were able to drastically reduce the nesting of our code and, at the same time,
    increase its reusability and testability. In fact, we could think about exporting
    both `saveFile()` and `download()` so that we could reuse them in other modules.
    This would also allow us to test their functionality as independent units.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通过应用早期返回原则和其他回调纪律原则，我们能够极大地减少代码的嵌套，同时提高其可重用性和可测试性。实际上，我们可以考虑导出`saveFile()`和`download()`，这样我们就可以在其他模块中重用它们。这也会允许我们测试它们作为独立单元的功能性。
- en: The refactoring we carried out in this section clearly demonstrates that most
    of the time, all we need is some discipline to make sure we do not abuse closures
    and anonymous functions. It works brilliantly, requires minimal effort, and it
    doesn't require external libraries.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中我们进行的重构清楚地表明，大多数情况下，我们只需要一些纪律来确保我们不会滥用闭包和匿名函数。它工作得非常出色，需要最小的努力，并且不需要外部库。
- en: Now that you know how to write clean asynchronous code using callbacks, we are
    ready to explore some of the most common asynchronous patterns, such as sequential
    and parallel execution.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了如何使用回调编写干净的异步代码，我们准备探索一些最常见的异步模式，例如顺序和并行执行。
- en: Sequential execution
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 顺序执行
- en: In this section, we will look at asynchronous control flow patterns and start
    by analyzing the sequential execution flow.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨异步控制流模式，并首先分析顺序执行流程。
- en: 'Executing a set of tasks in sequence means running them one at a time, one
    after the other. The order of execution matters and must be preserved, because
    the result of a task in the list may affect the execution of the next. *Figure
    4.1* illustrates this concept:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 按顺序执行一组任务意味着一次运行一个任务，一个接一个。执行顺序很重要，必须保持不变，因为列表中某个任务的执行结果可能会影响下一个任务的执行。*图4.1*展示了这个概念：
- en: '![](img/B15729_04_01.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B15729_04_01.png)'
- en: 'Figure 4.1: An example of sequential execution flow with three tasks'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1：三个任务的顺序执行流程示例
- en: 'There are different variations of this flow:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这个流程有几种不同的变体：
- en: Executing a set of known tasks in sequence, without propagating data across
    them.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按顺序执行一组已知任务，不在这组任务之间传递数据。
- en: Using the output of a task as the input for the next (also known as *chain*, *pipeline*,
    or *waterfall*).
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用任务的输出作为下一个任务的输入（也称为*链*、*管道*或*瀑布*）。
- en: Iterating over a collection while running an asynchronous task on each element,
    one after the other.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在运行异步任务的同时遍历集合。
- en: Sequential execution, despite being trivial when implemented using a direct
    style blocking API, is usually the main cause of the callback hell problem when
    using asynchronous CPS.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在直接风格阻塞API实现时很 trivial，但在使用异步CPS时，顺序执行通常是回调地狱问题的主要原因。
- en: Executing a known set of tasks in sequence
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 按顺序执行一组已知任务
- en: 'We already looked at a sequential execution flow while implementing the `spider()` function
    in the previous section. By applying some simple rules, we were able to organize
    a set of known tasks in a sequential execution flow. Taking that code as a guideline,
    we can now generalize the solution with the following pattern:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一节中实现 `spider()` 函数时已经看到了顺序执行流程。通过应用一些简单的规则，我们能够将一组已知任务组织成顺序执行流程。以那段代码为指南，我们现在可以用以下模式来概括解决方案：
- en: '[PRE18]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The preceding pattern shows how each task invokes the next upon completion of
    a generic asynchronous operation. The pattern puts the emphasis on the modularization
    of tasks, showing how closures are not always necessary to handle asynchronous
    code.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的模式展示了每个任务如何在通用异步操作完成后调用下一个任务。该模式强调任务的模块化，展示了闭包并不总是处理异步代码所必需的。
- en: Sequential iteration
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 顺序迭代
- en: The pattern described in the previous section works perfectly if we know in
    advance what and how many tasks are to be executed. This allows us to hardcode
    the invocation of the next task in the sequence, but what happens if we want to
    execute an asynchronous operation for each item in a collection? In cases such
    as this, we can't hardcode the task sequence anymore; instead, we have to build
    it dynamically.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节中描述的模式，如果我们事先知道要执行什么任务以及要执行多少任务，则工作得非常好。这允许我们硬编码序列中下一个任务的调用，但如果我们想对集合中的每个项目执行异步操作，会发生什么？在这种情况下，我们不能再硬编码任务序列；相反，我们必须动态构建它。
- en: Web spider version 2
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Web spider 版本 2
- en: To show an example of sequential iteration, let's introduce a new feature to
    the web spider application. We now want to download all the links contained in
    a web page recursively. To do that, we are going to extract all the links from
    the page and then trigger our web spider on each recursively and in sequence.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示顺序迭代的例子，让我们向 web spider 应用程序引入一个新功能。我们现在想要递归地下载网页中包含的所有链接。为此，我们将从页面中提取所有链接，然后依次递归地触发我们的
    web spider。
- en: The first step is modifying our `spider()` function so that it triggers a recursive
    download of all the links of a page by using a function named `spiderLinks()`,
    which we are going to create shortly.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是修改我们的 `spider()` 函数，使其通过使用我们即将创建的 `spiderLinks()` 函数来触发页面上所有链接的递归下载。
- en: 'Also, instead of checking whether the file already exists, we will try to read
    it and start spidering its links. This way, we will be able to resume interrupted downloads.
    As a final change, we need to make sure we propagate a new parameter, `nesting`,
    which will help us to limit the recursion depth. The code is as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们不再检查文件是否已存在，而是尝试读取它并开始爬取其链接。这样，我们就能恢复中断的下载。作为最后的更改，我们需要确保传播一个新的参数 `nesting`，这将帮助我们限制递归深度。代码如下：
- en: '[PRE19]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: In the next section, we will explore how the `spiderLinks()` function can be
    implemented.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨如何实现 `spiderLinks()` 函数。
- en: Sequential crawling of links
  id: totrans-101
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 链接的顺序抓取
- en: 'Now, we can create the core of this new version of our web spider application,
    the `spiderLinks()` function, which downloads all the links of an HTML page using
    a sequential asynchronous iteration algorithm. Pay attention to the way we are
    going to define that in the following code block:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以创建这个新版本的 web spider 应用程序的核心，即 `spiderLinks()` 函数，它使用顺序异步迭代算法下载 HTML 页面上的所有链接。请注意我们将在以下代码块中定义的方式：
- en: '[PRE20]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The important steps to understand from this new function are as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个新功能中需要理解的重要步骤如下：
- en: We obtain the list of all the links contained in the page using the `getPageLinks()` function.
    This function returns only the links pointing to an internal destination (the
    same hostname).
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 `getPageLinks()` 函数获取页面中包含的所有链接列表。此函数仅返回指向内部目标（同一主机名）的链接。
- en: We iterate over the links using a local function called `iterate()`, which takes
    the `index` of the next link to analyze. In this function, the first thing we
    do is check whether the `index` is equal to the length of the `links` array, in
    which case we immediately invoke the `cb()` function, as it means we have processed
    all the items.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用一个名为 `iterate()` 的本地函数遍历链接，该函数接受要分析的下一个链接的 `index`。在这个函数中，我们首先做的事情是检查 `index`
    是否等于 `links` 数组的长度，如果是这样，我们就立即调用 `cb()` 函数，因为这表示我们已经处理了所有项目。
- en: At this point, everything should be ready for processing the link. We invoke
    the `spider()` function by decreasing the nesting level and invoking the next
    step of the iteration when the operation completes.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 到这一点，一切应该都准备好处理链接了。我们通过减少嵌套级别并在操作完成后调用迭代的下一步来调用 `spider()` 函数。
- en: As the last step in the `spiderLinks()` function, we bootstrap the iteration
    by invoking `iterate(0)`.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `spiderLinks()` 函数的最后一步，我们通过调用 `iterate(0)` 来引导迭代。
- en: The algorithm that was just presented allows us to iterate over an array by
    executing an asynchronous operation in sequence, which in our case is the `spider()` function.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 刚才提出的算法允许我们通过执行异步操作按顺序遍历数组，在我们的例子中是 `spider()` 函数。
- en: 'Finally, we can change our `spider-cli.js` a bit so that we can specify the
    nesting level as an additional command-line interface (CLI) argument:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以稍微修改一下我们的 `spider-cli.js`，以便我们可以将嵌套级别作为额外的命令行界面（CLI）参数指定：
- en: '[PRE21]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We can now try this new version of the spider application and watch it download
    all the links of a web page recursively, one after the other. To interrupt the
    process, which can take a while if there are many links, remember that we can
    always use Ctrl + C. If we then decide to resume it, we can do so by launching
    the spider application and providing the same URL we used for the first run.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以尝试这个蜘蛛应用程序的新版本，并观察它递归地下载网页上的所有链接，一个接一个。要中断这个过程，如果有很多链接，这个过程可能会持续一段时间，请记住我们始终可以使用 Ctrl + C。如果我们决定继续，我们可以通过启动蜘蛛应用程序并使用与第一次运行相同的URL来实现。
- en: Now that our web spider application can potentially trigger the download of
    an entire website, please consider using it carefully. For example, do not set
    a high nesting level or leave the spider running for more than a few seconds.
    It is not polite to overload a server with thousands of requests. In some circumstances,
    this can also be considered illegal. Spider responsibly!
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们的网络蜘蛛应用程序有可能触发整个网站的下载，请谨慎使用。例如，不要设置过高的嵌套级别，或者让蜘蛛运行超过几秒钟。用数千个请求压垮服务器是不礼貌的。在某些情况下，这也可能被视为非法。负责任地使用蜘蛛！
- en: The pattern
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模式
- en: 'The code of the `spiderLinks()` function from the previous section is a clear
    example of how it''s possible to iterate over a collection while applying an asynchronous
    operation. You may also notice that it''s a pattern that can be adapted to any
    other situation where we need to iterate asynchronously over the elements of a
    collection or, in general, over a list of tasks. This pattern can be generalized
    as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个部分中 `spiderLinks()` 函数的代码是展示如何遍历集合同时应用异步操作的一个清晰的例子。你也许还会注意到，这是一个可以适应任何其他需要异步遍历集合元素或，更一般地说，遍历任务列表的情况的模式。这个模式可以概括如下：
- en: '[PRE22]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: It's important to notice that these types of algorithms become really recursive
    if `task()` is a synchronous operation. In such a case, the stack will not unwind
    at every cycle and there might be a risk of hitting the maximum call stack size
    limit.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，如果 `task()` 是一个同步操作，这些类型的算法会变得非常递归。在这种情况下，栈不会在每次循环中展开，可能会达到最大调用栈大小限制的风险。
- en: 'The pattern that was just presented is very powerful and can be extended or
    adapted to address several common needs. Just to mention some examples:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 刚才提出的模式非常强大，可以扩展或适应以解决几个常见需求。仅举一些例子：
- en: We can map the values of an array asynchronously.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以异步地将数组的值映射到另一个数组。
- en: We can pass the results of an operation to the next one in the iteration to
    implement an asynchronous version of the `reduce` algorithm.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以将操作的结果传递给迭代中的下一个操作，以实现 `reduce` 算法的异步版本。
- en: We can quit the loop prematurely if a particular condition is met (asynchronous
    implementation of the `Array.some()` helper).
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果满足特定条件，我们可以提前退出循环（`Array.some()` 助手的异步实现）。
- en: We can even iterate over an infinite number of elements.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们甚至可以遍历无限数量的元素。
- en: 'We could also choose to generalize the solution even further by wrapping it
    in a function with a signature such as the following:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以选择通过一个具有如下签名的函数进一步泛化解决方案：
- en: '[PRE23]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Here, `collection` is the actual dataset you want to iterate over, `iteratorCallback`
    is the function to execute over every item, and `finalCallback` is the function
    that gets executed when all the items are processed or in case of an error. The
    implementation of this helper function is left to you as an exercise.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`collection` 是你想要迭代的实际数据集，`iteratorCallback` 是要执行每个项目的函数，而 `finalCallback`
    是在所有项目处理完毕或发生错误时执行的函数。这个辅助函数的实现留给你作为练习。
- en: '**The Sequential Iterator pattern**'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**顺序迭代器模式**'
- en: Execute a list of tasks in sequence by creating a function named `iterator`,
    which invokes the next available task in the collection and makes sure to invoke
    the next step of the iteration when the current task completes.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 通过创建一个名为 `iterator` 的函数来按顺序执行一系列任务，该函数调用集合中下一个可用的任务，并在当前任务完成后确保调用迭代的下一步。
- en: In the next section, we will explore the parallel execution pattern, which is
    more convenient when the order of the various tasks is not important.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨并行执行模式，当各种任务的顺序不重要时，这种模式更方便。
- en: Parallel execution
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行执行
- en: 'There are some situations where the order of execution of a set of asynchronous
    tasks is not important, and all we want is to be notified when all those running
    tasks are completed. Such situations are better handled using a parallel execution flow,
    as shown in *Figure 4.2*:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些情况下，一组异步任务的执行顺序并不重要，我们只想在所有运行的任务完成时得到通知。这种情况下，使用并行执行流程处理会更好，如图 *图 4.2* 所示：
- en: '![](img/B15729_04_02.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15729_04_02.png)'
- en: 'Figure 4.2: An example of parallel execution with three tasks'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2：三个任务并行执行的示例
- en: This may sound strange if you consider that Node.js is single-threaded, but
    if you remember what we discussed in *Chapter 1*, *The Node.js Platform*, you'll
    realize that even though we have just one thread, we can still achieve concurrency,
    thanks to the non-blocking nature of Node.js. In fact, the word *parallel* is
    used improperly in this case, as it does not mean that the tasks run simultaneously,
    but rather that their execution is carried out by an underlying, non-blocking
    API and interleaved by the event loop.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你考虑到 Node.js 是单线程的，这可能会听起来很奇怪，但如果你记得我们在 *第 1 章* 中讨论的 *Node.js 平台*，你就会意识到尽管我们只有一个线程，但我们可以通过
    Node.js 的非阻塞特性来实现并发。实际上，在这个情况下，使用 *并行* 这个词是不恰当的，因为它并不意味着任务是同时运行的，而是它们的执行是由一个底层的非阻塞
    API 执行的，并且通过事件循环进行交错。
- en: As you know, a task gives control back to the event loop when it requests a
    new asynchronous operation, allowing the event loop to execute another task. The
    proper word to use for this kind of flow is *concurrency*, but we will still use
    parallel for simplicity.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，当任务请求新的异步操作时，它会将控制权交还给事件循环，允许事件循环执行另一个任务。这种流程的正确词是 *并发*，但为了简单起见，我们仍然使用并行。
- en: 'The following diagram shows how two asynchronous tasks can run in parallel in
    a Node.js program:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 **图** 展示了两个异步任务如何在 Node.js 程序中并行运行：
- en: '![](img/B15729_04_03.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15729_04_03.png)'
- en: 'Figure 4.3: An example of how asynchronous tasks run in parallel'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3：异步任务并行运行的示例
- en: 'In *Figure 4.3*, we have a **Main** function that executes two asynchronous
    tasks:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 4.3* 中，我们有一个执行两个异步任务的 **Main** 函数：
- en: The **Main** function triggers the execution of **Task 1** and **Task 2**. As
    they trigger an asynchronous operation, they immediately return control back to
    the **Main** function, which then returns it to the event loop.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Main** 函数触发 **Task 1** 和 **Task 2** 的执行。由于它们触发了异步操作，它们立即将控制权交还给 **Main**
    函数，然后 **Main** 函数再将控制权交还给事件循环。'
- en: When the asynchronous operation of **Task 1** is completed, the event loop gives
    control to it. When **Task 1** completes its internal synchronous processing as
    well, it notifies the **Main** function.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当 **Task 1** 的异步操作完成时，事件循环将其控制权交还给它。当 **Task 1** 完成其内部同步处理时，它通知 **Main** 函数。
- en: When the asynchronous operation triggered by **Task 2** is complete, the event
    loop invokes its callback, giving control back to **Task 2**. At the end of **Task
    2**, the **Main** function is notified once more. At this point, the **Main** function
    knows that both **Task 1** and **Task 2** are complete, so it can continue its
    execution or return the results of the operations to another callback.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当由**任务2**触发的异步操作完成时，事件循环调用其回调，将控制权交回**任务2**。在**任务2**结束时，**主**函数再次被通知。此时，**主**函数知道**任务1**和**任务2**都已完成，因此它可以继续执行或返回操作的成果给另一个回调。
- en: In short, this means that in Node.js, we can only execute asynchronous operations
    in parallel, because their concurrency is handled internally by the non-blocking
    APIs. In Node.js, synchronous (blocking) operations can't run concurrently unless
    their execution is interleaved with an asynchronous operation, or interleaved
    with `setTimeout()` or `setImmediate()`. You will see this in more detail in *Chapter 11*, *Advanced
    Recipes*.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，这意味着在Node.js中，我们只能并行执行异步操作，因为它们的并发性是由非阻塞API内部处理的。在Node.js中，同步（阻塞）操作不能并发运行，除非它们的执行与异步操作交织，或者与`setTimeout()`或`setImmediate()`交织。你将在*第11章*，*高级技巧*中看到更多细节。
- en: Web spider version 3
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Web蜘蛛版本 3
- en: Our web spider application seems like a perfect candidate to apply the concept
    of parallel execution. So far, our application is executing the recursive download
    of the linked pages in a sequential fashion. We can easily improve the performance
    of this process by downloading all the linked pages in parallel.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的Web蜘蛛应用程序似乎是应用并行执行概念的完美候选者。到目前为止，我们的应用程序是以顺序方式执行链接页面的递归下载。我们可以通过并行下载所有链接页面来轻松提高此过程的速度。
- en: 'To do that, we just need to modify the `spiderLinks()` function to make sure
    we spawn all the `spider()` tasks at once, and then invoke the final callback
    only when all of them have completed their execution. So, let''s modify our `spiderLinks()` function
    as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，我们只需要修改`spiderLinks()`函数，确保我们一次性启动所有`spider()`任务，然后在所有任务都完成执行后调用最终回调。所以，让我们按照以下方式修改我们的`spiderLinks()`函数：
- en: '[PRE24]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let''s discuss what we changed. As mentioned earlier, the `spider()` tasks
    are now started all at once. This is possible by simply iterating over the `links`
    array and starting each task without waiting for the previous one to finish:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一下我们做了什么改变。如前所述，`spider()`任务现在同时启动。这可以通过简单地遍历`links`数组并启动每个任务而不等待前一个任务完成来实现：
- en: '[PRE25]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Then, the trick to make our application wait for all the tasks to complete
    is to provide the `spider()` function with a special callback, which we call `done()`.
    The `done()` function increases a counter when a `spider` task completes. When
    the number of completed downloads reaches the size of the `links` array, the final
    callback is invoked:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使我们的应用程序等待所有任务完成的技巧是向`spider()`函数提供一个特殊的回调，我们称之为`done()`。当`spider`任务完成时，`done()`函数会增加计数器。当完成的下载数量达到`links`数组的大小，最终回调将被调用：
- en: '[PRE26]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The `hasErrors` variable is necessary because if one parallel task fails, we
    want to immediately call the callback with the given error. Also, we need to make
    sure that other parallel tasks that might still be running won't invoke the callback
    again.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`hasErrors`变量是必要的，因为如果其中一个并行任务失败，我们希望立即调用带有给定错误的回调。此外，我们需要确保可能仍在运行的其它并行任务不会再次调用回调。'
- en: With these changes in place, if we now try to run our spider against a web page,
    we will notice a huge improvement in the speed of the overall process, as every
    download will be carried out in parallel, without waiting for the previous link
    to be processed.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些更改到位后，如果我们现在尝试运行我们的蜘蛛程序对网页进行抓取，我们会注意到整体过程的速度有了巨大的提升，因为每个下载都会并行进行，无需等待前一个链接被处理。
- en: The pattern
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模式
- en: 'Finally, we can extract our nice little pattern for the parallel execution flow.
    Let''s represent a generic version of the pattern with the following code:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以提取出我们漂亮的并行执行流程模式。让我们用以下代码表示模式的通用版本：
- en: '[PRE27]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: With small modifications, we can adapt the pattern to accumulate the results
    of each task into a collection, to filter or map the elements of an array, or
    to invoke the `finish()` callback as soon as one or a given number of tasks complete
    (this last situation in particular is called **competitive race**).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一些小的修改，我们可以将模式调整为将每个任务的结果累积到一个集合中，过滤或映射数组的元素，或者在一项或给定数量的任务完成时立即调用`finish()`回调（这种情况特别称为**竞争性赛跑**）。
- en: '**The Unlimited Parallel Execution pattern**'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**无限制并行执行模式**'
- en: Run a set of asynchronous tasks in parallel by launching them all at once, and
    then wait for all of them to complete by counting the number of times their callbacks
    are invoked.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一次性启动所有异步任务，并行运行一组异步任务，然后通过计算它们的回调被调用的次数来等待所有任务完成。
- en: When we have multiple tasks running in parallel, we might have race conditions,
    that is, contention to access external resources (for example, files or records
    in a database). In the next section, we will talk about race conditions in Node.js
    and explore some techniques to identify and address them.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们并行运行多个任务时，我们可能会遇到竞争条件，即对外部资源（例如文件或数据库中的记录）的访问竞争。在下一节中，我们将讨论 Node.js 中的竞争条件，并探讨一些识别和解决它们的技术。
- en: Fixing race conditions with concurrent tasks
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用并发任务解决竞争条件
- en: Running a set of tasks in parallel can cause issues when using blocking I/O
    in combination with multiple threads. However, you have just seen that, in Node.js,
    this is a totally different story. Running multiple asynchronous tasks in parallel
    is, in fact, straightforward and cheap in terms of resources.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用阻塞 I/O 与多个线程结合使用时，并行运行一组任务可能会引起问题。然而，你刚刚看到，在 Node.js 中，这完全是另一回事。并行运行多个异步任务实际上既简单又节省资源。
- en: This is one of the most important strengths of Node.js, because it makes parallelization
    a common practice rather than a complex technique to only use when strictly necessary.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Node.js 最重要优势之一，因为它使得并行化成为一种常见实践，而不是仅在绝对必要时才使用的复杂技术。
- en: Another important characteristic of the concurrency model of Node.js is the
    way we deal with task synchronization and race conditions. In multithreaded programming,
    this is usually done using constructs such as locks, mutexes, semaphores, and
    monitors, and it can be one of the most complex aspects of parallelization, and
    has a considerable impact on performance. In Node.js, we usually don't need a
    fancy synchronization mechanism, as everything runs on a single thread. However,
    this doesn't mean that we can't have race conditions; on the contrary, they can
    be quite common. The root of the problem is the delay between the invocation of
    an asynchronous operation and the notification of its result.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Node.js 并发模型的重要特性之一是我们处理任务同步和竞争条件的方式。在多线程编程中，这通常使用锁、互斥锁、信号量和监视器等结构来完成，这可能是并行化的最复杂方面之一，并对性能有相当大的影响。在
    Node.js 中，我们通常不需要复杂的同步机制，因为所有操作都在单个线程上运行。然而，这并不意味着我们不能有竞争条件；相反，它们可能相当常见。问题的根源在于异步操作的调用和结果通知之间的延迟。
- en: 'To see a concrete example, we will refer again to our web spider application,
    and in particular, the last version we created, which actually contains a race
    condition (can you spot it?). The problem we are talking about lies in the `spider()` function,
    where we check whether a file already exists before we start to download the corresponding
    URL:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看到具体的例子，我们将再次参考我们的网络蜘蛛应用程序，特别是我们创建的最后一个版本，它实际上包含了一个竞争条件（你能找到吗？）。我们讨论的问题在于
    `spider()` 函数，我们在开始下载相应 URL 之前检查文件是否已经存在：
- en: '[PRE28]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The problem is that two `spider` tasks operating on the same URL might invoke `fs.readFile()` on
    the same file before one of the two tasks completes the download and creates a
    file, causing both tasks to start a download. *Figure 4.4* explains this situation:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于，两个在相同 URL 上操作的 **蜘蛛** 任务可能会在其中一个任务完成下载并创建文件之前对同一文件调用 `fs.readFile()`，导致两个任务都开始下载。*图
    4.4* 解释了这种情况：
- en: '![](img/B15729_04_04.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15729_04_04.png)'
- en: 'Figure 4.4: An example of a race condition in our spider() function'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4：蜘蛛()函数中的竞争条件示例
- en: '*Figure 4.4* shows how **Task 1** and **Task 2** are interleaved in the single
    thread of Node.js, as well as how an asynchronous operation can actually introduce
    a race condition. In our case, the two `spider` tasks end up downloading the same
    file.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4.4* 展示了在 Node.js 的单线程中 **任务 1** 和 **任务 2** 如何交错执行，以及异步操作实际上如何引入竞争条件。在我们的例子中，两个
    **蜘蛛** 任务最终下载了相同的文件。'
- en: 'How can we fix that? The answer is much simpler than you might think. In fact,
    all we need is a variable to mutually exclude multiple `spider()` tasks running
    on the same URL. This can be achieved with some code, such as the following:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们该如何解决这个问题？答案比你想象的要简单得多。实际上，我们只需要一个变量来互斥多个在相同 URL 上运行的 **蜘蛛** 任务。这可以通过一些代码实现，如下所示：
- en: '[PRE29]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The fix does not require many comments. We simply exit the function immediately
    if the given `url` is already present in the `spidering` set; otherwise, we add
    the `url` to the set and continue with the download. In our case, we don't need
    to release the lock, as we are not interested in downloading a URL twice, even
    if the `spider` tasks are executed at two completely different points in time.
    If you are building a spider that might have to download hundreds of thousands
    of web pages, removing the downloaded `url` from the set once a file is downloaded
    will help you to keep the set cardinality, and therefore the memory consumption,
    from growing indefinitely.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 修复不需要很多注释。如果给定的`url`已经存在于`spidering`集合中，我们立即退出函数；否则，我们将`url`添加到集合中，并继续下载。在我们的情况下，我们不需要释放锁，因为我们不感兴趣下载同一个URL两次，即使`spider`任务在两个完全不同的时间点执行。
- en: Race conditions can cause many problems, even if we are in a single-threaded
    environment. In some circumstances, they can lead to data corruption and are usually
    very hard to debug because of their ephemeral nature. So, it's always good practice
    to double-check for these types of situations when running tasks in parallel.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 竞态条件可以导致许多问题，即使我们处于单线程环境中。在某些情况下，它们可能导致数据损坏，并且由于它们的短暂性，通常很难调试。因此，在并行运行任务时，始终检查这些类型的情况是一个好的做法。
- en: Also, running an arbitrary number of parallel tasks can be a dangerous practice.
    In the next section, you will discover why it can be a problem and how to keep
    the number of parallel tasks under control.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，运行任意数量的并行任务可能是一种危险的做法。在下一节中，你将发现为什么这可能会成为一个问题以及如何控制并行任务的数量。
- en: Limited parallel execution
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制并行执行
- en: Spawning parallel tasks without control can often lead to excessive load. Imagine
    having thousands of files to read, URLs to access, or database queries to run
    in parallel. A common problem in such situations is running out of resources.
    The most common example is when an application tries to open too many files at
    once, utilizing all the file descriptors available to the process.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 无控制地生成并行任务往往会导致过载。想象一下，如果有成千上万的文件要读取，URL要访问，或者数据库查询要并行运行。这种情况下的一个常见问题是资源耗尽。最常见的情况是，当应用程序试图一次性打开太多文件时，利用了进程可用的所有文件描述符。
- en: A server that spawns unbounded parallel tasks to handle a user request could
    be exploited with a **denial-of-service** (**DoS**) attack. That is when a malicious
    actor can forge one or more requests to push the server to consume all the available
    resources and become unresponsive. Limiting the number of parallel tasks is, in
    general, a good practice that helps with building resilient applications.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 一个生成无界并行任务以处理用户请求的服务器可能会被**拒绝服务**（**DoS**）攻击所利用。这就是恶意行为者可以伪造一个或多个请求，将服务器推向消耗所有可用资源并变得无响应。限制并行任务的数量通常是一个好的做法，有助于构建健壮的应用程序。
- en: Version 3 of our web spider does not limit the number of parallel tasks and
    therefore, it is susceptible to crashing in a number of cases. For instance, if
    we try to run it against a significantly big website, we might see it running
    for a few seconds and then failing with the error code `ECONNREFUSED`. When we
    are downloading too many pages concurrently from a web server, the server might
    decide to start rejecting new connections from the same IP. In this case, our
    spider would just crash and we would be forced to relaunch the process if we wanted
    to continue crawling the website. We could just handle `ECONNREFUSED` to stop
    the process from crashing, but we would still be risking allocating too many parallel
    tasks and might run into other issues.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的网络爬虫的第三个版本不限制并行任务的数量，因此，它在许多情况下容易崩溃。例如，如果我们尝试运行它来针对一个显著大的网站，我们可能会看到它运行几秒钟然后失败，错误代码为`ECONNREFUSED`。当我们从网络服务器并发下载太多页面时，服务器可能会决定开始拒绝来自同一IP的新连接。在这种情况下，我们的爬虫会直接崩溃，如果我们想继续爬取网站，我们就必须重新启动进程。我们只是处理`ECONNREFUSED`来停止进程崩溃，但我们仍然冒着分配太多并行任务的风险，可能会遇到其他问题。
- en: In this section, you will see how we can make our spider more resilient by keeping
    the concurrency limited.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将了解我们如何通过限制并发来使我们的爬虫更加健壮。
- en: 'The following diagram shows a situation where we have five tasks that run in
    parallel with a concurrency limit of two:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图示显示了我们在有两个并发限制的情况下运行五个并行任务的情况：
- en: '![](img/B15729_04_05.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B15729_04_05.png)'
- en: 'Figure 4.5: An example of how concurrency can be limited to a maximum of two
    parallel tasks'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5：限制并发到最多两个并行任务的示例
- en: 'From *Figure 4.5*, it should be clear how our algorithm works:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图4.5*中，应该可以清楚地了解我们的算法是如何工作的：
- en: Initially, we spawn as many tasks as we can without exceeding the concurrency
    limit.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始时，我们将生成尽可能多的任务，而不超过并发限制。
- en: Then, every time a task is completed, we spawn one or more tasks until we reach
    the limit again.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，每次任务完成时，我们生成一个或多个任务，直到再次达到限制。
- en: In the next section, we will explore a possible implementation of the limited
    parallel execution pattern.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨有限并行执行模式的可能实现。
- en: Limiting concurrency
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 限制并发
- en: 'We will now look at a pattern that will execute a set of given tasks in parallel
    with limited concurrency:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将研究一种模式，它将以有限的并发性并行执行一组给定的任务：
- en: '[PRE30]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This algorithm can be considered a mixture of sequential execution and parallel
    execution. In fact, you might notice similarities with both patterns:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这个算法可以被认为是一种顺序执行和并行执行的混合体。事实上，你可能会注意到它与这两种模式都有相似之处：
- en: We have an iterator function, which we call `next()`, and then an inner loop
    that spawns as many tasks as possible in parallel while staying within the concurrency
    limit.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们有一个迭代函数，我们称之为`next()`，然后是一个内部循环，它尽可能多地并行生成任务，同时保持在并发限制内。
- en: The next important part is the callback we pass to each task, which checks whether
    we completed all the tasks in the list. If there are still tasks to run, it invokes `next()` to
    spawn another set of tasks.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个重要部分是我们传递给每个任务的回调，它检查我们是否完成了列表中的所有任务。如果有任务尚未运行，它将调用`next()`来生成另一组任务。
- en: Pretty simple, isn't it?
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 很简单，不是吗？
- en: Globally limiting concurrency
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 全局限制并发
- en: Our web spider application is perfect for applying what we just learned about
    limiting the concurrency of a set of tasks. In fact, to avoid the situation in
    which we have thousands of links being crawled at the same time, we can enforce
    a limit on the concurrency of this process by adding some predictability regarding
    the number of concurrent downloads.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的网页爬虫应用程序非常适合应用我们刚刚学到的关于限制任务集并发性的知识。事实上，为了避免同时爬取数千个链接的情况，我们可以通过添加一些关于并发下载数量的可预测性来限制此过程的并发性。
- en: We could apply this implementation of the limited concurrency pattern to our `spiderLinks()` function,
    but by doing that, we would only be limiting the concurrency of tasks spawned
    from the links found within a given page. If we chose, for example, a concurrency
    of two, we would have, at most, two links downloaded in parallel for each page.
    However, as we can download multiple links at once, each page would then spawn
    another two downloads, causing the grand total of download operations to grow
    exponentially anyway.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这种有限并发模式的实现应用于我们的`spiderLinks()`函数，但通过这样做，我们只会限制从给定页面中找到的链接生成的任务的并发性。例如，如果我们选择并发性为两个，那么每个页面最多只能并行下载两个链接。然而，由于我们可以一次性下载多个链接，每个页面随后会生成另外两个下载，因此总的下载操作数量仍然会呈指数增长。
- en: In general, this implementation of the limited concurrency pattern works very
    well when we have a predetermined set of tasks to execute, or when the set of
    tasks grows linearly over time. When, instead, a task can spawn two or more tasks
    directly, as happens with our web spider, this implementation is not suitable
    for limiting the global concurrency.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当我们有一个预定的任务集要执行，或者当任务集随时间线性增长时，这种有限并发模式的实现工作得非常好。相反，如果一个任务可以直接生成两个或更多任务，就像我们的网页爬虫那样，这种实现不适合限制全局并发。
- en: Queues to the rescue
  id: totrans-198
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 队列来拯救
- en: What we really want, then, is to limit the global number of download operations
    we can have running in parallel. We could slightly modify the pattern shown in
    the previous section, but this is left as an exercise for you. Instead, let's
    discuss another mechanism that makes use of **queues** to limit the concurrency
    of multiple tasks. Let's see how this works.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们真正想要的是限制可以并行运行的全球下载操作的数量。我们可以稍微修改前一个章节中显示的模式，但这留给你作为练习。相反，让我们讨论另一种机制，它利用**队列**来限制多个任务的并发性。让我们看看它是如何工作的。
- en: 'We are now going to implement a simple class named `TaskQueue`, which will
    combine a queue with the algorithm that was presented while discussing limited
    concurrency. Let''s create a new module named `taskQueue.js`:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将实现一个简单的名为`TaskQueue`的类，它将结合队列与在讨论限制并发时提出的算法。让我们创建一个新的模块名为`taskQueue.js`：
- en: '[PRE31]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The constructor of this class takes, as input, only the concurrency limit, but
    besides that, it initializes the instance variables `running` and `queue`. The
    former variable is a counter used to keep track of all the running tasks, while
    the latter is the array that will be used as a queue to store the pending tasks.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类的构造函数只接受并发限制作为输入，但除此之外，它初始化实例变量`running`和`queue`。前者是一个计数器，用于跟踪所有正在运行的任务，而后者是作为队列使用的数组，用于存储待处理任务。
- en: The `pushTask()` method simply adds a new task to the queue and then bootstraps
    the execution of the worker by asynchronously invoking `this.next()`. Note that
    we have to use `bind` because otherwise, the `next` function will lose its context
    when invoked by `process.nextTick`.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '`pushTask()`方法简单地将新任务添加到队列中，然后通过异步调用`this.next()`来启动工作进程的执行。请注意，我们必须使用`bind`，否则`next`函数在`process.nextTick`调用时将丢失上下文。'
- en: The `next()` method spawns a set of tasks from the queue, ensuring that it does
    not exceed the concurrency limit.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`next()`方法从队列中生成一系列任务，确保它不会超过并发限制。'
- en: You may notice that this method has some similarities with the pattern presented
    at the beginning of the *Limiting concurrency* section. It essentially starts
    as many tasks from the queue as possible, without exceeding the concurrency limit.
    When each task is complete, it updates the count of running tasks and then starts
    another round of tasks by asynchronously invoking `next()` again. The interesting
    property of the `TaskQueue` class is that it allows us to dynamically add new
    items to the queue. The other advantage is that, now, we have a central entity
    responsible for the limitation of the concurrency of our tasks, which can be shared
    across all the instances of a function's execution. In our case, it's the `spider()` function,
    as you will see in a moment.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到这个方法与*限制并发*部分开头提出的模式有一些相似之处。它本质上开始尽可能多地从队列中启动任务，而不超过并发限制。当每个任务完成时，它更新正在运行的任务计数，然后通过再次异步调用`next()`来启动另一轮任务。`TaskQueue`类的有趣属性是它允许我们动态地向队列中添加新项目。另一个优点是，现在我们有一个中央实体负责限制我们任务的并发性，这可以在函数执行的各个实例之间共享。在我们的例子中，它是`spider()`函数，你将在稍后看到。
- en: Refining the TaskQueue
  id: totrans-206
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 精炼`TaskQueue`
- en: The previous implementation of `TaskQueue` is sufficient to demonstrate the
    queue pattern, but in order to be used in real-life projects, it needs a couple
    of extra features. For instance, how can we tell when one of the tasks has failed?
    How do we know whether all the work in the queue has been completed?
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '`TaskQueue`的先前实现足以演示队列模式，但为了在实际项目中使用，它需要一些额外的功能。例如，我们如何知道任务中有一个失败了？我们如何知道队列中的所有工作是否已经完成？'
- en: Let's bring back some of the concepts we discussed in *Chapter 3*, *Callbacks
    and Events*, and let's turn the `TaskQueue` into an `EventEmitter` so that we
    can emit events to propagate task failures and to inform any observer when the
    queue is empty.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下我们在*第三章*，*回调和事件*中讨论的一些概念，并将`TaskQueue`转换为`EventEmitter`，这样我们就可以通过触发事件来传播任务失败，并在队列为空时通知任何观察者。
- en: 'The first change we have to make is to import the `EventEmitter` class and
    let our `TaskQueue` extend it:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须做的第一个改变是导入`EventEmitter`类，并让我们的`TaskQueue`扩展它：
- en: '[PRE32]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'At this point, we can use `this.emit` to fire events from within the `TaskQueue`
    `next()` method:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们可以使用`this.emit`在`TaskQueue`的`next()`方法中触发事件：
- en: '[PRE33]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Comparing this implementation with the previous one, there are two additions
    here:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 将这个实现与之前的实现进行比较，这里有两个新增内容：
- en: Every time the `next()` function is called, we check that no task is running
    and whether the queue is empty. In such a case, it means that the queue has been
    drained and we can fire the `empty` event.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每次调用`next()`函数时，我们检查没有任务正在运行，并且队列是否为空。在这种情况下，这意味着队列已经被清空，我们可以触发`empty`事件。
- en: The completion callback of every task can now be invoked by passing an error.
    We check whether an error is actually passed, indicating that the task has failed,
    and in that case, we propagate such an error with an `error` event.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个任务的完成回调现在可以通过传递一个错误来调用。我们检查是否实际传递了一个错误，这表明任务失败了，在这种情况下，我们通过`error`事件传播这样的错误。
- en: Notice that in case of an error, we are deliberately keeping the queue running.
    We are not stopping other tasks in progress, nor removing any pending tasks. This
    is quite common with queue-based systems. Errors are expected to happen and rather
    than letting the system crash on these occasions, it is generally better to identify
    errors and to think about retry or recovery strategies. We will discuss these
    concepts a bit more in *Chapter 13*, *Messaging and Integration Patterns*.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在出现错误的情况下，我们故意保持队列运行。我们不会停止正在进行的其他任务，也不会移除任何挂起的任务。这在基于队列的系统里是很常见的。错误是预期会发生的，而不是让系统在这些情况下崩溃，通常更好的做法是识别错误并考虑重试或恢复策略。我们将在*第13章*，*消息和集成模式*中更详细地讨论这些概念。
- en: Web spider version 4
  id: totrans-217
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Web爬虫版本4
- en: Now that we have our generic queue to execute tasks in a limited parallel flow,
    let's use it straightaway to refactor our web spider application.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了我们的通用队列，可以在有限的并行流中执行任务，让我们直接使用它来重构我们的 web爬虫 应用程序。
- en: We are going to use an instance of `TaskQueue` as a work backlog; every URL
    that we want to crawl needs to be appended to the queue as a task. The starting
    URL will be added as the first task, then every other URL discovered during the
    crawling process will be added as well. The queue will manage all the scheduling
    for us, making sure that the number of tasks in progress (that is, the number
    of pages being downloaded or read from the filesystem) at any given time is never
    greater than the concurrency limit configured for the given `TaskQueue` instance.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`TaskQueue`的一个实例作为工作待办事项；我们想要爬取的每个URL都需要作为任务添加到队列中。起始URL将被添加为第一个任务，然后爬取过程中发现的每个其他URL也将被添加。队列将为我们管理所有调度，确保在任何给定时间正在进行的任务数量（即正在下载或从文件系统中读取的页面数量）永远不会超过为给定`TaskQueue`实例配置的并发限制。
- en: 'We have already defined the logic to crawl a given URL inside our `spider()`
    function. We can consider this to be our generic crawling task. For more clarity,
    it''s best to rename this function `spiderTask`:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在`spider()`函数内部定义了爬取给定URL的逻辑。我们可以将这视为我们的通用爬取任务。为了更清晰，最好将此函数重命名为`spiderTask`：
- en: '[PRE34]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Other than renaming the function, you might have noticed that we applied some
    other small changes:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 除了重命名函数外，你可能还注意到我们做了一些其他的小改动：
- en: The function signature now accepts a new parameter called `queue`. This is an
    instance of `TaskQueue` that we need to carry over to be able to append new tasks
    when necessary.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数签名现在接受一个名为`queue`的新参数。这是一个`TaskQueue`的实例，我们需要将其传递过去，以便在必要时添加新任务。
- en: The function responsible for adding new links to crawl is `spiderLinks`, so
    we need to make sure that we pass the queue instance when we call this function
    after downloading a new page.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负责添加新链接进行爬取的函数是`spiderLinks`，因此我们需要确保在下载新页面后调用此函数时传递队列实例。
- en: We also need to pass the queue instance to `spiderLinks` when we are invoking
    that from an already downloaded file.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还需要在从已下载的文件调用`spiderLinks`时传递队列实例。
- en: 'Let''s revisit the `spiderLinks()` function. This function can now be greatly
    simplified as it doesn''t have to keep track of task completion anymore, as this
    work has been delegated to the queue. Its job becomes effectively synchronous
    now; it just needs to invoke the new `spider()` function (which we will define
    shortly) to push a new task to the queue, one for each discovered link:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下`spiderLinks()`函数。由于这项工作已经委托给队列，这个函数现在可以大大简化，因为它不再需要跟踪任务完成情况。现在，它的任务实际上是同步的；它只需要调用新的`spider()`函数（我们将在稍后定义）来向队列推送一个新任务，每个发现的链接一个任务：
- en: '[PRE35]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Let''s now revisit the `spider()` function, which needs to act as the *entry
    point* for the first URL; it will also be used to add every new discovered URL
    to the `queue`:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在回顾一下`spider()`函数，它需要作为第一个URL的*入口点*；它也将用于将每个新发现的URL添加到`queue`：
- en: '[PRE36]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'As you can see, this function now has two main responsibilities:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这个函数现在有两个主要职责：
- en: It manages the bookkeeping of the URLs already visited or in progress by using
    the `spidering` set.
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它通过使用`spidering`集合来管理已访问或正在进行的URL的账本。
- en: It pushes a new task to the `queue`. Once executed, this task will invoke the
    `spiderTask()` function, effectively starting the crawling of the given URL.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将新任务推送到`queue`。一旦执行，此任务将调用`spiderTask()`函数，实际上开始爬取给定的URL。
- en: 'Finally, we can update the `spider-cli.js` script, which allows us to invoke
    our spider from the command line:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以更新`spider-cli.js`脚本，它允许我们从命令行调用我们的爬虫：
- en: '[PRE37]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'This script is now composed of three main parts:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本现在由三个主要部分组成：
- en: CLI arguments parsing. Note that the script now accepts a third additional parameter
    that can be used to customize the concurrency level.
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CLI参数解析。请注意，现在脚本接受一个额外的第三个参数，可以用来自定义并发级别。
- en: A `TaskQueue` object is created and listeners are attached to the `error` and
    `empty` events. When an error occurs, we simply want to print it. When the queue
    is empty, that means that we've finished crawling the website.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建了一个`TaskQueue`对象，并将监听器附加到`error`和`empty`事件上。当发生错误时，我们只想简单地打印它。当队列为空时，这意味着我们已经完成了网站的爬取。
- en: Finally, we start the crawling process by invoking the `spider` function.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们通过调用`spider`函数开始爬取过程。
- en: 'After we have applied these changes, we can try to run the spider module again.
    When we run the following command:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们应用了这些更改之后，我们可以再次尝试运行蜘蛛模块。当我们运行以下命令：
- en: '[PRE38]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We should notice that no more than four downloads will be active at the same
    time.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该注意到，同时最多只能有四个下载活动。
- en: With this final example, we've concluded our exploration of callback-based patterns.
    In the next section, we will close this chapter by looking at a famous library
    that provides a production-ready implementation of these patterns and many other
    asynchronous utilities.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个最后的例子中，我们结束了基于回调模式的探索。在下一节中，我们将通过查看一个著名的库来结束这一章，这个库提供了一个这些模式和许多其他异步工具的生产就绪实现。
- en: The async library
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`async`库'
- en: If you take a look for a moment at every control flow pattern we have analyzed
    so far, you will see that they can be used as a base to build reusable and more
    generic solutions. For example, we could wrap the unlimited parallel execution
    algorithm into a function that accepts a list of tasks, runs them in parallel,
    and invokes the given callback when all of them are complete. This way of wrapping
    control flow algorithms into reusable functions can lead to a more declarative
    and expressive way of defining asynchronous control flows, and that's exactly
    what `async` ([nodejsdp.link/async](http://nodejsdp.link/async)) does.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你暂时回顾一下我们迄今为止分析过的每一个控制流模式，你会发现它们可以用作构建可重用和更通用解决方案的基础。例如，我们可以将无限并行执行算法封装成一个函数，该函数接受一个任务列表，并行运行它们，并在所有任务都完成时调用给定的回调。将控制流算法封装成可重用函数的方式可以导致定义异步控制流的一种更声明性和表达性的方式，这正是`async`([nodejsdp.link/async](http://nodejsdp.link/async))所做的事情。
- en: The `async` library (not to be confused with the `async`/`await` keywords, which
    we will discuss later in this book) is a very popular solution, in Node.js and
    JavaScript in general, for dealing with asynchronous code. It offers a set of
    functions that greatly simplify the execution of tasks in different configurations,
    and it also provides useful helpers for dealing with collections asynchronously.
    Even though there are several other libraries with a similar goal, `async` is
    the de facto standard in Node.js due to its historic popularity, especially when
    using callbacks to define asynchronous tasks.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '`async`库（不要与本书后面将要讨论的`async`/`await`关键字混淆）是Node.js和JavaScript中处理异步代码的一个非常流行的解决方案。它提供了一套函数，可以极大地简化不同配置下任务的执行，并且它还提供了处理集合的异步的有用辅助工具。尽管有其他几个具有类似目标的库，但由于其历史流行度，`async`在Node.js中成为了事实上的标准，尤其是在使用回调定义异步任务时。'
- en: 'Just to give you an idea of some of the most important capabilities of the
    async module, here is a sample of the functionalities it exposes:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 只为了给你一个关于异步模块最重要功能的印象，这里是一个它暴露的功能示例：
- en: Execute asynchronous functions over a collection of elements (in series or in
    parallel with limited concurrency).
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在一系列元素上执行异步函数（按顺序或有限并发地并行执行）。
- en: Execute a chain of asynchronous functions (waterfall) where the output of every
    function becomes the input of the next one.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行一系列异步函数（瀑布），其中每个函数的输出成为下一个函数的输入。
- en: Offers a queue abstraction functionally equivalent to the one we implemented
    with our `TaskQueue` utility.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供了一个队列抽象函数，功能上等同于我们使用`TaskQueue`实用程序实现的队列。
- en: Provides other interesting asynchronous patterns such as **race** (executes
    multiple asynchronous functions in parallel and stops when the first one completes).
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供其他有趣的异步模式，如**race**（并行执行多个异步函数，并在第一个完成时停止）。
- en: Check out the `async` documentation ([nodejsdp.link/async](http://nodejsdp.link/async))
    to find out more about the module and to see some examples.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 查看关于`async`的文档([nodejsdp.link/async](http://nodejsdp.link/async))，了解更多关于该模块的信息，并查看一些示例。
- en: Once you've understood the fundamentals of the asynchronous patterns described
    in this chapter, you shouldn't rely on the simplified implementations presented
    here for your everyday control flow needs. Instead, it's better to adopt a broadly
    used and battle-tested library like `async` for your production applications,
    unless your use case is so advanced that you require a custom algorithm.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你理解了本章描述的异步模式的基本原理，你不应该依赖这里提供的简化实现来满足你的日常控制流需求。相反，对于生产应用，最好采用广泛使用且经过实战考验的库，如`async`，除非你的用例非常高级，需要自定义算法。
- en: Summary
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: At the beginning of this chapter, it was stated that Node.js programming can
    be tough because of its asynchronous nature, especially for people used to developing
    on other platforms. However, throughout this chapter, you saw how asynchronous
    APIs can be bent to your will. You discovered that the tools at your disposal
    are indeed versatile and provide good solutions to most of your problems, in addition
    to offering a programming style for every taste.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的开头，提到Node.js编程可能很困难，因为它具有异步特性，尤其是对于那些习惯于在其他平台上开发的人来说。然而，在本章中，你看到了如何将异步API弯曲以适应你的意愿。你发现，你手中的工具确实非常灵活，并且为大多数问题提供了良好的解决方案，同时还提供了适合各种口味的编程风格。
- en: In this chapter, we also kept refactoring and improving our web crawler example.
    When dealing with asynchronous code, it can sometimes be challenging to figure
    out the right ergonomics that can keep your code simple and effective, so allow
    yourself some time to digest the concepts explored in this chapter and to experiment
    with them.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们也持续重构和改进我们的网络爬虫示例。在处理异步代码时，有时可能具有挑战性，需要找到合适的用户体验，以保持代码简单和有效，因此请给自己一些时间来消化本章探讨的概念，并尝试应用它们。
- en: Our journey with asynchronous Node.js programming has just started. In the next
    few chapters, you will be introduced to other broadly adopted techniques that
    leverage promises, and async/await. After you've learned all these techniques,
    you will be able to choose the best solution for your needs or use many of them
    together in the same project.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对异步Node.js编程的探索才刚刚开始。在接下来的几章中，你将了解到其他广泛采用的技术，这些技术利用了承诺（promises）和async/await。在你掌握了所有这些技术之后，你将能够为你的需求选择最佳解决方案，或者在同一项目中使用其中许多技术。
- en: Exercises
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: '**4.1 File concatenation**: Write the implementation of `concatFiles()`, a
    callback-style function that takes two or more paths to text files in the filesystem
    and a destination file:'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**4.1 文件连接**：编写`concatFiles()`的实现，这是一个回调风格的函数，它接受文件系统中两个或更多文本文件的路径和一个目标文件：'
- en: '[PRE39]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'This function must copy the contents of every source file into the destination
    file, respecting the order of the files, as provided by the arguments list. For
    instance, given two files, if the first file contains *foo* and the second file
    contains *bar*, the function should write *foobar* (and not *barfoo*) in the destination
    file. Note that the preceding example signature is not valid JavaScript syntax:
    you need to find a different way to handle an arbitrary number of arguments. For
    instance, you could use the **rest parameters** syntax ([nodejsdp.link/rest-parameters](http://nodejsdp.link/rest-parameters)).'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此函数必须将每个源文件的 内容复制到目标文件中，按照提供的参数列表中的顺序，例如，给定两个文件，如果第一个文件包含*foo*，第二个文件包含*bar*，则函数应在目标文件中写入*foobar*（而不是*barfoo*）。请注意，前面的示例签名不是有效的JavaScript语法：你需要找到不同的方法来处理任意数量的参数。例如，你可以使用**剩余参数**语法
    ([nodejsdp.link/rest-parameters](http://nodejsdp.link/rest-parameters))。
- en: '**4.2 List files recursively**: Write `listNestedFiles()`, a callback-style
    function that takes, as the input, the path to a directory in the local filesystem
    and that asynchronously iterates over all the subdirectories to eventually return
    a list of all the files discovered. Here is what the signature of the function
    should look like:'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**4.2 递归列出文件**：编写`listNestedFiles()`，一个回调风格的函数，它接受本地文件系统中目录的路径作为输入，并异步遍历所有子目录，最终返回找到的所有文件的列表。以下是该函数签名应如下所示：'
- en: '[PRE40]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Bonus points if you manage to avoid callback hell. Feel free to create additional
    helper functions if needed.
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你能成功避免回调地狱，将获得加分。如有需要，请自由创建额外的辅助函数。
- en: '**4.3 Recursive find**: Write `recursiveFind()`, a callback-style function
    that takes a path to a directory in the local filesystem and a keyword, as per
    the following signature:'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**4.3 递归查找**：编写`recursiveFind()`，这是一个回调风格的函数，它接受本地文件系统中目录的路径和一个关键字，如下所示：'
- en: '[PRE41]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The function must find all the text files within the given directory that contain
    the given keyword in the file contents. The list of matching files should be returned
    using the callback when the search is completed. If no matching file is found,
    the callback must be invoked with an empty array. As an example test case, if
    you have the files `foo.txt`, `bar.txt`, and `baz.txt` in `myDir` and the keyword
    `''batman''` is contained in the files `foo.txt` and `baz.txt`, you should be
    able to run the following code:'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 函数必须找到给定目录下所有包含给定关键词的文本文件。搜索完成后，应使用回调函数返回匹配文件的列表。如果没有找到匹配的文件，则必须使用空数组调用回调函数。作为一个示例测试用例，如果你在`myDir`目录下有`foo.txt`、`bar.txt`和`baz.txt`这三个文件，并且关键词`'batman'`包含在`foo.txt`和`baz.txt`这两个文件中，你应该能够运行以下代码：
- en: '[PRE42]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Bonus points if you make the search recursive (it looks for text files in any
    subdirectory as well). Extra bonus points if you manage to perform the search
    within different files and subdirectories in parallel, but be careful to keep
    the number of parallel tasks under control!
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你能使搜索递归（它会在任何子目录中查找文本文件），那么你会得到额外的分数。如果你能够并行地在不同的文件和子目录中执行搜索，那么你会得到更多的额外分数，但请注意要控制并行任务的数量！
