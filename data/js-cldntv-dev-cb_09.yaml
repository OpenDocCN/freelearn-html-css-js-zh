- en: Optimizing Performance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化性能
- en: 'In this chapter, the following recipes will be covered:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，将涵盖以下食谱：
- en: Tuning Function as a Service
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调优函数即服务
- en: Batching requests
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量请求
- en: Leveraging asynchronous non-blocking IO
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用异步非阻塞IO
- en: Grouping events in stream processors
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在流处理器中分组事件
- en: Autoscaling DynamoDB
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动扩展DynamoDB
- en: Utilizing cache-control
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用缓存控制
- en: Leveraging session consistency
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用会话一致性
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: Cloud-native turns performance testing, tuning, and optimization on their heads.
    Many of the fully-managed, serverless cloud services that are leveraged have implicit
    scalability. These services are purchased per request and will automatically scale
    to meet peak and unexpected demands. For these resources, it is much less necessary
    to perform upfront performance testing; instead, we optimize for observability,
    as discussed in [Chapter 7](64a4c0f7-3b2d-4638-a52c-f72953ff66d9.xhtml), *Optimizing
    Observability*, and continuously tune based on the information gathered from continuous
    testing in production. We also leverage continuous deployment to push necessary
    improvements. This worth-based development approach helps ensure that we are focusing
    our efforts on the highest value improvements.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生将性能测试、调优和优化颠倒过来。许多利用的完全管理的无服务器云服务具有隐式可伸缩性。这些服务按请求购买，并将自动扩展以满足峰值和意外的需求。对于这些资源，进行前期性能测试的必要性要小得多；相反，我们根据在生产环境中进行的持续测试收集到的信息进行优化，如第7章[优化可观察性](64a4c0f7-3b2d-4638-a52c-f72953ff66d9.xhtml)中所述，并基于收集到的信息持续调优。我们还利用持续部署来推动必要的改进。这种基于价值的开发方法有助于确保我们专注于最高价值的改进。
- en: Still, there are resources, such as some stream processors and data stores,
    that rely heavily on explicitly defined batch sizes and read/write capacities.
    For crucial services, these resources must be sufficiently allocated to ensure
    peak data processing volumes do not overwhelm them. The recipes in this chapter
    will therefore focus on performance optimization techniques that are worth applying
    upfront in the design and development process to help ensure services are not
    working against themselves.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，还有一些资源，如某些流处理器和数据存储，严重依赖于显式定义的批量大小和读写容量。对于关键服务，这些资源必须得到充分分配，以确保峰值数据处理量不会使其过载。因此，本章的食谱将专注于在设计和发展过程中值得提前应用的性能优化技术，以帮助确保服务不会相互对抗。
- en: Tuning Function as a Service
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调优函数即服务
- en: Tuning functions is very different from traditional service tuning because there
    are so few explicit knobs to turn. There are also many implications of the short
    life cycle of a function that turns traditional techniques and frameworks into
    anti-patterns. The following recipe explains a common memory mistake, discusses
    the cold start implications of traditional language and library choices, and will
    show you how to package a JavaScript function with **webpack** to minimize download
    time.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 调优函数与传统服务调优非常不同，因为可调整的旋钮很少。函数的短生命周期也带来了许多影响，使得传统的技术和框架成为反模式。以下食谱解释了一个常见的内存错误，讨论了传统语言和库选择对冷启动的影响，并展示如何使用**webpack**打包JavaScript函数以最小化下载时间。
- en: How to do it...
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Create the project from the following template:'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Navigate to the `cncb-tuning-faas` directory, `cd cncb-tuning-faas`.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到`cncb-tuning-faas`目录，`cd cncb-tuning-faas`。
- en: 'Review the file named `serverless.yml` with the following content:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看以下内容的`serverless.yml`文件：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Review the file named `webpack.config.js` with the following content:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看以下内容的`webpack.config.js`文件：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Install the dependencies with `npm install`.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`npm install`安装依赖项。
- en: Run the tests with `npm test`.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`npm test`运行测试。
- en: Review the contents generated in the `.serverless` directory, note the ZIP file
    per function, and then unzip each to see the contents.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看`.serverless`目录中生成的内容，注意每个函数的ZIP文件，然后解压每个文件以查看其内容。
- en: Deploy the stack, `npm run dp:lcl -- -s $MY_STAGE`.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署堆栈，`npm run dp:lcl -- -s $MY_STAGE`。
- en: Review the stack and resources in the AWS Console and note the code size in
    the Lambda console.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在AWS控制台中查看堆栈和资源，并在Lambda控制台中注意代码大小。
- en: Finally, remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，一旦完成`npm run rm:lcl -- -s $MY_STAGE`，请删除堆栈。
- en: How it works...
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The most obvious knob we have for tuning **Function as a Service** (**FaaS**)
    is `memorySize` allocation. This setting drives the price calculation as well.
    Unfortunately, the correlation with price tends to be counter-intuitive and can
    result in decisions that actually increase costs, while also reducing performance.
    The way AWS Lambda pricing works is if you double the memory allocation but consequently
    cut the execution time in half, the price is the same. The corollary is that if
    you cut memory allocation in half and consequently double the execution time,
    you are spending the same amount of money for less performance. It works this
    way because memory allocation actually correlates to the machine instance size
    that a function is executed on. More memory allocation means that the function
    will also have a faster CPU and more network IO throughput. In short, *do not
    skimp on memory allocation*.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们调整**函数即服务**（**FaaS**）的最明显旋钮是`memorySize`分配。这个设置也驱动着价格计算。不幸的是，价格的相关性往往具有反直觉性，可能会导致增加成本的同时降低性能的决策。AWS
    Lambda的价格机制是这样的：如果你将内存分配加倍，但相应地将执行时间减半，价格保持不变。由此推论，如果你将内存分配减半，相应地将执行时间加倍，你将花费相同数量的钱，但性能却更低。这是因为内存分配实际上与函数执行的机器实例大小相关。更多的内存分配意味着函数也将拥有更快的CPU和更多的网络IO吞吐量。简而言之，*不要在内存分配上节省*。
- en: A major concern and source of confusion with Function as a Service is cold start
    times. For asynchronous functions, such as processing a Kinesis Stream, cold start
    times are not as concerning. This is because cold start frequency is lower as
    functions tend to be reused for several hours for each shard. However, minimizing
    cold start times for synchronous functions behind an API Gateway is very important,
    because multiple functions are started to accommodate concurrent load. As a result,
    cold start times could impact the end user experience.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 函数即服务的主要担忧和混淆来源是冷启动时间。对于异步函数，例如处理Kinesis流，冷启动时间并不那么令人担忧。这是因为冷启动频率较低，因为函数通常在每个分片上重复使用数小时。然而，最小化API网关后面同步函数的冷启动时间非常重要，因为需要启动多个函数来适应并发负载。因此，冷启动时间可能会影响最终用户的使用体验。
- en: The first thing that impacts cold start time is the size of the function package
    that must be downloaded to the container. This is one reason that allocating more
    memory and hence more network IO throughput improves the performance of a function.
    It is also important to minimize the size of the package that must be downloaded.
    We will discuss how to use webpack to optimize JavaScript functions shortly.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 影响冷启动时间的第一个因素是必须下载到容器中的函数包的大小。这也是为什么分配更多内存和更多的网络IO吞吐量可以提高函数性能的一个原因。同时，最小化必须下载的包的大小也很重要。我们将在稍后讨论如何使用webpack来优化JavaScript函数。
- en: 'The next thing that impacts cold start times is the choice of language or runtime.
    Scripting languages, such as JavaScript and Python, do very little at startup
    and thus have very little impact on cold start times. Conversely, Java must do
    work at startup to load classes and prepare the JVM. As the number of classes
    increases, the impact on cold starts also increases. This leads to the next impact
    on cold start times: the choice of libraries and frameworks, such as **object
    relation mapping** (**ORM**) and dependency injection frameworks, and connection
    pooling libraries. These tend to do a lot of work at startup because they were
    designed to work in long running servers.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 影响冷启动时间的下一个因素是语言或运行时的选择。脚本语言，如JavaScript和Python，在启动时做的工作很少，因此对冷启动时间的影响很小。相反，Java必须在启动时执行工作来加载类和准备JVM。随着类数量的增加，对冷启动的影响也增加。这导致下一个影响冷启动时间的因素：库和框架的选择，例如**对象关系映射**（**ORM**）和依赖注入框架，以及连接池库。这些库和框架通常在启动时做大量工作，因为它们被设计成在长时间运行的服务器上工作。
- en: A common issue among FaaS developers using Java is the improvement of cold start
    times for functions written with Spring and Hibernate; however these tools were
    not designed for FaaS in the first place. I have programmed in Java for over 20
    years, from when it first appeared in the 1990s. I was skeptical about changing
    to JavaScript at first, but this cookbook is testament to its fit with cloud-native
    and serverless architecture. It is worth noting, however, that polyglot programming
    is the best policy; use the right programming language for a specific service,
    but understand the implications of it when using it with Faas.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 Java 编写的函数中，FaaS 开发者面临的一个常见问题是提高 Spring 和 Hibernate 函数的冷启动时间；然而，这些工具最初并不是为
    FaaS 设计的。我使用 Java 编程已经超过 20 年，从它在 1990 年代初出现时开始。起初我对转向 JavaScript 表示怀疑，但这个食谱证明了它与云原生和无服务器架构的契合度。然而，值得注意的是，多语言编程是最好的策略；为特定服务使用合适的编程语言，但了解在使用
    Faas 时其带来的影响。
- en: To minimize a JavaScript function's package size, we leverage webpack for the
    same reasons we use it to minimize downloads to browsers. Webpack performs tree
    shaking, which removes unused code to reduce package size. In the `serverless.yml`
    file, we include the `serverless-webpack` plugin and configure it to package functions
    individually. Packaging functions individually allows us to maximize the benefits
    of tree shaking. The `webpack.config.js` file further controls the packaging process.
    The `serverless-webpack` plugin provides the `slsw.lib.entries` utility so that
    we do not need to duplicate the function names to define all the `entry` points.
    We also turn off the `minimize` feature, which uglifies the code. We do this to
    avoid including source maps for debugging, which significantly increases the package
    size. We also exclude all of the external libraries in the `node_modules` folder
    and configure the plugin to `includeModules`, which includes those that are actually
    used as runtime. One special exception is the `aws-sdk` module, which is never
    included because it is already available in the function container. The end result
    is a lean function package that contains only what is necessary.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最小化 JavaScript 函数的包大小，我们利用 webpack，原因与我们在浏览器中用于最小化下载的原因相同。Webpack 执行摇树优化，移除未使用的代码以减小包大小。在
    `serverless.yml` 文件中，我们包括 `serverless-webpack` 插件并配置它以单独打包函数。单独打包函数使我们能够最大化摇树优化的好处。`webpack.config.js`
    文件进一步控制打包过程。`serverless-webpack` 插件提供了 `slsw.lib.entries` 工具，这样我们就不需要重复函数名称来定义所有的
    `entry` 点。我们还关闭了 `minimize` 功能，这会使代码变得难以阅读。我们这样做是为了避免包含源映射进行调试，这会显著增加包大小。我们还排除了
    `node_modules` 文件夹中的所有外部库，并配置插件为 `includeModules`，这包括那些实际用作运行时的库。一个特殊的例外是 `aws-sdk`
    模块，因为它已经在函数容器中可用，所以永远不会被包含。最终结果是包含仅必要内容的精简函数包。
- en: Batching requests
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批处理请求
- en: The design of a stream processor must account for the volume of data it will
    receive. The data should be processed in real time and the processor should not
    fall behind. The following recipe demonstrates how to use DynamoDB batch writes
    to help ensure sufficient throughput.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 流处理器的设计必须考虑到它将接收的数据量。数据应实时处理，处理器不应落后。以下菜谱演示了如何使用 DynamoDB 批写入来确保足够的吞吐量。
- en: Getting ready
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Before starting this recipe, you will need an AWS Kinesis Stream, such as the
    one created in the *Creating an event stream* recipe.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始此菜谱之前，您需要一个 AWS Kinesis Stream，例如在 *创建事件流* 菜谱中创建的那个。
- en: How to do it...
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Create the project from the following template:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Navigate to the `cncb-frp-batching` directory, `cd cncb-frp-batching`.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 `cncb-frp-batching` 目录，`cd cncb-frp-batching`。
- en: Review the file named `serverless.yml`.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看名为 `serverless.yml` 的文件。
- en: 'Review the file named `handler.js` with the following content:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看名为 `handler.js` 的文件，其内容如下：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Install the dependencies with `npm install`.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm install` 安装依赖项。
- en: Run the tests with `npm test -- -s $MY_STAGE`.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm test -- -s $MY_STAGE` 运行测试。
- en: Review the contents generated in the `.serverless` directory.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看在 `.serverless` 目录中生成的内容。
- en: Deploy the stack, `npm run dp:lcl -- -s $MY_STAGE`.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令部署堆栈，`npm run dp:lcl -- -s $MY_STAGE`。
- en: Review the stack and resources in the AWS Console.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 控制台中查看堆栈和资源。
- en: 'Invoke the `simulate` function with the following command:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令调用 `simulate` 函数：
- en: '[PRE5]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Take a look at the following `listener` function logs:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看以下 `listener` 函数日志：
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Finally, remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用 `npm run rm:lcl -- -s $MY_STAGE` 删除堆栈。
- en: How it works...
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: If a stream processor receives a batch of 1,000 events, will it execute faster
    if it has to make 1,000 requests to the database or just 100 requests? The answer
    of course depends on many variables, but in general, making fewer calls over the
    network is better because it minimizes the impact of network latency. To this
    end, services such as DynamoDB and Elasticsearchprovide APIs that allow batches
    of commands to be submitted in a single request. In this recipe, we use DynamoDB's
    `batchWrite` operation. To prepare a batch, we simply add a `batch` step to the
    pipeline and specify the `WRITE_BATCH_SIZE`. This performance improvement is very
    simple to add, but it is important to keep in mind that batching requests increase
    the rate at which DynamoDB's write capacity is consumed. Therefore, it is necessary
    to include the `WRITE_BATCH_SIZE` in the `ratelimit` calculation and increase
    the write capacity accordingly, as discussed in the *Implementing backpressure
    and rate limiting* recipe.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果流处理器接收一批1,000个事件，它是否需要向数据库发出1,000次请求或只需100次请求才能执行得更快？答案当然取决于许多变量，但一般来说，通过网络进行更少的调用更好，因为它最小化了网络延迟的影响。为此，像DynamoDB和Elasticsearch这样的服务提供了API，允许在单个请求中提交命令批处理。在这个配方中，我们使用DynamoDB的`batchWrite`操作。为了准备一个批处理，我们只需在管道中添加一个`batch`步骤并指定`WRITE_BATCH_SIZE`。这种性能提升非常简单添加，但重要的是要记住，批处理请求会增加DynamoDB写入容量消耗的速度。因此，有必要在`ratelimit`计算中包含`WRITE_BATCH_SIZE`并相应地增加写入容量，正如在*实现背压和速率限制*配方中讨论的那样。
- en: Another important thing to note is that these batch requests are not treated
    as a single transaction. Some commands may succeed and others may fail in a single
    request; it is therefore necessary to inspect the response for `UnprocessedItems`
    that needs to be resubmitted. In this recipe, we treat each batch as a **unit
    of work** (**uow**) and raise a fault for the entire batch, as discussed in the
    *Handling faults* recipe. This is a good, safe place to start before tuning the
    logic to retry only the commands that fail. Note that, ultimately, you would only
    raise a fault when the maximum number of retries has been attempted.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要注意的重要事项是，这些批处理请求不被视为单个事务。某些命令可能在单个请求中成功，而其他命令可能失败；因此，有必要检查响应中的`UnprocessedItems`，这些项目需要重新提交。在这个配方中，我们将每个批处理视为一个**工作单元**（**uow**）并引发整个批次的故障，正如在*处理故障*配方中讨论的那样。在调整逻辑以仅重试失败的命令之前，这是一个良好的、安全的地方。请注意，最终，你只有在尝试了最大重试次数后才会引发故障。
- en: Leveraging asynchronous non-blocking IO
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用异步非阻塞IO
- en: The design of a stream processor must account for the volume of data it will
    receive. The data should be processed in real-time and the processor should not
    fall behind. The following recipe demonstrates how to leverage asynchronous, non-blocking
    IO to process data in parallel to help ensure sufficient throughput.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 流处理器的设计必须考虑到它将接收的数据量。数据应实时处理，处理器不应落后。以下配方演示了如何利用异步、非阻塞IO并行处理数据，以确保足够的吞吐量。
- en: How to do it...
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create the project from the following template:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Navigate to the `cncb-frp-async-non-blocking-io` directory, `cd cncb-frp-async-non-blocking-io`.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到`cncb-frp-async-non-blocking-io`目录，`cd cncb-frp-async-non-blocking-io`。
- en: Review the file named `serverless.yml`.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查名为`serverless.yml`的文件。
- en: 'Review the file named `handler.js` with the following content:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查以下内容的`handler.js`文件：
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Install the dependencies with `npm install`.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`npm install`安装依赖项。
- en: Run the tests with `npm test -- -s $MY_STAGE`.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`npm test -- -s $MY_STAGE`运行测试。
- en: Review the contents generated in the `.serverless` directory.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查`.serverless`目录中生成的内容。
- en: Deploy the stack `npm run dp:lcl -- -s $MY_STAGE`.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署堆栈`npm run dp:lcl -- -s $MY_STAGE`。
- en: Review the stack and resources in the AWS Console.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在AWS控制台中检查堆栈和资源。
- en: 'Invoke the `simulate` function with the following command:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令调用`simulate`函数：
- en: '[PRE9]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Take a look at the following `listener` function logs:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看以下`listener`函数日志：
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Finally, remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，一旦你完成了`npm run rm:lcl -- -s $MY_STAGE`，请移除堆栈。
- en: How it works...
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: '*Asynchronous non-blocking IO* is extremely valuable for maximizing throughput.
    Without it, a stream processor will block and do nothing until an external call
    has completed. This recipe demonstrates how to use a `parallel` step to control
    the number of concurrent calls that can execute. As an example of the impact this
    can have, I once had a script that read from S3 and would take well over an hour
    to process, but once I added a `parallel` step with a setting of 16, the script
    executed in just five minutes. The improvement was so significant that Datadog
    contacted me, almost immediately, to see if we had a runaway process.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*异步非阻塞 I/O* 对于最大化吞吐量至关重要。没有它，流处理器将阻塞并无所事事，直到外部调用完成。这个配方演示了如何使用 `parallel` 步骤来控制可以执行的并发调用数量。作为一个例子，我曾经有一个从
    S3 读取的脚本，处理时间超过一个小时，但一旦我添加了一个设置为 16 的 `parallel` 步骤，脚本只用了五分钟就执行完毕。改进如此显著，Datadog
    几乎立即联系我，看看我们是否有失控的进程。'
- en: To allow concurrent calls, we simply add a `parallel` step to the pipeline after
    an external call step and specify the `PARALLEL` amount. This performance improvement
    is very simple to add, but it is important to keep in mind that parallel requests
    increase the rate at which DynamoDB's write capacity is consumed. It is therefore
    necessary to include the `PARALLEL` amount in the `ratelimit` calculation and
    increase the write capacity accordingly, as discussed in the *Implementing backpressure
    and rate limiting* recipe. Further performance improvements may be achieved by
    combining parallel execution with grouping and batching.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了允许并发调用，我们只需在外部调用步骤之后将 `parallel` 步骤添加到管道中，并指定 `PARALLEL` 数量。这种性能改进非常简单添加，但重要的是要记住，并行请求会增加
    DynamoDB 写入容量消耗的速度。因此，有必要在 `ratelimit` 计算中包含 `PARALLEL` 数量，并相应地增加写入容量，正如在 *实现背压和速率限制*
    配方中讨论的那样。通过结合并行执行、分组和批量，可以实现进一步的性能改进。
- en: Grouping events in stream processors
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流处理器中的事件分组
- en: The design of a stream processor must account for the volume of data it will
    receive. The data should be processed in real-time and the processor should not
    fall behind. The following recipe demonstrates how grouping related data in a
    stream can help ensure sufficient throughput.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 流处理器的设计必须考虑到它将接收的数据量。数据应实时处理，处理器不应落后。以下配方演示了如何通过在流中将相关数据分组来确保足够的吞吐量。
- en: How to do it...
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create the project from the following template:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Navigate to the `cncb-frp-grouping` directory, `cd cncb-frp-grouping`.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 `cncb-frp-grouping` 目录，`cd cncb-frp-grouping`。
- en: Review the file named `serverless.yml`.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看名为 `serverless.yml` 的文件。
- en: 'Review the file named `handler.js` with the following content:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看以下内容的 `handler.js` 文件：
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Install the dependencies with `npm install`.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm install` 安装依赖。
- en: Run the tests with `npm test -- -s $MY_STAGE`.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm test -- -s $MY_STAGE` 运行测试。
- en: Review the contents generated in the `.serverless` directory.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看在 `.serverless` 目录中生成的内容。
- en: Deploy the stack `npm run dp:lcl -- -s $MY_STAGE`.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署堆栈 `npm run dp:lcl -- -s $MY_STAGE`。
- en: Review the stack and resources in the AWS Console.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 控制台中查看堆栈和资源。
- en: 'Invoke the `simulate` function with the following command:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令调用 `simulate` 函数：
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Take a look at the following `listener` function logs:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看以下 `listener` 函数日志：
- en: '[PRE14]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Finally, remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，一旦完成，使用 `npm run rm:lcl -- -s $MY_STAGE` 删除堆栈。
- en: How it works...
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The *Batching requests* recipe demonstrates how to minimize the overhead of
    network IO by batching multiple unrelated commands into a single request. Another
    way to minimize network IO is to simply reduce the number of commands that need
    to be executed by grouping related events, and only executing a single command
    per grouping. For example, we might perform a calculation per group or just sample
    some of the data. In this recipe, we grouped events by the `partitionKey`. We
    can group events by any data in the events, but the best results are achieved
    when the grouping is relative to the partition key; this is because the partition
    key ensures that related events are sent to the same shard.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*批量请求* 配方演示了如何通过将多个不相关的命令批量到一个请求中，以最小化网络 I/O 的开销。另一种减少网络 I/O 的方法是简单地减少需要执行的命令数量，通过分组相关事件，并且每组只执行一个命令。例如，我们可能对每个组进行计算，或者只是采样一些数据。在这个配方中，我们根据
    `partitionKey` 对事件进行分组。我们可以根据事件中的任何数据进行分组，但最佳结果是在分组相对于分区键时实现；这是因为分区键确保相关事件被发送到同一个分片。'
- en: The `group` step makes it straightforward to reduce related events into groups
    based on the content of the events. For more complicated logic, a `reduce` step
    can be used directly. Next, we map each group to a unit of work (`groupUow`) that
    must succeed or fail together, as discussed in the *Handling faults* recipe. Finally,
    as shown in the preceding example, we write the `last` event of each group. Note
    from the logs that grouping results in significantly fewer writes; for this specific
    run, there were 4,500 events simulated and only 25 writes. Further performance
    improvements may be achieved by combining grouping with batching and parallel
    invocations.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`group` 步骤使得根据事件的内容将相关事件归组变得简单。对于更复杂的逻辑，可以直接使用 `reduce` 步骤。接下来，我们将每个组映射到一个必须成功或失败一起的工作单元（`groupUow`），正如在“处理故障”配方中讨论的那样。最后，如前例所示，我们写入每个组的最后一个事件。从日志中注意，分组导致写入次数显著减少；对于这次特定的运行，模拟了
    4,500 个事件，但只有 25 次写入。通过结合分组、批处理和并行调用，可以进一步提高性能。'
- en: Autoscaling DynamoDB
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动扩展 DynamoDB
- en: Cloud-native, with FaaS and serverless, minimize the amount of effort that is
    needed to scale the infrastructure that supports the service layer. However, we
    now need to focus on tuning the stream processors and minimize any throttling
    of the target data store. The following recipe demonstrates how to use DynamoDB
    autoscaling to help ensure that enough capacity is allocated to provide sufficient
    throughput and avoid throttling.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生，使用 FaaS 和无服务器架构，可以最小化支持服务层的基础设施扩展所需的努力。然而，我们现在需要关注调整流处理器并最小化对目标数据存储的任何限制。以下配方演示了如何使用
    DynamoDB 自动扩展来确保分配足够的容量以提供足够的吞吐量并避免限制。
- en: How to do it...
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create the project from the following template:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE15]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Navigate to the `cncb-dynamodb-autoscaling` directory, `cd cncb-dynamodb-autoscaling`.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 `cncb-dynamodb-autoscaling` 目录，`cd cncb-dynamodb-autoscaling`。
- en: 'Review the file named `serverless.yml` with the following content:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下内容审查名为 `serverless.yml` 的文件：
- en: '[PRE16]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Review the file named `handler.js`.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 审查名为 `handler.js` 的文件。
- en: Install the dependencies with `npm install`.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令安装依赖项：`npm install`。
- en: Run the tests with `npm test -- -s $MY_STAGE`.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令运行测试：`npm test -- -s $MY_STAGE`。
- en: Review the contents generated in the `.serverless` directory.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 审查 `.serverless` 目录中生成的内容。
- en: Deploy the stack `npm run dp:lcl -- -s $MY_STAGE`.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令部署堆栈：`npm run dp:lcl -- -s $MY_STAGE`。
- en: Review the stack and resources in the AWS Console.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 控制台中审查堆栈和资源。
- en: Invoke the `simulate` function multiple times with the following command to
    trigger autoscaling, `sls invoke -f simulate -r us-east-1 -s $MY_STAGE`.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令多次调用 `simulate` 函数以触发自动扩展：`sls invoke -f simulate -r us-east-1 -s $MY_STAGE`。
- en: 'Take a look at the following `listener` function logs with the following commands:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令查看以下“监听器”函数日志：
- en: '[PRE17]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Watch the Write capacity and Throttled write requests metrics on the DynamoDB
    Metrics tab in the AWS Console to see the autoscaling increment meet the demand,
    and then scale down at `night` and back up again in the `morning`.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 控制台的 DynamoDB 指标选项卡上查看“写入容量”和“受限写入请求数量”指标，以查看自动扩展增量是否满足需求，然后在夜间缩小规模，并在早晨再次扩大。
- en: Finally, remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，一旦完成，使用以下命令删除堆栈：`npm run rm:lcl -- -s $MY_STAGE`。
- en: How it works...
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the *Implementing backpressure and rate limiting* recipe, we see how it is
    important for stream processors to minimize throttling to maximize throughput.
    In this chapter, we have discussed techniques to optimize throughput, such as
    batching, grouping and asynchronous non-blocking requests, which all increase
    the data store capacity that must be allocated. However, while we do need to ensure
    that we have sufficient capacity, we also want to minimize wasted capacity, and
    autoscaling helps us achieve that. Autoscaling can address demand that grows over
    time to an expected peak, predictable demand, such as known events, and unpredictable
    demand.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在“实现背压和速率限制”配方中，我们看到流处理器最小化限制以最大化吞吐量的重要性。在本章中，我们讨论了优化吞吐量的技术，例如批处理、分组和异步非阻塞请求，这些都增加了必须分配的数据存储容量。然而，虽然我们需要确保有足够的容量，但我们还希望最小化浪费的容量，自动扩展帮助我们实现这一点。自动扩展可以解决随着时间的推移而增长到预期峰值的需求，如已知事件的可预测需求，以及不可预测的需求。
- en: In this recipe, we use the `serverless-dynamodb-autoscaling-plugin` to define
    the `autoscaling` policies on a per table basis. For both the `read` and `write`
    capacity, we specify the `minimum` and `maximum` capacity and the desired `usage`
    percentage. This `usage` percentage defines the amount of headroom we would like
    to have so that we can increase capacity early enough to help ensure that additional
    capacity is allocated before we reach 100 percent utilization and begin to throttle.
    We can also schedule autoscaling `actions` at specific times. In this recipe,
    we scale down at `night` to minimize waste and then scale back up in the `morning`
    before typical demand arrives.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们使用 `serverless-dynamodb-autoscaling-plugin` 在每个表的基础上定义 `autoscaling`
    策略。对于 `read` 和 `write` 容量，我们指定 `minimum` 和 `maximum` 容量和期望的 `usage` 百分比。这个 `usage`
    百分比定义了我们希望拥有的额外空间量，这样我们就可以提前增加容量，以确保在达到 100% 利用率并开始节流之前分配额外的容量。我们还可以在特定时间安排自动扩展
    `actions`。在本配方中，我们在夜间缩小规模以最小化浪费，然后在典型需求到来之前在早上恢复规模。
- en: Utilizing cache-control
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用缓存控制
- en: Autonomous, cloud-native services maintain their own materialized views and
    store this replicated data in highly-available and extremely performant cloud-native
    databases. When combined with the performance of an API Gateway and FaaS, it is
    typically unnecessary to add a traditional caching mechanism to achieve the desired
    performance for a user-facing, **backend-for-frontend** (**BFF**) service. That
    being said, this doesn't mean we shouldn't take advantage of the CDN, such as
    CloudFront, that is already wrapping a service. The following recipe will therefore
    show you how to utilize cache-control headers and leverage a CDN to improve performance
    for end users, as well as reduce the load on a service.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 自主、云原生服务维护自己的物化视图，并将复制的数据存储在高度可用且性能极优的云原生数据库中。当与 API 网关和 FaaS 的性能结合时，通常没有必要添加传统的缓存机制来实现面向用户的
    **前端后端**（**BFF**）服务的预期性能。但话虽如此，这并不意味着我们不应该利用已经包装服务的 CDN，例如 CloudFront。因此，以下配方将向您展示如何利用缓存控制头和利用
    CDN 来提高最终用户性能，同时减少对服务的负载。
- en: How to do it...
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create the project from the following template:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE18]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Navigate to the `cncb-cache-control` directory, `cd cncb-cache-control`.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 `cncb-cache-control` 目录，`cd cncb-cache-control`。
- en: Review the file named `serverless.yml`.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查名为 `serverless.yml` 的文件。
- en: 'Review the file named `handler.js` with the following content:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查名为 `handler.js` 的文件，其内容如下：
- en: '[PRE19]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Install the dependencies with `npm install`.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm install` 安装依赖项。
- en: Run the tests with `npm test`.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm test` 运行测试。
- en: Review the contents generated in the `.serverless` directory.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查 `.serverless` 目录中生成的内容。
- en: 'Deploy the stack, as follows:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下步骤部署堆栈：
- en: '[PRE20]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Deploying a CloudFront distribution can often take upwards of 20 minutes.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 部署 CloudFront 分发通常需要超过 20 分钟。
- en: Review the stack and resources in the AWS Console.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 控制台中检查堆栈和资源。
- en: 'Invoke the endpoint shown in the stack output with the following `curl` command
    multiple times to see the difference in performance for the cached results:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下 `curl` 命令多次调用堆栈输出中显示的端点，以查看缓存结果的性能差异：
- en: '[PRE21]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Finally, remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用 `npm run rm:lcl -- -s $MY_STAGE` 删除堆栈。
- en: How it works...
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this related recipe we focus on the service side of the equation. Cloud-native
    databases, such as DynamoDB, respond in the low 10s of milliseconds, and the overall
    latency across AWS API Gateway and AWS Lambda for a BFF service should typically
    execute in the low 100s of milliseconds. So long as the database capacity is set
    appropriately and throttling is minimized, it would be hard to make a noticeable
    improvement in this performance from the end user's perspective. The only way
    to really improve on this is to not have to make a request at all.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个相关的配方中，我们关注等式的服务端。云原生数据库，如 DynamoDB，响应时间在低 10 毫秒，AWS API 网关和 AWS Lambda 对于
    BFF 服务的整体延迟通常在低 100 毫秒。只要数据库容量设置得当且节流最小化，就很难从最终用户的角度观察到明显的性能提升。真正改善这一点的唯一方法就是根本不需要发出请求。
- en: This is a case where cloud-native can really be counter-intuitive. Traditionally,
    to improve performance, we would need to increase the amount of infrastructure
    and add an expensive caching layer between the code and the database. In other
    words, we would need to spend a lot more money to improve performance. However,
    in this recipe, we are leveraging an extremely low-cost edge cache to both improve
    performance and lower cost. By adding `Cache-Control` headers, such as `max-age`,
    to our responses, we can tell a browser not to repeat a request and also tell
    the CDN to reuse a response for other users. As a result, we reduce load on the
    API Gateway and the function and reduce the necessary capacity for the database,
    which reduces the cost for all of these services. It is also good practice to
    explicitly control which actions should store `no-cache`, for example the `PUT`,
    `POST`, and `DELETE` methods.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个云原生可能真正反直觉的案例。传统上，为了提高性能，我们需要增加基础设施的数量，并在代码和数据库之间添加一个昂贵的缓存层。换句话说，我们需要花费更多的钱来提高性能。然而，在这个菜谱中，我们利用了一个极低成本的边缘缓存，既提高了性能，又降低了成本。通过向我们的响应添加
    `Cache-Control` 头部，例如 `max-age`，我们可以告诉浏览器不要重复请求，并告诉 CDN 为其他用户重用响应。因此，我们减少了 API
    网关和函数的负载，并减少了数据库所需的容量，从而降低了所有这些服务的成本。明确控制哪些操作应该存储 `no-cache`，例如 `PUT`、`POST` 和
    `DELETE` 方法，也是一种良好的实践。
- en: Leveraging session consistency
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用会话一致性
- en: The design of a cloud-native frontend application must account for the fact
    that the system should be eventually consistent. For example, in a traditional
    frontend application, it is not uncommon to save data and then immediately execute
    a query to retrieve that same data. However, in an eventually consistent system,
    it is very likely that the query would not find the data on the first try. Instead,
    cloud-native frontends leverage the fact that single page applications can—at
    minimum—cache data locally for the duration of the user's session. This approach
    is referred to as session consistency. The following recipe demonstrates how to
    use the popular Apollo Client ([https://www.apollographql.com/client](https://www.apollographql.com/client))
    with ReactJS to improve perceived performance and reduce load on the system by
    implementing **session consistency**.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生前端应用程序的设计必须考虑到系统最终应该是一致的。例如，在一个传统的前端应用程序中，保存数据然后立即执行查询以检索相同的数据并不罕见。然而，在一个最终一致性的系统中，查询第一次尝试很可能找不到数据。相反，云原生前端利用了单页应用程序至少可以缓存数据的事实，以用户会话的持续时间为限。这种方法被称为会话一致性。以下菜谱演示了如何使用流行的
    Apollo Client ([https://www.apollographql.com/client](https://www.apollographql.com/client))
    与 ReactJS 结合使用，通过实现 **会话一致性** 来提高感知性能并减少系统负载。
- en: How to do it...
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Create the `service` and `spa` projects from the following templates:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建 `service` 和 `spa` 项目：
- en: '[PRE22]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Deploy the `service` with the following commands:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令部署 `service`：
- en: '[PRE23]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Navigate to the `cncb-session-consistency-spa` directory, `cd ../cncb-session-consistency-spa`.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 `cncb-session-consistency-spa` 目录，`cd ../cncb-session-consistency-spa`。
- en: 'Review the file named `src/index.js` with the following content and update
    the `uri` with the value output by the `service` stack, as follows:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看以下内容的 `src/index.js` 文件，并根据 `service` 堆栈输出的值更新 `uri`，如下所示：
- en: '[PRE24]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Review the file named `src/App.js` with the following content:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看名为 `src/App.js` 的文件，其内容如下：
- en: '[PRE25]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Install the dependencies with `npm install`.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm install` 安装依赖项。
- en: Run the app locally with `npm start`.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm start` 在本地运行应用程序。
- en: Browse to `http://localhost:3000`.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 浏览到 `http://localhost:3000`。
- en: Add and update several things to notice how the query results update.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加和更新一些内容，注意查询结果是如何更新的。
- en: 'Finally, remove the service stack once you are finished, as follows:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，一旦完成，按照以下方式删除服务堆栈：
- en: '[PRE26]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: How it works...
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we use a GraphQL BFF that is similar to the one we created in
    the *Implementing a GraphQL CRUD BFF* recipe. The focus here is on the frontend
    application, which we create with ReactJS and the Apollo Client, and specifically
    on how to cache our interactions with the service. First, we create the `ApolloClient`
    in the `src/index.js` file and initialize it with the endpoint for the service
    and, most importantly, the `InMemoryCache` object.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们使用了一个类似于我们在 *实现一个 GraphQL CRUD BFF* 菜谱中创建的 GraphQL BFF。这里的重点是前端应用程序，我们使用
    ReactJS 和 Apollo Client 创建它，并且特别关注如何缓存我们与服务的交互。首先，我们在 `src/index.js` 文件中创建 `ApolloClient`
    并用服务的端点和最重要的 `InMemoryCache` 对象初始化它。
- en: Next, we implement the user interface in the `src/App.js` file. The screen displays
    a list of things that are returned from the `things` query. The Apollo Client
    will automatically cache the results of the query. The mutation that updates the
    individual objects will automatically update the cache and thus trigger the screen
    to re-render. Note that adding new data requires more effort. The `AddThing` function
    uses the mutation's `update` feature to keep the cache in sync and trigger a re-render.
    The `update` function receives a reference to the cache and the object that was
    returned from the mutation. We then call `readQuery` to read the query from the
    cache, append the new object to the query results, and finally update the cache
    by calling `writeQuery`.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们在`src/App.js`文件中实现用户界面。屏幕显示从`things`查询返回的项目列表。Apollo客户端将自动缓存查询的结果。更新单个对象的突变将自动更新缓存并触发屏幕重新渲染。请注意，添加新数据需要更多努力。《AddThing》函数使用突变的`update`功能来保持缓存同步并触发重新渲染。`update`函数接收对缓存的引用和突变返回的对象。然后我们调用`readQuery`从缓存中读取查询，将新对象追加到查询结果中，并最终通过调用`writeQuery`来更新缓存。
- en: The end result is a very low-latency user experience because we are optimizing
    the number of requests that are performed, the amount of data that is transferred,
    and the amount of memory that is used. Most importantly, for both new and updated
    data, we are not throwing away anything that was created on the client side and
    replacing it with the same, retrieved values—after all, it is just unnecessary
    work. We already have the data, so why should we throw it away and retrieve it
    again? We also cannot be certain that the data is consistent on the service side—unless
    we perform a consistent read that is slower, costs more and, as stated, is unnecessary.
    Session consistency becomes even more valuable for multi-regional deployments
    in the event of a regional failure. As we will discuss in [Chapter 10](7ddedd13-fcee-4091-8566-02c9814cb782.xhtml),
    *Deploying to Multiple Regions*, eventually consistent, cloud-native systems are
    very tolerant of regional failure because they are already tolerant of eventual
    consistency, which can be more protracted during a failover. Therefore, session
    consistency helps make a regional failure transparent to the end user. For any
    data that must remain available during a regional failure, we can take session
    consistency a step further and persist the user session in local storage.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 最终结果是用户体验非常低延迟，因为我们正在优化执行请求的数量、传输的数据量以及使用的内存量。最重要的是，对于新数据和更新数据，我们不会丢弃客户端创建的任何内容，并用相同的检索值来替换它——毕竟，这只是不必要的劳动。我们已经有数据了，为什么还要丢弃它并再次检索呢？我们也无法确定服务端的数据是一致的——除非我们执行一个更慢、成本更高的连续读取，正如所述，这是不必要的。在区域故障的情况下，会话一致性对于多区域部署变得更加有价值。正如我们将在[第10章](7ddedd13-fcee-4091-8566-02c9814cb782.xhtml)“部署到多个区域”中讨论的，最终一致性的云原生系统对区域故障非常宽容，因为它们已经对最终一致性有容忍度，这在故障转移期间可能会更加持久。因此，会话一致性有助于使区域故障对最终用户透明。对于在区域故障期间必须保持可用的任何数据，我们可以将会话一致性进一步推进，并将用户会话持久化到本地存储。
