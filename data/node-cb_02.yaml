- en: Chapter 2. Exploring the HTTP Object
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章。探索HTTP对象
- en: 'In this chapter we will cover:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖：
- en: Processing POST data
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理POST数据
- en: Handling file uploads
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理文件上传
- en: Using Node as an HTTP client
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Node作为HTTP客户端
- en: Implementing download throttling
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现下载节流
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In the previous chapter, we used the `http` module to create a web server. Now
    we're going to look into some associated use cases beyond simply pushing content
    from server to client. The first three recipes will explore how to receive data
    via client-initiated HTTP POST (and PUT) requests, and in the final recipe we'll
    demonstrate how to throttle a stream of outbound data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们使用`http`模块创建了一个Web服务器。现在我们将探讨一些与简单地从服务器向客户端推送内容之外的一些相关用例。前三个示例将探讨如何通过客户端发起的HTTP
    POST（和PUT）请求接收数据，最后一个示例将演示如何对出站数据流进行节流。
- en: Processing POST data
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理POST数据
- en: If we want to be able to receive POST data, we have to instruct our server on
    how to accept and handle a POST request. In PHP we could access our POST values
    seamlessly with `$_POST['fieldname']`, because it would block until an array value
    was filled. By contrast, Node provides low-level interaction with the flow of
    HTTP data allowing us to interface with the incoming message body as a stream,
    leaving it entirely up to the developer to turn that stream into usable data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要接收POST数据，我们必须指示服务器如何接受和处理POST请求。在PHP中，我们可以无缝访问我们的POST值`$_POST['fieldname']`，因为它会阻塞，直到数组值被填充。相比之下，Node提供了与HTTP数据流的低级交互，允许我们与传入的消息体接口，完全由开发人员将该流转换为可用数据。
- en: Getting ready
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Let''s create a `server.js` file ready for our code, and an HTML file called
    `form.html`, containing the following code:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个准备好我们的代码的`server.js`文件，以及一个名为`form.html`的HTML文件，其中包含以下代码：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Tip
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: For our purposes, we'll place `form.html` in the same folder as `server.js`,
    though this is not generally a recommended practice. Usually, we should place
    our public code in a separate folder from our server code.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的目的，我们将把`form.html`放在与`server.js`相同的文件夹中，尽管这通常不是推荐的做法。通常，我们应该将我们的公共代码放在与服务器代码不同的文件夹中。
- en: How to do it...
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: We'll provision our server for both GET and POST requests. Let's start with
    GET by requiring the `http` module and loading `form.html` for serving through
    `createServer:`
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为我们的服务器提供GET和POST请求。让我们从GET开始，通过要求`http`模块并通过`createServer`加载`form.html`进行服务：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We are synchronously loading `form.html` at initialization time instead of
    accessing the disk on each request. If we navigate to `localhost:8080`, we''ll
    be presented with a form. However, if we fill out our form nothing happens because
    we need to handle POST requests:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在初始化时同步加载`form.html`，而不是在每个请求上访问磁盘。如果我们导航到`localhost:8080`，我们将看到一个表单。但是，如果我们填写我们的表单，什么也不会发生，因为我们需要处理POST请求：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Once the form is completed and submitted, the browser and console will output
    the raw query string sent from the client. Converting `postData` into an object
    provides an easy way to interact with and manipulate the submitted information.
    The `querystring` module has a `parse` method which transforms query strings into
    objects, and since form submission arrives in query string format, we can use
    it to objectify our data as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦表单完成并提交，浏览器和控制台将输出从客户端发送的原始查询字符串。将`postData`转换为对象提供了一种与提交的信息进行交互和操作的简单方法。`querystring`模块有一个`parse`方法，可以将查询字符串转换为对象，由于表单提交以查询字符串格式到达，我们可以使用它将我们的数据转换为对象，如下所示：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Notice the `util` module. We require it to use its `inspect` method for a simple
    way to output our `postDataObject` to the browser.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`util`模块。我们需要它来使用其`inspect`方法，以简单地将我们的`postDataObject`输出到浏览器。
- en: Finally, we're going to protect our server from memory overload exploits.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将保护我们的服务器免受内存超载攻击。
- en: Tip
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Protecting a POST server**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**保护POST服务器**'
- en: V8 (and therefore Node) has virtual memory limitations, based upon the processor
    architecture and operating system constraints. These limitations far exceed the
    demands of most use cases. Nevertheless, if we don't restrict the amount of data
    our POST server will accept, we could leave ourselves open for a type of Denial
    of Service attack. Without protection, an extremely large POST request could cause
    our server to slow down significantly or even crash.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: V8（因此Node）具有基于处理器架构和操作系统约束的虚拟内存限制。这些限制远远超出了大多数用例的需求。然而，如果我们不限制我们的POST服务器将接受的数据量，我们可能会使自己暴露于一种拒绝服务攻击。如果没有保护，一个非常大的POST请求可能会导致我们的服务器显著减速甚至崩溃。
- en: To achieve this, we'll set a variable for the maximum acceptable data size and
    check it against the growing length of our `postData` variable.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们将为最大可接受的数据大小设置一个变量，并将其与我们的“postData”变量不断增长的长度进行比较。
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: How it works...
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Once we know a POST request has been made of our server (by checking `request.method)`,
    we aggregate our incoming data into our `postData` variable via the `data` event
    listener on the `request` object. However, if we find that the submitted data
    exceeds our `maxData` limit, we will clear our `postData` variable and `pause`
    the incoming stream preventing any further data arriving from the client. Using
    `stream.destroy` instead of `stream.pause` seems to interfere with our response
    mechanism. Once a stream has been paused for a while it is automatically removed
    from memory by v8's garbage collector.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们知道服务器已经发出了POST请求（通过检查`request.method`），我们通过`request`对象上的`data`事件监听器将我们的传入数据聚合到我们的`postData`变量中。但是，如果我们发现提交的数据超过了我们的`maxData`限制，我们将清除我们的`postData`变量，并`pause`传入流，阻止客户端进一步传入数据。使用`stream.destroy`而不是`stream.pause`似乎会干扰我们的响应机制。一旦流暂停了一段时间，它就会被v8的垃圾收集器自动从内存中删除。
- en: 'Then we send a `413 Request Entity Too Large` HTTP header. In the `end` event
    listener, as long as `postData` hasn''t been cleared for exceeding `maxData` (or
    wasn''t blank in the first place), we use `querystring.parse` to turn our POST
    message body into an object. From this point, we could perform any number of interesting
    activities: manipulate, analyze, pass it to a database, and so on. However, for
    the example, we simply output `postDataObject` to the browser and `postData` to
    the console.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们发送一个`413 Request Entity Too Large`的HTTP头。在`end`事件监听器中，只要`postData`没有因超过`maxData`（或者一开始就不是空的）而被清除，我们就使用`querystring.parse`将我们的POST消息体转换成一个对象。从这一点开始，我们可以执行任意数量的有趣活动：操作、分析、传递到数据库等等。然而，对于这个例子，我们只是将`postDataObject`输出到浏览器，将`postData`输出到控制台。
- en: There's more...
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: If we want our code to look a little more elegant, and we're not so concerned
    about handling POST data as a stream, we can employ a user land (non-core) module
    to get a little sugar on our syntax.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望我们的代码看起来更加优雅，而且我们不太关心处理POST数据流，我们可以使用一个用户自定义（非核心）模块来为我们的语法增添一些便利。
- en: Accessing POST data with connect.bodyParser
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用connect.bodyParser访问POST数据
- en: Connect is an excellent middleware framework for Node providing a method framework
    that assimilates a higher level of abstraction for common server tasks. Connect
    is actually the basis of the Express web framework, which will be discussed In
    [Chapter 6](ch06.html "Chapter 6. Accelerating Development with Express"), *Accelerating
    Development with Express*
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Connect是Node的一个出色的中间件框架，提供了一个方法框架，为常见的服务器任务提供了更高级别的抽象。Connect实际上是Express Web框架的基础，将在[第6章](ch06.html
    "第6章 使用Express加速开发")中讨论，*使用Express加速开发*
- en: One piece of middleware that comes bundled with Connect is `bodyParser`. By
    chaining `connect.bodyParser` to a normal callback function, we suddenly have
    access to the POST data via `request.body` (when data is sent by the POST request
    it is held in the message body). `request.body` turns out to be exactly the same
    object as `postDataObject` we generated in our recipe.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Connect捆绑的一个中间件是`bodyParser`。通过将`connect.bodyParser`链接到普通的回调函数，我们突然可以通过`request.body`访问POST数据（当数据通过POST请求发送时，它被保存在消息体中）。结果，`request.body`与我们在配方中生成的`postDataObject`完全相同。
- en: 'First, let''s make sure we have Connect installed:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们确保已安装Connect：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We require `connect` in place of `http` since it provides us with the `createServer`
    capabilities. To access the `createServer` method, we can use `connect.createServer`,
    or the shorthand version, which is simply `connect`. Connect allows us to combine
    multiple pieces of middleware together by passing them in as parameters to the
    `createServer` method. Here''s how to implement similar behavior, as in the recipe
    using Connect:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要使用`connect`来代替`http`，因为它为我们提供了`createServer`的功能。要访问`createServer`方法，我们可以使用`connect.createServer`，或者简写版本，即`connect`。Connect允许我们通过将它们作为参数传递给`createServer`方法来将多个中间件组合在一起。以下是如何使用Connect实现类似的行为，就像在配方中一样：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Notice we are no longer using the `http` module directly. We pass `connect.limit`
    in as our first parameter to achieve the same `maxData` restriction implemented
    in the main example.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们不再直接使用`http`模块。我们将`connect.limit`作为第一个参数传递，以实现主要示例中实现的相同的`maxData`限制。
- en: Next, we pass in `bodyParser`, allowing `connect` to retrieve our POST data
    for us, objectifying the data into `request.body`. Finally, there's our callback
    function, with all the former POST functionality stripped out except the code
    to echo our data object (which is now `request.body)` to console and browser.
    This is where we deviate slightly from our original recipe.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们传入`bodyParser`，允许`connect`为我们检索POST数据，将数据对象化为`request.body`。最后，有我们的回调函数，除了用于将我们的数据对象（现在是`request.body`）回显到控制台和浏览器的代码之外，我们剥离了所有以前的POST功能。这是我们与原始配方略有不同的地方。
- en: 'In the recipe we return the raw `postData` to the console, though we return
    the `request.body` object here. To output raw data with Connect would either take
    pointless deconstruction of our object to reassemble the raw query string or an
    extension of the `bodyParser` function. This is the tradeoff with using third-party
    modules: we can only easily interact with information the module author expects
    us to interact with.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在配方中，我们将原始的`postData`返回到控制台，而在这里我们返回`request.body`对象。要使用Connect输出原始数据，要么需要无意义地拆解我们的对象以重新组装原始查询字符串，要么需要扩展`bodyParser`函数。这就是使用第三方模块的权衡之处：我们只能轻松地与模块作者期望我们交互的信息进行交互。
- en: 'Let''s look under the hood for a moment. If we fire up an instance of `node`
    without any arguments, we can access the REPL (Read-Eval-Print-Loop) which is
    the Node command-line environment. In the REPL, we can write:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下内部情况。如果我们启动一个没有任何参数的`node`实例，我们可以访问REPL（Read-Eval-Print-Loop），这是Node的命令行环境。在REPL中，我们可以写：
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: If we look at the output, we'll see its `connect.bodyParser` function code and
    should be able to easily identify the essential elements from our recipe at work
    in the `connect.bodyParser` code.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看输出，我们会看到它的`connect.bodyParser`函数代码，并且应该能够轻松地从`connect.bodyParser`代码中识别出我们的配方中的基本元素。
- en: See also
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: '*Handling file uploads* discussed in this chapter'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*处理文件上传*在本章中讨论'
- en: '*Browser-server transmission via AJAX* discussed In [Chapter 3](ch03.html "Chapter 3. Working
    with Data Serialization"), *Working with Data Serialization*'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过AJAX进行浏览器-服务器传输*在[第3章](ch03.html "第3章 数据序列化处理")中讨论，*数据序列化处理*'
- en: '*Initializing and using a session* discussed In [Chapter 6](ch06.html "Chapter 6. Accelerating
    Development with Express"), *Accelerating Development with Express*'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*初始化和使用会话*在[第6章](ch06.html "第6章 使用Express加速开发")中讨论，*使用Express加速开发*'
- en: Handling file uploads
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理文件上传
- en: We cannot process an uploaded file in the same way we process other POST data.
    When a file input is submitted in a form, the browser processes the file into
    a **multipart message.**
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法像处理其他POST数据那样处理上传的文件。当文件输入以表单形式提交时，浏览器会将文件处理成**多部分消息**。
- en: Multipart was originally developed as an email format allowing multiple pieces
    of mixed content to be combined into one message. If we intuitively attempted
    to receive the upload as a stream and write it to a file, we would have a file
    filled with multipart data instead of the file or files themselves. We need a
    multipart parser, the writing of which is more than a recipe can cover. So instead
    we'll be using the well-known and battle-tested `formidable` module to convert
    our upload data into files.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 多部分最初是作为一种电子邮件格式开发的，允许将多个混合内容组合成一条消息。如果我们直觉地尝试接收上传作为流并将其写入文件，我们将得到一个充满多部分数据而不是文件本身的文件。我们需要一个多部分解析器，其编写超出了一篇食谱的范围。因此，我们将使用众所周知且经过考验的`formidable`模块将我们的上传数据转换为文件。
- en: Getting ready
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Let's create a new `uploads` directory for storing uploaded files and get ready
    to make modifications to our `server.js` file from the previous recipe.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为存储上传文件创建一个新的`uploads`目录，并准备修改我们上一个食谱中的`server.js`文件。
- en: 'We''ll also need to install `formidable` as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要安装`formidable`，如下所示：
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, we''ll make some changes to our `form.html` from the last recipe:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将对上一个食谱中的`form.html`进行一些更改：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We've included an `enctype` attribute of `multipart/form-data` to signify to
    the browser that the form will contain upload data and we've replaced the text
    inputs with file inputs.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经包含了一个`enctype`属性为`multipart/form-data`，以向浏览器表示表单将包含上传数据，并用文件输入替换了文本输入。
- en: How to do it...
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作步骤...
- en: 'Let''s see what happens when we use our modified form to upload a file to the
    server from the last recipe. Let''s upload `form.html` itself as our file:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看当我们使用修改后的表单从上一个食谱中上传文件到服务器时会发生什么。让我们上传`form.html`本身作为我们的文件：
- en: '![How to do it...](img/7188-02-1.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![操作步骤...](img/7188-02-1.jpg)'
- en: Our POST server simply logs the raw HTTP message body to the console, which
    in this case is multipart data. We had two file inputs on the form. Though we
    only uploaded one file, the second input is still included in the multipart request.
    Each file is separated by a predefined boundary that is set in a secondary attribute
    of the `Content-Type` HTTP headers. We'll need to use `formidable` to parse this
    data, extracting each file contained therein.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的POST服务器只是将原始的HTTP消息主体记录到控制台中，这种情况下是多部分数据。我们在表单上有两个文件输入。虽然我们只上传了一个文件，但第二个输入仍然包含在多部分请求中。每个文件都由`Content-Type`HTTP头的次要属性中设置的预定义边界分隔。我们需要使用`formidable`来解析这些数据，提取其中包含的每个文件。
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Our POST server has now become an upload server.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的POST服务器现在已经成为一个上传服务器。
- en: How it works...
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: We create a new instance of the `formidable IncomingForm` class and tell it
    where to upload files. In order to provide feedback to the user, we can listen
    to our `incoming` instance. The `IncomingForm` class emits its own higher level
    events, so rather than listening to the `request` object for events and processing
    data as it comes, we wait for `formidable` to parse the files out of the multipart
    message and then notify us through its custom `file` event.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建一个`formidable IncomingForm`类的新实例，并告诉它在哪里上传文件。为了向用户提供反馈，我们可以监听我们的`incoming`实例。`IncomingForm`类会发出自己的高级事件，因此我们不是监听`request`对象的事件并在数据到来时处理数据，而是等待`formidable`解析多部分消息中的文件，然后通过其自定义的`file`事件通知我们。
- en: 'The `file` event callback provides us with two parameters: `field` and `file`.
    The `file` parameter is an object containing information about the uploaded file.
    We use this to filter out empty files (usually caused by empty input fields) and
    grab the filename which we show to users as confirmation. When `formidable` has
    finished parsing the multipart message, it sends an `end` event in which we end
    the response.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`file`事件回调为我们提供了两个参数：`field`和`file`。`file`参数是一个包含有关上传文件信息的对象。我们使用这个来过滤空文件（通常是由空输入字段引起的），并获取文件名，然后向用户显示确认。当`formidable`完成解析多部分消息时，它会发送一个`end`事件，我们在其中结束响应。'
- en: There's more...
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: We can post more than simple form fields and values from a browser. Let's take
    a look at transferring files from browser to server.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从浏览器中发布不仅仅是简单的表单字段和值。让我们来看看如何从浏览器传输文件到服务器。
- en: Using formidable to accept all POST data
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用formidable接受所有POST数据
- en: '`formidable` doesn''t just handle uploaded files, it will also process general
    POST data. All we have to do is add a listener for the `field` event to process
    forms containing both files and user data.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`formidable`不仅处理上传的文件，还会处理一般的POST数据。我们只需要为`field`事件添加一个监听器，以处理同时包含文件和用户数据的表单。'
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: There's no need to manually implement field data size limits as `formidable`
    takes care of this for us. However, we can change the defaults with `incoming.maxFieldsSize`,
    which allows us to limit the total byte count for the sum of all fields. This
    limit doesn't apply to file uploads.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 无需手动实现字段数据大小限制，因为`formidable`会为我们处理这些。但是，我们可以使用`incoming.maxFieldsSize`更改默认设置，这允许我们限制所有字段的总字节数。这个限制不适用于文件上传。
- en: Preserving filenames with formidable
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用formidable保留文件名
- en: 'When `formidable` places our files into the `uploads` directory, it assigns
    them a name consisting of a randomly generated hexadecimal number. This prevents
    files of the same name from being overwritten. But what if we want to know which
    files are which and yet still retain the unique filename advantage? We can alter
    the way `formidable` names each file during its `fileBegin` event as shown in
    the following code:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当`formidable`将我们的文件放入`uploads`目录时，它会为它们分配一个由随机生成的十六进制数字组成的名称。这可以防止同名文件被覆盖。但是如果我们想知道哪些文件是哪些，同时保留唯一文件名的优势呢？我们可以在`fileBegin`事件中修改`formidable`命名每个文件的方式，如下面的代码所示：
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We've appended the original filename onto the end of the random filename assigned
    by `formidable`, separating them with a dash. Now we can easily identify our files.
    However, for many scenarios this may not be necessary as we would likely be outputting
    file information to a database and cross referencing it to randomly generated
    names.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将原始文件名附加到`formidable`分配的随机文件名的末尾，并用破折号分隔它们。现在我们可以轻松地识别我们的文件。然而，对于许多情况来说，这可能并不是必要的，因为我们可能会将文件信息输出到数据库，并将其与随机生成的名称进行交叉引用。
- en: Uploading via PUT
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过PUT上传
- en: It's also possible to upload files via an HTTP PUT request. While we can only
    send one file per request, we don't need to do any parsing on the server side
    since the file will simply stream directly to our server, which means less server-side
    processing overhead. It would be magnificent if we could achieve this by changing
    our form's `method` attribute from `POST` to `PUT` but alas, no. However, thanks
    to the up and coming `XMLHttpRequest Level 2` (xhr2), we can now transfer binary
    data via JavaScript in some browsers (see [http://www.caniuse.com/#search=xmlhttprequest%202)](http://www.caniuse.com/#search=xmlhttprequest%202)).
    We grab a file pointer using a `change` event listener on the input file element,
    then we open a PUT request and send the file. The following is for use in `form.html`,
    which we'll save as `put_upload_form.html:`
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以通过HTTP PUT请求上传文件。虽然我们每次只能发送一个文件，但在服务器端我们不需要进行任何解析，因为文件将直接流向我们的服务器，这意味着更少的服务器端处理开销。如果我们可以通过将表单的`method`属性从`POST`更改为`PUT`来实现这一点就太好了，但遗憾的是不行。然而，由于即将到来的`XMLHttpRequest
    Level 2`（xhr2），我们现在可以在一些浏览器中通过JavaScript传输二进制数据（参见[http://www.caniuse.com/#search=xmlhttprequest%202)](http://www.caniuse.com/#search=xmlhttprequest%202)）。我们使用文件元素上的`change`事件监听器来获取文件指针，然后打开一个PUT请求并发送文件。以下是用于`form.html`的代码，我们将其保存为`put_upload_form.html`：
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`Id` is added to the form and file inputs while `method` and `enctype` attributes
    have been removed. We''re using just one file element because we can only send
    one file per request, although the example could be extended to asynchronously
    stream multiple files to our server at once.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在表单和文件输入中添加了`Id`，同时删除了`method`和`enctype`属性。我们只使用一个文件元素，因为我们只能在一个请求中发送一个文件，尽管示例可以扩展为异步流式传输多个文件到我们的服务器。
- en: 'Our script attaches a `change` listener to the file input element. When the
    user selects a file we are able to capture a pointer to the file. As the form
    is submitted, we prevent default behavior, check if a file is selected, initialize
    an `xhr` object, open a PUT request to our server, set a custom header so we can
    grab the filename later, and send the file to our server. Our server looks like
    the following code:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的脚本为文件输入元素附加了一个`change`监听器。当用户选择文件时，我们能够捕获文件的指针。在提交表单时，我们阻止默认行为，检查是否选择了文件，初始化`xhr`对象，向我们的服务器打开一个PUT请求，设置自定义标头以便稍后获取文件名，并将文件发送到我们的服务器。我们的服务器代码如下：
- en: '[PRE14]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Our PUT server follows a similar pattern to the simple POST server in the *Processing
    POST data* recipe. We listen to the data event and piece the chunks together.
    However, rather than string concatenate our data, we must throw our chunks into
    a buffer because a buffer can handle any data type including binary, whereas a
    string object will always coerce non-string data into string format. This changes
    the underlying binary resulting in corrupted files. Once the `end` event has triggered,
    we generate a random file name similar to the naming convention of `formidable`
    and write the file to our `uploads` folder.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的PUT服务器遵循了*处理POST数据*中简单POST服务器的类似模式。我们监听数据事件并将块拼接在一起。然而，我们不是将我们的数据串联起来，而是必须将我们的块放入缓冲区，因为缓冲区可以处理包括二进制在内的任何数据类型，而字符串对象总是将非字符串数据强制转换为字符串格式。这会改变底层二进制，导致文件损坏。一旦触发了`end`事件，我们会生成一个类似于`formidable`命名约定的随机文件名，并将文件写入我们的`uploads`文件夹。
- en: Note
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: This *Uploading via PUT* demonstration will not work in older browsers, so an
    alternative fall back should be provided in a production environment. Browsers
    that will support this method are IE 10 and above, Firefox, Chrome, Safari, iOS
    5+ Safari, and Android browsers. However, due to browser vendors differing implementations
    of the same functionality, the example may need some tweaking for cross-browser
    compatibility.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这个*通过PUT上传*的演示在旧版浏览器中无法工作，因此在生产环境中应提供替代方案。支持此方法的浏览器包括IE 10及以上版本、Firefox、Chrome、Safari、iOS
    5+ Safari和Android浏览器。然而，由于浏览器供应商对相同功能的实现不同，示例可能需要一些调整以实现跨浏览器兼容性。
- en: See also
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: '*Sending email discussed in* [Chapter 8](ch08.html "Chapter 8. Integrating
    Network Paradigms"), *Integrating Network Paradigms*'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在第8章中讨论的发送电子邮件* [第8章](ch08.html "第8章。集成网络范式")，*集成网络范式*'
- en: '*Using Node as an HTTP client* discussed in this chapter.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在本章中讨论的将Node用作HTTP客户端*。'
- en: Using Node as an HTTP client
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Node作为HTTP客户端
- en: The HTTP object doesn't just provide server capabilities, it also affords us
    with client functionality. In this task, we're going to use `http.get` with `process`
    to fetch external web pages dynamically via the command line.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP对象不仅提供了服务器功能，还为我们提供了客户端功能。在这个任务中，我们将使用`http.get`和`process`通过命令行动态获取外部网页。
- en: Getting ready
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: We are not creating a server, so in the naming convention we should use a different
    name for our new file, let's call it `fetch.js`.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不是在创建服务器，因此在命名约定中，我们应该为我们的新文件使用不同的名称，让我们称之为`fetch.js`。
- en: How to do it...
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: '`http.request` allows us to make requests of any kind (for example, GET, POST,
    DELETE, OPTION, and so on), but for GET requests we can use the short-hand `http.get`
    method as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`http.request`允许我们发出任何类型的请求（例如GET、POST、DELETE、OPTION等），但对于GET请求，我们可以使用`http.get`方法进行简写，如下所示：'
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Essentially we're done.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上我们已经完成了。
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If we run the preceding command, our console will output the HTML of `nodejs.org`.
    However, let''s pad it out a bit with some interactivity and error handling as
    shown in the following code:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们运行上述命令，我们的控制台将输出`nodejs.org`的HTML。然而，让我们用一些交互和错误处理来填充它，如下所示的代码所示：
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now we can use our script like this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以像这样使用我们的脚本：
- en: '[PRE18]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: How it works...
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: '`http.get` takes an object which defines the criteria of our desired request.
    We defined a variable called `urlOpts` for this purpose and set our host to [www.nodejs.org](http://www.nodejs.org).
    We use the `process.argv` property to check if a web address has been specified
    via the command line. Like `console, process` is a global variable that is always
    available within a Node runtime environment. `process.argv[2]` is the third command-line
    argument, with `node` and `fetch.js` being allocated to `[0]` and `[1]` respectively.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`http.get`接受一个定义我们所需请求条件的对象。我们为此目的定义了一个名为`urlOpts`的变量，并将我们的主机设置为[www.nodejs.org](http://www.nodejs.org)。我们使用`process.argv`属性检查是否通过命令行指定了网址。像`console`一样，`process`是一个在Node运行环境中始终可用的全局变量。`process.argv[2]`是第三个命令行参数，`node`和`fetch.js`分别分配给`[0]`和`[1]`。'
- en: If `process.argv[2]` exists (that is, if an address has been specified) we append
    `http://`. If it isn't there (`url.parse` requires it), then replace the object
    in our default `urlOpts` with the output from `url.parse`. Happily, `url.parse`
    returns an object with the same properties `http.get` requires.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`process.argv[2]`存在（也就是说，如果已经指定了地址），我们会追加`http://`。如果不存在（`url.parse`需要它），则用`url.parse`的输出替换我们默认的`urlOpts`中的对象。幸运的是，`url.parse`返回一个具有与`http.get`所需属性相同的对象。
- en: As a client, we are interacting with the server's response to us, rather than
    the client's request from us. So inside the `http.get` callback, we listen for
    the `data` event on `response` instead of (as with our server examples) `request`.
    As the `response` data stream arrives, we output the chunks to the console.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 作为客户端，我们与服务器对我们的响应进行交互，而不是与客户端对我们的请求进行交互。因此，在`http.get`回调中，我们监听`response`上的`data`事件，而不是（与我们的服务器示例一样）`request`。随着`response`数据流的到达，我们将块输出到控制台。
- en: There's more...
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Let's explore some of the possibilities of the underlying `http.request` method
    of `http.get`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索一下`http.get`的底层`http.request`方法的一些可能性。
- en: Sending POST requests
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 发送POST请求
- en: We'll need to fire up our `server.js` app from the *Processing POST data* recipe
    to receive our POST requests. Let's make a new file and call it `post.js`, which
    we'll use to send POST requests to our POST server.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要启动我们的`server.js`应用程序来接收我们的POST请求。让我们创建一个新文件，将其命名为`post.js`，我们将使用它来向我们的POST服务器发送POST请求。
- en: '[PRE19]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As we're using the more general `http.request`, we've had to define our HTTP
    verb in the `urlOpts` variable. Our `urlOpts` variable also specifies the server
    as `localhost:8080` (we must ensure that our POST server is running in order for
    this code to work).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用的是更通用的`http.request`，我们必须在`urlOpts`变量中定义我们的HTTP动词。我们的`urlOpts`变量还指定了服务器为`localhost:8080`（我们必须确保我们的POST服务器正在运行，以便此代码能够工作）。
- en: As before, we set up an event listener in our callback for `data` on the `response`
    object. `http.request` returns a `clientRequest` object which we load into a variable
    called `request`. This is a newly declared variable, which holds the returned
    `clientRequest` object from our `http.request` method.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 与以前一样，我们在`response`对象的`data`回调中设置了一个事件监听器。`http.request`返回一个`clientRequest`对象，我们将其加载到一个名为`request`的变量中。这是一个新声明的变量，它保存了从`http.request`方法返回的`clientRequest`对象。
- en: 'After our event listeners, we loop through the command-line arguments using
    the Ecmascript 5 `forEach` method (which is safe to use in Node but not yet in
    browsers). In running this script, `node` and `post.js` would be the 0th and 1st
    arguments, so we check that our array index is greater than 1 before sending any
    arguments as POST data. We use `request.write` to send data similar to how we
    would use `response.write` if we were building a server. Even though it uses a
    callback, `forEach` is not asynchronous (it blocks until completion), so only
    after every element is processed is our POST data written and our request ended.
    This is how we use it:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的事件监听器之后，我们使用Ecmascript 5的`forEach`方法循环遍历命令行参数（在Node中是安全的，但在浏览器中还不是）。在运行此脚本时，`node`和`post.js`将分别是第0个和第1个参数，因此我们在发送任何参数作为POST数据之前检查数组索引是否大于1。我们使用`request.write`发送数据，类似于我们在构建服务器时使用`response.write`。尽管它使用了回调，但`forEach`不是异步的（它会阻塞直到完成），因此只有在处理完每个元素后，我们的POST数据才会被写入，我们的请求才会结束。这是我们使用它的方式：
- en: '[PRE20]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Multipart file upload as a client
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作为客户端的多部分文件上传
- en: We'll use our upload server from *Handling File Uploads* to receive the files
    from our uploading client. To achieve this, we have to deal with the multipart
    data format. To inform a server of the client's intentions of sending multipart
    data, we set the `content-type` header to `multipart/form-data` with an additional
    attribute called `boundary`, which is a custom named delimiter, separating files
    in the multipart data.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用*处理文件上传*中的上传服务器来接收来自我们上传客户端的文件。为了实现这一点，我们必须处理多部分数据格式。为了告知服务器客户端打算发送多部分数据，我们将`content-type`头设置为`multipart/form-data`，并添加一个名为`boundary`的额外属性，这是一个自定义命名的分隔符，用于分隔多部分数据中的文件。
- en: '[PRE21]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We've required the `fs` module here too as we'll be needing that later to load
    our files.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里也需要`fs`模块，因为我们稍后将需要加载我们的文件。
- en: 'We''ve set our `boundary` to the current Unix time (milliseconds since midnight,
    January 1, 1970). We won''t need `boundary` again in this format, so let''s update
    it with the required multipart double dash (`--`) prefix and set up our `http.request`
    call:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将我们的`boundary`设置为当前的Unix时间（1970年1月1日午夜以来的毫秒数）。我们不需要再以这种格式使用`boundary`，所以让我们用所需的多部分双破折号（`--`）前缀更新它，并设置我们的`http.request`调用：
- en: '[PRE22]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We want to be able to stream multipart data to the server, which may be compiled
    from multiple files. If we streamed these files while simultaneously attempting
    to compile them together into the multipart format, the data would likely be mashed
    together from different file streams in an unpredictable order becoming impossible
    to parse. So we need a way to preserve the data order.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望能够将多部分数据流式传输到服务器，这些数据可能由多个文件编译而成。如果我们同时尝试将这些文件流式传输并将它们同时编译成多部分格式，数据很可能会从不同的文件流中混合在一起，顺序难以预测，变得无法解析。因此，我们需要一种方法来保留数据顺序。
- en: We could build it all in one go and afterwards send it to the server. However,
    a more efficient (and Node-like) solution is to build the multipart message by
    progressively assembling each file into the multipart format as the file is streamed
    in, while instantly streaming the multipart data as it's being built.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以一次性构建所有内容，然后将其发送到服务器。然而，一个更有效（并且类似于Node的）的解决方案是，通过逐步将每个文件组装成多部分格式来构建多部分消息，同时在构建时即时流式传输多部分数据。
- en: To achieve this, we can use a self-iterating function, calling each recursion
    from within the `end` event callback to ensure each stream is captured separately
    and in order.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们可以使用一个自迭代的函数，从`end`事件回调中调用每个递归，以确保每个流都被单独捕获并按顺序进行。
- en: '[PRE23]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This is also a self-calling function because we''ve changed it from a declaration
    to an expression by wrapping parenthesis around it. Then we''ve called it by appending
    parenthesis, also passing in the command-line arguments, which specify what files
    to upload:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是一个自调用函数，因为我们已经将它从声明更改为表达式，通过在其周围加括号。然后我们通过附加括号来调用它，同时传入命令行参数，指定要上传的文件：
- en: '[PRE24]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We use `splice` on the `process.argv` array to remove the first two arguments
    (which would be `node` and `upload.js)`. The result is passed into our `multipartAssembler`
    function as our `files` parameter.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`process.argv`数组上使用`splice`来删除前两个参数（即`node`和`upload.js`）。结果作为我们的`files`参数传递到我们的`multipartAssembler`函数中。
- en: 'Inside our function we immediately shift the first file off of the `files`
    array and load it into the variable `f`, which is passed into `createReadStream`.
    Once it''s finished reading, we pass any remaining files back through our `multipartAssembler`
    function and repeat the process until the array is empty. Now let''s flesh out
    our self-iterating function with multipart goodness as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的函数内部，我们立即将第一个文件从`files`数组中移除，并将其加载到变量`f`中，然后将其传递到`createReadStream`中。一旦读取完成，我们将任何剩余的文件再次通过我们的`multipartAssembler`函数，并重复该过程，直到数组为空。现在让我们用多部分的方式来完善我们的自迭代函数，如下所示：
- en: '[PRE25]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We specify a part with the predefined boundary initially set in the `content-type`
    header. Each part needs to begin with a header, we latch on to the `open` event
    to send this header out.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`content-type`头部中首先设置了预定义边界的部分。每个部分都需要以一个头部开始，我们利用`open`事件来发送这个头部。
- en: '`content-disposition` has three parts. In this scenario, the first part will
    always be `form-data`. The second part defines the name of the field (for instance,
    the `name` attribute of a file input), and the original filename. The `content-type`
    can be set to whatever mime is relevant. However, by setting all files to `application/octet-stream`
    and `content-transfer-encoding` to `binary`, we can safely treat all files the
    same way if all we''re doing is saving to disk without any interim processing.
    We finish each multipart header with a double CRLF (`\r\n\r\n`) at the end of
    our `request.write`.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`content-disposition`有三个部分。在这种情况下，第一部分将始终是`form-data`。第二部分定义了字段的名称（例如，文件输入的`name`属性）和原始文件名。`content-type`可以设置为任何相关的mime。然而，通过将所有文件设置为`application/octet-stream`并将`content-transfer-encoding`设置为`binary`，如果我们只是将文件保存到磁盘而没有任何中间处理，我们可以安全地以相同的方式处理所有文件。我们在每个多部分头部的末尾使用双CRLF（`\r\n\r\n`）来结束我们的`request.write`。'
- en: Also, notice we've assigned a new `progress` variable at the top of the `multipartAssembler`
    function. We use this to determine the relative percent of the upload by dividing
    the chunks received so far (`progress`), by the total file size (`fSize`). This
    calculation is performed in our `data` event callback, where we also stream each
    chunk to the server.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，我们在`multipartAssembler`函数的顶部分配了一个新的`progress`变量。我们使用这个变量来通过将到目前为止接收到的块数（`progress`）除以总文件大小（`fSize`）来确定上传的相对百分比。这个计算是在我们的`data`事件回调中执行的，我们也在那里将每个块流到服务器上。
- en: In our `end` event, if there are no more files to process, we end the request
    with the final multipart boundary which is the same as other boundary partitions
    except it has leading and trailing slashes.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`end`事件中，如果没有更多的文件需要处理，我们将以与其他边界分区相同的最终多部分边界结束请求，除了它有前导和尾随斜杠。
- en: See also
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: '*Working with real data: fetching trending tweets* discussed In [Chapter 3](ch03.html
    "Chapter 3. Working with Data Serialization"), *Working with Data Serialization*'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用真实数据：获取热门推文* 在[第3章](ch03.html "第3章. 使用数据序列化")中讨论了*使用数据序列化*'
- en: Implementing download throttling
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施下载限速
- en: For incoming streams, Node provides `pause` and `resume` methods, but not so
    for outbound streams. Essentially, this means we can easily throttle upload speeds
    in Node but download throttling requires a more creative solution.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 对于传入的流，Node提供了`pause`和`resume`方法，但对于传出的流则不然。基本上，这意味着我们可以在Node中轻松地限制上传速度，但下载限速需要更有创意的解决方案。
- en: Getting ready
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: We'll need a new `server.js` along with a good-sized file to serve. With the
    `dd` command-line program, we can generate a file for testing purposes.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个新的`server.js`以及一个很大的文件来提供服务。使用`dd`命令行程序，我们可以生成一个用于测试的文件。
- en: '[PRE26]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This will create a 50 MB file named `50meg` which we'll be serving.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个名为`50meg`的50MB文件，我们将提供服务。
- en: Tip
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: For a similar Windows tool that can be used to generate a large file, check
    out [http://www.bertel.de/software/rdfc/index-en.html](http://www.bertel.de/software/rdfc/index-en.html).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个类似的Windows工具，可以用来生成一个大文件，请查看[http://www.bertel.de/software/rdfc/index-en.html](http://www.bertel.de/software/rdfc/index-en.html)。
- en: How to do it...
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: To keep things as simple as possible our download server will serve just one
    file, but we'll implement it in a way which would allow us to easily plug in some
    router code to serve multiple files. First, we will require our modules and set
    up an `options` object for file and speed settings.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为了尽可能简单，我们的下载服务器将只提供一个文件，但我们将以一种方式来实现，可以轻松地插入一些路由代码来提供多个文件。首先，我们将需要我们的模块并设置一个`options`对象来设置文件和速度设置。
- en: '[PRE27]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: If we were serving multiple files, our `options` object would be largely redundant.
    However, we're using it here to emulate the concept of a user-determined file
    choice. In a multifile situation, we would be loading file specifics based upon
    the requested URL instead.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们正在提供多个文件，我们的 `options` 对象将大部分是多余的。但是，在这里我们使用它来模拟用户确定的文件选择概念。在多文件情况下，我们将根据请求的
    URL 加载特定文件信息。
- en: Note
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: To see how this recipe could be configured to serve and throttle more than one
    file, check out the routing recipes In [Chapter 1](ch01.html "Chapter 1. Making
    a Web Server"), *Making a Web Server*
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解这个方法如何配置以服务和限制多个文件，请查看 [第1章](ch01.html "第1章。制作Web服务器") 中的路由方法，*制作Web服务器*
- en: The `http` module is for the server while the `fs` module is for creating a
    `readStream` and grabbing the size of our file.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`http` 模块用于服务器，而 `fs` 模块用于创建 `readStream` 并获取我们文件的大小。'
- en: We're going to restrict how much data is sent out at once, but we first need
    to get the data in. So let's create our server and initialize a `readStream`.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将限制一次发送多少数据，但首先我们需要获取数据。所以让我们创建我们的服务器并初始化一个 `readStream`。
- en: '[PRE28]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We''ve created our server and specified a new object called `download`, which
    inherits from our `options` object. We add two properties to our request-bound
    `download` object: a `chunks` property that collects the file chunks inside the
    `readStream` data event listener and a `bufferOffset` property that will be used
    to keep track of the amount of bytes loaded from disk.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经创建了我们的服务器并指定了一个叫做 `download` 的新对象，它继承自我们的 `options` 对象。我们向我们的请求绑定的 `download`
    对象添加了两个属性：一个 `chunks` 属性，它在 `readStream` 数据事件监听器中收集文件块，以及一个 `bufferOffset` 属性，它将用于跟踪从磁盘加载的字节数。
- en: All we have to do now is the actual throttling. To achieve this, we simply apportion
    out the specified number of kilobytes from our buffer every second, thus achieving
    the specified kilobytes per second. We'll make a function for this, which will
    be placed outside of `http.createServer` and we'll call our function `throttle`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们所要做的就是实际的限流。为了实现这一点，我们只需每秒从我们的缓冲区中分配指定数量的千字节，从而实现指定的每秒千字节。我们将为此创建一个函数，它将放在
    `http.createServer` 之外，并且我们将称我们的函数为 `throttle`。
- en: '[PRE29]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '`throttle` interacts with the `download` object created on each server request
    to measure out each chunk according to our predetermined `options.kbps` speed.
    For the second parameter (`cb`), `throttle` accepts a functional callback. `cb`
    in turn takes one parameter, which is the chunk of data that `throttle` has determined
    to send. Our `throttle` function returns a convenience function that can be used
    to end the loop on abort, avoiding infinite looping. We initialize download throttling
    by calling our `throttle` function in the server callback when the `readStream`
    opens.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`throttle` 与每个服务器请求上创建的 `download` 对象交互，根据我们预定的 `options.kbps` 速度分配每个块。对于第二个参数（`cb`），`throttle`
    接受一个功能回调。`cb` 反过来接受一个参数，即 `throttle` 确定要发送的数据块。我们的 `throttle` 函数返回一个方便的函数，用于在中止时结束循环，避免无限循环。我们通过在服务器回调中调用我们的
    `throttle` 函数来初始化下载限流时钟，当 `readStream` 打开时。'
- en: '[PRE30]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: How it works...
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The key to this recipe is our `throttle` function. Let's walk through it. To
    achieve the specified speed, we send a chunk of data of a certain size every second.
    The size is determined by the desired amount of kilobytes per second. So, if `download.kbps`
    is 32, we'll send 32 KB chunks every second.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法的关键是我们的 `throttle` 函数。让我们来看看它。为了实现指定的速度，我们每秒发送一定大小的数据块。大小由所需的每秒千字节数量确定。因此，如果
    `download.kbps` 是 32，我们将每秒发送 32 KB 的数据块。
- en: Buffers work in bytes, so we set a new variable called `chunkOutSize` and multiply
    `download.kbps` by 1024 to realize the appropriate chunk size in bytes. Next,
    we set a `timer` variable which is passed into `setTimeout`. It is first set to
    `0` on two accounts. For one, it eliminates an unnecessary initial 1000 millisecond
    overhead, allowing our server the opportunity to immediately send the first chunk
    of data, if available. Secondly, if the `download.chunks` buffer is not full enough
    to accommodate the demand of `chunkOutSize`, the embedded `loop` function recurses
    without changing `timer`. This causes the CPU to cycle in real time until the
    buffer loads enough data to deliver a whole chunk (a process which should take
    less than a second).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 缓冲区以字节为单位工作，所以我们设置一个新变量叫做 `chunkOutSize`，并将 `download.kbps` 乘以 1024 以实现适当的块大小（以字节为单位）。接下来，我们设置一个
    `timer` 变量，它被传递给 `setTimeout`。它首先设置为 `0` 有两个原因。首先，它消除了不必要的初始1000毫秒开销，使我们的服务器有机会立即发送第一块数据（如果可用）。其次，如果
    `download.chunks` 缓冲区不足以满足 `chunkOutSize` 的需求，嵌入的 `loop` 函数在不改变 `timer` 的情况下进行递归。这会导致
    CPU 实时循环，直到缓冲区加载足够的数据以传递一个完整的块（这个过程应该在一秒钟内完成）。
- en: Once we have enough data for the first chunk, `timer` is set to 1000 because
    from here on out we want to push a chunk every second.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了第一个块的足够数据，`timer` 就设置为1000，因为从这里开始我们希望每秒推送一个块。
- en: '`loop` is the guts of our throttling engine. It''s a self-recursive function
    which calls itself with one parameter: `bytesSent`. The `bytesSent` parameter
    allows us to keep track of how much data has been sent so far, and we use it to
    determine which bytes to slice out of our `download.chunks` buffer using `Buffer.slice.
    Buffer.slice` takes two parameters, `start` and `end`. These two parameters are
    fulfilled with `bytesSent` and `bytesOut` respectively. `bytesOut` is also used
    against `download.bufferOffset` to ensure we have enough data loaded for a whole
    chunk to be sent out.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`loop` 是我们限流引擎的核心。它是一个自递归函数，它使用一个参数 `bytesSent` 调用自身。`bytesSent` 参数允许我们跟踪到目前为止发送了多少数据，并且我们使用它来确定从我们的
    `download.chunks` 缓冲区中切出哪些字节，使用 `Buffer.slice`。`Buffer.slice` 接受两个参数，`start` 和
    `end`。这两个参数分别由 `bytesSent` 和 `bytesOut` 实现。`bytesOut` 也用于与 `download.bufferOffset`
    对比，以确保我们加载了足够的数据以便发送一个完整的块。'
- en: If there is enough data, we proceed to set the `timer` to 1000 to initiate our
    chunk per second policy, then pass the result of `download.chunks.slice` into
    `cb` which becomes our `send` parameter.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有足够的数据，我们继续将`timer`设置为1000，以启动我们的每秒一个块的策略，然后将`download.chunks.slice`的结果传递给`cb`，这将成为我们的`send`参数。
- en: Back inside our server, our `send` parameter is passed to `response.write` within
    our `throttle` callback, so each chunk is streamed to the client. Once we've passed
    our sliced chunk to `cb` we call `loop(bytesOut)` for a new iteration (thus `bytesOut`
    transforms into `bytesSent)`, then we return from the function to prevent any
    further execution.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 回到服务器内部，我们的`send`参数被传递到`throttle`回调中的`response.write`，因此每个块都被流式传输到客户端。一旦我们将切片的块传递给`cb`，我们调用`loop(bytesOut)`进行新的迭代（因此`bytesOut`变成`bytesSent`），然后我们从函数中返回，以防止进一步执行。
- en: The third and final place `bytesOut` appears is in the second conditional statement
    of the `setTimeout` callback, where we use it against `download.chunks.length`.
    This is important for handling the last chunk of data. We don't want to loop again
    after the final chunk has been sent, and if `options.kbps` doesn't divide exactly
    into the total file size, the final `bytesOut` would be larger than the size of
    the buffer. If passed into the `slice` method unchecked, this would cause an object
    out of bounds (`oob`) error.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '`bytesOut`第三次出现的地方是在`setTimeout`回调的第二个条件语句中，我们将其与`download.chunks.length`进行比较。这对于处理最后一块数据很重要。我们不希望在最后一块数据发送后再次循环，如果`options.kbps`不能完全整除总文件大小，最后的`bytesOut`将大于缓冲区的大小。如果未经检查地传递给`slice`方法，这将导致对象越界（`oob`）错误。'
- en: So if `bytesOut` equals, or is greater than, the memory allocated to the `download.chunks`
    buffer (that is, the size of our file), we `slice` the remaining bytes from our
    `download.chunks` buffer and return from the function without calling `loop`,
    effectively terminating recursion.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果`bytesOut`等于或大于分配给`download.chunks`缓冲区的内存（即我们文件的大小），我们将从`download.chunks`缓冲区中切片剩余的字节，并在不调用`loop`的情况下从函数中返回，有效地终止递归。
- en: To prevent infinite looping when the connection is closed unexpectedly (for
    instance during connection failure or client abort) `throttle` returns another
    function, which is caught in the `handleAbort` variable and called in the `close`
    event of `response`. The function simply adds a property to the `download` object
    to say the download has been aborted. This is checked on each recursion of the
    `loop` function. As long as `download.aborted` isn't `true` it continues to iterate,
    otherwise the looping stops short.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止连接意外关闭时出现无限循环（例如在连接失败或客户端中止期间），`throttle`返回另一个函数，该函数在`handleAbort`变量中捕获并在`response`的`close`事件中调用。该函数简单地向`download`对象添加一个属性，表示下载已中止。这在`loop`函数的每次递归中都会进行检查。只要`download.aborted`不是`true`，它就会继续迭代，否则循环会提前停止。
- en: Note
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: There are (configurable) limits on operating systems defining how many files
    can be opened at once. We would probably want to implement caching in a production
    download server to optimize file system access. For file limits on Unix systems,
    see [http://www.stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux](http://www.stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统上有（可配置的）限制，定义了可以同时打开多少文件。我们可能希望在生产下载服务器中实现缓存，以优化文件系统访问。有关Unix系统上的文件限制，请参阅[http://www.stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux](http://www.stackoverflow.com/questions/34588/how-do-i-change-the-number-of-open-files-limit-in-linux)。
- en: Enabling resumes from broken downloads
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 启用断点续传
- en: 'If a connection breaks, or a user accidentally aborts a download, the client
    may initiate a resume request by sending a `Range` HTTP header to the server.
    A `Range` header would look something like this:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如果连接中断，或用户意外中止下载，客户端可以通过向服务器发送`Range` HTTP头来发起恢复请求。`Range`头可能如下所示：
- en: '[PRE31]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'When a server agrees to handle a `Range` header, it sends a `206 Partial Content`
    status and adds a `Content-Range` header in the response. Where the entire file
    is 1 MB, a `Content-Range` reply to the preceding `Range` header might look as
    follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 当服务器同意处理`Range`头时，它会发送`206 Partial Content`状态，并在响应中添加`Content-Range`头。如果整个文件大小为1
    MB，对先前的`Range`头的`Content-Range`回复可能如下所示：
- en: '[PRE32]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Notice that there is no equals sign (=) after `bytes` in a `Content-Range` header.
    We can pass an object into the second parameter of `fs.createReadStream`, which
    specifies where to start and end reading. Since we are simply handling resumes,
    we only need to set the `start` property.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在`Content-Range`头中`bytes`后面没有等号（=）。我们可以将对象传递给`fs.createReadStream`的第二个参数，指定从哪里开始和结束读取。由于我们只是处理恢复，因此只需要设置`start`属性。
- en: '[PRE33]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: By adding some properties to `download`, and using them to conditionally respond
    to a `Range` header, we can now handle resume requests.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 通过向`download`添加一些属性，并使用它们有条件地响应`Range`头，我们现在可以处理恢复请求。
- en: See also
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: '*Setting up a router* discussed in [Chapter 1](ch01.html "Chapter 1. Making
    a Web Server"), *Making a Web Server*'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*设置路由器*讨论在[第1章](ch01.html "第1章。制作Web服务器")中，*制作Web服务器*'
- en: '*Caching content in memory for immediate delivery* discussed In [Chapter 1](ch01.html
    "Chapter 1. Making a Web Server"), *Making a Web Server*'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在内存中缓存内容以进行即时交付*讨论在[第1章](ch01.html "第1章。制作Web服务器")中，*制作Web服务器*'
- en: '*Communicating via TCP* discussed In [Chapter 8](ch08.html "Chapter 8. Integrating
    Network Paradigms"), *Integrating Networking Paradigms*'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通过TCP通信*讨论在[第8章](ch08.html "第8章。集成网络范式")中，*集成网络范式*'
