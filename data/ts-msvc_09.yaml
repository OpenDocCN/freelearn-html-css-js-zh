- en: Deployment, Logging, and Monitoring
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署、日志记录和监控
- en: '"Tactics without strategy is the noise before defeat."'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: “没有战略的战术是失败前的噪音。”
- en: '- Sun Tzu'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '- 孙子'
- en: We need a very strong deployment strategy before going live to production and
    starting to earn revenue. Lack of planning always results in an unforeseen emergency,
    which leads to drastic failures. That's what we are going to do in this chapter.
    Now that we are done with our development stuff and have added double checks by
    testing and providing documentation, we are now going to target our *Go Live Phase*.
    We will see all aspects involved in deployment including current trending terms—continuous
    integration, continuous delivery, and the new serverless architecture. We will
    then see the need for logs and how to create a custom centralized logging solution.
    Moving further, we will look at **Zipkin**—an emerging tool for logging in distributed
    systems. In the end, we are going to look at monitoring challenges. We will look
    at two famous tools—**Keymetrics** and **Prometheus**.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在上线生产并开始赚取收入之前，我们需要一个非常强大的部署策略。缺乏计划总是会导致意外紧急情况，从而导致严重的失败。这就是我们在本章中要做的事情。现在我们已经完成了开发工作，并通过测试和提供文档添加了双重检查，我们现在要着手进行*上线阶段*。我们将看到部署中涉及的所有方面，包括当前流行的术语——持续集成、持续交付和新的无服务器架构。然后我们将看到日志的需求以及如何创建自定义的集中式日志解决方案。更进一步，我们将看看**Zipkin**——一个用于分布式系统日志记录的新兴工具。最后，我们将看到监控的挑战。我们将研究两个著名的工具——**Keymetrics**和**Prometheus**。
- en: 'This chapter covers the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下主题：
- en: Deployment 101
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署 101
- en: Build pipeline
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建流水线
- en: Introduction to Docker
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker简介
- en: Serverless architecture
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务器架构
- en: Logging 101
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志记录 101
- en: Customized logging using ELK
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用ELK进行定制日志记录
- en: Distributed tracing using Zipkin
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Zipkin进行分布式跟踪
- en: Monitoring 101
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控 101
- en: Monitoring with tools such as Keymetrics, Prometheus, and Grafana
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Keymetrics、Prometheus和Grafana等工具进行监控
- en: Deployment
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署
- en: Releasing an application in a production environment with sufficient confidence
    that it is not going to crash or lose organization money is a developers dream.
    Even a manual error, such as not loading proper configuration files, can cause
    huge problems. In this section, we will see how to automate most things and become
    aware of continuous integration and continuous delivery (CI and CD). Let's get
    started with understanding the overall build pipeline.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中发布一个应用程序，有足够的信心它不会崩溃或让组织损失资金，这是开发者的梦想。即使是手动错误，比如没有加载正确的配置文件，也会造成巨大问题。在本节中，我们将看到如何自动化大部分事情，并了解持续集成和持续交付（CI和CD）。让我们开始了解整体构建流水线。
- en: Deciding release plan
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决定发布计划
- en: 'While it is good to have confidence, it is bad to have overconfidence. We should
    always be ready for rolling back the new changes in case of major critical issues
    while deploying to production. An overall build pipeline is needed as it helps
    us to plan for the overall process. We will adopt this technique while doing a
    production build:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 自信是好事，但过分自信是不好的。在部署到生产环境时，我们应该随时准备好回滚新的更改，以防出现重大关键问题。需要一个整体的构建流水线，因为它可以帮助我们规划整个过程。在进行生产构建时，我们将采用这种技术：
- en: '![](img/727d2a3e-ddc3-4320-8e5e-3dfb23ff35ac.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/727d2a3e-ddc3-4320-8e5e-3dfb23ff35ac.png)'
- en: Build pipeline
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 构建流水线
- en: The overall build process begins by the **Start** block. Whenever any commit
    occurs, WebHooks (provided by both Bitbucket and GitHub) trigger the build pipeline.
    Bitbucket has build pipeline tools, too ([https://bitbucket.org/product/features/pipelines](https://bitbucket.org/product/features/pipelines)).
    This build pipeline can be triggered whenever there is a merge in the master branch.
    Once it comes to the build stage, we first run some code coverage analysis and
    unit tests. If the test results do not meet required SLAs, we abort the process.
    If it meets the overall SLAs, we then create an image out of it and build it on
    the staging server (if we do not have a staging server, we can directly move to
    the production server). Once you have a docker image ready, you set the environment
    depending on where you are deploying. Afterwards, some sanity checks are run to
    make sure that we don't deploy broken code. To run them at all, levels in the
    pipeline is an excellent idea that minimizes chances of error. Now, once the service
    meets SLAs, it's now time to deploy it on a real environment. A good practice
    that I usually follow is production servers should not have version controls.
    Depending on whatever tool we use (OpenShift, Kubernetes, Docker, and so on) we
    pass those tools to start the image. We then need to start integration testing,
    which will include things such as checking whether or not the container is healthy
    and checking with the service registry and API Gateway whether the service is
    registered or not. In order to make sure that nothing breaks, we need a rolling
    update where we deploy new instances and remove old instances one at a time. Our
    code base should be able to handle old/legacy code and it should be deprecated
    only after acceptance from every dependent. After completing integration testing,
    the next task involves running contract testing and acceptance testing. Once these
    tests have been successfully run, we can move from staging to production or going
    live. If the pipeline fails, the previous last successful source code is deployed
    back as part of a rollback strategy.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 整个构建过程始于**开始**块。每当发生任何提交时，WebHooks（由Bitbucket和GitHub提供）会触发构建流水线。Bitbucket也有构建流水线工具（[https://bitbucket.org/product/features/pipelines](https://bitbucket.org/product/features/pipelines)）。这个构建流水线可以在主分支合并时触发。一旦到达构建阶段，我们首先运行一些代码覆盖分析和单元测试。如果测试结果不符合要求的SLA，我们会中止流程。如果符合整体SLA，我们就会根据它创建一个镜像，并在暂存服务器上构建它（如果我们没有暂存服务器，我们可以直接移动到生产服务器）。一旦你有一个准备好的Docker镜像，你就根据你部署的位置设置环境。之后，运行一些理智检查以确保我们不部署破损的代码。在流水线的所有级别上运行它们是一个极好的想法，可以最大程度地减少错误的机会。现在，一旦服务符合SLA，现在是时候在真实环境中部署它了。我通常遵循的一个良好实践是生产服务器不应该有版本控制。根据我们使用的任何工具（OpenShift、Kubernetes、Docker等），我们将这些工具传递给它们来启动镜像。然后我们需要开始集成测试，其中包括检查容器是否健康以及与服务注册表和API网关检查服务是否注册。为了确保没有任何破坏，我们需要进行滚动更新，其中我们逐个部署新实例并移除旧实例。我们的代码库应该能够处理旧/遗留代码，并且只有在每个依赖方都接受后才能废弃它。完成集成测试后，下一个任务涉及运行契约测试和验收测试。一旦这些测试成功运行，我们就可以从暂存环境移动到生产环境或上线。如果流水线失败，上一个成功的源代码将作为回滚策略部署回来。
- en: 'The entire process should be automated as we are more prone to error. We will
    look at CI/CD and how they make our life a lot easier. CI/CD promises that we
    could deploy a feature whenever it is complete and still be pretty confident that
    it won''t break the product. The pipeline we looked at has loads of tasks and
    stages associated with it. Let''s look at the following stages:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程应该是自动化的，因为我们更容易出错。我们将研究CI/CD以及它们如何让我们的生活变得更加轻松。CI/CD承诺，我们可以在功能完成时部署它，并且仍然相当有信心它不会破坏产品。我们所看到的流水线有大量与之相关的任务和阶段。让我们看看以下阶段：
- en: '**Dev stage/feature branch**: We start our development by creating feature
    branches. We keep the master as it is and only keep verified and tested code in
    the master branch. This way our production is a replica of the master branch and
    we can do any number of experiments in the development branch. If something fails,
    we can always revert back to the master branch and discard or delete a branch.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开发阶段/功能分支**：我们通过创建功能分支来开始开发。我们保持主分支不变，并且只在主分支中保留经过验证和测试的代码。这样，我们的生产环境就是主分支的复制品，我们可以在开发分支中进行任意数量的实验。如果某些东西失败了，我们总是可以回到主分支并丢弃或删除一个分支。'
- en: '**Testing stage/QA branch**: Once our development is done, we push the code
    to the QA branch. Once our development is done, we push the code to the QA branch
    so it can be tested. Modern development approaches go one step beyond and we go
    with TDD/BDD. Whenever we push the code to QA we run test cases to get exact code
    coverage. We run some lint tools, which give us an idea about code quality. After
    all that, if these tests are successful, then only, do we push the code to the
    QA branch.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试阶段/QA分支**：一旦我们的开发完成，我们将代码推送到QA分支。现代开发方法更进一步，我们采用TDD/BDD。每当我们将代码推送到QA时，我们运行测试用例以获得精确的代码覆盖率。我们运行一些代码检查工具，这些工具给我们一个关于代码质量的想法。在所有这些之后，如果这些测试成功，那么我们才将代码推送到QA分支。'
- en: '**Release stage/master branch**: Once our QA is done and our test cases coverage
    are passed, we push the code to the master in hopes of getting it pushed to production.
    We again run our test cases and code coverage tools and check whether something
    has been broken or not. Once successful, we push the code to the production server
    and run some smoke testing and contract testing.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**发布阶段/主分支**：一旦我们的QA完成并且我们的测试用例覆盖通过了，我们将代码推送到主分支，希望将其推送到生产环境。我们再次运行我们的测试用例和代码覆盖工具，并检查是否有任何破坏。一旦成功，我们将代码推送到生产服务器并运行一些冒烟测试和契约测试。'
- en: '**Released/tag**: Once the code is pushed to production and it runs successfully,
    we create a branch/tag for the release. This helps us to make sure that we can
    return to this point in the near future.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**发布/标签**：一旦代码推送到生产环境并成功运行，我们会为发布创建一个分支/标签。这有助于确保我们可以在不久的将来返回到这一点。'
- en: 'Doing such processes at each and every stage manually is a cumbersome process.
    We need automation as humans are prone to error. We need a continuous delivery
    mechanism where a single commit in my code ensures me that the code deployed is
    safe for my ecosystem. In the next section, we are going to look at continuous
    integration and continuous delivery:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个阶段手动进行这样的过程是一个繁琐的过程。我们需要自动化，因为人类容易出错。我们需要一个持续交付机制，其中我的代码中的一个提交可以确保我部署的代码对我的生态系统是安全的。在下一节中，我们将看看持续集成和持续交付：
- en: '**Continuous integration**: It is the practice of integrating or merging a
    new feature from other branches to the master and making sure that new changes
    don''t break the existing features. A common CI workflow is that, along with the
    code, you also write test cases. Then you create a pull request representing the
    change. Build software that can run tests, check for code coverage, and decide
    whether the pull request is acceptable or not. Once the **Pull Request** (**PR**)
    is merged, it goes into the CD portion—that is continuous delivery.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续集成：**这是将新功能从其他分支集成或合并到主分支，并确保新更改不会破坏现有功能的实践。一个常见的CI工作流程是，除了代码，您还编写测试用例。然后创建代表更改的拉取请求。构建软件可以运行测试，检查代码覆盖率，并决定拉取请求是否可接受。一旦**拉取请求**（PR）合并，它就进入CD部分，即持续交付。'
- en: '**Continuous delivery:** It is an approach wherein we aim to deliver a small,
    testable, and easily deployable piece of code seamlessly at any point in time.
    CD is highly automatable, and in some tools, it is highly configurable. Such automation
    helps in quickly distributing components, features, and fixes to customers and
    gives anyone an exact idea as to how much and what is present in a production
    environment.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续交付：**这是一种方法，我们旨在随时无缝交付一小块可测试且易于部署的代码。CD是高度可自动化的，在某些工具中，它是高度可配置的。这种自动化有助于快速将组件、功能和修复程序分发给客户，并让任何人对生产环境中有多少以及有什么有一个确切的想法。'
- en: With constant improvement in DevOps and the rise of containers, there is a rise
    in new automation tools to help with the CI/CD pipeline. These tools integrate
    with day to day tools, such as code repository management (GitHub can be used
    with Travis and CircleCI, and Bitbucket can be used with Bitbucket pipelines)
    to tracking systems such as slack and Jira. Also, a new trend is emerging, which
    is serverless deployment, where developers just have to worry about their code
    and deployments and other headaches would be sorted by the providers (for example,
    Amazon has AWS and Google has GCP functions). In the next section, we are going
    to look at various available deployment options.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 随着DevOps的不断改进和容器的兴起，出现了许多新的自动化工具来帮助CI/CD流水线。这些工具与日常工具集成，例如代码存储库管理（GitHub可以与Travis和CircleCI一起使用，Bitbucket可以与Bitbucket
    pipelines一起使用）以及跟踪系统，如slack和Jira。此外，出现了一个新的趋势，即无服务器部署，开发人员只需关注他们的代码和部署，其他问题将由提供者解决（例如，亚马逊有AWS，谷歌有GCP函数）。在下一节中，我们将看看各种可用的部署选项。
- en: Deployment options
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署选项
- en: In this section, we will look at some of the famous deployment options available
    and look at each of their strengths and weaknesses. We will start with the world
    of containers and look at why everything is dockerized these days. So, let's get
    started.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将看一些著名的可用部署选项，并了解它们各自的优势和劣势。我们将从容器的世界开始，看看为什么现在所有东西都是docker化的。所以，让我们开始吧。
- en: Before we get started, let's get acquainted with DevOps 101 so as to understand
    all terminologies that we will be using.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，让我们先了解一下DevOps 101，以便理解我们将要使用的所有术语。
- en: DevOps 101
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DevOps 101
- en: In this section, we will look at some basic DevOps fundamentals. We will understand
    what is a container and what advantages it has. We will see the difference between
    containers and VM machines.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将了解一些基本的DevOps基础知识。我们将了解什么是容器以及它有什么优势。我们将看到容器和虚拟机之间的区别。
- en: Containers
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器
- en: As cloud computing advances, the world is seeing the re-entry of containers
    systems. Containers have become widely adopted due to simplification in technology
    (Docker follows the same commands as GIT). Containers give private spaces on top
    of operating systems. This technique is also termed as virtualization in the system.
    Containers are easy mechanisms to build, package, and run compartmentalized (software
    residing and limiting to that container only). Containers handle their own filesystem,
    network information, inbuilt internal processes, OS utilities, and other application
    configuration. Containers ship multiple software inside it.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 随着云计算的进步，世界正在看到容器系统的重新进入。由于技术的简化（Docker遵循与GIT相同的命令），容器已被广泛采用。容器在操作系统之上提供私有空间。这种技术也被称为系统中的虚拟化。容器是构建、打包和运行隔离的机制（软件仅驻留和限制在该容器中）。容器处理自己的文件系统、网络信息、内置内部进程、操作系统实用程序和其他应用程序配置。容器内部装载多个软件。
- en: 'Containers have the following advantages:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 容器具有以下优势：
- en: Independent
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立的
- en: Lightweight
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轻量级
- en: Easy to scale
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易于扩展
- en: Easy to move
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易于移动
- en: Lower license and infrastructure cost
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更低的许可和基础设施成本
- en: Automated via DevOps
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过DevOps自动化
- en: Version controlled just like GIT
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像GIT一样进行版本控制
- en: Reusable
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可重复使用
- en: Immutable
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不可变的
- en: Containers versus Virtual Machine (VMs)
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器与虚拟机（VMs）
- en: While a birds eye's view would seem both are stating the same thing, containers
    and VMs are hugely different. VM's provide hardware virtualization, too, such
    as number of CPUs, memory storage, and so on. VM is a separate unit along with
    OS. VMs replicate the full operating system, thus they are heavyweight. VM offers
    complete isolation to the processes running on it, but it limits the number of
    VMs that can be spun up as it is heavyweight and resource consuming and it will
    take effort to maintain it. Unlike VMs, containers share kernels and host systems
    and thus resource utilization of containers is very less. Containers are lightweight
    as they provide an isolation layer on top of a host operating system. A developer's
    life becomes much easier as container images can be made publicly available (there
    is a huge Docker repository). The lightweight nature of containers helps to automate
    builds, publish artifact anywhere, download and copy on a need basis, and so on.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然鸟瞰图似乎两者都在说同样的事情，但容器和虚拟机（VM）有很大的不同。虚拟机提供硬件虚拟化，例如CPU数量、内存存储等。虚拟机是一个独立的单元，还有操作系统。虚拟机复制完整的操作系统，因此它们很重。虚拟机为在其上运行的进程提供完全隔离，但它限制了可以启动的虚拟机数量，因为它很重且消耗资源，并且需要维护。与虚拟机不同，容器共享内核和主机系统，因此容器的资源利用率非常低。容器作为在主机操作系统之上提供隔离层，因此它们是轻量级的。容器镜像可以公开使用（有一个庞大的Docker存储库），这使得开发人员的生活变得更加轻松。容器的轻量特性有助于自动化构建、在任何地方发布构件、根据需要下载和复制等。
- en: Docker and the world of containers
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker和容器世界
- en: Virtualization is one of the biggest trends right now in DevOps. Virtualization
    enables us to share hardware across various software instances. Just like microservices
    supports isolation, Docker provides resources isolation by creating containers.
    Using a Docker container for microservices makes it possible to package the entire
    service along with its dependencies within a container and run it on any server.
    Wow! Gone are the days of installing software in each environment. Docker is an
    open source project used to pack, ship, and run any application as a lightweight
    container without much hassle to install everything on a new environment again.
    Docker containers are both platform and hardware agnostic, making it easy to run
    a container anywhere, right from a laptop to any server without using any particular
    language framework or packaging software. Containerization is nowadays referred
    to as dockerization. We are already dockerized starting from [Chapter 2](54b04f3b-39de-4147-9aa2-0b0a242515c5.xhtml),
    *Gearing up for the Journey*. So let's understand the overall process and concepts
    involved.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟化是DevOps中目前最大的趋势之一。虚拟化使我们能够在各种软件实例之间共享硬件。就像微服务支持隔离一样，Docker通过创建容器来提供资源隔离。使用Docker容器进行微服务可以将整个服务以及其依赖项打包到容器中，并在任何服务器上运行。哇！安装软件在每个环境中的日子已经过去了。Docker是一个开源项目，用于在新环境中轻松打包、运输和运行任何应用程序作为轻量级容器，而无需安装所有东西。Docker容器既不依赖于平台也不依赖于硬件，这使得可以轻松地在任何地方运行容器，从笔记本电脑到任何服务器，而无需使用任何特定的语言框架或打包软件。当今，容器化通常被称为dockerization。我们已经从[第2章](54b04f3b-39de-4147-9aa2-0b0a242515c5.xhtml)开始进行了docker化，*为旅程做准备*。因此，让我们了解涉及的整个过程和概念。
- en: We already saw the installation of Docker in [Chapter 2](54b04f3b-39de-4147-9aa2-0b0a242515c5.xhtml),
    *Gearing up for the Journey*. Now, let's dive deep into understanding Docker.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在[第2章](54b04f3b-39de-4147-9aa2-0b0a242515c5.xhtml)中看到了Docker的安装，*为旅程做准备*。现在，让我们深入了解Docker。
- en: Docker components
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker组件
- en: 'Docker has the following three components:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Docker有以下三个组件：
- en: '**Docker client**: Docker client is a command-line program that actually talks
    with the Docker daemon residing inside the Docker host through either socket based
    communication or communication over REST APIs. A Docker client with CLI options
    is used to build, package, ship, and run any Docker container.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Docker客户端**：Docker客户端是一个命令行程序，实际上通过套接字通信或REST API与Docker主机内的Docker守护程序进行通信。使用具有CLI选项的Docker客户端来构建、打包、运输和运行任何Docker容器。'
- en: '**Docker host**: Docker host is basically a server-side component that includes
    a docker daemon, containers, and images:'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Docker主机**：Docker主机基本上是一个服务器端组件，包括一个Docker守护程序、容器和镜像：'
- en: Docker daemon is a server-side component that runs on the host machine and contains
    the script for building, packaging, running, and distributing Docker containers.
    Docker daemon exposes RESTful APIs for the Docker client as one of the ways to
    interact with itself.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker守护程序是在主机机器上运行的服务器端组件，包含用于构建、打包、运行和分发Docker容器的脚本。Docker守护程序为Docker客户端公开了RESTful
    API，作为与其交互的一种方式。
- en: Along with the Docker daemon, Docker host also includes containers and images
    running in that particular container. Whatever containers are up and running,
    Docker host contains a list of those along with options such as starting, stopping,
    restarting, log files, and so on. Docker images are those that are either built
    or pulled from public repositories.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了Docker守护程序，Docker主机还包括在特定容器中运行的容器和镜像。无论哪些容器正在运行，Docker主机都包含这些容器的列表，以及启动、停止、重启、日志文件等选项。Docker镜像是那些从公共存储库构建或拉取的镜像。
- en: '**Docker registry**: The registry is a publicly available repository, just
    like GitHub. Developers can push their container image there, make it some common
    library, or use it as version control among a team.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Docker注册表**：注册表是一个公开可用的存储库，就像GitHub一样。开发人员可以将他们的容器镜像推送到那里，将其作为公共库，或者在团队之间用作版本控制。'
- en: 'In the following diagram, we can see the overall flow among all three Docker
    components:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，我们可以看到所有三个Docker组件之间的整体流程：
- en: '![](img/da4d11d3-3d0a-4817-97ae-abd01f7647c0.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/da4d11d3-3d0a-4817-97ae-abd01f7647c0.png)'
- en: Docker components and flow
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Docker组件和流程
- en: 'The following is a typical Docker flow:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是典型的Docker流程：
- en: Whenever we run any command such as `sudo docker run ubuntu /bin/echo 'hello
    carbon five!'`, the command goes to a daemon. It tries to search whether there
    is any existing image with the name Ubuntu. If not it goes to the registry and
    finds the image there. From there it will download that container image inside
    the host, create a container, and run the `echo` command. It adds the Ubuntu image
    in the list of images available inside the docker host.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每当我们运行诸如`sudo docker run ubuntu /bin/echo 'hello carbon five!'`的命令时，该命令会传递给守护进程。它会尝试搜索是否存在具有名称Ubuntu的现有镜像。如果没有，它会转到注册表并在那里找到镜像。然后它将在主机内下载该容器镜像，创建一个容器，并运行`echo`命令。它会将Ubuntu镜像添加到Docker主机内可用的镜像列表中。
- en: Most of our images would be on top of available images in the Docker Hub repository
    ([https://hub.docker.com/](https://hub.docker.com/)). We don't reinvent the wheel
    until and unless it is very much required. Docker pull issues a command to Docker
    host to pull out a particular image from the repository and make it available
    in the list of images in Docker host.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的大多数镜像都将基于Docker Hub存储库（[https://hub.docker.com/](https://hub.docker.com/)）中的可用镜像。除非非常需要，我们不会重新发明轮子。Docker
    pull会向Docker主机发出命令，从存储库中拉取特定镜像，并使其在Docker主机的镜像列表中可用。
- en: The `docker build` command builds Docker images from a Dockerfile and an available
    context. A build's context is the set of files that are located in the specified
    PATH or URL mentioned in Dockerfile. The build process can refer to any of the
    files in the context. For example in our case, we downloaded Node.js and then
    did `npm install` based on `package.json`. Docker build creates an image and makes
    it available in the list of images inside Docker host.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`docker build`命令从Dockerfile和可用的上下文构建Docker镜像。构建的上下文是指在Dockerfile中指定的路径或URL中的文件集。构建过程可以引用上下文中的任何文件。例如，在我们的情况下，我们下载了Node.js，然后根据`package.json`执行了`npm
    install`。Docker构建创建一个镜像，并使其在Docker主机内的镜像列表中可用。'
- en: Docker concepts
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker概念
- en: 'Now that we have understood the core Docker processes, let''s move on to understanding
    various concepts involved in Docker. These concepts will make our lives easy to
    write Docker files and create our own microservice container image:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了核心的Docker流程，让我们继续了解Docker涉及的各种概念。这些概念将使我们更容易编写Docker文件并创建自己的微服务容器镜像：
- en: '**Docker image**: A Docker image is just a snapshot of the components that
    make up Docker''s business capability. It is a read-only copy of OS libraries,
    applications, and its dependencies. Once an image is created it will run on any
    Docker platform without any problems. For example, a Docker image for our microservice
    would contain all components required to fulfill the business capability achieved
    by that microservice. In our case, web server (NGINX), Node.js, PM2, and database
    (NoSQL or SQL) are all configured for runtime. So, when someone who wants to use
    that microservice or deploy it somewhere, they just need to download the image
    and run it. The image would contain all layers right from Linux kernel (`bootfs`)
    to OS (Ubuntu/CentOS) to application environment needs.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Docker镜像**：Docker镜像只是Docker业务能力组成部分的快照。它是操作系统库、应用程序及其依赖项的只读副本。一旦创建了镜像，它将在任何Docker平台上运行而不会出现任何问题。例如，我们的微服务的Docker镜像将包含满足该微服务实现的业务能力所需的所有组件。在我们的情况下，Web服务器（NGINX）、Node.js、PM2和数据库（NoSQL或SQL）都已配置为运行时。因此，当有人想要使用该微服务或在某处部署它时，他们只需下载镜像并运行它。该镜像将包含从Linux内核（`bootfs`）到操作系统（Ubuntu/CentOS）再到应用程序环境需求的所有层。'
- en: '**Docker containers**: A Docker container is just a running instance of a Docker
    image. You download (or build) or pull a Docker image. It runs in a Docker container.
    Containers use the kernel of the host operating system on which the image has
    been run. So they essentially share the host kernel with other containers running
    on the same host (as seen in the preceding diagram). Docker runtime ensures that
    containers have their own isolated process environment as well as filesystem and
    network configurations.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Docker容器**：Docker容器只是Docker镜像的运行实例。您可以下载（或构建）或拉取Docker镜像。它在Docker容器中运行。容器使用镜像所在的主机操作系统的内核。因此，它们基本上与在同一主机上运行的其他容器共享主机内核（如前图所示）。Docker运行时确保容器具有其自己的隔离的进程环境以及文件系统和网络配置。'
- en: '**Docker Registry**: Docker Registry is just like GitHub, a central place where
    Docker images are published and downloaded [https://hub.docker.com](https://hub.docker.com)
    is the centrally available public registry provided by Docker. Just like GitHub
    (a repository providing version control), Docker also provides a public and private
    images repository that is specific to a needs basis (we can make our repository
    private). We can create an image and register it to Docker Hub. So, next time
    when we want the same image on any other machine, we just refer to the repository
    to pull the image.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Docker Registry**：Docker Registry就像GitHub一样，是Docker镜像发布和下载的中心位置。[https://hub.docker.com](https://hub.docker.com)是Docker提供的中央可用的公共注册表。就像GitHub（提供版本控制的存储库），Docker也提供了一个特定于需求的公共和私有镜像存储库（我们可以将我们的存储库设为私有）。我们可以创建一个镜像并将其注册到Docker
    Hub。因此，下次当我们想在任何其他机器上使用相同的镜像时，我们只需引用存储库来拉取镜像。'
- en: '**Dockerfile**: A Dockerfile is a build or a scripting file that contains written
    instructions on how to build a Docker image. There can be multiple steps documented,
    starting right from obtaining some public image to building our application on
    top of it. We already have written Docker files (recall `.Dockerfile` in [Chapter
    2](54b04f3b-39de-4147-9aa2-0b0a242515c5.xhtml), *Gearing up for the Journey*).'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Dockerfile**：Dockerfile是一个构建或脚本文件，其中包含了构建Docker镜像的指令。可以记录多个步骤，从获取一些公共镜像到在其上构建我们的应用程序。我们已经编写了Docker文件（回想一下[第2章](54b04f3b-39de-4147-9aa2-0b0a242515c5.xhtml)中的`.Dockerfile`，*为旅程做准备*）。'
- en: '**Docker Compose**: Compose is a tool provided by Docker to run multi-container
    Docker applications inside one container. Taking the same example of our product-catalog
    microservice, we need a MongoDB container as well as a Node.js container. Docker
    compose is just the tool for that. Docker compose is a three-step process wherein
    we define the application''s environment in Docker file, we make other services
    run together in the isolated environment through `docker-compose.yml`, and we
    run the app using `docker-compose up`.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Docker Compose**：Compose是Docker提供的一个工具，用于在一个容器内运行多容器Docker应用程序。以我们的产品目录微服务为例，我们需要一个MongoDB容器以及一个Node.js容器。Docker
    compose正是为此而设计的。Docker compose是一个三步过程，我们在Docker文件中定义应用程序的环境，在`docker-compose.yml`中使其他服务在隔离的环境中运行，然后使用`docker-compose
    up`运行应用程序。'
- en: Docker command reference
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker命令参考
- en: 'Now that we have had a look at Docker concepts, let''s go through Docker commands
    so we can add them in our playground:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了Docker的概念，让我们来学习Docker命令，以便我们可以将它们添加到我们的实验中：
- en: '| **Command** | **What does it do** |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| **命令** | **功能** |'
- en: '| `docker images` | See all Docker images available on my machine. |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| `docker images` | 查看我的机器上所有可用的Docker镜像。 |'
- en: '| `docker run <options> <docker_image_name>:<version> <operation>` | Launch
    a Docker image into a container. |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| `docker run <options> <docker_image_name>:<version> <operation>` | 将Docker镜像启动到容器中。
    |'
- en: '| `docker ps` | Check whether the Docker container is running or not. |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| `docker ps` | 检查Docker容器是否正在运行。 |'
- en: '| `docker exec -ti <container-id> bash` | See what''s inside the Docker image
    by actually running on bash prompt. Able to use commands such as `ls` and `ps`.
    |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| `docker exec -ti <container-id> bash` | 通过实际在bash提示符上运行来查看Docker镜像内部的内容。能够使用诸如`ls`和`ps`之类的命令。
    |'
- en: '| `docker exec <container_id> ifconfig` | Find out the IP address of a Docker
    container. |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| `docker exec <container_id> ifconfig` | 查找Docker容器的IP地址。 |'
- en: '| `docker build` | Build an image based on instructions in `.DockerFile`. |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| `docker build` | 根据`.DockerFile`中的指令构建镜像。 |'
- en: '| `docker kill <containername> && docker rm <containername>` | Kill a running
    Docker container. |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| `docker kill <containername> && docker rm <containername>` | 终止正在运行的Docker容器。
    |'
- en: '| `docker rmi <imagename>` | Delete a Docker image from local repository. |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| `docker rmi <imagename>` | 从本地存储库中删除Docker镜像。 |'
- en: '| `docker ps -q &#124; x args docker kill &#124; xargs docker rm` | Kill all
    running Docker containers. |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| `docker ps -q &#124; x args docker kill &#124; xargs docker rm` | 终止所有正在运行的Docker容器。
    |'
- en: Setting up Docker with NGINX, Node.js, and MongoDB
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用NGINX、Node.js和MongoDB设置Docker
- en: 'Now that we know fundamental commands, let''s write Dockerfile and Docker compose
    file for a product-catalog service with NGINX in front to handle load balancing,
    in the same way we wrote `docker compose up` for MongoDB and Node.js in [Chapter
    4](720d1d4e-1795-457c-903e-65c5a5fb5433.xhtml), *Beginning Your Microservice Journey*.
    You can follow along with the example in `chapter 9/Nginx-node-mongo`, which is
    just a copy of a product-catalog microservice with NGINX added on top, so that
    services are only accessed through NGINX. Create a structure like the following:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了基本命令，让我们为一个带有NGINX的产品目录服务编写Dockerfile和Docker compose文件，以处理负载平衡，就像我们在[第4章](720d1d4e-1795-457c-903e-65c5a5fb5433.xhtml)中为MongoDB和Node.js编写`docker
    compose up`一样，*开始您的微服务之旅*。您可以按照`第9章/Nginx-node-mongo`中的示例进行操作，该示例只是在产品目录微服务的副本上添加了NGINX，以便服务只能通过NGINX访问。创建以下结构：
- en: '![](img/6748e0aa-115c-4f07-bc86-de307ecad01a.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6748e0aa-115c-4f07-bc86-de307ecad01a.png)'
- en: NGINX-mongodb-node.js file structure
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: NGINX-mongodb-node.js文件结构
- en: 'Now let''s write some rules:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们写一些规则：
- en: We will create Dockerfile for Node.js. It will be the same as what we previously
    used.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将为Node.js创建Dockerfile。它将与我们之前使用的内容相同。
- en: 'We will write Dockerfile for NGINX. We basically tell NGINX to enable rules
    for applications defined in the `sites-enabled` folder:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将为NGINX编写Dockerfile。我们基本上告诉NGINX启用`sites-enabled`文件夹中定义的应用程序的规则：
- en: '[PRE0]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we define some hardening rules inside NGINX, so as to take care of our
    load balancing as well as caching and other needs. We will write our rules in
    two places—`nodejs_project` and `nginx.conf`. In `nodejs_project` we define all
    the proxy level settings and the NIGINX server settings. Write the following code
    inside `nodejs_project`:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们在NGINX中定义一些加固规则，以便处理我们的负载平衡以及缓存和其他需求。我们将在两个地方编写我们的规则——`nodejs_project`和`nginx.conf`。在`nodejs_project`中，我们定义所有代理级别设置和NIGINX服务器设置。在`nodejs_project`中写入以下代码：
- en: '[PRE1]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s see some of the example rules for configuring NGINX for production grade
    (hardening our web server). We will write these rules inside `nginx.conf`. For
    compressing all input and output requests coming to our NGINX server, we use the
    following code:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看一些用于配置NGINX以用于生产级别（加固我们的Web服务器）的示例规则。我们将这些规则写在`nginx.conf`中。为了压缩发送到我们的NGINX服务器的所有输入和输出请求，我们使用以下代码：
- en: '[PRE2]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The preceding parameters simply configure any inbound or outbound HTTP requests
    with those attributes. Say, for instance, that it will gzip the response, gzip
    all sorts of files, and so on.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的参数只是配置了任何入站或出站的HTTP请求，具有这些属性。例如，它将对响应进行gzip压缩，对所有类型的文件进行gzip压缩等。
- en: 'Whatever resources are exchanged between servers, we have the option to cache
    those, so each time we don''t need to query again. This is caching at the web
    server layer:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无论服务器之间交换了什么资源，我们都有选项将其缓存，这样每次都不需要再次查询。这是在Web服务器层进行缓存：
- en: '[PRE3]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Lastly, we create our `docker compose` file to start MongoDB, Node.js, and NGINX
    to define. Copy the `docker-compose.yml` file from source to execute the build.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们创建我们的`docker compose`文件来启动MongoDB、Node.js和NGINX来定义。从源中复制`docker-compose.yml`文件以执行构建。
- en: Open up the Terminal to hit `docker-compose up --build` to see our deployment
    live in action.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开终端，输入`docker-compose up --build`，看看我们的部署实际运行情况。
- en: 'All internal ports will be blocked now. The only accessible port is the default
    port, which is `80`. Hit the `localhost/products/products/products-listing` URL
    to see our deployment live in action. Hit the URL again, which will load the response
    from the cache. See the following screenshot:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 所有内部端口现在都将被阻止。唯一可访问的端口是默认端口`80`。访问`localhost/products/products/products-listing`URL以查看我们的部署实时运行。再次访问URL，将从缓存中加载响应。请参阅以下屏幕截图：
- en: '![](img/c9386336-7251-4e1e-905b-213df0b086bc.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c9386336-7251-4e1e-905b-213df0b086bc.png)'
- en: Cache response
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存响应
- en: Now that we are up and running with a container image that includes the web
    layer, in the next section we will look at our build pipeline and how WebHooks
    plays an important role in it.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经使用包含Web层的容器映像运行起来了，在接下来的部分中，我们将看一下我们的构建流水线以及WebHooks在其中扮演的重要角色。
- en: WebHooks in our build pipeline
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们构建流水线中的WebHooks
- en: 'WebHooks are something that can be used for binding events in the project whenever
    something is happening. Say a pull request is merged and we want to immediately
    trigger a build—WebHooks does our job for that. A WebHook is essentially an HTTP
    callback. You can configure WebHook in your repository by going to settings and
    adding WebHook. A typical WebHook screen looks as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: WebHooks是项目中可以用来绑定事件的东西，无论何时发生了什么。比如一个拉取请求被合并，我们想立即触发一个构建 - WebHooks就可以做到这一点。WebHook本质上是一个HTTP回调。您可以通过转到设置并添加WebHook来在存储库中配置WebHook。典型的WebHook屏幕如下所示：
- en: '![](img/38bddbf4-9f5d-45a5-b677-0ad20f06fbd8.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/38bddbf4-9f5d-45a5-b677-0ad20f06fbd8.png)'
- en: WebHook
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: WebHook
- en: As seen in the preceding screenshot, it has various triggers for things such
    as Push, Fork, Updated, Pull requests, Issues, and so on. We can set alerts and
    trigger various actions on the basis of this WebHook.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的屏幕截图所示，它有各种触发器，例如推送、分叉、更新、拉取请求、问题等。我们可以根据这个WebHook设置警报并触发各种操作。
- en: In the next section, we will see a new trend emerging in microservices development,
    which is serverless deployment.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看到微服务开发中出现的新趋势，即无服务器部署。
- en: Please check extraced source/pipeline to see end to end pipeline in action.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 请检查提取的源/流水线，以查看端到端流水线的运行情况。
- en: Serverless architecture
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无服务器架构
- en: The new trend emerging these days is serverless topology. It does not actually
    mean serverless or no server. Servers are abstracted from the users and users
    only focus on development aspects and leave everything else to the vendors. AWS
    Lambda is an example of a serverless architecture where you just package the microservice
    as a ZIP and upload it to AWS Lambda. Amazon takes care of other things, including
    spawning up enough instances to handle bulk service requests.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这些天出现的新趋势是无服务器拓扑结构。这并不实际上意味着无服务器或没有服务器。服务器被用户抽象化，用户只关注开发方面，其他一切都交给供应商。AWS Lambda就是无服务器架构的一个例子，您只需将微服务打包为ZIP并上传到AWS
    Lambda。亚马逊会处理其他事情，包括启动足够的实例来处理大量服务请求。
- en: 'A Lambda function is a stateless function. It handles the request by invoking
    AWS services. We are simply billed on a number of hit requests and time taken
    to serve those requests. Similarly, Google has cloud functions. However, this
    pattern has the following pros and cons:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda函数是一个无状态函数。它通过调用AWS服务来处理请求。我们只需根据请求次数和提供这些请求所花费的时间来计费。同样，Google也有云函数。但是，这种模式有以下优点和缺点：
- en: '**Pros:**'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优点：**'
- en: We just focus on the code and we don't need to worry about low-level infrastructure
    details. AWS has a built-in gateway to be used with Lambda functions.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们只关注代码，不需要担心底层基础设施的细节。AWS具有内置的网关，可与Lambda函数一起使用。
- en: Extremely elastic architecture. It automatically handles load requests.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 极具弹性的架构。它自动处理负载请求。
- en: You pay for each request rather than renting out the entire VM and paying monthly.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您只需为每个请求付费，而不是租用整个虚拟机并每月付费。
- en: '**Cons:**'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺点：**'
- en: Few supported languages only. No freedom of polyglot environment.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅支持少数语言。没有多语言环境的自由。
- en: These are always stateless applications. AWS Lambda cannot be used for queue
    processing like RabbitMQ.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些始终是无状态的应用程序。AWS Lambda不能用于像RabbitMQ这样的队列处理。
- en: If the application doesn't start quickly, serverless architecture is not the
    fit for us.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果应用程序启动不够快，无服务器架构就不适合我们。
- en: That's pretty much about deployment. In the next section, we will look at logging
    and how to create customized centralized logging solutions.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这基本上就是部署的内容。在下一节中，我们将看一下日志记录以及如何创建定制的集中式日志记录解决方案。
- en: Logging
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志记录
- en: Microservices being totally distributed as a single request can trigger multiple
    requests to other microservices, and it becomes problematic to track what was
    the root cause of a failure or a breakdown or the overall flow of request across
    all services.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务完全分布式，作为单个请求可以触发对其他微服务的多个请求，跟踪失败或故障的根本原因或跨所有服务的请求流程变得困难。
- en: In this section, we will learn about how to track different Node.js microservices
    by doing logging the right way. Recall the concepts of logging and types of log,
    which we saw in [Chapter 4](720d1d4e-1795-457c-903e-65c5a5fb5433.xhtml), *Beginning
    Your Microservice Journey*. We are going to move ahead in that direction and create
    a centralized log store. Let's start by understanding our logging requirements
    in a distributed environment and some of the best practices that we are going
    to follow to handle distributed logging.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何通过正确的方式记录不同的Node.js微服务。回顾我们在[第4章](720d1d4e-1795-457c-903e-65c5a5fb5433.xhtml)中看到的日志记录概念和日志类型，*开始您的微服务之旅*。我们将朝着这个方向前进，并创建一个集中式日志存储。让我们首先了解在分布式环境中我们的日志记录需求以及我们将遵循的一些最佳实践来处理分布式日志。
- en: Logging best practices
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志记录最佳实践
- en: Once in post development, let's say any issue comes up. We would be completely
    lost as we are not dealing with a single server. We are dealing with multiple
    servers and the entire system is constantly moving. Whoa! We need a full proof
    strategy as we can't just wander here and there, checking each and every service's
    logs. We are completely clueless as to which microservice runs on which host and
    which microservice served the request. To open up log files across all containers,
    grepping the logs and then relating them to all requests is indeed a cumbersome
    process. If our environment has auto scalability enabled, then debugging an issue
    becomes exponentially complex as we actually have to find the instance of microservice
    that served the request.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦在开发后出现任何问题，我们将完全迷失，因为我们不是在处理单个服务器。我们正在处理多个服务器，整个系统不断移动。哇！我们需要一个完整的策略，因为我们不能随意到处走动，检查每个服务的日志。我们完全不知道哪个微服务在哪个主机上运行，哪个微服务提供了请求。要在所有容器中打开日志文件，搜索日志，然后将其与所有请求相关联，这确实是一个繁琐的过程。如果我们的环境启用了自动扩展功能，那么调试问题将变得非常复杂，因为我们实际上必须找到提供请求的微服务实例。
- en: Here are some of the golden rules for logging in microservices that will make
    life easier.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是微服务日志记录的一些黄金规则，这将使生活更轻松。
- en: Centralizing and externalizing log storage
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集中和外部化日志存储
- en: 'Microservices are distributed across the ecosystem to ease up development and
    enable faster development. As microservices run on multiple hosts, it is unwise
    to have logs at each container or server level. Rather we should send all the
    generated logs to an external and centralized place from where we can easily get
    the log information from a single place. This might be any another physical system
    or any highly available storage option. Some of the famous options are the following:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务分布在生态系统中，以简化开发并实现更快的开发。由于微服务在多个主机上运行，因此在每个容器或服务器级别都记录日志是不明智的。相反，我们应该将所有生成的日志发送到一个外部和集中的位置，从那里我们可以轻松地从一个地方获取日志信息。这可能是另一个物理系统或任何高可用性存储选项。一些著名的选项包括以下内容：
- en: '**ELK or Elastic stack**: The ELK stack ([https://www.elastic.co/elk-stack](https://www.elastic.co/elk-stack))
    consists of Elasticsearch (a distributed, full-text scalable search database that
    allows storing large volumes of datasets), Logstash (it collects log events from
    multiple types of sources, and transforms it as per need), and Kibana (visualizes
    log events or anything that is stored in Elasticsearch). Using the ELK stack,
    we can have centralized logs in Elasticsearch powered by utilities from **Kibana**
    and **Logstash**.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ELK或弹性堆栈**：ELK堆栈（[https://www.elastic.co/elk-stack](https://www.elastic.co/elk-stack)）由Elasticsearch（一个分布式、全文可扩展搜索数据库，允许存储大量数据集）、Logstash（它从多种来源收集日志事件，并根据需要进行转换）、和Kibana（可视化存储在Elasticsearch中的日志事件或任何其他内容）组成。使用ELK堆栈，我们可以在由**Kibana**和**Logstash**提供的Elasticsearch中拥有集中的日志。'
- en: '**CloudWatch (only if your environment is in AWS)**: Amazon CloudWatch ([https://aws.amazon.com/cloudwatch/](https://aws.amazon.com/cloudwatch/))
    is a monitoring service for resources and applications that are running on your
    AWS environment. We can utilize Amazon CloudWatch to collect and track metrics,
    monitor log files, set some critical alarms, and automatically react to changes
    in deployments in AWS resources. CloudWatch has the ability to monitor AWS resources,
    which includes Amazon EC2 instances, DynamoDB tables, RDS DB instances, or any
    custom metrics that your application generates. It monitors log files of all the
    applications. It provides system wise visibility into utilizing resources and
    monitors performance and health.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CloudWatch（仅当您的环境在AWS中时）**：Amazon CloudWatch（[https://aws.amazon.com/cloudwatch/](https://aws.amazon.com/cloudwatch/)）是用于监视在AWS环境中运行的资源和应用程序的监控服务。我们可以利用Amazon
    CloudWatch来收集和跟踪指标，监视日志文件，设置一些关键警报，并自动对AWS资源部署中的更改做出反应。CloudWatch具有监视AWS资源的能力，其中包括Amazon
    EC2实例、DynamoDB表、RDS数据库实例或应用程序生成的任何自定义指标。它监视所有应用程序的日志文件。它提供了系统级别的资源利用情况可见性，并监视性能和健康状况。'
- en: Structured data in logs
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志中的结构化数据
- en: Log messages go beyond just raw messages and should include several things,
    such as the timestamp; the log level type; the time taken for requests; metadata,
    such as device type, microservice name, service request name, instance name, filename,
    line number; and so on, from which we get the right data available in the logs
    to debug any issues.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 日志消息不仅仅是原始消息，还应包括一些内容，如时间戳；日志级别类型；请求所花费的时间；元数据，如设备类型、微服务名称、服务请求名称、实例名称、文件名、行号；等等，从中我们可以在日志中获取正确的数据来调试任何问题。
- en: Identifiers via correlational IDs
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过相关ID进行标识
- en: We generate a unique identifier or a correlation ID when we are making the very
    first service request. The generated unique ID is passed downstream to other calling
    microservices. That way, we can use the uniquely generated ID coming from the
    response to get logs specified to any service request. For that, we have a so-called
    correlation identifier or uniquely generated UUID to pass it to all services that
    the transaction goes through. To generate a unique ID, NPM has module UUID ([https://www.npmjs.com/package/uuid](https://www.npmjs.com/package/uuid)).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们进行第一次服务请求时，我们会生成一个唯一标识符或相关ID。生成的唯一ID会传递给其他调用的微服务。这样，我们可以使用来自响应的唯一生成的ID来获取指定于任何服务请求的日志。为此，我们有一个所谓的相关标识符或唯一生成的UUID，将其传递给事务经过的所有服务。要生成唯一ID，NPM有模块UUID（[https://www.npmjs.com/package/uuid](https://www.npmjs.com/package/uuid)）。
- en: Log levels and logging mechanisms
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志级别和日志机制
- en: Based on different aspects of an application, we need different log levels in
    our code, along with enough logging statements in code. We will use `winston`
    ([https://www.npmjs.com/package/winston](https://www.npmjs.com/package/winston)),
    which will have the ability to change log level dynamically. Furthermore, we will
    use async log appenders so that our thread won't be blocked by log requests. We
    will leverage **Async Hooks** ([https://nodejs.org/api/async_hooks.html](https://nodejs.org/api/async_hooks.html)),
    which will help us track the life cycle of resources during our process. An Async
    Hook enables us to tap any life cycle events by registering callbacks to any life
    cycle events. At resource initialization, we get a unique identifier ID (`asyncId`)
    and parent identifier ID (`triggerAsyncId`) that created the resource.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 根据应用程序的不同方面，我们的代码需要不同的日志级别，以及足够的日志语句。我们将使用`winston`（[https://www.npmjs.com/package/winston](https://www.npmjs.com/package/winston)），它将能够动态更改日志级别。此外，我们将使用异步日志附加器，以便我们的线程不会被日志请求阻塞。我们将利用**异步钩子**（[https://nodejs.org/api/async_hooks.html](https://nodejs.org/api/async_hooks.html)），它将帮助我们跟踪我们的进程中资源的生命周期。异步钩子使我们能够通过向任何生命周期事件注册回调来监听任何生命周期事件。在资源初始化时，我们会得到一个唯一的标识符ID（`asyncId`）和创建资源的父标识符ID（`triggerAsyncId`）。
- en: Searchable logs
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可搜索的日志
- en: 'The logs files collected at a single place should be searchable. For example,
    if we get any UUID, our logging solution should be able to search based on that
    to find out the request flow. Now, let''s look at a custom logging solution that
    we are going to implement and understand how it will take care of our logging
    problem:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个地方收集的日志文件应该是可搜索的。例如，如果我们得到任何UUID，我们的日志解决方案应该能够根据它来查找请求流程。现在，让我们看看我们将要实现的定制日志解决方案，并了解它将如何解决我们的日志问题：
- en: '![](img/27d70bfb-2e91-4ce1-bd1e-6f0a9b09e733.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/27d70bfb-2e91-4ce1-bd1e-6f0a9b09e733.png)'
- en: Log custom flow
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 日志定制流
- en: 'The diagram explains the core components along with their defined purpose.
    Let''s look at all the components along with their purposes before moving on to
    the implementation part:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图表解释了核心组件及其定义的目的。在进入实施部分之前，让我们先看看所有组件及其目的：
- en: '**Log Dashboard**: It is the UI front piece of our customized central logging
    solution. We will be using Kibana ([https://www.elastic.co/products/kibana](https://www.elastic.co/products/kibana))
    on top of Elasticsearch datastore as it provides many out-of-the-box features.
    We will be able to search indexed logs with whatever parameters we have logged.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志仪表板：它是我们定制的中央日志解决方案的UI前端。我们将在Elasticsearch数据存储之上使用Kibana（[https://www.elastic.co/products/kibana](https://www.elastic.co/products/kibana)），因为它提供了许多开箱即用的功能。我们将能够使用已记录的任何参数搜索索引日志。
- en: '**Log Store**: To facilitate real-time logging and storing huge amount of logs
    we will use Elasticsearch as the datastore for our customized logging solution.
    Elasticsearch allows any client to query on any parameters based on text-based
    indexes. One of the other famous options is using Hadoop''s `MapReduce` program
    for processing logs offline.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志存储：为了实现实时日志记录和存储大量日志，我们将使用Elasticsearch作为我们定制日志解决方案的数据存储。Elasticsearch允许任何客户端根据基于文本的索引查询任何参数。另一个著名的选项是使用Hadoop的`MapReduce`程序进行离线日志处理。
- en: '**Log stream processor**: Log stream processors analyze real-time log events
    for processing quick decision making. For example, if any service is throwing
    a 404 error continuously, stream processors come in handy in such cases where
    they are capable of reacting to a specific stream of events. In our case, a stream
    processor gets data from our queue and processes it on the fly before sending
    it to Elasticsearch.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志流处理器：日志流处理器分析实时日志事件，用于快速决策。例如，如果任何服务持续抛出404错误，流处理器在这种情况下非常有用，因为它们能够对特定的事件流做出反应。在我们的情况下，流处理器从我们的队列获取数据，并在发送到Elasticsearch之前即时处理数据。
- en: '**Log shipper**: Log shippers usually collect log messages, which come from
    different endpoints and sources. Log shippers send these messages to another set
    of endpoints or write them to datastores or push them to stream processing endpoints
    for further real-time processing. We would be using tools such as RabbitMQ and
    ActiveMQ for processing streams of logs. Now that we have seen the architecture
    of our custom implementation, in the next section we will see how to implement
    that in our current application. So, let''s get started.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志发货人：日志发货人通常收集来自不同端点和来源的日志消息。日志发货人将这些消息发送到另一组端点，或将它们写入数据存储，或将它们推送到流处理端点进行进一步的实时处理。我们将使用RabbitMQ和ActiveMQ等工具来处理日志流。现在我们已经看到了我们定制实现的架构，在下一节中我们将看到如何在我们当前的应用程序中实现它。所以，让我们开始吧。
- en: Centralized custom logging solution implementation
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集中式定制日志解决方案实施
- en: 'In this section, we are going to look at the practical implementation of customized
    log architecture, which we have seen in the previous section. So, let''s commence
    our journey. As a set of pre-requisites, we will need the following software installed:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到定制日志架构的实际实施，这是我们在上一节中看到的。所以，让我们开始我们的旅程。作为一组先决条件，我们需要安装以下软件：
- en: Elasticsearch 6.2.4
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elasticsearch 6.2.4
- en: Logstash 6.2.4
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Logstash 6.2.4
- en: Kibana 6.2.4
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kibana 6.2.4
- en: Java 8
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java 8
- en: RabbitMQ 3.7.3
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RabbitMQ 3.7.3
- en: Setting up our environment
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置我们的环境
- en: 'We talked about quite a number of software in the previous section. We need
    to make sure that each software is installed properly and up and running on their
    respective ports. Also, we need to make sure that Kibana knows about our Elasticsearch
    host and Logstash knows about our Kibana and Elasticsearch host. Let''s get started:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一节讨论了相当多的软件。我们需要确保每个软件都已正确安装并在各自的端口上正常运行。此外，我们需要确保Kibana知道我们的Elasticsearch主机，Logstash知道我们的Kibana和Elasticsearch主机。让我们开始吧：
- en: 'Download Elasticsearch from: [https://www.elastic.co/downloads/elasticsearch](https://www.elastic.co/downloads/elasticsearch)
    and extract it in the location of your choice. Once extracted, start your server
    by `eitherelasticsearch.bat` or `./bin/elasticsearch`. Hit `http://localhost:9200/`
    and you should be able to see the JSON tagline: You Know, for Search along with
    the Elasticsearch version.'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[https://www.elastic.co/downloads/elasticsearch](https://www.elastic.co/downloads/elasticsearch)下载Elasticsearch并将其提取到所选位置。提取后，通过`eitherelasticsearch.bat`或`./bin/elasticsearch`启动服务器。访问`http://localhost:9200/`，您应该能够看到JSON标语：You
    Know, for Search，以及Elasticsearch版本。
- en: 'Next up is Kibana. Download Kibana from: [https://www.elastic.co/downloads/kibana](https://www.elastic.co/downloads/kibana)
    and extract it to the location of choice. Then open `<kibana_home>/config/kibana.yml`
    and add the line `elasticsearch.url: "http://localhost:9200"`. This tells Kibana
    about Elasticsearch. Then start Kibana from the `bin` folder and navigate to `http://localhost:5601`.
    You should see the Kibana dashboard.'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '接下来是Kibana。从[https://www.elastic.co/downloads/kibana](https://www.elastic.co/downloads/kibana)下载Kibana并将其提取到所选位置。然后打开`<kibana_home>/config/kibana.yml`并添加一行`elasticsearch.url:
    "http://localhost:9200"`。这告诉Kibana关于Elasticsearch。然后从`bin`文件夹启动Kibana并导航到`http://localhost:5601`。您应该能够看到Kibana仪表板。'
- en: 'Download Logstash from [https://www.elastic.co/downloads/logstash](https://www.elastic.co/downloads/logstash).
    Extract it to the location of your choice. We will check Logstash installation
    by writing a simple script. Create one file, `logstash-simple.conf`, and write
    the following code. You can find this snippet in `Chapter 9/logstash-simple.conf`:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[https://www.elastic.co/downloads/logstash](https://www.elastic.co/downloads/logstash)下载Logstash。将其提取到所选位置。我们将通过编写一个简单的脚本来检查Logstash的安装。创建一个文件`logstash-simple.conf`，并编写以下代码。您可以在`第9章/logstash-simple.conf`中找到此片段：
- en: '[PRE4]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now hit `logstash -f logstash-simple.conf`.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在运行`logstash -f logstash-simple.conf`。
- en: You should be able to see Elasticsearch information printed out. This ensures
    us that our Logstash installation is running perfectly.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该能够看到Elasticsearch信息的打印输出。这确保了我们的Logstash安装正常运行。
- en: 'Next, we need to install RabbitMQ. RabbitMQ is written in Erlang and it requires
    Erlang installation. Install Erlang and make sure that environment variable `ERLANG_HOME`
    is set. Then install RabbitMQ. Once installed, start the `rabbitmq` service as
    follows:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要安装RabbitMQ。RabbitMQ是用Erlang编写的，需要安装Erlang。安装Erlang并确保环境变量`ERLANG_HOME`已设置。然后安装RabbitMQ。安装完成后，按以下步骤启动`rabbitmq`服务：
- en: '[PRE5]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now hit the URL `http://localhost:15672`. You should be able to log in using
    guest/guest credentials, which are by default, and be able to see the RabbitMQ
    dashboard.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在访问`http://localhost:15672`。您应该能够使用默认的guest/guest凭据登录，并且能够看到RabbitMQ仪表板。
- en: 'If you are not able to see the server, you probably need to enable the plugin,
    as follows:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您无法看到服务器，则可能需要启用插件，如下所示：
- en: '`rabbitmq-plugins.bat enable rabbitmq_management rabbitmq_web_mqtt rabbitmq_amqp1_0`'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '`rabbitmq-plugins.bat enable rabbitmq_management rabbitmq_web_mqtt rabbitmq_amqp1_0`'
- en: We have successfully installed RabbitMQ, Logstash, Elasticsearch, and Kibana.
    Now we can move onto our implementation.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已成功安装了RabbitMQ、Logstash、Elasticsearch和Kibana。现在我们可以继续我们的实施。
- en: Please check extracted source `/customlogging` to see our solution in action.
    The solution makes use or previous architecture as explained.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 请检查提取的源代码`/customlogging`，以查看我们解决方案的运行情况。该解决方案利用了我们之前解释的架构。
- en: Distributed tracing in Node.js
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Node.js中的分布式跟踪
- en: 'Distributed tracing is like tracing a particular service request that spans
    across all of the services that are involved in serving that request. These services
    construct a graph like they form a tree rooted at the client that starts the initial
    request. Zipkin provides an instrumentation layer to generate IDs for a service
    request, based on which we can trace data from all applications by using that
    ID. In this section, we will look at how to use Zipkin. You can find the complete
    source at `Chapter 9/Zipkin`:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式跟踪就像跟踪跨越涉及提供该请求的所有服务的特定服务请求一样。这些服务构建了一个图形，就像它们形成了一个以启动初始请求的客户端为根的树。Zipkin提供了一个仪表层，用于为服务请求生成ID，基于这个ID，我们可以通过使用该ID跟踪所有应用程序的数据。在本节中，我们将看看如何使用Zipkin。您可以在`第9章/Zipkin`中找到完整的源代码：
- en: 'Spin up our first microservice or any single microservice project from [Chapter
    4](2dd92134-2db3-4427-8565-1be5bb13be1f.xhtml), *Beginning Your Microservices
    Journey*. We will add the `zipkin` dependencies to it:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[第4章](2dd92134-2db3-4427-8565-1be5bb13be1f.xhtml) *开始您的微服务之旅*中启动我们的第一个微服务或任何单个微服务项目。我们将向其添加`zipkin`依赖项：
- en: '[PRE6]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We now need a Zipkin server. We will configure it to use a Zipkin server along
    with its defaults and just install its jar. Download the `jar` from [https:](https://search.maven.org/remote_content?g=io.zipkin.java&a=zipkin-server&v=LATEST&c=exec)[//search.maven.org/remote_content?g=io.zipkin.java&a=zipkin-server&v=LATEST&c=exec](https://search.maven.org/remote_content?g=io.zipkin.java&a=zipkin-server&v=LATEST&c=exec)
    or you can find it in the extracted source in the `server` folder under `chapter
    9/zipkin`. Once downloaded, open the Zipkin server as follows:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们需要一个Zipkin服务器。我们将配置它以使用Zipkin服务器以及其默认设置，并只安装其jar。从[https:](https://search.maven.org/remote_content?g=io.zipkin.java&a=zipkin-server&v=LATEST&c=exec)[//search.maven.org/remote_content?g=io.zipkin.java&a=zipkin-server&v=LATEST&c=exec](https://search.maven.org/remote_content?g=io.zipkin.java&a=zipkin-server&v=LATEST&c=exec)下载`jar`，或者您可以在`第9章/zipkin`的`server`文件夹下找到它。下载完成后，按以下步骤打开Zipkin服务器：
- en: '[PRE7]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following screenshot shows a Zipkin server:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图显示了一个Zipkin服务器：
- en: '![](img/a3867b62-7ad7-4c7f-89a0-566dfee3c2d1.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a3867b62-7ad7-4c7f-89a0-566dfee3c2d1.png)'
- en: log Zipkin
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 记录Zipkin
- en: As seen in the screenshot, the Zipkin server has lots of options, including
    providing a collector for receiving trace information, storage, and UI options
    to examine it.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 如屏幕截图所示，Zipkin服务器有很多选项，包括提供用于接收跟踪信息的收集器、存储和UI选项以检查它。
- en: Now, we will configure multiple Express servers so as to observe how Zipkin
    instruments the whole thing. We will first set up Zipkin on a single microservice
    followed by multiple microservices later on. Our code from the previous chapter
    adds any product information in our MongoDB database. We will be configuring Zipkin
    here. We need to tell Zipkin where to send tracing data (that's pretty obvious!
    This will be our Zipkin server running on `9411`) and how to send tracing data
    (that's the question—Zipkin has three support options HTTP, Kafka, and Fluentd.
    We will be using HTTP). So basically we send a POST request to the Zipkin server.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将配置多个Express服务器，以观察Zipkin如何仪器化整个过程。我们将首先在单个微服务上设置Zipkin，然后稍后在多个微服务上设置。我们在上一章的代码中将任何产品信息添加到我们的MongoDB数据库中。我们将在这里配置Zipkin。我们需要告诉Zipkin要发送跟踪数据的位置（这是显而易见的！这将是运行在`9411`上的我们的Zipkin服务器）以及如何发送跟踪数据（这是个问题——Zipkin有三种支持选项HTTP、Kafka和Fluentd。我们将使用HTTP）。因此，基本上我们向Zipkin服务器发送一个POST请求。
- en: 'We need some imports to configure our Zipkin server. Open `Express.ts` and
    add the following lines of code:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要一些导入来配置我们的Zipkin服务器。打开`Express.ts`并添加以下代码行：
- en: '[PRE8]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`Tracer` is used to give information such as where and how to send tracing
    data. It handles generating `traceIds` and tells the transport layer when to record
    what.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Tracer`用于提供诸如何在哪里以及如何发送跟踪数据的信息。它处理生成`traceIds`并告诉传输层何时记录什么。'
- en: '`BatchRecorder` formats tracing data to be sent to the Zipkin collector.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BatchRecorder`格式化跟踪数据以发送到Zipkin收集器。'
- en: '`HTTPLogger` is our HTTP Transport layer. It knows how to post Zipkin data
    over HTTP.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HTTPLogger`是我们的HTTP传输层。它知道如何通过HTTP发布Zipkin数据。'
- en: '`CLSContext` object refers to Continuation Local Storage. Continuation passing
    is the pattern where the function calls the next function in a chain of functions
    with the data it needs. An example of this is Node.js custom middleware layer.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CLSContext`对象是指Continuation Local Storage。Continuation passing是指函数调用链中的下一个函数使用它需要的数据的模式。其中一个例子是Node.js自定义中间件层。'
- en: 'We''re now putting all the pieces together. Add the following lines of code:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在正在将所有部分放在一起。添加以下代码行：
- en: '[PRE9]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This will set up Zipkin essentials along with a tracer that will generate a
    64-bit trace ID. Now we need to instrument our Express server.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这将设置Zipkin基本要素以及将生成64位跟踪ID的跟踪器。现在我们需要为我们的Express服务器进行仪器化。
- en: 'Now, we will tell our `express` application to use `ZipkinMiddleware` in its
    middleware layer:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将告诉我们的`express`应用程序在其中间件层中使用`ZipkinMiddleware`：
- en: '[PRE10]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The name of service in our case `'products-service'` will actually come in tracing
    data.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，服务的名称`'products-service'`实际上将出现在跟踪数据中。
- en: 'Let''s hit our service to see what is the actual result. Run the program, make
    a POST request to `products/add-update-product`, and open up Zipkin. You will
    be able to see `products-service` (the name of the service under which we registered
    to Zipkin server) in the Service Name dropdown. And when you do a search query
    you will be able to see something like the following:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们调用我们的服务，看看实际结果是什么。运行程序，向`products/add-update-product`发出POST请求，并打开Zipkin。您将能够在服务名称下拉菜单中看到`products-service`（我们在Zipkin服务器下注册的服务名称）。当您进行搜索查询时，您将能够看到类似以下内容的东西：
- en: '![](img/2ed10c2e-8c07-4924-a91c-628676ef15f7.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2ed10c2e-8c07-4924-a91c-628676ef15f7.jpg)'
- en: Zipkin service log
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Zipkin服务日志
- en: This is how it looks when we are dealing with one microservice. You get traces
    about successful as well as failed service calls here too, as seen in the figure.
    We want to wrap our head around services that have more than one microservices
    involved.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是当我们处理一个微服务时的情况。您在这里也会得到有关成功和失败服务调用的跟踪，就像图中所示的那样。我们希望能够理解涉及多个微服务的服务。
- en: For those, who are directly running the code; please ensure that the following
    lines are commented out in the `ProductsController.tslet` file—`userRes= await
    this.zipkinFetch('http://localhost:3000/users/user-by-id/parthghiya');` and `console.log("user-res",userRes.text());`.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 对于直接运行代码的人，请确保在`ProductsController.tslet`文件中注释掉以下行—`userRes= await this.zipkinFetch('http://localhost:3000/users/user-by-id/parthghiya');`和`console.log("user-res",userRes.text());`。
- en: Let's assume in our case that we have one more microservice involved based on
    our business capability that plays with owners authenticity. So, whenever a product
    is added, we want to check whether the owner is an actual user or not.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设在我们的情况下，我们还涉及另一个微服务，基于我们的业务能力，它与所有者的真实性有关。因此，每当添加产品时，我们希望检查所有者是否是实际用户。
- en: We will just create two projects with dummy logic.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将只创建两个带有虚拟逻辑的项目。
- en: Create another microservice project with a user and create a GET request with
    `@Get('/user-by-id/:userId')`, which basically returns whether a user exists or
    not. We will be calling that microservice from our existing project. You can follow
    along from `chapter-9/user`.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建另一个带有用户的微服务项目，并使用`@Get('/user-by-id/:userId')`创建一个GET请求，该请求基本上返回用户是否存在。我们将从现有项目中调用该微服务。您可以从`chapter-9/user`中跟随。
- en: In the existing project, we moved out the configurations of Zipkin to the external
    file so it can be reused throughout the project. Check out the source code of
    `ZipkinConfig.ts`
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在现有项目中，我们将Zipkin的配置移出到外部文件中，以便在整个项目中重复使用。查看`ZipkinConfig.ts`的源代码
- en: 'In `ProductController.ts`, instantiate a new object of Zipkin instrumentation
    fetch, as follows:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`ProductController.ts`中，实例化一个新的Zipkin仪器化fetch对象，如下所示：
- en: '[PRE11]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Make a fetch request, as follows:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行fetch请求，如下所示：
- en: '[PRE12]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Open up the Zipkin dashboard and you will be able to see the following:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Zipkin仪表板，您将能够看到以下内容：
- en: '![](img/1239f4ec-7071-47d5-ac1d-386301963cff.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1239f4ec-7071-47d5-ac1d-386301963cff.png)'
- en: Zipkin combined
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: Zipkin组合
- en: 'The overall report can be viewed by clicking on the request:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 点击请求即可查看整体报告：
- en: '![](img/e0bf0c1c-5dbf-42aa-8d50-37c406a5bb96.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e0bf0c1c-5dbf-42aa-8d50-37c406a5bb96.png)'
- en: Tracing report
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪报告
- en: Tracing is an invaluable tool that helps to diagnose problems when they occur
    by tracing out any request across the entire microservices ecosystem. In the next
    section, we will look at monitoring microservices.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 追踪是一个无价的工具，它可以通过跟踪整个微服务生态系统中的任何请求来帮助诊断问题。在下一节中，我们将了解监控微服务。
- en: Monitoring
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控
- en: Microservices are truly distributed systems with a vast technological and deployment
    topology. Without proper monitoring in place, the operational team may soon run
    into trouble managing large-scale microservice systems. To add complications to
    our problem, microservices dynamically change their topologies based on load.
    This demands a proper monitoring service. In this section, we will learn about
    the need of monitoring and look at some monitoring tools.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务是真正分布式系统，具有庞大的技术和部署拓扑。如果没有适当的监控，运营团队可能很快就会遇到管理大规模微服务系统的麻烦。为了给我们的问题增加复杂性，微服务根据负载动态改变其拓扑。这需要一个适当的监控服务。在本节中，我们将了解监控的需求，并查看一些监控工具。
- en: Monitoring 101
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控101
- en: Let's start by discussing Monitoring 101\. Monitoring, in general, can be defined
    as a collection of some metrics, predefined **service level agreements** (**SLAs**),
    aggregation, and their validations and adherence to prefixed baseline values.
    Whenever there is a service level breach, a monitoring tool has to generate an
    alert and send it across to administrators. In this section, we will look at monitoring
    to understand the behavior of a system from a user experience point of view, and
    the challenges of monitoring, and to understand all aspects involved in Node.js
    monitoring.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从讨论监控101开始。一般来说，监控可以被定义为一些指标、预定义的**服务水平协议**（SLAs）、聚合以及它们的验证和遵守预设的基线值的集合。每当服务水平出现违规时，监控工具必须生成警示并发送给管理员。在本节中，我们将查看监控，以了解系统的用户体验方面的行为，监控的挑战，以及了解Node.js监控所涉及的所有方面。
- en: Monitoring challenges
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控挑战
- en: 'Similar to logging issues, the key challenge in monitoring microservices ecosystems
    is that there are too many dynamic parts. Being totally dynamic, the key challenges
    in monitoring microservices are as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 与记录问题类似，监控微服务生态系统的关键挑战在于有太多的动态部分。由于完全动态，监控微服务的主要挑战如下：
- en: Statistics and metrics are distributed across many services, multiple instances,
    and multiple machines or containers.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计数据和指标分布在许多服务、多个实例和多台机器或容器上。
- en: Polyglot environment adds more difficulties. A single monitoring tool does not
    suffice all the required monitoring options.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多语言环境增加了更多的困难。单一的监控工具无法满足所有所需的监控选项。
- en: Microservices deployment topologies differ in huge variations. Several parameters
    such as scalability, auto configuration, circuit breaker, and so on, change the
    architecture on-demand basis. This makes it impossible to monitor preconfigure
    servers, instances, or any other monitoring parameters.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务部署拓扑在很大程度上不同。诸如可伸缩性、自动配置、断路器等多个参数会根据需求基础改变架构。这使得不可能监控预配置的服务器、实例或任何其他监控参数。
- en: In the next section, we are going to look at the next part of monitoring, which
    is alerting. We cannot alert every time due to errors. We need some definitive
    rules.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将看一下监控的下一个部分，即警示。由于错误，我们不能每次都发出警示。我们需要一些明确的规则。
- en: When to alert and when not to alert?
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时警示何时不警示？
- en: 'No one is excited to wake up at 3.00 AM in the morning on Sunday. The general
    rule for alerting can be if something is not stopping customers from using your
    system and increasing your funds, then the situation is not worth waking up at
    3.00 AM. In this section, we will look at some instances and decide when to alert
    and when not to:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 没有人会因为某些事情阻止客户使用系统并增加资金而在凌晨3点被吵醒而感到兴奋。警示的一般规则可以是，如果某事没有阻止客户使用您的系统并增加您的资金，那么这种情况不值得在凌晨3点被吵醒。在本节中，我们将查看一些实例，并决定何时警示何时不警示：
- en: '**Service goes down**: Had it been monolithic, this would surely be a huge
    blow but, being a good microservice coder, you already have set up multiple instances
    and clustering. This would impact just a single user who would get functionality
    back on again service request and would prevent the failure to cascade up. However,
    if many services go down then this is definitely something worth alerting.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务宕机**：如果是单体化，这肯定会是一个巨大的打击，但作为一个优秀的微服务编码人员，您已经设置了多个实例和集群。这只会影响一个用户，该用户会在服务请求后再次获得功能，并防止故障级联。但是，如果许多服务宕机，那么这绝对值得警示。'
- en: '**Memory leak**: Memory leaks are another painful thing, as only after careful
    monitoring can we actually find the leak. A good microservice practice suggests
    setting up the environment so that it should be able to decommission an instance
    once it surpasses a certain memory threshold. The problem will fix itself on system
    restart. But if processes are running out of memory quickly then it is something
    worth alerting.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存泄漏：内存泄漏是另一件令人痛苦的事情，只有经过仔细监控，我们才能真正找到泄漏。良好的微服务实践建议设置环境，使其能够在实例超过一定内存阈值后停用该实例。问题将在系统重新启动时自行解决。但是，如果进程迅速耗尽内存，那么这是值得警示的事情。
- en: '**Slow services**: A slow usable service is not worth alerting until or unless
    it occupies a huge resource pool. A good microservice practice suggests using
    an async architecture with event-based and queue-based implementations.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务变慢**：一个慢的可用服务不值得警示，除非它占用了大量资源。良好的微服务实践建议使用基于事件和基于队列的异步架构。'
- en: '**Increasing 400s and 500s**: If there is an exponential increase in the number
    of 400s and 500s then there is something fishy worth alerting. 4xx codes usually
    indicate erroneous services or misconfigured core tools. This is definitely worth
    alerting.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**400和500的增加**：如果400和500的数量呈指数增长，那么值得警示。4xx代码通常表示错误的服务或配置错误的核心工具。这绝对值得警示。'
- en: In the next section, we will get the actual implementation of monitoring tools
    available in the Node.js community. We will see hands-on examples with those in
    sections of Keymetrics and Prometheus with Grafana.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看到Node.js社区中可用的监控工具的实际实现。我们将在Keymetrics和Grafana中看到这些工具的实际示例。
- en: Monitoring tools
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控工具
- en: 'In this section, we will look at some of the available tools for monitoring
    and how those tools help us to solve different monitoring challenges. When monitoring
    a microservice, we are mostly interested in hardware resources and application
    metrics:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将看一些可用的监控工具，以及这些工具如何帮助我们解决不同的监控挑战。在监控微服务时，我们主要关注硬件资源和应用程序指标：
- en: '| **  Hardware resources** |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| **硬件资源** |'
- en: '| Memory utilization metrics | The amount of memory that is consumed by the
    application, such as RAM utilization, hard disk occupied, and so on. |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 内存利用率指标 | 应用程序消耗的内存量，比如RAM利用率、硬盘占用等等。 |'
- en: '| CPU utilization metrics | How much percentage of total available CPU memory
    is it using at a given time. |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| CPU利用率指标 | 在给定时间内使用了多少百分比的总可用CPU内存。 |'
- en: '| Disk Utilization metrics | The I/O memory in a hard drive, such as swap space,
    available space, used space, and so on. |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| 磁盘利用率指标 | 硬盘中的I/O内存，比如交换空间、可用空间、已用空间等等。 |'
- en: '| **Application metrics** |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| **应用程序指标** |'
- en: '| Errors thrown per unit of time | The number of critical errors that are thrown
    from the application. |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 每单位时间抛出的错误 | 应用程序抛出的关键错误的数量。 |'
- en: '| Calls made/service occupancy per unit of time | This metric basically tells
    us about the traffic on a service. |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| 每单位时间的调用次数/服务占用率 | 这个指标基本上告诉我们服务的流量情况。 |'
- en: '| Response time | How much time is being utilized to respond to a service request.
    |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| 响应时间 | 用于响应服务请求所使用的时间。 |'
- en: '| The number of restarts of service | Node.JS being single threaded, this thing
    should be monitored. |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 服务重启次数 | Node.JS是单线程的，这个事情应该被监控。 |'
- en: The power of LINUX makes it easy to query hardware metrics. The `/proc` folder
    in Linux has all the necessary information. Basically, it has a directory for
    each of the running processes in the system, including kernel processes. Each
    directory there contains other useful metadata.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: LINUX的强大使得查询硬件指标变得容易。Linux的`/proc`文件夹中包含了所有必要的信息。基本上，它为系统中运行的每个进程都有一个目录，包括内核进程。那里的每个目录都包含其他有用的元数据。
- en: 'When it comes to application metrics it becomes hard to go with some inbuilt
    tools. Some of the widely used monitoring tools are as follows:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到应用程序指标时，很难使用一些内置工具。一些广泛使用的监控工具如下：
- en: AppDynamics, Dynatrace, and New Relic are leaders in application performance
    monitoring. But these are in the commercial segment.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AppDynamics、Dynatrace和New Relic是应用程序性能监控领域的领导者。但这些都是商业领域的。
- en: Cloud vendors come with their own monitoring tools, like AWS uses Amazon Cloudwatch
    and Google Cloud platform uses Cloud monitoring.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云供应商都有自己的监控工具，比如AWS使用Amazon Cloudwatch，Google Cloud平台使用Cloud monitoring。
- en: Loggly, ELK, Splunk, and Trace are top candidates in open source segments.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Loggly、ELK、Splunk和Trace是开源领域中的热门候选者。
- en: We will now look at some of the available tools in the Node.js community.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将看一些Node.js社区中可用的工具。
- en: PM2 and keymetrics
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PM2和keymetrics
- en: 'We already looked at the power of PM2 and how it helps us solve various issues,
    such as clustering, keeping Node.js processes running forever, zero downtimes,
    and so on. PM2 has a monitoring tool, too, that maintains several application
    metrics. PM2 introduced keymetrics as a complete tool with in-built features,
    such as the dashboard, optimization process, code manipulation from keymetrics,
    exception reporting, load balancer, transaction tracing, CPU and memory monitoring,
    and so on. It is an SAAS-based product with an option of free tier. In this section,
    we will use the free tier. So, let''s get started:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了PM2的强大之处，以及它如何帮助我们解决各种问题，比如集群、使Node.js进程永远运行、零停机时间等等。PM2也有一个监控工具，可以维护多个应用程序指标。PM2引入了keymetrics作为一个完整的工具，具有内置功能，如仪表板、优化过程、来自keymetrics的代码操作、异常报告、负载均衡器、事务跟踪、CPU和内存监控等等。它是一个基于SAAS的产品，有免费套餐选项。在这一节中，我们将使用免费套餐。所以，让我们开始吧：
- en: The first thing we need to do is to sign up for the free tier. Create an account
    and once you log in, you will be able to see the main screen. Once registered
    we will come to a screen where we configure our bucket.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是注册免费套餐。创建一个账户，一旦你登录，你就能看到主屏幕。注册后，我们将来到一个屏幕，在那里我们配置我们的bucket。
- en: A bucket is a container on which multiple servers and multiple apps are attached.
    A bucket is something through which keymetrics define the context. For example,
    our shopping cart microservice has different services (payments, product catalog,
    inventory, and so on) hosted somewhere, and we could monitor all the servers in
    one bucket so that everything is easy to access.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 一个bucket是一个容器，上面连接了多个服务器和多个应用程序。一个bucket是keymetrics定义上下文的东西。例如，我们的购物车微服务有不同的服务（支付、产品目录、库存等等）托管在某个地方，我们可以监控一个bucket中的所有服务器，这样一切都很容易访问。
- en: 'Once we create our bucket we will get a screen like the following. This screen
    has all the information and necessary documentation required for getting started
    with keymetrics:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们创建了我们的bucket，我们将会得到一个像下面这样的屏幕。这个屏幕上有所有启动keymetrics所需的信息和必要的文档：
- en: '![](img/17044d3e-ccc1-4e78-8aaa-57bfc3f7a291.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![](img/17044d3e-ccc1-4e78-8aaa-57bfc3f7a291.png)'
- en: Keymetrics after bucket created
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 创建bucket后的Keymetrics
- en: 'We can see commands for connecting PM2 to keymetrics and Docker with keymetrics,
    which we will be using further on:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到连接PM2到keymetrics和Docker与keymetrics的命令，我们将在接下来使用：
- en: '[PRE13]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Also as part of the installation, you will need the PM2 monitor. Once PM2 is
    installed, run the following command:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 作为安装的一部分，你将需要PM2监视器。一旦安装了PM2，运行以下命令：
- en: '[PRE14]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The next step is to configure PM2 to push data in keymetrics. Now, to enable
    communication between server and keymetrics, the following ports need to be opened: Ports
    80 (TCP out) and 43554 (TCP in/out) must be opened. PM2 pushes data to port `80`
    on keymetrics, whereas keymetrics pushes data back on port `43554`. Now, we will
    configure keymetrics in our product-catalog microservice.
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是配置PM2将数据推送到keymetrics。现在，为了启用服务器和keymetrics之间的通信，需要打开以下端口：需要打开端口80（TCP输出）和43554（TCP输入/输出）。PM2将数据推送到keymetrics的端口`80`，而keymetrics将数据推送回端口`43554`。现在，我们将在我们的产品目录微服务中配置keymetrics。
- en: 'Make sure that PM2 is installed in your system. If not, just install it as
    a global module by executing the following command:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保在您的系统中安装了PM2。如果没有，请执行以下命令将其安装为全局模块：
- en: '[PRE15]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Then link your PM2 with keymetrics by executing the following command:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后通过执行以下命令将您的PM2与keymetrics连接起来：
- en: '[PRE16]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Once open, just change your `package.json` script to start with PM2 instead
    of a simple node process. Just add the following script in `package.json`:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦打开，只需更改您的`package.json`脚本，以使用PM2而不是简单的node进程启动。只需在`package.json`中添加以下脚本：
- en: '[PRE17]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Once started as a PM2 process you should be able to see the process started
    and the dashboard URL:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦作为PM2进程启动，您应该能够看到进程已启动和仪表板URL：
- en: '![](img/16c6686c-a4cc-4f88-8831-80634dd158b2.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![](img/16c6686c-a4cc-4f88-8831-80634dd158b2.png)'
- en: PM2 start with keymetrics
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 使用keymetrics启动PM2
- en: 'Head over to keymetrics and you will be able to see the live dashboard:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到keymetrics，您将能够看到实时仪表板：
- en: '![](img/2d29e270-86ae-40e8-b8f5-96b057ae3220.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2d29e270-86ae-40e8-b8f5-96b057ae3220.png)'
- en: Keymetrics dashboard
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: Keymetrics 仪表板
- en: It gives us interesting metrics, such as CPU usage, available memory, HTTP average
    response, available disk memory, errors, processes, and so on. In the next section,
    we will look at utilizing keymetrics to solve our monitoring challenges.
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它为我们提供了有趣的指标，比如CPU使用率、可用内存、HTTP平均响应时间、可用磁盘内存、错误、进程等等。在接下来的部分，我们将看看如何利用keymetrics来解决我们的监控挑战。
- en: Keymetrics to monitor application exceptions and runtime problems
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Keymetrics 监控应用程序异常和运行时问题
- en: 'Although PM2 does a pretty good job of keeping the server up and running, we
    need to monitor all unknown exceptions that occur or potential sources of memory
    leaks. PMX provides just the module for that. You can follow the example in `chapter
    9/pmx-utilities`. Initialize `pmx` as usual. Just whenever there is an error,
    notify `pmx` with the `notify` method:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管PM2在保持服务器运行良好方面做得很好，但我们需要监视所有发生的未知异常或潜在的内存泄漏源。PMX正好提供了这个模块。您可以在`第9章/pmx-utilities`中查看示例。像往常一样初始化`pmx`。只要有错误发生，就用`notify`方法通知`pmx`：
- en: '[PRE18]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This is enough to send out an error to keymetrics to give it information about
    application exceptions. You will receive email notifications, too.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这足以向keymetrics发送错误，以便提供有关应用程序异常的信息。您也将收到电子邮件通知。
- en: PMX monitors constant usage of the service, too, in order to detect memory leaks,
    if any. Check the route `/memory-leak`, for example.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: PMX还监视服务的持续使用，以便检测内存泄漏。例如，检查路由`/memory-leak`。
- en: 'The following shows several important keymetrics highlighted:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 以下显示了几个重要的keymetrics亮点：
- en: '![](img/7f15decc-9a17-423a-82a0-b207195786fb.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7f15decc-9a17-423a-82a0-b207195786fb.png)'
- en: Pmx utilities
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: Pmx实用程序
- en: Adding custom metrics
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加自定义指标
- en: 'Lastly, we will see how to add our own custom metrics based on our business
    capabilities and on a need basis. Most of the time, we often need some customization
    or we are not able to use out of the box functionalities as such. Keymetrics provides
    us with probes for this. A probe in keymetrics is a custom metric that is sent
    to keymetrics programmatically. There are four kinds of probes that we will see,
    with examples:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将看到如何根据我们的业务能力和需求添加自定义指标。大多数情况下，我们经常需要一些定制，或者我们无法使用现成的功能。Keymetrics为我们提供了用于此目的的探针。在keymetrics中，探针是以编程方式发送到keymetrics的自定义指标。我们将看到四种探针及其示例：
- en: '**Simple metrics**: Values that can be read instantly, that is, used to monitor
    any variable value. It is a very basic metric where the developer can set a value
    to the data that is pushed to keymetrics.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简单指标**：可以立即读取的值，用于监视任何变量值。这是一个非常基本的指标，开发人员可以为推送到keymetrics的数据设置一个值。'
- en: '**Counter**: Things that increment or decrement, that is, downloads being processed,
    a user connected, number of times a service request is hit, the database goes
    down, and so on.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计数器**：递增或递减的事物，比如正在处理的下载、已连接的用户、服务请求被命中的次数、数据库宕机等。'
- en: '**Meter**: Things that are measured as events/intervals, that is, requests
    per minute for an HTTP server, and so on.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计量器**：被视为事件/间隔进行测量的事物，比如HTTP服务器每分钟的请求次数等。'
- en: '**Histogram**: It keeps a reservoir of statistically relevant values especially
    biased towards the last five minutes to explore their distribution, such as monitoring
    the mean of execution of a query into a database for the last five minutes, and
    so on.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**直方图**：它保留了一个与统计相关的储备，特别偏向于最后五分钟，以探索它们的分布，比如监控最近五分钟内查询执行的平均时间等。'
- en: We will be using `pmx` ([https://www.npmjs.com/package/pmx](https://www.npmjs.com/package/pmx))
    to see examples of custom metrics. PMX is one of the leading modules for PM2 runner
    that allows exposure of metrics that are associated with the application. It can
    reveal useful patterns that can help scale the service as per demand or to efficiently
    utilize resources.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`pmx`（[https://www.npmjs.com/package/pmx](https://www.npmjs.com/package/pmx)）来查看自定义指标的示例。PMX是PM2运行器的主要模块之一，允许公开与应用程序相关的指标。它可以揭示有用的模式，有助于根据需求扩展服务或有效利用资源。
- en: Simple metrics
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单指标
- en: 'Setting a PM2 metric value is just a matter of initializing a probe and setting
    a value in it. We can create a simple metric with the following steps. You can
    follow the source in `chapter 9/simple_metric`:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 设置PM2指标值只是初始化一个探针并在其中设置一个值的问题。我们可以通过以下步骤创建一个简单的指标。您可以在`第9章/简单指标`中查看源代码：
- en: 'Copy our `first microservice` skeleton from [Chapter 2](c1987454-3c62-4e25-abf5-28a9abf833e8.xhtml),
    *Gearing up for the Journey*. We will add our changes here. Install `pm2` and
    `pmx` modules as a dependency:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[第2章](c1987454-3c62-4e25-abf5-28a9abf833e8.xhtml)复制我们的`first microservice`骨架，*为旅程做准备*。我们将在这里添加我们的更改。安装`pm2`和`pmx`模块作为依赖项：
- en: '[PRE19]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In `HelloWorld.ts`, initialize `pmx` with the following code. We will add a
    simple metric name `''Simple Custom metric''` along with variable initializations:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`HelloWorld.ts`中，使用以下代码初始化`pmx`。我们将添加一个简单的度量名称`'Simple Custom metric'`以及变量初始化：
- en: '[PRE20]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We initialized pmx with a few options, such as the following:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用一些选项初始化了pmx，比如以下内容：
- en: '`http`: HTTP routes should be logged and PM2 will be enabled to perform HTTP
    watching for HTTP related metrics'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`http`：HTTP路由应该被记录，并且PM2将被启用来执行与HTTP相关的度量监视'
- en: '`errors`: Exceptions logging'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`errors`：异常日志记录'
- en: '`custom_probes`: JS Loop latency and HTTP requests should be automatically
    exposed as custom metrics'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`custom_probes`：JS循环延迟和HTTP请求应该自动公开为自定义度量'
- en: '`ports`: It should show which ports our app is listening to'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`端口`：它应该显示我们的应用正在监听的端口'
- en: 'Now you can initialize this value anywhere using the following:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你可以在任何地方使用以下方法初始化这个值：
- en: '[PRE21]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'You can now see it in the keymetrics dashboard, as follows:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以在keymetrics仪表板中看到它，如下所示：
- en: '![](img/95b1e043-fcf4-45dc-86b8-03d680d2a9a6.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![](img/95b1e043-fcf4-45dc-86b8-03d680d2a9a6.png)'
- en: Simple metric
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 简单度量
- en: Counter metric
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计数器度量
- en: 'This metric is very useful in order to see things such as how many times an
    event has occurred. In this exercise, we will see the number of times that our
    `/hello-world` is invoked. You can follow along with the example in `Chapter 9/counter-metric`:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 这个度量是非常有用的，可以看到事件发生的次数。在这个练习中，我们将看到我们的`/hello-world`被调用的次数。你可以在`Chapter 9/counter-metric`中的示例中跟着做：
- en: 'Initialize the project as before. Add the `pmx` dependency. Create one `CustomMiddleware`
    with the option of routing controller:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 像往常一样初始化项目。添加`pmx`依赖项。创建一个带有路由控制器选项的`CustomMiddleware`：
- en: '[PRE22]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Add that annotation before `HelloWorld.ts` and run the application:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`HelloWorld.ts`之前添加注释并运行应用程序：
- en: '[PRE23]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You should be able to see something like the following:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能够看到类似以下的东西：
- en: '![](img/b8088b76-83df-4685-9c86-b67ea87f2502.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b8088b76-83df-4685-9c86-b67ea87f2502.png)'
- en: Counter metric
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 计数器度量
- en: Meter
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计量
- en: 'This metric allows us to record when an event actually occurs and the number
    of occurrences of events per time unit. Calculating average is quite useful as
    it essentially gives us an idea about the load in the system. In this exercise,
    we will look at how to utilize meter metrics:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 这个度量允许我们记录事件实际发生的时间以及每个时间单位内事件发生的次数。计算平均值非常有用，因为它基本上给了我们一个关于系统负载的想法。在这个练习中，我们将看一下如何利用计量度量：
- en: 'Initialize project as usual. Install the `pmx` and `pm2` dependency. It consists
    of the following keywords:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 像往常一样初始化项目。安装`pmx`和`pm2`依赖项。它包括以下关键字：
- en: '**samples:** This parameter corresponds to interval based on which we want
    to measure the metric. In our case, it is the number of calls per minute, hence
    `60`.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**样本：**此参数对应于我们想要测量指标的间隔。在我们的案例中，这是每分钟的呼叫次数，因此是`60`。'
- en: '**timeframe:** This is how long we want to hold the keymetrics data, the overall
    time frame over which it will be analyzed.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间范围：**这是我们想要保存keymetrics数据的时间长度，它将被分析的总时间范围。'
- en: 'Add the following code in the constructor to initialize meter metric dependency:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在构造函数中添加以下代码以初始化计量器度量依赖项：
- en: '[PRE24]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In route, `@Get('/')` will initialize this mark. This will give us an average
    number of calls per minute for the route `<server_url>/hello-world: this.metric.mark();`.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在路由中，`@Get('/')`将初始化这个标记。这将给我们一个路由`<server_url>/hello-world`每分钟平均呼叫次数。
- en: Now, run this metric. You will be able to see the value in the keymetrics dashboard.
    Similarly, you can use histogram metric.
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在运行这个度量。你将能够在keymetrics仪表板中看到这个值。同样，你可以使用直方图度量。
- en: In the next section, we will look at the more advanced tools available.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看一下更高级的可用工具。
- en: Prometheus and Grafana
  id: totrans-324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Prometheus和Grafana
- en: 'Prometheus is a famous open-source tool, which provides powerful data compression
    options along with fast data querying for time series data analysis for Node.js
    monitoring. Prometheus has built-in visualization methods, but it''s not configurable
    enough to leverage in dashboards. That''s where Grafana steps in. In this section,
    we will look at how to monitor a Node.js microservice using Prometheus and Grafana.
    So let''s get our hands dirty with coding. You can follow along with the example
    in `Chapter 9/prometheus-grafana` in the source:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus是一个著名的开源工具，它为Node.js监控提供了强大的数据压缩选项以及快速的时间序列数据查询。Prometheus具有内置的可视化方法，但它的可配置性不足以在仪表板中利用。这就是Grafana的作用。在本节中，我们将看一下如何使用Prometheus和Grafana监控Node.js微服务。所以让我们开始动手编码吧。你可以在源代码中的`Chapter
    9/prometheus-grafana`中的示例中跟着做：
- en: 'As always, initialize a new project from `chapter-2/first microservice`. Add
    the following dependencies:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 像往常一样，从`chapter-2/first microservice`初始化一个新项目。添加以下依赖项：
- en: '[PRE25]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: These dependencies will make sure that we will be able to monitor the Node.js
    engine as well as be able to collect response time from the service.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 这些依赖项将确保我们能够监控Node.js引擎，并能够从服务中收集响应时间。
- en: 'Next, we will write some middlewares to be used across the microservice stages,
    such as injecting in Express, and using after middleware. Create a `MetricModule.ts` file
    and add the following code:'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将编写一些中间件，用于跨微服务阶段使用，比如在Express中注入，并在后期使用中间件。创建一个`MetricModule.ts`文件，并添加以下代码：
- en: '[PRE26]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Next we will create some custom functions to be used as middlewares. Here,
    we will create one function; you can check out other functions in `Chapter 9/prometheus-grafana/config/metrics-module/MetricModule.ts`:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来我们将创建一些自定义函数用作中间件。在这里，我们将创建一个函数；你可以在`Chapter 9/prometheus-grafana/config/metrics-module/MetricModule.ts`中查看其他函数：
- en: '[PRE27]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Take a look at the following functions mentioned in the preceding code:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下前面代码中提到的以下函数：
- en: The  first function starts a new counter with variable
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个函数启动一个新的计数器变量
- en: The second function starts Prometheus metrics
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个功能启动Prometheus指标
- en: The third function is a middleware that increments the number of requests
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个功能是一个中间件，用于增加请求的数量
- en: The function counter except for metrics route
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了指标路由之外的功能计数器
- en: 'Next, we add the metrics route:'
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们添加指标路由：
- en: '[PRE28]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Next, we inject middleware in our `express` application. In `express.ts`, simply
    add the following LOC:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们在`express`应用程序中注入中间件。在`express.ts`中，只需添加以下LOC：
- en: '[PRE29]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Node.js setup is done. Now it''s time to start Prometheus. Create one folder
    called `prometheus-data` and inside it create one `yml config` file:'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Node.js设置完成。现在是启动Prometheus的时候了。创建一个名为`prometheus-data`的文件夹，在其中创建一个`yml配置`文件：
- en: '[PRE30]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Spawn up the Docker process by running the following:'
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令来启动Docker进程：
- en: '[PRE31]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Your Prometheus should be up and running and you should see a screen like the
    following:'
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的Prometheus应该已经启动并运行，并且您应该看到以下屏幕：
- en: '![](img/1ed18efc-4bcd-4457-8476-90bb1f3002de.png)'
  id: totrans-347
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1ed18efc-4bcd-4457-8476-90bb1f3002de.png)'
- en: Prom dashboard
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: Prom仪表板
- en: Perform something on your application or use some stress testing tools, such
    as JMeter or [https://www.npmjs.com/package/loadtest](https://www.npmjs.com/package/loadtest).
    Then open up Prometheus and, in the query shell, write `sum(numOfRequests)`. You
    will be able to see live graph and results. These are the same results that can
    be seen when we hit `<server_url>/metrics`. Hit the following query to try to
    see Node.js memory usage the `avg(nodejs_external_memory_bytes / 1024 / 1024)
    by (service)`.
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在应用程序上执行一些操作，或者使用一些压力测试工具，如JMeter或[https://www.npmjs.com/package/loadtest](https://www.npmjs.com/package/loadtest)。然后打开Prometheus，在查询shell中写入`sum(numOfRequests)`。您将能够看到实时图形和结果。这些结果与我们访问`<server_url>/metrics`时看到的结果相同。尝试使用以下查询来查看Node.js内存使用情况`avg(nodejs_external_memory_bytes
    / 1024 / 1024) by (service)`。
- en: 'Prometheus is great, but it cannot be used as a dashboard. Hence, we utilize
    Grafana, which has excellent and pluggable visualization platform features. It
    has built-in Prometheus data source support. Hit the following command to open
    up Docker images of Grafana:'
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Prometheus很棒，但不能用作仪表板。因此，我们使用Grafana，它具有出色的可插拔可视化平台功能。它具有内置的Prometheus数据源支持。输入以下命令以打开Grafana的Docker镜像：
- en: '[PRE32]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Once up, go to `localhost:3000` and add `admin/admin` in username/password to
    log in.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦启动，转到`localhost:3000`，并在用户名/密码中添加`admin/admin`以登录。
- en: 'Once logged in, add a data source with Prometheus as type (open up the Add
    Data source screen) and enter your IP address: `9090` in the HTTP URL (your Prometheus
    running URL) and `Server (Default)` (the way you are accessing Prometheus) in
    the Access text box, so as to configure Prometheus as a data source. Click on
    save and test to confirm whether the settings are working or not. You can checkout 
    the following screenshot for better understanding:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录后，添加一个类型为Prometheus的数据源（打开“添加数据源”屏幕），并在HTTP URL（您的Prometheus运行URL）中输入IP地址：`9090`，在“访问”文本框中输入“服务器（默认）”（您访问Prometheus的方式），以配置Prometheus作为数据源。单击保存并测试以确认设置是否有效。您可以查看以下屏幕截图以更好地理解：
- en: '![](img/c0b1f294-7cad-4351-a6f3-0873375f7fda.png)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c0b1f294-7cad-4351-a6f3-0873375f7fda.png)'
- en: Grafana
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana
- en: 'Once the data source is configured, you can have custom graphs or anything,
    and design your own custom dashboard through GUI tools. It will look as follows:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦配置了数据源，您可以通过GUI工具自定义图形或其他内容，并设计自己的自定义仪表板。它将如下所示：
- en: '![](img/907fdaa8-2b11-4945-abfd-ec8e210eb8cc.png)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![](img/907fdaa8-2b11-4945-abfd-ec8e210eb8cc.png)'
- en: Grafana
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana
- en: Prometheus is a powerful tool for not only monitoring single Node.js applications,
    but it can be used in a polyglot environment too. With Grafana, you can create
    the dashboard that fits your needs best.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus不仅是监控单个Node.js应用程序的强大工具，还可以在多语言环境中使用。使用Grafana，您可以创建最适合您需求的仪表板。
- en: These are prominent tools used in deployment in Node.js Monitoring. There are
    other tools, too, but integrating them involves need of Polyglot environment.
    For instance, [Simian Army](https://github.com/Netflix/SimianArmy/wiki/Chaos-Monkey).
    It is widely used and promoted by Netflix to handle various cloud computing challenges.
    It is built with a variety of simian army monkey tools to maintain network health,
    handle traffic, and locate security problems.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是在Node.js监控部署中使用的重要工具。还有其他工具，但整合它们需要多语言环境。例如，[Simian Army](https://github.com/Netflix/SimianArmy/wiki/Chaos-Monkey)。它被Netflix广泛使用和推广，用于处理各种云计算挑战。它构建了各种类猴工具来维护网络健康，处理流量，并定位安全问题。
- en: Production-ready microservice criteria
  id: totrans-361
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可投入生产的微服务标准
- en: 'We are quickly going to summarize a production-ready microservice and its criteria:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将快速总结一个可投入生产的微服务及其标准：
- en: 'A production-ready to go microservice is reliable and stable for service requests:'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可投入生产的微服务对服务请求是可靠和稳定的：
- en: It follows a standard development cycle adhering to 12-factor app standards
    (recall [Chapter 1](2eeeb09d-ecd0-403b-8a64-ac754090cebe.xhtml), *Debunking Microservices*)
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它遵循符合12因素应用标准的标准开发周期（回顾[第1章](2eeeb09d-ecd0-403b-8a64-ac754090cebe.xhtml)，*揭秘微服务*）
- en: Its code is thoroughly tested through linters, unit test cases, integration,
    contract, and E2E test cases
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它的代码经过严格的测试，包括linter、单元测试用例、集成、合同和端到端测试用例
- en: It uses CI/CD pipelines and incremental build strategy
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使用CI/CD流水线和增量构建策略
- en: There are either backups, alternatives, fallbacks, and cache in place in case
    of service failures
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在服务失败的情况下，有备份、替代、回退和缓存
- en: It has stable service registration and discovery process as per standards
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它具有符合标准的稳定的服务注册和发现过程
- en: 'A production-ready to go microservice is scalable and highly available:'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可投入生产的微服务是可扩展和高可用的：
- en: It has auto scalability based on load coming at any time
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它根据任何时间到来的负载自动扩展
- en: It utilizes hardware resources efficiently and does not block resource pool
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它有效利用硬件资源，不会阻塞资源池
- en: Its dependencies scale with the application
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它的依赖随着应用程序的规模而扩展
- en: Its traffic can be rerouted on a need basis
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它的流量可以根据需要重新路由
- en: It handles tasks and processes in a performant nonblocking and preferably asynchronous
    reactive manner
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它以高性能的非阻塞和最好是异步的反应方式处理任务和进程
- en: 'A production-ready to go microservice is ready for any unprepared catastrophe:'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可以立即投入生产的微服务应该准备好应对任何未经准备的灾难：
- en: It does not have any single point of failure
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它没有任何单点故障
- en: It is tested for resiliency through enough code testing and load testing
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它经过足够的代码测试和负载测试来测试其弹性
- en: Failure detection, stopping the failure from cascading, and remediation towards
    failure have been automated along with auto scalability
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 故障检测，阻止故障级联，以及故障修复都已经自动化，并且具备自动扩展能力
- en: 'A production-ready to go microservice is properly monitored:'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可以立即投入生产的微服务应该得到适当的监控：
- en: It has its identified keymetrics (custom metrics, errors, the memory occupied,
    and so on) monitored constantly not only pertaining to microservice level, but
    also expanding to host and infrastructure level
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它不仅在微服务级别不断监控其识别的关键指标（自定义指标，错误，内存占用等），还扩展到主机和基础设施级别
- en: It has a dashboard that is easy to interpret and has all important keymetrics
    (you bet, PM2 is our only choice)
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它有一个易于解释的仪表板，并且具有所有重要的关键指标（你打赌，PM2是我们唯一的选择）
- en: Actionable alerts defined by signal providing thresholds (Prometheus and time
    series query)
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过信号提供阈值（Prometheus和时间序列查询）定义可操作的警报
- en: 'A production-ready to go microservice is documented:'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可以立即投入生产的微服务应该有文档支持：
- en: Comprehensive document generated through tools such as Swagger
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Swagger等工具生成的全面文档
- en: Architecture is audited frequently and well reviewed to support polyglot environment
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 架构经常审计和审查，以支持多语言环境
- en: Summary
  id: totrans-386
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about the deployment process. We saw some go live
    criteria, a deployment pipeline, and finally got acquainted with Docker. We saw
    some Docker commands and got acquainted with the world of dockerization. Then
    we saw some of the challenges involved with logging and monitoring when dealing
    with huge distributed microservices. We explored various solutions for logging
    and implemented a custom centralized logging solution using the famous ELK stack.
    In the latter half of the chapter, we saw monitoring tools, such as keymetrics
    and Prometheus.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了部署过程。我们看到了一些上线标准，部署流水线，并最终熟悉了Docker。我们看到了一些Docker命令，并熟悉了Docker化的世界。然后，我们看到了处理大型分布式微服务时涉及的一些日志记录和监控方面的挑战。我们探索了各种日志记录的解决方案，并实施了使用著名的ELK堆栈的自定义集中式日志记录解决方案。在本章的后半部分，我们看到了一些监控工具，比如keymetrics和Prometheus。
- en: 'The next chapter will explore the final part of our product: security and scalability.
    We will see how to protect our Node.js applications against brute force attacks
    and what exactly our security plan should be. Then, we will look at scalability
    and scale our microservice through AWS—auto scalability.'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将探讨我们产品的最后部分：安全性和可扩展性。我们将看到如何保护我们的Node.js应用程序免受暴力攻击，以及我们的安全计划应该是什么。然后，我们将研究可扩展性，并通过AWS实现微服务的自动扩展。
