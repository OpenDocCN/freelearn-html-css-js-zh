- en: Deploying Microservices
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微服务部署
- en: 'In this chapter, we''ll cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下菜谱：
- en: Configuring your service to run in a container
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置您的服务以在容器中运行
- en: Running multi-container applications with Docker Compose
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Docker Compose运行多容器应用程序
- en: Deploying your service on Kubernetes
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Kubernetes上部署您的服务
- en: Test releases with canary deployments
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用金丝雀部署进行测试发布
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: The way we deliver software to users has changed dramatically over the years.
    In the not too distant past, it was common to deploy to production by running
    a shell script on a collection of servers that pulled an update from some kind
    of source control repository. The problems with this approach are clear—scaling
    this out was difficult, bootstrapping servers was error prone, and deployments
    could easily get stuck in an undesired state, resulting in unpredictable experiences
    for users.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，我们向用户交付软件的方式发生了巨大的变化。在不太遥远的过去，通过在服务器集合上运行shell脚本来部署到生产环境是很常见的，这些服务器从某种源代码存储库中拉取更新。这种方法的问题很明显——扩展这个方法很困难，启动服务器容易出错，部署可能会陷入不希望的状态，从而导致用户体验不可预测。
- en: The advent of configuration management systems, such as **Chef** or **Puppet**,
    improved this situation somewhat. Instead of having custom bash scripts or commands
    that ran on remote servers, remote servers could be tagged with a kind of role
    that instructed them on how to configure and install software. The declarative
    style of automating configuration was better suited for large-scale software deployments.
    Server automation tools such as **Fabric** or **Capistrano** were also adopted;
    they sought to automate the process of pushing code to production, and are still
    very popular today for applications that do not run in containers.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 配置管理系统的出现，如**Chef**或**Puppet**，在某种程度上改善了这种情况。与在远程服务器上运行自定义bash脚本或命令不同，远程服务器可以被标记为一种角色，指示它们如何配置和安装软件。声明式自动化配置的风格更适合大规模软件部署。还采用了服务器自动化工具，如**Fabric**或**Capistrano**；它们旨在自动化将代码推送到生产的过程，并且至今仍非常受欢迎，用于不在容器中运行的应用程序。
- en: Containers have revolutionized the way we deliver software. Containers allow
    developers to package their code with all the dependencies, including libraries,
    the runtime, OS tools, and configurations. This allows code to be delivered without
    the need to configure the host server, which dramatically simplifies the process
    by removing the number of moving pieces.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 容器已经彻底改变了我们交付软件的方式。容器允许开发者将他们的代码及其所有依赖项打包，包括库、运行时、操作系统工具和配置。这使得代码的交付无需配置主机服务器，通过减少移动部件的数量，大大简化了过程。
- en: The process of shipping services in containers has been referred to as **immutable
    infrastructure**, because once an image is built, it isn't typically changed;
    instead, new versions of a service result in a new image being built.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器中运输服务的过程被称为**不可变基础设施**，因为一旦构建了镜像，通常不会对其进行更改；相反，服务的新版本会导致构建新的镜像。
- en: Another big change in how software is deployed is the popularization of the
    twelve-factor methodology ([https://12factor.net/](https://12factor.net/)). **Twelve-factor**
    (or **12f**, as it is commonly written) is a set of guidelines originally written
    by engineers at Heroku. At their core, twelve-factor apps are designed to be loosely
    coupled with their environment, resulting in services that can be used along with
    various logging tools, configuration systems, package management systems, and
    source control systems. Arguably, the most universally adopted concepts employed
    by twelve-factor apps are that the configuration is accessed through environment
    variables and logs are output to standard out. As we saw in the previous chapters,
    this is how we've integrated with systems such as Vault. These chapters are worth
    a read, but we've already been following many concepts described in twelve-factor
    so far in this book.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 软件部署方式中的另一个重大变化是十二要素方法的普及([https://12factor.net/](https://12factor.net/))。**十二要素**（或**12f**，如通常书写）是由Heroku的工程师编写的一系列指南。在核心上，十二要素应用程序旨在与环境松散耦合，从而产生可以与各种日志工具、配置系统、软件包管理系统和源代码控制系统一起使用的服务。可以说，十二要素应用程序最普遍采用的概念是配置通过环境变量访问，日志输出到标准输出。正如我们在前面的章节中看到的，这是我们与Vault等系统集成的这种方式。这些章节值得一读，但我们在本书中已经遵循了许多十二要素中描述的概念。
- en: In this chapter, we'll be discussing containers, orchestration, and scheduling,
    and various methods for safely shipping changes to users. This is a very active
    topic, and new techniques are being improvised and discussed, but the recipes
    in this chapter should serve as a good starting point, especially if you're accustomed
    to deploying monoliths on virtual machines or bare metal servers.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论容器、编排和调度，以及将更改安全地发送给用户的各种方法。这是一个非常活跃的话题，新的技术正在被发明和讨论，但本章中的菜谱应该是一个很好的起点，特别是如果你习惯于在虚拟机或裸机服务器上部署单体应用。
- en: Configuring your service to run in a container
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置你的服务在容器中运行
- en: As we know, services are made up of source code and configurations. A service
    written in Java, for instance, can be packaged as a **Java Archive** (**JAR**)
    file containing compiled class files in Java bytecode, as well as resources such
    as configuration and properties files. Once packaged, the JAR file can then be
    executed on any machine running a **Java Virtual Machine** (**JVM**).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所知，服务由源代码和配置组成。例如，用 Java 编写的服务可以被打包成一个包含编译后的 Java 字节码的 **Java 存档**（**JAR**）文件，以及配置和属性文件等资源。一旦打包，JAR
    文件就可以在任何运行 **Java 虚拟机**（**JVM**）的机器上执行。
- en: In order for this to work, however, the machine that we want to run our service
    on must have a JVM installed. Oftentimes, it must be a specific version of the
    JVM. Additionally, the machine might need to have some other utilities installed,
    or it might need access to a shared filesystem. While these are not parts of the
    service themselves, they do make up what we refer to as the runtime environment
    of the service.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了使这一切工作，我们想要运行服务的机器必须安装了 JVM。通常，它必须是 JVM 的特定版本。此外，机器可能需要安装一些其他实用程序，或者可能需要访问共享文件系统。虽然这些不是服务本身的组成部分，但它们构成了我们所说的服务的运行时环境。
- en: Linux containers are a technology that allow developers to package an application
    or service with its complete runtime environment. Containers separate out the
    runtime for a particular application from the runtime of the host machine that
    the container is running on.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Linux 容器是一种技术，允许开发者将应用程序或服务及其完整的运行时环境打包在一起。容器将特定应用程序的运行时与容器运行的宿主机的运行时分离出来。
- en: This makes applications more portable, making it easier to move a service from
    one environment to another. An engineer can run a service on their laptop, then
    move it into a preproduction environment, and then into production, without changing
    the container itself. Containers also allow you to easily run multiple services
    on the same machine, therefore allowing much more flexibility in how application
    architectures are deployed and providing opportunities for operational cost optimization.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得应用程序更加可移植，使得将服务从一个环境迁移到另一个环境变得更加容易。工程师可以在他们的笔记本电脑上运行一个服务，然后将其移动到预生产环境，然后进入生产环境，而无需更改容器本身。容器还允许你轻松地在同一台机器上运行多个服务，因此提供了更多灵活性，以部署应用程序架构，并提供了优化运营成本的机会。
- en: Docker is a container runtime and set of tools that allows you to create self-contained
    execution environments for your service. There are other popular container runtimes
    they are widely used today, but Docker is designed to make containers portable
    and flexible, making it an ideal choice for building containers for services.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 是一个容器运行时和一系列工具，允许你为你的服务创建自包含的执行环境。今天还有其他流行的容器运行时被广泛使用，但 Docker 被设计成使容器可移植和灵活，使其成为构建服务容器的理想选择。
- en: In this recipe, we'll use Docker to create an image that packages our message-service.
    We'll do this by creating a `Dockerfile` file and using the Docker command-line
    utility to create an image and then run that image as a container.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用 Docker 创建一个打包我们的消息服务的镜像。我们将通过创建一个 `Dockerfile` 文件，并使用 Docker 命令行工具来创建镜像，然后运行该镜像作为容器来实现这一点。
- en: How to do it…
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'The steps for this recipe are as follows:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个菜谱的步骤如下：
- en: 'First, open our message-service project from the previous chapters. Create
    a new file in the root of the project called `Dockerfile`:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，从上一章打开我们的消息服务项目。在项目的根目录下创建一个名为 `Dockerfile` 的新文件：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `Dockerfile` file defines the base image that we''ll use to build our message-service
    image. In this case, we''re basing our image off of an Alpine Linux image with
    OpenJDK 8\. Next, we expose the port that our service binds to and define how
    to run our service after it''s packaged as a JAR file. We''re now ready to use
    the `Dockerfile` file to build an image. This is done with the following command:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Dockerfile` 文件定义了我们将用于构建 message-service 镜像的基础镜像。在这种情况下，我们基于一个带有 OpenJDK 8
    的 Alpine Linux 镜像。接下来，我们暴露了我们的服务绑定的端口，并定义了如何将我们的服务作为 JAR 文件打包后运行。我们现在可以使用 `Dockerfile`
    文件来构建镜像。这可以通过以下命令完成：'
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You can verify that the preceding command worked by running `docker images`
    and seeing ours listed. Now we''re ready to run the message service by executing
    our service in a container. This is done with the `docker run` command. We''ll
    also give it a port mapping and specify the image that we want to use to run our
    service:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以通过运行 `docker images` 并查看我们的镜像是否列出来验证前面的命令是否成功。现在我们准备好通过在容器中执行我们的服务来运行消息服务。这是通过
    `docker run` 命令完成的。我们还将给它一个端口映射并指定我们想要用于运行服务的镜像：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Running multi-container applications with Docker Compose
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Docker Compose 运行多容器应用
- en: Services rarely run in isolation. A microservice usually connects to a data
    store of some kind, and could have other runtime dependencies. In order to work
    on a microservice, it's necessary to run it locally on a developer's machine.
    Requiring engineers to manually install and manage all the runtime dependencies
    of a service in order to work on a microservice would be impractical and time
    consuming. Instead, we need a way to automatically manage runtime service dependencies.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 服务很少独立运行。一个微服务通常连接到某种类型的数据存储，并且可能有其他运行时依赖。为了在微服务上工作，有必要在开发者的机器上本地运行它。要求工程师手动安装和管理服务的所有运行时依赖以在微服务上工作将是不切实际且耗时的。相反，我们需要一种自动管理运行时服务依赖的方法。
- en: Containers have made services more portable by packaging the runtime environment
    and configuration with the application code as a shippable artifact. In order
    to maximize the benefits of using containers for local development, it would be
    great to be able to declare all the dependencies and run them in separate containers.
    This is what Docker Compose is designed to do.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 容器通过将运行时环境和配置与应用程序代码一起打包为可运输的工件，使得服务更加便携。为了最大限度地发挥使用容器进行本地开发的益处，能够声明所有依赖并在单独的容器中运行它们将是非常好的。这正是
    Docker Compose 设计来做的。
- en: Docker Compose uses a declarative YAML configuration file to determine how an
    application should be executed in multiple containers. This makes it easy to quickly
    start up a service, a database, and any other runtime dependencies of the service
    in a way that makes local development especially easy.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose 使用声明性的 YAML 配置文件来确定应用程序应该如何在多个容器中执行。这使得快速启动服务、数据库以及服务的任何其他运行时依赖变得非常容易。
- en: In this recipe, we'll follow some of the steps from the previous recipe to create
    a `Dockerfile` file for the authentication-service project. We'll then create
    a Docker Compose file that specifies MySQL as a dependency of the authentication-service.
    We'll then look at how to configure our project and run it locally with one container
    running our application and another running a database server.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将遵循前一个食谱中的某些步骤来为 authentication-service 项目创建一个 `Dockerfile` 文件。然后，我们将创建一个
    Docker Compose 文件，指定 MySQL 作为 authentication-service 的依赖项。然后，我们将查看如何配置我们的项目并在本地运行它，一个容器运行我们的应用程序，另一个运行数据库服务器。
- en: How to do it…
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'For this recipe, you need to perform the following steps:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个食谱，你需要执行以下步骤：
- en: 'Open the authentication-service project and create a new file called `Dockerfile`:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 authentication-service 项目并创建一个名为 `Dockerfile` 的新文件：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Docker Compose uses a file called `docker-compose.yml` to declare how containerized
    applications should be run:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Compose 使用一个名为 `docker-compose.yml` 的文件来声明容器化应用应该如何运行：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As we''ll be connecting to the MySQL server running in the `docker-mysql` container,
    we''ll need to modify our authentication-service configuration to use that host
    when connecting to MySQL:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们将连接到在 `docker-mysql` 容器中运行的 MySQL 服务器，我们需要修改 authentication-service 的配置，以便在连接到
    MySQL 时使用该主机：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You can now run the authentication-service and MySQL with the following:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你现在可以使用以下命令运行 authentication-service 和 MySQL：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: That's it! The authentication-service should now be running locally in a container.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就这样！authentication-service 应该现在已经在本地容器中运行了。
- en: Deploying your service on Kubernetes
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上部署你的服务
- en: Containers make services portable by allowing you to package code, dependencies,
    and the runtime environment together in one artifact. Deploying containers is
    generally easier than deploying applications that do not run in containers. The
    host does not need to have any special configuration or state; it just needs to
    be able to execute the container runtime. The ability to deploy one or more containers
    on a single host gave rise to another challenge when managing production environments—scheduling
    and orchestrating containers to run on specific hosts and manage scaling.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 容器通过允许你将代码、依赖项和运行时环境打包在一个工件中，使得服务可移植。部署容器通常比部署不运行在容器中的应用程序更容易。主机不需要任何特殊的配置或状态；它只需要能够执行容器运行时。在单个主机上部署一个或多个容器的能力，在管理生产环境时产生了另一个挑战——调度和编排容器在特定主机上运行并管理扩展。
- en: Kubernetes is an open source container orchestration tool. It is responsible
    for scheduling, managing, and scaling your containerized applications. With Kubernetes,
    you do not need to worry about deploying your container to one or more specific
    hosts. Instead, you declare what resources your container needs and let Kubernetes
    decide how to do the work (what host the container runs on, what services it runs
    alongside, and so on). Kubernetes grew out of the **Borg paper** ([https://research.google.com/pubs/pub43438.html](https://research.google.com/pubs/pub43438.html)),
    published by engineers at Google, which described how they managed services in
    Google's data centers using the Borg cluster manager.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是一个开源的容器编排工具。它负责调度、管理和扩展你的容器化应用程序。使用 Kubernetes，你无需担心将容器部署到一台或多台特定的主机上。相反，你只需声明你的容器需要哪些资源，然后让
    Kubernetes 决定如何执行工作（容器运行在哪个主机上，它旁边运行哪些服务等等）。Kubernetes 是从 Google 工程师发布的 **Borg
    论文** ([https://research.google.com/pubs/pub43438.html](https://research.google.com/pubs/pub43438.html))
    中发展而来的，这篇论文描述了他们如何使用 Borg 集群管理器在 Google 的数据中心管理服务。
- en: Kubernetes was started by Google as an open source project in 2014 and has enjoyed
    widespread adoption by organizations deploying code in containers.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是 Google 在 2014 年启动的一个开源项目，并且被部署容器代码的组织广泛采用。
- en: Installing and managing a Kubernetes cluster is beyond the scope of this book.
    Luckily, a project called **Minikube** allows you to easily run a single-node
    Kubernetes cluster on your development machine. Even though the cluster only has
    one node, the way you interface with Kubernetes when deploying your service is
    generally the same, so the steps here can be followed for any Kubernetes cluster.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 安装和管理 Kubernetes 集群超出了本书的范围。幸运的是，一个名为 **Minikube** 的项目允许你在开发机器上轻松运行单个节点的 Kubernetes
    集群。尽管集群只有一个节点，但当你部署服务时与 Kubernetes 交互的方式通常是一样的，所以这里的步骤可以适用于任何 Kubernetes 集群。
- en: In this recipe, we'll install Minikube, start a single-node Kubernetes cluster,
    and deploy the `message-service` command we've worked with in previous chapters.
    We'll use the Kubernetes CLI tool (`kubectl`) to interface with Minikube.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将安装 Minikube，启动单个节点的 Kubernetes 集群，并部署我们在前几章中使用的 `message-service`
    命令。我们将使用 Kubernetes CLI 工具 (`kubectl`) 与 Minikube 进行交互。
- en: How to do it…
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'For this recipe, you need to go through the following steps:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个菜谱，你需要完成以下步骤：
- en: 'In order to demonstrate how to deploy our service to a `kubernetes` cluster,
    we''ll be using a tool called `minikube`. The `minikube` tool makes it easy to
    run a single-node `kubernetes` cluster on a VM that can be run on a laptop or
    development machine. Install `minikube`. On macOS X, you can use HomeBrew to do
    this:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了演示如何将我们的服务部署到 `kubernetes` 集群，我们将使用一个名为 `minikube` 的工具。`minikube` 工具使得在可以运行在笔记本电脑或开发机器上的虚拟机（VM）上运行单个节点的
    `kubernetes` 集群变得容易。在 macOS X 上，你可以使用 HomeBrew 来安装它：
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We''ll also be using the `kubernetes` CLI tools in this recipe, so install
    those. On macOS X, using HomeBrew, you can type as follows:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们还将使用 `kubernetes` CLI 工具，所以请安装它们。在 macOS X 上，使用 HomeBrew，你可以输入以下内容：
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now we''re ready to start our single-node `kubernetes` cluster. You can do
    this by running `minikube start`:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经准备好启动我们的单个节点 `kubernetes` 集群。你可以通过运行 `minikube start` 来完成这个操作：
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, set the `minikube` cluster up as the default configuration for the `kubectl`
    CLI tool:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，将 `minikube` 集群设置为 `kubectl` CLI 工具的默认配置：
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Verify that everything is configured properly by running the `cluster-info`
    command:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行 `cluster-info` 命令来验证一切配置是否正确：
- en: '[PRE11]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: To further debug and diagnose cluster problems, use `kubectl cluster-info dump`.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步调试和诊断集群问题，使用 `kubectl cluster-info dump`。
- en: 'You should now be able to launch the `kubernetes` dashboard in a browser:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你应该能够在浏览器中启动`kubernetes`仪表板：
- en: '[PRE12]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The `minikube` tool uses a number of environment variables to configure the
    CLI client. Evaluate the environment variables with the following command:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`minikube`工具使用多个环境变量来配置CLI客户端。使用以下命令评估环境变量：'
- en: '[PRE13]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Next, we''ll build the docker image for our service using the `Dockerfile` file
    created in the previous recipe:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用之前配方中创建的`Dockerfile`文件为我们的服务构建docker镜像：
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Finally, run the `message-service` command on the `kubernetes` cluster, telling
    `kubectl` the correct image to use and the port to expose:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，在`kubernetes`集群上运行`message-service`命令，告诉`kubectl`正确的镜像和要暴露的端口：
- en: '[PRE15]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can verify that the `message-service` command is running in the `kubernetes`
    cluster by listing the pods on the cluster:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过列出集群上的pods来验证`message-service`命令是否在`kubernetes`集群中运行：
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In order to access the `message-service` command, we''ll need to expose it
    as a new service:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了访问`message-service`命令，我们需要将其作为新的服务暴露出来：
- en: '[PRE17]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We can verify the previous command by listing services on the `kubernetes`
    services:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过列出`kubernetes`服务上的服务来验证上一条命令：
- en: '[PRE18]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The `minikube` tool has a convenient command for accessing a service running
    on the `kubernetes` cluster. Running the following command will list the URL that
    the `message-service` command is running on:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`minikube`工具有一个方便的命令来访问在`kubernetes`集群上运行的服务。运行以下命令将列出`message-service`命令正在运行的URL：'
- en: '[PRE19]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Use `curl` to try and make a request against the service to verify that it's
    working. Congratulations! You've deployed the `message-service` command on `kubernetes`.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`curl`尝试向服务发送请求以验证其是否正常工作。恭喜！你已经在`kubernetes`上部署了`message-service`命令。
- en: Test releases with canary deployments
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用金丝雀部署进行测试发布
- en: Improvements in best practices for deploying have greatly improved the stability
    of deploys over the years. Automating the repeatable steps, standardizing the
    way our application interacts with the runtime environment, and packaging our
    application code with the runtime environment have all made deployments safer
    and easier than they used to be.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 部署最佳实践的改进极大地提高了多年来部署的稳定性。自动化可重复步骤、标准化我们的应用程序与运行时环境的交互方式，以及将我们的应用程序代码与运行时环境打包在一起，都使得部署比以前更安全、更容易。
- en: Introducing new code to a production environment is not without risk, however.
    All the techniques discussed in this chapter help prevent predictable mistakes,
    but they do nothing to prevent actual software bugs from negatively impacting
    users of the software we write. Canary deployment is a technique for reducing
    this risk and increasing confidence in new code that is being deployed to production.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 将新代码引入生产环境并非没有风险。本章中讨论的所有技术都有助于防止可预测的错误，但它们并不能阻止实际软件错误对我们所编写的软件用户产生负面影响。金丝雀部署是一种减少这种风险并增加对部署到生产环境的新代码的信心的一种技术。
- en: With a canary deployment, you begin by shipping your code to a small percentage
    of production traffic. You can then monitor metrics, logs, traces, or whatever
    other tools allow you to observe how your software is working. Once you are confident
    that things are going as they should, you can gradually increase the percentage
    of traffic that receives your updated version until all production traffic is
    being served by the newest release of your service.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在金丝雀部署中，你首先将代码发送到一小部分生产流量。然后你可以监控指标、日志、跟踪或其他允许你观察软件工作情况的工具。一旦你确信一切按预期进行，你可以逐渐增加接收更新版本流量的百分比，直到所有生产流量都由你服务的最新版本提供服务。
- en: The term **canary deployment** comes from a technique that coal miners used
    to use to protect themselves from carbon monoxide or methane poisoning. By having
    a canary in the mine, the toxic gases would kill the canary before the miners,
    giving the miners an early warning sign that they should get out. Similarly, canary
    deployments allow us to expose a subset of users to risk without impacting the
    rest of the production environment. Thankfully, no animals have to be harmed when
    deploying code to production environments.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: “金丝雀部署”这个术语来自煤矿工人用来保护自己免受一氧化碳或甲烷中毒的技术。通过在矿井中放置金丝雀，有毒气体会在矿工之前杀死金丝雀，给矿工一个提前的警告信号，告诉他们应该离开。同样，金丝雀部署允许我们向一小部分用户暴露风险，而不会影响生产环境的其余部分。幸运的是，在将代码部署到生产环境时，不需要伤害任何动物。
- en: Canary deployments used to be very difficult to get right. Teams shipping software
    in this way usually had to come up with some kind of feature-toggling solution
    that would gate requests to certain versions of the application being deployed.
    Thankfully, containers have made this much easier, and Kubernetes has made it
    even more so.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 金丝雀部署过去一直很难正确实施。以这种方式运输软件的团队通常必须想出某种功能切换解决方案，以控制对正在部署的应用程序特定版本的请求。幸运的是，容器使这变得容易得多，而Kubernetes则使其变得更加容易。
- en: In this recipe, we'll deploy an update to our `message-service` application
    using a canary deployment. As Kubernetes is able to pull images from a Docker
    container registry, we'll run a registry locally. Normally, you'd use a self-hosted
    registry or a service such as *Docker Hub* or *Google Container Registry*. First,
    we'll ensure that we have a stable version of the `message-service` command running
    in `minikube`, then we'll introduce an update and gradually roll it out to 100%
    traffic.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用金丝雀部署来部署我们的`message-service`应用程序的更新。由于Kubernetes能够从Docker容器仓库拉取镜像，我们将在本地运行一个仓库。通常，你会使用自托管的仓库或像*Docker
    Hub*或*Google Container Registry*这样的服务。首先，我们将确保在`minikube`中运行一个稳定的`message-service`命令版本，然后我们将引入一个更新，并逐渐将其推出到100%流量。
- en: How to do it…
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Go through the following steps to set up a canary deployment:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤设置金丝雀部署：
- en: 'Open the `message-service` project we''ve worked on in the previous recipes.
    Add the following `Dockerfile` file to the root directory of the project:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开我们在之前菜谱中工作的`message-service`项目。将以下`Dockerfile`文件添加到项目的根目录：
- en: '[PRE20]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In order for Kubernetes to know whether the service is running, we need to
    add a liveness probe endpoint. Open the `MessageController.java` file and add
    a method to respond to GET requests at the `/ping` path:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了让Kubernetes知道服务是否正在运行，我们需要添加一个存活性探针端点。打开`MessageController.java`文件，并添加一个方法来响应`/ping`路径的GET请求：
- en: '[PRE21]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s start our container registry on port 5000:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在5000端口上启动我们的容器仓库：
- en: '[PRE22]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'As we''re using a local repository that is not configured with a valid SSL
    cert, start `minikube` with the ability to pull from insecure repositories:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们正在使用一个未配置有效SSL证书的本地仓库，请以能够从非安全仓库拉取的能力启动`minikube`：
- en: '[PRE23]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Build the `message-service` docker image, and then push the image to the local
    container registry with the following commands:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建名为`message-service`的docker镜像，然后使用以下命令将镜像推送到本地容器仓库：
- en: '[PRE24]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'A **Kubernetes Deployment** object describes the desired state for a pod and
    `ReplicaSet`. In our deployment, we''ll specify that we want three replicas of
    our `message-service` pod running at all times, and we''ll specify the liveness
    probe that we created a few steps earlier. To create a deployment for our `message-service`,
    create a file called `deployment.yaml` with the following contents:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Kubernetes Deployment**对象描述了Pod和`ReplicaSet`的期望状态。在我们的部署中，我们将指定我们希望始终运行三个`message-service`
    Pod的副本，并且我们将指定我们之前创建的存活性探针。为了为我们的`message-service`创建一个部署，创建一个名为`deployment.yaml`的文件，并包含以下内容：'
- en: '[PRE25]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Next, using `kubectl`, we''ll create our deployment object:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用`kubectl`，我们将创建我们的部署对象：
- en: '[PRE26]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'You can now verify that our deployment is live and that Kubernetes is creating
    the pod replicas by running `kubectl get pods`:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你现在可以通过运行`kubectl get pods`来验证我们的部署是活跃的，并且Kubernetes正在创建Pod副本：
- en: '[PRE27]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now that our application is running in Kubernetes, the next step is to create
    an update and roll it out to a subset of pods. First, we need to create a new
    docker image; in this case, we''ll call it version 0.1.2 and push it to the local
    repository:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们的应用程序正在Kubernetes中运行，下一步是创建一个更新并将其推出到Pod子集。首先，我们需要创建一个新的docker镜像；在这种情况下，我们将称之为版本0.1.2，并将其推送到本地仓库：
- en: '[PRE28]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We can now configure a deployment to run the newest version of our image before
    rolling it out to the rest of the pods.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以配置一个部署，在将其推出到其他Pod之前先运行我们的最新版本镜像。
