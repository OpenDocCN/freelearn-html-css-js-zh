- en: Chapter 7. Abstracting Concurrency
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章。抽象并发
- en: Up until this point in the book, we explicitly modelled concurrency issues in
    our code. With promises, we synchronized two or more asynchronous actions. With
    generators, we created data on-the-fly, avoiding unnecessary memory allocations.
    Finally, we learned that web workers are the workhorses that leverages multiple
    CPU cores.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们在代码中明确地建模了并发问题。使用承诺，我们同步了两个或多个异步操作。使用生成器，我们即时创建数据，避免了不必要的内存分配。最后，我们了解到Web工作者是利用多个CPU核心的得力助手。
- en: In this chapter, we will take all these ideas and put them into the context
    of application code. That is, if concurrency is the default, then we will need
    to make concurrency as unobtrusive as possible. We'll start by exploring various
    techniques that will help us encapsulate concurrency mechanisms within the components
    that we use. Then, we will move straight to improving our code from the previous
    two chapters by using promises to facilitate worker communication.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将把这些想法融入到应用代码的上下文中。也就是说，如果并发是默认的，那么我们需要尽可能让并发不显眼。我们将从探索各种技术开始，这些技术将帮助我们封装我们使用的组件中的并发机制。然后，我们将通过使用承诺来促进工作通信，直接改进前两章中的代码。
- en: Once we're able to abstract worker communication using promises, we'll look
    at implementing lazy workers with the help of generators. We'll also cover worker
    abstraction using the `Parallel.js` library, followed by the concept of worker
    pools.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们能够使用承诺来抽象工作通信，我们将探讨在生成器的帮助下实现懒工作者的方法。我们还将介绍使用`Parallel.js`库进行工作抽象的概念，以及工作池的概念。
- en: Writing concurrent code
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写并发代码
- en: Concurrent programming is hard to get right. Even with contrived example applications,
    the bulk of complexity comes from concurrent code. We obviously want our code
    to be readable while keeping the benefits of concurrency. We want to get the most
    out of each CPU on the system. We only want to compute what we need, when we need
    it. We don't want spaghetti code that joins together several asynchronous operations.
    Focusing on all these aspects of concurrent programming while developing applications
    detracts from what we should really be focusing on—the features that give our
    application value.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 并发编程很难做对。即使是在构造的示例应用中，大部分的复杂性都来自于并发代码。我们显然希望代码可读，同时保持并发的优势。我们希望从系统中的每个CPU上获取最大利益。我们只想在需要的时候计算所需的内容。我们不希望代码像意大利面一样杂乱无章地连接几个异步操作。在开发应用时，专注于所有这些并发编程的方面会分散我们真正应该关注的焦点——那些赋予应用价值的功能。
- en: In this section, we'll look at the approaches that we might use to insulate
    the rest of our application from tricky concurrency bits. This generally means
    making concurrency the default mode—even when there's no real concurrency happening
    under the hood. In the end, we don't want our code to contain 90% concurrency
    acrobatics and 10% functionality.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨我们可能使用的各种方法来隔离我们应用的其他部分，以避免棘手的并发部分。这通常意味着即使底层没有真正的并发发生，也要将并发作为默认模式。最终，我们不希望我们的代码包含90%的并发技巧和10%的功能。
- en: Hiding the concurrency mechanism
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 隐藏并发机制
- en: 'The difficulty with exposing concurrency mechanisms all throughout our code
    is that they''re all slightly different from one another. This magnifies the callback
    hell that we may already find ourselves in. For example, not all concurrent operations
    are network requests that fetch data from some remote resource. Asynchronous data
    might come from a worker or some another callback that''s asynchronous in itself.
    Picture a scenario where we have three disparate data sources used to compute
    a value that we need—all of which are asynchronous. Here''s an illustration of
    the problem:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个代码中暴露并发机制的问题是它们彼此之间都有所不同。这放大了我们可能已经陷入的回调地狱。例如，并非所有的并发操作都是从远程资源获取数据的网络请求。异步数据可能来自工作者或某些本身也是异步的回调。想象一下这样一个场景：我们有三个不同的数据源用于计算我们需要的值——所有这些都是异步的。以下是问题的说明：
- en: '![Hiding the concurrency mechanism](img/B05133_07_01.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![隐藏并发机制](img/B05133_07_01.jpg)'
- en: The data in this diagram is the thing we care about in our application code.
    From the perspective of the feature that we're building we don't care about anything
    above it. So, our front-end architecture needs to encapsulate the complexities
    associated with concurrency. This means each of our components should be able
    to access data in the same way. There's another complication to consider here
    in addition to all our asynchronous data sources—what about when the data isn't
    asynchronous and originates from a local source? What about synchronizing a local
    data source and an HTTP request? We'll cover this in the following section.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 此图中所示的数据是我们应用代码中关注的东西。从我们所构建的功能的角度来看，我们对其之上的任何东西都不感兴趣。因此，我们的前端架构需要封装与并发相关的复杂性。这意味着我们的每个组件都应该能够以相同的方式访问数据。除了我们所有的异步数据源之外，这里还有一个需要考虑的复杂问题——当数据不是异步的，而是来自本地源时怎么办？同步本地数据源和HTTP请求怎么办？我们将在下一节中介绍这个问题。
- en: Without concurrency
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 没有并发
- en: Just because we're writing a concurrent JavaScript application, not every operation
    is inherently concurrent. For example, if one component asks another component
    for data that it already has in memory, then it's not an asynchronous operation
    and is returned immediately. Our application is likely filled with operations
    these, where concurrency simply doesn't make sense. And therein lies the challenge—how
    do we mix asynchronous operations seamlessly with synchronous operations?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们正在编写一个并发JavaScript应用，但并非每个操作都是固有的并发操作。例如，如果一个组件请求另一个组件它已经存储在内存中的数据，那么这不是一个异步操作，会立即返回。我们的应用可能充满了这样的操作，其中并发性根本不适用。这就是挑战所在——我们如何无缝地将异步操作与同步操作混合？
- en: 'The simple answer is that we make the default assumption of concurrency everywhere.
    Promises make this problem tractable. Here''s an illustration of using a promise
    to encapsulate both asynchronous and synchronous operations:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的答案是我们在每个地方都做出了并发的默认假设。承诺使这个问题变得可操作。以下是一个使用承诺封装异步和同步操作的示例：
- en: '![Without concurrency](img/B05133_07_02.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![没有并发](img/B05133_07_02.jpg)'
- en: This looks a lot like the previous diagram with two important differences. We've
    added a `synchronous()` operation; this doesn't have a callback function because
    it doesn't need one. It's not waiting for anything else, so it returns without
    delay. The other two functions are just as they were in the previous diagram;
    both rely on callback functions to feed their data into our application. The second
    important difference is that there's a promise object. This replaces both the
    `sync()` operation and the data concept. Or rather, it melds them into the same
    concept.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来与之前的图表非常相似，但有两大重要区别。我们添加了一个`synchronous()`操作；这个操作没有回调函数，因为它不需要。它不需要等待任何其他东西，所以它会立即返回。其他两个函数与之前的图表中的函数一样；它们都依赖于回调函数将数据输入我们的应用。第二个重要区别是存在一个承诺对象。它取代了`sync()`操作和数据概念。或者更确切地说，它将它们融合成了同一个概念。
- en: This is the key aspect of promises—their general ability to abstract synchronization
    problems away for us. This is applicable not just with network requests, but also
    web worker messages, or any other asynchronous operation that relies on callbacks.
    It requires a bit of an adjustment to think about our data as we promise that
    it'll get here eventually. But, once we close this mental gap, concurrency is
    enabled by default. Concurrency is the default as far as our features are concerned,
    and what we do behind the operating curtain isn't disruptive in the slightest.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是承诺的关键特性——它们能够为我们抽象出同步问题的通用能力。这不仅适用于网络请求，也适用于Web Worker消息，或任何依赖回调的异步操作。我们需要稍微调整一下思维，将数据视为我们承诺它最终会到达。但是，一旦我们填补了这个心理差距，并发性就默认开启了。就我们的功能而言，并发性是默认的，而且我们在操作系统幕后所做的一切都不会造成任何干扰。
- en: 'Let''s turn our attention to some code now. We''ll create two functions: one
    asynchronous and the other a plain old function that simply returns a value. The
    goal here is to make the code that uses these functions the same, despite the
    major differences in how the value is generated:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将注意力转向一些代码。我们将创建两个函数：一个异步函数和一个简单的函数，它只是返回一个值。我们的目标是使使用这些函数的代码相同，尽管值生成的方式存在重大差异：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The trade-off here is the added promise complexity, wrapped around what would
    otherwise be a simple value returned from a function. But in reality, the complexity
    is encapsulated within the promise, and if we weren't writing a concurrent application,
    we obviously would need to concern ourselves with issues such as these. The benefit
    is huge. When everything is a promised value, we can safely rule out the inconsistencies
    that lead to nasty concurrency bugs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的权衡是增加了承诺的复杂性，围绕着一个函数原本简单返回的值。但在现实中，这种复杂性被封装在承诺中，如果我们不是在编写并发应用程序，我们显然需要关注这些问题。好处是巨大的。当一切都是承诺值时，我们可以安全地排除导致讨厌的并发错误的矛盾。
- en: Worker communication with promises
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用承诺进行工作者通信
- en: We now have a handle on why treating primitive values as promises benefits our
    code. It's time to apply this concept to web workers. In the preceding two chapters,
    our code that synchronized responses coming from web workers started to look a
    little intractable. This was because we were essentially trying to emulate many
    boilerplate chores that promises are good at handling. We'll first attempt to
    solve these problems by creating helper functions that wrap the worker communications
    for us, returning promises. Then we'll try another approach that involves extending
    the web worker interface at a lower level. Lastly, we'll look at some more complex
    synchronization scenarios that involve multiple workers, such as those from the
    last chapter.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在明白了将原始值作为承诺处理如何使我们的代码受益。现在是时候将这个概念应用到Web工作者上了。在前面的两章中，我们的代码开始看起来有点难以处理，因为我们实际上是在尝试模拟承诺擅长处理的许多样板工作。我们首先尝试通过创建辅助函数来解决这个问题，这些辅助函数为我们包装了工作者通信，并返回承诺。然后我们将尝试另一种涉及在较低级别扩展Web工作者接口的方法。最后，我们将查看一些更复杂的同步场景，这些场景涉及多个工作者，例如上一章中的那些。
- en: Helper functions
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 辅助函数
- en: It would be ideal if we could get web worker responses back in the form of a
    promise resolution. But, we need to create the promise in the first place—how
    do we do this? Well, we could manually create the promise, where the message that's
    sent to the worker is sent from within the promise executor function. But, if
    we take this approach, we're not much better off than we were before introducing
    promises.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能以承诺解决的形式获取Web工作者的响应，那将是理想的。但是，我们需要首先创建这个承诺——我们如何做到这一点呢？嗯，我们可以手动创建承诺，其中发送给工作者的消息是在承诺执行函数内部发送的。但是，如果我们采取这种方法，我们并没有比引入承诺之前好多少。
- en: 'The trick is to encapsulate both the message posted to the worker and any message
    received from the worker, within a single helper function as is illustrated here:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 技巧是将发送给工作者的消息以及从工作者接收到的任何消息都封装在单个辅助函数中，就像这里所展示的那样：
- en: '![Helper functions](img/B05133_07_03.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![辅助函数](img/B05133_07_03.jpg)'
- en: 'Let''s take a look at an example helper function that implements this pattern.
    First, we''ll need a worker that carries out some task—we''ll start with this:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个实现这种模式的示例辅助函数。首先，我们需要一个执行某些任务的工作者——我们从这个开始：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here we have a worker that will square any number we pass it. This `work()`
    function is intentionally slow so that we can see how our application, as a whole,
    performs when web workers take longer than usual to complete a task. It also uses
    an ID as we''ve seen with our previous web worker examples, so it can reconcile
    with the code that sent the message. Let''s implement the helper function that
    uses this worker now:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，有一个工作者，它会对我们传递给它的任何数字进行平方。这个`work()`函数故意设计得较慢，这样我们就可以看到当Web工作者完成任务的用时比平时长时，整个应用程序的表现。它还使用了一个ID，就像我们在之前的Web工作者示例中看到的那样，这样它就可以与发送消息的代码进行协调。现在让我们实现使用这个工作者的辅助函数：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If we focus on the way that the `square()` function is used, passing a number
    argument and getting a promise as a return value, we can see that this fits in
    with our earlier discussion on making code concurrent by default. For example,
    we can completely remove workers from this scenario and simply change the way
    the helper function resolves the promise that it returns, and the rest of our
    code will continue to function unaltered.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们关注`square()`函数的使用方式，即传递一个数字参数并返回一个承诺作为结果，我们可以看到这符合我们之前关于默认使代码并行的讨论。例如，我们可以完全从这种场景中移除工作者，只需简单地改变辅助函数解决它返回的承诺的方式，其余的代码将继续按原样运行。
- en: The helper function tactic is just one approach to simplify worker communication
    using promises. Perhaps we can decide that we don't necessarily want to maintain
    a bunch of helper functions. Next, we'll look at a more granular approach than
    helper functions.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 辅助函数策略只是简化使用承诺的工作线程通信的一种方法。也许我们可以决定我们不一定需要维护一大堆辅助函数。接下来，我们将探讨一种比辅助函数更细粒度的方法。
- en: Extending postMessage()
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展`postMessage()`
- en: Rather than amassing vast quantities of helper functions, we can take a more
    generic route. There's nothing wrong with helper functions; they're direct and
    to the point. If we reach a point where there are literally hundreds of them,
    their value would start to depreciate very quickly. The more generic approach
    is to keep using `worker.postMessage()`.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 与积累大量辅助函数相比，我们可以采取更通用的路线。辅助函数没有错；它们直接且简洁。如果我们真的有数百个，它们的价值会迅速贬值。更通用的方法是一直使用`worker.postMessage()`。
- en: 'So let''s see if we can make this method return a promise just like our helper
    function from the previous section. This way, we keep using the granular `postMessage()`method,
    but improve our synchronization semantics. First, here''s the worker code:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们是否可以使这个方法返回一个承诺，就像我们上一节中的辅助函数一样。这样，我们继续使用细粒度的`postMessage()`方法，但改进了我们的同步语义。首先，这是工作线程代码：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This is nothing radically different from what we''ve seen so far in our web
    worker code. Now, in the main thread, we have to figure out how to alter the interface
    of `Worker`. Let''s do this now. Then, we''ll try posting some messages to this
    worker and resolving promises as a response:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们迄今为止在web工作线程代码中看到的内容并没有什么根本的不同。现在，在主线程中，我们必须找出如何改变`Worker`的接口。让我们现在就做这件事。然后，我们将尝试向这个工作线程发送一些消息，并作为响应解析承诺：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Well, this is exactly what we need, right? We can post message data directly
    to the worker, and the response data is sent back to us through the promise resolution.
    As an added bonus, we can actually wrap helper functions around this new `postMessage()`
    function implementation if we're so inclined. The main trick involved with making
    this work is storing a reference to the original `postMessage()`. Then, we override
    the web worker property `postMessage`, not the function itself. Finally, we can
    reuse it to add the necessary reconciliation and promise goodness.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，这正是我们所需要的，对吧？我们可以直接将消息数据发送到工作线程，响应数据则通过承诺解析返回给我们。作为额外的奖励，如果我们愿意，实际上可以在这个新的`postMessage()`函数实现周围包装辅助函数。使这一切工作起来的主要技巧是存储对原始`postMessage()`的引用。然后，我们覆盖web工作线程属性`postMessage`，而不是函数本身。最后，我们可以重用它来添加必要的协调和承诺的好处。
- en: Synchronizing worker results
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 同步工作线程结果
- en: The code in the last two sections has adequately reduced our web worker callback
    hell to a more tolerable level. In fact, now that we've got a handle on how to
    encapsulate web worker communication by having `postMessage()` return a promise,
    we're ready to start simplifying any messy worker code that isn't using this approach.
    The examples that we've looked at, so far, have benefited greatly from promises,
    they are simple; not having these abstractions wouldn't be the end of the world.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 最后两个部分的代码已经足够减少我们的web工作线程回调地狱到一个更可容忍的水平。事实上，现在我们已经掌握了如何通过`postMessage()`返回承诺来封装web工作线程通信，我们准备开始简化任何不使用此方法的混乱工作线程代码。到目前为止，我们所查看的示例已经从承诺中受益匪浅，它们很简单；没有这些抽象并不会是世界末日。
- en: 'What about the scenario where we map a collection of data and then reduce the
    mapped collection? We may recall the map reduce code got a little hairy in [Chapter
    6](ch06.html "Chapter 6. Practical Parallelism"), *Practical Parallelism*. This
    is mostly due to all the worker communication boilerplate code entangled with
    the code that''s trying to execute a map/reduce operation. Let''s see if we fair
    any better using our promise technique. First, we''ll create a very basic worker:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，当我们映射一组数据然后减少映射集合的场景呢？我们可能会回忆起在[第6章](ch06.html "第6章. 实践并行性") *实践并行性* 中，映射/减少代码变得有些复杂。这主要是因为所有与尝试执行映射/减少操作代码纠缠在一起的工人通信样板代码。让我们看看使用我们的承诺技术是否会有所改善。首先，我们将创建一个非常基础的工作线程：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can use this worker to pass arrays for mapping. So we''ll create two of
    them and split the workload between the two workers, shown as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这个工作线程来传递映射数组。因此，我们将创建两个，并在两个工作线程之间分配工作量，如下所示：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: When this is all we need to post data to workers, and to synchronize data from
    two or more workers, we're actually motivated to write concurrent code—it looks
    the same as the rest of our application code now.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们只需要将数据发布到工作者，并从两个或更多工作者同步数据时，我们实际上有动力编写并发代码——现在它看起来和我们的应用代码一样。
- en: Lazy workers
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 懒工作者
- en: It's time for us to look at web workers from a different angle. The fundamental
    reason we're using workers in the first place is that we want to compute more
    than we have in the past in the same amount of time. Doing this, as we now know,
    involves messaging intricacies, divide and conquer strategies so to speak. We
    have to get data into and out of the worker, usually as an array.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候从不同角度审视 Web Workers 了。我们最初使用工作者的基本原因是我们想要在相同的时间内计算比过去更多的内容。正如我们现在所知，这样做涉及到消息的复杂性、分而治之的策略。我们必须将数据放入和取出工作者，通常作为一个数组。
- en: Generators help us compute lazily. That is, we don't want to compute something
    or allocate data in memory until we really need it. Do web workers make this difficult
    or impossible to achieve? Or can we leverage generators to compute lazily and
    in parallel?
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器帮助我们懒加载地计算。也就是说，我们不想在真正需要之前计算某些东西或分配内存。Web Workers 会使得这种懒加载变得困难或不可能实现吗？或者我们可以利用生成器来懒加载和并行计算？
- en: In this section, we'll explore ideas related to using generators in web workers.
    First, we'll look at the overhead issues associated with web workers. Then, we'll
    write some code that uses generators to pass data in and out of workers. Finally,
    we'll see if we can lazily pass data through a chain of generators, all residing
    in web workers.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨与在 Web Workers 中使用生成器相关的一些想法。首先，我们将查看与 Web Workers 相关的开销问题。然后，我们将编写一些使用生成器在工作者之间传递数据的代码。最后，我们将看看我们是否可以懒加载地通过一系列生成器传递数据，所有这些生成器都位于
    Web Workers 中。
- en: Reducing overhead
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 减少开销
- en: 'The main thread can offload expensive operations web workers, running them
    in another thread. This means the DOM is able to paint pending updates and process
    pending user events. However, we still face the overhead of allocating large arrays
    and the time taken to update the UI. Despite parallel processing with web workers,
    our users could still face a slowdown because there''s no update to the UI until
    the entire data set has been processed. Here is a visualization of the general
    pattern:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 主线程可以将昂贵的操作卸载给 Web Workers，在另一个线程中运行它们。这意味着 DOM 能够绘制挂起的更新并处理挂起的用户事件。然而，我们仍然面临分配大型数组以及更新
    UI 所需时间的开销。尽管使用了 Web Workers 进行并行处理，但我们的用户仍然可能面临速度减慢，因为没有更新到 UI，直到整个数据集被处理。以下是这种一般模式的可视化：
- en: '![Reducing overhead](img/B05133_07_04.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![减少开销](img/B05133_07_04.jpg)'
- en: This is a generic path taken by data with a single worker; the same approach
    applies when there are multiple workers. With this approach, we can't escape the
    fact that we need to serialize the data twice, and we have to allocate it twice.
    These overheads are merely to facilitate the worker communication and have very
    little to do with the application functionality that we're trying to implement.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个单工作者处理数据的通用路径；当有多个工作者时，也适用同样的方法。采用这种方法，我们无法避免需要两次序列化数据，并且需要两次分配。这些开销仅仅是方便工作者之间的通信，与我们试图实现的应用功能关系不大。
- en: The overhead with arrays and serialization, required for worker communication,
    generally isn't a big deal. However, with larger collections, we could be faced
    with real performance issues, stemming from the very mechanism that we use to
    improve performance. So looking at worker communication from another perspective
    doesn't hurt, even if it's not necessary at first.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 由于工作者通信所需的数组和序列化开销通常不是什么大问题。然而，对于更大的集合，我们可能会面临真正的性能问题，这些问题源于我们用来提高性能的机制。因此，从另一个角度审视工作者通信是有益的，即使最初并不必要。
- en: Here's a variation of the generic path taken by most workers. Instead of allocating
    and serializing lots of data upfront, individual items are passed in and out of
    workers. This gives the UI a chance to update using the data that's been processed,
    before all of the processed data arrives.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是大多数工作者采取的通用路径的一种变体。不是预先分配和序列化大量数据，而是将单个项目在工作者之间传递。这给了 UI 使用已处理的数据更新的机会，在所有处理数据到达之前。
- en: '![Reducing overhead](img/B05133_07_05.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![减少开销](img/B05133_07_05.jpg)'
- en: Generating values in workers
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在工作者中生成值
- en: 'If we want to update the UI as our workers generate results, then they can''t
    package the result set as an array to send back to the main thread after all the
    computations are done. While this happens, the UI sits there without responding
    to the user. We want a lazier approach where values are generated one at a time
    so that the UI can be updated sooner. Let''s build an example that sends input
    to the web worker and sends results back at a much more granular level than what
    we''ve seen so far in this book:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想在工作者生成结果时更新UI，那么它们不能在所有计算完成后将结果集打包为数组发送回主线程。在这个过程中，UI会坐那里不响应用户。我们想要一个更懒惰的方法，一次生成一个值，这样UI就可以更早地更新。让我们构建一个示例，将输入发送到Web工作者，并以比我们在本书中迄今为止看到的更细粒度的方式发送结果：
- en: 'First, we''ll create a worker; the code for it is as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将创建一个工作者；它的代码如下：
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'There''s nothing earth-shattering here. It''s the same `work()` function that
    we''ve already used to intentionally slow-down our code by inefficiently squaring
    a number. There''s no actual generator used inside the worker. This is because
    we really don''t need one, we''ll see why in a moment:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这里没有什么石破天惊的。这正是我们之前已经使用过的`work()`函数，通过不高效地平方一个数字来故意减慢我们的代码。在工作者内部没有使用实际的生成器。这是因为我们真的不需要一个，我们稍后会看到原因：
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Each number that's passed to our worker is more expensive to process than the
    previous number. So overall, processing the entire input array before showing
    anything to the user would feel as if the application is hanging or broken. But,
    this is not the case here because although each number is expensive to process,
    we're posting the results back as they become available.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 传递给我们的工作者的每个数字比前一个数字处理起来更昂贵。因此，在向用户显示任何内容之前处理整个输入数组会给人一种应用程序挂起或损坏的感觉。但在这里并非如此，因为尽管每个数字处理起来都很昂贵，但我们正在将结果作为它们可用时发送回去。
- en: We perform the same amount of work as we would perform by passing in an array
    and getting back an array as output. However, this approach simply changes the
    order in which things happen. We've introduced cooperative multi-tasking into
    the picture—compute some data in one task and update the UI in another. The aggregate
    time taken to complete the work is the same, but to the user, it feels much faster.
    At the end of the day, the user perceivable performance of our application is
    the only performance metric that counts.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们执行的工作量与我们通过传递数组并返回数组作为输出所执行的工作量相同。然而，这种方法只是改变了事情发生的顺序。我们已经引入了协作多任务处理——在一个任务中计算一些数据，在另一个任务中更新UI。完成工作所需的总时间是相同的，但对用户来说，感觉要快得多。最终，我们应用程序的用户可感知性能是唯一重要的性能指标。
- en: Note
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: We passed in the input as individual messages. We could have passed in the input
    as an array, posted the results individually, and gotten the same effect. However,
    this would probably amount to nothing more than an unneeded complexity. There's
    a natural correspondence to the pattern as it is—item in, item out. Don't change
    it if you don't have to.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将输入作为单个消息传递。我们也可以将输入作为数组传递，分别发布结果，并得到相同的效果。然而，这可能只是无用的复杂性。按照目前的模式，这种对应关系是自然的——输入项目，输出项目。如果不需要，就不要改变它。
- en: Lazy worker chains
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 惰性工作者链
- en: As we saw in [Chapter 4](ch04.html "Chapter 4. Lazy Evaluation with Generators"),
    *Lazy Evaluation with Generators* we can assemble chains of generators. This is
    how we implement complex functionality lazily; an item flows through a chain of
    generator functions that transform the item before yielding to the next generator
    until it reaches the caller. Without generators, we would have to allocate a lot
    of intermediary data structures just for the sake of passing data from one function
    to the next.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在[第4章](ch04.html "第4章。使用生成器的惰性求值")中看到的，*使用生成器的惰性求值*，我们可以组装生成器的链。这就是我们如何以惰性方式实现复杂功能；一个项目通过一系列在传递给下一个生成器之前转换项目的生成器函数流动，直到它达到调用者。如果没有生成器，我们可能不得不分配大量的中间数据结构，仅仅是为了将数据从一个函数传递到下一个函数。
- en: In the section prior to this one, we saw that a pattern similar to generators
    was possible with web workers. Since we face a similar problem here, we don't
    want to allocate large data structures. We can avoid doing this by passing in
    items at a more granular level. This has the added benefit of keeping the UI responsive
    because we're able to update it before the last item arrives from the worker.
    Given that we can do this much with workers, could we not build on this idea and
    assemble more complex chains of worker processing nodes?
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节之前，我们看到了使用Web工作者实现类似于生成器的模式是可能的。由于我们在这里面临类似的问题，我们不希望分配大型数据结构。我们可以通过在更细粒度级别传递项来避免这样做。这还有一个额外的优点，即保持UI响应，因为我们能够在工作者从最后一个项到达之前更新它。鉴于我们可以通过工作者做到这一点，我们能否在此基础上构建并组装更复杂的工作者处理节点链？
- en: For instance, let's say we have a collection of numbers and several transformations.
    We need to make these transformations in a specific order before we can display
    them in our UI. Ideally, we would setup a chain of workers where each worker is
    responsible for performing its designated transformation, then passing the output
    on to the next worker. Eventually, the main thread gets a value back that it can
    display in the DOM.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有一组数字和几个转换。在我们能在UI中显示它们之前，我们需要按照特定的顺序执行这些转换。理想情况下，我们会设置一个工作者的链，其中每个工作者负责执行其指定的转换，然后将输出传递给下一个工作者。最终，主线程会得到一个可以显示在DOM中的值。
- en: The problem with this goal is the tricky communication that it involves. Since
    dedicated workers only communicate with the main thread that created them, it's
    hardly advantageous to send the results back to the main thread, then onto the
    next worker in the chain, and so on. Well, it turns out that dedicated workers
    can directly communicate without involving the main thread. We can use something
    called channel messaging here. The idea is simple; it involves creating a channel,
    which has two ports—messages posted on one port and received on the other.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这个目标的问题在于其中涉及到的复杂通信。由于专用工作者只与创建它们的线程通信，将结果发送回主线程，然后传递给链中的下一个工作者，如此等等，几乎没有什么优势。然而，事实证明，专用工作者可以直接通信，而不涉及主线程。在这里，我们可以使用一种称为通道消息的东西。这个想法很简单；它涉及到创建一个通道，该通道有两个端口——消息在一个端口上发布，在另一个端口上接收。
- en: We've been using messaging channels and ports all along. They're baked into
    web workers. This is where the message event and `postMessage()` method pattern
    comes from.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直在使用消息通道和端口。它们是内置于Web工作者中的。这就是消息事件和`postMessage()`方法模式来源的地方。
- en: 'The following is a visualization of how we would go about connecting our web
    workers using channels and ports:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们如何使用通道和端口连接我们的Web工作者的可视化：
- en: '![Lazy worker chains](img/B05133_07_06.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![懒工作者链](img/B05133_07_06.jpg)'
- en: As we can see, each channel uses two messaging ports. The first port is used
    to post messages, whereas the second is used to receive message events. The only
    time the main thread is used is when the processing chain is first kicked off
    by posting a message to the first channel and when the message is received from
    the third channel.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，每个通道使用两个消息端口。第一个端口用于发布消息，而第二个端口用于接收消息事件。唯一使用主线程的时候是当处理链首次启动时，通过向第一个通道发布消息，以及从第三个通道接收消息时。
- en: 'Instead of letting the six ports required for worker communication intimidate
    us, let''s write some code; maybe, it''ll look a little more approachable there.
    First we''ll create the workers used in the chain. Actually, they''re two instances
    of the same worker. Here''s the code:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 不要让六个用于工作者通信的端口让我们感到害怕，让我们写一些代码；也许在那里它看起来会更容易接近。首先，我们将创建链中使用的工作者。实际上，它们是同一工作者的两个实例。以下是代码：
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This is interesting. In this worker, we have message ports to work with. The
    first port is used to receive input, and the second port is used to send output.
    The `work()` function simply squares the given number using our now familiar approach
    of wasting CPU cycles to see how workers behave. What we want to do in our main
    thread is to create two instances of this worker so that we can pass the first
    instance a number to square. Then, without passing the result back to the main
    thread, it passes the result to the next worker, and the number is squared again.
    The communication paths should closely mimic the previous diagram. Let''s look
    at some code that connects workers using messaging channels:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这很有趣。在这个工作进程中，我们有可以工作的消息端口。第一个端口用于接收输入，第二个端口用于发送输出。`work()` 函数简单地使用我们熟悉的通过浪费
    CPU 周期来观察工作进程行为的方法，对给定的数字进行平方。在我们的主线程中，我们想要创建这个工作进程的两个实例，以便我们可以将一个数字传递给第一个实例进行平方。然后，它不将结果传回主线程，而是将结果传递给下一个工作进程，数字再次被平方。通信路径应该与之前的图非常相似。让我们看看一些使用消息通道连接工作进程的代码：
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In addition to the data that we want to send to the worker, we can also send
    a list of message ports that we want to transfer to the worker context. This is
    what we do with the first two messages sent to the worker. The message data is
    `null` because we're not doing anything with it. In fact, these are the only messages
    we're sending directly to the worker. The rest of the communication happens through
    the message channels that we've created. The expensive computation happens on
    the worker because that's where the message handler resides.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们想要发送给工作进程的数据外，我们还可以发送一个我们想要传递给工作进程上下文的消息端口列表。这就是我们向工作进程发送前两条消息所做的事情。消息数据是
    `null`，因为我们没有对它做任何事情。实际上，这是我们直接发送给工作进程的唯一消息。其余的通信都是通过我们创建的消息通道进行的。昂贵的计算发生在工作进程中，因为消息处理程序就驻留在那里。
- en: Using Parallel.js
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Parallel.js
- en: The aim of the `Parallel.js` library is to make interacting with web workers
    as seamless as possible. In fact, it handles one of the key goals of this book—it
    hides the concurrency mechanism and allows us to focus on the application that
    we're building.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`Parallel.js` 库的目标是使与 Web Workers 的交互尽可能无缝。实际上，它处理了本书的一个关键目标——隐藏并发机制，并允许我们专注于我们正在构建的应用程序。'
- en: In this section, we'll look at the approach taken by `Parallel.js` for worker
    communication and the general approach of passing code to workers. Then, we'll
    walk through some code that uses `Parallel.js` to spawn new worker processes.
    Lastly, we'll explore the built-in map/reduce capabilities that the library has
    to offer.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨 `Parallel.js` 用于工作进程通信的方法以及将代码传递给工作进程的一般方法。然后，我们将通过一些使用 `Parallel.js`
    创建新工作进程的代码进行说明。最后，我们将探索库提供的内置的 map/reduce 功能。
- en: How it works
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的
- en: All the workers that we've used so far in this book have been our own creation.
    We implemented message event handling in our workers that computed some value,
    then posted a response. With `Parallel.js`, we don't implement workers. Instead,
    we implement functions, which are then passed to workers that are managed by the
    library.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们使用过的所有工作进程都是我们自己创建的。我们在工作进程中实现了消息事件处理，计算了一些值，然后发布了响应。使用 `Parallel.js`，我们不实现工作进程。相反，我们实现函数，这些函数随后被传递给由库管理的工作进程。
- en: This takes care of a few headaches for us. All our code is implemented in the
    main thread, meaning that it's easier to use the functions that we've implemented
    in the main thread because we don't need to import them into web workers using
    `importScripts()`. We also don't need to manually start web workers by creating
    them with a script path. Instead, we let `Parallel.js` spawn new workers for us,
    and then, we can tell the workers what to do by passing functions and data to
    them. So, how does this work, exactly?
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们解决了一些头疼的问题。我们所有的代码都在主线程中实现，这意味着使用我们在主线程中实现的函数更容易，因为我们不需要使用 `importScripts()`
    将它们导入到 Web Workers 中。我们也不需要手动通过创建带有脚本路径的脚本来启动 Web Workers。相反，我们让 `Parallel.js`
    为我们创建新的工作进程，然后，我们可以通过向它们传递函数和数据来告诉工作进程要做什么。那么，这究竟是如何工作的呢？
- en: Workers need a script argument. Without a valid script, workers simply do not
    work. `Parallel.js` has a straightforward `eval` script. This is what's passed
    to any worker that the library creates. Then, the API within the main thread assembles
    code that's to be evaluated within the worker and sends it over whenever we need
    to communicate with workers.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 工作者需要一个脚本参数。如果没有有效的脚本，工作者将无法工作。`Parallel.js` 有一个直接的 `eval` 脚本。这是库创建的任何工作者接收到的脚本。然后，主线程中的
    API 组装要工作者评估的代码，并在需要与工作者通信时发送它。
- en: This is feasible because `Parallel.js` doesn't aim to expose a plethora of functionality
    backed by workers. Instead, the aim is to make the worker communication mechanism
    as seamless as possible while providing minimal functionality. This makes it easy
    to build only the concurrency functionality that's relevant to our application
    and not a host of other functions that we'll never use.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这是可行的，因为 `Parallel.js` 并不旨在通过工作者提供大量功能。相反，目标是使工作者通信机制尽可能无缝，同时提供最小功能。这使得我们能够仅构建与我们的应用程序相关的并发功能，而不是一大堆我们永远不会使用的其他功能。
- en: 'Here is an illustration of how we pass data and code into a worker using `Parallel.js`
    and its `eval` script:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是使用 `Parallel.js` 和其 `eval` 脚本将数据和代码传递给工作者的说明：
- en: '![How it works](img/B05133_07_07.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![工作原理](img/B05133_07_07.jpg)'
- en: Spawning workers
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动工作者
- en: The `Parallel.js` library has the notion of a job. The primary input to a job
    is the data that the job is going to process. The creation of a job isn't directly
    tied to the creation of a background worker. Workers are distinct from `Parallel.js`
    jobs; we don't interact directly with workers when using the library. Once we
    have our job instance, and it's supplied with our data, we use a job method to
    invoke workers.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`Parallel.js` 库有一个关于工作的概念。工作的主要输入是工作将要处理的数据。工作的创建并不直接与后台工作者的创建相关联。工作者与 `Parallel.js`
    的工作不同；当我们使用库时，我们不直接与工作者交互。一旦我们有了工作实例，并且它提供了我们的数据，我们就使用工作方法来调用工作者。'
- en: 'The most basic method is `spawn()`, which takes a function as an argument and
    runs it in a web worker. The function that we pass to it can return results, and
    these are then resolved as a thenable object that''s returned by `spawn()`. Let''s
    look at some code that uses `Parallel.js` to spawn new job backed by a web worker:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 最基本的方法是 `spawn()`，它接受一个函数作为参数，并在一个网络工作者中运行它。我们传递给它的函数可以返回结果，这些结果随后作为由 `spawn()`
    返回的可解析对象。让我们看看一些使用 `Parallel.js` 通过网络工作者启动新任务的代码示例：
- en: '[PRE11]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Well now, that's pretty cool; we don't have to worry about any of the monotonous
    web worker life-cycle tasks. We have some data and some function that we want
    to apply to the data, and we want to run it in parallel with other work taking
    place on the page. The cherry on the top is the familiar thenable that's returned
    from the `spawn()` method. It fits right into our concurrent application, where
    everything else is treated as a promise.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，这真的很酷；我们不必担心任何单调的网络工作者生命周期任务。我们有一些数据和想要应用于这些数据的函数，我们希望与其他页面上的工作并行运行它。最棒的是，从
    `spawn()` 方法返回的熟悉的可解析对象完美地融入我们的并发应用程序中，其中其他所有内容都被视为承诺。
- en: We log how long it takes for our function to process the input data we give
    it. We only spawn a single web worker for this task, so the result is reached
    in the same amount of time as it would have been, were it computed in the main
    thread. Aside from freeing up the main thread to handle DOM events and repainting,
    there's no objective performance gain. We'll see if we can use a different method
    to up the concurrency level.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们记录我们的函数处理我们给出的输入数据所需的时间。为此任务，我们只启动一个网络工作者，因此结果达到的时间与在主线程中计算的时间相同。除了释放主线程以处理
    DOM 事件和重绘外，没有客观的性能提升。我们将看看我们是否可以使用不同的方法来提高并发级别。
- en: Note
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The worker created by `spawn()` is immediately terminated when we're done with
    it. This frees up memory for us. However, there's no concurrency level governing
    the use of `spawn()`, we can call it 100 times in a row if we like.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们完成与 `spawn()` 创建的工作者的操作时，该工作者会立即终止。这为我们释放了内存。然而，没有并发级别来控制 `spawn()` 的使用，我们可以连续调用它100次。
- en: Mapping and reducing
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 映射和归约
- en: 'In the last section, we spawned a worker thread using the `spawn()` method.
    `Parallel.js` also has a `map()` method and a `reduce()` method. The idea is to
    make things easier for us. By passing `map()` a function, the library will automatically
    apply it to each item in the job data. Similar semantics apply with the `reduce()`
    method. Let''s take a look at how this works by writing some code:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一节中，我们使用`spawn()`方法创建了一个工作线程。`Parallel.js`还有一个`map()`方法和一个`reduce()`方法。我们的想法是让事情变得更容易。通过将函数传递给`map()`，库将自动将其应用于工作数据中的每个项目。类似的语义也适用于`reduce()`方法。让我们通过编写一些代码来看看它是如何工作的：
- en: '[PRE12]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Ouch! This is quite the performance hit—what's going on here? What we're seeing
    here is a phenomenon called parallel slowdown. This slowdown takes place when
    there's too much parallel communication overhead. The reason this is happening
    in this particular example is due to the way `Parallel.js` processes arrays in
    `map()`. Each array item goes through a worker. This doesn't mean that 'there
    are `2500` workers created—one for each element in the array. The number of created
    workers maxes out at four or the `navigator.hardwareConcurrency` value—similar
    semantics we looked at earlier in this book.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀！这里的性能损失相当大——这是怎么回事？我们在这里看到的是一种称为并行减速的现象。这种减速发生在并行通信开销过多的情况下。这个特定例子中发生这种情况的原因是`Parallel.js`在`map()`中处理数组的方式。每个数组项都会通过一个工作者。这并不意味着“创建了`2500`个工作者——每个数组元素一个。创建的工作者数量最多为四个或`navigator.hardwareConcurrency`的值——这是我们在这本书前面看到的类似语义。
- en: 'The real overhead comes from messages sent to and received from the workers—5000
    messages! This is obviously not optimal, as evidenced by the timer in the code.
    Let''s see if we can make a drastic improvement on these numbers while keeping
    roughly the same code structure:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 真正的开销来自于发送到工作者和从工作者接收的消息——5000条消息！这显然不是最优的，正如代码中的计时器所示。让我们看看我们是否可以在保持大致相同的代码结构的同时，对这些数字进行大幅改进：
- en: '[PRE13]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Here, we can see that the same results are generated, and much faster. The difference
    is that we start things off by slicing the array into chunks of smaller arrays.
    These arrays are the items that get passed to the workers, instead of individual
    numbers. So the mapping job has to change slightly as well, instead of squaring
    a number, it's mapping a smaller array to an array of squares. The reduce logic
    is slightly more complex, but overall, our approach is still the same. Most importantly,
    we've removed the heavy message-passing bottleneck that was causing unacceptable
    performance flaws in the first implementation.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到产生了相同的结果，而且速度要快得多。区别在于我们首先将数组切割成更小的数组块。这些数组是传递给工作者的项目，而不是单个数字。因此，映射工作也需要稍微改变，不再是平方一个数字，而是将较小的数组映射到平方数的数组。减少逻辑稍微复杂一些，但总体上，我们的方法仍然是相同的。最重要的是，我们移除了导致第一次实现性能不佳的严重消息传递瓶颈。
- en: Note
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Just like the `spawn()` method cleans up the worker when it returns, so too
    do the `map()` and `reduce()` `Parallel.js` methods. The downside to freeing workers
    is that they need to be recreated whenever these methods are called. We'll address
    this challenge in the next section.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 就像`spawn()`方法在返回时清理工作者一样，`map()`和`reduce()`的`Parallel.js`方法也是如此。释放工作者的缺点是每次调用这些方法时都需要重新创建它们。我们将在下一节中解决这个挑战。
- en: Worker pools
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作池
- en: The final section of this chapter covers the concept of worker pools. In the
    preceding section on `Parallel.js`, we ran up against an issue where workers were
    frequently created and terminated. This is a lot of overhead. If we know the level
    of concurrency we're capable of operating at, then why not allocate a statically-sized
    pool of workers that can take on work?
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的最后部分涵盖了工作池的概念。在前面的`Parallel.js`部分中，我们遇到了一个问题，即工作者（workers）频繁地被创建和终止。这造成了大量的开销。如果我们知道我们能够处理的并发级别，那么为什么不分配一个静态大小的工人池来承担工作呢？
- en: The first design task for creating a worker pool is to allocate the workers.
    The next step is to schedule the jobs as they come in by distributing them to
    available workers in the pool. Lastly, we'll need to account for busy states when
    all the workers are busy. Let's do this.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 创建工作池的第一个设计任务是分配工作者。下一步是将作业按顺序分配给池中可用的工人。最后，我们需要考虑到所有工作者都忙碌时的忙碌状态。让我们这样做。
- en: Allocating pools
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分配池
- en: Before we think about allocating pools of worker threads, we need to look at
    the overarching worker pool abstraction. How do we want it to look and behave?
    Ideally, we want the pool abstraction to look and behave like a plain dedicated
    worker. We can post a message to the pool and get a promise in response. So while
    we can't directly extend the Worker prototype, we can create a new abstraction
    that closely resembles the Worker API.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们考虑分配工作线程池之前，我们需要查看总的工人池抽象。我们希望它看起来和表现如何？理想情况下，我们希望池抽象看起来和表现像一个普通的专用工人。我们可以向池发送消息并得到一个响应的承诺。因此，虽然我们不能直接扩展
    Worker 原型，但我们可以创建一个新的抽象，该抽象与 Worker API 非常相似。
- en: 'Let''s look at some code now. Here''s the initial abstraction that we''ll use:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些代码。这是我们将要使用的初始抽象：
- en: '[PRE14]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: When a new `WorkerPool` is created, the given script is used to spawn all the
    workers within the pool. The `workers` property is a `Map` instance, and the worker
    instances themselves are the keys. The reason we store the workers as map keys
    is so that we can easily lookup the appropriate resolver function to call.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建一个新的 `WorkerPool` 时，给定的脚本用于在池中启动所有工作线程。`workers` 属性是一个 `Map` 实例，工作线程实例本身是键。我们之所以将工作线程存储为映射键，是为了能够轻松查找要调用的适当解析函数。
- en: When a given worker responds, the `message` event handler that we've added to
    each worker is called, and this is where we find the resolver function that's
    waiting to be called. There's no chance of us calling the wrong resolver because
    a given worker doesn't take on new work until it's finished with its current task.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当给定的工作线程响应时，我们添加到每个工作线程的 `message` 事件处理程序被调用，这就是我们找到等待调用的解析函数的地方。由于给定的工作线程在完成当前任务之前不会接受新的工作，所以我们不可能调用错误的解析函数。
- en: Scheduling jobs
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调度任务
- en: 'Now we''ll implement the `postMessage()` method. This is what the caller will
    use to post a message to one of the workers in the pool. The caller doesn''t know
    which worker fulfills their request, nor do they care. They get a promise as a
    return value, and it''s resolved with the worker response as the value:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将实现 `postMessage()` 方法。调用者将使用此方法向池中的某个工作线程发送消息。调用者不知道哪个工作线程会满足他们的请求，也不关心。他们获得一个承诺作为返回值，并且当工作线程响应时，承诺被解决：
- en: '[PRE15]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: It's the promise executor function that takes care of actually finding the first
    available worker and posting our message there. When an available worker is found,
    we also set the worker's resolver function in our `workers` map. If there are
    no available `workers` in the pool, the posted message goes into the `queue`.
    This queue is emptied in the `message` event handler. This is because when a worker
    comes back with a message, it means the worker is free to take on more work, and
    it checks if there's anything queued before returning to an idle state.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这是承诺执行函数，它负责找到第一个可用的工人并在此处发送我们的消息。当找到可用的工人时，我们也在我们的 `workers` 映射中设置工人的解析函数。如果没有可用的
    `workers` 在池中，发送的消息将进入 `queue`。这是因为在 `message` 事件处理程序中清空队列。这是因为当工作线程带着消息回来时，意味着工作线程可以接受更多的工作，并且在返回空闲状态之前会检查是否有任何排队的内容。
- en: 'The `getWorker()` method is a simple helper that finds the next available worker
    for us. We know a worker is available to take on a task if its `resolver` function
    is set to null in the `workers` map. Lastly, let''s see this worker pool in action:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`getWorker()` 方法是一个简单的辅助函数，用于为我们找到下一个可用的工人。我们知道，如果 `workers` 映射中的 `resolver`
    函数设置为 null，则工作线程可以接受任务。最后，让我们看看这个工作池的实际应用：'
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: In this usage scenario, we have a couple of form controls that send parameterized
    work to the worker. The larger the number, the longer the work will take; it uses
    our standard `work()` function that slowly squares numbers. If we use a large
    number and frequently click the button that posts the message to the pool, then
    eventually, we'll exhaust the pool. If 'this is the case, we will display a warning.
    However, this is just for troubleshooting purposes—the posted messages aren't
    lost when the pool is busy, they're simply queued.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个使用场景中，我们有一些表单控件将参数化工作发送到工作线程。数字越大，工作所需的时间越长；它使用我们的标准 `work()` 函数，该函数会缓慢地平方数字。如果我们使用一个大的数字并频繁地点击发送消息到池的按钮，那么最终我们会耗尽池中的资源。如果出现这种情况，我们将显示一个警告。然而，这只是为了故障排除目的——当池忙碌时，发送的消息并没有丢失，它们只是被排队。
- en: Summary
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: The focus of this chapter has been removing obtrusive concurrency semantics
    from our code. It simply raises the likelihood of our application's success because
    we'll have code that's easy to maintain and build upon. The first issue that we
    tackled was writing concurrent code by making everything concurrent. When there's
    no guesswork involved, our code is consistent and less susceptible to concurrency
    bugs.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的重点一直是从我们的代码中移除显眼的并发语义。这仅仅提高了我们应用程序成功的可能性，因为我们会有易于维护和构建的代码。我们首先解决的问题是通过使一切并发来编写并发代码。当没有猜测的成分时，我们的代码是一致的，并且对并发错误的抵抗力更小。
- en: Then, we looked at various approaches we can take to abstract web worker communication.
    Helper functions are one option and so is extending the `postMessage()` method.
    We then addressed some of the limitations of web workers when we need our UI to
    be responsive. Even though our large dataset is processed faster, we still have
    the issue of updating the UI. This is done by treating web workers as generators.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们探讨了我们可以采取的各种方法来抽象Web工作者的通信。辅助函数是一个选择，扩展`postMessage()`方法也是一个选择。当我们需要UI保持响应时，我们解决了一些Web工作者的局限性。尽管我们的大数据集处理得更快，但我们仍然有更新UI的问题。这是通过将Web工作者视为生成器来完成的。
- en: We don't have to write all these JavaScript parallelization tools ourselves.
    We spent some time looking at the various capabilities and limitations of the
    `Parallel.js` library. We wrapped up the chapter with a look at web worker pools.
    These remove a lot of overhead related to worker creation and termination, and
    they drastically simplify how tasks are distributed and results are reconciled.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不必自己编写所有这些JavaScript并行化工具。我们花了一些时间来查看`Parallel.js`库的各种功能和限制。我们通过查看Web工作池来结束本章，这些工作池减少了与工作创建和终止相关的许多开销，并且极大地简化了任务分配和结果协调的方式。
- en: That does it for our concurrency topics in the front-end. Now it's time to shift
    gears and look at JavaScript concurrency in the back-end with NodeJS.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 前端并发主题的内容就到这里。现在是我们转换方向，用NodeJS来探讨后端JavaScript并发的时候了。
