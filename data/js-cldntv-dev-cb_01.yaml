- en: Getting Started with Cloud-Native
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用云原生
- en: 'In this chapter, the following recipes will be covered:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下食谱：
- en: Creating a stack
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个栈
- en: Creating a function and working with metrics and logs
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个函数并处理指标和日志
- en: Creating an event stream and publishing an event
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个事件流并发布一个事件
- en: Creating a stream processor
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个流处理器
- en: Creating an API Gateway
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个 API Gateway
- en: Deploying a single-page application
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署单页应用程序
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: Cloud-native is lean. Companies today must continuously experiment with new
    product ideas so that they can adapt to changing market demands; otherwise, they
    risk falling behind their competition. To operate at this pace, they must leverage
    fully managed cloud services and fully-automated deployments to minimize time
    to market, mitigate operating risks, and empower self-sufficient, full-stack teams
    to accomplish far more with much less effort.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生是精简的。今天的公司必须不断尝试新的产品想法，以便能够适应不断变化的市场需求；否则，它们可能会落后于竞争对手。为了以这种速度运营，它们必须利用完全托管的云服务和完全自动化的部署，以最小化上市时间，降低运营风险，并赋予自给自足的全栈团队以更少的努力完成更多的工作。
- en: The recipes in this cookbook demonstrate how to use fully managed, serverless
    cloud services to develop and deploy lean and autonomous services. This chapter
    contains bare-boned recipes with no clutter in order to focus on the core aspects
    of deploying cloud-native components and to establish a solid foundation for the
    remainder of this cookbook.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱中的食谱展示了如何使用完全托管的无服务器云服务来开发和部署精简且自主的服务。本章包含简化的食谱，没有杂乱，以便专注于部署云原生组件的核心方面，并为本书的其余部分建立一个坚实的基础。
- en: Creating a stack
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个栈
- en: Each autonomous cloud-native service and all its resources are provisioned as
    a cohesive and self-contained group called a **stack**. On AWS, these are **CloudFormation**
    stacks. In this recipe, we will use the Serverless Framework to create and manage
    a bare-bones stack to highlight the steps involved in deploying a cloud-native
    service.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 每个自主的云原生服务和其所有资源都作为一个统一且自包含的组进行配置，称为**栈**。在 AWS 上，这些是**CloudFormation**栈。在本食谱中，我们将使用
    Serverless Framework 来创建和管理一个基础栈，以突出部署云原生服务所涉及的步骤。
- en: Getting ready
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Before starting this recipe, you will need to follow the instructions in the
    *Preface* for configuring your development environment with Node.js, the Serverless
    Framework, and AWS account credentials.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始本食谱之前，您需要按照*前言*中的说明配置您的开发环境，包括 Node.js、Serverless Framework 和 AWS 账户凭证。
- en: How to do it...
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create the project from the following template:'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Navigate to the `cncb-create-stack` directory with `cd cncb-create-stack`.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cd cncb-create-stack` 切换到 `cncb-create-stack` 目录。
- en: 'Review the file named `serverless.yml` with the following content:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看名为 `serverless.yml` 的文件，内容如下：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Review the file named `package.json` with the following content:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看名为 `package.json` 的文件，内容如下：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Install the dependencies with `npm install`.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm install` 安装依赖项。
- en: Run the tests with `npm test`.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm test` 运行测试。
- en: Review the contents generated in the `.serverless` directory.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看在 `.serverless` 目录中生成的内容。
- en: 'Deploy the stack:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署栈：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Review the stack in the AWS Console:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 控制台中查看栈：
- en: '![](img/3effc87e-5bd7-48fe-86a8-2a3d087cc88a.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3effc87e-5bd7-48fe-86a8-2a3d087cc88a.png)'
- en: Remove the stack once you have finished with `npm run rm:lcl -- -s $MY_STAGE`.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm run rm:lcl -- -s $MY_STAGE` 删除栈。
- en: How it works...
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The **Serverless Framework** (**SLS**) ([https://serverless.com/framework/docs](https://serverless.com/framework/docs))
    is my tool of choice for deploying cloud resources, regardless of whether or not
    I am deploying serverless resources, such as functions. SLS is essentially an
    abstraction layer on top of **infrastructure as code** tools, such as AWS CloudFormation,
    with extensibility features such as plugins and dynamic variables. We will use
    SLS in all of our recipes. Each recipe starts by using the SLS feature to `create`
    a new project by cloning a `template`. You will ultimately want to create your
    own templates for jump-starting your own projects.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**Serverless Framework**（**SLS**）([https://serverless.com/framework/docs](https://serverless.com/framework/docs)）是我部署云资源的首选工具，无论是否部署无服务器资源，如函数。SLS
    实质上是建立在**基础设施即代码**工具（如 AWS CloudFormation）之上的抽象层，具有插件和动态变量等可扩展功能。我们将使用 SLS 在所有食谱中。每个食谱都从使用
    SLS 功能通过克隆模板来 `创建` 一个新项目开始。您最终可能希望创建自己的模板，以便快速启动自己的项目。'
- en: This first project is as bare bones as we can get. It essentially creates an
    empty CloudFormation stack. In the `serverless.yml` file, we define the `service`
    name and the `provider`. The `service` name will be combined with the `stage`,
    which we will discuss shortly, to create a unique stack name within your account
    and `region`. I have prefixed all the stacks in our recipes with `cncb` to make
    it easy to filter for these stacks in the AWS Console if you are using a shared
    account, such as your development or sandbox account at work.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这个第一个项目尽可能简单。它本质上创建了一个空的 CloudFormation 堆栈。在 `serverless.yml` 文件中，我们定义了 `service`
    名称和 `provider`。`service` 名称将与即将讨论的 `stage` 结合，以在您的账户和 `region` 内创建一个唯一的堆栈名称。我已将所有堆栈的前缀设置为
    `cncb`，以便在您使用共享账户（如工作中的开发或沙盒账户）时，在 AWS 控制台中轻松筛选这些堆栈。
- en: Our next most important tool is **Node Package Manager** (**NPM**) ([https://docs.npmjs.com/](https://docs.npmjs.com/)).
    We will not be packaging any Node modules (also known as libraries), but we will
    be leveraging NPM's dependency management and scripting features. In the `package.json`
    file, we declared a development dependency on the Serverless Framework and three
    custom scripts to test, deploy, and remove our stack. The first command we execute
    is `npm install`, which will install all the declared dependencies into the project's
    `node_modules` directory.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下一个最重要的工具是 **Node 包管理器**（**NPM**）([https://docs.npmjs.com/](https://docs.npmjs.com/))。我们不会打包任何
    Node 模块（也称为库），但我们将利用 NPM 的依赖关系管理和脚本功能。在 `package.json` 文件中，我们声明了对 Serverless Framework
    的开发依赖，以及三个自定义脚本，用于测试、部署和删除我们的堆栈。我们执行的第一条命令是 `npm install`，它将安装所有声明的依赖项到项目的 `node_modules`
    目录中。
- en: Next, we execute the `npm test` script. This is one of several standard scripts
    for which NPM provides a shortcut alias. We have defined the `test` script to
    invoke the `sls package` command to assert that everything is configured properly
    and help us see what is going on under the covers. This command processes the
    `serverless.yml` file and generates a CloudFormation template in the `.serverless`
    directory. One of the advantages of the Serverless Framework is that it embodies
    best practices and uses a **configuration by exception** approach to take a small
    amount of declaration in the `serverless.yml` files and expand it into a much
    more verbose CloudFormation template.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们执行 `npm test` 脚本。这是 NPM 提供的几个标准脚本之一，用于提供快捷别名。我们定义了 `test` 脚本来调用 `sls package`
    命令，以断言一切配置是否正确，并帮助我们了解底层发生了什么。此命令处理 `serverless.yml` 文件，并在 `.serverless` 目录中生成
    CloudFormation 模板。Serverless Framework 的一个优点是它体现了最佳实践，并采用 **异常配置** 方法，在 `serverless.yml`
    文件中只声明少量内容，并将其扩展为更详细的 CloudFormation 模板。
- en: Now, we are ready to deploy the stack. As developers, we need to be able to
    deploy a stack and work on it in isolation from other developers and other environments,
    such as production. To support this requirement, SLS uses the concept of a **stage**.
    Stage (`-s $MY_STAGE`) and region (`-r us-east-1`) are two required command-line
    options when invoking an SLS command. A stack is deployed into a specific region
    and the stage is used as a prefix in the stack name to make it unique within an
    account and region. Using this feature, each developer can *deploy* (`dp`) what
    I refer to as a *local* (`lcl`) stack with their name as the stage with `npm run
    dp:lcl -- -s $MY_STAGE`. In the examples, I use my name for the stage. We declared
    the `$MY_STAGE` environment variable in the *Getting ready* section. The double
    dash (`--`) is NPM's way of letting us pass additional options to a custom script.
    In [Chapter 6](390bdaaf-5f53-4d65-8a6c-2e47c815f2b3.xhtml), *Building a Continuous
    Deployment Pipeline*, we will discuss deploying stacks to shared environments,
    such as **staging** and **production**.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好部署堆栈。作为开发者，我们需要能够独立于其他开发者和其他环境（如生产环境）部署堆栈并进行工作。为了支持这一需求，SLS 使用了 **阶段**
    的概念。阶段 (`-s $MY_STAGE`) 和区域 (`-r us-east-1`) 是调用 SLS 命令时的两个必需的命令行选项。堆栈被部署到特定的区域，阶段用作堆栈名称的前缀，以使其在账户和区域内部独特。使用此功能，每个开发者都可以使用他们的名字作为阶段，通过
    `npm run dp:lcl -- -s $MY_STAGE` 来 *部署*（`dp`）我所说的 *本地*（`lcl`）堆栈。在示例中，我使用我的名字作为阶段。我们在
    *准备就绪* 部分中声明了 `$MY_STAGE` 环境变量。双横线（`--`）是 NPM 让我们向自定义脚本传递额外选项的方式。在 [第 6 章](390bdaaf-5f53-4d65-8a6c-2e47c815f2b3.xhtml)，*构建持续部署管道*
    中，我们将讨论将堆栈部署到共享环境，如 **预发布** 和 **生产**。
- en: CloudFormation has a limit regarding the template body size in a request to
    the API. Typical templates easily surpass this limit and must be uploaded to S3
    instead. The Serverless Framework handles this complexity for us. In the `.serverless`
    directory, you will notice that there is a `cloudformation-template-create-stack.json`
    file that declares a `ServerlessDeploymentBucket`. In the `sls deploy` output,
    you can see that SLS uses this template first and then it uploads the `cloudformation-template-update-stack.json` file
    to the bucket and updates the stack. It's nice to have this problem already solved
    for us because it is typical to learn about this limit the hard way.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: CloudFormation在API请求中对模板体的大小有限制。典型的模板很容易超过这个限制，必须上传到S3。Serverless Framework为我们处理了这个复杂性。在`.serverless`目录中，您会注意到有一个`cloudformation-template-create-stack.json`文件，它声明了一个`ServerlessDeploymentBucket`。在`sls
    deploy`输出中，您可以看到SLS首先使用这个模板，然后它将`cloudformation-template-update-stack.json`文件上传到桶中并更新堆栈。这个问题已经为我们解决是很令人高兴的，因为通常是通过困难的方式才了解到这个限制。
- en: At first glance, creating an empty stack may seem like a silly idea, but in
    practice it is actually quite useful. In a sense, you can think of CloudFormation
    as a CRUD tool for cloud resources. CloudFormation keeps track of the state of
    all the resources in a stack. It knows when a resource is new to a stack and must
    be created, when a resource has been removed from a stack and must be deleted,
    and when a resource has changed and must be updated. It also manages the dependencies
    and ordering between resources. Furthermore, when an update to a stack fails,
    it rolls back all the changes.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 初看起来，创建一个空堆栈可能似乎是一个愚蠢的想法，但实际上它非常有用。从某种意义上说，您可以将CloudFormation视为云资源的CRUD工具。CloudFormation跟踪堆栈中所有资源的状态。它知道何时一个资源是新添加到堆栈中并且必须被创建，何时一个资源已从堆栈中移除并且必须被删除，以及何时资源已更改并且必须被更新。它还管理资源之间的依赖关系和顺序。此外，当堆栈的更新失败时，它会回滚所有更改。
- en: Unfortunately, when deploying a large number of changes, these rollbacks can
    be very time-consuming and painful when the error is in one of the last resources
    to be changed. Therefore, it is best to make changes to a stack in small increments.
    In [Chapter 6](390bdaaf-5f53-4d65-8a6c-2e47c815f2b3.xhtml), *Building a Continuous
    Deployment Pipeline*, we will discuss the practices of small batch sizes, task
    branch workflow, and decoupling deployment from release. For now, if you are creating
    a new service from a proven template, then initialize the new project and deploy
    the stack with all the template defaults all the way to production with your first
    pull request. Then, create a new branch for each incremental change. However,
    if you are working on an experimental service with no proven starting point, then
    an empty stack is perfectly reasonable for your first deployment to production.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，当部署大量更改时，如果在最后更改的资源中发生错误，这些回滚操作可能会非常耗时且痛苦。因此，最好以小批量逐步进行更改。在[第6章](390bdaaf-5f53-4d65-8a6c-2e47c815f2b3.xhtml)《构建持续部署管道》中，我们将讨论小批量大小、任务分支工作流程以及将部署与发布解耦的实践。目前，如果您是从经过验证的模板创建新服务，那么请初始化新项目，并使用所有模板默认设置通过第一次拉取请求将堆栈部署到生产环境。然后，为每个增量更改创建一个新的分支。然而，如果您正在开发一个没有经过验证的起始点的实验性服务，那么对于您的第一次生产部署，一个空堆栈是完全合理的。
- en: In your daily development routine, it is important to clean up your local stacks
    when you have completed work on a task or story. The cost of a development account
    can creep surprisingly high when orphaned stacks accumulate and are rarely removed.
    The `npm run rm:lcl -- -s $MY_STAGE` script serves this purpose.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的日常开发工作中，当您完成一个任务或故事的工作后，清理您的本地堆栈是很重要的。当孤儿堆栈积累且很少被移除时，开发账户的成本可能会意外地很高。`npm
    run rm:lcl -- -s $MY_STAGE` 脚本就是为了这个目的。
- en: Creating a function and working with metrics and logs
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建函数以及与指标和日志一起工作
- en: '**Function-as-a-Service** is the cornerstone of cloud-native architecture.
    Functions enable self-sufficient, full-stack teams to focus on delivering lean
    business solutions without being weighed down by the complexity of running cloud
    infrastructure. There are no servers to manage, and functions implicitly scale
    to meet demand. They are integrated with other value-added cloud services, such
    as streams, databases, API gateways, logging, and metrics, to further accelerate
    development. Functions are disposable architecture, which empower teams to experiment
    with different solutions. This recipe demonstrates how straightforward it is to
    deploy a function.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**函数即服务**是云原生架构的基石。函数使自给自足的全栈团队能够专注于交付精简的业务解决方案，而无需被运行云基础设施的复杂性所拖累。没有要管理的服务器，并且函数隐式地扩展以满足需求。它们与其他增值云服务（如流、数据库、API
    网关、日志和指标）集成，以进一步加速开发。函数是可丢弃的架构，赋予团队能够尝试不同解决方案的能力。这个配方演示了部署函数是多么简单。'
- en: How to do it...
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create the project from the following template:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Navigate to the `cncb-create-function` directory with `cd cncb-create-function`.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cd cncb-create-function` 命令导航到 `cncb-create-function` 目录。
- en: 'Review the file named `serverless.yml` with the following content:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看以下内容的 `serverless.yml` 文件：
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Review the file named `handler.js` with the following content:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看以下内容的 `handler.js` 文件：
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Install the dependencies with `npm install`.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm install` 安装依赖项。
- en: Run the tests with `npm test`.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm test` 运行测试。
- en: Review the contents generated in the `.serverless` directory.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看在 `.serverless` 目录中生成的内容。
- en: 'Deploy the stack:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署堆栈：
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Review the stack and function in the AWS Console.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 控制台中查看堆栈和函数。
- en: 'Invoke the function with the following command:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令调用函数：
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Review the function metrics in the AWS Console:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 控制台中查看函数指标：
- en: '![](img/21c0d7ed-059d-417e-a2a9-6c0aa6232cd7.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/21c0d7ed-059d-417e-a2a9-6c0aa6232cd7.png)'
- en: 'Review the function logs in the AWS Console:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 控制台中查看函数日志：
- en: '![](img/3a23c0ff-0fd6-4417-94c7-96702e0e6201.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3a23c0ff-0fd6-4417-94c7-96702e0e6201.png)'
- en: 'Take a look at the logs locally:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本地查看日志：
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Remove the stack once you have finished with `npm run rm:lcl -- -s $MY_STAGE`.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成操作后，使用 `npm run rm:lcl -- -s $MY_STAGE` 命令删除堆栈。
- en: How it works...
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The Serverless Framework handles the heavy lifting, which allows us to focus
    on writing the actual function code. The first thing to note is that we must define
    the `runtime: nodejs8.10` in the `serverless.yml` file. Next, we define a function
    in the `functions` section with a name and a handler. All other settings have
    defaulted, following the **configuration by exception** approach. When you look
    at the generated CloudFormation template, you will see that over 100 lines were
    generated from just a handful of lines declared in the `serverless.yml` file.
    A large portion of the generated template is dedicated to defining boilerplate
    security policies. Dig into the `.serverless/cloudformation-template-update-stack.json`
    file to see the details.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 'Serverless 框架处理繁重的工作，这使我们能够专注于编写实际的函数代码。首先要注意的是，我们必须在 `serverless.yml` 文件中定义
    `runtime: nodejs8.10`。接下来，我们在 `functions` 部分定义一个函数，包括一个名称和处理程序。所有其他设置都默认，遵循**异常配置**方法。当你查看生成的
    CloudFormation 模板时，你会看到仅从 `serverless.yml` 文件中声明的几行代码就生成了超过 100 行。生成模板的大部分内容都用于定义样板化的安全策略。深入查看
    `.serverless/cloudformation-template-update-stack.json` 文件以查看详细信息。'
- en: We also define `environment` variables in the serverless.yml. This allows the
    functions to be parameterized per deployment stage. We will cover this in more
    detail in [Chapter 6](390bdaaf-5f53-4d65-8a6c-2e47c815f2b3.xhtml), *Building a
    Continuous Deployment Pipeline*. This also allows settings, such as the debug
    level, to be temporarily tweaked without redeploying the function.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在 `serverless.yml` 中定义了 `environment` 变量。这允许函数根据部署阶段进行参数化。我们将在第 6 章[构建持续部署管道](390bdaaf-5f53-4d65-8a6c-2e47c815f2b3.xhtml)中更详细地介绍这一点。这也允许设置，如调试级别，可以临时调整而不需要重新部署函数。
- en: When we deploy the project, the Serverless Framework packages the function along
    with its runtime dependencies, as specified in the `package.json` file, into a
    ZIP file. Then, it uploads the ZIP file to the `ServerlessDeploymentBucket` so
    that it can be accessed by CloudFormation. The output of the deployment command
    shows when this is happening. You can look at the content of the ZIP file in the
    `.serverless` directory or download it from the deployment bucket. We will cover
    advanced packaging options in [Chapter 9](b2c8b5bd-dfe5-461e-a8fa-3e71c94e633c.xhtml),
    *Optimizing Performance*.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们部署项目时，Serverless Framework会将函数及其在`package.json`文件中指定的运行时依赖项打包到一个ZIP文件中。然后，它将ZIP文件上传到`ServerlessDeploymentBucket`，以便CloudFormation可以访问。部署命令的输出显示了这一过程。您可以在`.serverless`目录中查看ZIP文件的内容或从部署存储桶中下载它。我们将在[第9章](b2c8b5bd-dfe5-461e-a8fa-3e71c94e633c.xhtml)《优化性能》中介绍高级打包选项。
- en: 'The signature of an AWS Lambda function is straightforward. It must export
    a function that accepts three arguments: an event object, a context object, and
    a callback function. Our first function will just log the event, content, and
    the environment variables so that we can peer into the execution environment a
    little bit. Finally, we must invoke the callback. It is a standard JavaScript
    callback. We pass an error to the first argument or the successful result to the
    second argument.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Lambda函数的签名很简单。它必须导出一个接受三个参数的函数：一个事件对象、一个上下文对象和一个回调函数。我们的第一个函数将仅记录事件、内容和环境变量，以便我们可以稍微了解执行环境。最后，我们必须调用回调。这是一个标准的JavaScript回调。我们将错误传递给第一个参数或成功的结果传递给第二个参数。
- en: Logging is an important standard feature of **Function as a Service** (**FaaS**).
    Due to the ephemeral nature of cloud resources, logging in the cloud can be tedious,
    to put it lightly. In AWS Lambda, console logging is performed asynchronously
    and recorded in CloudWatch logs. It's a fully-managed logging solution built right
    in. Take the time to look at the details in the log statements that this function
    writes. The environment variables are particularly interesting. For example, we
    can see that each invocation of a function gets a new temporary access key.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录是**函数即服务**（**FaaS**）的一个重要标准功能。由于云资源的短暂性，轻描淡写地说，云中的日志记录可能会很繁琐。在AWS Lambda中，控制台日志是异步执行的，并记录在CloudWatch日志中。这是一个内置的完全托管日志解决方案。花点时间查看此函数写入的日志语句的详细信息。环境变量尤其有趣。例如，我们可以看到每个函数调用都会获得一个新的临时访问密钥。
- en: Functions also provide a standard set of metrics out-of-the-box, such as invocation
    count, duration, errors, throttling, and so forth. We will cover this in detail
    in [Chapter 7](64a4c0f7-3b2d-4638-a52c-f72953ff66d9.xhtml), *Optimizing Observability*.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 函数还提供了一套标准的指标，例如调用次数、持续时间、错误、节流等。我们将在[第7章](64a4c0f7-3b2d-4638-a52c-f72953ff66d9.xhtml)《优化可观察性》中详细介绍这一点。
- en: Creating an event stream and publishing an event
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建事件流并发布事件
- en: Cloud-native services are autonomous. Each service is completely self-sufficient
    and runs in isolation to minimize the blast radius when any given service experiences
    a failure. To achieve this isolation, *bulkheads* must be established between
    the services. **Event streaming** is one mechanism that is used to create these
    bulkheads. Autonomous cloud-native services perform all inter-service communication
    asynchronously via streams to decouple upstream services from downstream services.
    In [Chapter 2](129afdee-aa82-4ba6-9d80-5ec70c4a766e.xhtml), *Applying The Event
    Sourcing and CQRS Patterns*, we will dive deeper into how we create bounded, isolated,
    and autonomous cloud-native services. This recipe creates the event stream that
    we will use throughout this cookbook and provides a function for publishing events
    to the stream.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生服务是自治的。每个服务都是完全自给自足的，并且独立运行以最小化任何给定服务出现故障时的影响范围。为了实现这种隔离，必须在服务之间建立**防波堤**。**事件流**是创建这些防波堤的一种机制。自治的云原生服务通过流异步执行所有服务间通信，从而解耦上游服务与下游服务。在[第2章](129afdee-aa82-4ba6-9d80-5ec70c4a766e.xhtml)，《应用事件源和CQRS模式》中，我们将更深入地探讨我们如何创建有界、隔离和自治的云原生服务。此配方创建了我们将在整个食谱中使用的的事件流，并提供了一个将事件发布到流的函数。
- en: How to do it...
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create the project from the following template:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE10]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Navigate to the `cncb-event-stream` directory with `cd cncb-event-stream`.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cd cncb-event-stream` 命令进入 `cncb-event-stream` 目录。
- en: 'Review the file named `serverless.yml` with the following content:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看名为 `serverless.yml` 的文件，其内容如下：
- en: '[PRE11]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Review the file named `handler.js` with the following content:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看以下内容的`handler.js`文件：
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Install the dependencies with `npm install`.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`npm install`安装依赖项。
- en: Run the tests with `npm test`.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`npm test`运行测试。
- en: Review the contents generated in the `.serverless` directory.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看在`.serverless`目录中生成的内容。
- en: 'Deploy the stack:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署堆栈：
- en: '[PRE14]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Review the stack, stream, and function in the AWS Console.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在AWS控制台中查看堆栈、流和函数。
- en: 'Invoke the function with the following command:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令调用函数：
- en: '[PRE15]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Take a look at the logs:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看日志：
- en: '[PRE16]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Remove the stack once you have finished with `npm run rm:lcl -- -s $MY_STAGE`.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，使用`npm run rm:lcl -- -s $MY_STAGE`删除堆栈。
- en: This stack is a prerequisite for other recipes, as indicated in the *Getting
    ready* section of each recipe. If you are continuing with related recipes, then
    you can leave this stack running until you complete the related recipes. However,
    the stream in this stack is not included in the AWS free tier, so you may want
    to go ahead and remove this stack and recreate it when needed.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 此堆栈是其他菜谱的先决条件，如每个菜谱的*准备就绪*部分所示。如果你正在继续相关菜谱，那么你可以让这个堆栈运行，直到你完成相关菜谱。然而，此堆栈中的流不包括在AWS免费层中，因此你可能想先删除此堆栈，并在需要时重新创建它。
- en: How it works...
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `resources` section of the `serverless.yml` file is used to create cloud
    resources that are used by services. These resources are defined using standard
    AWS CloudFormation resource types. In this recipe, we are creating an AWS *Kinesis*
    stream. We give the stream a name, define the retention period, and specify the
    number of shards. The Serverless Framework provides a robust mechanism for dynamically
    replacing variables.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`serverless.yml`文件的`resources`部分用于创建由服务使用的云资源。这些资源使用标准的AWS CloudFormation资源类型定义。在这个菜谱中，我们创建了一个AWS
    *Kinesis* 流。我们给流起了一个名字，定义了保留期，并指定了分片数量。Serverless Framework提供了一个强大的机制来动态替换变量。'
- en: Here, we use the `${opt:stage}` option passed in on the command line and the
    `${self:service}` name defined in the `serverless.yml` file to create a unique
    stream name. The standard retention period is 24 hours and the maximum is seven
    days. For our recipes, one shard will be more than sufficient. We will discuss
    shards shortly and again in [Chapter 7](64a4c0f7-3b2d-4638-a52c-f72953ff66d9.xhtml),
    *Optimizing Observability*, and [Chapter 9](b2c8b5bd-dfe5-461e-a8fa-3e71c94e633c.xhtml),
    *Optimizing Performance*.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用命令行中传入的`${opt:stage}`选项和`serverless.yml`文件中定义的`${self:service}`名称来创建一个唯一的流名称。标准保留期是24小时，最大是7天。对于我们的菜谱，一个分片将绰绰有余。我们将在不久的将来讨论分片，并在[第7章](64a4c0f7-3b2d-4638-a52c-f72953ff66d9.xhtml)，*优化可观察性*和[第9章](b2c8b5bd-dfe5-461e-a8fa-3e71c94e633c.xhtml)，*优化性能*中再次讨论。
- en: The `Outputs` section of the `serverless.yml` file is where we define values,
    such as generated IDs and names, that we want to use outside of the stack. We
    output the **Amazon Resource Names** (**ARNs**) `streamName` and `streamArn` so
    that we can reference them with Serverless Framework variables in other projects.
    These values are also displayed on the Terminal when a deployment is complete.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`serverless.yml`文件的`Outputs`部分是我们定义要在外部堆栈中使用的值的区域，例如生成的ID和名称。我们输出**Amazon Resource
    Names**（**ARNs**）`streamName`和`streamArn`，这样我们就可以在其他项目中使用Serverless Framework变量来引用它们。这些值在部署完成后也会在终端上显示。'
- en: 'The `publish` function defined in the `serverless.yml` file is used to demonstrate
    how to publish an event to the stream. We are passing the `STREAM_NAME` to the
    function as an environment variable. In the `iamRoleStatements` section, we give
    the function `kinesis: PutRecord` permission to allow it to publish events to
    this specific stream.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '在`serverless.yml`文件中定义的`publish`函数用于演示如何将事件发布到流中。我们将`STREAM_NAME`作为环境变量传递给函数。在`iamRoleStatements`部分，我们授予函数`kinesis:
    PutRecord`权限，允许它将事件发布到这个特定的流。'
- en: The function `handler.js` file has runtime dependencies on two external libraries—`aws-sdk`
    and `uuid`. The Serverless Framework will automatically include the runtime dependencies,
    as defined in the `package.json` file. Take a look inside the generated `.serverless/cncb-event-stream.zip`
    file. The `aws-sdk` is a special case. It is already available in the AWS Lambda
    `Node.js` runtime, and therefore is not included. This is important because `aws-sdk`
    is a large library and the ZIP file size impacts cold start times. We will discuss
    this in more detail in [Chapter 9](b2c8b5bd-dfe5-461e-a8fa-3e71c94e633c.xhtml),
    *Optimizing Performance*.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`handler.js` 函数文件依赖于两个外部库——`aws-sdk` 和 `uuid`。Serverless 框架将自动包含在 `package.json`
    文件中定义的运行时依赖项。查看生成的 `.serverless/cncb-event-stream.zip` 文件。`aws-sdk` 是一个特殊情况。它已经在
    AWS Lambda `Node.js` 运行时中可用，因此不包括在内。这很重要，因为 `aws-sdk` 是一个大型库，ZIP 文件的大小会影响冷启动时间。我们将在第
    9 章 *优化性能* 中更详细地讨论这个问题。'
- en: The `publish` function expects to receive an event object as input, such as
    `{"type":"thing-created"}`. We then adorn the event with additional information
    to conform to our standard event format, which we will discuss shortly. Finally,
    the function creates the required `params` object and then calls `kinesis.putRecord`
    from the `aws-sdk`. We will be using this function in this and other recipes to
    simulate event traffic.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`publish` 函数期望接收一个事件对象作为输入，例如 `{"type":"thing-created"}`。然后我们为事件添加额外的信息，以符合我们的标准事件格式，我们将在稍后讨论。最后，该函数创建所需的
    `params` 对象，然后从 `aws-sdk` 调用 `kinesis.putRecord`。我们将在本食谱和其他食谱中使用此函数来模拟事件流量。'
- en: 'All events in our cloud-native systems will conform to the following **Event
    structure** to allow for consistent handling across all services. Additional fields
    are event-type-specific:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们云原生系统中的所有事件都将符合以下 **事件结构**，以便在所有服务中进行一致的处理。额外的字段是事件类型特定的：
- en: '[PRE17]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '`type` describes the event, such as `thing-created`'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`type` 描述了事件，例如 `thing-created`'
- en: '`timestamp` is an epoch value, as returned from `Date.now()`'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestamp` 是一个纪元值，由 `Date.now()` 返回'
- en: '`id` should be a V1 UUID, which is time-based'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id` 应该是一个 V1 UUID，基于时间'
- en: '`partitionKey` should be a V4 UUID, which is random number-based'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`partitionKey` 应该是一个 V4 UUID，基于随机数'
- en: '`tags` is a hashmap of useful data values that are leveraged for content-based
    routing and aggregating event metrics'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tags` 是一个包含有用数据值的哈希表，这些值被用于基于内容的路由和聚合事件度量'
- en: It is important to use a *V4 UUID* for the `partitionKey` to avoid hot shards
    and maximize concurrency. If a *V1 UUID* were used, then all events produced at
    the same time would go to the same shard. The `partitionKey` will typically be
    the ID of the domain entity that produced the event, which should use a V4 UUID
    for the same reason. This has the added benefit of ensuring that all events for
    the same domain entity are processed through the same shard in the order received.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个 *V4 UUID* 作为 `partitionKey` 非常重要，以避免热点分片并最大化并发性。如果使用 *V1 UUID*，则同一时间产生的所有事件都会进入同一个分片。`partitionKey`
    通常将是产生事件的域实体的 ID，这也应该使用 V4 UUID，原因相同。这还有一个额外的优点，即确保所有同一域实体的所有事件都按接收顺序通过同一个分片进行处理。
- en: Creating a stream processor
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建流处理器
- en: '**Stream processors** do most of the heavy lifting in cloud-native services.
    Autonomous cloud-native services perform all inter-service communication asynchronously
    via event streaming to decouple upstream services from **downstream services**.
    **Upstream services** publish events to a stream, with no knowledge of the specific
    downstream services that will eventually consume the events. Downstream services
    deploy stream-processing functions to consume events of interest. Stream processors
    will be covered extensively throughout this cookbook. This recipe demonstrates
    how to create a function that listens for events from an **AWS Kinesis** stream
    and provides a quick introduction to using the functional reactive programming
    paradigm for implementing stream processing.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**流处理器** 在云原生服务中承担大部分繁重的工作。自主云原生服务通过事件流异步执行所有服务间通信，从而解耦上游服务与**下游服务**。**上游服务**将事件发布到流中，无需了解最终将消费这些事件的特定下游服务。下游服务部署流处理函数以消费感兴趣的事件。流处理器将在整个烹饪书中进行详细说明。本食谱演示了如何创建一个监听来自
    **AWS Kinesis** 流的事件的函数，并快速介绍了使用函数式响应式编程范式实现流处理。'
- en: Getting ready
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Before starting this recipe, you will need an AWS Kinesis Stream, such as the
    one created in the *Creating an event stream* recipe.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始此配方之前，您需要一个 AWS Kinesis Stream，例如在 *创建事件流* 配方中创建的那个。
- en: How to do it...
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Create the project from the following template:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE18]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Navigate to the `cncb-create-stream-processor` directory with `cd cncb-create-stream-processor`.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cd cncb-create-stream-processor` 命令进入 `cncb-create-stream-processor` 目录。
- en: 'Review the file named `serverless.yml` with the following content:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看名为 `serverless.yml` 的文件，其内容如下：
- en: '[PRE19]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Review the file named `handler.js` with the following content:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看名为 `handler.js` 的文件，其内容如下：
- en: '[PRE20]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Install the dependencies with `npm install`.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm install` 命令安装依赖项。
- en: Run the tests with `npm test -- -s $MY_STAGE`.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm test -- -s $MY_STAGE` 命令运行测试。
- en: Review the contents generated in the `.serverless` directory.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看 `.serverless` 目录中生成的内容。
- en: 'Deploy the stack:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署堆栈：
- en: '[PRE21]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Review the stack and function in the AWS Console.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 控制台中查看堆栈和函数。
- en: 'Publish an event from a separate Terminal with the following commands:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令从另一个终端发布事件：
- en: '[PRE22]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Take a look at the logs from the original Terminal:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看原始终端的日志：
- en: '[PRE23]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，使用 `npm run rm:lcl -- -s $MY_STAGE` 命令删除堆栈。
- en: How it works...
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Stream processors listen for data from a streaming service such as **Kinesis**
    or **DynamoDB Streams**. Deploying a stream processor is completely declarative.
    We configure a function with the `stream` event type and the pertinent settings,
    such as the `type`, `arn`, `batchSize`, and `startingPosition`. The `arn` is set
    dynamically using a CloudFormation variable, `${cf:cncb-event-stream-${opt:stage}.streamArn}`,
    that references the output value of the `cnbc-event-stream` stack.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 流处理器监听来自流服务（如 **Kinesis** 或 **DynamoDB Streams**）的数据。部署流处理器是完全声明式的。我们使用 `stream`
    事件类型和相关设置（如 `type`、`arn`、`batchSize` 和 `startingPosition`）配置一个函数。`arn` 使用 CloudFormation
    变量 `${cf:cncb-event-stream-${opt:stage}.streamArn}` 动态设置，该变量引用 `cnbc-event-stream`
    堆栈的输出值。
- en: Streams are the only resources that are shared between autonomous cloud-native
    services.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 流是唯一在自主云原生服务之间共享的资源。
- en: We will discuss batch size and starting position in detail in both [Chapter
    8](5c400ff6-91da-4782-9369-549622d4a0d1.xhtml), *Designing for Failure*, and [Chapter
    9](b2c8b5bd-dfe5-461e-a8fa-3e71c94e633c.xhtml), *Optimizing Performance*. For
    now, you may have noticed that the new stream processor logged all the events
    that were published to the stream in the last 24 hours. This is because the `startingPosition`
    is set to `TRIM_HORIZON`. If it was set to `LATEST`, then it would only receive
    events that were published after the function was created.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在第 8 章 [设计故障](5c400ff6-91da-4782-9369-549622d4a0d1.xhtml)和第 9 章 [优化性能](b2c8b5bd-dfe5-461e-a8fa-3e71c94e633c.xhtml)中详细讨论批量大小和起始位置。目前，您可能已经注意到新的流处理器记录了在过去
    24 小时内发布到流中的所有事件。这是因为 `startingPosition` 被设置为 `TRIM_HORIZON`。如果它被设置为 `LATEST`，那么它只会接收在函数创建后发布的事件。
- en: Stream processing is a perfect match for functional reactive programming with
    Node.js streams. The terminology can be a little confusing because the word *stream*
    is overloaded. I like to think of streams as either *macro* or *micro*. For example,
    Kinesis is the *macro* stream and the code in our stream processor function is
    the *micro* stream. My favorite library for implementing the *micro* stream is
    **Highland.js** ([https://highlandjs.org](https://highlandjs.org)). A popular
    alternative is **RxJS** ([https://rxjs-dev.firebaseapp.com](https://rxjs-dev.firebaseapp.com)).
    As you can see in this recipe, functional reactive programming is very descriptive
    and readable. One of the reasons for this is that there are no loops. If you try
    to implement a stream processor with *imperative programming*, you will find that
    it quickly gets very messy. You also lose backpressure, which we will discuss
    in [Chapter 8](5c400ff6-91da-4782-9369-549622d4a0d1.xhtml), *Designing for Failure*.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 流处理与 Node.js 流的函数式响应式编程非常匹配。术语可能有点令人困惑，因为“流”这个词被过度使用了。我喜欢将流想象成“宏观”或“微观”。例如，Kinesis
    是“宏观”流，而我们流处理器函数中的代码是“微观”流。我最喜欢的实现“微观”流的库是 **Highland.js** ([https://highlandjs.org](https://highlandjs.org))。一个流行的替代方案是
    **RxJS** ([https://rxjs-dev.firebaseapp.com](https://rxjs-dev.firebaseapp.com))。正如您在这个配方中可以看到的，函数式响应式编程非常直观且易于阅读。其中一个原因是没有任何循环。如果您尝试使用
    **命令式编程** 实现流处理器，您会发现它很快就会变得非常混乱。您还会丢失背压，我们将在第 8 章 [设计故障](5c400ff6-91da-4782-9369-549622d4a0d1.xhtml)中讨论这一点。
- en: The code in the `listener` function creates a pipeline of steps that the data
    from the Kinesis stream will ultimately flow through. The first step, `_(event.Records)`,
    converts the array of Kinesis records into a Highland.js stream object that will
    allow each element in the array to be pulled through the stream in turn as the
    downstream steps are ready to receive the next element. The `.map(recordToEvent)`
    step decodes the Base64 encoded data from the Kinesis record and parses the JSON
    into an event object. The next step, `.tap(printEvent)`, simply logs the event
    so that we can see what is happening in the recipe.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`listener` 函数中的代码创建了一系列步骤，Kinesis 流中的数据最终将通过这些步骤流动。第一步，`_(event.Records)`，将
    Kinesis 记录的数组转换为 Highland.js 流对象，允许数组中的每个元素在下游步骤准备好接收下一个元素时依次通过流。`.map(recordToEvent)`
    步骤解码 Kinesis 记录中的 Base64 编码数据，并将 JSON 解析为事件对象。下一步，`.tap(printEvent)`，简单地记录事件，以便我们可以看到配方中的情况。'
- en: Kinesis and event streaming, in general, is a member of the high performance,
    dumb-pipe-smart-endpoints generation of messaging middleware. This means that
    Kinesis, the dumb pipe, does not waste its processing power on filtering data
    for the endpoints. Instead, all that logic is spread out across the processing
    power of the smart endpoints. Our stream processor function is the smart endpoint.
    To that end, the `.filter(forThingCreated)` step is responsible for filtering
    out the events that the processor is not interested in. All the remaining steps
    can assume that they are receiving the expected event types.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Kinesis 和事件流，通常来说，是高性能、哑管道-智能端点生成消息中间件的一员。这意味着 Kinesis，这个哑管道，不会浪费其处理能力来过滤端点数据。相反，所有这些逻辑都分散在智能端点的处理能力上。我们的流处理器函数是智能端点。为此，`.filter(forThingCreated)`
    步骤负责过滤掉处理器不感兴趣的事件。所有剩余的步骤都可以假设它们正在接收预期的事件类型。
- en: Our bare-boned stream processor needs something somewhat interesting but simple
    to do. So, we count and print the number of `thing-created` events in the batch.
    We have filtered out all other event types, so the `.collect()` step collects
    all the remaining events into an array. Then, the `.tap(printCount)` step logs
    the length of the array. Finally, the `.toCallback(cb)` step will invoke the callback
    function once all the data in the batch has been processed. At this point, the
    Kinesis checkpoint is advanced and the next batch of events is processed. We will
    cover error handling and how it relates to batches and checkpoints in [Chapter
    8](5c400ff6-91da-4782-9369-549622d4a0d1.xhtml), *Designing for Failure*.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这个简单的流处理器需要做一些有趣但简单的事情。因此，我们统计并打印批次中 `thing-created` 事件的数量。我们已经过滤掉了所有其他事件类型，所以
    `.collect()` 步骤将所有剩余的事件收集到一个数组中。然后，`.tap(printCount)` 步骤记录数组的长度。最后，`.toCallback(cb)`
    步骤将在批次中的所有数据都处理完毕后调用回调函数。此时，Kinesis 检查点将前进，并处理下一批事件。我们将在第 8 章 [设计故障处理](5c400ff6-91da-4782-9369-549622d4a0d1.xhtml)中介绍错误处理及其与批次和检查点的关联。
- en: Creating an API Gateway
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 API 网关
- en: An API Gateway is an essential element of cloud-native architecture. It provides
    a secure and performant perimeter at the boundaries of our cloud-native systems.
    The boundaries are where the system interacts with everything that is external
    to the system, including humans and other systems. We will leverage an API Gateway
    in the recipes that create boundary components such as a **Backend For Frontend** (**BFF**)
    or an External Service Gateway. This recipe demonstrates how straightforward it
    is to deploy an API Gateway.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: API 网关是云原生架构的一个基本元素。它为我们云原生系统的边界提供了一个安全且高效的防护。边界是系统与系统外部的一切（包括人类和其他系统）交互的地方。我们将利用
    API 网关在创建边界组件（如 **Backend For Frontend**（BFF）或外部服务网关）的配方中。本配方演示了部署 API 网关是多么简单。
- en: How to do it...
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create the project from the following template:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE24]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Navigate to the `cncb-create-api-gateway` directory with `cd cncb-create-api-gateway`.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cd cncb-create-api-gateway` 切换到 `cncb-create-api-gateway` 目录。
- en: 'Review the file named `serverless.yml` with the following content:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看名为 `serverless.yml` 的文件，其内容如下：
- en: '[PRE25]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Review the file named `handler.js` with the following content:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看名为 `handler.js` 的文件，其内容如下：
- en: '[PRE26]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Install the dependencies with `npm install`.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm install` 安装依赖项。
- en: Run the tests with `npm test`.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm test` 运行测试。
- en: Review the contents generated in the `.serverless` directory.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看在 `.serverless` 目录中生成的内容。
- en: 'Deploy the stack:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署堆栈：
- en: '[PRE27]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Review the stack, API, and function in the AWS Console.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 控制台中查看堆栈、API 和函数。
- en: 'Invoke the `endpoint` shown in the stack output in the following commands:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在以下命令中调用堆栈输出中显示的 `endpoint`：
- en: '[PRE28]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Take a look at the logs:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看日志：
- en: '[PRE29]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成操作后，使用 `npm run rm:lcl -- -s $MY_STAGE` 删除堆栈。
- en: How it works...
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Creating an API Gateway is completely declarative. We just configure a function
    with the `http` event type and the pertinent settings, such as the `path` and
    `method`. All other settings have defaulted following the **configuration by exception**
    approach. When you look at the generated `.serverless/cloudformation-template-update-stack.json`
    file, you will see that over 100 lines were generated from just a handful of lines
    declared in the `serverless.yml` file. The API name is calculated based on the
    combination of the service name declared at the top of the `serverless.yml` file
    and the specified stage. There is a one-to-one mapping between a serverless project
    and an API Gateway. All the functions in the project declared with an `http` event
    are included in the API.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 API 网关是完全声明式的。我们只需配置一个具有 `http` 事件类型和相关设置的函数，例如 `path` 和 `method`。所有其他设置都遵循
    **异常配置** 方法默认设置。当你查看生成的 `.serverless/cloudformation-template-update-stack.json`
    文件时，你会看到仅从 `serverless.yml` 文件中声明的几行代码就生成了超过 100 行。API 名称是根据 `serverless.yml`
    文件顶部的服务名称和指定的阶段组合计算得出的。无服务器项目和 API 网关之间存在一对一的映射。项目中所有使用 `http` 事件声明的函数都包含在 API
    中。
- en: 'The signature of the function is the same as all others; however, the contents
    of the event and the expected response format are specific to the API Gateway
    service. The `event` contains the full contents of the HTTP request including
    the path, parameters, header, body, and more. The `response` requires a `statusCode`
    and options headers and body. The body must be a string, and the header must be
    an object. I declared the function with the `cors: true` setting so that the recipe
    could include a legitimate set of response headers. We will cover security in
    detail in [Chapter 5](75b256e5-1fe4-4c9e-ab56-28cef7a8a0ab.xhtml), *Securing Cloud-Native
    Systems*. For now, know that security features such as SSL, throttling, and DDoS
    protection are default features of the AWS API Gateway.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '函数的签名与其他函数相同；然而，事件的内容和预期的响应格式是针对 API 网关服务的。`event` 包含 HTTP 请求的全部内容，包括路径、参数、头部、主体等。`response`
    需要一个 `statusCode` 和选项头部和主体。主体必须是一个字符串，头部必须是一个对象。我使用 `cors: true` 设置声明了函数，以便食谱可以包括一组合法的响应头部。我们将在
    [第 5 章](75b256e5-1fe4-4c9e-ab56-28cef7a8a0ab.xhtml)，*保护云原生系统* 中详细讨论安全性。目前，知道 SSL、节流和
    DDoS 保护是 AWS API 网关的默认功能。'
- en: The `endpoint` for the API Gateway is declared as a stack output and displayed
    after the stack is deployed. We will see ways to customize the endpoint in [Chapter
    4](766f325f-38d5-474b-bac2-79f8af7d01ae.xhtml), *Leveraging the Edge of the Cloud*,
    and in [Chapter 10](7ddedd13-fcee-4091-8566-02c9814cb782.xhtml), *Deploying to
    Multiple Regions*. Once you invoke the service, you will be able to see the details
    of the inputs and outputs, both in the HTTP response as it was coded and then
    in the function's logs. Take a look at the API Gateway in the AWS Console as well.
    However, the goal of automation and the *Serverless Framework* is to eliminate
    the need to make changes in the console. I looked at the API in the console while
    writing this book, but other than that I can't remember the last time I actually
    needed to go into the API Gateway console.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: API 网关的 `endpoint` 被声明为堆栈输出，并在部署堆栈后显示。我们将在 [第 4 章](766f325f-38d5-474b-bac2-79f8af7d01ae.xhtml)，*利用云的边缘*
    和 [第 10 章](7ddedd13-fcee-4091-8566-02c9814cb782.xhtml)，*部署到多个区域* 中看到自定义端点的方法。一旦调用服务，你将能够看到输入和输出的详细信息，包括编码的
    HTTP 响应以及函数的日志。同时查看 AWS 控制台中的 API 网关。然而，自动化和 *Serverless Framework* 的目标是消除在控制台中进行更改的需要。我在写这本书时查看控制台中的
    API，但除此之外，我不记得上一次我真正需要进入 API 网关控制台是什么时候了。
- en: Deploying a single-page application
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署单页应用程序
- en: The cloud-native light bulb first turned on in my head when I realized I could
    deploy a single page application, such as Angular, to an S3 bucket and serve it
    up globally with no need for servers and load balancers whatsoever. This was my
    first cloud-native W*ow!* moment. It was the moment when I began to understand
    that cloud-native plays by an entirely different set of rules. The combination
    of S3 and a JavaScript-based UI delivers a web presentation tier with virtually
    limitless scalability, virtually no cost, and essentially no operation headaches.
    This recipe demonstrates how straightforward it is to deploy a single-page application.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 当我意识到可以将单页应用，如Angular，部署到S3存储桶，并无需服务器和负载均衡器即可在全球范围内提供时，云原生灯泡首先在我的脑海中亮起。这是我第一次云原生W*ow!*时刻。这是我开始理解云原生完全遵循一套不同规则的时刻。S3和基于JavaScript的UI的组合提供了一种几乎无限可扩展、几乎无成本和几乎没有操作烦恼的Web表示层。这个配方展示了部署单页应用是多么简单。
- en: How to do it...
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create the project from the following template:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE30]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Navigate to the `cncb-deploy-spa` directory with `cd cncb-deploy-spa`.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`cd cncb-deploy-spa`导航到`cncb-deploy-spa`目录。
- en: 'Review the file named `serverless.yml` with the following content:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查名为`serverless.yml`的文件，其内容如下：
- en: '[PRE31]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Review the file named `package.json` with the following content:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查名为`package.json`的文件，其内容如下：
- en: '[PRE32]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Install the dependencies with `npm install`.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`npm install`安装依赖。
- en: Run the app locally with `npm start`.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`npm start`在本地运行应用。
- en: Run the tests with `npm test`.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`npm test`运行测试。
- en: Review the contents generated in the `.serverless` directory.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查`.serverless`目录中生成的内容。
- en: Build the app with `npm run build`.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`npm run build`构建应用。
- en: Review the contents generated in the `build` directory.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查`build`目录中生成的内容。
- en: 'Deploy the stack:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署栈：
- en: '[PRE33]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Review the stack and bucket in the AWS Console
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在AWS控制台中检查栈和存储桶。
- en: 'Browse to the `WebsiteURL` shown in the stack output:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 浏览栈输出中显示的`WebsiteURL`：
- en: '![](img/da5cc4c6-148f-4d68-8592-85bebf07c8f9.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/da5cc4c6-148f-4d68-8592-85bebf07c8f9.png)'
- en: Remove the stack once you have finished with `npm run rm:lcl -- -s $MY_STAGE`
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成操作后，使用`npm run rm:lcl -- -s $MY_STAGE`删除栈。
- en: How it works...
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The first thing to notice is that we are using all the same development tools
    for the full stack. This is one of many advantages of using JavaScript for backend
    development. A single, self-sufficient, full-stack team can develop the frontend
    application and the BFF service with the same programming language. This can allow
    for more efficient utilization of team resources.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要注意的是，我们正在使用全套相同的开发工具。这是使用JavaScript进行后端开发的优势之一。一个单一、自给自足的全栈团队能够使用相同的编程语言开发前端应用和BFF服务。这可以允许更有效地利用团队资源。
- en: There are two new standard scripts—`start` and `build`. `npm start` will run
    the frontend app locally using Node.js as the web server. `npm run build` will
    prepare the application for deployment. I used the `react-scripts` library so
    as not to clutter the example with a detailed ReactJS build process. This recipe
    uses a small, canned ReactJS example for the same reason. I wanted an app that
    was just large enough to have something to deploy. ReactJS is not the focus of
    this recipe or cookbook. There are volumes already written on ReactJS and similar
    frameworks.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个新的标准脚本——`start`和`build`。`npm start`将使用Node.js作为网络服务器在本地运行前端应用。`npm run build`将为部署准备应用。我使用了`react-scripts`库，以便不使示例因详细的ReactJS构建过程而变得杂乱。这个配方使用了一个小型、预制的ReactJS示例，原因相同。我想创建一个足够大的应用，以便有东西可以部署。ReactJS不是这个配方或食谱的重点。已经有大量关于ReactJS和类似框架的书籍。
- en: We are creating an S3 bucket, `WebsiteBucket`, and configuring it as a website.
    The stack output displays the `WebsiteUrl` used to access the SPA. The SPA will
    be served from a bucket with no need for servers whatsoever. In this context,
    we can think of S3 as a global web server.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在创建一个S3存储桶，名为`WebsiteBucket`，并将其配置为网站。栈输出显示了用于访问SPA的`WebsiteUrl`。SPA将从无需服务器的存储桶中提供。在这种情况下，我们可以将S3视为一个全球性的网络服务器。
- en: We are using a Serverless plugin for the first time in this recipe. The `serverless-spa-deploy`
    plugin will upload the SPA files from the `./build` directory after the stack
    is deployed. Note that we are not explicitly naming the bucket. CloudFormation
    will generate the name with a random suffix. This is important because bucket
    names must be globally unique. The plugin infers the generated bucket name. The
    plugin has sensible defaults that can be customized, such as to change the `CacheControl`
    headers for different files. The plugin also empties the bucket, before stack
    removal.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这个菜谱中首次使用无服务器插件。`serverless-spa-deploy` 插件将在栈部署后从 `./build` 目录上传 SPA 文件。请注意，我们没有明确命名存储桶。CloudFormation
    将使用随机后缀生成名称。这很重要，因为存储桶名称必须是全局唯一的。插件推断生成的存储桶名称。该插件有合理的默认设置，可以进行自定义，例如更改不同文件的 `CacheControl`
    头部。插件还会在栈移除前清空存储桶。
- en: We will build on this architecture in [Chapter 4](766f325f-38d5-474b-bac2-79f8af7d01ae.xhtml),
    *Leveraging the Edge of the Cloud*.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 [第 4 章](766f325f-38d5-474b-bac2-79f8af7d01ae.xhtml) 中构建这个架构，*利用云的边缘*。
