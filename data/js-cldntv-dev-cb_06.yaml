- en: Building a Continuous Deployment Pipeline
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建持续部署管道
- en: 'In this chapter, the following recipes will be covered:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，将涵盖以下食谱：
- en: Creating the CI/CD pipeline
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建 CI/CD 管道
- en: Writing unit tests
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写单元测试
- en: Writing integration tests
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写集成测试
- en: Writing contract tests for a synchronous API
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为同步 API 编写合同测试
- en: Writing contract tests for an asynchronous API
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为异步 API 编写合同测试
- en: Assembling transitive end-to-end tests
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组装传递性端到端测试
- en: Leveraging feature flags
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用功能标志
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: Throughout the preceding chapters, we have seen how cloud-native is lean and
    autonomous. Leveraging fully-managed cloud services and establishing proper bulkheads
    empowers self-sufficient, full-stack teams to rapidly and continuously deliver
    autonomous services with the confidence that a failure in any one service will
    not cripple the upstream and downstream services that depend on it. This architecture
    is a major advancement because these safeguards protect us from inevitable human
    errors. However, we must still endeavor to minimize human error and increase our
    confidence in our systems.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们看到了云原生是如何精益和自主的。利用完全管理的云服务和建立适当的防波堤，使自给自足的全栈团队能够快速且持续地交付自主服务，并具有信心，即任何单个服务的故障都不会损害依赖于它的上游和下游服务。这种架构是一个重大进步，因为这些保障措施保护我们免受不可避免的人类错误的影响。然而，我们仍然必须努力减少人类错误并提高我们对系统的信心。
- en: To minimize and control potential mistakes, we need to minimize and control
    our batch sizes. We accomplish this by following the practice of *decoupling deployment
    from release*. A **deployment** is just the act of deploying a piece of software
    into an environment, whereas a **release** is just the act of making that software
    available to a set of users. Following **lean** methods, we release functionality
    to users in a series of small, focused experiments that determine whether or not
    the solution is on the right track, so that timely course corrections can be made.
    Each experiment consists of a set of stories, and each story consists of a set
    of small focused tasks. These tasks are our unit of deployment. For each story,
    we plan a roadmap that will continuously deploy these tasks in an order that accounts
    for all inter-dependencies, so that there is zero downtime. The practices that
    govern each individual task are collectively referred to as a **task branch workflow**.
    The recipes in this chapter demonstrate the inner-working of a task branch workflow
    and how, ultimately, we enable these features for users with feature flags.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最小化和控制潜在的错误，我们需要最小化和控制我们的批次大小。我们通过遵循将部署与发布**解耦**的实践来实现这一点。**部署**只是将软件部署到环境中的行为，而**发布**只是将软件提供给一组用户的行为。遵循**精益**方法，我们通过一系列小而专注的实验向用户发布功能，以确定解决方案是否在正确的轨道上，以便及时进行纠正。每个实验由一系列故事组成，每个故事由一系列小而专注的任务组成。这些任务是我们的部署单元。对于每个故事，我们制定一个路线图，以连续部署这些任务，并考虑到所有相互依赖关系，以确保零停机时间。管理每个单独任务的实践统称为**任务分支工作流程**。本章中的食谱展示了任务分支工作流程的内部运作方式以及我们如何最终通过功能标志为用户提供这些功能。
- en: Creating the CI/CD pipeline
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 CI/CD 管道
- en: Small batch sizes reduce deployment risk because it is much easier to reason
    about their correctness and much easier to correct them when they are in error.
    Task branch workflow is a Git workflow that is focused on extremely short-lived
    branches, in the range of just hours rather than days. It is similar to an *issue
    branch workflow*, in that each task is tracked as an issue in the project management
    tool. The length of an issue is ambiguous, however, because an issue can be used
    to track an entire feature. This recipe demonstrates how issue tracking, Git branches,
    pull requests, testing, code review, and the CI/CD pipeline work together in a
    task branch workflow to govern small focused units of deployment.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 小批次大小可以降低部署风险，因为更容易推理它们的正确性，并且在出错时更容易纠正。任务分支工作流程是一种 Git 工作流程，专注于极短生命周期的分支，范围仅为几小时而不是几天。它类似于**问题分支工作流程**，因为每个任务都作为项目管理工具中的问题进行跟踪。然而，问题的长度是模糊的，因为一个问题可以用来跟踪整个功能。这个食谱展示了在任务分支工作流程中，问题跟踪、Git
    分支、拉取请求、测试、代码审查和 CI/CD 管道如何协同工作，以管理小而专注的部署单元。
- en: Getting ready
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Before starting this recipe, you will need to have an account on GitLab ([https://about.gitlab.com/](https://about.gitlab.com/)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始这个食谱之前，您需要在 GitLab 上有一个账户([https://about.gitlab.com/](https://about.gitlab.com/))。
- en: How to do it...
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Create the project from the following template:'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Navigate to the `cncb-pipeline` directory, `cd cncb-pipeline`.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 `cncb-pipeline` 目录，`cd cncb-pipeline`。
- en: 'Initialize the Git repository locally and remotely in `gitlab.com`, as follows:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `gitlab.com` 上本地和远程初始化 Git 仓库，如下所示：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Confirm that the project was created in your Gitlab account.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确认项目已在您的 Gitlab 账户中创建。
- en: Create a new issue in the project named `intialize-project`.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在项目中创建一个名为 `intialize-project` 的新问题。
- en: Press the Create merge request button and note the name of the branch, such
    as `1-initialize-project`.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击创建合并请求按钮并注意分支名称，例如 `1-initialize-project`。
- en: Check out the branch locally at with `git pull && git checkout 1-initialize-project`.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `git pull && git checkout 1-initialize-project` 在本地检出分支。
- en: 'Review the file named `.gitlab-ci.yml` with the following content:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看名为 `.gitlab-ci.yml` 的文件，其内容如下：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Review the file named `package.json` with the following content:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看名为 `package.json` 的文件，其内容如下：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Review the file named `serverless.yml` with the following content:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看名为 `serverless.yml` 的文件，其内容如下：
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Configure the `DEV_AWS_ACCESS_KEY_ID`, `DEV_AWS_SECRET_ACCESS_KEY`, `PROD_AWS_ACCESS_KEY_ID`,
    `PROD_AWS_SECRET_ACCESS_KEY`, and `NPM_TOKEN` environment variables in the GitLab
    project ([https://gitlab.com/](https://gitlab.com/)) under Settings* | *CI/CD
    |Variables.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 GitLab 项目（[https://gitlab.com/](https://gitlab.com/)）的设置* | *CI/CD | 变量下配置
    `DEV_AWS_ACCESS_KEY_ID`、`DEV_AWS_SECRET_ACCESS_KEY`、`PROD_AWS_ACCESS_KEY_ID`、`PROD_AWS_SECRET_ACCESS_KEY`
    和 `NPM_TOKEN` 环境变量。
- en: 'Push the project files to the remote repository, as follows:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按如下方式将项目文件推送到远程仓库：
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Before pushing your changes, you should always execute `git pull` to keep your
    task branch in sync with the master branch.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在推送更改之前，你应该始终执行 `git pull` 以保持你的任务分支与主分支同步。
- en: Review the code in the merge request.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看合并请求中的代码。
- en: Review the progress of the branch pipeline.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看分支管道的进度。
- en: Review the `cncb-pipeline-stg` stack in the AWS Console.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 控制台中查看 `cncb-pipeline-stg` 堆栈。
- en: Remove the `WIP:` prefix from the name of the merge request and accept the merge
    request.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从合并请求的名称中移除 `WIP:` 前缀并接受合并请求。
- en: It is best to start a pull request as early as possible to receive feedback
    as early as possible. The `WIP:` prefix indicates to reviewers that work is still
    progressing. The prefix is purely procedural, but GitLab will not allow a merge
    request with a WIP prefix to be accidentally accepted.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 最好尽早开始拉取请求，以便尽早收到反馈。`WIP:` 前缀向审阅者表明工作仍在进行中。前缀纯粹是程序性的，但 GitLab 不会允许带有 WIP 前缀的合并请求被意外接受。
- en: Review the progress of the master pipeline.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看主管道的进度。
- en: Review the `cncb-pipeline-prd` stack in the AWS Console.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 AWS 控制台中查看 `cncb-pipeline-prd` 堆栈。
- en: Remove both stacks once you are finished.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，删除两个堆栈。
- en: How it works...
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: We are using `GitLab.com` simply because it is a freely-available and hosted
    toolset that is well-integrated. There are other alternatives, such as Bitbucket
    Pipelines, that require a little more elbow grease to stand up but they still
    offer comparable features. A `bitbucket-pipelines.yml` file is included in the
    recipes for comparison.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `GitLab.com` 简单是因为它是一个免费且托管的工具集，且集成良好。还有其他替代方案，如 Bitbucket Pipelines，虽然需要更多努力才能设置，但它们仍然提供类似的功能。比较的食谱中包含了一个
    `bitbucket-pipelines.yml` 文件。
- en: As we have seen throughout this cookbook, our unit of deployment is a stack,
    as defined by a `serverless.yml` file in the root of a project directory. As we
    see in this recipe, each project is managed in its own Git repository and has
    its own CI/CD pipeline. The pipeline is defined by a configuration file that lives
    in the root of the project as well, such as a `.gitlab-ci.yml` or `bitbucket-pipelines.yml`
    file. These pipelines are integrated with the Git branching strategy and are governed
    by pull requests.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在整个食谱中看到的那样，我们的部署单元是一个堆栈，由项目目录根目录中的 `serverless.yml` 文件定义。正如我们在本食谱中看到的那样，每个项目都在其自己的
    Git 仓库中管理，并有自己的 CI/CD 管道。管道由位于项目根目录的配置文件定义，例如 `.gitlab-ci.yml` 或 `bitbucket-pipelines.yml`
    文件。这些管道与 Git 分支策略集成，并由拉取请求管理。
- en: Note that GitLab uses the term *merge request*, whereas other tools use the
    term *pull request*. The two terms can be used interchangeably.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 GitLab 使用术语 *merge request*，而其他工具使用术语 *pull request*。这两个术语可以互换使用。
- en: A task branch workflow begins when an issue or task is pulled in from the backlog
    and used to create a branch in the repository. A pull request is created to govern
    the branch. The pipeline executes all tests on the branch and its progress is
    displayed in the pull request. Once the tests are considered successful, the pipeline
    deploys the stack to the staging environment in the development account. A code
    review is performed in the pull request and discussion is recorded with comments.
    Once everything is in order, the pull request can be accepted to merge the changes
    to the master branch and trigger deployment of the stack to the production environment
    in the production account.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当从待办事项中拉取问题或任务以在仓库中创建分支时，任务分支工作流程开始。创建一个拉取请求来管理分支。管道在分支上执行所有测试，并在拉取请求中显示其进度。一旦测试被认为成功，管道将堆栈部署到开发账户的预发布环境中。在拉取请求中执行代码审查，并通过评论记录讨论。一旦一切就绪，拉取请求可以被接受以合并更改到主分支，并触发将堆栈部署到生产账户的生产环境的部署。
- en: The first line of the pipeline definition denotes that the `node:8` Docker image
    will be used to execute the pipeline. The rest of the pipeline definition orchestrates
    the steps we have been executing manually throughout this cookbook. First, `npm
    install` installs all the dependencies as defined in the `package.json` file.
    Then, we execute all the tests on the given branch. Finally, we deploy the stack
    to the specific environment and region with `npm`; in this case, `npm run dp:stg:e`
    or `npm run dp:prd:e`. The details of each step are encapsulated in the `npm`
    scripts.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 管道定义的第一行表示将使用`node:8` Docker镜像来执行管道。管道定义的其余部分编排了我们在此菜谱中手动执行的步骤。首先，`npm install`安装了在`package.json`文件中定义的所有依赖项。然后，我们在给定的分支上执行所有测试。最后，我们使用`npm`将堆栈部署到特定的环境和区域；在这种情况下，`npm
    run dp:stg:e`或`npm run dp:prd:e`。每个步骤的详细信息都封装在`npm`脚本中。
- en: Note that, throughout this cookbook, we have been using the `npm run dp:lcl`
    script to perform our deployments. These allow each developer to perform development
    and testing in a personal stack (that is, local or `lcl`) to help ensure that
    the staging (`stg`) environment stays stable and therefore the production (`prd`)
    environment as well.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在整个菜谱中，我们一直在使用`npm run dp:lcl`脚本来执行我们的部署。这些允许每个开发者在一个个人堆栈（即本地或`lcl`）中进行开发和测试，以确保预发布（`stg`）环境保持稳定，从而生产（`prd`）环境也是如此。
- en: Environment variables, such as `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`,
    are securely stored by the pipeline and never logged. We define a set of variables
    per account, as identified by the `DEV_` and `PROD_` prefix, and then map them
    in the pipeline definition. In the *Securing your cloud account* recipe, we created `CiCdUser`
    to grant permissions to the pipelines. Here, we need to manually create an access
    key for those users and securely store them as pipeline variables. The keys and
    pipeline variables are then periodically rotated and updated.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 环境变量，如`AWS_ACCESS_KEY_ID`和`AWS_SECRET_ACCESS_KEY`，由管道安全存储且不会被记录。我们为每个账户定义一组变量，由`DEV_`和`PROD_`前缀标识，然后在管道定义中映射它们。在*保护您的云账户*菜谱中，我们创建了`CiCdUser`来授予管道权限。在这里，我们需要为这些用户手动创建访问密钥并将它们作为管道变量安全存储。密钥和管道变量随后定期轮换和更新。
- en: The pipeline deploys the stack to the staging environment in the development
    account for each task branch, and to the production environment in the production
    account for the master branch. The access key determines which account is used
    and the Serverless Framework `-s` option fully qualifies the name of the stack.
    We then add an additional option called `--acct` to allow us to index into account-scoped
    custom variables, such as `${self:custom.accounts.${opt:acct}.accountNumber}`.
    To help avoid confusion between the production stage and the production account,
    we need to use use slightly different abbreviations, such as `prd` and `prod`.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 管道将堆栈部署到开发账户的每个任务分支的预发布环境中，以及生产账户的主分支的生产环境中。访问密钥决定了使用哪个账户，Serverless Framework
    `-s`选项完全限定堆栈的名称。然后我们添加一个额外的选项`--acct`，允许我们索引到账户范围的自定义变量，例如`${self:custom.accounts.${opt:acct}.accountNumber}`。为了避免在生产阶段和生产账户之间产生混淆，我们需要使用略微不同的缩写，例如`prd`和`prod`。
- en: Writing unit tests
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写单元测试
- en: Unit testing is arguably the most important type of testing and should certainly
    account for the majority of test cases in the test pyramid. Testing should follow
    a scientific method where we hold some variables constant, adjust the input, and
    measure the output. Unit testing accomplishes this by testing individual units
    in isolation. This allows unit tests to focus on functionality and maximize coverage.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 单元测试可能是最重要的测试类型，并且应该当然占据测试金字塔中的大多数测试用例。测试应遵循科学方法，其中我们保持一些变量不变，调整输入，并测量输出。单元测试通过在隔离状态下测试单个单元来实现这一点。这使得单元测试能够专注于功能并最大化覆盖率。
- en: How to do it...
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create the project from the following template:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Navigate to the `cncb-unit-testing` directory with `cd cncb-unit-testing`.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cd cncb-unit-testing` 命令导航到 `cncb-unit-testing` 目录。
- en: Install the dependencies with `npm install`.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm install` 安装依赖项。
- en: 'Review the file named `package.json` with the following content:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查名为 `package.json` 的文件，其内容如下：
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Run the unit tests, as follows:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按以下方式运行单元测试：
- en: '[PRE8]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Review the file named `test/unit/connector/db.test.js` with the following content:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查名为 `test/unit/connector/db.test.js` 的文件，其内容如下：
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Review the file named `test/unit/get/index.test.js` with the following content:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查名为 `test/unit/get/index.test.js` 的文件，其内容如下：
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: (Optional) Repeat the steps from the *Creating the CI/CD pipeline* recipe with
    this project.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (可选) 使用此项目重复从“创建 CI/CD 管道”菜谱中的步骤。
- en: How it works...
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In previous recipes, we purposefully simplified the examples to a reasonable
    degree to highlight the specific topics. The code was correct but the recipes
    did not have any unit tests, because the topic had not yet been addressed. The
    first thing you are likely to notice in the recipes in this chapter is that we
    are adding additional structure to the code; for example, each function has its
    own directory and files and we have also added some lightweight layering to the
    code. This structure is intended to facilitate the testing process by making it
    easier to isolate the unit that is under test. So, let's now dig deeper into the
    tools and structure that have been added.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的菜谱中，我们故意将示例简化到合理的程度，以突出特定主题。代码是正确的，但菜谱没有包含任何单元测试，因为该主题尚未被涉及。你在这个章节的菜谱中可能首先注意到的是，我们正在向代码中添加额外的结构；例如，每个函数都有自己的目录和文件，我们还在代码中添加了一些轻量级分层。这种结构旨在通过使隔离测试单元更容易而简化测试过程。因此，现在让我们更深入地探讨已添加的工具和结构。
- en: The first tool that is called in the `npm test` script is `nyc`, which is the
    command line interface for the `istanbul` code coverage tool. The `.nycrc` file
    configures the code coverage process. Here, we require 100% coverage. This is
    perfectly reasonable for the scope of our bounded, isolated, and autonomous services.
    It is also reasonable because we are writing the unit tests incrementally as we
    also incrementally build the services in a series of task branch workflows. Furthermore,
    without keeping the coverage at 100%, it would be too easy to skip the testing
    until later on in the development process, which is dangerous in a continuous
    deployment pipeline and defeats the purpose. Fortunately, the structure of the
    code makes it much easier to identify which features are lacking tests.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `npm test` 脚本中调用的第一个工具是 `nyc`，它是 `istanbul` 代码覆盖率工具的命令行界面。`.nycrc` 文件配置了代码覆盖率过程。在这里，我们要求达到
    100% 的覆盖率。对于我们的边界、隔离和自主服务的范围来说，这是完全合理的。这也合理，因为我们正在以增量方式编写单元测试，同时也在一系列任务分支工作流程中增量构建服务。此外，如果不保持覆盖率在
    100%，那么在开发过程的后期跳过测试就会变得过于容易，这在持续部署管道中是危险的，并且违背了测试的目的。幸运的是，代码的结构使得识别缺少测试的功能变得更加容易。
- en: The `npm pretest` script runs the linting process. `eslint` is a very valuable
    tool. It enforces best practices, automatically fixes many violations, and identifies
    common problems. In essence, linting helps to teach developers how to write better
    code. The linting process can be tuned with the `.eslintignore` and `.eslintrc.js`
    files.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`npm pretest` 脚本运行 linting 过程。`eslint` 是一个非常宝贵的工具。它强制执行最佳实践，自动修复许多违规行为，并识别常见问题。从本质上讲，linting
    有助于教会开发者如何编写更好的代码。可以通过 `.eslintignore` 和 `.eslintrc.js` 文件调整 linting 过程。'
- en: Isolating external dependencies is an essential part of unit testing. Our testing
    tools of choice are `mocha`, `chai`, `sinon`, and `aws-sdk-mock`. There are many
    tools available, but this combination is extremely popular. mocha is the overarching
    testing framework; `chai` is the assertion library; `sinon` provides test spies,
    stubs, and mocks; and `aws-sdk-mock` builds on sinon to simplify testing against
    the `aws-sdk`. To further facilitate this process, we isolate our `aws-sdk` calls
    inside Connector classes. This does have the added benefit of reusing code throughout
    the service, but its primary benefit is to simplify testing. We write unit tests
    specifically for the classes that use `aws-sdk-mock`. Throughout the rest of the
    unit test code, we stub out the connector layer, which greatly simplifies the
    setup of each test, because we have isolated the complexities of the `aws-sdk`.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 隔离外部依赖是单元测试的一个基本部分。我们选择的测试工具是 `mocha`、`chai`、`sinon` 和 `aws-sdk-mock`。有许多工具可用，但这个组合非常受欢迎。mocha
    是总的测试框架；`chai` 是断言库；`sinon` 提供测试间谍、存根和模拟；`aws-sdk-mock` 基于 `sinon` 来简化对 `aws-sdk`
    的测试。为了进一步便于这个过程，我们在连接器类中隔离了我们的 `aws-sdk` 调用。这确实有代码在整个服务中重用的额外好处，但其主要好处是简化测试。我们专门为使用
    `aws-sdk-mock` 的类编写单元测试。在整个单元测试代码中，我们存根化连接器层，这极大地简化了每个测试的设置，因为我们已经隔离了 `aws-sdk`
    的复杂性。
- en: The `Handler` classes account for the bulk of the testing. These classes encapsulate
    and orchestrate the business logic, and therefore will require the most testing
    permutations. To facilitate this effort, we decouple the `Handler` classes from
    the `callback` function. The `handle` method either returns a *promise* or a *stream*
    and the top-level function then adapts these to the callback. This allows tests
    to easily tap into the processing flow to assert the outputs.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`Handler` 类负责大部分的测试。这些类封装和编排业务逻辑，因此将需要最多的测试组合。为了便于这项工作，我们将 `Handler` 类与 `callback`
    函数解耦。`handle` 方法要么返回一个 *promise*，要么返回一个 *stream*，然后顶层函数将这些适配到回调。这允许测试轻松地接入处理流程以断言输出。'
- en: Our tests are inherently asynchronous; therefore, it is important to guard against
    evergreen tests that do not fail when the code is broken. For handlers that return
    promises, the best approach is to use `async`/`await` to guard against swallowed
    exceptions. For handlers that return a stream, the best approach is to use the
    collect/tap/done pattern to protect against scenarios where the data does not
    flow all the way through the stream.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的测试本质上是异步的；因此，防止永远不失败的测试（即代码出错时不会失败的测试）非常重要。对于返回 promises 的处理器，最佳做法是使用 `async`/`await`
    来防止吞没异常。对于返回 stream 的处理器，最佳做法是使用 collect/tap/done 模式来保护数据没有完全通过流流动的场景。
- en: Writing integration tests
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写集成测试
- en: Integration tests focus on testing the API calls between dependent services.
    In our cloud-native systems, these are concentrated on intra-service interactions
    with fully-managed cloud services. They ensure that the interactions are properly
    coded to send and receive proper payloads. These calls require the network, but
    networks are notoriously unreliable. This is the major cause of flaky tests that
    randomly and haphazardly fail. Flaky tests, in turn, are a major cause of poor
    team morale. This recipe demonstrates how to use a VCR library to create test
    doubles that allow integration testing to be executed in isolation without a dependency
    on the network or the deployment of external services.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 集成测试专注于测试依赖服务之间的 API 调用。在我们的云原生系统中，这些集中在与完全托管的云服务之间的服务内交互。它们确保交互被正确编码以发送和接收正确的有效负载。这些调用需要网络，但网络是出了名的不可靠。这是随机和随意失败的测试不稳定的主要原因。不稳定测试反过来又是团队士气低落的主要原因。这个食谱展示了如何使用
    VCR 库来创建测试替身，允许在没有网络依赖或外部服务部署的情况下独立执行集成测试。
- en: Getting ready
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Before starting this recipe, you will need an AWS Kinesis Stream, such as the
    one created in the *Creating an event stream* recipe.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始这个食谱之前，你需要一个 AWS Kinesis Stream，例如在 *创建事件流* 食谱中创建的那个。
- en: How to do it...
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create the project from the following template:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Navigate to the `cncb-integration-testing` directory with `cd cncb-integration-testing`.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cd cncb-integration-testing` 命令导航到 `cncb-integration-testing` 目录。
- en: Install the dependencies with `npm install`.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm install` 安装依赖。
- en: 'Review the file named `package.json` with the following content:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看名为 `package.json` 的文件，其内容如下：
- en: '[PRE12]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Run the unit test with `npm test`.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm test` 运行单元测试。
- en: 'Run the integration tests in `replay` mode, as follows:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以`replay`模式运行集成测试，如下所示：
- en: '[PRE13]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Review the files in the `./fixtures` directory.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查`./fixtures`目录中的文件。
- en: 'Review the files related to the synchronous integration tests, as follows:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查与同步集成测试相关的文件，如下所示：
- en: '[PRE14]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Review the files related to the asynchronous integration tests, as follows:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查与异步集成测试相关的文件，如下所示：
- en: '[PRE15]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Deploy the stack with `npm run dp:stg:e`.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`npm run dp:stg:e`部署堆栈。
- en: 'Delete the `./fixtures` directory and run the integration tests again in `record`
    mode, as follows:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除`./fixtures`目录，并以`record`模式再次运行集成测试，如下所示：
- en: '[PRE16]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: (Optional) Repeat the steps from the *Creating the CI/CD pipeline* recipe with
    this project.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可选）使用此项目重复“创建CI/CD管道”配方中的步骤。
- en: How it works...
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Integration testing uses all of the same tools that are used for unit testing,
    plus some additional tools. This is an advantage in that the learning curve is
    incremental. The first new tool of interest is the `serverless-offline` plugin.
    This plugin reads the `serverless.yml` file and simulates the API Gateway locally
    to facilitate the testing of synchronous APIs. Next, we use `supertest` to make
    HTTP calls to the locally-running service and assert the responses. Inevitably,
    these services make calls to AWS services using the default or specified access
    key. These are the calls that we want to record and playback in the CI/CD pipeline. `baton-vcr-serverless-plugin`
    initializes the `Replay` VCR library in the `serverless-offline` process. By default,
    the VCR runs in `replay` mode and will fail if a recording is not found under
    the fixtures directory. When writing a new test, the developer runs the tests
    in `record` mode by setting the `REPLAY` environment variable, `REPLAY=record
    npm run test:int`. To ensure that a recording is found, we must hold constant
    all dynamically-generated values that are used in the requests; to accomplish
    this, we inject mocks into the webpack configuration. In this example, the `./test/int/mocks.js`
    file uses `sinon` to mock UUID.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 集成测试使用与单元测试相同的工具，并增加了一些额外的工具。这有一个优点，就是学习曲线是逐步增加的。第一个引起兴趣的新工具是`serverless-offline`插件。此插件读取`serverless.yml`文件，并在本地模拟API网关，以方便同步API的测试。接下来，我们使用`supertest`向本地运行的服务发送HTTP请求并断言响应。不可避免的是，这些服务会使用默认或指定的访问密钥调用AWS服务。这些是我们想在CI/CD管道中记录和回放的调用。"baton-vcr-serverless-plugin"在`serverless-offline`过程中初始化`Replay`
    VCR库。默认情况下，VCR以`replay`模式运行，如果固定目录下找不到记录，则会失败。当编写新测试时，开发者通过设置`REPLAY`环境变量以`record`模式运行测试，`REPLAY=record
    npm run test:int`。为了确保找到记录，我们必须保持所有在请求中使用的动态生成的值不变；为此，我们在webpack配置中注入模拟。在这个例子中，`./test/int/mocks.js`文件使用`sinon`来模拟UUID。
- en: Writing integration tests for asynchronous functions, such as `triggers` and
    `listeners`, is mostly similar. First, we need to manually capture the events
    in the log files, such as a DynamoDB Stream event, and include them in test cases.
    Then, we initialize the `baton-vcr-replay-for-aws-sdk` library when the tests
    begin. From here, the process of recording requests is the same. In the case of
    a `trigger` function, it will record a call to publish an event to Kinesis, where
    a `listener` function will typically record calls to the service's tables.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为异步函数，如`triggers`和`listeners`编写集成测试，大部分是相似的。首先，我们需要手动捕获日志文件中的事件，例如DynamoDB流事件，并将它们包含在测试用例中。然后，在测试开始时初始化`baton-vcr-replay-for-aws-sdk`库。从这里开始，记录请求的过程是相同的。对于`trigger`函数，它将记录向Kinesis发布事件的调用，而对于`listener`函数，通常记录对服务表的调用。
- en: When writing integration tests, it is important to keep the test pyramid in
    mind. Integration tests are focused on interactions within the specific API calls;
    they do not need to cover all of the different functional scenarios, as that is
    the job of unit tests. The integration tests just need to focus on the structure
    of the messages to ensure they are compatible with what is expected by and returned
    from the external service. To support the creation of the recordings for these
    tests, the external system may need to be initialized with a specific dataset.
    This initialization should be coded as part of the tests and recorded as well.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写集成测试时，重要的是要记住测试金字塔。集成测试专注于特定API调用内的交互；它们不需要覆盖所有不同的功能场景，因为这是单元测试的工作。集成测试只需要关注消息的结构，以确保它们与外部服务期望和返回的内容兼容。为了支持这些测试的记录创建，外部系统可能需要使用特定的数据集进行初始化。这个初始化应该作为测试的一部分进行编码，并记录下来。
- en: Writing contract tests for a synchronous API
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为同步 API 编写合约测试
- en: Contract testing and integration testing are two sides of the same coin. Integration
    tests ensure that a consumer is calling a provider service correctly, whereas
    contract tests ensure that the provider service continues to meet its obligations
    to its consumers and that any changes are backward-compatible. These tests are
    also consumer driven. This means that the consumer submits a pull request to the
    provider's project to add these additional tests. The provider is not supposed
    to change these tests. If a contract test breaks, it implies that a backwards-incompatible
    change has been made. The provider has to make the change compatible and then
    work with the consumer team to create an upgrade roadmap.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 合约测试和集成测试是同一枚硬币的两面。集成测试确保消费者正确调用提供商服务，而合约测试确保提供商服务继续满足其对消费者的义务，并且任何更改都是向后兼容的。这些测试也是由消费者驱动的。这意味着消费者向提供商的项目提交拉取请求以添加这些额外的测试。提供商不应该更改这些测试。如果合约测试失败，则意味着已经做出了不兼容的更改。提供商必须使更改兼容，然后与消费者团队合作创建升级路线图。
- en: How to do it...
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create the project from the following template:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Navigate to the `bff` directory with `cd cncb-contract-testing-sync/bff`
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cd cncb-contract-testing-sync/bff` 命令导航到 `bff` 目录
- en: Install the dependencies with `npm install`.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm install` 安装依赖项。
- en: Run the unit tests with `npm test`.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm test` 运行单元测试。
- en: Run the integration tests in `replay` mode with `npm run test:int`.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm run test:int` 在 `replay` 模式下运行集成测试。
- en: Review the files in the `./fixtures` directory.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查 `./fixtures` 目录中的文件。
- en: 'Review the file named `./test/int/frontend/contract.test.js` with the following
    content:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查名为 `./test/int/frontend/contract.test.js` 的文件，其内容如下：
- en: '[PRE18]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Review the consumer's `test` and `fixture` files under `./frontend`.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查 `./frontend` 下的消费者的 `test` 和 `fixture` 文件。
- en: (Optional) Repeat the steps from the *Creating the CI/CD pipeline* recipe with
    this project.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可选）使用此项目重复 *创建 CI/CD 管道* 菜单中的步骤。
- en: How it works...
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: When it comes to integration and contract testing, the devil is in the detail.
    Specifically, the detail of the individual fields, their data types, and their
    valid values. It is all too easy for a provider to change a seemingly mundane
    detail that violates a consumer's understanding of the contract. These changes
    then go unnoticed until the worst possible moment. In this regard, handcrafted
    contract tests are unreliable, because the same misunderstanding about the contract
    usually translates into the test as well. Instead, we need to use the same recordings
    on both sides of the interaction.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到集成和合约测试时，魔鬼藏在细节中。具体来说，是各个字段的细节、它们的数据类型以及它们的有效值。提供商改变看似微不足道的细节，可能会违反消费者对合约的理解。这些变化往往直到最糟糕的时刻才被发现。在这方面，手工制作的合约测试是不可靠的，因为关于合约的相同误解通常也会反映在测试中。相反，我们需要在交互的双方使用相同的录音。
- en: The consumer creates an integration test in its project that records the interaction
    with the provider's service. These same recordings are then copied to the provider's
    project and used to drive the contract tests. A consumer-specific `fixtures` subdirectory
    is created for the recordings. The contract tests use the `baton-request-relay`
    library to read the recordings so that they can be used to drive `supertest` to
    execute the same requests in the provider's project.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者在其项目中创建一个集成测试，记录与提供商服务的交互。然后，将这些相同的录音复制到提供商的项目中，并用于驱动合约测试。为录音创建一个针对消费者的特定
    `fixtures` 子目录。合约测试使用 `baton-request-relay` 库读取录音，以便它们可以用来驱动 `supertest` 在提供商的项目中执行相同的请求。
- en: In our cloud-native systems, these synchronous requests are usually between
    a frontend and its **Backend for Frontend** (**BFF**) service, which is owned
    by the same team. The fact that the same team owns the consumer and provider does
    not negate the value of these tests, because even a subtle change, such as changing
    a short integer to a long integer, can have a drastic impact if all the wrong
    assumptions were made on either side.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的云原生系统中，这些同步请求通常是在前端和其 **Backend for Frontend**（**BFF**）服务之间进行的，该服务由同一团队拥有。同一团队拥有消费者和提供商的事实并不否定这些测试的价值，因为即使是细微的变化，例如将短整数更改为长整数，如果任一方做出了所有错误的假设，都可能产生巨大的影响。
- en: Writing contract tests for an asynchronous API
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为异步 API 编写合约测试
- en: The objective of contract testing for asynchronous APIs is to ensure backwards-compatibility
    between the provider and the consumer—just as it is with synchronous APIs. Testing
    asynchronous communication is naturally flaky, as there is the unreliability of
    networks plus the unreliable latency of asynchronous messaging. All too often
    these tests fail because messages are slow to arrive and the tests timeout. To
    solve this problem, we isolate the tests from the messaging system; we record
    the send message request on one end, then relay the message and assert the contract
    on the receiving side.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 异步 API 的合同测试目标是确保提供者和消费者之间的向后兼容性——就像同步 API 一样。测试异步通信自然是不可靠的，因为网络不可靠加上异步消息的不可靠延迟。这些测试经常失败，因为消息到达缓慢，测试超时。为了解决这个问题，我们将测试从消息系统中隔离出来；我们在一端记录发送消息请求，然后中继消息并在接收端断言合同。
- en: How to do it...
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create the upstream and downstream projects from the following templates:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建上游和下游项目：
- en: '[PRE19]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Navigate to the `upstream` directory with `cd cncb-contract-testing-async-upstream`.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cd cncb-contract-testing-async-upstream` 命令导航到 `upstream` 目录。
- en: Install the dependencies with `npm install`.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm install` 安装依赖。
- en: Run the unit test with `npm test`.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm test` 运行单元测试。
- en: Run the integration tests in `replay` mode with `npm run test:int`.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm run test:int` 在 `replay` 模式下运行集成测试。
- en: Review the files in the `./fixtures/downstream-consumer-x` directory.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查 `./fixtures/downstream-consumer-x` 目录中的文件。
- en: 'Review the file named `./test/int/downstream-consumer-x/contract.test.js` with
    the following content:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查名为 `./test/int/downstream-consumer-x/contract.test.js` 的文件，内容如下：
- en: '[PRE20]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Navigate to the `downstream` directory with `cd ../cncb-contract-testing-async-downstream`.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `cd ../cncb-contract-testing-async-downstream` 命令导航到 `downstream` 目录。
- en: Repeat the same steps to run the tests.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复相同的步骤来运行测试。
- en: 'Review the downstream consumer''s `./test/int/upstream-provider-y` and `./fixture/upstream-provider-y`
    files, as follows:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查下游消费者的 `./test/int/upstream-provider-y` 和 `./fixture/upstream-provider-y`
    文件，如下所示：
- en: '[PRE21]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: (Optional) Repeat the steps from the *Creating the CI/CD pipeline* recipe with
    this project.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可选）使用此项目重复 *创建 CI/CD 管道* 配方中的步骤。
- en: How it works...
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The process of recording and creating a contract test for an asynchronous API
    is the inverse of a synchronous API. With a synchronous API, the consumer initiates
    the interaction, whereas with an asynchronous API, the provider initiates the
    publishing of the event. However, asynchronous providers are unaware of their
    consumers, so these tests still need to be consumer-driven.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 记录和为异步 API 创建合同测试的过程与同步 API 的过程相反。对于同步 API，消费者启动交互，而对于异步 API，提供者启动事件的发布。然而，异步提供者不知道他们的消费者，因此这些测试仍然需要由消费者驱动。
- en: First, the consumer project creates a test in the upstream project and records
    the call to publish an event to the event stream. Then, the consumer relays the
    recording in its own project, using the `baton-event-relay` library, to assert
    that the content of the event is as it expects. Once again, the provider project
    does not own these tests and should not fix the test if it breaks due to a backwards-incompatible
    change.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，消费者项目在上游项目中创建一个测试，并记录向事件流发布事件的调用。然后，消费者使用 `baton-event-relay` 库在其自己的项目中中继记录，以断言事件的内容符合预期。再次强调，提供者项目不拥有这些测试，如果由于向后不兼容的更改而测试失败，不应修复测试。
- en: Assembling transitive end-to-end tests
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 组装传递的端到端测试
- en: Traditional end-to-end testing is labor-intensive and expensive. As a result,
    traditional batch sizes are large and end-to-end testing is performed infrequently
    or skipped altogether. This is the exact opposite of our objective with continuous
    deployment. We want small batch sizes and we want full testing on every deployment,
    multiple times per day, which is when we typically hear cries of heresy. This
    recipe demonstrates how this can be achieved with the tools and techniques already
    covered in this chapter.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的端到端测试劳动密集且成本高昂。因此，传统的批量大小很大，端到端测试执行频率低，甚至完全跳过。这与我们持续部署的目标正好相反。我们希望批量大小小，并且希望每次部署都进行全面测试，每天多次，这时我们通常听到异端的呼声。这个配方展示了如何使用本章中已介绍的工具和技术实现这一点。
- en: How to do it...
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create the `author-frontend`, `author-bff`, `customer-bff`, and `customer-frontend`
    projects from the following templates:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建 `author-frontend`、`author-bff`、`customer-bff` 和 `customer-frontend`
    项目：
- en: '[PRE22]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Install the dependencies in each project with `npm install`.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `npm install` 在每个项目中安装依赖。
- en: 'Run the end-to-end tests in `replay` mode for each project, as follows:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下方式在每个项目中以 `replay` 模式运行端到端测试：
- en: '[PRE23]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Review all of the following fixture files:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 审查以下所有固定文件：
- en: '[PRE24]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Review all of the following end-to-end test case files:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 审查以下所有端到端测试用例文件：
- en: '[PRE25]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: How it works...
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Integration testing and contract testing are two sides of the same coin. We
    have already seen how these tests can be implemented with test doubles that replay
    previously recorded request and response pairs. This allows each service to be
    tested in isolation without the need to deploy any other service. A service provider
    team creates integration tests to ensure their service works as they expect, and
    service consumer teams create contract tests to ensure that the provider's service
    works as they expect. We then build on this so that the test engineers from all
    teams work together to define sufficient end-to-end test scenarios to ensure that
    all of the services are working together. For each scenario, we string together
    a series of integration and contract tests across all projects, where the recordings
    from one project are used to drive the tests in the next project, and so forth.
    Borrowing from the transitive property of equality, if Service *A* produces Payload
    1, which works with Service *B* to produce Payload 2, which works with Service
    *C* to produce the expected Payload 3, then we can assert that when Service *A*
    produces Payload 1 then ultimately Service *C* will produce Payload 3.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 集成测试和契约测试是同一枚硬币的两面。我们已经看到了如何使用测试双倍体来实现这些测试，这些测试双倍体重新播放之前记录的请求和响应对。这使得每个服务都可以在无需部署任何其他服务的情况下独立测试。服务提供者团队创建集成测试以确保他们的服务按预期工作，而服务消费者团队创建契约测试以确保提供者的服务按预期工作。然后我们在此基础上构建，使得所有团队中的测试工程师一起工作，定义足够的端到端测试场景以确保所有服务协同工作。对于每个场景，我们在所有项目中串联一系列集成和契约测试，其中来自一个项目的记录用于驱动下一个项目的测试，依此类推。借鉴等价传递性质，如果服务
    *A* 产生有效载荷 1，它与服务 *B* 一起工作产生有效载荷 2，它与服务 *C* 一起工作产生预期的有效载荷 3，那么我们可以断言当服务 *A* 产生有效载荷
    1 时，最终服务 *C* 将产生有效载荷 3。
- en: In this recipe, we have an authoring application and a customer application.
    Each consists of a frontend project and a BFF project. The `author-frontend` project
    made the `save-thing0` recording. This recording was copied to the `author-bff`
    project and ultimately resulted in the `thing0-created` recording. The `thing0-created`
    recording was then copied to the `customer-bff` project and ultimately resulted
    in the `get-thing0` recording. The `get-thing0` recording was then copied to the
    `customer-frontend` project to support its testing.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们有一个作者应用和一个客户应用。每个应用都包含一个前端项目和bff项目。`author-frontend` 项目制作了 `save-thing0`
    记录。这个记录被复制到 `author-bff` 项目，最终产生了 `thing0-created` 记录。然后，`thing0-created` 记录被复制到
    `customer-bff` 项目，最终产生了 `get-thing0` 记录。`get-thing0` 记录随后被复制到 `customer-frontend`
    项目以支持其测试。
- en: The end result is a set of completely autonomous test suites. The test suite
    of a specific service is asserted each time the service is modified, without the
    need to rerun a test suite in each project. Only a backwards-incompatible change
    requires dependent projects to update their test cases and recordings; so, we
    no longer need to maintain an end-to-end testing environment. Database scripts
    are no longer needed to reset databases to a known state, as the data is embodied
    in test cases and recordings. These transitive end-to-end tests form the tip of
    a comprehensive testing pyramid that increases our confidence that we have minimized
    the chance of human error in our continuous deployment pipeline.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 最终结果是完全自主的测试套件集合。每次修改特定服务的测试套件时都会断言该服务的测试套件，无需在每个项目中重新运行测试套件。只有不兼容的更改需要依赖项目更新其测试用例和记录；因此，我们不再需要维护端到端测试环境。不再需要数据库脚本将数据库重置到已知状态，因为数据体现在测试用例和记录中。这些传递性的端到端测试构成了一个全面测试金字塔的尖端，增加了我们对我们持续部署管道中人为错误最小化的信心。
- en: Leveraging feature flags
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用功能标志
- en: The practice of decoupling deployment from release is predicated on the use
    of feature flags. We are continuously deploying small batches of change to mitigate
    the risks of each deployment. These changes are deployed all the way to production,
    so we need a feature flag mechanism to disable these capabilities until we are
    ready to release them and make them generally available. We also need the ability
    to enable these capabilities for a subset of users, such as beta users and internal
    testers. It is also preferable to leverage the natural feature flags of a system,
    such as permissions and preferences, to minimize the technical debt that results
    from littering code with custom feature flags. This recipe will show you how to
    leverage the claims in a JWT token to enable and disable features.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 将部署与发布解耦的实践基于使用功能标志。我们持续部署小批量的变更以减轻每次部署的风险。这些变更一直部署到生产环境，因此我们需要一个功能标志机制来禁用这些功能，直到我们准备好发布它们并使其普遍可用。我们还需要能够为用户子集，如测试用户和内部测试人员，启用这些功能。利用系统的自然功能标志，如权限和偏好，以最小化因在代码中添加自定义功能标志而产生的技术债务也是更好的选择。这个配方将向您展示如何利用JWT令牌中的声明来启用和禁用功能。
- en: Getting ready
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Before starting this recipe, you will need an AWS Cognito user pool, such as
    the one created in the *Creating a federated identity pool* recipe. The user pool
    should have the following two groups defined: `Author` and `BetaUser`.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始这个配方之前，您需要一个AWS Cognito用户池，例如在*创建联合身份池*配方中创建的那个。用户池应该定义以下两个组：`Author`和`BetaUser`。
- en: How to do it...
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create the project from the following template:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从以下模板创建项目：
- en: '[PRE26]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Navigate to the `cncb-feature-flag` directory with `cd cncb-feature-flag`.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`cd cncb-feature-flag`命令导航到`cncb-feature-flag`目录。
- en: 'Review the file named `src/Authorize.js`, as follows:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查名为`src/Authorize.js`的文件，如下所示：
- en: '[PRE27]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Review the file named `src/Home.js`, as follows:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查名为`src/Home.js`的文件，如下所示：
- en: '[PRE28]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Review the file named `src/App.js` and update the `clientId` and `domain` fields
    with the values for the user pool stack.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查名为`src/App.js`的文件，并使用用户池堆栈的值更新`clientId`和`domain`字段。
- en: Install the dependencies with `npm install`.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`npm install`安装依赖项。
- en: Run the app locally with `npm start`.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`npm start`命令在本地运行应用程序。
- en: Click the `Sign Up` link and follow the instructions.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击`Sign Up`链接并遵循指示。
- en: Click the `Sign Out` link and then `Sign Up` another user.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击`Sign Out`链接，然后为另一个用户`Sign Up`。
- en: Assign each user to a different group in the AWS user pool console—one to the
    `Author` group and the other to the `BetaUser` group.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在AWS用户池控制台中为每个用户分配不同的组——一个分配到`Author`组，另一个分配到`BetaUser`组。
- en: '`Sign In` as each user and notice how the screen renders differently for each
    one.'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以每个用户身份`Sign In`，并注意屏幕对每个用户的渲染方式都不同。
- en: How it works...
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: First and foremost, zero-downtime deployment has to be treated as a first-class
    requirement and must be accounted for in the task roadmap and system design. If
    an enhancement is just adding a new optional field on an existing domain entity
    then a feature flag isn't required at all. If a field is just being removed, the
    order of deployment is important, from most dependent to least dependent. If an
    entirely new feature is being added, then access to the whole feature can be restricted.
    The most interesting scenarios are when a significant change is being made to
    an existing and popular feature. If the change is significant then it may be best
    to support two versions of the feature simultaneously, such as two versions of
    a page—in which case the scenario is essentially the same as the entirely new
    feature scenario. If a new version is not warranted, then care should be taken
    not to tie the code in knots.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 首先最重要的是，零停机部署必须被视为一级要求，必须在任务路线图和系统设计中予以考虑。如果增强功能只是在一个现有的域实体上添加一个新可选字段，那么根本不需要功能标志。如果只是删除一个字段，部署的顺序很重要，从最依赖到最不依赖。如果添加了一个全新的功能，则可以限制对整个功能的访问。最有趣的场景是当对现有且流行的功能进行重大修改时。如果变化很大，那么同时支持两个版本的功能可能是最好的选择，比如两个版本的页面——在这种情况下，场景本质上与全新的功能场景相同。如果没有必要添加新版本，那么应该注意不要使代码变得过于复杂。
- en: In this simplified ReactJS example, the JWT token is accessible after sign-in
    through the `auth` property. Instances of the `HasRole` component are configured
    with  `allowedRoles`. The component checks if the JWT token has a matching group
    in the `cognito:groups` field. If a match is found then the `children` components
    are rendered; otherwise, `null` is returned and nothing is rendered.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简化的ReactJS示例中，JWT令牌在登录后通过`auth`属性可访问。`HasRole`组件的实例配置了`allowedRoles`。该组件会检查JWT令牌在`cognito:groups`字段中是否有匹配的组。如果找到匹配项，则渲染`children`组件；否则，返回`null`且不进行渲染。
