- en: Chapter 6. Deploying and Scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Running our application on the local server is fine, but making a web application
    really useful requires deploying it to a public server and making it accessible
    to others. To run our chat server application on Node.js, along with using protocols
    such as WebSocket, requires some special considerations. In this chapter, we will
    take a look at the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Things to consider while deploying our application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommendations for a production-ready deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reason why scaling of socket.io applications is different than other web applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How we can scale our chat application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The production environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first thing we should do before running an application on a production
    server is to set the environment to `production`. Every modern server or framework
    has separate development and production modes and so does node. In fact, in node
    you can set the environment to any name and then have different configurations
    for that name in your code. To set the environment our node server runs in, we
    set an environment variable `NODE_ENV` to the environment we want to run node
    in. So, to run node in the `production` environment, we use the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'And then run your node application. In [Chapter 2](ch02.html "Chapter 2. Getting
    Started with Node.js"), *Getting Started with Node.js*, we saw how the first argument
    in `app.configure` is the environment variable we need to configure for:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In this snippet we are setting the application to activate `express.errorHandler`
    in the `development` environment, which is the default environment. If we have
    set `NODE_ENV` to `production`, `express.errorHandler` will not be used.
  prefs: []
  type: TYPE_NORMAL
- en: Running the application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Running the application on the command line using node, like we have been doing
    until now, works during development; but on a production server where we connect
    remotely, it is generally not feasible or advisable to keep the console running.
    There are two ways to handle this, either we run node as a background process
    redirecting all console output to a file or we run it in a persistent console,
    to which we can reconnect, using `screen` or `byobu`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run node as a background process, like any other process on Linux, we will
    use the `&` operator and to make sure that it keeps running even after we log
    out, we will use `nohup`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command will redirect the `stdout` and `stderr` commands to `npmout.log`
    and will put the npm process in the background.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another option is to run node on a long-lasting console, using utilities such
    as `screen` or `byobu`. To use this, start `screen` and then run your application,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can detach from this screen by using *Ctrl* +*a* and then hitting *d*.
    This will drop us to the default shell. We can then disconnect. When we connect
    back to the server, to see the server output, we can attach back to the screen
    by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Keeping it running
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Not only do we want the application to run when we log out, we want our application
    to keep running reliably. The production servers are not frequently restarted,
    and in general we will like to ensure that they come back up as soon as possible
    when there is a crash, a failure, or an error. For node, generally it means restarting
    the process as soon as it fails. There are many ways to keep the node server running.
    In this section we will see two of them:'
  prefs: []
  type: TYPE_NORMAL
- en: Monit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Forever
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is how Monit is described on its website ([http://mmonit.com/monit/](http://mmonit.com/monit/)):'
  prefs: []
  type: TYPE_NORMAL
- en: Monit is a free open source utility for managing and monitoring processes, programs,
    files, directories, and filesystems on a UNIX system. Monit conducts automatic
    maintenance and repair and can execute meaningful causal actions in error situations.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Let us begin with installing Monit. On RPM-based or Yum-based systems such
    as RHEL, Fedora, or CentOS, you can install it using the `yum` command, as shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Or on a Debian- or apt-get-based system, you can install Monit using `apt-get`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: For other systems, you can check the installation instructions at the Monit
    website.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once Monit is installed, we can configure it to manage our node application.
    For this, we will create a configuration file (in our case we will call it `awesome-chat`)
    in `/etc/monit.d/` or `/etc/monit/conf.d/`, depending on your Monit installation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In this file, you should notice the highlighted section. We are emphasizing
    the program or more importantly, the commands to start/stop our application and
    then finally configuring Monit to restart the application in case of a failure.
    This is detected by sending an HTTP request to fetch the page at port `3000`.
  prefs: []
  type: TYPE_NORMAL
- en: 'That is it; we can start our application with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'And stop it with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: In case of a crash, Monit will take care of restarting the application.
  prefs: []
  type: TYPE_NORMAL
- en: Monit can be used to run and watch any daemon service. It also has a web interface
    in case you want to check the status, which by default runs on port `2812`. You
    can learn more about Monit on its website and in its manual online.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another, more node-specific way to keep our server up and running is **Forever**
    ([https://github.com/nodejitsu/forever](https://github.com/nodejitsu/forever)).
    Forever describes itself as:'
  prefs: []
  type: TYPE_NORMAL
- en: A simple CLI tool for ensuring that a given script runs continuously.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'And that''s what is does. Given your node application script, Forever will
    start it and make sure it keeps running continuously. Since Forever itself is
    a node application, we will use npm to install it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, to start the application with Forever, it is just a matter of executing
    the `app.js` file with `forever`. Just run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see the list of applications running forever with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'To stop the application, use the `forever stop` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Visit Forever's github page for understanding more about Forever and its workings.
  prefs: []
  type: TYPE_NORMAL
- en: There are several other tools on *nix systems to make node run as a daemon.
    Few of them are as follows
  prefs: []
  type: TYPE_NORMAL
- en: '[http://upstart.ubuntu.com/](http://upstart.ubuntu.com/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supervisord ([http://supervisord.org/](http://supervisord.org/))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Daemontools ([http://cr.yp.to/daemontools.html](http://cr.yp.to/daemontools.html))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have made sure that our application will keep running and also
    will restart from failures, it''s time we start looking at ways to handle millions
    of users flocking to our chat room. To begin with this, the first step is to put
    up a load-balancer proxy in front of our server. There are lots of options in
    this, we can use the Apache HTTP server, Nginx, and so on. All these servers work
    very well with balancing traditional HTTP traffic, but still have some time to
    catch up to work with WebSockets. So we will use a server that works on load-balancing
    TCP/IP itself. This is **HAProxy** ([http://haproxy.1wt.eu/](http://haproxy.1wt.eu/)).
    This is how HAProxy is described in its official website:'
  prefs: []
  type: TYPE_NORMAL
- en: HAProxy is a free, very fast and reliable solution offering high availability,
    load balancing, and proxying for TCP and HTTP-based applications. It is particularly
    suited for web sites crawling under very high loads while needing persistence
    or Layer7 processing. Supporting tens of thousands of connections is clearly realistic
    with today's hardware.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'HAProxy works with frontends and backends. These are configured using the HAProxy
    configuration file present at `/etc/haproxy/haproxy.cfg`. The following file creates
    a frontend listener at port `80` and forwards it to a single server at `3000`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In this file, we are defining a frontend listener at `0.0.0.0:80` with the default
    `www_Node.js` backend listening at `3000` on the same `127.0.0.1` server.
  prefs: []
  type: TYPE_NORMAL
- en: 'But this configuration is not ready to handle WebSockets. To support and handle
    WebSockets, refer to the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The first thing we did was to increase the client timeout value, so the client
    connection doesn't drop off if there is a long inactivity from the client. The
    `acl` lines of code instruct HAProxy to understand and check when we get a `websocket`
    request.
  prefs: []
  type: TYPE_NORMAL
- en: By using the `use_backend` instruction, we configure HAProxy to use the `www_Node.js`
    backend to handle the `websocket` request. This is useful when you want to serve
    your static pages from any server, such as Apache HTTP, and want to use node exclusively
    to handle socket.io.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we come to the part where we would like the request to be handled by more
    than one node server/process. To do this, first we will tell the proxy to round
    robin the requests by adding the following instruction to the backend:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we will add more server entries to the backend:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we are adding two new node instances: one is a new process listening on
    port `4000` on the same server, while the other one is running on another server,
    which is accessible to the load-balancer at `192.168.1.101` on port `3000`.'
  prefs: []
  type: TYPE_NORMAL
- en: We are done configuring the servers and the incoming requests will now be routed
    between the three node instances that we have configured.
  prefs: []
  type: TYPE_NORMAL
- en: The node cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Node now comes with its own completely rewritten cluster module. Cluster allows
    node to start multiple processes behind the cluster frontend and monitors and
    manages them. We will take a quick look at how to make an application cluster
    with this module, but note that this is only for creating multiple processes and
    we must still set up a tool to monitor the cluster master and also a proxy to
    forward requests to the node server.
  prefs: []
  type: TYPE_NORMAL
- en: Let us see how we can use the cluster module. The best part about the cluster
    module is you don't need to actually change your application. Cluster will run
    a master instance, and we can start multiple instances of our application and
    they will all listen to a shared port.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the script that we can use for clustering the `app.js` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: So, what's happening here? The first thing we do is use `require` on the `cluster`
    module. In the next line, we are checking whether the instance that is started
    is the master process or the worker.
  prefs: []
  type: TYPE_NORMAL
- en: 'If it is the master process, we check if the `NODE_WORKERS` environment variable
    is set, else we get the number of processors available on the system our server
    is running on. To set the `NODE_WORKERS` environment variable, you can run the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The previous command will tell the cluster to start two nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Now, in the loop, we call `fork` on the cluster. This calls `child_process.fork`
    so that the master and the started workers can communicate via IPC.
  prefs: []
  type: TYPE_NORMAL
- en: When the cluster process is run from `fork`, `cluster.isMaster` is false and
    so our `app.js` script is in the current worker process.
  prefs: []
  type: TYPE_NORMAL
- en: In our application, when we call `server.listen(3000)`, the worker serializes
    this and sends over the request to the server, the server checks if it already
    is listening on that port, and returns the handle for the listener, if it is present.
    Else, the server starts listening on the port and passes on the handle to the
    newly created listener.
  prefs: []
  type: TYPE_NORMAL
- en: Since all our workers request to listen on port `3000`, the server will start
    listening on the port when the first worker starts and will pass on the same handler
    to all the workers. When a request comes in, it will be handled by any worker
    that can take it up and process it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since our monitoring tool (Monit or Forever, or others) will now be monitoring
    only the master process, it becomes the master''s responsibility to monitor the
    workers. This means that the cluster should restart any worker that happens to
    die. We will do this, by adding the following event handler in the master process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Monitoring of the process is done by listening to the `exit` event on the socket.
    This is the event that will be triggered when any worker dies. The event handler
    will get the worker, its exit code, and the signal that caused the process to
    be killed. In the handler, we log the death and we start a new worker process
    using `cluster.fork()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can start the new clustered application; we''ll run `cluster.js` instead
    of `app.js`. So change the `start` script in `package.json` to run `cluster.js`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: And then run the application with npm.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This will start the application and everything will look just as it was. But
    when you start using it, you'll notice that there are errors while trying to connect
    to a room, or while sending messages. These errors are because we are using an
    in-memory store for our Express.js sessions and socket.io uses an in-memory store
    to store and transfer all the messages.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling up the application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section we saw how we can cluster a Node.js app and how it remains
    restricted due to our application mechanisms. In its current state, the application
    uses an in-memory store to keep the session data. This store is local to the Node.js
    instance and so won't be accessible in any another clustered instance. Also, the
    data will be lost in a Node.js instance restart. So, what we need is a way to
    store the session in a persistent store. Also, we want to configure socket.io
    such that all its instances use a shared pub-sub and data store. The Connect framework
    has an extension mechanism so a new store can be plugged in, and there is one
    store that is persistent as well as excels at pub-sub. It is the **Redis** **Session
    Store**.
  prefs: []
  type: TYPE_NORMAL
- en: Redis ([http://redis.io/](http://redis.io/)) is a high performance, distributed,
    open source key-value store that can also be used as a queue. We will use Redis
    and corresponding Redis stores to provide a reliable, distributed, and shared
    store and pub-sub queue. Please check out the instructions to install the Redis
    server on your operating system and start it up.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s make a few changes to our chat application, beginning with `package.json`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This will add support for the Connect/Express.js Redis store and the Redis
    connection client. Let''s first get Express.js to use Redis; to do so, edit `app.js`
    by referring to the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: So the two changes we make here are pulling in the Redis session store and then
    we can replace the session store to be an instance of `RedisStore`. That's all
    that is needed to get Express running using the Redis store.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next thing we need to do is get socket.io using Redis. So, let us edit
    `socket.js`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The first thing in the preceding code snippet that we are doing is `require
    (''redis'')`, which provides the client and `redisStore` from socket.io, which
    provides redis backed for socket.io. Then we create three different Redis clients
    to use for pub-sub and the data store:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'In the previous code snippet, we configure socket.io to use Redis for the queue
    and data store. And we are ready to go! Now run the application again using the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Tips for node in production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some tips to help us execute node in production:'
  prefs: []
  type: TYPE_NORMAL
- en: Run the server in the `production` environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Never expose the node application directly on the Internet; always use a proxy.
    Servers such as Apache HTTP, Nginx, and HAProxy have been hardened and made robust
    over the years in production to make them secure against various kinds of attacks,
    especially DOS and DDOS. Node is new; it may become stable over time but today
    it is not recommended to be put directly on the front.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Never run node as root. Well, that is the advice for any application server,
    and it applies to node too. If we run node as root, there are chances of hackers
    gaining root access or running some harmful code as root. So, never ever run it
    as root!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Always run more than one node process. Node is a single-threaded, single-process
    application server. An error in the application can bring the server down. So,
    always have more than one process for reliability. Also, thinking in terms of
    1+ processes keeps us ready for scaling out when the need comes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Always use a monitor. Monit, Forever, Upstart pick one you like, but always
    use it. Better safe than sorry.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Never use `MemoryStore` in `production`; `MemoryStore` is for the `development`
    environment; I recommend using `RedisStore` even in `development`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log all errors. Everything runs fine until it doesn't! And when something goes
    wrong, logs are your best friend. Try to catch exceptions as close to the cause
    as possible and log all the relevant information in the context. Don't just log
    some error message, log all the relevant objects.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Never block unless there is no alternative. Node runs on an event loop, and
    blocking for one request will cause unwanted overheads and degrade performance
    for all requests.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Always keep your server, node, and all dependency modules up-to-date.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we saw the work involved in putting our application to production.
    We must remember that these are not the only ways to do it. For every task we
    did, there are many other ways of doing them, and there is no one solution that
    fits all scenarios. But now that we know what is expected out of a `production`
    environment, we can research the options and choose one according to our requirements.
  prefs: []
  type: TYPE_NORMAL
