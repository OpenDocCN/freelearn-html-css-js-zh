- en: 2 Big O notation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Before you begin: Join our book community on Discord**'
  prefs: []
  type: TYPE_NORMAL
- en: Give your feedback straight to the author himself and chat to other early readers
    on our Discord server (find the "learning-javascript-dsa-4e" channel under EARLY
    ACCESS SUBSCRIPTION).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/file0.png)'
  prefs: []
  type: TYPE_IMG
- en: '[https://packt.link/EarlyAccess/](https://packt.link/EarlyAccess/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will unlock the power of **Big O notation**, a fundamental
    tool for analyzing the efficiency of algorithms in terms of both **time complexity**
    (how runtime scales with input size) and **space complexity** (how memory usage
    scales). We will explore common time complexities like *O(1)*, *O(log n)*, *O(n)*,
    and others, along with their real-world implications for choosing the right algorithms
    and optimizing code. Understanding Big O notation is not only essential for writing
    scalable and performant software but also for acing technical interviews, as it
    demonstrates your ability to think critically about algorithmic efficiency. In
    this chapter we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Big O time complexities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Space complexity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculating the complexity of an algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Big O notation and tech interviews
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding Big O notation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Big O notation is used to describe and classify the performance or complexity
    of an algorithm according to how much time it will take for the algorithm to run
    as the input size grows.
  prefs: []
  type: TYPE_NORMAL
- en: And how do we measure the efficiency of an algorithm? We usually use resources
    such as CPU (time) usage, memory usage, disk usage, and network usage. When talking
    about Big O notation, we usually consider CPU (time) usage.
  prefs: []
  type: TYPE_NORMAL
- en: In simpler terms, this notation is a way to describe how the running time of
    an algorithm grows as the size of the input gets bigger. While the actual time
    an algorithm takes to run can vary depending on factors like processor speed and
    available resources, Big O notation allows us to focus on the fundamental steps
    an algorithm must take. Think of it as measuring the number of operations an algorithm
    performs relative to the input size.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you have a stack of papers on your desk. If you need to find a specific
    document, you will have to search through each paper one by one until you locate
    it. With a small stack of 10 papers, this would not take long. But if you had
    20 papers, the search would likely take twice as long, and with 100 papers, it
    could take ten times as long!
  prefs: []
  type: TYPE_NORMAL
- en: The tasks that a developer must perform daily include choosing what data structure
    and algorithms to use to resolve a specific problem. It can be an existing algorithm,
    or you may have to write your own logic to resolve a business user story. It is
    important to note that any algorithm can work fine and seem okay for a low volume
    of data, however, then the volume of the input data increases, an inefficient
    algorithm will grind to halt and impact the application. Knowing how to measure
    performance is key to achieving these tasks successfully.
  prefs: []
  type: TYPE_NORMAL
- en: Big O notation is important because it helps us compare different algorithms
    and choose the most efficient one for a particular task. For instance, if you
    are searching for a specific product in a large online store, you would not want
    to use an algorithm that requires looking at every single product. Instead, you
    would use a more efficient algorithm that only needs to look at a small subset
    of products.
  prefs: []
  type: TYPE_NORMAL
- en: Big O time complexities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Big O notation uses capital *O* to denote upper bound. It signifies that the
    actual running time could be less than but not greater than what the function
    expresses. It does not tell us the exact running time of an algorithm. Instead,
    it tells us how bad things could get as the input size grows large.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you have a messy room and need to find a specific sock. In the worst
    case, you have to check each item of clothing one by one (this is like a linear
    time algorithm). Big O tells you that even if your room gets super messy, you
    will not need to look at more items than are actually there. You might get lucky
    and find the sock quickly! The actual time might be much less than the Big O prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'When analyzing algorithms, the following classifications of time and space
    complexities are most encountered:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Notation** | **Name** | **Explanation** |'
  prefs: []
  type: TYPE_TB
- en: '| O(1) | Constant | The algorithm''s runtime or space usage remains the same
    regardless of the input size (n). |'
  prefs: []
  type: TYPE_TB
- en: '| O(log(n)) | Logarithmic | The algorithm''s runtime or space usage grows logarithmically
    with the input size (n). This means that as the input size doubles, the number
    of operations or memory usage increases by a constant amount. |'
  prefs: []
  type: TYPE_TB
- en: '| O(n) | Linear | The algorithm''s runtime or space usage grows linearly with
    the input size (n). This means that as the input size doubles, the number of operations
    or memory usage also doubles. |'
  prefs: []
  type: TYPE_TB
- en: '| O(n ² ) | Quadratic | The algorithm''s runtime or space usage grows quadratically
    with the input size (n). This means that as the input size doubles, the number
    of operations or memory usage quadruples. |'
  prefs: []
  type: TYPE_TB
- en: '| O(n ^c ) | Polynomial | The algorithm''s runtime or space usage grows as
    a polynomial function of the input size (n). This means that as the input size
    doubles, the number of operations or memory usage increases by a factor (c) that
    is a polynomial function of the input size. |'
  prefs: []
  type: TYPE_TB
- en: '| O(c ^n ) | Exponential | The algorithm''s runtime or space usage grows exponentially
    with the input size (n). This means that as the input size increases, the number
    of operations or memory usage grows at an increasingly rapid rate. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2.1: Big O notation classifications of time and space complexities'
  prefs: []
  type: TYPE_NORMAL
- en: Let's review each one to understand time complexities in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'O(1): constant time'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*O(1)* signifies that an algorithm''s runtime (or sometimes space complexity)
    remains constant, regardless of the size of the input data. Whether we are dealing
    with a small input or a massive one, the time it takes to execute the algorithm
    does not change significantly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, suppose we would like to calculate the number of seconds of a
    given number of days. We could create the following function to resolve this request:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Each minute has 60 seconds, each hour has 60 minutes, and each day has 24 hours.
  prefs: []
  type: TYPE_NORMAL
- en: 'And we can use `console.log` to see the output of the results passing different
    numbers of days:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: If we call this function passing `1` as argument (`secondsinDays(1)`), it will
    take a few milliseconds for this code to output the results. If we execute the
    function again passing `10` as argument (`secondsinDays(10)`), it will also take
    a few milliseconds for the code to output the results.
  prefs: []
  type: TYPE_NORMAL
- en: This `secondsInDays` function has a time complexity of *O(1)* – constant time.
    The number of operations it performs (multiplication) is fixed and doesn't change
    with the input `numberOfDays`. It will take the same amount of time to calculate
    the result, whether you input 1 day or 1000 days.
  prefs: []
  type: TYPE_NORMAL
- en: '*O(1)* algorithms typically do not involve loops that iterate over the data
    or recursive calls that multiply operations. They often involve direct access
    to data, like looking up a value in an array by its index or performing a simple
    calculation. And while *O(1)* algorithms are incredibly efficient, they are not
    always applicable to every problem. Some tasks inherently require processing each
    item in the input, leading to different time complexities.'''
  prefs: []
  type: TYPE_NORMAL
- en: 'O(log(n)): logarithmic time'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An *O(log n)* algorithm's runtime (or sometimes space complexity) grows logarithmically
    with the input size (*n*). This means that each step of the algorithm significantly
    reduces the problem size, often by dividing it in half or a similar fraction.
    The larger the input size, the smaller the impact each additional element has
    on the overall runtime. In other words, as the input size doubles, the runtime
    increases by a constant amount (for example, only one more step).
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you are playing a "*guess the number*" game. You start with a range
    of 1 to 64, and with each guess, you cut the possible numbers in half. Let's say
    your first guess is 30\. If it is too high, you now know the number is somewhere
    between 1 and 29\. You have effectively halved the search space! Next, you guess
    10 (too low), narrowing the range further to 11 through 29\. Your third guess,
    20, happens to be correct!
  prefs: []
  type: TYPE_NORMAL
- en: Even if you had started with a much larger range of numbers (like 1 to 1000
    or even 1 to 1 million), this halving strategy would still allow you to find the
    number in a surprisingly small number of guesses – around 7 for 1 to 64, 10 for
    1 to 1000, and 20 for 1 to 1 million. This demonstrates the power of logarithmic
    growth.'
  prefs: []
  type: TYPE_NORMAL
- en: We can say this approach has a time complexity of *O(log(n))*. With each step,
    the algorithm eliminates a significant portion of the input, making the remaining
    work much smaller.
  prefs: []
  type: TYPE_NORMAL
- en: A function that has a time complexity of *O(log(n))* typically halves the problem
    size with each step. This complexity is often related to divide and conquer algorithms,
    which we will cover in *Chapter 18, Algorithm Designs and Techniques*.
  prefs: []
  type: TYPE_NORMAL
- en: Logarithmic algorithms are incredibly efficient, especially for large datasets.
    They are often used in scenarios where you need to quickly search or manipulate
    sorted data, which we will also cover later in this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'O(n): linear time'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*O(n)* signifies that an algorithm''s runtime (or sometimes space complexity)
    grows linearly and proportionally with the input size (*n*). If we double the
    size of the input data, the algorithm will take approximately twice as long to
    run. If we triple the input, it will take about three times as long, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine you have an array of monthly expenses and want to calculate the total
    amount spent. Here is how we could do it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The for loop iterates through each element (`monthlyExpense`) in the array adding
    it to the `total` variable, which is then returned with the amount of the total
    expenses.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the following code to check the output of this function, passing
    different parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The number of iterations (and additions to the `total`) directly depends on
    the size of the array (`monthlyExpenses.length`). If the array has 12 months of
    expenses, the loop runs 12 times. If it has 24 months, the loop runs 24 times.
    The runtime increases proportionally to the number of elements in the array.
  prefs: []
  type: TYPE_NORMAL
- en: This is because the function contains a loop that runs *n* times. Therefore,
    the time it takes to run this function grows in proportion to the size of the
    input *n*. If *n* doubles, the time to run the function approximately doubles
    as well. For this reason, we can say the preceding function has a complexity of *O(n)*,
    where in this context, *n* is the input size.
  prefs: []
  type: TYPE_NORMAL
- en: While *O(n)* algorithms are not as fast as constant time (*O(1)*) algorithms,
    they are still considered efficient for many tasks. There are many situations
    where you need to process every element of the input, making linear time a reasonable
    expectation.
  prefs: []
  type: TYPE_NORMAL
- en: 'O(nˆ2): quadratic time'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*O(n²)* signifies that an algorithm''s runtime (or sometimes space complexity)
    grows quadratically with the input size (*n*). This means that as the input size
    doubles, the runtime roughly quadruples. If you triple the input, the runtime
    increases by a factor of nine, and so on. *O(n²)* algorithms often involve nested
    loops, where the inner loop iterates *n* times for each iteration of the outer
    loop. This results in approximately *n * n* (or *n²*) operations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go back to the calculation of expenses example. Suppose you have the
    following data in a spreadsheet, with each expense by month:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Month/Expense** | **January** | **February** | **March** | **April** |
    **May** | **June** |'
  prefs: []
  type: TYPE_TB
- en: '| Water Utility | 100 | 105 | 100 | 115 | 120 | 135 |'
  prefs: []
  type: TYPE_TB
- en: '| Power Utility | 180 | 185 | 185 | 185 | 200 | 210 |'
  prefs: []
  type: TYPE_TB
- en: '| Trash Fees | 30 | 30 | 30 | 30 | 30 | 30 |'
  prefs: []
  type: TYPE_TB
- en: '| Rent/Mortgage | 2000 | 2000 | 2000 | 2000 | 2000 | 2000 |'
  prefs: []
  type: TYPE_TB
- en: '| Groceries | 600 | 620 | 610 | 600 | 620 | 600 |'
  prefs: []
  type: TYPE_TB
- en: '| Hobbies | 150 | 100 | 130 | 200 | 150 | 100 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2.2: Example of monthly expenses'
  prefs: []
  type: TYPE_NORMAL
- en: 'What if we want to write a function that calculates the total expenses for
    several months? The code for this function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The function has two nested loops:'
  prefs: []
  type: TYPE_NORMAL
- en: The outer loop (`i`) iterates over the rows of the matrix (categories or types
    of expenses within each month).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The inner loop (`j`) iterates over the columns of the matrix (each month) for
    each row.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Inside the nested loop we simply add the expense to the `total`, which is then
    returned at the end of the function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s test this function with the data we previous represented:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We can say the preceding function has a complexity of *O(nˆ2)*. This is because
    the function contains two nested loops. The outer loop will run 6 times (*n*)
    and the inner loop will also run 6 times as we have 6 months (*m*). We can say
    the total number of operations is *n * m*. If *n* and *m* are similar numbers,
    we can say *n * n*, hence *nˆ2*.
  prefs: []
  type: TYPE_NORMAL
- en: In Big O notation, we simplify this to the highest order of magnitude, which
    is *nˆ2*. This means the time complexity of the function grows quadratically (input
    size squared) with the input size. So, If you have a 12x12 matrix (12 categories
    of expenses with 12 months each), the inner loop runs 12 times for each of the
    12 months, resulting in 144 operations. If we expand the list of expenses and
    also the number of months, with a matrix 24x24, the number of operations becomes
    576 (24 * 24). This is characteristic of an algorithm with *O(nˆ2)* time complexity.
  prefs: []
  type: TYPE_NORMAL
- en: 'O(2^n): exponential time complexity'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*O(2^n)* signifies that an algorithm''s runtime (or sometimes space complexity)
    doubles with each additional unit of input size (*n*). If you add just one more
    element to the input, the algorithm takes approximately twice as long. If you
    add two more elements, it takes about four times as long, and so on. The runtime
    increases exponentially. An algorithm with exponential time complexity does not
    have satisfactory performance.'
  prefs: []
  type: TYPE_NORMAL
- en: A classic example of an algorithm that is *O(2ˆn)* is when we have brute force
    that will try all possible combinations of a set of values.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine we want to know how many unique combinations we can have with ice cream
    toppings or no toppings at all. The available toppings are chocolate sauce, maraschino
    cherries and rainbow sprinkles.
  prefs: []
  type: TYPE_NORMAL
- en: What are the possible combinations?
  prefs: []
  type: TYPE_NORMAL
- en: 'Since each topping can be either present or absent, and we have three different
    toppings, the total number of possible combinations is: 2 * 2 * 2 = 2^3 = 8.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a list of the following combinations:'
  prefs: []
  type: TYPE_NORMAL
- en: No toppings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chocolate sauce only
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maraschino cherries only
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rainbow sprinkles only
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chocolate sauce + maraschino cherries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chocolate sauce + rainbow sprinkles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maraschino cherries + rainbow sprinkles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chocolate sauce + maraschino cherries + rainbow sprinkles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we had 10 toppings to choose from, we would have 2 ^ 10 possible combinations,
    totaling 1024 different combinations.
  prefs: []
  type: TYPE_NORMAL
- en: Another example of exponential complexity algorithm is the brute force attack
    to break passwords or PINs. If we have a 4-digit (0-9) code PIN, we have a total
    of 10ˆ4 combinations, totaling 10000 combinations. If we have passwords using
    letters only, we will have a total of 26ˆn combinations, where n is the number
    of letters in the password. If we allow uppercase and lowercase characters in
    the password, we have a total of 62ˆn combinations. This is one of the reasons
    it is important to always create long passwords with letters (both uppercase and
    lowercase), numbers and especial characters, as the number of possible combinations
    grow exponentially, making it more difficult to break the password by using brute
    force.
  prefs: []
  type: TYPE_NORMAL
- en: Exponential algorithms are generally considered impractical for large inputs
    due to their incredibly rapid growth in runtime. They can quickly become infeasible
    even for moderately sized datasets. It is crucial to find more efficient algorithms
    whenever possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'O(n!): factorial time'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*O(n!)* signifies an algorithm''s runtime (or sometimes space complexity) grows
    incredibly rapidly with the input size (*n*). This growth is even faster than
    exponential time complexity. An algorithm with factorial time complexity has one
    of the worst performances.'
  prefs: []
  type: TYPE_NORMAL
- en: The factorial of a number *n* (denoted as *n!*) is calculated as *n * (n-1)
    * (n-2) , …, * 1*. For example, 4! is 4 * 3 * 2 * 1 = 24 .1 As we can see, factorials
    get very large very quickly
  prefs: []
  type: TYPE_NORMAL
- en: 'A classic example of an algorithm that is *O(n!)* is when we try to find all
    possible permutations of a set, for example, the letters ABCD as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ABCD | BACD | CABD | DABC |'
  prefs: []
  type: TYPE_TB
- en: '| ABDC | BADC | CADB | DACB |'
  prefs: []
  type: TYPE_TB
- en: '| ACBD | BCAD | CBAD | DBAC |'
  prefs: []
  type: TYPE_TB
- en: '| ACDB | BCDA | CBDA | DBCA |'
  prefs: []
  type: TYPE_TB
- en: '| ADBC | BDAC | CDAB | DCAB |'
  prefs: []
  type: TYPE_TB
- en: '| ADCB | BDCA | CDBA | DCBA |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2.3: All permutations of letters ABCD'
  prefs: []
  type: TYPE_NORMAL
- en: 'Algorithms with factorial time complexity are generally considered highly inefficient
    and should be avoided whenever possible. For many problems that initially seem
    to require *O(n!)* solutions, there are often cleverer algorithms with much better
    time complexities (for example: dynamic programming technique).'
  prefs: []
  type: TYPE_NORMAL
- en: We will cover algorithms with exponential and factorial times in *Chapter 18,
    Algorithm Designs and Techniques*.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Comparing complexities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can create a table with some values to exemplify the cost of the algorithm
    based on its time complexity and input size, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Input Size (n)** | **O(1)** | **O(log (n))** | **O(n)** | **O(n log(n))**
    | **O(nˆ2)** | **O(2ˆn)** | **O(n!)** |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 1 | 1 | 10 | 10 | 100 | 1024 | 3628800 |'
  prefs: []
  type: TYPE_TB
- en: '| 20 | 1 | 1.30 | 20 | 26.02 | 400 | 1048576 | 2.4329E+18 |'
  prefs: []
  type: TYPE_TB
- en: '| 50 | 1 | 1.69 | 50 | 84.94 | 2500 | 1.1259E+15 | 3.04141E+64 |'
  prefs: []
  type: TYPE_TB
- en: '| 100 | 1 | 2 | 100 | 200 | 10000 | 1.26765E+30 | 9.33262E+157 |'
  prefs: []
  type: TYPE_TB
- en: '| 500 | 1 | 2.69 | 500 | 1349.48 | 250000 | 3.27339E+150 | Very big number
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1000 | 1 | 3 | 1000 | 3000 | 1000000 | 1.07151E+301 | Very big number |'
  prefs: []
  type: TYPE_TB
- en: '| 10000 | 1 | 4 | 10000 | 40000 | 100000000 | Very big number | Very big number
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2.4: Comparing Big O time complexity based on input size'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can draw a chart based on the information presented in the preceding table
    to display the cost of different Big O notation complexities as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1 – Big O Notation complexity chart](img/file7.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – Big O Notation complexity chart
  prefs: []
  type: TYPE_NORMAL
- en: The preceding chart was also plotted using JavaScript. You can find its source
    code in the `src/02-bigOnotation` directory of the source code bundle.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'When we plot the runtime of algorithms with different time complexities against
    the input size on a graph, distinct patterns emerge:'
  prefs: []
  type: TYPE_NORMAL
- en: '***O(1) - Constant Time***: a horizontal line. The runtime remains the same
    regardless of the input size.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***O(log n) - Logarithmic Time***: a gently rising curve that gradually flattens
    as the input size increases. Think of it as a slope that gets less and less steep.
    Each additional input element has a diminishing impact on the overall runtime.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***O(n) - Linear Time***: a straight line with a positive slope. The runtime
    increases proportionally with the input size. Double the input, and the runtime
    roughly doubles.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***O(n²) - Quadratic Time***: a curve that starts shallow but becomes increasingly
    steep. The runtime grows much faster than the input size. Double the input, and
    the runtime roughly quadruples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***O(2^n) - Exponential Time***: a curve that initially seems flat but then
    explodes upwards as the input size increases even slightly. The runtime grows
    incredibly rapidly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***O(n!) - Factorial Time***: a curve that rises almost vertically. The runtime
    becomes astronomically large even for relatively small inputs, quickly becoming
    impractical to compute.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These visualizations are invaluable tools for understanding the long-term behavior
    of algorithms as the input size grows. They help us make informed choices about
    which algorithms are best suited for different scenarios, especially when dealing
    with large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Space complexity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Space complexity refers to the amount of memory (or space) an algorithm uses
    to solve a problem. It is a measure of how much additional storage the algorithm
    requires beyond the space occupied by the input data itself.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to understand space complexity as real-world computers have
    finite memory. If the algorithm's space complexity is too high, it might run out
    of memory on large datasets. And even if we have plenty of memory, an algorithm
    with a high space complexity can still be slower due to factors like increased
    memory access times and cache issues. Also, it is all about tradeoffs. Sometimes,
    we might choose an algorithm with a slightly higher space complexity if it offers
    a significant improvement in time complexity. This of course, needs to be reviewed
    case by case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Big O notation works for space complexity just like it does for time complexity.
    It expresses the upper bound of how the algorithm''s memory usage grows as the
    input size increases. Let''s review the common Big O space complexities:'
  prefs: []
  type: TYPE_NORMAL
- en: '***O(1) - Constant Space*:** the algorithm uses a fixed amount of memory, regardless
    of the input size. This is ideal, as the memory usage will not become a bottleneck.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example: swapping two variables.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '***O(n) - Linear Space*:** the algorithm''s memory usage grows linearly with
    the input size. If we double the input, the memory usage roughly doubles.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example: storing a copy of an input array.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '***O(log n) - Logarithmic Space*:** the algorithm''s memory usage grows logarithmically.
    This is relatively efficient, especially for large datasets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example: certain recursive algorithms where the depth of recursion is logarithmic.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '***O(nˆ2) - Quadratic Space*:** the algorithm''s memory usage grows quadratically.
    This can become a problem for large inputs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example: storing a multiplication table in a 2D array.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '***O(2^n) - Exponential Space*:** like the exponential time complexity, this
    indicates extremely rapid growth in memory usage. It is generally not practical
    and should be avoided.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculating the complexity of an algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is also important to understand how to read algorithmic code and identify
    its complexity in terms of Big O notation. By analyzing the complexity of an algorithm,
    we can identify potential bottlenecks and focus on improving that specific area.
  prefs: []
  type: TYPE_NORMAL
- en: 'To determine the cost of a code in terms of ***time complexity***, we need
    to review it step by step, and focus on the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: Basic operations such as assignments, bits and math operations, which will usually
    have constant time (*O(1)*).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logarithmic algorithms (*O(log (n))*) typically follow a divide-and-conquer
    strategy. They break the problem into smaller subproblems and solve them recursively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Loops: the number of times a loop runs directly impacts time complexity. Nested
    loops multiply their effects. So, if we have one loop iterating through the input
    of size *n*, it will be linear time (*O(n)*), two nested loops (*O(nˆ2)*), and
    so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Recursions: recursive functions call themselves, potentially leading to exponential
    time complexity if not carefully designed. We will cover recursion in *Chapter
    9, Recursion*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Function calls: consider the time complexity of any functions that are called
    within your code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And to determine the cost of a code in terms of **space complexity**, we need
    to review it step by step, and focus on the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Variables: how much memory do variables used in the algorithm consume? Does
    the number of variables grow with the input size?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data structures: what data structures are being used (arrays, lists, trees,
    etc.)? How does their size scale with the input?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Function calls: if the algorithm uses recursion, how many recursive calls are
    made? Each call adds to the space complexity of the call stack.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Allocations: are we dynamically allocating memory within the algorithm? How
    much memory is allocated, and how does it relate to the input size?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s see an example of a function that logs the multiplication table of a
    given number:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s break down the time and space complexity of the `multiplicationTable`
    function using Big O notation. First, let''s focus on time complexity:'
  prefs: []
  type: TYPE_NORMAL
- en: '***O(1) operations***:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assigning variables (`let s = ''` and `let numberOfAsterisks = num * x`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Printing fixed strings (`console.log('Calculating the time complexity of a function')`)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '***O(n) operations***:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Building the asterisk string: the loop iterates *num * x* times, and each iteration
    involves string concatenation, which can be a linear operation depending on the
    JavaScript implementation.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Printing the asterisk string: outputting a string of length *num * x* takes
    time proportional to its length.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '***O(nˆ2) operations***:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nested loops: the outer loop runs num times, and for each iteration, the inner
    loop runs *x* times. This leads to roughly *num * x* (or *nˆ2*) iterations of
    the innermost `console.log` statement, where the actual multiplication takes place.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: While there are *O(1)* and *O(n)* operations in the function, the dominant factor
    in the time complexity is the nested loop structure, which leads to quadratic
    time complexity *O(n^2)*. In Big O notation, we simplify this to the highest order
    of magnitude, which is *n^2*. Therefore, the overall time complexity of the function
    is *O(n^2)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s review the space complexity:'
  prefs: []
  type: TYPE_NORMAL
- en: '***O(1) space***:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple variables (`s`, `numberOfAsterisks`, loop counters `i` and `j`) use a
    fixed amount of memory, regardless of the input values `num` and `x`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '***O(n) space*** (*potential*):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The string `s` could potentially grow to a size of *num * x*, meaning its space
    usage is linear in the input size. However, in most implementations, string concatenation
    is optimized, so this might not be a major concern unless the input values are
    very large.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: So, overall, the space complexity could be considered *O(n)* due to the potential
    growth of the asterisk string. However, for practical purposes, the space usage
    is usually not a significant issue, and we often focus on the *O(n²)* time complexity
    as the primary concern for this function.
  prefs: []
  type: TYPE_NORMAL
- en: Big O notation and tech interviews
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: During technical interviews for software developer positions, it is common for
    companies to do a coding test using some services online such as **LeetCode**,
    **Hackerrank**, and other similar services.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the correct data structure or algorithm to solve a problem can tell
    the company some information about how you solve problems that might pop up for
    you to resolve.
  prefs: []
  type: TYPE_NORMAL
- en: Interviewers might ask you to analyze code and predict how its runtime or memory
    usage might change under different input sizes. Once you write code to resolve
    a problem, interviewers might also ask you to pinpoint potential performance problems
    in your code and if you can identify areas of optimization. Also, different algorithms
    and data structures have different time complexities, and knowing Big O allows
    you to make informed decisions about which solution is best suited for a particular
    problem, considering all the tradeoffs.
  prefs: []
  type: TYPE_NORMAL
- en: During interviews, you can also showcase your velocity in resolving problems
    and how to optimize them. For example, in case there is any problem involving
    array search, you can start with a simple algorithm, to demonstrate you can resolve
    a problem quickly, depending on the criticality, and once the problem is fixed,
    demonstrate it can be optimized to use a more performative search, if you have
    more time to resolve the problem.
  prefs: []
  type: TYPE_NORMAL
- en: In each chapter of this book, we will cover some problems pertaining to the
    chapter topic, and what we can do to further optimize them.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that you've explored the fundamentals of time and space complexity with
    Big O notation, it's time to test your understanding! Analyze the following JavaScript
    functions and determine their time and space complexities. Experiment with different
    inputs to see how the functions behave.
  prefs: []
  type: TYPE_NORMAL
- en: '***1***: determines if the array''s size is odd or even:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '***2***: calculates and returns the average of an array of numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '***3***: checks if two arrays have any common values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '***4***: filters odd numbers from an input array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: You will find the answers in the source code for this chapter (file `src/02-bigOnotation/03-exercises.js`).
    Compare your analysis with the provided solutions to solidify your understanding
    of Big O notation in real-world JavaScript code!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we delved into the fundamental concept of Big O notation, a
    powerful tool for analyzing and expressing the efficiency of algorithms. We explored
    how to calculate both time complexity (the relationship between input size and
    runtime) and space complexity (the relationship between input size and memory
    usage). We also discussed how Big O analysis is a crucial skill for software developers,
    aiding in algorithm selection, performance optimization, and technical interviews.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will dive into our first data structure: the versatile
    **Array**. We will explore its common operations, analyze their time complexities,
    and tackle some practical coding challenges.'
  prefs: []
  type: TYPE_NORMAL
