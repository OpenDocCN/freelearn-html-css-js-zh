<html><head></head><body>
        

                            
                    <h1 class="header-title">Review and Continued Development</h1>
                
            
            
                
<p>Throughout this book, we've covered a wide range of topics and learned skills in lots of different areas. We've combined these skills to design and create complex chatbots on both the Alexa and Lex platforms.</p>
<p>This chapter will cover the following:</p>
<ul>
<li>Recap the skills that we've learned throughout this book</li>
<li>Discuss how to continue your chatbot development exploration</li>
<li>Discuss the future of chatbots</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">What we've learned</h1>
                
            
            
                
<p>There have been a lot of skills that have been covered in this book, both technical and non-technical.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Conversation design</h1>
                
            
            
                
<p>The first topic that was covered was conversation design. This is one of the most important sections of this book, as every good chatbot will need to go through this design stage. It doesn't matter whether it's going to be an Alexa Skill, Lex chatbot, or even a chatbot built using different technology.</p>
<p>When designing a chatbot, we always try to start with a perfect user conversation. Starting with a perfect conversation means that the users are likely to have the best possible experience with our chatbots.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Using the perfect conversation, we can start to build our flow diagrams. These provide more technical structure to the design, allowing us to specify what data we're saving, which APIs we're hitting, and triggering one flow from another. Creating a set of shorter flow diagrams that link together is incredibly powerful, as it provides flexibility to connect new entry points and features as the chatbot matures.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Amazon Web Services</h1>
                
            
            
                
<p>Next, we were introduced to <strong>Amazon Web Services</strong> (<strong>AWS</strong>) and the tools that we have access to. We started by creating an AWS Lambda using the Lambda console and then checked it using the built-in testing features.</p>
<p>Although creating Lambdas in the console is great for simple functions, we often need more functionality and a more reliable experience. We discussed the two other options—<strong>Cloud9</strong> and <strong>local editing</strong>—and we mentioned their advantages and their limitations.</p>
<p>Local editing had some great advantages but lacked the ability to easily create and update Lambdas. To fix this, we learned about the <kbd>aws-cli</kbd> and how we can use it to control our AWS products. Using the <kbd>aws-cli</kbd>, we created a build script that could take our local files, bundle them together, and deploy them to AWS. With this script, we now had a powerful development environment with easy deployment.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Amazon Alexa</h1>
                
            
            
                
<p>Then it was time to start building some chatbots. We started with Alexa and learned about the components that make up a chatbot. We learned to use intents, utterances, and slots to allow our users to interact with our chatbots.</p>
<p>To power this skill, we needed to create a Lambda to handle the requests. We used <kbd>alexa-sdk</kbd> to make it much easier to create the responses that we would be sending back to the user.</p>
<p>With a working Alexa Skill, we learned how to test it using the built-in testing tools. This way, we can test it as if we were a user, but with the ability to see how our skill is acting in the background.</p>
<p>Once we had tested the chatbot, we were ready to publish it. Alexa Skills need to be published to the Alexa Skill Store, and we learned how to follow this process to make our skills available to the public.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Amazon S3</h1>
                
            
            
                
<p>To increase the usefulness of all of our chatbots, we needed to be able to access large amounts of stored data. To do this, we learned how to create an S3 bucket, store data in it, and then access this data from our Lambdas. With this data access, we could provide users with a much larger amount of information on the topic that they requested.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Using APIs</h1>
                
            
            
                
<p>We then learned how to access third-party APIs to further improve the usefulness of our chatbots. We used the <kbd>openWeatherMaps</kbd> API as an example and this allowed us to access live information that we would never have been able to generate ourselves.</p>
<p>To do this, we also learned about <kbd>axios</kbd> and making API requests. With these skills, you'll be able to make requests to an API to add new features to your chatbots. We also looked at the two best ways to handle errors—using <kbd>try</kbd>/<kbd>catch</kbd> and the <kbd>to()</kbd> method. We discussed the reasons that you might want to use one or the other and why error handling is important.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Amazon Lex</h1>
                
            
            
                
<p>Building text-based chatbots came next as we learned about Amazon Lex. We saw the similarities and differences between Lex and Alexa, and we built on our existing knowledge to create our first Lex chatbots.</p>
<p>We learned that each intent can return a hardcoded response or trigger a Lambda. Being able to trigger a different Lambda from each intent allowed us to create lots of very customized Lambdas to do exactly what we wanted.</p>
<p>When we triggered a Lambda from Lex, it expected a very defined response format. Unfortunately, there isn't a <kbd>lex-sdk</kbd> yet, so we built our own. We saw five different response types and created methods for each of them. This allowed us to create the required responses much more easily.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Dynamo DB</h1>
                
            
            
                
<p>While S3 is great for storing large amounts of data that probably won't change very much, it isn't great for storing data that is regularly changing. To store this type of data, we learned about DynamoDB. This is Amazon's non-relational database, and it gives us the ability to easily store, access, and update information. We used this to store the shopping cart used for an online store.</p>
<p>We created a <kbd>Dynamo</kbd> class that had methods for getting, writing, updating, and deleting these Dynamo tables so that we didn't have to write the long and complex code needed every time.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Publishing Lex chatbots</h1>
                
            
            
                
<p>There's no point being able to build an amazing chatbot if your users can't access it. We learned to leverage the massive existing user bases of Facebook, Slack, and Twilio by integrating our chatbot into those platforms.</p>
<p>We also built an API service that allowed us to integrate our chatbot into a much wider range of applications. Building on this API, we created our own frontend interface for our chatbot. This was great, as it gave us the ability to make it look and work exactly how we wanted it to.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Advanced features</h1>
                
            
            
                
<p>The first seven chapters of this book taught us how to create powerful Alexa Skills and Lex chatbots by using other services such as S3, DynamoDB, and external APIs. In <a href="78bc7277-515a-4a49-8ace-6726512c3862.xhtml" target="_blank">Chapter 8</a>, <em>Improving User Experience for Your Bots</em>, we looked at some of the advanced features that are built into Lex and Alexa.</p>
<p>We first learned how to create information cards for Lex. This allowed us to send the user more visual information than the basic messages we were sending before. Adding these cards provided a huge boost to the user experience.</p>
<p>Then we learned about phrase slots in Alexa and how they can be used to capture information where the options that could be entered are too large to create a custom slot type. Being able to capture such a wide range of inputs into a slot makes our skills more reliable and robust.</p>
<p class="mce-root"/>
<p>The last thing that we learned about was utterance monitoring in Lex. This is where we can look at the utterances that Lex has detected and those that it has missed, which gives us an insight into the way that users are interacting with our chatbots. This also provides a mechanism to easily add utterances that we've missed to our existing intents.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Continuing your learning</h1>
                
            
            
                
<p>Now that you've completed this book, you have a great understanding of voice, and text-based chatbots. You're able to build complex, multi-flow chatbots that integrate other services such as S3, DynamoDB, and external APIs. If you've enjoyed learning how to build these systems, then you're in a great position to continue your journey.</p>
<p>There are a lot of different directions you can go with your learning, and I'll outline some possibilities for you—a few specific to Alexa or Lex, and then a few that would be great to learn for both Alexa and Lex.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Alexa</h1>
                
            
            
                
<p>If you really enjoyed building skills for Alexa, then there are two directions that I would go in with my learning.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Amazon Echo Spot and Amazon Echo Show</h1>
                
            
            
                
<p>The <strong>Amazon Echo Spot</strong> and <strong>Amazon Echo Show</strong> are Amazon's Alexa devices that also have screens. This means that you can provide users with visual information as well as voice responses. As with the cards on Lex, having that extra visual information can make the user experience much richer.</p>
<p>One big advantage of Echo devices with screens is that you can provide images to the user. Trying to tell a user about a product just using voice can be very hard but, with an image, the user experience is much smoother. You can also play videos, have a slideshow, or create custom displays with lots of varying information.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Building a library of functions</h1>
                
            
            
                
<p>If you enjoy building Alexa Skills and want to start building more of them, then there are going to be times when you want to use the same methods across multiple skills. There are two options—just copy the code every time, or create a library of method Lambdas. The first one is good for a small number of skills but will become annoying as you build more skills.</p>
<p>The second option will take longer to set up but will make building future skills much easier. The design for this setup is similar to the way that Lex works, where each intent triggers a single Lambda. Unfortunately, this isn't supported already, but we can create the same effect using the Lambda Invoke functions. This lets us trigger a Lambda from our <kbd>handlers</kbd> object.</p>
<p>The advantage of this method is that the common intents can trigger the same Lambda, reducing repeated code, whilst unique intents can still be built in the main handler Lambda.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Lex</h1>
                
            
            
                
<p>If you want to learn more skills specific to Lex, then the best direction would be learning to integrate it into more services.</p>
<p>There are hundreds of messaging services that Lex doesn't natively support, and being able to integrate your chatbot into these services would be a great skill to have. You could try integrating you chatbot into Telegram, Twitter, WeChat, or any other messaging services. To do this, you'll probably have to map the message into the correct format for that specific service. The mapping between formats can be quite tricky but is a great skill to learn.</p>
<p>Once you've built a mechanism to integrate Lex into these messaging platforms, you can advertise your integration or the fact that you can build a mechanism to integrate into the company's own messaging platform. Lots of companies want to be able to add chatbots to their existing messaging platform.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Alexa and Lex</h1>
                
            
            
                
<p>Continuing your learning with skills that can be used with both Alexa and Lex is probably the best use of your time, and there are many different directions to go in.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Improving the build process</h1>
                
            
            
                
<p>As you build more Alexa Skills and Lex chatbots, you will become frustrated with having to open the Alexa Skills Kit or the Lex console to add a new utterance or change an intent. Luckily, there is the <kbd>aws-cli</kbd> and <kbd>ask-cli</kbd> that we can use to build and update our skills and chatbots without having to go online.</p>
<p>You may remember the <kbd>aws-cli</kbd> from <a href="ac448944-0559-408e-a9c4-972933a03611.xhtml" target="_blank">Chapter 2</a>, <em>Getting Started with AWS and Amazon CLI</em>, where we used it to allow us to build Lambdas from our local machines. You can also use <kbd>aws-cli</kbd> to do something similar for Lex chatbots, whilst <kbd>ask-cli</kbd> has similar functionality for Alexa Skills. For both of these systems, there is quite a steep learning curve and you'll end up reading a lot of documentation, but being able to build a new chatbot or skill without ever using a browser is really useful.</p>
<p>You can either have the full structure of the chatbot or skill saved as a file on your computer, or you can create a system to generate these files based on a more simple config file. The advantage of the latter method is that the config files should be a lot easier to read and understand, making it a lot easier to figure out what needs to change for your update.</p>
<p>Once you've got this system in place, you should be able to create a new config file for a new bot within minutes. If you use this system, there is nothing stopping you from still using the online Alexa Skills Kit or Lex console to check, edit, and update your skills and chatbots.</p>
<p>If you are considering building chatbots or Alexa Skills as a job, then this tool will prove invaluable.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Integrating more AWS services</h1>
                
            
            
                
<p>In this book, we have learned how to use S3 and DynamoDB to improve the functionality of our skills and chatbots. There are currently over 100 AWS services, and some of them could be used to add even more functionality to your chatbots.</p>
<p>Here are a few ideas for service integrations:</p>
<ul>
<li>Amazon Redshift or Amazon ElastiCache, for a different method for database storage</li>
<li>Amazon Cognito, for allowing users to sign in to access existing orders and chats or to provide results that are adjusted to match their user information</li>
<li>Amazon Transcribe and Amazon Simple Email Service, to send the user an email with everything they said whilst chatting to Alexa</li>
</ul>
<p>With the number of services available, what you can build and do with Alexa and Lex is limited only by your imagination.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Integrating other APIs</h1>
                
            
            
                
<p>The number of APIs available online is incredible! Just looking through one list of top APIs can give you some incredible ideas. What about a chatbot that you can ask about a certain product and it searches eBay for those products, allowing you to bid on it without leaving the chat! There's a census API that could be used to build an Alexa Skill where you can find out about the population, employment stats, economics, number of new houses, and much more about any area in the United States.</p>
<p>If you're looking to come up with some ideas for your own chatbots, then I highly recommend looking at APIs that are available and what you can do with them. You might find a function on one API that combines with a function on another API to create an immensely powerful chatbot.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The future of chatbots</h1>
                
            
            
                
<p>Chatbots have come a long way over the last decade and are now often found in households through Amazon Echo and Google Home. Technologically, they have improved in leaps and bounds, with improvements in AI and machine learning resulting in better language understanding as well as voice-to-text that power the Echo and Google Home devices.</p>
<p>I expect that the growth of chatbots will continue and we'll start seeing them used in a huge range of application and through a wide range of devices. As they improve, they'll be trusted with increasingly complex and important tasks and will completely revolutionize a lot of industries. Industries such as customer services are already changing, with chatbots on multiple banking and retail websites and phone systems.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Language understanding</h1>
                
            
            
                
<p>To be able to properly respond to someone, you need to understand what they are saying so you can build the correct response. This has improved a lot with the adoption of machine learning but is far from perfect.</p>
<p>One issue that can occur is that there are two intents with similar utterances, or with the same keyword in the utterances. When the user says a similar utterance, it matches both of the intents similarly and therefore can't choose which one to trigger. A chatbot with an intent with an utterance of <kbd>When is the football match?</kbd> and another intent with <kbd>Where is the football match?</kbd> is very likely to get confused and not be able to handle the request.</p>
<p>Another issue can be with spelling mistakes and typos. Lex currently seems to be OK with handling typos and spelling mistakes, but there have been quite a few times that these have caused issues.</p>
<p>As machine learning and language understanding improve, I expect to see these sorts of issues decrease.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Working with spoken interactions</h1>
                
            
            
                
<p>As with language understanding, being able to respond to a user's request means being able to understand what they said. With voice systems, this involves converting the spoken sound waves into text. Whilst this can work brilliantly if you happen to speak clearly with a neutral accent, there are often issues when people speak very quickly or with a strong accent.</p>
<p>When the text is generated from the users with a strong accent, it can often be misunderstood, and the text that is produced makes no sense. This then means that when it is passed into the language-understanding system, the speech can't be matched to an intent. This can be very frustrating for users with a strong accent who are unable to interact with these devices. This is a significant hurdle to overcome before voice-based chatbots become common in commercial applications.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Improved device interaction</h1>
                
            
            
                
<p>The continued increase of devices and systems that you can interact with through voice- and text-based conversation is key to the expansion of chatbots into our everyday lives. The great thing is that it's possible to install Alexa software onto a Raspberry Pi Zero, a $10 computer chip. This means that adding voice interaction to any device can be cheap and relatively simple. Alexa integration can already be seen in cars, smart mirrors, smart tables, and much more.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Another sector where I believe that chat interfaces are going to grow significantly is in wearables. Bluetooth hands-free systems are becoming smaller and more discrete and they could very easily integrate voice chat systems. At any point in your day, you could ask Alexa for the weather or the meetings for the day and get an instant response. This would overcome the security concerns that some people have about voice systems projecting their response for everyone in the room to hear.</p>
<p>Smart watches with built-in voice- and text-based chatbots provide another way that we will see chatbots integrated into our lives. The advantage of watches over earpieces is that they have screens, allowing the chatbot to display visual media or show the user the information, instead of having to say it all. Being able to glance at the weather is more convenient than having to listen to the weather forecast for the next five days when all you cared about was next Wednesday.</p>
<p>The last wearable that I can imagine using chatbots in the near future is smart glasses. Glasses similar to Google Glasses would allow you to receive visual information in the same way that a smart watch would, but you wouldn't even need to look down at your wrist. The addition of chatbots to an augmented reality system such as this could be very powerful.</p>
<p>The most powerful way the chatbots could be integrated into wearables would be an integration of multiple systems. Using an earpiece for a voice-based chat, but having a smart watch or smart glasses to display the visual information, would combine the best of both worlds.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Connected devices</h1>
                
            
            
                
<p>The second obstacle to overcome, before chatbots are commonplace, is the number of devices that can be connected to these smart home systems or remotely controlled solutions. You can currently get smart light switches, coffee makers, and even door locks that you can control through chat interfaces.</p>
<p>In the future, I expect that more and more devices will come out with a similar control system. I can imagine a washing machine that you can set and start by just talking to Alexa and eventually a kitchen where every device and appliance is speech-controlled. Imagine telling Alexa to turn the oven on to 180 degrees and to let you know when it gets to the right temperature, all while you sat watching TV, and then preparing a turkey and asking Alexa to open the oven so you can put it straight in. The oven could then weigh the turkey and set a reminder for 50 minutes before it will be ready to start preparing the roast potatoes.</p>
<p>As well as domestic appliances with integrated chatbots, I expect to see an increase in chatbots in businesses over the next 10-20 years. Bank tellers could become a screen with an animation of a person, powered by a voice-based chatbot. You could get your fresh meat and cheese from a chatbot that controls a robotic delicatessen. These could work in exactly the same way as current human workers, asking if that is a large enough piece of the brie wheel whilst holding the knife in position.</p>
<p>As well as commercial applications, I expect to see public service information begin to integrate chatbots. You arrive at the shopping center car park and want to find a particular store. All you need to do is to walk up to one of the information signs and ask where the shop is and it'll display the directions on a map, tell you how to get there, or even send the directions to your smart watch or smart glasses.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Unique voice-based systems</h1>
                
            
            
                
<p>To power the sorts of integrations and devices just mentioned, there needs to be a change in the way that voice-based chatbots are built. If you want to build a system that handles user speech, then your two main options are to build an Alexa Skill or a Google Home action. This is great for integrating into devices that already run these systems, but companies wouldn't want to run Alexa as your bank teller chatbot system.</p>
<p>There needs to be a change in the market with the move to being able to create custom voice-based chatbot systems that don't have to be run on Alexa or Google Home. This is currently possible through Amazon Lex, as it has been built to handle voice interaction, but I hope to see an increase in the range of systems that can do this.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">General Artificial Intelligence</h1>
                
            
            
                
<p>A lot of the issues that exist with current chatbots will gradually be fixed, and their performance will increase incrementally, but the next large step forward will be the creation of <strong>general AI</strong>.</p>
<p>General AI is the concept where a single system can handle any request. This may sound not too far off with projects such as IBM Watson building a system that can dominate Jeopardy and other quiz games, but being able to answer simple questions is only part of the challenge.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The issues start when the system has to work out what other information it needs to fulfill the request and how to ask for that information. If someone asked you to find their class graduation photo, you would probably ask them what school they went to and what year they graduated in. You have used your knowledge about class photos to decide that you need to ask about school and year to accurately find their class photo. Our brains are extremely good at these sorts of tasks, but building an AI system that can work this out for every possible request, now or in the future, is a daunting task. Building an intent for every possible question just isn't possible so the system will need to gather what information it has on the topic, work out what else it needs to know to answer the question, and then ask for those pieces of data in a human way.</p>
<p>Another issue is with integrating into external systems. Throughout this book, we've used APIs to access data that is stored by a third party. To use these APIs, we had to have an API key, and, even then, we only had access to the data and functionality that we were given through the API. If we wanted to create a chatbot that did our weekly supermarket shop, had it delivered to our house, and paid for it, we'd need to get an API that allows us to do all of this. Creating an API like that is something I expect most supermarkets wouldn't dream of doing.</p>
<p>In my job, integrating into a client's existing system is a major hurdle to getting their chatbot functioning. Having a general AI system that has access to every API in the world is unrealistic, and, even then, there are systems that are not exposed through APIs.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Improving people's opinions</h1>
                
            
            
                
<p>One large hurdle to increased acceptance of chatbots is improving people's opinions of chatbots. When chatbots first came out, they were very limited in functionality, couldn't deal with many variations in utterance, and often proved to be more frustrating than useful. Modern chatbots have improved a lot, but there are a lot of older systems that are still very discouraging to use. Even modern chatbot systems have their limitation, as we've discussed earlier, and can still end up disappointing users with missed intents or misunderstood speech.</p>
<p>As the systems improve, better systems will have better user retention and the old systems will be replaced. I expect to see a continual improvement in people's opinions about chatbots. As systems like Alexa and Google Home become increasingly common in households, younger generations will grow up with chatbots and interacting with them will become second nature.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>This book has given us a practical introduction to chatbots through building increasingly complex Alexa Skills and Lex chatbots. We've learned about starting from a perfect conversation and creating flow diagrams to visualize the users' conversational path with a chatbot. Using these flow diagrams, we've built intents using utterances and slots that are handled in Lambdas.</p>
<p>We've improved the features and abilities of our chatbots through the use of S3 storage, DynamoDB databases, and external APIs. To improve the user experience, we also learned about using SSML to change how Alexa talks with our users, learned how to create cards to provide more visual information, and learned about search query slot types in Alexa for gathering wider ranges of slot values.</p>
<p>Finally, we've discussed a few great ways to build upon what we've already learned in this book and what we expect is in store for the future of chatbots.</p>


            

            
        
    </body></html>