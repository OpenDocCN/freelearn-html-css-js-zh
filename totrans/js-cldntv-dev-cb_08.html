<html><head></head><body>
        

                            
                    <h1 class="header-title">Designing for Failure</h1>
                
            
            
                
<p>In this chapter, the following recipes will be covered:</p>
<ul>
<li class="mce-root">Employing proper timeouts and retries</li>
<li class="mce-root">Implementing backpressure and rate limiting</li>
<li class="mce-root">Handling faults</li>
<li class="mce-root">Resubmitting fault events</li>
<li class="mce-root">Implementing idempotence with an inverse OpLock</li>
<li class="mce-root">Implementing idempotence with Event Sourcing</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Introduction</h1>
                
            
            
                
<p>Managing failure is the cornerstone of cloud-native. We build autonomous services that limit the blast radius when they do fail and continue to operate when other services fail. We decouple deployment from release, and we control the batch size of each deployment so that we can easily identify the problem when a deployment does go wrong. We shift testing to the left into the continuous deployment pipeline to catch issues before a deployment, as well as all the way to the right into production, where we continuously test the system and alert on anomalies to minimize the meantime to recovery. The recipes in this chapter demonstrate how to design a service to be resilient and forgiving in the face of failure so that transient failures are properly handled, their impact is minimized, and the service can self-heal.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Employing proper timeouts and retries</h1>
                
            
            
                
<p>The reality of computer networks is that they are unreliable. The reality of cloud computing is that it relies on computer networks, therefore it is imperative that we implement services to properly handle network anomalies. This recipe demonstrates how to properly configure functions and SDK calls with the appropriate timeouts and retries.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<ol>
<li>Create the project from the following template:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch8/timeout-retry --path cncb-timeout-retry</pre>
<ol start="2">
<li>Navigate to the <kbd>cncb-timeout-retry</kbd> directory with <kbd>cd cncb-timeout-retry</kbd>.</li>
<li>Review the file named <kbd>serverless.yml</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">service: cncb-timeout-retry<br/>...<br/>functions:<br/>  command:<br/>    handler: handler.command<br/>    <strong>timeout</strong>: 6<br/>    <strong>memorySize</strong>: 1024<br/>...</pre>
<ol start="4">
<li>Review the file named <kbd>handler.js</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">module.exports.command = (request, context, callback) =&gt; {<br/>  const db = new aws.DynamoDB.DocumentClient({<br/>    httpOptions: { <strong>timeout</strong>: 1000 },<br/>    logger: console,<br/>  });<br/>...<br/>  db.put(params, callback);<br/>};</pre>
<ol start="5">
<li>Install the dependencies with <kbd>npm install</kbd>.</li>
<li>Run the tests with <kbd> npm test</kbd>.</li>
<li>Review the contents generated in the <kbd>.serverless</kbd> directory.</li>
<li>Deploy the stack with <kbd>npm run dp:lcl -- -s $MY_STAGE</kbd>.</li>
<li>Review the stack and resources in the AWS Console.</li>
<li>Invoke the function with the following command:</li>
</ol>
<pre style="padding-left: 30px">$ sls invoke -f command -r us-east-1 -s $MY_STAGE -d '{"name":"thing one"}'</pre>
<ol start="11">
<li>Take a look at the following command function logs:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ sls logs -f command -r us-east-1 -s $MY_STAGE</strong><br/><br/>2018-07-14 23:41:14.229 (-04:00) ... [AWS dynamodb 200 0.063s <strong>0 retries</strong>] putItem({ TableName: 'john-cncb-timeout-retry-things',<br/>  Item:<br/>   { id: { S: 'c22f3ce3-551a-4999-b750-a20e33c3d53b' },<br/>     name: { S: 'thing one' } } })   </pre>
<ol start="12">
<li>Remove the stack once you are finished with <kbd>npm run rm:lcl -- -s $MY_STAGE</kbd>.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p><strong>Network hiccups</strong> can happen at any time. Where one request may not go through, the next request may go through just fine; therefore, we should have short timeouts so that we can retry the process as soon as possible, but not so short that a good request times out before it has a chance to complete normally. We must also ensure that our timeout and retry cycle has enough time to complete before the function times out. The <kbd>aws-sdk</kbd> is configured by default to time out after two minutes and performs three retries with an increasing delay time. Of course, two minutes is too long. Setting the <kbd>timeout</kbd> to 1000 (1 second) will typically be long enough for a request to complete and allow for three retries to complete before a function timeout of 6 seconds.<br/>
<br/>
If requests time out too frequently then this could be an indication that the function has been allocated with too few resources. For example, there is a correlation between the <kbd>memorySize</kbd> allocated to a function and the machine instance size that is used. Smaller machine instances also have less network I/O capacity, which could lead to more frequent network hiccups. Thus, increasing <kbd>memorySize</kbd> will decrease network volatility.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementing backpressure and rate limiting</h1>
                
            
            
                
<p>The various services in a cloud-native system must be able to handle the ebb and flow of traffic through the system. Upstream services should never overload downstream services, and downstream services must be able to handle peak loads without falling behind or overloading services further downstream. This recipe shows how to leverage the natural backpressure of stream processors and implement additional rate limiting to manage throttling.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Getting ready</h1>
                
            
            
                
<p>Before starting this recipe, you will need an AWS Kinesis Stream, such as the one created in the <em>Creating an event stream</em> recipe.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<ol>
<li>Create the project from the following template:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch8/backpressure-ratelimit --path cncb-backpressure-ratelimit</pre>
<ol start="2">
<li>Navigate to the <kbd>cncb-backpressure-ratelimit</kbd> directory with <kbd>cd cncb-backpressure-ratelimit</kbd>.</li>
<li>Review the file named <kbd>serverless.yml</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">service: cncb-backpressure-ratelimit<br/>...<br/>functions:<br/>  <strong>listener</strong>:<br/>    handler: handler.<strong>listener</strong><br/>    <strong>timeout</strong>: 240 # headroom for retries<br/>    events:<br/>      - stream:<br/>          <strong>batchSize</strong>: 1000 # / (timeout / 2) &lt; write capacity<br/>          ...<br/>    environment:<br/>      <strong>WRITE_CAPACITY_UNITS</strong>: 10<br/>      <strong>SHARD_COUNT</strong>: 1<br/>...<br/>resources:<br/>  Resources:<br/>    Table:<br/>      Type: AWS::DynamoDB::Table<br/>      Properties:<br/>        ...<br/>        ProvisionedThroughput:<br/>          ...<br/>          <strong>WriteCapacityUnits</strong>: ${self:functions.listener.environment.WRITE_CAPACITY_UNITS}</pre>
<ol start="4">
<li>Review the file named <kbd>handler.js</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">module.exports.<strong>listener</strong> = (event, context, cb) =&gt; {<br/>  _(event.Records)<br/>    .map(recordToUow)<br/>    .filter(forPurple)<br/>    .<strong>ratelimit</strong>(Number(process.env.<strong>WRITE_CAPACITY</strong>) / <br/>      Number(process.env.<strong>SHARD_COUNT</strong>) / <strong>10</strong>, <strong>100</strong>)<br/>    .flatMap(put)<br/>    .collect()<br/>    .toCallback(cb);<br/>};<br/><br/>const put = uow =&gt; {<br/>  const params = { ... };<br/>  const db = new aws.DynamoDB.DocumentClient({<br/>    httpOptions: { timeout: 1000 },<br/>    // default values:<br/>    // <strong>maxRetries</strong>: 10,<br/>    // retryDelayOptions: {<br/>    //   <strong>base</strong>: 50,<br/>    // },<br/>    logger: console,<br/>  });<br/><br/>  return _(db.put(params).promise()<br/>    .then(() =&gt; uow)<br/>  );<br/>};</pre>
<ol start="5">
<li>Install the dependencies with <kbd>npm install</kbd>.</li>
<li>Run the tests with <kbd>npm test -- -s $MY_STAGE</kbd>.<kbd><br/></kbd></li>
<li>Review the contents generated in the <kbd>.serverless</kbd> directory.</li>
<li>Deploy the stack with <kbd>npm run dp:lcl -- -s $MY_STAGE</kbd>.</li>
<li>Review the stack and resources in the AWS Console.</li>
<li>Invoke the <kbd>simulate</kbd> function with the following command:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ sls invoke -f simulate -r us-east-1 -s $MY_STAGE</strong><br/>[<br/>    {<br/>        "<strong>total</strong>": 4775,<br/>        "blue": 1221,<br/>        "green": 1190,<br/>        "<strong>purple</strong>": 1202,</pre>
<pre style="padding-left: 30px">        "orange": 1162<br/>    }<br/>]</pre>
<ol start="11">
<li>Take a look at the following <kbd>trigger</kbd> function logs:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ sls logs -f listener -r us-east-1 -s $MY_STAGE --filter 'event count'<br/></strong>2018-07-15 22:53:29 ... event count: 1000<br/>2018-07-15 22:54:00 ... event count: 1000<br/>2018-07-15 22:54:33 ... event count: 1000<br/>2018-07-15 22:55:05 ... event count: 425<br/>2018-07-15 22:55:19 ... event count: 1000<br/>2018-07-15 22:55:51 ... event count: 350<strong><br/><br/></strong><strong>$ sls logs -f listener -r us-east-1 -s $MY_STAGE --filter 'Duration'<br/></strong>REPORT ... Duration: 31011.59 ms ...<br/>REPORT ... Duration: 33038.58 ms ...<br/>REPORT ... Duration: 32399.91 ms ...<br/>REPORT ... Duration: 13999.56 ms ...<br/>REPORT ... Duration: 31670.86 ms ...<br/>REPORT ... Duration: 12856.77 ms ...<br/><br/><strong>$ sls logs -f listener -r us-east-1 -s $MY_STAGE --filter 'retries'<br/></strong>...<br/>2018-07-15 22:55:49 ... [AWS dynamodb 200 <strong>0.026s</strong> 0 retries] putItem({ TableName: '...',<br/>  Item:<br/>   { id: { S: '686dc03a-88a3-11e8-829c-67d049599dd2' },<br/>     type: { S: 'purple' },<br/>     timestamp: { N: '1531709604787' },<br/>     partitionKey: { S: '3' },<br/>     tags: { M: { region: { S: 'us-east-1' } } } },<br/>  ReturnConsumedCapacity: 'TOTAL' })<br/>2018-07-15 22:55:50 ... [AWS dynamodb 200 <strong>0.013s</strong> 0 retries] putItem({ TableName: '...',<br/>  Item:<br/>   { id: { S: '686d4b14-88a3-11e8-829c-67d049599dd2' },<br/>     type: { S: 'purple' },<br/>     timestamp: { N: '1531709604784' },<br/>     partitionKey: { S: '4' },<br/>     tags: { M: { region: { S: 'us-east-1' } } } },<br/>  ReturnConsumedCapacity: 'TOTAL' })<br/>...</pre>
<ol start="12">
<li>Remove the stack once you are finished with <kbd>npm run rm:lcl -- -s $MY_STAGE</kbd>.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p><em>Backpressure</em> is a critical characteristic of a well-implemented stream processor. When using the <em>imperative programming paradigm</em>, such as looping over the array of records in a batch, the downstream target system could easily be overwhelmed because the loop will process the records as fast as it can without regard for the throughput capacity of the target system. Alternatively, the <strong>Functional Reactive Programming</strong> (<strong>FRP</strong>) paradigm, with a library such as Highland.js (<a href="https://highlandjs.org">https://highlandjs.org</a>) or RxJS (<a href="https://github.com/ReactiveX/rxjs">https://github.com/ReactiveX/rxjs</a>), provides a natural backpressure, because data is pulled downstream only as fast as the downstream steps are able to complete their tasks. For example, an external system that has low throughput will only pull data as quickly as its capacity will allow.</p>
<p>On the other hand, highly-scalable systems, such as DynamoDB or Kinesis, that are able to process data with extremely high throughput rely on throttling to restrict capacity. In this case, the natural backpressure of FRP is not enough; additional use of the <kbd>ratelimit</kbd> feature is required. As an example, when I was writing this recipe I ran a simulation without rate limiting and then went out to dinner. When I came back several hours later, the events generated by the simulation were still trying to process. This is because DynamoDB was throttling the requests and the exponential backoff and retry built into the <kbd>aws-sdk</kbd> was taking up too much time, leading the function to <kbd>timeout</kbd> and retry the whole batch again. This demonstrates that while retries, as discussed in the <em>Employing proper timeouts and retries</em> recipe, are important for synchronous requests, they cannot be solely relied upon for asynchronous stream processing. Instead, we need to proactively limit the rate of flow to avoid throttling and exponential backoff to help ensure a batch completes within the function timeout.</p>
<p>In this recipe, we use a simple algorithm to calculate the rate of flow—<kbd>WRITE_CAPACITY / SHARD_COUNT / 10</kbd> per every <kbd>100</kbd> milliseconds. This ensures that DynamoDB will not receive more requests per second than have been allocated. I also used a simple algorithm to determine the batch size—<kbd>batchSize / (timeout / 2) &lt; WRITE_CAPACITY</kbd>. This ensures that there should be plenty of time to complete the batch under normal conditions, but there will be twice the necessary time available in case there is throttling. Note that this is just a logical starting point; this is the area where performance tuning in cloud-native systems should be focused. The characteristics of your data and target systems will dictate the most effective settings. As we will see in the <em>Autoscaling DynamoDB</em> recipe, autoscaling adds yet another dimension to backpressure, rate limiting, and performance tuning. Regardless, you can start with these simple and safe algorithms and tune them over time.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Handling faults</h1>
                
            
            
                
<p>Stream processors are naturally resilient and forgiving of transient errors because they employ backpressure and automatically retry failing batches. However, hard errors, if not handled properly, can cause a traffic jam that results in dropped messages. This recipe will show you how to delegate these errors as fault events so that good messages can continue to flow.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<ol>
<li>Create the project from the following template:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch8/handling-faults --path cncb-handling-faults</pre>
<ol start="2">
<li>Navigate to the <kbd>cncb-handling-faults</kbd> directory with <kbd>cd cncb-handling-faults</kbd>.</li>
<li>Review the file named <kbd>serverless.yml</kbd>.</li>
<li>Review the file named <kbd>handler.js</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">module.exports.<strong>listener</strong> = (event, context, cb) =&gt; {<br/>  _(event.Records)<br/>    .map(recordToUow)<br/>    .filter(forThingCreated)<br/>    .tap(<strong>validate</strong>)<br/>    .tap(<strong>randomError</strong>)<br/>    .flatMap(save)<br/>    <strong>.errors(errors)</strong><br/>    .collect().toCallback(cb);<br/>};<br/><br/>const validate = uow =&gt; {<br/>  if (uow.event.thing.name === undefined) {<br/>    const err = new Error('Validation Error: name is required');<br/>    // handled<br/>    <strong>err.uow = uow;</strong><br/>    throw err;<br/>  }<br/>};<br/><br/>const randomError = () =&gt; {<br/>  if (Math.floor((Math.random() * 5) + 1) === 3) {<br/>    // unhandled<br/>    throw new Error('Random Error');<br/>  }<br/>};<br/><br/>const save = uow =&gt; {<br/> ...<br/> return _(db.put(uow.params).promise()<br/>   .catch(err =&gt; {<br/>     // handled<br/>     <strong>err.uow = uow;</strong><br/>     throw err;<br/>   }));<br/>};<br/><br/>const <strong>errors</strong> = (err, push) =&gt; {<br/>  if (<strong>err.uow</strong>) {<br/>    // handled exceptions are adorned with the uow in error<br/>    push(null, <strong>publish</strong>({<br/>      type: '<strong>fault</strong>',<br/>      timestamp: Date.now(),<br/>      tags: {<br/>        <strong>functionName</strong>: process.env.AWS_LAMBDA_FUNCTION_NAME,<br/>      },<br/>      <strong>err</strong>: {<br/>        name: err.name,<br/>        message: err.message,<br/>        stack: err.stack,<br/>      },<br/>      <strong>uow</strong>: err.uow,<br/>    }));<br/>  } else {<br/>    // rethrow unhandled errors to stop processing<br/>    push(err);<br/>  }<br/>};</pre>
<ol start="5">
<li>Install the dependencies with <kbd>npm install</kbd>.</li>
<li>Run the tests with <kbd>npm test -- -s $MY_STAGE</kbd>.</li>
<li>Review the contents generated in the <kbd>.serverless</kbd> directory.</li>
<li>Deploy the stack with <kbd>npm run dp:lcl -- -s $MY_STAGE</kbd>.</li>
<li>Review the stack and resources in the AWS Console.</li>
<li>Invoke the <kbd>simulate</kbd> function with the following command:</li>
</ol>
<pre style="padding-left: 30px">$ sls invoke -f simulate -r us-east-1 -s $MY_STAGE</pre>
<ol start="11">
<li>Take a look at the following <kbd>trigger</kbd> function logs:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ sls logs -f listener -r us-east-1 -s $MY_STAGE --filter 'publishing fault'<br/></strong>... {"type":"fault","timestamp":...,"tags":{"functionName":"cncb-handling-faults-john-listener"},"err":{"name":"Error","message":"Validation Error: name is required" ...<br/><br/>... {"type":"fault","timestamp":...,"tags":{"functionName":"cncb-handling-faults-john-listener"},"err":{"name":"ValidationException","message":"...Missing the key id..." ...<strong><br/></strong><strong><br/></strong></pre>
<ol start="12">
<li>Remove the stack once you are finished with <kbd>npm run rm:lcl -- -s $MY_STAGE</kbd>.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>This recipe implements the <em>Stream Circuit Breaker</em> pattern that I discuss in depth in my book, <em>Cloud Native Development Patterns and Best Practices</em> (<a href="https://www.packtpub.com/application-development/cloud-native-development-patterns-and-best-practices">https://www.packtpub.com/application-development/cloud-native-development-patterns-and-best-practices</a>). Stream processors that experience hard errors will continue to reprocess those events until they expire from the stream—unless the stream processor is implemented to set these errors aside by delegating them as fault events for processing elsewhere, such as described in the <em>Resubmitting fault events</em> recipe. This alleviates the traffic jam so that other events can continue to flow.</p>
<p>This recipe simulates events that will fail at different stages in the stream processor. Some events simulate upstream bugs that will fail the validation logic that asserts that events are being created properly upstream. Other events will fail when they are inserted into DynamoDB. The logic also randomly fails some events to simulate transient errors that do not produce faults and will automatically be retried. In the logs, you will see two fault events published. When a random error is generated, you will see in the logs that the function retries the batch. If the simulation does not raise a random error then you should rerun it until it does.</p>
<p>To isolate events in a stream, we need to introduce the concept of a <strong>unit of work</strong> (<strong>UOW</strong>) that groups one or more events from the batch into an atomic unit that must succeed or fail together. The UOW contains the original Kinesis record (<kbd>uow.record</kbd>), the event parsed from the record (<kbd>uow.event</kbd>), and any intermediate processing results (<kbd>uow.params</kbd>) that are attached to the UOW as it passes through the stream processor. The UOW is also used to identify errors as handled or unhandled. When an expected error is identified by the validation logic or caught from external calls, the UOW is adorned to the error and the error is re-thrown. The adorned unit of work (<kbd>error.uow</kbd>) acts as the indicator to the <kbd>errors</kbd> handler that the error was handled in the stream processor and that it should <kbd>publish</kbd> the error as a fault event. Unexpected errors, such as randomly-generated errors, are not handled by the stream processor logic and thus will not have an adorned UOW. The error handler will <kbd>push</kbd> these errors downstream to cause the function to fail and retry. In the <em>Creating alerts</em> recipe, we discuss monitoring for fault events, as well as iterator age, so that the team can receive timely notifications about stream processor errors.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Resubmitting fault events</h1>
                
            
            
                
<p>We have designed our stream processors to delegate errors as fault events so that valid events can continue to flow. We monitor for and alert on fault events so that appropriate action can be taken to address the root cause. Once the problem is resolved, it may be necessary to reprocess the failed events. This recipe demonstrates how to resubmit fault events back to the stream processor that raised the fault.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<ol>
<li>Create the <kbd>monitor</kbd>, <kbd>simulator</kbd>, and <kbd>cli</kbd> projects from the following templates:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch8/resubmitting-faults/monitor --path cncb-resubmitting-faults-monitor<br/><br/>$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch8/resubmitting-faults/cli --path cncb-resubmitting-faults-cli<br/><br/>$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch8/resubmitting-faults/simulator --path cncb-resubmitting-faults-simulator</pre>
<ol start="2">
<li>Review the file named <kbd>serverless.yml</kbd> in the <kbd>cncb-resubmitting-faults-monitor</kbd> and <kbd>cncb-resubmitting-faults-simulator</kbd> directories.</li>
<li>Deploy the <kbd>monitor</kbd> and <kbd>simulator</kbd> stacks, as follows:</li>
</ol>
<pre style="padding-left: 30px">$ cd ../cncb-resubmitting-faults-monitor<br/>$ npm install<br/>$ npm test -- -s $MY_STAGE<br/>$ npm run dp:lcl -- -s $MY_STAGE<br/><br/>  Stack Outputs<br/><strong>  BucketName</strong>: cncb-resubmitting-faults-monitor-john-bucket-1llq835xdczd8<br/><br/>$ cd ../cncb-resubmitting-faults-simulator<br/>$ npm install<br/>$ npm test -- -s $MY_STAGE<br/>$ npm run dp:lcl -- -s $MY_STAGE</pre>
<ol start="4">
<li>Review the stacks and resources in the AWS Console.</li>
<li>Run the simulator from the <kbd>cncb-resubmitting-faults-simulator</kbd> directory, as follows:</li>
</ol>
<pre style="padding-left: 30px">$ sls invoke -f simulate -r us-east-1 -s $MY_STAGE</pre>
<ol start="6">
<li>Confirm that a fault file is written to the bucket specified in the monitor stack output <kbd>cncb-resubmitting-faults-monitor-*-bucket-*</kbd> and note the path. If no fault was generated, run the simulator again until one is generated.</li>
<li>Review the file named <kbd>./cli/lib/resubmit.js</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">exports.command = 'resubmit [bucket] [prefix]'<br/>exports.desc = 'Resubmit the faults in [bucket] for [prefix]'<br/>...<br/>const <strong>invoke</strong> = (lambda, options, event) =&gt; {<br/>  const Payload = JSON.stringify({<br/>      Records: [<strong>event.uow.record</strong>],<br/>  });<br/><br/>  const params = {<br/>    FunctionName: <strong>event.tags.functionName</strong>,<br/>    ...<br/>    Payload: Buffer.from(Payload),<br/>  };<br/><br/>  return _(lambda.invoke(params).promise());<br/>}</pre>
<ol start="8">
<li>Resubmit the fault with the following command:</li>
</ol>
<pre style="padding-left: 30px">$ cd ../cncb-resubmitting-faults-cli<br/>$ npm install<br/>$ node index.js resubmit -b cncb-resubmitting-faults-monitor-$MY_STAGE-bucket-&lt;suffix&gt; -p &lt;s3-path&gt; --dry false</pre>
<ol start="9">
<li>Empty the <kbd>cncb-resubmitting-faults-monitor-*</kbd> bucket manually and remove the <kbd>monitor</kbd> and <kbd>simulator</kbd> stacks once you are finished with <kbd>npm run rm:lcl -- -s $MY_STAGE</kbd>.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>In the <em>Handling faults</em> recipe, we saw how stream processors delegate hard errors by publishing fault events with all the data pertaining to the unit of work that failed. In this recipe, a fault monitor consumes these fault events and stores them in an S3 bucket. This enables the team to review the specific fault to help determine the root cause of the problem. The fault contains the specific exception that was caught, the event that failed, and all of the contextual information that was attached to the unit of work.</p>
<p>Once the root cause has been addressed, the original event can be submitted back to the stream processor that published the fault. This is possible because the fault event contains the original Kinesis record (<kbd>event.uow.record</kbd>) and the name of the function to invoke (<kbd>event.tags.functionName</kbd>). The command line utility reads all the fault events from the bucket for the specified path and invokes the specific functions. From the perspective of the function logic, this direct invocation of the function is no different to it being invoked directly from the Kinesis stream. However, the stream processor must be designed to be idempotent and to be able to handle events out of order, as we will discuss in the <em>Implementing idempotence with an inverse OpLock</em> and <em>Implementing idempotence with Event Sourcing</em> recipes.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementing idempotence with an inverse OpLock</h1>
                
            
            
                
<p>From a business rule standpoint, it is important that events are processed exactly once; otherwise, problems may arise, such as double counting or not counting at all. However, our cloud-native systems must be resilient to failure and proactively retry to ensure no messages are dropped. Unfortunately, this means that messages may be delivered multiple times, for example when a producer re-publishes an event or a stream processor retries a batch that may have been partially processed. The solution to this problem is to implement all actions to be idempotent. This recipe implements idempotency with what I refer to as an inverse OpLock.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<ol>
<li>Create the project from the following template:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch8/idempotence-inverse-oplock --path cncb-idempotence-inverse-oplock</pre>
<ol start="2">
<li>Navigate to the <kbd>cncb-idempotence-inverse-oplock</kbd> directory with <kbd>cd cncb-idempotence-inverse-oplock</kbd>.</li>
<li>Review the file named <kbd>serverless.yml</kbd>.</li>
<li>Review the file named <kbd>handler.js</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">module.exports.<strong>listener</strong> = (event, context, cb) =&gt; {<br/>  _(event.Records)<br/>    .map(recordToUow)<br/>    .filter(forThingSaved)<br/>    .flatMap(save)<br/>    .collect().toCallback(cb);<br/>};<br/><br/>const <strong>save</strong> = uow =&gt; {<br/>  const params = {<br/>    TableName: process.env.TABLE_NAME,<br/>    Item: {<br/>      ...uow.event.thing,<br/>      <strong>oplock</strong>: <strong>uow.event.timestamp</strong>,<br/>    },<br/>    <strong>ConditionExpression</strong>: 'attribute_not_exists(#oplock) OR #<strong>oplock</strong> &lt; :timestamp',<br/>    ...<br/>  };<br/><br/>  const db = new aws.DynamoDB.DocumentClient({<br/>    httpOptions: { timeout: 1000 },<br/>    logger: console,<br/>  });<br/><br/>  return _(db.put(params).promise()<br/>    .catch(<strong>handleConditionalCheckFailedException</strong>)<br/>    .then(() =&gt; uow)<br/>  );<br/>}<br/><br/>const <strong>handleConditionalCheckFailedException</strong> = (err) =&gt; {<br/>  if (err.code !== '<strong>ConditionalCheckFailedException</strong>') {<br/>    err.uow = uow;<br/>    throw err;<br/>  }<br/>};</pre>
<ol start="5">
<li>Install the dependencies with <kbd>npm install</kbd>.</li>
<li>Run the tests with <kbd>npm test -- -s $MY_STAGE</kbd>.</li>
<li>Review the contents generated in the <kbd>.serverless</kbd> directory.</li>
<li>Deploy the stack with <kbd>npm run dp:lcl -- -s $MY_STAGE</kbd>.</li>
<li>Review the stack and resources in the AWS Console.</li>
<li>Invoke the simulate function with the following command:</li>
</ol>
<pre style="padding-left: 30px">$ sls invoke -f simulate -r us-east-1 -s $MY_STAGE</pre>
<ol start="11">
<li>Take a look at the following <kbd>listener</kbd> function logs:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ sls logs -f listener -r us-east-1 -s $MY_STAGE</strong><br/><br/>... [AWS dynamodb <strong>200</strong> 0.098s 0 retries] putItem({ TableName: '...',<br/>  Item:<br/>   { id: { S: '3022eaeb-45b7-46d5-b0a1-696c0eb9aa25' },<br/>     oplock: { N: '<strong>1531628180237</strong>' } },<br/>...<br/>... [AWS dynamodb <strong>400</strong> 0.026s 0 retries] putItem({ TableName: '...',<br/>  Item:<br/>   { id: { S: '3022eaeb-45b7-46d5-b0a1-696c0eb9aa25' },<br/>     oplock: { N: '<strong>1531628180237</strong>' } },<br/>...<br/>... { ConditionalCheckFailedException: The conditionalrequest failed<br/>    at Request.extractError ...<br/>...<br/><strong>  message: 'The conditional request failed',</strong><br/>  code: 'ConditionalCheckFailedException',<br/>  time: 2018-07-15T04:16:21.202Z,<br/>  requestId: '36BB14IGTPGM8DE8CFQJS0ME3VVV4KQNSO5AEMVJF66Q9ASUAAJG',<br/>  statusCode: 400,<br/><strong>  retryable: false,</strong><br/>  retryDelay: 20.791698133966396 }<br/><br/>... [AWS dynamodb <strong>200</strong> 0.025s 0 retries] putItem({ TableName: '...',<br/>  Item:<br/>   { id: { S: '3022eaeb-45b7-46d5-b0a1-696c0eb9aa25' },<br/>     oplock: { N: '<strong>1531628181237</strong>' } },<br/>...<br/>... [AWS dynamodb <strong>400</strong> 0.038s 0 retries] putItem({ TableName: '...',<br/>  Item:<br/>   { id: { S: '3022eaeb-45b7-46d5-b0a1-696c0eb9aa25' },<br/>     oplock: { N: '<strong>1531628180237</strong>' } },<br/>...<br/>... { ConditionalCheckFailedException: The conditionalrequest failed<br/>    at Request.extractError ...<br/>...    <br/>  <strong>message: 'The conditional request failed',</strong><br/>...</pre>
<ol start="12">
<li>Remove the stack once you are finished with <kbd>npm run rm:lcl -- -s $MY_STAGE</kbd>.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>Traditional optimistic locking prevents multiple users from updating the same record at the same time. A record is only updated if the <kbd>oplock</kbd> field has not changed since the user retrieved the data. If the data has changed then an exception is thrown and the user is forced to retrieve the data again before proceeding with the update. This forces the updates to be performed sequentially, and it requires human interaction to resolve any potential conflicts.</p>
<p>The <strong>inverse OpLock</strong> is designed to provide idempotency for asynchronous processing. Instead of forcing the transaction to retry, we simply do the opposite—we drop the older or duplicate event. A traditional OpLock may be used in the upstream Backend For Frontend service to sequence user transactions, where, downstream services implement an inverse OpLock to ensure that older or duplicate events do not overwrite the most recent data. In this recipe, we use the <kbd>uow.event.timestamp</kbd> as the <kbd>oplock</kbd> value. In some scenarios, it may be preferential to use the sequence number if multiple events happen at the exact same millisecond. <kbd>ConditionalCheckFailedException</kbd> is caught and ignored. All other exceptions are re-thrown with the unit of work attached to cause a fault event to be published, as discussed in the <em>Handling faults</em> recipe.</p>
<p>The simulation in this recipe publishes a <kbd>thing-created</kbd> event, publishes it again, and then publishes a <kbd>thing-updated</kbd> event followed by the <kbd>thing-created</kbd> event a third time. The logs show that the <kbd>thing-created</kbd> event is only processed once and the duplicates are ignored.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementing idempotence with Event Sourcing</h1>
                
            
            
                
<p>From a business rule standpoint, it is important that events are processed exactly once; otherwise, problems may arise, such as double counting or not counting at all. However, our cloud-native systems must be resilient to failure and proactively retry to ensure no messages are dropped. Unfortunately, this means that messages may be delivered multiple times, such as when a producer re-publishes an event or a stream processor retries a batch that may have been partially processed. The solution to this problem is to implement all actions to be idempotent. This recipe demonstrates how to use Event Sourcing and a micro event store to implement idempotence.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How to do it...</h1>
                
            
            
                
<ol>
<li>Create the project from the following template:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch8/idempotence-es --path cncb-idempotence-es</pre>
<ol start="2">
<li>Navigate to the <kbd>cncb-idempotence-es</kbd> directory with <kbd>cd cncb-idempotence-es</kbd>.</li>
<li>Review the file named <kbd>serverless.yml</kbd>.</li>
<li>Review the file named <kbd>handler.js</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">module.exports.<strong>listener</strong> = (event, context, cb) =&gt; {<br/>  _(event.Records)<br/>    .map(recordToUow)<br/>    .filter(forThingSaved)<br/>    .flatMap(saveEvent)<br/>    .collect().toCallback(cb);<br/>};<br/><br/>const saveEvent = uow =&gt; {<br/>  const params = {<br/>    TableName: process.env.EVENTS_TABLE_NAME,<br/>    Item: {<br/><strong>      id: uow.event.thing.id,</strong><br/><strong>      sequence: uow.event.id,</strong><br/>      event: uow.event,<br/>    }<br/>  };<br/><br/>  const db = new aws.DynamoDB.DocumentClient({<br/>    httpOptions: { timeout: 1000 },<br/>    logger: console,<br/>  });<br/><br/>  return _(db.put(params).promise()<br/>    .then(() =&gt; uow)<br/>  );<br/>}</pre>
<ol start="5">
<li>Install the dependencies with <kbd>npm install</kbd>.</li>
<li>Run the tests with <kbd>npm test -- -s $MY_STAGE</kbd>.</li>
<li>Review the contents generated in the <kbd>.serverless</kbd> directory.</li>
<li>Deploy the stack with <kbd>npm run dp:lcl -- -s $MY_STAGE</kbd>.</li>
<li>Review the stack and resources in the AWS Console.</li>
<li>Invoke the simulate function with the following command:</li>
</ol>
<pre style="padding-left: 30px">$ sls invoke -f simulate -r us-east-1 -s $MY_STAGE</pre>
<ol start="11">
<li>Take a look at the following <kbd>trigger</kbd> function logs:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ sls logs -f trigger -r us-east-1 -s $MY_STAGE</strong><br/><br/>... record: { ... "Keys":{"sequence":{"S":"<strong>3fdb8c10</strong>-87ea-11e8-9cf5-0b6c5b83bdcb"},"id":{"S":"8c083ef9-d180-48b8-a773-db0f61815f38"}}, ...<br/><br/>... record: { ... "Keys":{"sequence":{"S":"<strong>3fdb8c11</strong>-87ea-11e8-9cf5-0b6c5b83bdcb"},"id":{"S":"8c083ef9-d180-48b8-a773-db0f61815f38"}}, ...<br/><br/></pre>
<ol start="12">
<li>Remove the stack once you are finished with <kbd>npm run rm:lcl -- -s $MY_STAGE</kbd></li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">How it works...</h1>
                
            
            
                
<p>Event Sourcing facilitates idempotence because events are immutable. The same event with the same unique ID can be published or processed multiple times with the same outcome. The micro event store serves as a buffer that weeds out duplicates. The service consumes desired events and stores them in a micro event store with a <strong>hashkey</strong> that groups related events, such as the <kbd>uow.event.thing.id</kbd> of the domain object, and a range key based on the <kbd>uow.event.id</kbd>. This primary key is also immutable. As a result, the same event can be saved multiple times, but only a single event is produced on the database stream. Thus, the business logic, which is discussed in the <em>Creating a micro event store</em> or <em>Implementing an analytics BFF</em> recipe, is only triggered once.</p>
<p>The simulation in this recipe publishes a <kbd>thing-created</kbd> event, publishes it again, and then publishes a <kbd>thing-updated</kbd> event followed by the <kbd>thing-created</kbd> event a third time. The logs show that the three <kbd>thing-created</kbd> event instances only result in a single event on the DynamoDB Stream.</p>


            

            
        
    </body></html>