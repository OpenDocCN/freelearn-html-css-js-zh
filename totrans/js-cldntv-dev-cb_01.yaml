- en: Getting Started with Cloud-Native
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, the following recipes will be covered:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a stack
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a function and working with metrics and logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating an event stream and publishing an event
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a stream processor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating an API Gateway
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying a single-page application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloud-native is lean. Companies today must continuously experiment with new
    product ideas so that they can adapt to changing market demands; otherwise, they
    risk falling behind their competition. To operate at this pace, they must leverage
    fully managed cloud services and fully-automated deployments to minimize time
    to market, mitigate operating risks, and empower self-sufficient, full-stack teams
    to accomplish far more with much less effort.
  prefs: []
  type: TYPE_NORMAL
- en: The recipes in this cookbook demonstrate how to use fully managed, serverless
    cloud services to develop and deploy lean and autonomous services. This chapter
    contains bare-boned recipes with no clutter in order to focus on the core aspects
    of deploying cloud-native components and to establish a solid foundation for the
    remainder of this cookbook.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a stack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each autonomous cloud-native service and all its resources are provisioned as
    a cohesive and self-contained group called a **stack**. On AWS, these are **CloudFormation**
    stacks. In this recipe, we will use the Serverless Framework to create and manage
    a bare-bones stack to highlight the steps involved in deploying a cloud-native
    service.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before starting this recipe, you will need to follow the instructions in the
    *Preface* for configuring your development environment with Node.js, the Serverless
    Framework, and AWS account credentials.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create the project from the following template:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Navigate to the `cncb-create-stack` directory with `cd cncb-create-stack`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Review the file named `serverless.yml` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Review the file named `package.json` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Install the dependencies with `npm install`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the tests with `npm test`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the contents generated in the `.serverless` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Deploy the stack:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Review the stack in the AWS Console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3effc87e-5bd7-48fe-86a8-2a3d087cc88a.png)'
  prefs: []
  type: TYPE_IMG
- en: Remove the stack once you have finished with `npm run rm:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Serverless Framework** (**SLS**) ([https://serverless.com/framework/docs](https://serverless.com/framework/docs))
    is my tool of choice for deploying cloud resources, regardless of whether or not
    I am deploying serverless resources, such as functions. SLS is essentially an
    abstraction layer on top of **infrastructure as code** tools, such as AWS CloudFormation,
    with extensibility features such as plugins and dynamic variables. We will use
    SLS in all of our recipes. Each recipe starts by using the SLS feature to `create`
    a new project by cloning a `template`. You will ultimately want to create your
    own templates for jump-starting your own projects.
  prefs: []
  type: TYPE_NORMAL
- en: This first project is as bare bones as we can get. It essentially creates an
    empty CloudFormation stack. In the `serverless.yml` file, we define the `service`
    name and the `provider`. The `service` name will be combined with the `stage`,
    which we will discuss shortly, to create a unique stack name within your account
    and `region`. I have prefixed all the stacks in our recipes with `cncb` to make
    it easy to filter for these stacks in the AWS Console if you are using a shared
    account, such as your development or sandbox account at work.
  prefs: []
  type: TYPE_NORMAL
- en: Our next most important tool is **Node Package Manager** (**NPM**) ([https://docs.npmjs.com/](https://docs.npmjs.com/)).
    We will not be packaging any Node modules (also known as libraries), but we will
    be leveraging NPM's dependency management and scripting features. In the `package.json`
    file, we declared a development dependency on the Serverless Framework and three
    custom scripts to test, deploy, and remove our stack. The first command we execute
    is `npm install`, which will install all the declared dependencies into the project's
    `node_modules` directory.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we execute the `npm test` script. This is one of several standard scripts
    for which NPM provides a shortcut alias. We have defined the `test` script to
    invoke the `sls package` command to assert that everything is configured properly
    and help us see what is going on under the covers. This command processes the
    `serverless.yml` file and generates a CloudFormation template in the `.serverless`
    directory. One of the advantages of the Serverless Framework is that it embodies
    best practices and uses a **configuration by exception** approach to take a small
    amount of declaration in the `serverless.yml` files and expand it into a much
    more verbose CloudFormation template.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we are ready to deploy the stack. As developers, we need to be able to
    deploy a stack and work on it in isolation from other developers and other environments,
    such as production. To support this requirement, SLS uses the concept of a **stage**.
    Stage (`-s $MY_STAGE`) and region (`-r us-east-1`) are two required command-line
    options when invoking an SLS command. A stack is deployed into a specific region
    and the stage is used as a prefix in the stack name to make it unique within an
    account and region. Using this feature, each developer can *deploy* (`dp`) what
    I refer to as a *local* (`lcl`) stack with their name as the stage with `npm run
    dp:lcl -- -s $MY_STAGE`. In the examples, I use my name for the stage. We declared
    the `$MY_STAGE` environment variable in the *Getting ready* section. The double
    dash (`--`) is NPM's way of letting us pass additional options to a custom script.
    In [Chapter 6](390bdaaf-5f53-4d65-8a6c-2e47c815f2b3.xhtml), *Building a Continuous
    Deployment Pipeline*, we will discuss deploying stacks to shared environments,
    such as **staging** and **production**.
  prefs: []
  type: TYPE_NORMAL
- en: CloudFormation has a limit regarding the template body size in a request to
    the API. Typical templates easily surpass this limit and must be uploaded to S3
    instead. The Serverless Framework handles this complexity for us. In the `.serverless`
    directory, you will notice that there is a `cloudformation-template-create-stack.json`
    file that declares a `ServerlessDeploymentBucket`. In the `sls deploy` output,
    you can see that SLS uses this template first and then it uploads the `cloudformation-template-update-stack.json` file
    to the bucket and updates the stack. It's nice to have this problem already solved
    for us because it is typical to learn about this limit the hard way.
  prefs: []
  type: TYPE_NORMAL
- en: At first glance, creating an empty stack may seem like a silly idea, but in
    practice it is actually quite useful. In a sense, you can think of CloudFormation
    as a CRUD tool for cloud resources. CloudFormation keeps track of the state of
    all the resources in a stack. It knows when a resource is new to a stack and must
    be created, when a resource has been removed from a stack and must be deleted,
    and when a resource has changed and must be updated. It also manages the dependencies
    and ordering between resources. Furthermore, when an update to a stack fails,
    it rolls back all the changes.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, when deploying a large number of changes, these rollbacks can
    be very time-consuming and painful when the error is in one of the last resources
    to be changed. Therefore, it is best to make changes to a stack in small increments.
    In [Chapter 6](390bdaaf-5f53-4d65-8a6c-2e47c815f2b3.xhtml), *Building a Continuous
    Deployment Pipeline*, we will discuss the practices of small batch sizes, task
    branch workflow, and decoupling deployment from release. For now, if you are creating
    a new service from a proven template, then initialize the new project and deploy
    the stack with all the template defaults all the way to production with your first
    pull request. Then, create a new branch for each incremental change. However,
    if you are working on an experimental service with no proven starting point, then
    an empty stack is perfectly reasonable for your first deployment to production.
  prefs: []
  type: TYPE_NORMAL
- en: In your daily development routine, it is important to clean up your local stacks
    when you have completed work on a task or story. The cost of a development account
    can creep surprisingly high when orphaned stacks accumulate and are rarely removed.
    The `npm run rm:lcl -- -s $MY_STAGE` script serves this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a function and working with metrics and logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Function-as-a-Service** is the cornerstone of cloud-native architecture.
    Functions enable self-sufficient, full-stack teams to focus on delivering lean
    business solutions without being weighed down by the complexity of running cloud
    infrastructure. There are no servers to manage, and functions implicitly scale
    to meet demand. They are integrated with other value-added cloud services, such
    as streams, databases, API gateways, logging, and metrics, to further accelerate
    development. Functions are disposable architecture, which empower teams to experiment
    with different solutions. This recipe demonstrates how straightforward it is to
    deploy a function.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create the project from the following template:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Navigate to the `cncb-create-function` directory with `cd cncb-create-function`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Review the file named `serverless.yml` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Review the file named `handler.js` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Install the dependencies with `npm install`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the tests with `npm test`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the contents generated in the `.serverless` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Deploy the stack:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Review the stack and function in the AWS Console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Invoke the function with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Review the function metrics in the AWS Console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/21c0d7ed-059d-417e-a2a9-6c0aa6232cd7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Review the function logs in the AWS Console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3a23c0ff-0fd6-4417-94c7-96702e0e6201.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Take a look at the logs locally:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Remove the stack once you have finished with `npm run rm:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Serverless Framework handles the heavy lifting, which allows us to focus
    on writing the actual function code. The first thing to note is that we must define
    the `runtime: nodejs8.10` in the `serverless.yml` file. Next, we define a function
    in the `functions` section with a name and a handler. All other settings have
    defaulted, following the **configuration by exception** approach. When you look
    at the generated CloudFormation template, you will see that over 100 lines were
    generated from just a handful of lines declared in the `serverless.yml` file.
    A large portion of the generated template is dedicated to defining boilerplate
    security policies. Dig into the `.serverless/cloudformation-template-update-stack.json`
    file to see the details.'
  prefs: []
  type: TYPE_NORMAL
- en: We also define `environment` variables in the serverless.yml. This allows the
    functions to be parameterized per deployment stage. We will cover this in more
    detail in [Chapter 6](390bdaaf-5f53-4d65-8a6c-2e47c815f2b3.xhtml), *Building a
    Continuous Deployment Pipeline*. This also allows settings, such as the debug
    level, to be temporarily tweaked without redeploying the function.
  prefs: []
  type: TYPE_NORMAL
- en: When we deploy the project, the Serverless Framework packages the function along
    with its runtime dependencies, as specified in the `package.json` file, into a
    ZIP file. Then, it uploads the ZIP file to the `ServerlessDeploymentBucket` so
    that it can be accessed by CloudFormation. The output of the deployment command
    shows when this is happening. You can look at the content of the ZIP file in the
    `.serverless` directory or download it from the deployment bucket. We will cover
    advanced packaging options in [Chapter 9](b2c8b5bd-dfe5-461e-a8fa-3e71c94e633c.xhtml),
    *Optimizing Performance*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The signature of an AWS Lambda function is straightforward. It must export
    a function that accepts three arguments: an event object, a context object, and
    a callback function. Our first function will just log the event, content, and
    the environment variables so that we can peer into the execution environment a
    little bit. Finally, we must invoke the callback. It is a standard JavaScript
    callback. We pass an error to the first argument or the successful result to the
    second argument.'
  prefs: []
  type: TYPE_NORMAL
- en: Logging is an important standard feature of **Function as a Service** (**FaaS**).
    Due to the ephemeral nature of cloud resources, logging in the cloud can be tedious,
    to put it lightly. In AWS Lambda, console logging is performed asynchronously
    and recorded in CloudWatch logs. It's a fully-managed logging solution built right
    in. Take the time to look at the details in the log statements that this function
    writes. The environment variables are particularly interesting. For example, we
    can see that each invocation of a function gets a new temporary access key.
  prefs: []
  type: TYPE_NORMAL
- en: Functions also provide a standard set of metrics out-of-the-box, such as invocation
    count, duration, errors, throttling, and so forth. We will cover this in detail
    in [Chapter 7](64a4c0f7-3b2d-4638-a52c-f72953ff66d9.xhtml), *Optimizing Observability*.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an event stream and publishing an event
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloud-native services are autonomous. Each service is completely self-sufficient
    and runs in isolation to minimize the blast radius when any given service experiences
    a failure. To achieve this isolation, *bulkheads* must be established between
    the services. **Event streaming** is one mechanism that is used to create these
    bulkheads. Autonomous cloud-native services perform all inter-service communication
    asynchronously via streams to decouple upstream services from downstream services.
    In [Chapter 2](129afdee-aa82-4ba6-9d80-5ec70c4a766e.xhtml), *Applying The Event
    Sourcing and CQRS Patterns*, we will dive deeper into how we create bounded, isolated,
    and autonomous cloud-native services. This recipe creates the event stream that
    we will use throughout this cookbook and provides a function for publishing events
    to the stream.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create the project from the following template:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Navigate to the `cncb-event-stream` directory with `cd cncb-event-stream`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Review the file named `serverless.yml` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Review the file named `handler.js` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Install the dependencies with `npm install`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the tests with `npm test`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the contents generated in the `.serverless` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Deploy the stack:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Review the stack, stream, and function in the AWS Console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Invoke the function with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the logs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Remove the stack once you have finished with `npm run rm:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This stack is a prerequisite for other recipes, as indicated in the *Getting
    ready* section of each recipe. If you are continuing with related recipes, then
    you can leave this stack running until you complete the related recipes. However,
    the stream in this stack is not included in the AWS free tier, so you may want
    to go ahead and remove this stack and recreate it when needed.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `resources` section of the `serverless.yml` file is used to create cloud
    resources that are used by services. These resources are defined using standard
    AWS CloudFormation resource types. In this recipe, we are creating an AWS *Kinesis*
    stream. We give the stream a name, define the retention period, and specify the
    number of shards. The Serverless Framework provides a robust mechanism for dynamically
    replacing variables.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we use the `${opt:stage}` option passed in on the command line and the
    `${self:service}` name defined in the `serverless.yml` file to create a unique
    stream name. The standard retention period is 24 hours and the maximum is seven
    days. For our recipes, one shard will be more than sufficient. We will discuss
    shards shortly and again in [Chapter 7](64a4c0f7-3b2d-4638-a52c-f72953ff66d9.xhtml),
    *Optimizing Observability*, and [Chapter 9](b2c8b5bd-dfe5-461e-a8fa-3e71c94e633c.xhtml),
    *Optimizing Performance*.
  prefs: []
  type: TYPE_NORMAL
- en: The `Outputs` section of the `serverless.yml` file is where we define values,
    such as generated IDs and names, that we want to use outside of the stack. We
    output the **Amazon Resource Names** (**ARNs**) `streamName` and `streamArn` so
    that we can reference them with Serverless Framework variables in other projects.
    These values are also displayed on the Terminal when a deployment is complete.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `publish` function defined in the `serverless.yml` file is used to demonstrate
    how to publish an event to the stream. We are passing the `STREAM_NAME` to the
    function as an environment variable. In the `iamRoleStatements` section, we give
    the function `kinesis: PutRecord` permission to allow it to publish events to
    this specific stream.'
  prefs: []
  type: TYPE_NORMAL
- en: The function `handler.js` file has runtime dependencies on two external libraries—`aws-sdk`
    and `uuid`. The Serverless Framework will automatically include the runtime dependencies,
    as defined in the `package.json` file. Take a look inside the generated `.serverless/cncb-event-stream.zip`
    file. The `aws-sdk` is a special case. It is already available in the AWS Lambda
    `Node.js` runtime, and therefore is not included. This is important because `aws-sdk`
    is a large library and the ZIP file size impacts cold start times. We will discuss
    this in more detail in [Chapter 9](b2c8b5bd-dfe5-461e-a8fa-3e71c94e633c.xhtml),
    *Optimizing Performance*.
  prefs: []
  type: TYPE_NORMAL
- en: The `publish` function expects to receive an event object as input, such as
    `{"type":"thing-created"}`. We then adorn the event with additional information
    to conform to our standard event format, which we will discuss shortly. Finally,
    the function creates the required `params` object and then calls `kinesis.putRecord`
    from the `aws-sdk`. We will be using this function in this and other recipes to
    simulate event traffic.
  prefs: []
  type: TYPE_NORMAL
- en: 'All events in our cloud-native systems will conform to the following **Event
    structure** to allow for consistent handling across all services. Additional fields
    are event-type-specific:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '`type` describes the event, such as `thing-created`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timestamp` is an epoch value, as returned from `Date.now()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`id` should be a V1 UUID, which is time-based'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`partitionKey` should be a V4 UUID, which is random number-based'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tags` is a hashmap of useful data values that are leveraged for content-based
    routing and aggregating event metrics'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is important to use a *V4 UUID* for the `partitionKey` to avoid hot shards
    and maximize concurrency. If a *V1 UUID* were used, then all events produced at
    the same time would go to the same shard. The `partitionKey` will typically be
    the ID of the domain entity that produced the event, which should use a V4 UUID
    for the same reason. This has the added benefit of ensuring that all events for
    the same domain entity are processed through the same shard in the order received.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a stream processor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Stream processors** do most of the heavy lifting in cloud-native services.
    Autonomous cloud-native services perform all inter-service communication asynchronously
    via event streaming to decouple upstream services from **downstream services**.
    **Upstream services** publish events to a stream, with no knowledge of the specific
    downstream services that will eventually consume the events. Downstream services
    deploy stream-processing functions to consume events of interest. Stream processors
    will be covered extensively throughout this cookbook. This recipe demonstrates
    how to create a function that listens for events from an **AWS Kinesis** stream
    and provides a quick introduction to using the functional reactive programming
    paradigm for implementing stream processing.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before starting this recipe, you will need an AWS Kinesis Stream, such as the
    one created in the *Creating an event stream* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create the project from the following template:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Navigate to the `cncb-create-stream-processor` directory with `cd cncb-create-stream-processor`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Review the file named `serverless.yml` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Review the file named `handler.js` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Install the dependencies with `npm install`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the tests with `npm test -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the contents generated in the `.serverless` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Deploy the stack:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Review the stack and function in the AWS Console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Publish an event from a separate Terminal with the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the logs from the original Terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Stream processors listen for data from a streaming service such as **Kinesis**
    or **DynamoDB Streams**. Deploying a stream processor is completely declarative.
    We configure a function with the `stream` event type and the pertinent settings,
    such as the `type`, `arn`, `batchSize`, and `startingPosition`. The `arn` is set
    dynamically using a CloudFormation variable, `${cf:cncb-event-stream-${opt:stage}.streamArn}`,
    that references the output value of the `cnbc-event-stream` stack.
  prefs: []
  type: TYPE_NORMAL
- en: Streams are the only resources that are shared between autonomous cloud-native
    services.
  prefs: []
  type: TYPE_NORMAL
- en: We will discuss batch size and starting position in detail in both [Chapter
    8](5c400ff6-91da-4782-9369-549622d4a0d1.xhtml), *Designing for Failure*, and [Chapter
    9](b2c8b5bd-dfe5-461e-a8fa-3e71c94e633c.xhtml), *Optimizing Performance*. For
    now, you may have noticed that the new stream processor logged all the events
    that were published to the stream in the last 24 hours. This is because the `startingPosition`
    is set to `TRIM_HORIZON`. If it was set to `LATEST`, then it would only receive
    events that were published after the function was created.
  prefs: []
  type: TYPE_NORMAL
- en: Stream processing is a perfect match for functional reactive programming with
    Node.js streams. The terminology can be a little confusing because the word *stream*
    is overloaded. I like to think of streams as either *macro* or *micro*. For example,
    Kinesis is the *macro* stream and the code in our stream processor function is
    the *micro* stream. My favorite library for implementing the *micro* stream is
    **Highland.js** ([https://highlandjs.org](https://highlandjs.org)). A popular
    alternative is **RxJS** ([https://rxjs-dev.firebaseapp.com](https://rxjs-dev.firebaseapp.com)).
    As you can see in this recipe, functional reactive programming is very descriptive
    and readable. One of the reasons for this is that there are no loops. If you try
    to implement a stream processor with *imperative programming*, you will find that
    it quickly gets very messy. You also lose backpressure, which we will discuss
    in [Chapter 8](5c400ff6-91da-4782-9369-549622d4a0d1.xhtml), *Designing for Failure*.
  prefs: []
  type: TYPE_NORMAL
- en: The code in the `listener` function creates a pipeline of steps that the data
    from the Kinesis stream will ultimately flow through. The first step, `_(event.Records)`,
    converts the array of Kinesis records into a Highland.js stream object that will
    allow each element in the array to be pulled through the stream in turn as the
    downstream steps are ready to receive the next element. The `.map(recordToEvent)`
    step decodes the Base64 encoded data from the Kinesis record and parses the JSON
    into an event object. The next step, `.tap(printEvent)`, simply logs the event
    so that we can see what is happening in the recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Kinesis and event streaming, in general, is a member of the high performance,
    dumb-pipe-smart-endpoints generation of messaging middleware. This means that
    Kinesis, the dumb pipe, does not waste its processing power on filtering data
    for the endpoints. Instead, all that logic is spread out across the processing
    power of the smart endpoints. Our stream processor function is the smart endpoint.
    To that end, the `.filter(forThingCreated)` step is responsible for filtering
    out the events that the processor is not interested in. All the remaining steps
    can assume that they are receiving the expected event types.
  prefs: []
  type: TYPE_NORMAL
- en: Our bare-boned stream processor needs something somewhat interesting but simple
    to do. So, we count and print the number of `thing-created` events in the batch.
    We have filtered out all other event types, so the `.collect()` step collects
    all the remaining events into an array. Then, the `.tap(printCount)` step logs
    the length of the array. Finally, the `.toCallback(cb)` step will invoke the callback
    function once all the data in the batch has been processed. At this point, the
    Kinesis checkpoint is advanced and the next batch of events is processed. We will
    cover error handling and how it relates to batches and checkpoints in [Chapter
    8](5c400ff6-91da-4782-9369-549622d4a0d1.xhtml), *Designing for Failure*.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an API Gateway
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An API Gateway is an essential element of cloud-native architecture. It provides
    a secure and performant perimeter at the boundaries of our cloud-native systems.
    The boundaries are where the system interacts with everything that is external
    to the system, including humans and other systems. We will leverage an API Gateway
    in the recipes that create boundary components such as a **Backend For Frontend** (**BFF**)
    or an External Service Gateway. This recipe demonstrates how straightforward it
    is to deploy an API Gateway.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create the project from the following template:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Navigate to the `cncb-create-api-gateway` directory with `cd cncb-create-api-gateway`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Review the file named `serverless.yml` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Review the file named `handler.js` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Install the dependencies with `npm install`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the tests with `npm test`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the contents generated in the `.serverless` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Deploy the stack:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Review the stack, API, and function in the AWS Console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Invoke the `endpoint` shown in the stack output in the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the logs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating an API Gateway is completely declarative. We just configure a function
    with the `http` event type and the pertinent settings, such as the `path` and
    `method`. All other settings have defaulted following the **configuration by exception**
    approach. When you look at the generated `.serverless/cloudformation-template-update-stack.json`
    file, you will see that over 100 lines were generated from just a handful of lines
    declared in the `serverless.yml` file. The API name is calculated based on the
    combination of the service name declared at the top of the `serverless.yml` file
    and the specified stage. There is a one-to-one mapping between a serverless project
    and an API Gateway. All the functions in the project declared with an `http` event
    are included in the API.
  prefs: []
  type: TYPE_NORMAL
- en: 'The signature of the function is the same as all others; however, the contents
    of the event and the expected response format are specific to the API Gateway
    service. The `event` contains the full contents of the HTTP request including
    the path, parameters, header, body, and more. The `response` requires a `statusCode`
    and options headers and body. The body must be a string, and the header must be
    an object. I declared the function with the `cors: true` setting so that the recipe
    could include a legitimate set of response headers. We will cover security in
    detail in [Chapter 5](75b256e5-1fe4-4c9e-ab56-28cef7a8a0ab.xhtml), *Securing Cloud-Native
    Systems*. For now, know that security features such as SSL, throttling, and DDoS
    protection are default features of the AWS API Gateway.'
  prefs: []
  type: TYPE_NORMAL
- en: The `endpoint` for the API Gateway is declared as a stack output and displayed
    after the stack is deployed. We will see ways to customize the endpoint in [Chapter
    4](766f325f-38d5-474b-bac2-79f8af7d01ae.xhtml), *Leveraging the Edge of the Cloud*,
    and in [Chapter 10](7ddedd13-fcee-4091-8566-02c9814cb782.xhtml), *Deploying to
    Multiple Regions*. Once you invoke the service, you will be able to see the details
    of the inputs and outputs, both in the HTTP response as it was coded and then
    in the function's logs. Take a look at the API Gateway in the AWS Console as well.
    However, the goal of automation and the *Serverless Framework* is to eliminate
    the need to make changes in the console. I looked at the API in the console while
    writing this book, but other than that I can't remember the last time I actually
    needed to go into the API Gateway console.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a single-page application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The cloud-native light bulb first turned on in my head when I realized I could
    deploy a single page application, such as Angular, to an S3 bucket and serve it
    up globally with no need for servers and load balancers whatsoever. This was my
    first cloud-native W*ow!* moment. It was the moment when I began to understand
    that cloud-native plays by an entirely different set of rules. The combination
    of S3 and a JavaScript-based UI delivers a web presentation tier with virtually
    limitless scalability, virtually no cost, and essentially no operation headaches.
    This recipe demonstrates how straightforward it is to deploy a single-page application.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create the project from the following template:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Navigate to the `cncb-deploy-spa` directory with `cd cncb-deploy-spa`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Review the file named `serverless.yml` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Review the file named `package.json` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Install the dependencies with `npm install`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the app locally with `npm start`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the tests with `npm test`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the contents generated in the `.serverless` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the app with `npm run build`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the contents generated in the `build` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Deploy the stack:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Review the stack and bucket in the AWS Console
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Browse to the `WebsiteURL` shown in the stack output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/da5cc4c6-148f-4d68-8592-85bebf07c8f9.png)'
  prefs: []
  type: TYPE_IMG
- en: Remove the stack once you have finished with `npm run rm:lcl -- -s $MY_STAGE`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first thing to notice is that we are using all the same development tools
    for the full stack. This is one of many advantages of using JavaScript for backend
    development. A single, self-sufficient, full-stack team can develop the frontend
    application and the BFF service with the same programming language. This can allow
    for more efficient utilization of team resources.
  prefs: []
  type: TYPE_NORMAL
- en: There are two new standard scripts—`start` and `build`. `npm start` will run
    the frontend app locally using Node.js as the web server. `npm run build` will
    prepare the application for deployment. I used the `react-scripts` library so
    as not to clutter the example with a detailed ReactJS build process. This recipe
    uses a small, canned ReactJS example for the same reason. I wanted an app that
    was just large enough to have something to deploy. ReactJS is not the focus of
    this recipe or cookbook. There are volumes already written on ReactJS and similar
    frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: We are creating an S3 bucket, `WebsiteBucket`, and configuring it as a website.
    The stack output displays the `WebsiteUrl` used to access the SPA. The SPA will
    be served from a bucket with no need for servers whatsoever. In this context,
    we can think of S3 as a global web server.
  prefs: []
  type: TYPE_NORMAL
- en: We are using a Serverless plugin for the first time in this recipe. The `serverless-spa-deploy`
    plugin will upload the SPA files from the `./build` directory after the stack
    is deployed. Note that we are not explicitly naming the bucket. CloudFormation
    will generate the name with a random suffix. This is important because bucket
    names must be globally unique. The plugin infers the generated bucket name. The
    plugin has sensible defaults that can be customized, such as to change the `CacheControl`
    headers for different files. The plugin also empties the bucket, before stack
    removal.
  prefs: []
  type: TYPE_NORMAL
- en: We will build on this architecture in [Chapter 4](766f325f-38d5-474b-bac2-79f8af7d01ae.xhtml),
    *Leveraging the Edge of the Cloud*.
  prefs: []
  type: TYPE_NORMAL
