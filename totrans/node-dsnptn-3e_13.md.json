["```js\nimport { createServer } from 'http'\nimport staticHandler from 'serve-handler'\nimport ws from 'ws'\n// serve static files\nconst server = createServer((req, res) => {                // (1)\n  return staticHandler(req, res, { public: 'www' })\n})\nconst wss = new ws.Server({ server })                      // (2)\nwss.on('connection', client => {\n  console.log('Client connected')\n  client.on('message', msg => {                            // (3)\n    console.log(`Message: ${msg}`)\n    broadcast(msg)\n  })\n})\nfunction broadcast (msg) {                                 // (4)\n  for (const client of wss.clients) {\n    if (client.readyState === ws.OPEN) {\n      client.send(msg)\n    }\n  }\n}\nserver.listen(process.argv[2] || 8080) \n```", "```js\n<!DOCTYPE html>\n<html>\n  <body>\n    Messages:\n    <div id=\"messages\"></div>\n    <form id=\"msgForm\">\n      <input type=\"text\" placeholder=\"Send a message\" id=\"msgBox\"/>\n      <input type=\"submit\" value=\"Send\"/>\n    </form>\n    <script>\n      const ws = new WebSocket(\n        `ws://${window.document.location.host}`\n      )\n      ws.onmessage = function (message) {\n        const msgDiv = document.createElement('div')\n        msgDiv.innerHTML = message.data\n        document.getElementById('messages').appendChild(msgDiv)\n      }\n      const form = document.getElementById('msgForm')\n      form.addEventListener('submit', (event) => {\n        event.preventDefault()\n        const message = document.getElementById('msgBox').value\n        ws.send(message)\n        document.getElementById('msgBox').value = ''\n      })\n    </script>\n  </body>\n</html> \n```", "```js\nnode index.js 8080 \n```", "```js\nnode index.js 8081 \n```", "```js\nimport { createServer } from 'http'\nimport staticHandler from 'serve-handler'\nimport ws from 'ws'\n**import** **Redis** **from****'ioredis'**                                // (1)\n**const** **redisSub =** **new** **Redis()**\n**const** **redisPub =** **new** **Redis()**\n// serve static files\nconst server = createServer((req, res) => {\n  return staticHandler(req, res, { public: 'www' })\n})\nconst wss = new ws.Server({ server })\nwss.on('connection', client => {\n  console.log('Client connected')\n  client.on('message', msg => {\n    console.log(`Message: ${msg}`)\n    **redisPub.publish(****'chat_messages'****, msg)**                 // (2)\n  })\n})\n**redisSub.subscribe(****'chat_messages'****)**                        // (3)\n**redisSub.on(****'message'****,** **(****channel, msg****) =>** **{**\n  for (const client of wss.clients) {\n    if (client.readyState === ws.OPEN) {\n      client.send(msg)\n    }\n  }\n})\nserver.listen(process.argv[2] || 8080) \n```", "```js\nnode index.js 8080\nnode index.js 8081\nnode index.js 8082 \n```", "```js\nimport { createServer } from 'http'\nimport staticHandler from 'serve-handler'\nimport ws from 'ws'\nimport yargs from 'yargs'                                    // (1)\nimport zmq from 'zeromq'\n// serve static files\nconst server = createServer((req, res) => {\n  return staticHandler(req, res, { public: 'www' })\n})\nlet pubSocket\nasync function initializeSockets () {\n  pubSocket = new zmq.Publisher()                            // (2)\n  await pubSocket.bind(`tcp://127.0.0.1:${yargs.argv.pub}`)\n  const subSocket = new zmq.Subscriber()                     // (3)\n  const subPorts = [].concat(yargs.argv.sub)\n  for (const port of subPorts) {\n    console.log(`Subscribing to ${port}`)\n    subSocket.connect(`tcp://127.0.0.1:${port}`)\n  }\n  subSocket.subscribe('chat')\n  for await (const [msg] of subSocket) {                     // (4)\n    console.log(`Message from another server: ${msg}`)\n    broadcast(msg.toString().split(' ')[1])\n  }\n}\ninitializeSockets()\nconst wss = new ws.Server({ server })\nwss.on('connection', client => {\n  console.log('Client connected')\n  client.on('message', msg => {\n    console.log(`Message: ${msg}`)\n    broadcast(msg)\n    pubSocket.send(`chat ${msg}`)                            // (5)\n  })\n})\nfunction broadcast (msg) {\n  for (const client of wss.clients) {\n    if (client.readyState === ws.OPEN) {\n      client.send(msg)\n    }\n  }\n}\nserver.listen(yargs.argv.http || 8080) \n```", "```js\nnode index.js --http 8080 --pub 5000 --sub 5001 --sub 5002\nnode index.js --http 8081 --pub 5001 --sub 5000 --sub 5002\nnode index.js --http 8082 --pub 5002 --sub 5000 --sub 5001 \n```", "```js\nimport { createServer } from 'http'\nimport level from 'level'\nimport timestamp from 'monotonic-timestamp'\nimport JSONStream from 'JSONStream'\nimport amqp from 'amqplib'\nasync function main () {\n  const db = level('./msgHistory')\n  const connection = await amqp.connect('amqp://localhost')  // (1)\n  const channel = await connection.createChannel()\n  await channel.assertExchange('chat', 'fanout')             // (2)\n  const { queue } = channel.assertQueue('chat_history')      // (3)\n  await channel.bindQueue(queue, 'chat')                     // (4)\n  channel.consume(queue, async msg => {                      // (5)\n    const content = msg.content.toString()\n    console.log(`Saving message: ${content}`)\n    await db.put(timestamp(), content)\n    channel.ack(msg)\n  })\n  createServer((req, res) => {\n    res.writeHead(200)\n    db.createValueStream()\n      .pipe(JSONStream.stringify())\n      .pipe(res)\n  }).listen(8090)\n}\nmain().catch(err => console.error(err)) \n```", "```js\nimport { createServer } from 'http'\nimport staticHandler from 'serve-handler'\nimport ws from 'ws'\nimport amqp from 'amqplib'\nimport JSONStream from 'JSONStream'\nimport superagent from 'superagent'\nconst httpPort = process.argv[2] || 8080\nasync function main () {\n  const connection = await amqp.connect('amqp://localhost')\n  const channel = await connection.createChannel()\n  await channel.assertExchange('chat', 'fanout')\n  const { queue } = await channel.assertQueue(               // (1)\n    `chat_srv_${httpPort}`,\n    { exclusive: true }\n  )\n  await channel.bindQueue(queue, 'chat')\n  channel.consume(queue, msg => {                            // (2)\n    msg = msg.content.toString()\n    console.log(`From queue: ${msg}`)\n    broadcast(msg)\n  }, { noAck: true })\n  // serve static files\n  const server = createServer((req, res) => {\n    return staticHandler(req, res, { public: 'www' })\n  })\n  const wss = new ws.Server({ server })\n  wss.on('connection', client => {\n    console.log('Client connected')\n    client.on('message', msg => {\n      console.log(`Message: ${msg}`)\n      channel.publish('chat', '', Buffer.from(msg))          // (3)\n    })\n    // query the history service\n    superagent                                               // (4)\n      .get('http://localhost:8090')\n      .on('error', err => console.error(err))\n      .pipe(JSONStream.parse('*'))\n      .on('data', msg => client.send(msg))\n  })\n  function broadcast (msg) {\n    for (const client of wss.clients) {\n      if (client.readyState === ws.OPEN) {\n        client.send(msg)\n      }\n    }\n  }\n  server.listen(httpPort)\n}\nmain().catch(err => console.error(err)) \n```", "```js\nnode index.js 8080\nnode index.js 8081\nnode historySvc.js \n```", "```js\nimport { createServer } from 'http'\nimport staticHandler from 'serve-handler'\nimport ws from 'ws'\nimport Redis from 'ioredis'\nconst redisClient = new Redis()\nconst redisClientXRead = new Redis()\n// serve static files\nconst server = createServer((req, res) => {\n  return staticHandler(req, res, { public: 'www' })\n})\nconst wss = new ws.Server({ server })\nwss.on('connection', async client => {\n  console.log('Client connected')\n  client.on('message', msg => {\n    console.log(`Message: ${msg}`)\n    redisClient.xadd('chat_stream', '*', 'message', msg)     // (1)\n  })\n  // Load message history\n  const logs = await redisClient.xrange(                     // (2)\n    'chat_stream', '-', '+')\n  for (const [, [, message]] of logs) {\n    client.send(message)\n  }\n})\nfunction broadcast (msg) {\n  for (const client of wss.clients) {\n    if (client.readyState === ws.OPEN) {\n      client.send(msg)\n    }\n  }\n}\nlet lastRecordId = '$'\nasync function processStreamMessages () {                    // (3)\n  while (true) {\n    const [[, records]] = await redisClientXRead.xread(\n      'BLOCK', '0', 'STREAMS', 'chat_stream', lastRecordId)\n    for (const [recordId, [, message]] of records) {\n      console.log(`Message from stream: ${message}`)\n      broadcast(message)\n      lastRecordId = recordId\n    }\n  }\n}\nprocessStreamMessages().catch(err => console.error(err))\nserver.listen(process.argv[2] || 8080) \n```", "```js\nfor (const [, [, message]] of logs) {...} \n```", "```js\nfor (const [recordId, [propertyId, message]] of logs) {...} \n```", "```js\n[\n  [\"1588590110918-0\", [\"message\", \"This is a message\"]],\n  [\"1588590130852-0\", [\"message\", \"This is another message\"]]\n] \n```", "```js\nexport function * generateTasks (searchHash, alphabet,\n  maxWordLength, batchSize) {\n  let nVariations = 0\n  for (let n = 1; n <= maxWordLength; n++) {\n    nVariations += Math.pow(alphabet.length, n)\n  }\n  console.log('Finding the hashsum source string over ' +\n    `${nVariations} possible variations`)\n  let batchStart = 1\n  while (batchStart <= nVariations) {\n    const batchEnd = Math.min(\n      batchStart + batchSize - 1, nVariations)\n    yield {\n      searchHash,\n      alphabet: alphabet,\n      batchStart,\n      batchEnd\n    }\n    batchStart = batchEnd + 1\n  }\n} \n```", "```js\nimport zmq from 'zeromq'\nimport delay from 'delay'\nimport { generateTasks } from './generateTasks.js'\nconst ALPHABET = 'abcdefghijklmnopqrstuvwxyz'\nconst BATCH_SIZE = 10000\nconst [, , maxLength, searchHash] = process.argv\nasync function main () {\n  const ventilator = new zmq.Push()                          // (1)\n  await ventilator.bind('tcp://*:5016')\n  await delay(1000) // wait for all the workers to connect\n  const generatorObj = generateTasks(searchHash, ALPHABET,\n    maxLength, BATCH_SIZE)\n  for (const task of generatorObj) {\n    await ventilator.send(JSON.stringify(task))              // (2)\n  }\n}\nmain().catch(err => console.error(err)) \n```", "```js\nimport isv from 'indexed-string-variation'\nimport { createHash } from 'crypto'\nexport function processTask (task) {\n  const variationGen = isv.generator(task.alphabet)\n  console.log('Processing from ' +\n    `${variationGen(task.batchStart)} (${task.batchStart}) ` +\n    `to ${variationGen(task.batchEnd)} (${task.batchEnd})`)\n  for (let idx = task.batchStart; idx <= task.batchEnd; idx++) {\n    const word = variationGen(idx)\n    const shasum = createHash('sha1')\n    shasum.update(word)\n    const digest = shasum.digest('hex')\n    if (digest === task.searchHash) {\n      return word\n    }\n  }\n} \n```", "```js\nimport zmq from 'zeromq'\nimport { processTask } from './processTask.js'\nasync function main () {\n  const fromVentilator = new zmq.Pull()\n  const toSink = new zmq.Push()\n  fromVentilator.connect('tcp://localhost:5016')\n  toSink.connect('tcp://localhost:5017')\n  for await (const rawMessage of fromVentilator) {\n    const found = processTask(JSON.parse(rawMessage.toString()))\n    if (found) {\n      console.log(`Found! => ${found}`)\n      await toSink.send(`Found: ${found}`)\n    }\n  }\n}\nmain().catch(err => console.error(err)) \n```", "```js\nimport zmq from 'zeromq'\nasync function main () {\n  const sink = new zmq.Pull()\n  await sink.bind('tcp://*:5017')\n  for await (const rawMessage of sink) {\n    console.log('Message from worker: ', rawMessage.toString())\n  }\n}\nmain().catch(err => console.error(err)) \n```", "```js\nnode worker.js\nnode worker.js\nnode collector.js \n```", "```js\nnode producer.js 4 f8e966d1e207d02c44511a58dccff2f5429e9a3b \n```", "```js\nimport amqp from 'amqplib'\nimport { generateTasks } from './generateTasks.js'\nconst ALPHABET = 'abcdefghijklmnopqrstuvwxyz'\nconst BATCH_SIZE = 10000\nconst [, , maxLength, searchHash] = process.argv\nasync function main () {\n  const connection = await amqp.connect('amqp://localhost')\n  const channel = await connection.createConfirmChannel()    // (1)\n  await channel.assertQueue('tasks_queue')\n  const generatorObj = generateTasks(searchHash, ALPHABET,\n    maxLength, BATCH_SIZE)\n  for (const task of generatorObj) {\n    channel.sendToQueue('tasks_queue',                       // (2)\n      Buffer.from(JSON.stringify(task)))\n  }\n  await channel.waitForConfirms()\n  channel.close()\n  connection.close()\n}\nmain().catch(err => console.error(err)) \n```", "```js\nimport amqp from 'amqplib'\nimport { processTask } from './processTask.js'\nasync function main () {\n  const connection = await amqp.connect('amqp://localhost')\n  const channel = await connection.createChannel()\n  const { queue } = await channel.assertQueue('tasks_queue')\n  channel.consume(queue, async (rawMessage) => {\n    const found = processTask(\n      JSON.parse(rawMessage.content.toString()))\n    if (found) {\n      console.log(`Found! => ${found}`)\n      await channel.sendToQueue('results_queue',\n        Buffer.from(`Found: ${found}`))\n    }\n    await channel.ack(rawMessage)\n  })\n}\nmain().catch(err => console.error(err)) \n```", "```js\nimport amqp from 'amqplib'\nasync function main () {\n  const connection = await amqp.connect('amqp://localhost')\n  const channel = await connection.createChannel()\n  const { queue } = await channel.assertQueue('results_queue')\n  channel.consume(queue, msg => {\n    console.log(`Message from worker: ${msg.content.toString()}`)\n  })\n}\nmain().catch(err => console.error(err)) \n```", "```js\nnode worker.js\nnode worker.js \n```", "```js\nnode collector.js\nnode producer.js 4 f8e966d1e207d02c44511a58dccff2f5429e9a3b \n```", "```js\nimport Redis from 'ioredis'\nimport { generateTasks } from './generateTasks.js'\nconst ALPHABET = 'abcdefghijklmnopqrstuvwxyz'\nconst BATCH_SIZE = 10000\nconst redisClient = new Redis()\nconst [, , maxLength, searchHash] = process.argv\nasync function main () {\n  const generatorObj = generateTasks(searchHash, ALPHABET,\n    maxLength, BATCH_SIZE)\n  for (const task of generatorObj) {\n    await redisClient.xadd('tasks_stream', '*',\n      'task', JSON.stringify(task))\n  }\n  redisClient.disconnect()\n}\nmain().catch(err => console.error(err)) \n```", "```js\nimport Redis from 'ioredis'\nimport { processTask } from './processTask.js'\nconst redisClient = new Redis()\nconst [, , consumerName] = process.argv\nasync function main () {\n  await redisClient.xgroup('CREATE', 'tasks_stream',         // (1)\n    'workers_group', '$', 'MKSTREAM')\n    .catch(() => console.log('Consumer group already exists'))\n  const [[, records]] = await redisClient.xreadgroup(        // (2)\n    'GROUP', 'workers_group', consumerName, 'STREAMS',\n    'tasks_stream', '0')\n  for (const [recordId, [, rawTask]] of records) {\n    await processAndAck(recordId, rawTask)\n  }\n  while (true) {\n    const [[, records]] = await redisClient.xreadgroup(      // (3)\n      'GROUP', 'workers_group', consumerName, 'BLOCK', '0',\n      'COUNT', '1', 'STREAMS', 'tasks_stream', '>')\n    for (const [recordId, [, rawTask]] of records) {\n      await processAndAck(recordId, rawTask)\n    }\n  }\n}\nasync function processAndAck (recordId, rawTask) {           // (4)\n  const found = processTask(JSON.parse(rawTask))\n  if (found) {\n    console.log(`Found! => ${found}`)\n    await redisClient.xadd('results_stream', '*', 'result',\n      `Found: ${found}`)\n  }\n  await redisClient.xack('tasks_stream', 'workers_group', recordId)\n}\nmain().catch(err => console.error(err)) \n```", "```js\nnode worker.js workerA\nnode worker.js workerB \n```", "```js\nnode collector.js\nnode producer.js 4 f8e966d1e207d02c44511a58dccff2f5429e9a3b \n```", "```js\nimport { nanoid } from 'nanoid'\nexport function createRequestChannel (channel) {             // (1)\n  const correlationMap = new Map()\n  function sendRequest (data) {                              // (2)\n    console.log('Sending request', data)\n    return new Promise((resolve, reject) => {\n      const correlationId = nanoid()\n      const replyTimeout = setTimeout(() => {\n        correlationMap.delete(correlationId)\n        reject(new Error('Request timeout'))\n      }, 10000)\n      correlationMap.set(correlationId, (replyData) => {\n        correlationMap.delete(correlationId)\n        clearTimeout(replyTimeout)\n        resolve(replyData)\n      })\n      channel.send({\n        type: 'request',\n        data,\n        id: correlationId\n      })\n    })\n  }\n  channel.on('message', message => {                         // (3)\n    const callback = correlationMap.get(message.inReplyTo)\n    if (callback) {\n      callback(message.data)\n    }\n  })\n  return sendRequest\n} \n```", "```js\nexport function createReplyChannel (channel) {\n  return function registerHandler (handler) {\n    channel.on('message', async message => {\n      if (message.type !== 'request') {\n        return\n      }\n      const replyData = await handler(message.data)      // (1)\n      channel.send({                                     // (2)\n        type: 'response',\n        data: replyData,\n        inReplyTo: message.id\n      })\n    })\n  }\n} \n```", "```js\nimport { createReplyChannel } from './createReplyChannel.js'\nconst registerReplyHandler = createReplyChannel(process)\nregisterReplyHandler(req => {\n  return new Promise(resolve => {\n    setTimeout(() => {\n      resolve({ sum: req.a + req.b })\n    }, req.delay)\n  })\n})\nprocess.send('ready') \n```", "```js\nimport { fork } from 'child_process'\nimport { dirname, join } from 'path'\nimport { fileURLToPath } from 'url'\nimport { once } from 'events'\nimport { createRequestChannel } from './createRequestChannel.js'\nconst __dirname = dirname(fileURLToPath(import.meta.url))\nasync function main () {\n  const channel = fork(join(__dirname, 'replier.js'))          // (1)\n  const request = createRequestChannel(channel)\n  try {\n    const [message] = await once(channel, 'message')       // (2)\n    console.log(`Child process initialized: ${message}`)\n    const p1 = request({ a: 1, b: 2, delay: 500 })         // (3)\n      .then(res => {\n        console.log(`Reply: 1 + 2 = ${res.sum}`)\n      })\n    const p2 = request({ a: 6, b: 1, delay: 100 })         // (4)\n      .then(res => {\n        console.log(`Reply: 6 + 1 = ${res.sum}`)\n      })\n    await Promise.all([p1, p2])                            // (5)\n  } finally {\n    channel.disconnect()                                   // (6)\n  }\n}\nmain().catch(err => console.error(err)) \n```", "```js\nChild process initialized: ready\nSending request { a: 1, b: 2, delay: 500 }\nSending request { a: 6, b: 1, delay: 100 }\nReply: 6 + 1 = 7\nReply: 1 + 2 = 3 \n```", "```js\nexport class AMQPRequest {\n  constructor () {\n    this.correlationMap = new Map()\n  }\n  //... \n```", "```js\nasync initialize () {\n  this.connection = await amqp.connect('amqp://localhost')\n  this.channel = await this.connection.createChannel()\n  const { queue } = await this.channel.assertQueue('',       // (1)\n    { exclusive: true })\n  this.replyQueue = queue\n  this.channel.consume(this.replyQueue, msg => {             // (2)\n    const correlationId = msg.properties.correlationId\n    const handler = this.correlationMap.get(correlationId)\n    if (handler) {\n      handler(JSON.parse(msg.content.toString()))\n    }\n  }, { noAck: true })\n} \n```", "```js\nsend (queue, message) {\n  return new Promise((resolve, reject) => {\n    const id = nanoid()                                    // (1)\n    const replyTimeout = setTimeout(() => {\n      this.correlationMap.delete(id)\n      reject(new Error('Request timeout'))\n    }, 10000)\n    this.correlationMap.set(id, (replyData) => {           // (2)\n      this.correlationMap.delete(id)\n      clearTimeout(replyTimeout)\n      resolve(replyData)\n    })\n    this.channel.sendToQueue(queue,                        // (3)\n      Buffer.from(JSON.stringify(message)),\n      { correlationId: id, replyTo: this.replyQueue }\n    )\n  })\n} \n```", "```js\n destroy () {\n    this.channel.close()\n    this.connection.close()\n  }\n} \n```", "```js\nimport amqp from 'amqplib'\nexport class AMQPReply {\n  constructor (requestsQueueName) {\n    this.requestsQueueName = requestsQueueName\n  }\n  async initialize () {\n    const connection = await amqp.connect('amqp://localhost')\n    this.channel = await connection.createChannel()\n    const { queue } = await this.channel.assertQueue(        // (1)\n      this.requestsQueueName)\n    this.queue = queue\n  }\n  handleRequests (handler) {                                 // (2)\n    this.channel.consume(this.queue, async msg => {\n      const content = JSON.parse(msg.content.toString())\n      const replyData = await handler(content)\n      this.channel.sendToQueue(                              // (3)\n        msg.properties.replyTo,\n        Buffer.from(JSON.stringify(replyData)),\n        { correlationId: msg.properties.correlationId }\n      )\n      this.channel.ack(msg)\n    })\n  }\n} \n```", "```js\nimport { AMQPReply } from './amqpReply.js'\nasync function main () {\n  const reply = new AMQPReply('requests_queue')\n  await reply.initialize()\n  reply.handleRequests(req => {\n    console.log('Request received', req)\n    return { sum: req.a + req.b }\n  })\n}\nmain().catch(err => console.error(err)) \n```", "```js\nimport { AMQPRequest } from './amqpRequest.js'\nimport delay from 'delay'\nasync function main () {\n  const request = new AMQPRequest()\n  await request.initialize()\n  async function sendRandomRequest () {\n    const a = Math.round(Math.random() * 100)\n    const b = Math.round(Math.random() * 100)\n    const reply = await request.send('requests_queue', { a, b })\n    console.log(`${a} + ${b} = ${reply.sum}`)\n  }\n  for (let i = 0; i < 20; i++) {\n    await sendRandomRequest()\n    await delay(1000)\n  }\n  request.destroy()\n}\nmain().catch(err => console.error(err)) \n```", "```js\nnode replier.js\nnode requestor.js\nnode requestor.js \n```"]