<html><head></head><body>
  <div><h1 class="chapterNumber">11</h1>
    <h1 id="_idParaDest-293" class="chapterTitle">Advanced Recipes</h1>
    <p class="normal">In this chapter, we'll take a problem-solution approach and, like in a cookbook, we'll present a set of ready-to-use <em class="italic">recipes</em> to solve some common Node.js programming problems.</p>
    <p class="normal">You shouldn't be surprised by the fact that most of the problems presented in this chapter arise when we try to do things asynchronously. In fact, as we've seen repeatedly in the previous chapters of this book, tasks that are trivial in traditional synchronous programming can become more complicated when applied to asynchronous programming. A typical example is trying to use a component that requires an asynchronous initialization step. In this case, we have the inconvenience of delaying any attempt to use the component until the initialization completes. We'll show you how to solve this elegantly later.</p>
    <p class="normal">But this chapter is not just about recipes involving asynchronous programming. You will also learn the best ways to run CPU-intensive tasks in Node.js.</p>
    <p class="normal">These are the recipes you will learn in this chapter:</p>
    <ul>
      <li class="Bullet--PACKT-">Dealing with asynchronously initialized components</li>
      <li class="Bullet--PACKT-">Asynchronous request batching and caching</li>
      <li class="Bullet--PACKT-">Canceling asynchronous operations</li>
      <li class="Bullet-End--PACKT-">Running CPU-bound tasks</li>
    </ul>
    <p class="normal">Let's get started.</p>
    <h1 id="_idParaDest-294" class="title">Dealing with asynchronously initialized components</h1>
    <p class="normal">One of the reasons for the existence of synchronous APIs in the Node.js core modules <a id="_idIndexMarker1000"/>and many npm packages is because they are handy to use for implementing initialization tasks. For simple programs, using synchronous APIs at initialization time can streamline things a lot and the drawbacks associated with their use remain contained because they are used only once, which is when the program or a particular component is initialized.</p>
    <p class="normal">Unfortunately, this is not always possible. A synchronous API might not always be available, especially for components using the network during their initialization phase to, for example, perform handshake protocols or to retrieve configuration parameters. This is the case for many database drivers and clients for middleware systems such as message queues.</p>
    <h2 id="_idParaDest-295" class="title">The issue with asynchronously initialized components</h2>
    <p class="normal">Let's consider an example where a module called <code class="Code-In-Text--PACKT-">db</code> is used to interact with a remote database. The <code class="Code-In-Text--PACKT-">db</code> module will accept API requests only after the connection and handshake <a id="_idIndexMarker1001"/>with the database server have been successfully completed. Therefore, no queries or other commands can be sent until the initialization phase is complete. The following is the code for such a sample module (the <code class="Code-In-Text--PACKT-">db.js</code> file):</p>
    <pre class="programlisting code"><code class="hljs-code">import { EventEmitter } from 'events'
class DB extends EventEmitter {
  connected = false
  connect () {
    // simulate the delay of the connection
    setTimeout(() =&gt; {
      this.connected = true
      this.emit('connected')
    }, 500)
  }
  async query (queryString) {
    if (!this.connected) {
      throw new Error('Not connected yet')
    }
    console.log(`Query executed: ${queryString}`)
  }
}
export const db = new DB()
</code></pre>
    <p class="normal">This is a <a id="_idIndexMarker1002"/>typical example of an asynchronously initialized component. Under these assumptions, we usually have two quick and easy solutions to this problem, which we can call <em class="italic">local initialization check</em> and <em class="italic">delayed startup</em>. Let's analyze them in more detail.</p>
    <h3 id="_idParaDest-296" class="title">Local initialization check</h3>
    <p class="normal">The first solution makes sure that the module is initialized before any of its APIs are <a id="_idIndexMarker1003"/>invoked; otherwise, we wait for its initialization. This check has to be done every time we want to invoke an operation on the asynchronous module:</p>
    <pre class="programlisting code"><code class="hljs-code">import { once } from 'events'
import { db } from './db.js'
db.connect()
async function updateLastAccess () {
  if (!db.connected) {
    await once(db, 'connected')
  }
  await db.query(`INSERT (${Date.now()}) INTO "LastAccesses"`)
}
updateLastAccess()
setTimeout(() =&gt; {
  updateLastAccess()
}, 600)
</code></pre>
    <p class="normal">As we already anticipated, any time we want to invoke the <code class="Code-In-Text--PACKT-">query()</code> method on the <code class="Code-In-Text--PACKT-">db</code> component, we have to check if the module is initialized; otherwise, we wait for its initialization by listening for the <code class="Code-In-Text--PACKT-">'connected'</code> event. A variation of this technique performs the check inside the <code class="Code-In-Text--PACKT-">query()</code> method itself, which shifts the burden of the boilerplate code from the consumer to the provider of the service.</p>
    <h3 id="_idParaDest-297" class="title">Delayed startup</h3>
    <p class="normal">The second quick and dirty solution to the problem of asynchronously initialized components <a id="_idIndexMarker1004"/>involves delaying the execution of any code relying on the asynchronously initialized component until the component has finished its initialization routine. We can see an example of such a technique in the following code fragment:</p>
    <pre class="programlisting code"><code class="hljs-code">import { db } from './db.js'
import { once } from 'events'
async function initialize () {
  db.connect()
  await once(db, 'connected')
}
async function updateLastAccess () {
  await db.query(`INSERT (${Date.now()}) INTO "LastAccesses"`)
}
initialize()
  .then(() =&gt; {
    updateLastAccess()
    setTimeout(() =&gt; {
      updateLastAccess()
    }, 600)
  })
</code></pre>
    <p class="normal">As we can see from the preceding code, we first wait for the initialization to complete, and then we proceed with executing any routine that uses the <code class="Code-In-Text--PACKT-">db</code> object.</p>
    <p class="normal">The main disadvantage of this technique is that it requires us to know, in advance, which components will make use of the asynchronously initialized component, which makes our code fragile and exposed to mistakes. One solution to this problem is delaying the startup of the entire application until all the asynchronous services are initialized. This has the advantage of being simple and effective; however, it can add a significant delay to the overall startup time of the application and moreover, it won't take into account the case in which the asynchronously initialized component has to be reinitialized.</p>
    <p class="normal">As we <a id="_idIndexMarker1005"/>will see in the next section, there is a third alternative that allows us to transparently and efficiently delay every operation until the asynchronous initialization step has completed.</p>
    <h2 id="_idParaDest-298" class="title">Pre-initialization queues</h2>
    <p class="normal">Another recipe to make sure that the services of a component are invoked only after the component <a id="_idIndexMarker1006"/>is initialized involves the use of queues and the Command pattern. The idea is to queue the method invocations (only those requiring the component to be initialized) received while the component is not yet initialized, and then execute them as soon as all the initialization steps have been completed.</p>
    <p class="normal">Let's see how this technique can be applied to our sample <code class="Code-In-Text--PACKT-">db</code> component:</p>
    <pre class="programlisting code"><code class="hljs-code">import { EventEmitter } from 'events'
class DB extends EventEmitter {
  connected = false
  commandsQueue = []
  async query (queryString) {
    if (!this.connected) {
      console.log(`Request queued: ${queryString}`)
      return new Promise((resolve, reject) =&gt; {            // (1)
        const command = () =&gt; {
          this.query(queryString)
            .then(resolve, reject)
        }
        this.commandsQueue.push(command)
      })
    }
    console.log(`Query executed: ${queryString}`)
  }
  connect () {
    // simulate the delay of the connection
    setTimeout(() =&gt; {
      this.connected = true
      this.emit('connected')
      this.commandsQueue.forEach(command =&gt; command())     // (2)
      this.commandsQueue = []
    }, 500)
  }
}
export const db = new DB()
</code></pre>
    <p class="normal">As we <a id="_idIndexMarker1007"/>already mentioned, the technique described here consists of two parts:</p>
    <ol>
      <li class="numbered">If the component has not been initialized—which, in our case, is when the <code class="Code-In-Text--PACKT-">connected</code> property is <code class="Code-In-Text--PACKT-">false</code>—we create a command from the parameters received with the current invocation and push it to the <code class="Code-In-Text--PACKT-">commandsQueue</code> array. When the command is executed, it will run the original <code class="Code-In-Text--PACKT-">query()</code> method again and forward the result to the <code class="Code-In-Text--PACKT-">Promise</code> we are returning to the caller.</li>
      <li class="numbered">When the initialization of the component is completed—which, in our case, means that the connection with the database server is established—we go through the <code class="Code-In-Text--PACKT-">commandsQueue</code>, executing all the commands that have been previously queued.</li>
    </ol>
    <p class="normal">With the <code class="Code-In-Text--PACKT-">DB</code> class we just implemented, there is no need to check if the component is initialized before invoking its methods. In fact, all the logic is embedded in the component itself and any consumer can just transparently use it without worrying about its initialization status.</p>
    <p class="normal">We can also go a step further and try to reduce the boilerplate of the <code class="Code-In-Text--PACKT-">DB</code> class we just created and, at the same time, improve its modularity. We can achieve that by applying the State pattern, which we learned about in <em class="chapterRef">Chapter 9</em>, <em class="italic">Behavioral Design Patterns</em>, with two states:</p>
    <ul>
      <li class="Bullet--PACKT-">The first state implements all the methods that require the component to be initialized, and it's activated only when there is a successful initialization. Each of these methods implements its own business logic without worrying about the initialization status of the <code class="Code-In-Text--PACKT-">db</code> component</li>
      <li class="Bullet-End--PACKT-">The second state is activated before the initialization has completed and it implements the same methods as the first state, but their only role here is to add a new command to the queue using the parameters passed to the invocation.</li>
    </ul>
    <p class="normal">Let's see how we can apply the structure we just described to our <code class="Code-In-Text--PACKT-">db</code> component. First, we create the <code class="Code-In-Text--PACKT-">InitializedState</code>, which implements the actual business logic of our component:</p>
    <pre class="programlisting code"><code class="hljs-code">class InitializedState {
  async query (queryString) {
    console.log(`Query executed: ${queryString}`)
  }
}
</code></pre>
    <p class="normal">As we <a id="_idIndexMarker1008"/>can see, the only method that we need to implement in the <code class="Code-In-Text--PACKT-">InitializedState</code> class is the <code class="Code-In-Text--PACKT-">query()</code> method, which will print a message to the console when it receives a new query.</p>
    <p class="normal">Next, we implement the <code class="Code-In-Text--PACKT-">QueuingState</code>, the core of our recipe. This state implements the queuing logic:</p>
    <pre class="programlisting code"><code class="hljs-code">const METHODS_REQUIRING_CONNECTION = ['query']
const deactivate = Symbol('deactivate')
class QueuingState {
  constructor (db) {
    this.db = db
    this.commandsQueue = []
    METHODS_REQUIRING_CONNECTION.forEach(methodName =&gt; {
      this[methodName] = function (...args) {
        console.log('Command queued:', methodName, args)
        return new Promise((resolve, reject) =&gt; {
          const command = () =&gt; {
            db[methodName](...args)
              .then(resolve, reject)
          }
          this.commandsQueue.push(command)
        })
      }
    })
  }
  [deactivate] () {
    this.commandsQueue.forEach(command =&gt; command())
    this.commandsQueue = []
  }
}
</code></pre>
    <p class="normal">It's interesting to note how the <code class="Code-In-Text--PACKT-">QueuingState</code> is mostly built dynamically at creation time. For each method that requires an active connection, we create a new method for the current instance, which queues a new command representing the function invocation. When the command is executed at a later time, when a connection is established, the result of the invocation of the method on the <code class="Code-In-Text--PACKT-">db</code> instance is forwarded to the caller (through the returned promise).</p>
    <p class="normal">The <a id="_idIndexMarker1009"/>other important part of this state class is <code class="Code-In-Text--PACKT-">[deactivate]()</code>. This method is invoked when the state is deactivated (which is when the component is initialized) and it executes all the commands in the queue. Note how we used a <code class="Code-In-Text--PACKT-">Symbol</code> to name the method. </p>
    <p class="normal">This will avoid any name clashes in the future if we add more methods to the state (for example, what if we need to decorate a hypothetical <code class="Code-In-Text--PACKT-">deactivate()</code> method of the <code class="Code-In-Text--PACKT-">DB</code> class?).</p>
    <p class="normal">Now, it's time to reimplement the <code class="Code-In-Text--PACKT-">DB</code> class using the two states we just described:</p>
    <pre class="programlisting code"><code class="hljs-code">class DB extends EventEmitter {
  constructor () {
    super()
    this.state = new QueuingState(this)                    // (1)
  }
  async query (queryString) {
    return this.state.query(queryString)                   // (2)
  }
  connect () {
    // simulate the delay of the connection
    setTimeout(() =&gt; {
      this.connected = true
      this.emit('connected')
      const oldState = this.state                          // (3)
      this.state = new InitializedState(this)
      oldState[deactivate] &amp;&amp; oldState[deactivate]()
    }, 500)
  }
}
export const db = new DB()
</code></pre>
    <p class="normal">Let's further analyze the most important parts of the new <code class="Code-In-Text--PACKT-">DB</code> class:</p>
    <ol>
      <li class="numbered">In the constructor, we initialize the current <code class="Code-In-Text--PACKT-">state</code> of the instance. It's going to be the <code class="Code-In-Text--PACKT-">QueuingState</code> as the asynchronous initialization of the component hasn't been completed yet.</li>
      <li class="numbered">The only method of our class implementing some (stub) business logic is the <code class="Code-In-Text--PACKT-">query()</code> method. Here, all we have to do is invoke the homonymous method on the currently active state.</li>
      <li class="numbered">Finally, when we establish the connection with the database (initialization complete), we switch the current state to the <code class="Code-In-Text--PACKT-">InitializedState</code> and we deactivate the old one. The effect of deactivating the <code class="Code-In-Text--PACKT-">QueuedState</code>, as we've seen previously, is that any command that had been queued is now executed.</li>
    </ol>
    <p class="normal">We can immediately see how this approach allows us to reduce the boilerplate and, at the <a id="_idIndexMarker1010"/>same time, create a class that is purely business logic (the <code class="Code-In-Text--PACKT-">InitializedState</code>) free from any repetitive initialization check.</p>
    <p class="normal">The approach we've just seen will only work if we can modify the code of our asynchronously initialized component. In all those cases in which we can't make modifications to the component, we will need to create a wrapper or proxy, but the technique will be mostly similar to what we've seen here.</p>
    <h2 id="_idParaDest-299" class="title">In the wild</h2>
    <p class="normal">The pattern we just presented is used by many database drivers and ORM libraries. The most notable is Mongoose (<a href="http://nodejsdp.link/mongoose">nodejsdp.link/mongoose</a>), which is an ORM for <strong class="keyword">MongoDB</strong>. With Mongoose, it's not <a id="_idIndexMarker1011"/>necessary to wait for the database connection <a id="_idIndexMarker1012"/>to open in order to be able to send queries. This is because each operation is queued and then executed later when the connection with the database is fully established, exactly as we've described in <a id="_idIndexMarker1013"/>this section. This is clearly a must for any API that wants to provide a good <strong class="keyword">developer experience</strong> (<strong class="keyword">DX</strong>).</p>
    <p class="normal">Take a look at the code of Mongoose to see how every method in the native driver is proxied to add the pre-initialization queue. This also demonstrates an alternative way of implementing the recipe we presented in this section. You can find the relevant code fragment at <a href="http://nodejsdp.link/mongoose-init-queue">nodejsdp.link/mongoose-init-queue</a>.</p>
    <p class="normal">Similarly, the <code class="Code-In-Text--PACKT-">pg</code> package (<a href="http://nodejsdp.link/pg">nodejsdp.link/pg</a>), which is a client for the PostgreSQL database, leverages <a id="_idIndexMarker1014"/>pre-initialization queues, but in a slightly different fashion. <code class="Code-In-Text--PACKT-">pg</code> queues every query, regardless of the initialization status of the database, and then immediately tries to execute all the commands in the queue. Take a look at the relevant code line at <a href="http://nodejsdp.link/pg-queue">nodejsdp.link/pg-queue</a>.</p>
    <h1 id="_idParaDest-300" class="title">Asynchronous request batching and caching</h1>
    <p class="normal">In high-load applications, <strong class="keyword">caching</strong> plays a critical role and it's used almost everywhere on the web, from <a id="_idIndexMarker1015"/>static resources such as web pages, images, and stylesheets, to pure data such as the result of database queries. In this section, we <a id="_idIndexMarker1016"/>are going to learn how caching applies to asynchronous operations and how a high request throughput can be turned to our advantage.</p>
    <h2 id="_idParaDest-301" class="title">What's asynchronous request batching?</h2>
    <p class="normal">When dealing <a id="_idIndexMarker1017"/>with asynchronous operations, the most basic level of caching can be achieved by <strong class="keyword">batching</strong> together a set of invocations to the same API. The idea is very simple: if we invoke an asynchronous function while there is still another one pending, we can piggyback on the already running operation instead of creating a brand new request. Take a look at the following diagram:</p>
    <figure class="mediaobject"><img src="img/B15729_11_01.png" alt="A screenshot of a social media post  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 11.1: Two asynchronous requests with no batching</p>
    <p class="normal">The previous <a id="_idIndexMarker1018"/>diagram shows two clients invoking the same asynchronous operation with <em class="italic">exactly the same input</em>. Of course, the natural way to picture this situation is with the two clients starting two separate operations that will complete at two different moments.</p>
    <p class="normal">Now, consider the following scenario:</p>
    <figure class="mediaobject"><img src="img/B15729_11_02.png" alt="A screenshot of a social media post  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 11.2: Batching of two asynchronous requests</p>
    <p class="normal"><em class="italic">Figure 11.2</em> shows us how two identical requests—which invoke the same API with the same input—can be batched, or in other words, appended to the same running operation. By doing this, when the operation completes, both clients are notified, even though the <a id="_idIndexMarker1019"/>async operation is actually executed only once. This represents a simple, yet extremely powerful, way to optimize the load of an application while not having to deal with more complex caching mechanisms, which usually require an adequate memory management and invalidation strategy.</p>
    <h2 id="_idParaDest-302" class="title">Optimal asynchronous request caching</h2>
    <p class="normal">Request batching is less effective if the operation is fast enough or if matching requests are spread <a id="_idIndexMarker1020"/>across a longer period of time. Also, most of the time, we can safely assume that the result of two identical API invocations will not change so often, so simple request batching will not provide the best performance. In all these circumstances, the best candidate to reduce the load of an application and increase its responsiveness is definitely a more aggressive caching mechanism.</p>
    <p class="normal">The idea is simple: as soon as a request completes, we store its result in the cache, which can be an in-memory variable or an item in a specialized caching server (such as Redis). Hence, the next time the API is invoked, the result can be retrieved immediately from the cache, instead of spawning another request.</p>
    <p class="normal">The idea of caching should not be new to an experienced developer, but what makes this technique different in asynchronous programming is that it should be combined with request batching to be optimal. The reason for this is because multiple requests might run concurrently while the cache is not set and when those requests complete, the cache would be set multiple times.</p>
    <p class="normal">Based on these assumptions, we can illustrate the Combined Request Batching and Caching pattern as follows:</p>
    <figure class="mediaobject"><img src="img/B15729_11_03.png" alt="A screenshot of a cell phone  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 11.3: Combined batching and caching</p>
    <p class="normal">The preceding <a id="_idIndexMarker1021"/>figure shows the two phases <a id="_idIndexMarker1022"/>of an optimal asynchronous caching algorithm:</p>
    <ul>
      <li class="Bullet--PACKT-">The first phase is totally identical to the batching pattern. Any request received while the cache is not set will be batched together. When the request completes, the cache is set, once.</li>
      <li class="Bullet-End--PACKT-">When the cache is finally set, any subsequent request will be served directly from it.</li>
    </ul>
    <p class="normal">Another crucial detail to consider is the <em class="italic">Zalgo</em> anti-pattern (as we saw in <em class="chapterRef">Chapter 3</em>, <em class="italic">Callbacks and Events</em>). Since we are dealing with asynchronous APIs, we must be sure to always return the cached value asynchronously, even if accessing the cache involves only a synchronous operation, such as in the case in which the cached value is retrieved from an in-memory variable.</p>
    <h2 id="_idParaDest-303" class="title">An API server without caching or batching</h2>
    <p class="normal">Before we start diving into this new challenge, let's implement a small demo server that we will <a id="_idIndexMarker1023"/>use as a reference to measure <a id="_idIndexMarker1024"/>the impact of the various techniques we are going to implement.</p>
    <p class="normal">Let's consider an API server that manages the sales of an e-commerce company. In particular, we want to query our server for the sum of all the transactions of a particular type of merchandise. For this purpose, we are going to use a LevelUP database through the <code class="Code-In-Text--PACKT-">level</code> npm package (<a href="http://nodejsdp.link/level">nodejsdp.link/level</a>). The data model that we are going to use is a simple list of transactions stored in the <code class="Code-In-Text--PACKT-">sales</code> sublevel (a subsection of the database), which is organized in the following format:</p>
    <pre class="programlisting code"><code class="hljs-code">transactionId {amount, product}
</code></pre>
    <p class="normal">The key <a id="_idIndexMarker1025"/>is represented by <code class="Code-In-Text--PACKT-">transactionId</code> and the value is a JSON object that contains the amount of the sale (<code class="Code-In-Text--PACKT-">amount</code>) and the product type (<code class="Code-In-Text--PACKT-">product</code>).</p>
    <p class="normal">The data <a id="_idIndexMarker1026"/>to process is really basic, so let's implement a simple query over the database that we can use for our experiments. Let's say that we want to get the total amount of sales for a particular product. The routine would look as follows (file <code class="Code-In-Text--PACKT-">totalSales.js</code>):</p>
    <pre class="programlisting code"><code class="hljs-code">import level from 'level'
import sublevel from 'subleveldown'
const db = level('example-db')
const salesDb = sublevel(db, 'sales', { valueEncoding: 'json' })
export async function totalSales (product) {
  const now = Date.now()
  let sum = 0
  for await (const transaction of salesDb.createValueStream()) {
    if (!product || transaction.product === product) {
      sum += transaction.amount
    }
  }
  console.log(`totalSales() took: ${Date.now() - now}ms`)
  return sum
}
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">totalSales()</code> function iterates over all the transactions of the <code class="Code-In-Text--PACKT-">sales</code> sublevel and calculates the sum of the amounts of a particular product. The algorithm is intentionally slow as we want to highlight the effect of batching and caching later on. In a real-world application, we would have used an index to query the transactions by <code class="Code-In-Text--PACKT-">product</code> or, even better, we could have used an incremental map/reduce algorithm to continuously calculate the sum for every product</p>
    <p class="normal">We can <a id="_idIndexMarker1027"/>now expose the <code class="Code-In-Text--PACKT-">totalSales()</code> API through a simple HTTP server (the <code class="Code-In-Text--PACKT-">server.js</code> file):</p>
    <pre class="programlisting code"><code class="hljs-code">import { createServer } from 'http'
import { totalSales } from './totalSales.js'
createServer(async (req, res) =&gt; {
  const url = new URL(req.url, 'http://localhost')
  const product = url.searchParams.get('product')
  console.log(`Processing query: ${url.search}`)
  const sum = await totalSales(product)
  res.setHeader('Content-Type', 'application/json')
  res.writeHead(200)
  res.end(JSON.stringify({
    product,
    sum
  }))
}).listen(8000, () =&gt; console.log('Server started'))
</code></pre>
    <p class="normal">Before we start the server for the first time, we need to populate the database with some <a id="_idIndexMarker1028"/>sample data. We can do this with the <code class="Code-In-Text--PACKT-">populateDb.js</code> script, which can be found in this book's code repository in the folder dedicated to this section. This script creates 100,000 random sales transactions in the database so that our query spends some time crunching data:</p>
    <pre class="programlisting con"><code class="hljs-con">node populateDb.js
</code></pre>
    <p class="normal">Okay! Now, everything is ready. Let's start the server:</p>
    <pre class="programlisting con"><code class="hljs-con">node server.js
</code></pre>
    <p class="normal">To query the server, you can simply navigate with a browser to the following URL:</p>
    <pre class="programlisting con"><code class="hljs-con">http://localhost:8000?product=book
</code></pre>
    <p class="normal">However, to have a better idea of the performance of our server, we will need more than one request. So, we will use a small script named <code class="Code-In-Text--PACKT-">loadTest.js</code>, which sends 20 requests at intervals of 200 ms. The script can be found in the code repository of this book and it's already configured to connect to the local URL of the server, so, to run it, just execute the following command:</p>
    <pre class="programlisting con"><code class="hljs-con">node loadTest.js
</code></pre>
    <p class="normal">We will <a id="_idIndexMarker1029"/>see that the 20 requests <a id="_idIndexMarker1030"/>will take a while to complete. Take note of the total execution time of the test. Now, we are going to apply our optimizations and measure how much time we can save. We'll start by implementing both batching and caching by leveraging the properties of promises.</p>
    <h2 id="_idParaDest-304" class="title">Batching and caching with promises</h2>
    <p class="normal">Promises <a id="_idIndexMarker1031"/>are a great tool for implementing <a id="_idIndexMarker1032"/>asynchronous batching and caching of requests. Let's see why.</p>
    <p class="normal">If we recall what we learned about promises in <em class="chapterRef">Chapter 5</em>, <em class="italic">Asynchronous Control Flow Patterns with Promises and Async/Await</em>, there are two properties that can be exploited to our advantage in this circumstance:</p>
    <ul>
      <li class="Bullet--PACKT-">Multiple <code class="Code-In-Text--PACKT-">then()</code> listeners can be attached to the same promise.</li>
      <li class="Bullet-End--PACKT-">The <code class="Code-In-Text--PACKT-">then()</code> listener is guaranteed to be invoked (only once), and it works even if it's attached after the promise is already resolved. Moreover, <code class="Code-In-Text--PACKT-">then()</code> is guaranteed to always be invoked asynchronously.</li>
    </ul>
    <p class="normal">In short, the first property is exactly what we need for batching requests, while the second means that a promise is already a cache for the resolved value and offers a natural mechanism for returning a cached value in a consistent, asynchronous way. In other words, this means that batching and caching become extremely simple and concise with promises.</p>
    <h3 id="_idParaDest-305" class="title">Batching requests in the total sales web server</h3>
    <p class="normal">Let's now add a batching layer on top of our <code class="Code-In-Text--PACKT-">totalSales</code> API. The pattern we are going to use is <a id="_idIndexMarker1033"/>very simple: if there is another identical request pending when the API is invoked, we will wait for that request to complete instead of launching a new one. As we will see, this can easily be implemented with promises. In fact, all we have to do is save the promise in a map, associating it to the specified request parameters (the <code class="Code-In-Text--PACKT-">product</code> type, in our case) every time we launch a new request. Then, at every subsequent request, we check if there is already a promise for the specified <code class="Code-In-Text--PACKT-">product</code> and if there is one, we just return it; otherwise, we launch a new request.</p>
    <p class="normal">Now, let's see how this translates into code. Let's create a new module named <code class="Code-In-Text--PACKT-">totalSalesBatch.js</code>. Here, we're going to implement a batching layer on top of the original <code class="Code-In-Text--PACKT-">totalSales()</code> API:</p>
    <pre class="programlisting code"><code class="hljs-code">import { totalSales as totalSalesRaw } from './totalSales.js'
const runningRequests = new Map()
export function totalSales (product) {
  if (runningRequests.has(product)) {                      // (1)
    console.log('Batching')
    return runningRequests.get(product)
  }
  const resultPromise = totalSalesRaw(product)             // (2)
  runningRequests.set(product, resultPromise)
  resultPromise.finally(() =&gt; {
    runningRequests.delete(product)
  })
  return resultPromise
}
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">totalSales()</code> function of the <code class="Code-In-Text--PACKT-">totalSalesBatch</code> module is a proxy for the original <code class="Code-In-Text--PACKT-">totalSales()</code> API, and it works as follows:</p>
    <ol>
      <li class="numbered">If a promise for the given <code class="Code-In-Text--PACKT-">product</code> already exists, we just return it. This is where we <em class="italic">piggyback</em> on an already running request.</li>
      <li class="numbered">If there is no request running for the given <code class="Code-In-Text--PACKT-">product</code>, we execute the original <code class="Code-In-Text--PACKT-">totalSales()</code> function and we save the resulting promise into the <code class="Code-In-Text--PACKT-">runningRequests</code> map. Next, we make sure to remove the same promise from the <code class="Code-In-Text--PACKT-">runningRequests</code> map as soon as the request completes.</li>
    </ol>
    <p class="normal">The behavior <a id="_idIndexMarker1034"/>of the new <code class="Code-In-Text--PACKT-">totalSales()</code> function is identical to that of the original <code class="Code-In-Text--PACKT-">totalSales()</code> API, with the difference that, now, multiple calls to the API using the same input are batched, thus saving us time and resources.</p>
    <p class="normal">Curious to know what the performance improvement compared to the raw, non-batched version of the <code class="Code-In-Text--PACKT-">totalSales()</code> API is? Let's then replace the <code class="Code-In-Text--PACKT-">totalSales</code> module used by the HTTP server with the one we just created (the <code class="Code-In-Text--PACKT-">app.js</code> file):</p>
    <pre class="programlisting code"><code class="hljs-code">// import { totalSales } from './totalSales.js'
<strong class="hljs-keyword-slc">import</strong><strong class="hljs-slc"> { totalSales } </strong><strong class="hljs-keyword-slc">from</strong><strong class="hljs-slc"> </strong><strong class="hljs-string-slc">'./totalSalesBatch.js'</strong>
createServer(async (req, res) =&gt; {
  // ...
</code></pre>
    <p class="normal">If we now try to start the server again and run the load test against it, the first thing we will see is that the requests are returned in <em class="italic">batches</em>. This is the effect of the recipe we just implemented, and it's a great practical demonstration of how it works.</p>
    <p class="normal">Besides that, we should also observe a considerable reduction in the total time for executing <a id="_idIndexMarker1035"/>the test. It should be at least four times faster than the original test performed against the plain <code class="Code-In-Text--PACKT-">totalSales()</code> API!</p>
    <p class="normal">This result substantiates the huge performance boost that we can obtain by just applying a simple batching layer, without all the complexity of managing a full-fledged cache and, more importantly, without worrying about invalidation strategies.</p>
    <div><p class="Information-Box--PACKT-">The Request Batching pattern reaches its best potential in high-load applications and with slow APIs. This is because it's exactly in these circumstances that we can batch together a high number of requests.</p>
    </div>
    <p class="normal">Let's now see how we can implement both batching and caching using a slight variation of the technique we've just explored.</p>
    <h3 id="_idParaDest-306" class="title">Caching requests in the total sales web server</h3>
    <p class="normal">Adding a <a id="_idIndexMarker1036"/>caching layer to our batching API is straightforward, thanks to promises. All we have to do is leave the promise in our request map, even after the request has completed.</p>
    <p class="normal">Let's implement the <code class="Code-In-Text--PACKT-">totalSalesCache.js</code> module straightaway:</p>
    <pre class="programlisting code"><code class="hljs-code">import { totalSales as totalSalesRaw } from './totalSales.js'
const CACHE_TTL = 30 * 1000 // 30 seconds TTL
const cache = new Map()
export function totalSales (product) {
  if (cache.has(product)) {
    console.log('Cache hit')
    return cache.get(product)
  }
  const resultPromise = totalSalesRaw(product)
  cache.set(product, resultPromise)
  <strong class="hljs-slc">resultPromise.then(</strong><strong class="hljs-function-slc">() =&gt;</strong><strong class="hljs-slc"> {</strong>
    <strong class="hljs-built_in-slc">setTimeout</strong><strong class="hljs-slc">(</strong><strong class="hljs-function-slc">() =&gt;</strong><strong class="hljs-slc"> {</strong>
      <strong class="hljs-slc">cache.delete(product)</strong>
    <strong class="hljs-slc">}, CACHE_TTL)</strong>
  <strong class="hljs-slc">}, </strong><strong class="hljs-params-slc">err</strong><strong class="hljs-function-slc"> =&gt;</strong><strong class="hljs-slc"> {</strong>
    <strong class="hljs-slc">cache.delete(product)</strong>
    <strong class="hljs-keyword-slc">throw</strong><strong class="hljs-slc"> err</strong>
  <strong class="hljs-slc">})</strong>
  return resultPromise
}
</code></pre>
    <p class="normal">The relevant <a id="_idIndexMarker1037"/>code that enables caching is highlighted. All we have to do is remove the promise from the cache after a certain time (<code class="Code-In-Text--PACKT-">CACHE_TTL</code>) after the request has completed, or immediately if the request has failed. This is a very basic cache invalidation technique, but it works perfectly for our demonstration.</p>
    <p class="normal">Now, we are ready to try the <code class="Code-In-Text--PACKT-">totalSales()</code> caching wrapper we just created. To do that, we only need to update the <code class="Code-In-Text--PACKT-">app.js</code> module, as follows:</p>
    <pre class="programlisting code"><code class="hljs-code">// import { totalSales } from './totalSales.js'
// import { totalSales } from './totalSalesBatch.js'
<strong class="hljs-keyword-slc">import</strong><strong class="hljs-slc"> { totalSales } </strong><strong class="hljs-keyword-slc">from</strong><strong class="hljs-slc"> </strong><strong class="hljs-string-slc">'./totalSalesCache.js'</strong>
createServer(async (req, res) =&gt; {
  // ...
</code></pre>
    <p class="normal">Now, the server can be started again and profiled using the <code class="Code-In-Text--PACKT-">loadTest.js</code> script, as we did in the previous examples. With the default test parameters, we should see a 10% reduction in the execution time compared to simple batching. Of course, this is highly dependent on a lot of factors; for example, the number of requests received and the delay between one request and the other. The advantages of using caching over batching will be much more substantial when the number of requests is higher and spans a longer period of time.</p>
    <h3 id="_idParaDest-307" class="title">Notes about implementing caching mechanisms</h3>
    <p class="normal">We must remember that in real-life applications, we may want to use more advanced cache <a id="_idIndexMarker1038"/>invalidation techniques and storage mechanisms. This is necessary for the following reasons:</p>
    <ul>
      <li class="Bullet--PACKT-">A large amount <a id="_idIndexMarker1039"/>of cached values can easily consume a lot of memory. In this case, a <strong class="keyword">least recently used</strong> (<strong class="keyword">LRU</strong>) or a <strong class="keyword">first in first out</strong> (<strong class="keyword">FIFO</strong>) policy can be applied <a id="_idIndexMarker1040"/>to maintain constant memory utilization.</li>
      <li class="Bullet--PACKT-">When the application is distributed across multiple processes, keeping the cache in memory may produce different results across each server instance. If that's undesired for the particular application we are implementing, the solution is to use a shared store for the cache. This is also more performant than a simple in-memory solution as the cache is shared across multiple instances. Popular caching solutions include Redis (<a href="http://nodejsdp.link/redis">nodejsdp.link/redis</a>) and Memcached (<a href="http://nodejsdp.link/memcached">nodejsdp.link/memcached</a>).</li>
      <li class="Bullet--PACKT-">A manual cache invalidation (for example, when the related non-cached value changes), as opposed to a timed expiry, can enable a longer-living cache and at the same time provide more up-to-date data, but, of course, it would be a lot more complex to manage. Let's not forget the famous quote by Phil Karlton (principal engineer at Netscape, Silicon Graphics, and more): "There are only two hard things in Computer Science: cache invalidation and naming things."</li>
    </ul>
    <p class="normal">With this, we conclude this section on request batching and caching. Next, we are going to learn how to tackle a tricky business: canceling asynchronous operations.</p>
    <h1 id="_idParaDest-308" class="title">Canceling asynchronous operations</h1>
    <p class="normal">Being able to stop a long-running operation is particularly useful if the operation has been canceled <a id="_idIndexMarker1041"/>by the user or if it has become redundant. In multithreaded programming, we can just terminate the thread, but on a single-threaded platform such as Node.js, things can get a little bit more complicated.</p>
    <div><p class="Information-Box--PACKT-">In this section, we'll be talking about canceling asynchronous operations and not about canceling promises, which is a different matter altogether. By the way, the Promises/A+ standard doesn't include an API for canceling promises. However, you can use a third-party promise library such as bluebird if you need such a feature (more at <a href="http://nodejsdp.link/bluebird-cancelation">nodejsdp.link/bluebird-cancelation</a>). Note that canceling a promise doesn't mean that the operation the promise refers to will also be canceled; in fact, bluebird offers an <code class="Code-In-Text--PACKT-">onCancel</code> callback in the promise constructor, in addition to <code class="Code-In-Text--PACKT-">resolve</code> and <code class="Code-In-Text--PACKT-">reject</code>, which can be used to cancel the underlying async operation when the promise is canceled. This is actually what this section is about.</p>
    </div>
    <h2 id="_idParaDest-309" class="title">A basic recipe for creating cancelable functions</h2>
    <p class="normal">Actually, in asynchronous programming, the basic principle for canceling the execution of a function <a id="_idIndexMarker1042"/>is very simple: we check if the operation has been canceled after every asynchronous call, and if that's the case, we prematurely quit the operation. Consider, for example, the following code:</p>
    <pre class="programlisting code"><code class="hljs-code">import { asyncRoutine } from './asyncRoutine.js'
import { CancelError } from './cancelError.js'
async function cancelable (cancelObj) {
  const resA = await asyncRoutine('A')
  console.log(resA)
  <strong class="hljs-keyword-slc">if</strong><strong class="hljs-slc"> (cancelObj.cancelRequested) {</strong>
    <strong class="hljs-keyword-slc">throw</strong><strong class="hljs-slc"> </strong><strong class="hljs-keyword-slc">new</strong><strong class="hljs-slc"> CancelError()</strong>
  <strong class="hljs-slc">}</strong>
  const resB = await asyncRoutine('B')
  console.log(resB)
  <strong class="hljs-keyword-slc">if</strong><strong class="hljs-slc"> (cancelObj.cancelRequested) {</strong>
    <strong class="hljs-keyword-slc">throw</strong><strong class="hljs-slc"> </strong><strong class="hljs-keyword-slc">new</strong><strong class="hljs-slc"> CancelError()</strong>
  <strong class="hljs-slc">}</strong>
  const resC = await asyncRoutine('C')
  console.log(resC)
}
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">cancelable()</code> function receives, as input, an object (<code class="Code-In-Text--PACKT-">cancelObj</code>) containing a single property called <code class="Code-In-Text--PACKT-">cancelRequested</code>. In the function, we check the <code class="Code-In-Text--PACKT-">cancelRequested</code> property after every asynchronous call, and if that's <code class="Code-In-Text--PACKT-">true</code>, we throw a special <code class="Code-In-Text--PACKT-">CancelError</code> exception to interrupt the execution of the function.</p>
    <p class="normal">The <code class="Code-In-Text--PACKT-">asyncRoutine()</code> function is just a demo function that prints a string to the console and returns another string after 100 ms. You will find its full implementation, along with that of <code class="Code-In-Text--PACKT-">CancelError</code>, in the code repository for this book.</p>
    <p class="normal">It's important to note that any code external to the <code class="Code-In-Text--PACKT-">cancelable()</code> function will be able to set the <code class="Code-In-Text--PACKT-">cancelRequested</code> property only after the <code class="Code-In-Text--PACKT-">cancelable()</code> function gives back control to the event loop, which is usually when an asynchronous operation is awaited. This is why it's worth checking the <code class="Code-In-Text--PACKT-">cancelRequested</code> property only after the completion of an asynchronous operation and not more often.</p>
    <p class="normal">The following <a id="_idIndexMarker1043"/>code demonstrates how we can cancel the <code class="Code-In-Text--PACKT-">cancelable()</code> function:</p>
    <pre class="programlisting code"><code class="hljs-code">const cancelObj = { cancelRequested: false }
cancelable(cancelObj)
  .catch(err =&gt; {
    if (err instanceof CancelError) {
      console.log('Function canceled')
    } else {
      console.error(err)
    }
  })
setTimeout(() =&gt; {
  cancelObj.cancelRequested = true
}, 100)
</code></pre>
    <p class="normal">As we can see, all we have to do to cancel the function is set the <code class="Code-In-Text--PACKT-">cancelObj.cancelRequested</code> property to <code class="Code-In-Text--PACKT-">true</code>. This will cause the function to stop and throw a <code class="Code-In-Text--PACKT-">CancelError</code>.</p>
    <h2 id="_idParaDest-310" class="title">Wrapping asynchronous invocations</h2>
    <p class="normal">Creating and using a basic asynchronous cancelable function is very easy, but there is a lot of <a id="_idIndexMarker1044"/>boilerplate involved. In fact, it involves so much extra code that it becomes hard to identify the actual business logic of the function.</p>
    <p class="normal">We can reduce the boilerplate by including the cancelation logic inside a wrapping function, which we can use to invoke asynchronous routines. </p>
    <p class="normal">Such a wrapper would look as follows (the <code class="Code-In-Text--PACKT-">cancelWrapper.js</code> file):</p>
    <pre class="programlisting code"><code class="hljs-code">import { CancelError } from './cancelError.js'
export function createCancelWrapper () {
  let cancelRequested = false
  function cancel () {
    cancelRequested = true
  }
  function cancelWrapper (func, ...args) {
    if (cancelRequested) {
      return Promise.reject(new CancelError())
    }
    return func(...args)
  }
  return { cancelWrapper, cancel }
}
</code></pre>
    <p class="normal">Our wrapper is created through a factory function called <code class="Code-In-Text--PACKT-">createCancelWrapper()</code>. The factory returns two functions: the wrapper function (<code class="Code-In-Text--PACKT-">cancelWrapper</code>) and a function to trigger the <a id="_idIndexMarker1045"/>cancelation of the asynchronous operation (<code class="Code-In-Text--PACKT-">cancel</code>). This allows us to create a wrapper function to wrap multiple asynchronous invocations and then use a single <code class="Code-In-Text--PACKT-">cancel()</code> function to cancel all of them.</p>
    <p class="normal">The <code class="Code-In-Text--PACKT-">cancelWrapper()</code> function takes, as input, a function to invoke (<code class="Code-In-Text--PACKT-">func</code>) and a set of parameters to pass to the function (<code class="Code-In-Text--PACKT-">args</code>). The wrapper simply checks if a cancelation has been requested and if positive, it will return a promise rejected with a <code class="Code-In-Text--PACKT-">CancelError</code> object as the rejection reason; otherwise, it will invoke <code class="Code-In-Text--PACKT-">func</code>.</p>
    <p class="normal">Let's now see how our wrapper factory can greatly improve the readability and modularity of our <code class="Code-In-Text--PACKT-">cancelable()</code> function:</p>
    <pre class="programlisting code"><code class="hljs-code">import { asyncRoutine } from './asyncRoutine.js'
import { createCancelWrapper } from './cancelWrapper.js'
import { CancelError } from './cancelError.js'
async function cancelable (cancelWrapper) {
  const resA = await cancelWrapper(asyncRoutine, 'A')
  console.log(resA)
  const resB = await cancelWrapper(asyncRoutine, 'B')
  console.log(resB)
  const resC = await cancelWrapper(asyncRoutine, 'C')
  console.log(resC)
}
const { cancelWrapper, cancel } = createCancelWrapper()
cancelable(cancelWrapper)
  .catch(err =&gt; {
    if (err instanceof CancelError) {
      console.log('Function canceled')
    } else {
      console.error(err)
    }
  })
setTimeout(() =&gt; {
  cancel()
}, 100)
</code></pre>
    <p class="normal">We can <a id="_idIndexMarker1046"/>immediately see the benefits of using a wrapper function for implementing our cancelation logic. In fact, the <code class="Code-In-Text--PACKT-">cancelable()</code> function is now much more concise and readable.</p>
    <h2 id="_idParaDest-311" class="title">Cancelable async functions with generators</h2>
    <p class="normal">The <code class="Code-In-Text--PACKT-">cancelable</code> wrapper function we just created is already a big step ahead compared to embedding <a id="_idIndexMarker1047"/>the cancelation logic directly in our code. However, it's still not ideal for two reasons: it is error prone (what if we forget to wrap one function?) and it still affects the readability of our code, which makes it not ideal for implementing cancelable asynchronous operations that are already large and complex.</p>
    <p class="normal">An even neater solution involves the use of generators. In <em class="chapterRef">Chapter 9</em>, <em class="italic">Behavioral Design Patterns</em>, we introduced generators as a means to implement iterators. However, they are a very versatile tool and can be used to implement all sorts of algorithms. In this case, we will be using generators to build a supervisor to control the asynchronous flow of a function. The result will be an asynchronous function that is transparently cancelable, whose behavior resembles an async function in which the <code class="Code-In-Text--PACKT-">await</code> instruction is replaced by <code class="Code-In-Text--PACKT-">yield</code>.</p>
    <p class="normal">Let's see how we can implement this cancelable function using generators (the <code class="Code-In-Text--PACKT-">createAsyncCancelable.js</code> file):</p>
    <pre class="programlisting code"><code class="hljs-code">import { CancelError } from './cancelError.js'
export function createAsyncCancelable (generatorFunction) {   // (1)
  return function asyncCancelable (...args) {
    const generatorObject = generatorFunction(...args)        // (3)
    let cancelRequested = false
    function cancel () {
      cancelRequested = true
    }
    const promise = new Promise((resolve, reject) =&gt; {
      async function nextStep (prevResult) {                  // (4)
        if (cancelRequested) {
          return reject(new CancelError())
        }
        if (prevResult.done) {
          return resolve(prevResult.value)
        }
        try {                                                 // (5)
          nextStep(generatorObject.next(await prevResult.value))
        } catch (err) {
          try {                                               // (6)
            nextStep(generatorObject.throw(err))
          } catch (err2) {
            reject(err2)
          }
        }
      }
      nextStep({})
    })
    return { promise, cancel }                                // (2)
  }
}
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">createAsyncCancelable()</code> function may seem complex, so let's analyze it in more detail:</p>
    <ol>
      <li class="numbered">First, we should note that the <code class="Code-In-Text--PACKT-">createAsyncCancelable()</code> function takes, as input, a generator function (the supervised function) and returns another function (<code class="Code-In-Text--PACKT-">asyncCancelable()</code>) that wraps the generator function with our supervising logic. The <code class="Code-In-Text--PACKT-">asyncCancelable()</code> function is what we will use to invoke the asynchronous operation.</li>
      <li class="numbered">The <code class="Code-In-Text--PACKT-">asyncCancelable()</code> function returns an object with two properties:<ol style="list-style-type: lower-alpha">
          <li class="alphabetic-l2">The <code class="Code-In-Text--PACKT-">promise</code> property, which contains the promise representing the eventual resolution (or rejection) of the asynchronous operation.</li>
          <li class="alphabetic-l2">The <code class="Code-In-Text--PACKT-">cancel</code> property, which is a function that can be used to cancel the supervised asynchronous flow.</li>
        </ol>
      </li>
      <li class="numbered">When invoked, the first task of <code class="Code-In-Text--PACKT-">asyncCancelable()</code> is to invoke the generator function with the arguments received as input (<code class="Code-In-Text--PACKT-">args</code>) and obtain a generator object, which we can use to control the execution flow of the running coroutine.</li>
      <li class="numbered">The entire <a id="_idIndexMarker1048"/>logic of the supervisor is implemented within the <code class="Code-In-Text--PACKT-">nextStep()</code> function, which is responsible for iterating over the values yielded by the supervised coroutine (<code class="Code-In-Text--PACKT-">prevResult</code>). Those can be actual values or promises. If a cancelation is requested, we throw the usual <code class="Code-In-Text--PACKT-">CancelError</code>; otherwise, if the coroutine has been terminated (for example, <code class="Code-In-Text--PACKT-">prevResult.done</code> is <code class="Code-In-Text--PACKT-">true</code>), we immediately resolve the outer promise and complete the return.</li>
      <li class="numbered">The core part of the <code class="Code-In-Text--PACKT-">nextStep()</code> function is where we retrieve the next value yielded by the supervised coroutine (which, let's not forget, it's a generator). We <code class="Code-In-Text--PACKT-">await</code> on that value so we can make sure we get the actual resolution value in case we are dealing with a promise. This also makes sure that if <code class="Code-In-Text--PACKT-">prevResult.value</code> is a promise and it rejects, we end up in the <code class="Code-In-Text--PACKT-">catch</code> statement. We can end up in the <code class="Code-In-Text--PACKT-">catch</code> statement even if the supervised coroutine actually throws an exception.</li>
      <li class="numbered">In the <code class="Code-In-Text--PACKT-">catch</code> statement, we throw the caught error inside the coroutine. This is redundant if that error was already thrown by the coroutine, but not if it's the result of a promise rejection. Even if not optimal, this trick can simplify our code a bit for the sake of this demonstration. We invoke <code class="Code-In-Text--PACKT-">nextStep()</code> using whatever value is yielded next after throwing it inside the coroutine, but if the result is another exception (for example, the exception is not caught inside the coroutine or another one is thrown), we immediately reject the outer promise and complete the asynchronous operation.</li>
    </ol>
    <p class="normal">As we saw, there are a lot of moving parts in the <code class="Code-In-Text--PACKT-">createAsyncCancelable()</code> function. But we should appreciate the fact that, in just a few lines of code, we were able to create a cancelable function that doesn't require any manual cancelation logic. As we will see now, the results are impressive.</p>
    <p class="normal">Let's <a id="_idIndexMarker1049"/>rewrite our sample asynchronous cancelable operation using the supervisor we implemented in the <code class="Code-In-Text--PACKT-">createAsyncCancelable()</code> function:</p>
    <pre class="programlisting code"><code class="hljs-code">import { asyncRoutine } from './asyncRoutine.js'
import { createAsyncCancelable } from './createAsyncCancelable.js'
import { CancelError } from './cancelError.js'
const cancelable = createAsyncCancelable(function * () {
  const resA = yield asyncRoutine('A')
  console.log(resA)
  const resB = yield asyncRoutine('B')
  console.log(resB)
  const resC = yield asyncRoutine('C')
  console.log(resC)
})
const { promise, cancel } = cancelable()
promise.catch(err =&gt; {
  if (err instanceof CancelError) {
    console.log('Function canceled')
  } else {
    console.error(err)
  }
})
setTimeout(() =&gt; {
  cancel()
}, 100)
</code></pre>
    <p class="normal">We can immediately see that the generator wrapped by <code class="Code-In-Text--PACKT-">createAsyncCancelable()</code> closely resembles an async function, but we are using <code class="Code-In-Text--PACKT-">yield</code> instead of <code class="Code-In-Text--PACKT-">await</code>. Also, there is no visible cancelation logic at all. The generator function maintains the excellent properties of async functions (for example, to make asynchronous code look like synchronous code), but unlike the async function and thanks to the supervisor introduced by <code class="Code-In-Text--PACKT-">createAsyncCancelable()</code>, it's also possible to cancel the operation.</p>
    <p class="normal">The second interesting aspect is that <code class="Code-In-Text--PACKT-">createAsyncCancelable()</code> creates a function (called <code class="Code-In-Text--PACKT-">cancelable</code>) that can be invoked like any other function but at the same time returns a promise representing the result of the operation and a function to cancel the operation.</p>
    <p class="normal">This <a id="_idIndexMarker1050"/>technique of using generators represents the best option we have to implement cancelable asynchronous operations.</p>
    <div><p class="Information-Box--PACKT-">For use in production, most of the time, we can rely on a widely used package from the Node.js ecosystem such as <code class="Code-In-Text--PACKT-">caf</code> (the acronym means Cancelable Async Flows), which you can find at <a href="http://nodejsdp.link/caf">nodejsdp.link/caf</a>.</p>
    </div>
    <h1 id="_idParaDest-312" class="title">Running CPU-bound tasks</h1>
    <p class="normal">The <code class="Code-In-Text--PACKT-">totalSales()</code> API that we implemented in the <em class="italic">Asynchronous request batching and caching</em> section was (intentionally) expensive in terms of resources and took a few hundred milliseconds to run. Nonetheless, invoking the <code class="Code-In-Text--PACKT-">totalSales()</code> function did not affect the <a id="_idIndexMarker1051"/>ability of the application to process concurrent incoming requests. What we learned about the event loop in <em class="chapterRef">Chapter 1</em>, <em class="italic">The Node.js Platform</em>, should explain this behavior: invoking an asynchronous operation always causes the stack to unwind back to the event loop, leaving it free to handle other requests.</p>
    <p class="normal">But what happens when we run a synchronous task that takes a long time to complete and that never gives back the control to the event loop until it has finished? This kind of task is also known as <strong class="keyword">CPU-bound</strong>, because its main characteristic is that it is heavy on CPU utilization rather than being heavy on I/O operations.</p>
    <p class="normal">Let's work immediately on an example to see how these types of task behave in Node.js.</p>
    <h2 id="_idParaDest-313" class="title">Solving the subset sum problem</h2>
    <p class="normal">Let's now <a id="_idIndexMarker1052"/>choose a computationally expensive problem to use as a base for our experiment. A good candidate <a id="_idIndexMarker1053"/>is the <strong class="keyword">subset sum</strong> problem, which decides whether a set (or multiset) of integers contains a non-empty subset that has a sum equal to zero. For example, if we had as input the set [1, 2, –4, 5, –3], the subsets satisfying the problem are [1, 2, –3] and [2, –4, 5, –3].</p>
    <p class="normal">The simplest algorithm is the one that checks every possible combination of subsets of any size and has a computational cost of <em class="italic">O</em>(2<sup style="font-style: italic;">n</sup>), or in other words, it grows exponentially with the size of the input. This means that a set of 20 integers would require up to 1,048,576 combinations to be checked, which is not bad for testing our assumptions. For our example, we are going to consider the following variation of the subset sum problem: given a set of integers, we want to calculate all the possible combinations whose sum is equal to a given arbitrary integer, not just zero.</p>
    <p class="normal">Now, let's <a id="_idIndexMarker1054"/>work to implement such an algorithm. First, let's create a new module called <code class="Code-In-Text--PACKT-">subsetSum.js</code>. We will start by creating a class called <code class="Code-In-Text--PACKT-">SubsetSum</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">export class SubsetSum extends EventEmitter {
  constructor (sum, set) {
    super()
    this.sum = sum
    this.set = set
    this.totalSubsets = 0
  }
//...
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">SubsetSum</code> class is extending <code class="Code-In-Text--PACKT-">EventEmitter</code>. This allows us to produce an event every time we find a new subset matching the sum received as input. As we will see, this will give us a lot of flexibility.</p>
    <p class="normal">Next, let's see how we can generate all the possible combinations of subsets:</p>
    <pre class="programlisting code"><code class="hljs-code">_combine (set, subset) {
  for (let i = 0; i &lt; set.length; i++) {
    const newSubset = subset.concat(set[i])
    this._combine(set.slice(i + 1), newSubset)
    this._processSubset(newSubset)
  }
}
</code></pre>
    <p class="normal">We will not go into too much detail about the algorithm, but there are two important things to notice:</p>
    <ul>
      <li class="Bullet--PACKT-">The <code class="Code-In-Text--PACKT-">_combine()</code> method is completely synchronous. It recursively generates every possible subset without ever giving back control to the event loop.</li>
      <li class="Bullet-End--PACKT-">Every time a new combination is generated, we provide it to the <code class="Code-In-Text--PACKT-">_processSubset()</code> method for further processing.</li>
    </ul>
    <p class="normal">The <code class="Code-In-Text--PACKT-">_processSubset()</code> method is responsible for verifying that the sum of the elements of the given subset is equal to the number we are looking for:</p>
    <pre class="programlisting code"><code class="hljs-code">_processSubset (subset) {
  console.log('Subset', ++this.totalSubsets, subset)
  const res = subset.reduce((prev, item) =&gt; (prev + item), 0)
  if (res === this.sum) {
    this.emit('match', subset)
  }
}
</code></pre>
    <p class="normal">Trivially, the <code class="Code-In-Text--PACKT-">_processSubset()</code> method applies a <code class="Code-In-Text--PACKT-">reduce</code> operation to the subset in order to calculate the sum of its elements. Then, it emits an event of the type <code class="Code-In-Text--PACKT-">match</code> when the resulting sum is equal to the one we are interested in finding (<code class="Code-In-Text--PACKT-">this.sum</code>).</p>
    <p class="normal">Finally, the <code class="Code-In-Text--PACKT-">start()</code> method puts all the preceding pieces together:</p>
    <pre class="programlisting code"><code class="hljs-code">start () {
  this._combine(this.set, [])
  this.emit('end')
}
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">start()</code> method triggers the generation of all the combinations by invoking <code class="Code-In-Text--PACKT-">_combine()</code>, and lastly, emits an <code class="Code-In-Text--PACKT-">end</code> event, signaling that all the combinations were checked and any possible match has already been emitted. This is possible because <code class="Code-In-Text--PACKT-">_combine()</code> is synchronous; therefore, the <code class="Code-In-Text--PACKT-">end</code> event is emitted as soon as the function returns, which means that all the combinations have been calculated.</p>
    <p class="normal">Next, we have <a id="_idIndexMarker1055"/>to expose the algorithm we just created over the network. As always, we can use a simple HTTP server for this task. In particular, we want to create an endpoint that accepts requests in the format <code class="Code-In-Text--PACKT-">/subsetSum?data=&lt;Array&gt;&amp;sum=&lt;Integer&gt;</code> that invokes the <code class="Code-In-Text--PACKT-">SubsetSum</code> algorithm with the given array of integers and sum to match.</p>
    <p class="normal">Let's implement this simple server in a module named <code class="Code-In-Text--PACKT-">index.js</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">import { createServer } from 'http'
import { SubsetSum } from './subsetSum.js'
createServer((req, res) =&gt; {
  const url = new URL(req.url, 'http://localhost')
  if (url.pathname !== '/subsetSum') {
    res.writeHead(200)
    return res.end('I\'m alive!\n')
  }
  const data = JSON.parse(url.searchParams.get('data'))
  const sum = JSON.parse(url.searchParams.get('sum'))
  res.writeHead(200)
  const subsetSum = new SubsetSum(sum, data)
  subsetSum.on('match', match =&gt; {
    res.write(`Match: ${JSON.stringify(match)}\n`)
  })
  subsetSum.on('end', () =&gt; res.end())
  subsetSum.start()
}).listen(8000, () =&gt; console.log('Server started'))
</code></pre>
    <p class="normal">Thanks to the fact that the <code class="Code-In-Text--PACKT-">SubsetSum</code> object returns its results using events, we can stream the matching subsets as soon as they are generated by the algorithm, in real time. Another detail to mention is that our server responds with the text <code class="Code-In-Text--PACKT-">I'm alive!</code> every time we hit a URL different than <code class="Code-In-Text--PACKT-">/subsetSum</code>. We will use this for checking the responsiveness of our server, as we will see in a moment.</p>
    <p class="normal">We are now <a id="_idIndexMarker1056"/>ready to try our subset sum algorithm. Curious to know how our server will handle it? Let's fire it up, then:</p>
    <pre class="programlisting con"><code class="hljs-con">node index.js
</code></pre>
    <p class="normal">As soon as the server starts, we are ready to send our first request. Let's try it with a multiset of 17 random numbers, which will result in the generation of 131,071 combinations, a nice amount to keep our server busy for a while:</p>
    <pre class="programlisting con"><code class="hljs-con">curl -G http://localhost:8000/subsetSum --data-urlencode "data=[16, 19,1,1,-16,9,1,-5,-2,17,-15,-97,19,-16,-4,-5,15]" --data-urlencode "sum=0"
</code></pre>
    <p class="normal">After a few seconds, we should see the results coming from the server. But if we try the following command in another terminal while the first request is still running, we will spot a huge problem:</p>
    <pre class="programlisting con"><code class="hljs-con">curl -G http://localhost:8000
</code></pre>
    <p class="normal">We will immediately see that this last request hangs until the subset sum algorithm of the first request has finished: the server is unresponsive! This was actually expected. The Node.js event loop runs in a single thread, and if this thread is blocked by a long synchronous computation, it will be unable to execute even a single cycle in order to respond with a simple <code class="Code-In-Text--PACKT-">I'm alive!</code></p>
    <p class="normal">We quickly <a id="_idIndexMarker1057"/>understand that this behavior does not work for any kind of application meant to process multiple concurrent requests. But don't despair. In Node.js, we can tackle this type of situation in several ways. So, let's analyze the three most popular methods, which are "interleaving with <code class="Code-In-Text--PACKT-">setImmediate</code>," "using external processes," and "using worker threads."</p>
    <h2 id="_idParaDest-314" class="title">Interleaving with setImmediate</h2>
    <p class="normal">Usually, a CPU-bound algorithm is built upon a set of steps. This can be a set of recursive invocations, a loop, or any variation/combination of these. So, a simple solution <a id="_idIndexMarker1058"/>to our problem would be to give back the control to the event loop after each of these steps completes (or after a certain number of them). This way, any pending I/O can still be processed by the event loop in those intervals in which the long-running algorithm yields the CPU. A simple way to achieve this is to schedule the next step of the algorithm to run after any pending I/O requests. This sounds like the perfect use case for the <code class="Code-In-Text--PACKT-">setImmediate()</code> function (we already introduced this API in <em class="chapterRef">Chapter 3</em>, <em class="italic">Callbacks and Events</em>).</p>
    <h3 id="_idParaDest-315" class="title">Interleaving the steps of the subset sum algorithm</h3>
    <p class="normal">Let's now <a id="_idIndexMarker1059"/>see how this technique applies to our subset sum algorithm. All we have to do is slightly modify the <code class="Code-In-Text--PACKT-">subsetSum.js</code> module. For convenience, we are going to create a new module called <code class="Code-In-Text--PACKT-">subsetSumDefer.js</code>, taking the code of the original <code class="Code-In-Text--PACKT-">subsetSum</code> class as a starting point.</p>
    <p class="normal">The first change we are going to make is to add a new method called <code class="Code-In-Text--PACKT-">_combineInterleaved()</code>, which is the core of the technique we are implementing:</p>
    <pre class="programlisting code"><code class="hljs-code">_combineInterleaved (set, subset) {
  this.runningCombine++
  setImmediate(() =&gt; {
    this._combine(set, subset)
    if (--this.runningCombine === 0) {
      this.emit('end')
    }
  })
}
</code></pre>
    <p class="normal">As we can see, all we had to do is defer the invocation of the original (synchronous) <code class="Code-In-Text--PACKT-">_combine()</code> method with <code class="Code-In-Text--PACKT-">setImmediate()</code>. However, now, it becomes more difficult to know when the function has finished generating all the combinations, because the algorithm is not synchronous anymore. </p>
    <p class="normal">To fix this, we have to keep track of all the <a id="_idIndexMarker1060"/>running instances of the <code class="Code-In-Text--PACKT-">_combine() </code>method using a pattern very similar to the asynchronous parallel execution flow that we saw in <em class="chapterRef">Chapter 4</em>, <em class="italic">Asynchronous Control Flow Patterns with Callbacks</em>. When all the instances of the <code class="Code-In-Text--PACKT-">_combine()</code> method have finished running, we can emit the <code class="Code-In-Text--PACKT-">end</code> event, notifying any listener that the process has completed.</p>
    <p class="normal">To finish refactoring the subset sum algorithm, we need to make a couple more tweaks. First, we need to replace the recursive step in the <code class="Code-In-Text--PACKT-">_combine()</code> method with its deferred counterpart:</p>
    <pre class="programlisting code"><code class="hljs-code">_combine (set, subset) {
  for (let i = 0; i &lt; set.length; i++) {
    const newSubset = subset.concat(set[i])
    <strong class="hljs-built_in-slc">this</strong><strong class="hljs-slc">._combineInterleaved(set.slice(i + </strong><strong class="hljs-number-slc">1</strong><strong class="hljs-slc">), newSubset)</strong>
    this._processSubset(newSubset)
  }
}
</code></pre>
    <p class="normal">With the preceding change, we make sure that each step of the algorithm will be queued in the event loop using <code class="Code-In-Text--PACKT-">setImmediate()</code> and, therefore, executed after any pending I/O request instead of being run synchronously.</p>
    <p class="normal">The other small tweak is in the <code class="Code-In-Text--PACKT-">start()</code> method:</p>
    <pre class="programlisting code"><code class="hljs-code">start () {
  this.runningCombine = 0
  this._combineInterleaved(this.set, [])
}
</code></pre>
    <p class="normal">In the preceding code, we initialized the number of running instances of the <code class="Code-In-Text--PACKT-">_combine()</code> method to <code class="Code-In-Text--PACKT-">0</code>. We also replaced the call to <code class="Code-In-Text--PACKT-">_combine()</code> with a call to <code class="Code-In-Text--PACKT-">_combineInterleaved()</code> and removed the emission of the <code class="Code-In-Text--PACKT-">end</code> event because this is now handled asynchronously in <code class="Code-In-Text--PACKT-">_combineInterleaved()</code>.</p>
    <p class="normal">With this last change, our subset sum algorithm should now be able to run its CPU-bound code in steps interleaved by intervals, where the event loop can run and process any other pending request.</p>
    <p class="normal">The last <a id="_idIndexMarker1061"/>missing bit is updating the <code class="Code-In-Text--PACKT-">index.js</code> module so that it can use the new version of the <code class="Code-In-Text--PACKT-">SubsetSum</code> API. This is actually a trivial change:</p>
    <pre class="programlisting code"><code class="hljs-code">import { createServer } from 'http'
// import { SubsetSum } from './subsetSum.js'
<strong class="hljs-keyword-slc">import</strong><strong class="hljs-slc"> { SubsetSum } </strong><strong class="hljs-keyword-slc">from</strong><strong class="hljs-slc"> </strong><strong class="hljs-string-slc">'./subsetSumDefer.js'</strong>
createServer((req, res) =&gt; {
  // ...
</code></pre>
    <p class="normal">We are now ready to try this new version of the subset sum server. Start the server again and then try to send a request to calculate all the subsets matching a given sum:</p>
    <pre class="programlisting con"><code class="hljs-con">curl -G http://localhost:8000/subsetSum --data-urlencode "data=[16, 19,1,1,-16,9,1,-5,-2,17,-15,-97,19,-16,-4,-5,15]" --data-urlencode "sum=0"
</code></pre>
    <p class="normal">While the request is running, check again whether the server is responsive:</p>
    <pre class="programlisting con"><code class="hljs-con">curl -G http://localhost:8000
</code></pre>
    <p class="normal">Cool! The second request should return almost immediately, even while the <code class="Code-In-Text--PACKT-">SubsetSum</code> task is still running, confirming that our technique is working well.</p>
    <h3 id="_idParaDest-316" class="title">Considerations on the interleaving approach</h3>
    <p class="normal">As we saw, running a CPU-bound task while preserving the responsiveness of an application is <a id="_idIndexMarker1062"/>not that complicated; it just requires the use of <code class="Code-In-Text--PACKT-">setImmediate()</code> to schedule the next step of an algorithm to run after any pending I/O. However, this is not the best recipe in terms of efficiency. In fact, deferring a task introduces a small overhead that, multiplied by all the steps that an algorithm has to run, can have a significant impact on the overall running time. This is usually the last thing we want when running a CPU-bound task. A possible solution to mitigate this problem would be using <code class="Code-In-Text--PACKT-">setImmediate()</code> only after a certain number of steps—instead of using it at every single step—but still, this would not solve the root of the problem.</p>
    <p class="normal">Also, this technique doesn't work very well if each step takes a long time to run. In this case, in fact, the event loop would lose responsiveness, and the whole application would start lagging, which is undesirable in a production environment.</p>
    <p class="normal">Bear in mind that this does not mean that the technique we have just seen should be avoided at <a id="_idIndexMarker1063"/>all costs. In certain situations in which the synchronous task is executed sporadically and doesn't take too long to run, using <code class="Code-In-Text--PACKT-">setImmediate()</code> to interleave its execution is sometimes the simplest and most effective way to avoid blocking the event loop.</p>
    <div><p class="Tip--PACKT-">Note that <code class="Code-In-Text--PACKT-">process.nextTick()</code> cannot be used to interleave a long-running task. As we saw in <em class="chapterRef">Chapter 3</em>, <em class="italic">Callbacks and Events</em>, <code class="Code-In-Text--PACKT-">nextTick()</code> schedules a task to run before any pending I/O, and this will cause I/O starvation in case of repeated calls. You can verify this yourself by replacing <code class="Code-In-Text--PACKT-">setImmediate()</code> with <code class="Code-In-Text--PACKT-">process.nextTick()</code> in the previous example.</p>
    </div>
    <h2 id="_idParaDest-317" class="title">Using external processes</h2>
    <p class="normal">Deferring the steps of an algorithm is not the only option we have for running CPU-bound tasks. Another <a id="_idIndexMarker1064"/>pattern for preventing the event loop from blocking is using <strong class="keyword">child processes</strong>. We already know that Node.js gives <a id="_idIndexMarker1065"/>its best when running I/O-intensive applications such as web servers, which allows us to optimize resource utilization thanks to its asynchronous architecture. So, the best way we have to maintain the responsiveness of an application is to not run expensive CPU-bound tasks in the context of the main application and, instead, use separate processes. This has three main advantages:</p>
    <ul>
      <li class="Bullet--PACKT-">The synchronous task can run at full speed, without the need to interleave the steps of its execution.</li>
      <li class="Bullet--PACKT-">Working with processes in Node.js is simple, probably easier than modifying an algorithm to use <code class="Code-In-Text--PACKT-">setImmediate()</code>, and allows us to easily use multiple processors without the need to scale the main application itself.</li>
      <li class="Bullet-End--PACKT-">If we really need maximum performance, the external process could be created in lower-level languages, such as good old C or more modern compiled languages like Go or Rust. Always use the best tool for the job!</li>
    </ul>
    <p class="normal">Node.js has an ample toolbelt of APIs for interacting with external processes. We can find all we need in the <code class="Code-In-Text--PACKT-">child_process</code> module. Moreover, when the external process is just another Node.js program, connecting it to the main application is extremely easy and allows <a id="_idIndexMarker1066"/>seamless communication with the local application. This magic happens thanks to the <code class="Code-In-Text--PACKT-">child_process.fork()</code> function, which creates a new child Node.js process and also automatically creates a communication channel with it, allowing us to exchange information using an interface very similar to the <code class="Code-In-Text--PACKT-">EventEmitter</code>. Let's see how this works by refactoring our subset sum server again.</p>
    <h3 id="_idParaDest-318" class="title">Delegating the subset sum task to an external process</h3>
    <p class="normal">The goal of refactoring the <code class="Code-In-Text--PACKT-">SubsetSum</code> task is to create a separate child process responsible <a id="_idIndexMarker1067"/>for handling the synchronous processing, leaving the event loop of the main server free to handle requests coming <a id="_idIndexMarker1068"/>from the network. This is the recipe we are going to follow to make this possible:</p>
    <ol>
      <li class="numbered">We will create a new module named <code class="Code-In-Text--PACKT-">processPool.js</code> that will allow us to create a pool of running processes. Starting a new process is expensive and requires time, so keeping them constantly running and ready to handle requests allows us to save time and CPU cycles. Also, the pool will help us limit the number of processes <a id="_idIndexMarker1069"/>running at the same time to prevent exposing the application to <strong class="keyword">denial-of-service</strong> (<strong class="keyword">DoS</strong>) attacks.</li>
      <li class="numbered">Next, we will create a module called <code class="Code-In-Text--PACKT-">subsetSumFork.js</code> responsible for abstracting a <code class="Code-In-Text--PACKT-">SubsetSum</code> task running in a child process. Its role will be communicating with the child process and forwarding the results of the task as if they were coming from the current application.</li>
      <li class="numbered">Finally, we need a <strong class="keyword">worker</strong> (our child process), a new Node.js program with the only goal of running the subset sum algorithm and forwarding its results to the parent process.</li>
    </ol>
    <div><p class="Information-Box--PACKT-">The purpose of a DoS attack is to make a machine unavailable to its users. This is usually achieved by exhausting the capacity of such a machine by exploiting a vulnerability or massively overloading it with requests (DDoS – distributed DoS).</p>
    </div>
    <h4 class="title">Implementing a process pool</h4>
    <p class="normal">Let's <a id="_idIndexMarker1070"/>start by building the <code class="Code-In-Text--PACKT-">processPool.js</code> module piece by piece:</p>
    <pre class="programlisting code"><code class="hljs-code">import { fork } from 'child_process'
export class ProcessPool {
  constructor (file, poolMax) {
    this.file = file
    this.poolMax = poolMax
    this.pool = []
    this.active = []
    this.waiting = []
  }
//...
</code></pre>
    <p class="normal">In the first part of the module, we import the <code class="Code-In-Text--PACKT-">fork()</code> function from the <code class="Code-In-Text--PACKT-">child_process</code> module, which we will use to create new processes. Then, we define the <code class="Code-In-Text--PACKT-">ProcessPool</code> constructor, which accepts a <code class="Code-In-Text--PACKT-">file</code> parameter representing the Node.js program to run, and the maximum number of running instances in the pool (<code class="Code-In-Text--PACKT-">poolMax</code>). We then <a id="_idIndexMarker1071"/>define three instance variables:</p>
    <ul>
      <li class="Bullet--PACKT-"><code class="Code-In-Text--PACKT-">pool</code> is the set of running processes ready to be used.</li>
      <li class="Bullet--PACKT-"><code class="Code-In-Text--PACKT-">active</code> contains the list of the processes currently being used.</li>
      <li class="Bullet-End--PACKT-"><code class="Code-In-Text--PACKT-">waiting</code> contains a queue of callbacks for all those requests that could not be fulfilled immediately because of the lack of an available process.</li>
    </ul>
    <p class="normal">The next piece of the <code class="Code-In-Text--PACKT-">ProcessPool</code> class is the <code class="Code-In-Text--PACKT-">acquire()</code> method, which is responsible for eventually returning a process ready to be used, when one becomes available:</p>
    <pre class="programlisting code"><code class="hljs-code">acquire () {
  return new Promise((resolve, reject) =&gt; {
    let worker
    if (this.pool.length &gt; 0) {                            // (1)
      worker = this.pool.pop()
      this.active.push(worker)
      return resolve(worker)
    }
    if (this.active.length &gt;= this.poolMax) {              // (2)
      return this.waiting.push({ resolve, reject })
    }
    worker = fork(this.file)                               // (3)
    worker.once('message', message =&gt; {
      if (message === 'ready') {
        this.active.push(worker)
        return resolve(worker)
      }
      worker.kill()
      reject(new Error('Improper process start'))
    })
    worker.once('exit', code =&gt; {
      console.log(`Worker exited with code ${code}`)
      this.active = this.active.filter(w =&gt; worker !== w)
      this.pool = this.pool.filter(w =&gt; worker !== w)
    })
  })
}
</code></pre>
    <p class="normal">The logic of <code class="Code-In-Text--PACKT-">acquire()</code> is <a id="_idIndexMarker1072"/>very simple and is explained as follows:</p>
    <ol>
      <li class="numbered">If we have a process in the <code class="Code-In-Text--PACKT-">pool</code> ready to be used, we simply move it to the <code class="Code-In-Text--PACKT-">active</code> list and then use it to fulfill the outer promise with <code class="Code-In-Text--PACKT-">resolve()</code>.</li>
      <li class="numbered">If there are no available processes in the <code class="Code-In-Text--PACKT-">pool</code> and we have already reached the maximum number of running processes, we have to wait for one to be available. We achieve this by queuing the <code class="Code-In-Text--PACKT-">resolve()</code> and <code class="Code-In-Text--PACKT-">reject()</code> callbacks of the outer promise, for later use.</li>
      <li class="numbered">If we haven't reached the maximum number of running processes yet, we create a new one using <code class="Code-In-Text--PACKT-">child_process.fork()</code>. Then, we wait for the <code class="Code-In-Text--PACKT-">ready</code> message coming from the newly launched process, which indicates that the process has started and is ready to accept new jobs. This message-based channel is automatically provided with all processes started with <code class="Code-In-Text--PACKT-">child_process.fork()</code>.</li>
    </ol>
    <p class="normal">The last method of the <code class="Code-In-Text--PACKT-">ProcessPool</code> class is <code class="Code-In-Text--PACKT-">release()</code>, whose purpose is to put a process back into the <code class="Code-In-Text--PACKT-">pool</code> once we are done with it:</p>
    <pre class="programlisting code"><code class="hljs-code">release (worker) {
  if (this.waiting.length &gt; 0) {                           // (1)
    const { resolve } = this.waiting.shift()
    return resolve(worker)
  }
  this.active = this.active.filter(w =&gt; worker !== w)      // (2)
  this.pool.push(worker)
}
</code></pre>
    <p class="normal">This is how the <code class="Code-In-Text--PACKT-">release()</code> method works:</p>
    <ol>
      <li class="numbered">If there is a request in the <code class="Code-In-Text--PACKT-">waiting</code> list, we simply reassign the <code class="Code-In-Text--PACKT-">worker</code> we are releasing by passing it to the <code class="Code-In-Text--PACKT-">resolve()</code> callback at the head of the <code class="Code-In-Text--PACKT-">waiting</code> queue.</li>
      <li class="numbered">Otherwise, we remove the worker that we are releasing from the <code class="Code-In-Text--PACKT-">active</code> list and put it back into the <code class="Code-In-Text--PACKT-">pool</code>.</li>
    </ol>
    <p class="normal">As we can see, the processes are never stopped but just reassigned, allowing us to save time by <a id="_idIndexMarker1073"/>not restarting them at each request. However, it's important to observe that this might not always be the best choice, and this greatly depends on the requirements of your application.</p>
    <p class="normal">Other possible tweaks for reducing long-term memory usage and adding resilience to our process pool are:</p>
    <ul>
      <li class="Bullet--PACKT-">Terminate idle processes to free memory after a certain time of inactivity.</li>
      <li class="Bullet-End--PACKT-">Add a mechanism to kill non-responsive processes or restart those that have crashed.</li>
    </ul>
    <p class="normal">In this example, we will keep the implementation of our process pool simple as the details we could add are really endless.</p>
    <h4 class="title">Communicating with a child process</h4>
    <p class="normal">Now that our <code class="Code-In-Text--PACKT-">ProcessPool</code> class is ready, we can use it to implement the <code class="Code-In-Text--PACKT-">SubsetSumFork</code> class, whose role <a id="_idIndexMarker1074"/>is to communicate with the worker and forward the results it produces. As we already mentioned, starting a process with <code class="Code-In-Text--PACKT-">child_process.fork()</code> also gives us a simple message-based communication channel, so let's see how this works by implementing the <code class="Code-In-Text--PACKT-">subsetSumFork.js</code> module:</p>
    <pre class="programlisting code"><code class="hljs-code">import { EventEmitter } from 'events'
import { dirname, join } from 'path'
import { fileURLToPath } from 'url'
import { ProcessPool } from './processPool.js'
const __dirname = dirname(fileURLToPath(import.meta.url))
const workerFile = join(__dirname,
  'workers', 'subsetSumProcessWorker.js')
const workers = new ProcessPool(workerFile, 2)
export class SubsetSum extends EventEmitter {
  constructor (sum, set) {
    super()
    this.sum = sum
    this.set = set
  }
  async start () {
    const worker = await workers.acquire()                 // (1)
    worker.send({ sum: this.sum, set: this.set })
    const onMessage = msg =&gt; {
      if (msg.event === 'end') {                           // (3)
        worker.removeListener('message', onMessage)
        workers.release(worker)
      }
      this.emit(msg.event, msg.data)                       // (4)
    }
    worker.on('message', onMessage)                        // (2)
  }
}
</code></pre>
    <p class="normal">The first thing to note is that we created a new <code class="Code-In-Text--PACKT-">ProcessPool</code> object using the file <code class="Code-In-Text--PACKT-">./workers/subsetSumProcessWorker.js</code> as the child worker. We also set the maximum capacity of the pool to <code class="Code-In-Text--PACKT-">2</code>.</p>
    <p class="normal">Another point <a id="_idIndexMarker1075"/>worth mentioning is that we tried to maintain the same public API of the original <code class="Code-In-Text--PACKT-">SubsetSum</code> class. In fact, <code class="Code-In-Text--PACKT-">SubsetSumFork</code> is an <code class="Code-In-Text--PACKT-">EventEmitter</code> whose constructor accepts <code class="Code-In-Text--PACKT-">sum</code> and <code class="Code-In-Text--PACKT-">set</code>, while the <code class="Code-In-Text--PACKT-">start()</code> method triggers the execution of the algorithm, which, this time, runs on a separate process. This is what happens when the <code class="Code-In-Text--PACKT-">start()</code> method is invoked:</p>
    <ol>
      <li class="numbered">We try to acquire a new child process from the pool. When the operation completes, we immediately use the <code class="Code-In-Text--PACKT-">worker</code> handle to send a message to the child process with the data of the job to run. The <code class="Code-In-Text--PACKT-">send()</code> API is provided automatically by Node.js to all processes started with <code class="Code-In-Text--PACKT-">child_process.fork()</code>. This is essentially the communication channel that we were talking about.</li>
      <li class="numbered">We then start listening for any message sent by the worker process using the <code class="Code-In-Text--PACKT-">on()</code> method to attach a new listener (this is also a part of the communication channel provided by all processes started with <code class="Code-In-Text--PACKT-">child_process.fork()</code>).</li>
      <li class="numbered">In the <code class="Code-In-Text--PACKT-">onMessage</code> listener, we first check if we received an <code class="Code-In-Text--PACKT-">end</code> event, which means that the <code class="Code-In-Text--PACKT-">SubsetSum</code> task has finished, in which case we remove the <code class="Code-In-Text--PACKT-">onMessage</code> listener and release the <code class="Code-In-Text--PACKT-">worker</code>, putting it back into the pool.</li>
      <li class="numbered">The worker produces messages in the format <code class="Code-In-Text--PACKT-">{event, data}</code>, allowing us to seamlessly forward (re-emit) any event produced by the child process.</li>
    </ol>
    <p class="normal">That's it <a id="_idIndexMarker1076"/>for the <code class="Code-In-Text--PACKT-">SubsetSumFork</code> wrapper. Let's now implement the worker (our child process).</p>
    <div><p class="Information-Box--PACKT-">It is good to know that the <code class="Code-In-Text--PACKT-">send()</code> method available on a child process instance can also be used to propagate a socket handle from the main application to a child process (look at the documentation at <a href="http://nodejsdp.link/childprocess-send">nodejsdp.link/childprocess-send</a>). This is actually the technique used by the <code class="Code-In-Text--PACKT-">cluster</code> module to distribute the load of an HTTP server across multiple processes. We will see this in more detail in the next chapter.</p>
    </div>
    <h4 class="title">Implementing the worker</h4>
    <p class="normal">Let's now <a id="_idIndexMarker1077"/>create the <code class="Code-In-Text--PACKT-">workers/subsetSumProcessWorker.js</code> module, our worker process:</p>
    <pre class="programlisting code"><code class="hljs-code">import { SubsetSum } from '../subsetSum.js'
process.on('message', msg =&gt; {                             // (1)
  const subsetSum = new SubsetSum(msg.sum, msg.set)
  subsetSum.on('match', data =&gt; {                          // (2)
    process.send({ event: 'match', data: data })
  })
  subsetSum.on('end', data =&gt; {
    process.send({ event: 'end', data: data })
  })
  subsetSum.start()
})
process.send('ready')
</code></pre>
    <p class="normal">We can immediately see that we are reusing the original (and synchronous) <code class="Code-In-Text--PACKT-">SubsetSum</code> as it is. Now that we are in a separate process, we don't have to worry about blocking the event loop anymore; all the HTTP requests will continue to be handled by the event loop of the main application without disruptions.</p>
    <p class="normal">When the <a id="_idIndexMarker1078"/>worker is started as a child process, this is what happens:</p>
    <ol>
      <li class="numbered">It immediately starts listening for messages coming from the parent process. This can be easily done with the <code class="Code-In-Text--PACKT-">process.on()</code> function (a part of the communication API provided when the process is started with <code class="Code-In-Text--PACKT-">child_process.fork()</code>). <p class="numbered">The only message we expect from the parent process is the one providing the input to a new <code class="Code-In-Text--PACKT-">SubsetSum</code> task. As soon as such a message is received, we create a new instance of the <code class="Code-In-Text--PACKT-">SubsetSum</code> class and register the listeners for the <code class="Code-In-Text--PACKT-">match</code> and <code class="Code-In-Text--PACKT-">end</code> events. Lastly, we start the computation with <code class="Code-In-Text--PACKT-">subsetSum.start()</code>.</p>
      </li>
      <li class="numbered">Every time an event is received from the running algorithm, we wrap it in an object having the format <code class="Code-In-Text--PACKT-">{event, data}</code> and send it to the parent process. These messages are then handled in the <code class="Code-In-Text--PACKT-">subsetSumFork.js</code> module, as we have seen in the previous section.</li>
    </ol>
    <p class="normal">As we can see, we just had to wrap the algorithm we already built, without modifying its internals. This clearly shows that any portion of an application can be easily put in an external process by simply using the technique we have just seen.</p>
    <div><p class="Information-Box--PACKT-">When the child process is not a Node.js program, the simple communication channel we just described (<code class="Code-In-Text--PACKT-">on()</code>, <code class="Code-In-Text--PACKT-">send()</code>) is not available. In these situations, we can still establish an interface with the child process by implementing our own protocol on top of the standard input and standard output streams, which are exposed to the parent process. To find out more about all the capabilities of the <code class="Code-In-Text--PACKT-">child_process</code> API, you can refer to the official Node.js documentation at <a href="http://nodejsdp.link/child_process">nodejsdp.link/child_process</a>.</p>
    </div>
    <h3 id="_idParaDest-319" class="title">Considerations for the multi-process approach</h3>
    <p class="normal">As always, to try this new version of the subset sum algorithm, we simply have to replace <a id="_idIndexMarker1079"/>the module used by the HTTP server (the <code class="Code-In-Text--PACKT-">index.js</code> file):</p>
    <pre class="programlisting code"><code class="hljs-code">import { createServer } from 'http'
// import { SubsetSum } from './subsetSum.js'
// import { SubsetSum } from './subsetSumDefer.js'
<strong class="hljs-keyword-slc">import</strong><strong class="hljs-slc"> { SubsetSum } </strong><strong class="hljs-keyword-slc">from</strong><strong class="hljs-slc"> </strong><strong class="hljs-string-slc">'./subsetSumFork.js'</strong>
createServer((req, res) =&gt; {
//...
</code></pre>
    <p class="normal">We can now start the server again and try to send a sample request:</p>
    <pre class="programlisting con"><code class="hljs-con">curl -G http://localhost:8000/subsetSum --data-urlencode "data=[16, 19,1,1,-16,9,1,-5,-2,17,-15,-97,19,-16,-4,-5,15]" --data-urlencode "sum=0"
</code></pre>
    <p class="normal">As for the interleaving approach that we saw previously, with this new version of the <code class="Code-In-Text--PACKT-">SubsetSum</code> module, the event loop is not blocked while running the CPU-bound task. This can be confirmed by sending another concurrent request, as follows:</p>
    <pre class="programlisting con"><code class="hljs-con">curl -G http://localhost:8000
</code></pre>
    <p class="normal">The preceding command should immediately return the text <code class="Code-In-Text--PACKT-">I'm alive!</code></p>
    <p class="normal">More interestingly, we can also try to start two <code class="Code-In-Text--PACKT-">SubsetSum</code> tasks concurrently and we will be able to see that they will use the full power of two different processors in order to run (if your system has more than one processor, of course). Instead, if we try to run three <code class="Code-In-Text--PACKT-">SubsetSum</code> tasks concurrently, the result should be that the last one to start will hang. This is not because the event loop of the main process is blocked, but because we set a concurrency limit of two processes for the <code class="Code-In-Text--PACKT-">SubsetSum</code> task, which means that the third request will be handled as soon as at least one of the two processes in the pool becomes available again.</p>
    <p class="normal">As we saw, the multi-process approach has many advantages compared to the interleaving approach. First, it doesn't introduce any computational penalty when running the algorithm. Second, it can take full advantage of a multi-processor machine.</p>
    <p class="normal">Now, let's see an alternative approach that uses threads instead of processes.</p>
    <h2 id="_idParaDest-320" class="title">Using worker threads</h2>
    <p class="normal">Since Node 10.5.0, we have a new mechanism for running CPU-intensive algorithms outside of the <a id="_idIndexMarker1080"/>main event loop called <strong class="keyword">worker threads</strong>. Worker threads can be seen as a lightweight alternative to <code class="Code-In-Text--PACKT-">child_process.fork()</code> with some extra goodies. Compared to processes, worker threads have a smaller memory footprint and a faster startup time since they run within the main process but inside different threads.</p>
    <p class="normal">Even though <a id="_idIndexMarker1081"/>worker threads are based on real threads, they don't allow the deep synchronization and sharing capabilities supported by other languages such as Java or Python. This is because JavaScript is a single-threaded language and it doesn't have any built-in mechanism to synchronize access to variables from multiple threads. JavaScript with threads simply wouldn't be JavaScript. The solution to bring all the advantages of threads within Node.js without actually changing the language is worker threads.</p>
    <p class="normal">Worker threads are essentially threads that, by default, don't share anything with the main application thread; they run within their own V8 instance, with an independent Node.js runtime and event loop. Communication with the main thread is possible thanks to message-based communication channels, the transfer of <code class="Code-In-Text--PACKT-">ArrayBuffer</code> objects, and the use of <code class="Code-In-Text--PACKT-">SharedArrayBuffer</code> objects whose synchronization is managed by the user (usually with the help of <code class="Code-In-Text--PACKT-">Atomics</code>).</p>
    <div><p class="Information-Box--PACKT-">You can read more about <code class="Code-In-Text--PACKT-">SharedArrayBuffer</code> and <code class="Code-In-Text--PACKT-">Atomics</code> in the following article: <a href="http://nodejsdp.link/shared-array-buffer">nodejsdp.link/shared-array-buffer</a>. Even though the article focuses on Web Workers, a lot of concepts are similar to Node.js's worker threads.</p>
    </div>
    <p class="normal">This extensive level of isolation of worker threads from the main thread preserves the integrity of the language. At the same time, the basic communication facilities and data-sharing capabilities are more than enough for 99% of use cases.</p>
    <p class="normal">Now, let's use worker threads in our <code class="Code-In-Text--PACKT-">SubsetSum</code> example.</p>
    <h3 id="_idParaDest-321" class="title">Running the subset sum task in a worker thread</h3>
    <p class="normal">The worker <a id="_idIndexMarker1082"/>threads API has a lot in common <a id="_idIndexMarker1083"/>with that of <code class="Code-In-Text--PACKT-">ChildProcess</code>, so the changes to our code will be minimal.</p>
    <p class="normal">First, we need to create a new class called <code class="Code-In-Text--PACKT-">ThreadPool</code>, which is our <code class="Code-In-Text--PACKT-">ProcessPool</code> adapted to operate with worker threads instead of processes. The following code shows the differences between the new <code class="Code-In-Text--PACKT-">ThreadPool</code> class and the <code class="Code-In-Text--PACKT-">ProcessPool</code> class. There are only a <a id="_idIndexMarker1084"/>few differences in the <code class="Code-In-Text--PACKT-">acquire()</code> method, which <a id="_idIndexMarker1085"/>are highlighted; the rest of the code is identical:</p>
    <pre class="programlisting code"><code class="hljs-code">import { Worker } from 'worker_threads'
export class ThreadPool {
  // ...
  acquire () {
    return new Promise((resolve, reject) =&gt; {
      let worker
      if (this.pool.length &gt; 0) {
        worker = this.pool.pop()
        this.active.push(worker)
        return resolve(worker)
      }
      if (this.active.length &gt;= this.poolMax) {
        return this.waiting.push({ resolve, reject })
      }
      <strong class="hljs-slc">worker = </strong><strong class="hljs-keyword-slc">new</strong><strong class="hljs-slc"> Worker(</strong><strong class="hljs-built_in-slc">this</strong><strong class="hljs-slc">.file)</strong>
      <strong class="hljs-slc">worker.once(</strong><strong class="hljs-string-slc">'online'</strong><strong class="hljs-slc">, </strong><strong class="hljs-params-slc">()</strong><strong class="hljs-function-slc"> =&gt;</strong><strong class="hljs-slc"> {</strong>
        <strong class="hljs-built_in-slc">this</strong><strong class="hljs-slc">.active.push(worker)</strong>
        <strong class="hljs-slc">resolve(worker)</strong>
      <strong class="hljs-slc">})</strong>
      worker.once('exit', code =&gt; {
        console.log(`Worker exited with code ${code}`)
        this.active = this.active.filter(w =&gt; worker !== w)
        this.pool = this.pool.filter(w =&gt; worker !== w)
      })
    })
  }
  //...
}
</code></pre>
    <p class="normal">Next, we need to adapt the worker and place it in a new file called <code class="Code-In-Text--PACKT-">subsetSumThreadWorker.js</code>. The main difference from our old worker is that instead of using <code class="Code-In-Text--PACKT-">process.send()</code> and <code class="Code-In-Text--PACKT-">process.on()</code>, we'll have to use <code class="Code-In-Text--PACKT-">parentPort.postMessage()</code> and <code class="Code-In-Text--PACKT-">parentPort.on()</code>:</p>
    <pre class="programlisting code"><code class="hljs-code">import { parentPort } from 'worker_threads'
import { SubsetSum } from '../subsetSum.js'
parentPort.on('message', msg =&gt; {
  const subsetSum = new SubsetSum(msg.sum, msg.set)
  subsetSum.on('match', data =&gt; {
    parentPort.postMessage({ event: 'match', data: data })
  })
  subsetSum.on('end', data =&gt; {
    parentPort.postMessage({ event: 'end', data: data })
  })
  subsetSum.start()
})
</code></pre>
    <p class="normal">Similarly, the <a id="_idIndexMarker1086"/>module <code class="Code-In-Text--PACKT-">subsetSumThreads.js</code> is essentially the same as the <code class="Code-In-Text--PACKT-">subsetSumFork.js</code> module except for a <a id="_idIndexMarker1087"/>couple of lines of code, which are highlighted in the following code fragment:</p>
    <pre class="programlisting code"><code class="hljs-code">import { EventEmitter } from 'events'
import { dirname, join } from 'path'
import { fileURLToPath } from 'url'
<strong class="hljs-keyword-slc">import</strong><strong class="hljs-slc"> { ThreadPool } </strong><strong class="hljs-keyword-slc">from</strong><strong class="hljs-slc"> </strong><strong class="hljs-string-slc">'./threadPool.js'</strong>
const __dirname = dirname(fileURLToPath(import.meta.url))
<strong class="hljs-keyword-slc">const</strong><strong class="hljs-slc"> workerFile = join(__dirname,</strong>
  <strong class="hljs-string-slc">'workers'</strong><strong class="hljs-slc">, </strong><strong class="hljs-string-slc">'subsetSumThreadWorker.js'</strong><strong class="hljs-slc">)</strong>
<strong class="hljs-keyword-slc">const</strong><strong class="hljs-slc"> workers = </strong><strong class="hljs-keyword-slc">new</strong><strong class="hljs-slc"> ThreadPool(workerFile, </strong><strong class="hljs-number-slc">2</strong><strong class="hljs-slc">)</strong>
export class SubsetSum extends EventEmitter {
  constructor (sum, set) {
    super()
    this.sum = sum
    this.set = set
  }
  async start () {
    const worker = await workers.acquire()
    <strong class="hljs-slc">worker.postMessage({ </strong><strong class="hljs-attr-slc">sum</strong><strong class="hljs-slc">: </strong><strong class="hljs-built_in-slc">this</strong><strong class="hljs-slc">.sum, </strong><strong class="hljs-attr-slc">set</strong><strong class="hljs-slc">: </strong><strong class="hljs-built_in-slc">this</strong><strong class="hljs-slc">.set })</strong>
    const onMessage = msg =&gt; {
      if (msg.event === 'end') {
        worker.removeListener('message', onMessage)
        workers.release(worker)
      }
      this.emit(msg.event, msg.data)
    }
    worker.on('message', onMessage)
  }
}
</code></pre>
    <p class="normal">As we've seen, adapting an existing application to use worker threads instead of forked processes <a id="_idIndexMarker1088"/>is a trivial operation. This is because the API of the two components are very similar, but also because a worker thread <a id="_idIndexMarker1089"/>has a lot in common with a full-fledged Node.js process.</p>
    <p class="normal">Finally, we need to update the <code class="Code-In-Text--PACKT-">index.js</code> module so that it can use the new <code class="Code-In-Text--PACKT-">subsetSumThreads.js</code> module, as we've seen for the other implementations of the algorithm:</p>
    <pre class="programlisting code"><code class="hljs-code">import { createServer } from 'http'
// import { SubsetSum } from './subsetSum.js'
// import { SubsetSum } from './subsetSumDefer.js'
// import { SubsetSum } from './subsetSumFork.js'
<strong class="hljs-keyword-slc">import</strong><strong class="hljs-slc"> { SubsetSum } </strong><strong class="hljs-keyword-slc">from</strong><strong class="hljs-slc"> </strong><strong class="hljs-string-slc">'./subsetSumThreads.js'</strong>
createServer((req, res) =&gt; {
  // ...
</code></pre>
    <p class="normal">Now, you can try the new version of the subset sum server using worker threads. As for the previous <a id="_idIndexMarker1090"/>two implementations, the event <a id="_idIndexMarker1091"/>loop of the main application is not blocked by the subset sum algorithm as it runs in a separate thread.</p>
    <div><p class="Tip--PACKT-">The example we've seen uses only a small subset of all the capabilities offered by worker threads. For more advanced topics such as transferring <code class="Code-In-Text--PACKT-">ArrayBuffer</code> objects or <code class="Code-In-Text--PACKT-">SharedArrayBuffer</code> objects, you can read the official API documentation at <a href="http://nodejsdp.link/worker-threads">nodejsdp.link/worker-threads</a>.</p>
    </div>
    <h2 id="_idParaDest-322" class="title">Running CPU-bound tasks in production</h2>
    <p class="normal">The examples we've seen so far should give you an idea of the tools at our disposal for running CPU-intensive operations in Node.js. However, components such as process pools and <a id="_idIndexMarker1092"/>thread pools are complex pieces of machinery that require proper mechanisms to deal with timeouts, errors, and other types of failures, which, for brevity, we left out from our implementation. Therefore, unless you have special requirements, it's better to rely on more battle-tested libraries for production use. Two of those libraries are <code class="Code-In-Text--PACKT-">workerpool</code> (<a href="http://nodejsdp.link/workerpool">nodejsdp.link/workerpool</a>) and <code class="Code-In-Text--PACKT-">piscina</code> (<a href="http://nodejsdp.link/piscina">nodejsdp.link/piscina</a>), which are based on the same concepts we've seen in this section. They allow us to coordinate the execution of CPU-intensive tasks using external processes or worker threads.</p>
    <p class="normal">One last observation is that we must consider that if we have particularly complex algorithms to run or if the number of CPU-bound tasks exceeds the capacity of a single node, we may have to think about scaling out the computation across multiple nodes. This is a completely different problem and we'll learn more about this in the next two chapters.</p>
    <h1 id="_idParaDest-323" class="title">Summary</h1>
    <p class="normal">This chapter added some great new weapons to our toolbelt, and as you can see, our journey is getting more focused on advanced problems. Due to this, we have started to delve deeply into more complex solutions. This chapter gave us not only a set of recipes to reuse and customize for our needs, but also some great demonstrations of how mastering a few principles and patterns can help us tackle the most complex problems in Node.js development.</p>
    <p class="normal">The next two chapters represent the peak of our journey. After studying the various tactics of Node.js development, we are now ready to move on to the strategies and explore the architectural patterns for scaling and distributing our Node.js applications.</p>
    <h1 id="_idParaDest-324" class="title">Exercises</h1>
    <ul>
      <li class="Bullet--PACKT-"><strong class="keyword">11.1 Proxy with pre-initialization queues</strong>: Using a JavaScript Proxy, create a wrapper for adding pre-initialization queues to any object. You should allow the consumer of the wrapper to decide which methods to augment and the name of the property/event that indicates if the component is initialized.</li>
      <li class="Bullet--PACKT-"><strong class="keyword">11.2 Batching and caching with callbacks</strong>: Implement batching and caching for the <code class="Code-In-Text--PACKT-">totalSales</code> API examples using only callbacks, streams, and events (without using promises or async/await). Hint: Pay attention to Zalgo when returning cached values!</li>
      <li class="Bullet--PACKT-"><strong class="keyword">11.3 Deep async cancelable</strong>: Extend the <code class="Code-In-Text--PACKT-">createAsyncCancelable()</code> function so that it's possible to invoke other cancelable functions from within the main cancelable function. Canceling the main operation should also cancel all nested operations. Hint: Allow to <code class="Code-In-Text--PACKT-">yield</code> the result of an <code class="Code-In-Text--PACKT-">asyncCancelable()</code> from within the generator function.</li>
      <li class="Bullet--PACKT-"><strong class="keyword">11.4 Compute farm</strong>: Create an HTTP server with a <code class="Code-In-Text--PACKT-">POST</code> endpoint that receives, as input, the code of a function (as a string) and an array of arguments, executes the function with the given arguments in a worker thread or in a separate process, and returns the result back to the client. Hint: You can use <code class="Code-In-Text--PACKT-">eval()</code>, <code class="Code-In-Text--PACKT-">vm.runInContext()</code>, or neither of the two. Note: Whatever code you produce for this exercise, please be aware that allowing users to run arbitrary code in a production setting can pose serious security risks, and you should never do it unless you know exactly what the implications are.</li>
    </ul>
  </div>
</body></html>