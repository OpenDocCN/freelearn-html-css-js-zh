<html><head></head><body><div class="chapter" title="Chapter&#xA0;2.&#xA0;Installing and Virtualizing Node Servers"><div class="titlepage"><div><div><h1 class="title"><a id="ch02"/>Chapter 2. Installing and Virtualizing Node Servers</h1></div></div></div><p>Recall the story from <a class="link" href="ch01.html" title="Chapter 1. Appreciating Node">Chapter 1</a>, <span class="emphasis"><em>Appreciating Node</em></span>, about how Walmart ran all of its <span class="emphasis"><em>Black Friday</em></span> mobile traffic through Node, which was deployed across <span class="emphasis"><em>the equivalent of 2 CPUs and 30 gigs of RAM</em></span>. This demonstrates that Node processes I/O so efficiently that even Walmart-level traffic on <span class="emphasis"><em>Black Friday</em></span> can be handled with only a few servers. This means that, for many people, running your Node application on a single server is all you'll ever need to do.</p><p>Nevertheless, it is often good to have several servers at your disposal, such as redundant servers to ensure failover recovery, a distinct database server, specialized media servers, one hosting a message queue, and so on. In keeping with the idea of separating concerns into many independent processes, Node-based applications are often composed of many lightweight servers spread across a data center, possibly even spread across several data centers.</p><p>In this chapter, we will look at the basics of setting up single Node servers concretely and virtually. The goal is to explore your options for <span class="emphasis"><em>mass producing</em></span> servers in response to scaling needs and to see how you can connect these together. You will learn how to set up an HTTP/S server yourself as well as how to do tunneling and proxying with Node. We'll then look at a few popular cloud-hosting solutions and how to set up Node servers on those. We'll close with a discussion <a id="id94" class="indexterm"/>on <span class="strong"><strong>Docker</strong></span>, an exciting new technology to create lightweight virtual services.</p><div class="section" title="Getting a basic Node server up and running"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec12"/>Getting a basic Node server up and running</h1></div></div></div><p>HTTP is a data<a id="id95" class="indexterm"/> transfer protocol built upon a request/response model. Normally, a client makes a request to a server, receives a response, makes another request, and so on. HTTP is stateless, which simply means that each request or response maintains no information on previous requests or responses. Facilitating this sort of rapid-pattern network communication is the sort of I/O that Node is designed to excel at. While Node represents a much more interesting technology stack overall, it does <a id="id96" class="indexterm"/>help engineers in creating networked protocol servers. In this section, we will move through a general overview of how to set up a basic HTTP server and then into a few more specialized uses of the protocol.</p><div class="section" title="Hello world"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec16"/>Hello world</h2></div></div></div><p>An HTTP server<a id="id97" class="indexterm"/> responds to connection attempts and <a id="id98" class="indexterm"/>manages data as it arrives and as it is sent along. A Node server is typically created using the <code class="literal">createServer</code> method of the HTTP module:</p><div class="informalexample"><pre class="programlisting">var http = require('http');

var server = http.createServer(function(request, response) {
  console.log('Got Request Headers: ');
  console.log(request.headers);
  response.writeHead(200, {
    'Content-Type': 'text/plain'
  });
  response.write('PONG');
  response.end();
}).listen(8080);</pre></div><p>The object returned by <code class="literal">http.createServer</code> is an instance of <code class="literal">http.Server</code>, which extends <code class="literal">EventEmitter</code> and broadcasts network events as they occur, such as a client connection or request. Most server implementations using Node use this method of instantiation. However, listening for event broadcasts by an <code class="literal">http.Server</code> instance can be a more useful, even natural, way to organize server/client interactions within a Node program.</p><p>Here, we create a basic server that simply reports when a connection is made and when it is terminated:</p><div class="informalexample"><pre class="programlisting">var http = require('http');
var server = new http.Server();

server.on("connection", function(socket) {
  console.log("Client arrived: " + new Date());
  socket.on("end", function() {
    console.log("Client left: " + new Date());
  });
})

server.listen(8080);</pre></div><p>When building multiuser systems, especially authenticated multiuser systems, this point in the server-client transaction is an excellent place for client validation and a tracking code. Cookies <a id="id99" class="indexterm"/>can be set and read, along with other <a id="id100" class="indexterm"/>session variables. A client arrival event can be broadcast to other concurrent clients interacting within real-time applications.</p><p>By adding a listener for requests, we arrive at the more common request/response pattern, handled as a <code class="literal">Readable</code> stream. When a client posts data, we can catch that data, as shown here:</p><div class="informalexample"><pre class="programlisting">server.on("request", function(request, response) {
  request.setEncoding("utf8");
  request.on("readable", function() {
    console.log(request.read())
  });
});</pre></div><p>Send this<a id="id101" class="indexterm"/> server some data using <span class="strong"><strong>curl</strong></span>:</p><div class="informalexample"><pre class="programlisting">curl http://localhost:8080 -d "Here is some data"</pre></div><p>Using connection events, we can nicely separate our connection-handling code, grouping it into clearly defined functional domains, which are correctly described as executing in response to particular events.</p><p>For example, we can set timers on server connections. Here, we can terminate client connections that fail to send new data within a roughly 2-second window:</p><div class="informalexample"><pre class="programlisting">server.setTimeout(2000, function(socket) {
  socket.write("Too Slow!", "utf8");
  socket.end();
});</pre></div></div><div class="section" title="Making HTTP requests"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec17"/>Making HTTP requests</h2></div></div></div><p>HTTP servers<a id="id102" class="indexterm"/> are often called upon to perform HTTP<a id="id103" class="indexterm"/> services for clients making requests. Most commonly, this sort of proxying was done on behalf of web applications running in browsers with restrictions on cross-domain requests. Node provides an easy interface to make external HTTP calls.</p><p>For example, the following code will fetch the front page of <a class="ulink" href="http://google.com">google.com</a>:</p><div class="informalexample"><pre class="programlisting">var http = require('http');

http.request({
  host: 'www.google.com',
  method: 'GET',
  path: "/"
}, function(response) {
  response.setEncoding('utf8');
  response.on('readable', function() {
    console.log(response.read())
  });
}).end();</pre></div><p>Here, we <a id="id104" class="indexterm"/>simply dump a <code class="literal">Readable</code> stream to the <a id="id105" class="indexterm"/>terminal, but this stream could easily be piped to a <code class="literal">Writable</code> stream, perhaps bound to a file handle. Note that you must always signify that you're done with a request using the <code class="literal">request.end</code> method.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip03"/>Tip</h3><p>A<a id="id106" class="indexterm"/> popular Node module to manage HTTP requests <a id="id107" class="indexterm"/>is Mikeal Rogers' <span class="strong"><strong>request</strong></span>:</p><p>
<a class="ulink" href="https://github.com/mikeal/request">https://github.com/mikeal/request</a>
</p></div></div><p>Because it is common to use <code class="literal">HTTP.request</code> in order to GET external pages, Node offers a shortcut:</p><div class="informalexample"><pre class="programlisting">http.get("http://www.google.com/", function(response) {
  console.log("Status: " + response.statusCode);
}).on('error', function(err) {
  console.log("Error: " + err.message);
});</pre></div><p>Let's now look at a few more advanced implementations of HTTP servers, where we perform general network services for clients.</p></div><div class="section" title="Proxying and tunneling"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec18"/>Proxying and tunneling</h2></div></div></div><p>Sometimes, it is <a id="id108" class="indexterm"/>useful to <a id="id109" class="indexterm"/>provide a means <a id="id110" class="indexterm"/>for<a id="id111" class="indexterm"/> one server to function as a proxy, or broker, for other servers. This would allow one server to distribute requests to other servers, for example. Another use would be to provide access to a secured server to users who are unable to connect to that server directly—this is often seen in countries that place restrictions on Internet access. It is also common to have one server answering for more than one URL using a proxy; that one server can forward requests to the right recipient.</p><p>Because Node has consistent network interfaces implemented as evented streams, we can build a simple HTTP proxy in just a few lines of code. For example, the following program will <a id="id112" class="indexterm"/>set up an HTTP server on port <code class="literal">8080</code>, which will respond <a id="id113" class="indexterm"/>to any request by fetching the front page of Google<a id="id114" class="indexterm"/> and <a id="id115" class="indexterm"/>piping that back to the client:</p><div class="informalexample"><pre class="programlisting">var http = require('http');
var server = new http.Server();

server.on("request", function(request, socket) {
  http.request({
    host: 'www.google.com',
    method: 'GET',
    path: "/",
    port: 80
  }, function(response) {
    response.pipe(socket);
  }).end();
});

server.listen(8080);</pre></div><p>Once this server receives the client socket, it is free to push content from any readable stream back to the client. Here, the result of the GET of <a class="ulink" href="http://www.google.com">www.google.com</a> is so streamed. One can easily see how an external content server managing a caching layer for your application might become a proxy endpoint.</p><p>Using similar ideas, we can create a tunneling service using Node's native CONNECT support:</p><div class="informalexample"><pre class="programlisting">var http = require('http');
var net = require('net');
var url = require('url');
var proxy = new http.Server();

proxy.on('connect', function(request, clientSocket, head) {
  var reqData = url.parse('http://' + request.url);
  var remoteSocket = net.connect(reqData.port, reqData.hostname, function() {
    clientSocket.write('HTTP/1.1 200 \r\n\r\n');
    remoteSocket.write(head);

    // The bi-directional tunnel
    remoteSocket.pipe(clientSocket);
    clientSocket.pipe(remoteSocket);
  });
}).listen(8080, function() {</pre></div><p>We've set up a proxy server that responds to clients requesting an HTTP CONNECT method [<code class="literal">on("connect")</code>], which contains the request object, the network socket-binding client and <a id="id116" class="indexterm"/>server, and the 'head' (the first packet) of the tunneling<a id="id117" class="indexterm"/> stream. When a CONNECT request is received from a <a id="id118" class="indexterm"/>client, we<a id="id119" class="indexterm"/> parse out <code class="literal">request.url</code>, fetch the requested host information, and open the requested network socket. By piping remote data to the client and client data to the remote connection, a bidirectional data tunnel is established. Now we need only make the CONNECT request to our proxy, as follows:</p><div class="informalexample"><pre class="programlisting">  var request = http.request({
    port: 8080,
    hostname: 'localhost',
    method: 'CONNECT',
    path: 'www.google.com:80'
  });
  request.end();</pre></div><p>Once a status 200 confirmation of our CONNECT request is received, we can push request packets down this tunnel, catching responses and dumping those to <code class="literal">stdout</code>:</p><div class="informalexample"><pre class="programlisting">  request.on('connect', function(res, socket, head) {
    socket.setEncoding("utf8");
    socket.write('GET / HTTP/1.1\r\nHost: www.google.com:80\r\nConnection: close\r\n\r\n');
    socket.on('readable', function() {
      console.log(socket.read());
    });
    socket.on('end', function() {
      proxy.close();
    });
  });
});</pre></div></div><div class="section" title="HTTPS, TLS (SSL), and securing your server"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec19"/>HTTPS, TLS (SSL), and securing your server</h2></div></div></div><p>Web <a id="id120" class="indexterm"/>applications<a id="id121" class="indexterm"/> have grown in<a id="id122" class="indexterm"/> size, importance, and complexity. The security of web applications has, therefore, become an important topic. For one reason or another, early web applications were allowed to venture into the experimental world of client-side business logic, unsecured password transmission, and open web services while shielded by only a diaphanous curtain. This is becoming harder to find among users interested in the security of their information.</p><p>As Node<a id="id123" class="indexterm"/> is <a id="id124" class="indexterm"/>regularly deployed as a web server, it is imperative that the community begins to accept responsibility for securing these servers. HTTPS is a secure transmission protocol—essentially, encrypted HTTP formed by layering the HTTP protocol on top of the SSL/TLS protocol. Let's learn how to secure our Node deployments.</p></div><div class="section" title="Creating a self-signed certificate for development"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec20"/>Creating a self-signed certificate for development</h2></div></div></div><p>In order to<a id="id125" class="indexterm"/> support SSL connections, a server will<a id="id126" class="indexterm"/> need a properly signed certificate. While developing, it is much easier to simply create a self-signed certificate, allowing us to use Node's HTTPS module.</p><p>These are the steps needed to create a certificate for development. Remember that this process does not create a real certificate, and the generated certificate is <span class="emphasis"><em>not secure</em></span>—it simply allows us to develop within an HTTPS environment from a terminal:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>openssl genrsa -out server-key.pem 2048</strong></span>
<span class="strong"><strong>openssl req -new -key server-key.pem -out server-csr.pem</strong></span>
<span class="strong"><strong>openssl x509 -req -in server-csr.pem -signkey server-key.pem -out server-cert.pem</strong></span>
</pre></div><p>These keys can now be used to develop HTTPS servers. The contents of these files need simply be passed along as options to a Node server running on the (default) SSL port <code class="literal">443</code>:</p><div class="informalexample"><pre class="programlisting">var https = require('https');
var fs = require('fs');

https.createServer({
  key: fs.readFileSync('server-key.pem'),
  cert: fs.readFileSync('server-cert.pem')
}, function(req,res) {
   ...
}).listen(443)</pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note06"/>Note</h3><p>Free <span class="strong"><strong>low-assurance</strong></span> SSL certificates<a id="id127" class="indexterm"/> are<a id="id128" class="indexterm"/> available from <a class="ulink" href="http://www.startssl.com/">http://www.startssl.com/</a> for cases where self-signed certificates are not ideal during<a id="id129" class="indexterm"/> development.</p></div></div></div><div class="section" title="Installing a real SSL certificate"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec21"/>Installing a real SSL certificate</h2></div></div></div><p>In order to move a secure application out of a development environment and into an Internet-exposed environment, a real certificate will need to be purchased. The prices of these <a id="id130" class="indexterm"/>certificates have been dropping year by year, and it<a id="id131" class="indexterm"/> should be easy to find providers of reasonably priced certificates with a high enough level of security. Some providers even offer free personal-use certificates.</p><p>Setting up a professional certificate simply requires changing the HTTPS options we introduced previously. Different providers will have different processes and filenames. Typically, you will need to download or, otherwise, receive a private <code class="literal">#key</code> file from your provider, your signed domain certificate <code class="literal">#crt</code> file, and a general bundle <code class="literal">#ca</code> describing certificate chains:</p><div class="informalexample"><pre class="programlisting">var options = {
  key  : fs.readFileSync('mysite.key'),
  cert  : fs.readFileSync('mysite.com.crt'),
  ca  : [ fs.readFileSync('gd_bundle.crt') ]
};</pre></div><p>It is important to note that the <code class="literal">#ca</code> parameter must be sent as an <span class="emphasis"><em>array</em></span> even if the bundle of certificates has been concatenated into one file.</p><p>Here are the key takeaways of this:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">HTTP sockets are abstracted into evented streams. This is true for all network interfaces provided by Node. These streams can easily be connected to one another.</li><li class="listitem" style="list-style-type: disc">Because stream activity is evented, those events can be recorded. Very precise logging information on the behavior of a system can be recorded either in event handlers or by piping streams through a <code class="literal">PassThrough Stream</code> parameter that might listen for and record events.</li><li class="listitem" style="list-style-type: disc">Node excels as an I/O service. Node servers can act as dispatchers solely interested in brokering communication between a client and any number of remote services or even specialized processes running on a local OS.</li></ul></div><p>Now that you know how to set up an HTTP server and work with the protocol within Node, go ahead and experiment. Create a small application on your local machine that allows users to read a Twitter feed or connect to a public data API. Get used to authenticating remote services over the wire and interacting with them either through their API <a id="id132" class="indexterm"/>or by otherwise acting as a proxy for their<a id="id133" class="indexterm"/> data. Get used to composing network applications by integrating remote network services using Node as a broker.</p><p>Running your own servers in production can be expensive and time consuming, especially if you aren't familiar with systems administration. For this reason, a large number of cloud-hosting companies have sprung up and many are designed specifically for the Node developer.</p><p>Let's take a look at a few of them. By way of comparison, the same Node application will be deployed <a id="id134" class="indexterm"/>on each—an editable JSON document stored in <span class="strong"><strong>MongoDB</strong></span> bound to a simple<a id="id135" class="indexterm"/> browser-based <span class="strong"><strong>User Interface</strong></span> (<span class="strong"><strong>UI</strong></span>). You are encouraged to try these services out in order, which is not necessary though.</p></div></div></div>
<div class="section" title="Installing applications on Heroku"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec13"/>Installing applications on Heroku</h1></div></div></div><p>Heroku is<a id="id136" class="indexterm"/> a<a id="id137" class="indexterm"/> mature PaaS cloud-hosting solution that supports the development of Node applications. To get started, visit <a class="ulink" href="http://www.heroku.com">http://www.heroku.com</a> and<a id="id138" class="indexterm"/> submit an e-mail address. Heroku is free to start with. After you've confirmed your account, you can start deploying apps right away.</p><p>Scaling Heroku applications involves increasing the number of <span class="emphasis"><em>dynos</em></span> that you are paying for. Each <span class="strong"><strong>dyno</strong></span> is<a id="id139" class="indexterm"/> an isolated container running your application and you are able to increase or decrease the number of dynos your application uses with ease. In this way, there aren't any hosting <span class="emphasis"><em>packages</em></span> to buy—you simply scale as needed by asking for more, or fewer, dynos.</p><p>Heroku allows you to deploy applications on many platforms and languages—it is not Node-centric. This is something to keep in mind should you anticipate the need to add services to your application not written in Node.</p><p>To<a id="id140" class="indexterm"/> control Heroku remote instances, you will use a local <span class="emphasis"><em>utility belt</em></span> application. Once you've joined Heroku and confirmed your signup, log in and go to the <span class="strong"><strong>Apps</strong></span> section of <a id="id141" class="indexterm"/>your dashboard. There should be instructions there on installing Heroku <a id="id142" class="indexterm"/>Toolbelt (<a class="ulink" href="https://toolbelt.heroku.com/">https://toolbelt.heroku.com/</a>).</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note07"/>Note</h3><p>The <code class="literal">heroku</code> command-line client will be installed in <code class="literal">/usr/local/heroku</code> and <code class="literal">/usr/local/heroku/bin</code> will be added to your path.</p></div></div><p>Once you have Toolbelt installed, open a terminal and log in to Heroku with <code class="literal">heroku login</code>. Since this is your first time, you will most likely be asked to generate a public key. Once this key is generated and uploaded, you are secure, and, going forward, you can administer your Heroku deployments via Toolbelt and the command line.</p><p>Heroku recognizes your application as a Node application if it finds a <code class="literal">package.json</code> file in the root directory of your application folder. Our sample app already contains one, so there is no need to create another. However, as Heroku is not an exclusive Node host, it does not automatically find the start script for our -- <code class="literal">server.js </code>-- application at the <code class="literal">start</code> attribute of that package file:</p><div class="informalexample"><pre class="programlisting">"scripts": {
  "start": "node server.js"
}</pre></div><p>Instead, Heroku requires what is <a id="id143" class="indexterm"/>called <span class="strong"><strong>Procfile</strong></span>. Create a <code class="literal">Procfile</code> file in the root directory of our sample application and insert the following text into it:</p><div class="informalexample"><pre class="programlisting">web: node server.js</pre></div><p>It's slightly different, but we can see that the effect is ultimately the same. Procfile declares that we want a "web" process—the process that will be spun up after the command <code class="literal">node server.js</code> is executed will expect to have HTTP traffic routed to it.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note08"/>Note</h3><p>When you installed Heroku Toolbelt, another application was also installed: <span class="strong"><strong>Foreman</strong></span>. Foreman<a id="id144" class="indexterm"/> helps you manage Procfile-based applications. Its primary importance for us is that it allows you to start Heroku applications locally. While you can simply update the <code class="literal">scripts</code> attribute of your Node package and run your application directly through Node, it does save a step. Try <code class="literal">foreman start</code> and visit <code class="literal">localhost:8080</code>.</p></div></div><p>In the following sections, we will look at how a repository is installed and managed on Heroku, and <a id="id145" class="indexterm"/>how to add to our applications on MongoDB, and we'll deploy a JSON editing application.</p><div class="section" title="Add-ons"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec22"/>Add-ons</h2></div></div></div><p>On Heroku, databases are understood as one of many add-ons. From logging tools, to caching layers, to <a id="id146" class="indexterm"/>databases, Heroku offers dozens of add-ons. Since we need a<a id="id147" class="indexterm"/> MongoDB instance to run our application, let's install one.</p><p>Note that, while a developer (sandbox) MongoDB instance from MongoLab is free, Heroku requires you to verify your account with a credit card. If you don't have a credit card, it is still possible to get a free MongoDB cloud account through other services and use those credentials for your Heroku application. In the end, we simply need a MongoDB endpoint somewhere to connect to.</p><p>To add a MongoDB account, run the <code class="literal">heroku addons:add mongolab</code> command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Adding mongolab on mighty-hamlet-7855... done, v14 (free)</strong></span>
<span class="strong"><strong>Welcome to MongoLab. Your new subscription is being created and will be available shortly. Please consult the MongoLab Add-on Admin UI to check on its progress.</strong></span>
</pre></div><p>Use <code class="literal">heroku addons:docs mongolab</code> to view documentation in your browser.</p><p>You just added a configuration option to your Heroku instance. Not surprisingly, you can view this information via <code class="literal">heroku config</code>, which will return you something like this:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>MONGOLAB_URI: mongodb://heroku_app2485743:ie02k3nnic3l0tjfgi3135inq@ds035488.mongolab.com:35488/heroku_app2487483</strong></span>
</pre></div><p>With our database established, let's now push our application into Heroku and get it running.</p></div><div class="section" title="Git"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec23"/>Git</h2></div></div></div><p>Deploying<a id="id148" class="indexterm"/> applications<a id="id149" class="indexterm"/> on Heroku involves pushing your local version into the remote application repository you just provisioned. There is no <code class="literal">heroku deploy</code> command; what you do is push to <span class="strong"><strong>Git</strong></span>, thus triggering post-receive hooks at Heroku's end. These deploy your app.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note09"/>Note</h3><p>If you're <a id="id150" class="indexterm"/>unfamiliar with Git, visit <a class="ulink" href="http://git-scm.com/book/en/Getting-Started-Git-Basics">http://git-scm.com/book/en/Getting-Started-Git-Basics</a>.</p></div></div><p>Let's try it out. Within your code bundle, there exists a <code class="literal">json-editor</code> folder. First, enter that folder and update the MongoDB connection and authentication code in <code class="literal">server.js</code> so that we<a id="id151" class="indexterm"/> can <a id="id152" class="indexterm"/>use the database connection defined earlier:</p><div class="informalexample"><pre class="programlisting">var mongodb = require('mongodb');
var db = new mongodb.Db('your_db_identifier',
  new mongodb.Server('dt019963.mongolab.com', 29960, {})
);
db.open(function (err, db_p) {
  if (err) { throw err; }
  db.authenticate('your_username', '6i490i5d3teoen62524vqkccgu', function (err, replies) {
    // You are now connected and authenticated.
  });
});</pre></div><p>Next, run the following commands in your terminal:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>git init</strong></span>
<span class="strong"><strong>git add .</strong></span>
<span class="strong"><strong>git commit -m "initial commit"</strong></span>
</pre></div><p>This initializes our application as a proper Git repository. Now, we need to inform Heroku of our new application and our new Git repository. Let's deploy.</p><p>From within the <code class="literal">json-editor</code> folder of your code bundle, use Heroku Toolbelt to create your first Heroku app:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>heroku create</strong></span>
</pre></div><p>If all goes well, you should see something like this in your terminal:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Creating mighty-hamlet-7855... done, stack is cedar</strong></span>
<span class="strong"><strong>http://mighty-hamlet-7855.herokuapp.com/ | git@heroku.com:mighty-hamlet-7855.git</strong></span>
<span class="strong"><strong>Git remote heroku added</strong></span>
</pre></div><p>If you visit that URL immediately, you will receive an error message. We haven't pushed our repository, so there is nothing deployed, which means there is nothing to show. To deploy an application to Heroku, push your local Git repo:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>git push heroku master</strong></span>
</pre></div><p>This should result in a lot of build output, clearly informing you of what is happening:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>-----&gt; Node.js app detected</strong></span>
<span class="strong"><strong>-----&gt; Requested node range: 0.10.x</strong></span>
<span class="strong"><strong>...</strong></span>
<span class="strong"><strong>-----&gt; Building runtime environment</strong></span>
<span class="strong"><strong>-----&gt; Discovering process types</strong></span>
<span class="strong"><strong>    Procfile declares types -&gt; web</strong></span>
<span class="strong"><strong>...</strong></span>
<span class="strong"><strong>-----&gt; Launching... done, v3</strong></span>
<span class="strong"><strong>    http://mighty-hamlet-7855.herokuapp.com/ deployed to Heroku</strong></span>
</pre></div><p>Deploying<a id="id153" class="indexterm"/> to Heroku, therefore, naturally combines the actual container <a id="id154" class="indexterm"/>deployment with the application version management via Git. What is more, pushing changes on your Git repository to Heroku will automatically update a running application, allowing "hot" code refreshes. Being able to continuously deploy your application can be of great benefit in some circumstances, as we'll see in later chapters.</p><p>Before we begin, take note that the URL of your deployed app has no port number. Heroku automatically assigns a port through which the web process communicates with your application—this is not in our control. However, it is made available to your Node process via <code class="literal">process.env.PORT</code>. For this reason, you will need to change the <code class="literal">}).listen(8081);</code> line in <code class="literal">server.js</code> to <code class="literal">}).listen(process.env.PORT || 8081);</code>.</p><p>We are now ready to start up our application. Remember that we are deploying a Procfile-based application—processes are defined as being of a certain type. In our case, that type is "web". We also need to assign dynos to our deployment—we need to requisition a process from Heroku to run our app within. The command to start up such an application is as follows:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>heroku ps:scale web=1</strong></span>
</pre></div><p>This tells Heroku to give us one (<code class="literal">1</code>) dyno (also known as a process) of the <span class="emphasis"><em>web type</em></span>. You could also ask for two, or more, depending on your needs.</p><p>Run that command. You should see something like the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Scaling dynos... done, now running web at 1:1X.</strong></span>
</pre></div><p>This tells us that everything is running fine and we have <code class="literal">1</code> dyno that is <code class="literal">1x</code> in size handling our application. You can check that your process is running with the <code class="literal">heroku ps</code> command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>=== web (1X): `node server.js`</strong></span>
<span class="strong"><strong>web.1: up 2014/04/04 17:40:34 (~ 27m ago)</strong></span>
</pre></div><p>Our application is running! Visit the Heroku URL you were given earlier. You should see a JSON editor and our MongoDB document:</p><div class="mediaobject"><img src="graphics/1403OS_02_04.jpg" alt="Git"/></div><p>This is a JSON editor reading the MongoDB document created on our server. It doesn't do much other<a id="id155" class="indexterm"/> than letting you change the value of the <code class="literal">for</code> attribute. If you look at<a id="id156" class="indexterm"/> the JavaScript code in <code class="literal">index.html</code>, you'll see that we've structured our client to send updates to the server via an <code class="literal">/update</code> path whenever values are changed in this document:</p><div class="informalexample"><pre class="programlisting">var editor = new jsoneditor.JSONEditor(container, {
  change : function() {
    var json = editor.get();

    var xhr = new XMLHttpRequest();
    xhr.open('POST', '/update', true);
    xhr.onload = function () {
      console.log("POST RESPONSE: ", this.responseText);
    };
    xhr.send('data=' + JSON.stringify(json));
  },
  mode : "form"
});</pre></div><p>Try it out. Use the editor to change <code class="literal">Deploying NodeJS</code> to something else. If you open your browser's console, you should see <span class="strong"><strong>POST RESPONSE: OK</strong></span> on each change you make to this value. After you've made a change, reload your browser. You'll see the new value—the <a id="id157" class="indexterm"/>changes you've made are being persisted on MongoDB via our Heroku <a id="id158" class="indexterm"/>instance.</p></div><div class="section" title="Managing configuration variables"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec24"/>Managing configuration variables</h2></div></div></div><p>It is normal <a id="id159" class="indexterm"/>for certain aspects of an application to be <a id="id160" class="indexterm"/>configurable. For example, an application deployed for production will most likely be configured differently than one being built in a development environment. Also, authentication credentials (such as the one we are using for our MongoDB connection) will be included in environment variables.</p><p>As many configuration variables are sensitive, it is a bad idea to include them in an application repository or in a public file. How can variables be shared across multiple processes in a secure way? One solution is to pass environment variables when starting a Node process via the command line. If we wanted to inform a Node process that it should execute as a production server, for example, we can do something like this:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>NODE_ENV=PRODUCTION node myprogram.js</strong></span>
</pre></div><p>Within that script, we can access the value via <code class="literal">process.env</code>:</p><div class="informalexample"><pre class="programlisting">console.log(process.env.NODE_ENV);
// production</pre></div><p>While passing configuration variables in this way works very well in terms of privacy, it can be tedious to do this repeatedly for every process, especially if there are many variables.</p><p>Heroku provides an interface to help with managing environment variables. If you log in to your Heroku instance and visit the <span class="strong"><strong>Settings</strong></span> section, you will see something like the following:</p><div class="mediaobject"><img src="graphics/1403OS_02_05.jpg" alt="Managing configuration variables"/></div><p>These <a id="id161" class="indexterm"/>environment variables will be passed to <a id="id162" class="indexterm"/>your application automatically when it is started and/or restarted. Using the <span class="strong"><strong>Edit</strong></span> button, you can add or remove additional settings.</p></div><div class="section" title="Managing your deployment"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec25"/>Managing your deployment</h2></div></div></div><p>If your application crashes for any reason, <code class="literal">heroku ps</code> will indicate this. You also have access to your <a id="id163" class="indexterm"/>process logs via <code class="literal">heroku logs</code>. Just as when you are starting your process, stopping your process involves scaling your dynos down to zero:</p><div class="informalexample"><pre class="programlisting">heroku ps:scale web=0</pre></div><p>Heroku allows you to very precisely scale and configure your process, scale to many dynos, add various workers, and change the size of the dynos themselves. In our example, we use the basic <span class="strong"><strong>1x</strong></span> dyno, which has the smallest memory and compute power, and is the cheapest. For <a id="id164" class="indexterm"/>more information, visit <a class="ulink" href="https://devcenter.heroku.com/articles/dyno-size">https://devcenter.heroku.com/articles/dyno-size</a> and <a class="ulink" href="https://devcenter.heroku.com/articles/process-model">https://devcenter.heroku.com/articles/process-model</a>.</p><p>From time to time, you might commit a change that is incorrect or want to redeploy a previous release. Don't worry! Toolbelt allows you to manage your releases.</p><p>To list releases, use <code class="literal">heroku releases</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>v11 Deploy 310fe56  nataxia@gmail.com 2014/05/04 18:19:45 (~ 6m ago)</strong></span>
<span class="strong"><strong>v10 Deploy a0c6005  nataxia@gmail.com 2014/05/04 18:15:17 (~ 10m ago)</strong></span>
<span class="strong"><strong>...</strong></span>
</pre></div><p>You can get specific information on a release:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; heroku releases:info v11</strong></span>
<span class="strong"><strong>=== Release v11</strong></span>
<span class="strong"><strong>By:   spasquali@gmail.com</strong></span>
<span class="strong"><strong>Change: Deploy 310fe56</strong></span>
<span class="strong"><strong>When:  2014/04/04 18:19:45 (~ 8m ago)</strong></span>
</pre></div><p>Rolling back to the immediately previous version is accomplished with a simple Heroku rollback. You can also roll back to a specific release:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; heroku rollback v11</strong></span>
<span class="strong"><strong>Rolling back mighty-hamlet-7855... done, v11</strong></span>
</pre></div><p>Just as when pushing changes, the version rolled back to will automatically "go live".</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip04"/>Tip</h3><p>You can <a id="id165" class="indexterm"/>open your application right from the command line with <code class="literal">heroku open</code>.</p></div></div></div></div>
<div class="section" title="Installing applications on OpenShift"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec14"/>Installing applications on OpenShift</h1></div></div></div><p>Red Hat, the enterprise Linux company, operates OpenShift, a cloud-hosting solution. OpenShift offers <a id="id166" class="indexterm"/>several options for how you want to deploy your apps—via a web-based interface, via the command line, or through an online IDE. As we've worked on the command line for our other deployment examples, we'll do the same with OpenShift.</p><p>Once you've joined and confirmed your account, you will need to install the OpenShift client tools—<code class="literal">rhc</code>. For the purposes of this section, I'll use the Mac OS X client. Regardless of which package you happen to choose, the command set remains the same:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>sudo gem install rhc</strong></span>
<span class="strong"><strong>gem update rhc</strong></span>
</pre></div><p>This will install the client and update it to the latest version.</p><p>Once installed, you will need to set up your SSH keys and authenticate with the system by running an <code class="literal">rhc</code> setup. Just enter your authentication information, confirm the installation of keys, and confirm the upload of credentials.</p><p>You will then be asked to enter a namespace. This will serve as your identifier in the system, among other things forming the subdomain of your deployed instance.</p><p>OpenShift works<a id="id167" class="indexterm"/> on<a id="id168" class="indexterm"/> the idea of <span class="strong"><strong>Gears</strong></span> and <span class="strong"><strong>Cartridges</strong></span>.</p><p>Gears<a id="id169" class="indexterm"/> are, roughly, containers with a certain allocation of compute units, memory, disk, bandwidth, and so on, with a given capacity of cartridges. Larger gears are <a id="id170" class="indexterm"/>more performant and (generally) can support a greater number of cartridges. You can think of your installation as a collection of managed runtimes (cartridges), fully isolated and deployed to one or more gears. As your application needs to grow, you will add gears and cartridges. When you add cartridges, the OpenShift system deploys your cartridge to the correct gear within your deployment—certain cartridges with access to only their own gear and others with access to all gears. Pricing depends on the number of gears used and, depending on the characteristic of those gears, the implied number of cartridge slots.</p><p>OpenShift supports many types of development environments, open source repositories, web frameworks, databases, and so on—a very rich ecosystem of tools, many more than are available<a id="id171" class="indexterm"/> in the providers we've looked at so far. You can even develop your own cartridges or use community cartridges.</p><p>The system makes it easy to dynamically scale your deployment in terms of gears, or cartridges, or both. The free tier we will use offers three small gears.</p><div class="section" title="Installing a Node application and MongoDB"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec26"/>Installing a Node application and MongoDB</h2></div></div></div><p>In the OpenShift ecosystem, Node is not a special citizen (as it is with NodeJitsu) or one of a fixed <a id="id172" class="indexterm"/>set of process types (as with Heroku). Because<a id="id173" class="indexterm"/> of the modularity that this concept of<a id="id174" class="indexterm"/> gears and cartridges offers, creating a sample Node application <a id="id175" class="indexterm"/>with access to a MongoDB instance can be accomplished in one line:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>rhc app create MyApp nodejs-0.10 mongodb-2.4</strong></span>
<span class="strong"><strong>Application Options</strong></span>
<span class="strong"><strong>-------------------</strong></span>
<span class="strong"><strong>Domain:   &lt;your namespace&gt;</strong></span>
<span class="strong"><strong>Cartridges: nodejs-0.10, mongodb-2.4</strong></span>
<span class="strong"><strong>Gear Size: default</strong></span>
<span class="strong"><strong>Scaling:  no</strong></span>

<span class="strong"><strong>Creating application 'MyApp' ...</strong></span>
<span class="strong"><strong>...</strong></span>
<span class="strong"><strong>Your application 'myapp' is now available.</strong></span>

<span class="strong"><strong>URL:    http://yoursub.rhcloud.com/</strong></span>
<span class="strong"><strong>SSH to:   5366e4cc500446d15300022d@yoursub.rhcloud.com</strong></span>
<span class="strong"><strong>Git remote: ssh://5366e4cc500446d15300022d@yoursub.rhcloud.com/~/git/myapp.git/</strong></span>
<span class="strong"><strong>Cloned to: /json_editor/myapp</strong></span>
</pre></div><p>As you can see, your deployment is powerfully configured, allowing SSH access and HTTP access, and is ready as a Git repo—if you look inside your json-editor folder, a new folder, <code class="literal">myapp/</code>, has been created. Go ahead and visit your URL. Full instructions on how to use Git are provided as well as how to access your application via other means.</p><p>We want to now replace this sample Node app with our own <code class="literal">json-editor</code> app.</p></div><div class="section" title="Deploying your app"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec27"/>Deploying your app</h2></div></div></div><p>We, of<a id="id176" class="indexterm"/> course, do not want to use the sample app<a id="id177" class="indexterm"/> provided by OpenShift. Rather than reconfiguring, let's keep the <code class="literal">.git</code> remote configuration in <code class="literal">myapp/</code> and copy the following files and folders in our <code class="literal">json-editor/</code> folder into the <code class="literal">myapp</code> folder:</p><div class="informalexample"><pre class="programlisting">index.html
jsoneditor.css
jsoneditor.js
package.json
server.js
/img</pre></div><p>These will overwrite any similar files that OpenShift created, while preserving the others. Make sure you have changed the directory to myapp/ as we'll be working from there from now on.</p><p>As we did when installing on Heroku, we will need to consult the <code class="literal">process.env</code> object when starting our Node server. Open <code class="literal">server.js</code> and go to this line:</p><div class="informalexample"><pre class="programlisting">}).listen(8081);</pre></div><p>Now, change the line to the following:</p><div class="informalexample"><pre class="programlisting">}).listen(process.env.OPENSHIFT_NODEJS_PORT || 8081, process.env.OPENSHIFT_NODEJS_IP || "127.0.0.1");</pre></div><p>We are now ready to deploy our app. Update Git with all local files, commit them, and push to OpenShift:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>git add .</strong></span>
<span class="strong"><strong>git commit -m "first"</strong></span>
<span class="strong"><strong>git push</strong></span>
</pre></div><p>If all goes well, you should see the following at the tail end of the resulting output:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>remote: Starting MongoDB cartridge</strong></span>
<span class="strong"><strong>remote: Starting NodeJS cartridge</strong></span>
<span class="strong"><strong>remote: Starting application 'myapp' ...</strong></span>
<span class="strong"><strong>remote: -------------------------</strong></span>
<span class="strong"><strong>remote: Git Post-Receive Result: success</strong></span>
<span class="strong"><strong>remote: Activation status: success</strong></span>
<span class="strong"><strong>remote: Deployment completed with status: success</strong></span>
</pre></div><p>We can see how both Node and MongoDB are cartridges (not special processes or add-ons) and how a successful post-receive hook will automatically deploy and activate our app (not unlike what we saw when deploying to Heroku).</p><p>Should <a id="id178" class="indexterm"/>anything go wrong, we have direct access<a id="id179" class="indexterm"/> to our deployment logs. To connect to your application (<code class="literal">myapp</code>) via SSH, use the <a id="id180" class="indexterm"/>
<code class="literal">rhc</code> tool:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>rhc ssh myapp</strong></span>
</pre></div><p>Once connected, jump to your log directory using <code class="literal">cd $OPENSHIFT_LOG_DIR</code>. You should see two logs:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>mongodb.log</strong></span>
<span class="strong"><strong>nodejs.log</strong></span>
</pre></div><p>These are standard Linux log files and you can read or otherwise manipulate them, for example, by tailing them.</p><p>You can also tail your logs via <code class="literal">rhc</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>rhc tail</strong></span>
</pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip05"/>Tip</h3><p>When you are remotely logged in to your virtual container, you can jump to the root directory of your app via <code class="literal">cd $OPENSHIFT_REPO_DIR</code>.</p></div></div><p>Controlling your application is easily done via <code class="literal">rhc</code>. Several commands are available via <code class="literal">rhc app &lt;command&gt;</code>. These are a few commonly used commands:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>delete</strong></span>: This <a id="id181" class="indexterm"/>deletes an application from the server</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>force-stop</strong></span>: This <a id="id182" class="indexterm"/>stops all application processes</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>reload</strong></span>: This <a id="id183" class="indexterm"/>reloads the application's configuration</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>restart</strong></span>: This <a id="id184" class="indexterm"/>restarts the application</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>show</strong></span>: This <a id="id185" class="indexterm"/>shows information about an application</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>start</strong></span>: This <a id="id186" class="indexterm"/>starts the application</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>stop</strong></span>: This <a id="id187" class="indexterm"/>stops the application</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>tidy</strong></span>: This <a id="id188" class="indexterm"/>cleans out logs and <code class="literal">tmp</code> directories and tidies up the <code class="literal">git</code> repo on the server</li></ul></div><p>OpenShift offers a flexible option for those who want a little more control over the application they are deploying—power tools for power users.</p></div></div>
<div class="section" title="Using Docker to create lightweight virtual containers"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec15"/>Using Docker to create lightweight virtual containers</h1></div></div></div><p>This<a id="id189" class="indexterm"/> image from the Docker <a id="id190" class="indexterm"/>website (<a class="ulink" href="http://www.docker.com/">http://www.docker.com/</a>) gives<a id="id191" class="indexterm"/> information on how and why the Docker team feels their technology fits into the future of application development:</p><div class="mediaobject"><img src="graphics/1403OS_02_01.jpg" alt="Using Docker to create lightweight virtual containers"/></div><p>The preceding image, concisely describing the generational shift in application architecture we are now experiencing, can just as easily be used to describe the how and why of Node's design.</p><p>Docker, according to the website, <span class="emphasis"><em>…is an open source engine that automates the deployment of any application as a lightweight, portable, self-sufficient container that will run virtually anywhere</em></span>. Once you have created a Docker image of your application, a running instance of that image can be spun in milliseconds. Yes, that's right: a few milliseconds. Docker lets you create even hundreds of deployments of your application in a few <a id="id192" class="indexterm"/>seconds.</p><p>The<a id="id193" class="indexterm"/> Docker ecosystem has three main <a id="id194" class="indexterm"/>components. Here's some information about the components from the documentation:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Docker containers</strong></span>: Docker containers are like directories. A Docker container<a id="id195" class="indexterm"/> holds everything that is needed for<a id="id196" class="indexterm"/> an application to run. Each container is created from a Docker image. Docker containers can be run, started, stopped, moved, and deleted. Each container is an isolated and secure application platform. You can consider Docker containers to be the <code class="literal">run</code> portion of the Docker framework.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Docker images</strong></span>: The Docker image is a template, for example, an Ubuntu operating<a id="id197" class="indexterm"/> system with Apache and your web <a id="id198" class="indexterm"/>application installed. Docker containers are launched from images. Docker provides a simple way to build new images or update existing images. You can consider Docker images to be the <code class="literal">build</code> portion of the Docker framework.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Docker registries</strong></span>: Docker registries hold images. These are public (or private) stores<a id="id199" class="indexterm"/> that you can upload or<a id="id200" class="indexterm"/> download images to and from. These images can be images you create yourself, or you can make use of images that others have previously created. Docker registries allow you to build simple and powerful development and deployment workflows. You can consider Docker registries to be the <code class="literal">share</code> portion of the Docker framework.</li></ul></div><p>You can create images of applications to be run in any number of isolated containers, sharing those images with others if you'd like. The concept of composing Node applications out of many independent processes naturally aligns with the philosophy behind Docker. Docker containers are sandboxed, with their own filesystems, and so on, and are unable to execute instructions on their host without your knowledge. They can expose a port to their host OS, however, and later in this chapter, we'll learn how to use Node to link together many independent virtual containers into a larger application.</p><div class="section" title="First, some Unix"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec28"/>First, some Unix</h2></div></div></div><p>Docker is a new technology, and at the time of this writing, it is not yet available on all flavors of Unix (although the team is working hard to make that a reality in the near future). I will install <a id="id201" class="indexterm"/>Docker on CentOS. The Docker website (<a class="ulink" href="https://www.docker.io/">https://www.docker.io/</a>) is regularly updated with information on how to install on your<a id="id202" class="indexterm"/> favorite flavor of Unix.</p><p>Knowing the<a id="id203" class="indexterm"/> details of your OS is important. To find out your OS distribution name and version, use <code class="literal">cat /etc/*-release</code>, which should return something like this:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>CentOS release 6.5 (Final)</strong></span>
</pre></div><p>Or you can try <code class="literal">cat /proc/version</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>Linux version 2.6.32-279.14.1.el6.x86_64 (mockbuild@cb79.bsys.dev.centos.org) (gcc version 4.4.6 20120305 (Red Hat 4.4.6-4) (GCC) ) #1 SMP Tue Nov 6 23:43:09 UTC 2012</strong></span>
</pre></div><p>When you begin to create virtual machines and bind to ports, it will be necessary to check the status of your network on occasion. You should definitely install a good process viewer, such as <a id="id204" class="indexterm"/>
<span class="strong"><strong>HTOP</strong></span> (<a class="ulink" href="http://hisham.hm/htop/">http://hisham.hm/htop/</a>), as this will <a id="id205" class="indexterm"/>let you quickly scan/search through your open process list.</p><p>To get a quick list of stats on the network connections for your box, use <code class="literal">netstat</code>, which will return a list somewhat like this:</p><div class="mediaobject"><img src="graphics/1403OS_02_02.jpg" alt="First, some Unix"/></div><p>You can see that port <code class="literal">8080</code> is bound to the Node process <code class="literal">31878</code>. You can also directly ask for the process ID associated with a port:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; fuser 8080/tcp</strong></span>
<span class="strong"><strong>8080/tcp:      31878</strong></span>
</pre></div><p>To get more information on a process, type <code class="literal">ls -l /proc/31878/exe</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>lrwxrwxrwx 1 root root 0 Oct 9 2013 /proc/31878/exe -&gt; /root/nvm/v0.10.20/bin/node</strong></span>
</pre></div><p>To get more information on a port user, try <code class="literal">lsof</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>&gt; lsof -i :8080</strong></span>
<span class="strong"><strong>COMMAND  PID USER  FD  TYPE  DEVICE NODE NAME</strong></span>
<span class="strong"><strong>node  31878 root  10u IPv4 22570201 TCP *:webcache (LISTEN)</strong></span>
</pre></div><p>Keeping <a id="id206" class="indexterm"/>on top of who is listening where, and to what, will<a id="id207" class="indexterm"/> serve you well as you move through this book.</p></div><div class="section" title="Getting started with Docker"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec29"/>Getting started with Docker</h2></div></div></div><p>First, you will need to install Docker. Installation instructions for all supported Linux distributions<a id="id208" class="indexterm"/> can be found at <a class="ulink" href="http://docs.docker.io/installation/">http://docs.docker.io/installation/</a>.</p><p>Once you have the Docker service installed, you will need to start it:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>service docker start</strong></span>
</pre></div><p>Then, stop the Docker service:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>service docker stop</strong></span>
</pre></div><p>If everything is <a id="id209" class="indexterm"/>working, this command should tell you something about your Docker installation:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>docker info</strong></span>
</pre></div><p>A Docker container runs an image of your application. You can create these images yourself, of course, but there does exist a large ecosystem of existing images. Let's create our own image of a Node server running Express.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note10"/>Note</h3><p>To search the <a id="id210" class="indexterm"/>Docker image repository, visit <a class="ulink" href="https://index.docker.io/">https://index.docker.io/</a>.</p></div></div><p>First, we'll need to build an application to run. Create a folder to put your application files into. Just as with all Node applications, we'll need to create a <code class="literal">package.json</code> file for npm to parse:</p><div class="informalexample"><pre class="programlisting">{
  "name": "docker-example",
  "private": true,
  "version": "0.0.0",
  "description": "Example of running a Node app within a CENTOS container",
  "author": "Sandro Pasquali &lt;spasquali@gmail.com&gt;",
  "dependencies": {
    "express": "4.1.1"
  }
}</pre></div><p>Next, we <a id="id211" class="indexterm"/>need a program that will start an Express HTTP server. Create the following file and name it <code class="literal">server.js</code>:</p><div class="informalexample"><pre class="programlisting">var express = require('express');

var port = 8087;

var app = express();
app.get('/', function (req, res) {
  res.send('You just deployed some Node!\n');
});

app.listen(port);
console.log('Running on http://localhost:' + port);</pre></div><p>Now, install and start your application:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>npm install;</strong></span>
<span class="strong"><strong>node app.js</strong></span>
<span class="strong"><strong>// Running on http://localhost:8087</strong></span>
</pre></div><p>You can now point your browser to your host on port <code class="literal">8087</code> and see <span class="strong"><strong>You just deployed some Node!</strong></span> displayed.</p><p>Now, we will look at how we can build these files into a virtual container using Docker.</p></div><div class="section" title="Creating a Dockerfile"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec30"/>Creating a Dockerfile</h2></div></div></div><p>Our goal is to describe the environment this application executes within such that Docker can reproduce <a id="id212" class="indexterm"/>that environment in a container. Also, we want to add the source files of our application to run in this newly virtualized environment. Docker can act as a builder that follows the instructions you provide on how to build an <a id="id213" class="indexterm"/>image of your application.</p><p>To begin with, you should have a folder containing your application files. This is your source code repository. Within this repository, create a <code class="literal">./src</code> folder. We will shortly learn why this folder is created. If this folder is the one where your test application was built, remove the <code class="literal">node_modules</code> folder.</p><p>A Dockerfile is a list of instructions to build an application. You can build Docker images manually, of course, but it is likely that you will want to repeat those actions many times. A Dockerfile describes a build process. What you will normally declare in a Dockerfile is the Linux version that the container will run and any OS installations you might need to do—such as Node and npm. Additionally, you will indicate where the source code for your application resides: within the <code class="literal">./src</code> folder created earlier.</p><p>A Dockerfile is <a id="id214" class="indexterm"/>always built upon another Docker image. Normally, you <a id="id215" class="indexterm"/>will build upon an OS image. We'll use CentOS 6.4 for this example. My Dockerfile starts with a comment about the version of Docker I am building on and the name of the image this image will be built from:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong># DOCKER-VERSION 0.9.0</strong></span>
<span class="strong"><strong>FROM  centos:6.4</strong></span>
</pre></div><p>We have now established an OS to run in the container. Now we will simply list typical Unix commands to set up a build environment. First, we'll need Node and npm:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong># Enable EPEL for Node.js</strong></span>
<span class="strong"><strong>RUN   rpm -Uvh http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm</strong></span>
<span class="strong"><strong># Install Node.js and npm</strong></span>
<span class="strong"><strong>RUN   yum install -y npm</strong></span>
</pre></div><p>Great! Now our container knows how to build Node and npm. Now let's bundle our application into the <code class="literal">./src</code> directory of our container using the <code class="literal">ADD</code> directive:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong># Bundle app source</strong></span>
<span class="strong"><strong>ADD . /src</strong></span>
</pre></div><p>Now that our application files are bundled into <code class="literal">./src</code>, let's enter that directory and install the application package:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong># Install app</strong></span>
<span class="strong"><strong>RUN cd /src; npm install</strong></span>
</pre></div><p>Our app is now installed. Note that in <code class="literal">app.js</code> we are exposing an Express server on port <code class="literal">8087</code>. A container can't know this, so we have to tell the container to set up the port redirection on the host system:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>EXPOSE 8087</strong></span>
</pre></div><p>Finally, the container is told to start the Node application:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>CMD ["node", "/src/app.js"]</strong></span>
</pre></div><p>That's it. Now, create a file named (exactly) <code class="literal">Dockerfile</code>, containing the preceding instructions. We can now use this Dockerfile to build a Docker image.</p></div><div class="section" title="Building and running a Docker image"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec31"/>Building and running a Docker image</h2></div></div></div><p>The command to <a id="id216" class="indexterm"/>build a Docker image is <code class="literal">docker build</code>. Docker will look in the current folder for a Dockerfile and build an image based <a id="id217" class="indexterm"/>on the instructions contained therein. Since<a id="id218" class="indexterm"/> we <a id="id219" class="indexterm"/>will most likely reuse this image, it is a good idea to tag it with a special name. To give an image a name, use the <code class="literal">–t</code> directive, followed by the tag of your choice, followed by a path to the Dockerfile (here, the current directory):</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>docker build -t docker/example .</strong></span>
</pre></div><p>When you run that command, you will see a lot of output to your terminal as the requested packages are downloaded and installed. This may take some time. Thankfully, Docker caches these installs—the next build using this Dockerfile, or others containing identical install instructions, will be much faster.</p><p>If the build went well, your image can be listed, with the <code class="literal">docker images</code> command outputting something like this:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>REPOSITORY   TAG   IMAGE ID   CREATED    VIRTUAL SIZE</strong></span>
<span class="strong"><strong>docker/example latest d8bb295407f1 20 minutes ago   667.8 MB</strong></span>
<span class="strong"><strong>centos     6.4  539c0211cd76 2 months ago    300.6 MB</strong></span>
</pre></div><p>To remove an image, use <code class="literal">docker rmi &lt;image id&gt;</code>.</p><p>Our application is now containerized. We can run it using the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>docker run -p 49001:8087 -d docker/example</strong></span>
</pre></div><p>The <code class="literal">–d</code> directive instructs Docker to run this image in detached mode—to run it in the background. The <code class="literal">49001:8087</code> segment is necessary to map the <span class="emphasis"><em>virtual</em></span> port that our Express server is listening to <span class="emphasis"><em>within the container</em></span> (<code class="literal">8087</code>) to an actual port on our host machine.</p><p>Open your browser and point it to the host machine at port <code class="literal">49001</code>. You should see <span class="strong"><strong>You just deployed some Node!</strong></span> displayed. The Node application we created earlier is now running in a container.</p><p>To demonstrate the point of Docker, execute the same <code class="literal">run</code> instruction given earlier, but change the port mapping to something like <code class="literal">49002:8087</code>. Open a different browser window on your application by changing the port accordingly. You now have two identical copies of your application running on the same host in isolated containers.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note11"/>Note</h3><p>More details on <a id="id220" class="indexterm"/>run directives can be found at <a class="ulink" href="http://docs.docker.io/reference/run/">http://docs.docker.io/reference/run/</a>.</p><p>To learn more <a id="id221" class="indexterm"/>about port redirection, visit <a class="ulink" href="http://docs.docker.io/use/port_redirection/#port-redirection">http://docs.docker.io/use/port_redirection/#port-redirection</a>.</p></div></div><p>You<a id="id222" class="indexterm"/> will <a id="id223" class="indexterm"/>want to be able to check for the running Docker instances. The command to do this is <code class="literal">docker ps</code>, which will display information similar to the following:</p><div class="mediaobject"><img src="graphics/1403OS_02_03.jpg" alt="Building and running a Docker image"/></div><p>Here we<a id="id224" class="indexterm"/> see our two running containers, including<a id="id225" class="indexterm"/> information about what they are running and how they are mapped. To stop a running container, use <code class="literal">docker stop &lt;container id&gt;</code>. You can use <code class="literal">docker start &lt;container id&gt;</code> to either restart a stopped container or, of course, start a new one. This implies that stopping a container does not destroy the container. To do that, use <code class="literal">docker rm &lt;container id&gt;</code>.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip06"/>Tip</h3><p>For a full list of Docker commands, simply type <code class="literal">docker</code> in your terminal.</p></div></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec16"/>Summary</h1></div></div></div><p>In this chapter, you learned how to create Node servers and applications, both locally and <span class="emphasis"><em>in the cloud</em></span>. Having deployed a simple document-editing application using Node and MongoDB across three different PaaS providers, you have an early sense of what is available to the Node developer who is looking to scale their application. You were introduced to Docker, which offers a powerful new containerization technology, allowing us to make many cheap clones of our applications; wherever there is Linux, there exists a deploy target for Docker.</p><p>In the next chapter, we will take these simple ideas about scaling farther and deeper by exploring in more detail how Node can be scaled both vertically and horizontally—across cores and across many machines.</p></div></body></html>