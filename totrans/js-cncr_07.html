<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch07"/>Chapter 7. Abstracting Concurrency</h1></div></div></div><p>Up until this point in the book, we explicitly modelled concurrency issues in our code. With promises, we synchronized two or more asynchronous actions. With generators, we created data on-the-fly, avoiding unnecessary memory allocations. Finally, we learned that web workers are the workhorses that leverages multiple CPU cores.</p><p>In this chapter, we will take all these ideas and put them into the context of application code. That is, if concurrency is the default, then we will need to make concurrency as unobtrusive as possible. We'll start by exploring various techniques that will help us encapsulate concurrency mechanisms within the components that we use. Then, we will move straight to improving our code from the previous two chapters by using promises to facilitate worker communication.</p><p>Once we're able to abstract worker communication using promises, we'll look at implementing lazy workers with the help of generators. We'll also cover worker abstraction using the <code class="literal">Parallel.js</code> library, followed by the concept of worker pools.</p><div><div><div><div><h1 class="title"><a id="ch07lvl1sec46"/>Writing concurrent code</h1></div></div></div><p>Concurrent programming <a id="id286" class="indexterm"/>is hard to get right. Even with contrived example applications, the bulk of<a id="id287" class="indexterm"/> complexity comes from concurrent code. We obviously want our code to be readable while keeping the benefits of concurrency. We want to get the most out of each CPU on the system. We only want to compute what we need, when we need it. We don't want spaghetti code that joins together several asynchronous operations. Focusing on all these aspects of concurrent programming while developing applications detracts from what we should really be focusing on—the features that give our application value.</p><p>In this section, we'll look at the approaches that we might use to insulate the rest of our application from tricky concurrency bits. This generally means making concurrency the default mode—even when there's no real concurrency happening under the hood. In the end, we don't want our code to contain 90% concurrency acrobatics and 10% functionality.</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec93"/>Hiding the concurrency mechanism</h2></div></div></div><p>The difficulty with exposing<a id="id288" class="indexterm"/> concurrency mechanisms all throughout our code is that they're all slightly different from one another. This magnifies the callback hell that we may already find ourselves in. For example, not all concurrent operations are network requests that fetch data from some remote resource. Asynchronous data might come from a worker or some another callback that's asynchronous in itself. Picture a scenario where we have three disparate data sources used to compute a value that we need—all of which are asynchronous. Here's an illustration of the problem:</p><div><img src="img/B05133_07_01.jpg" alt="Hiding the concurrency mechanism"/></div><p>The data in this diagram is the thing we care about in our application code. From the perspective of the feature that we're building we don't care about anything above it. So, our front-end architecture needs to encapsulate the complexities associated with concurrency. This means each of our components should be able to access data in the same way. There's another complication to consider here in addition to all our asynchronous data sources—what about when the data isn't asynchronous and originates from a local source? What about synchronizing a local data source and an HTTP request? We'll cover this in the following section.</p></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec94"/>Without concurrency</h2></div></div></div><p>Just because we're writing <a id="id289" class="indexterm"/>a concurrent JavaScript application, not every operation is inherently concurrent. For example, if one component asks another component for data that it already has in memory, then it's not an asynchronous operation and is returned immediately. Our application is likely filled with operations these, where concurrency simply doesn't make sense. And therein lies the challenge—how do we mix asynchronous operations seamlessly with synchronous operations?</p><p>The simple answer is that we make the default assumption of concurrency everywhere. Promises make this problem tractable. Here's an illustration of using a promise to encapsulate both asynchronous and synchronous operations:</p><div><img src="img/B05133_07_02.jpg" alt="Without concurrency"/></div><p>This looks a lot like the <a id="id290" class="indexterm"/>previous diagram with two important differences. We've added a <code class="literal">synchronous()</code> operation; this doesn't have a callback function because it doesn't need one. It's not waiting for anything else, so it returns without delay. The other two functions are just as they were in the previous diagram; both rely on callback functions to feed their data into our application. The second important difference is that there's a promise object. This replaces both the <code class="literal">sync()</code> operation and the data concept. Or rather, it melds them into the same concept.</p><p>This is the key aspect of promises—their general ability to abstract synchronization problems away for us. This is applicable not just with network requests, but also web worker messages, or any other asynchronous operation that relies on callbacks. It requires a bit of an adjustment to think about our data as we promise that it'll get here eventually. But, once we close this mental gap, concurrency is enabled by default. Concurrency is the default as far as our features are concerned, and what we do behind the operating curtain isn't disruptive in the slightest.</p><p>Let's turn our attention to <a id="id291" class="indexterm"/>some code now. We'll create two functions: one asynchronous and the other a plain old function that simply returns a value. The goal here is to make the code that uses these functions the same, despite the major differences in how the value is generated:</p><div><pre class="programlisting">// An asynchronous "fetch" function. We use "setTimeout()"
// to pass "callback()" some data after 1 second.
function fetchAsync(callback) {
    setTimeout(() =&gt; {
        callback({ hello: 'world' });
    }, 1000);
}

// The synchronous fetch simply returns the data.
function fetchSync() {
    return { hello: 'world' };
}

// A promise for the "fetchAsync()" call. We pass the
// "resolve" function as the callback.
var asyncPromise = new Promise((resolve, reject) =&gt; {
    fetchAsync(resolve);
});

// A promise for the "fetchSync()" call. This promise
// is resolved immediately with the return value.
var syncPromise = new Promise((resolve, reject) =&gt; {
    resolve(fetchSync());
});

// Creates a promise that'll wait for two promises
// to complete before resolving. This allows us
// to seamlessly mix synchronous and asynchronous
// values.
Promise.all([
    asyncPromise, 
    syncPromise 
]).then((results) =&gt; {
    var [ asyncResult, syncResult ] = results;

    console.log('async', asyncResult);
    // → async { hello: 'world' }

    console.log('sync', syncResult);
    // → sync { hello: 'world' }
});</pre></div><p>The trade-off here is the<a id="id292" class="indexterm"/> added promise complexity, wrapped around what would otherwise be a simple value returned from a function. But in reality, the complexity is encapsulated within the promise, and if we weren't writing a concurrent application, we obviously would need to concern ourselves with issues such as these. The benefit is huge. When everything is a promised value, we can safely rule out the inconsistencies that lead to nasty concurrency bugs.</p></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec47"/>Worker communication with promises</h1></div></div></div><p>We now have a handle on why <a id="id293" class="indexterm"/>treating primitive values as promises benefits our code. It's time to apply this concept to web workers. In the preceding two chapters, our code that synchronized responses coming from web workers started to look a little intractable. This was because we were essentially trying to emulate many boilerplate chores that promises are good at handling. We'll first attempt to solve these problems by creating helper functions that wrap the worker communications for us, returning promises. Then we'll try another approach that involves extending the web worker interface at a lower level. Lastly, we'll look at some more complex synchronization scenarios that involve multiple workers, such as those from the last chapter.</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec95"/>Helper functions</h2></div></div></div><p>It would be ideal if we could get web <a id="id294" class="indexterm"/>worker responses back in the form of a promise resolution. But, we need to create the promise in the first place—how do we do this? Well, we could manually create the promise, where the message that's sent to the worker is sent from within the promise executor function. But, if we take this approach, we're not much better off than we were before introducing promises.</p><p>The trick is to encapsulate both the message posted to the worker and any message received from the worker, within a single helper function as is illustrated here:</p><div><img src="img/B05133_07_03.jpg" alt="Helper functions"/></div><p>Let's take a look at an example helper function that implements this pattern. First, we'll need a worker that carries out some task—we'll start with this:</p><div><pre class="programlisting">// Eat some CPU cycles...
// Taken from http://adambom.github.io/parallel.js/
function work(n) {
    var i = 0;
    while (++i &lt; n * n) {}
    return i;
}

// When we receive a message, we post a message with the
// id, and the result of performing "work()" on "number".
addEventListener('message', (e) =&gt; {
    postMessage({
        id: e.data.id,
        result: work(e.data.number)
    });
});</pre></div><p>Here we have a worker that will square any number we pass it. This <code class="literal">work()</code> function is intentionally slow so that we can see how our application, as a whole, performs when web workers take longer than usual to complete a task. It also uses an ID as we've seen with our previous web worker examples, so it can reconcile with the code that sent the message. Let's <a id="id295" class="indexterm"/>implement the helper function that uses this worker now:</p><div><pre class="programlisting">// This will generate unique IDs. We need them to
// map tasks executed by web workers to the larger
// operation that created them.
function* genID() {
    var id = 0;

    while (true) {
        yield id++;
    }
}

// Creates the global "id" generator.
var id = genID();

// This object holds the resolver functions from promises,
// as results comeback from workers, we look them up here,
// based on ID.
var resolvers = {};

// Starts our worker...
var worker = new Worker('worker.js');

worker.addEventListener('message', (e) =&gt; {
    // Finds the appropriate resolver function.
    var resolver = resolvers[e.data.id];

    // Deletes it from the "resolvers" object.
    delete resolvers[e.data.id];

    // Pass the worker data to the promise by calling
    // the resolver function.
    resolver(e.data.result);
});

// This is our helper function. It handles the posting of
// messages to the worker, and tying the promise to the
// worker responses.
function square(number) {
    return new Promise((resolve, reject) =&gt; {
        // The ID that's used to tie together a web 
        // worker response, and a resolver function.
        var msgId = id.next().value;

        // Stores the resolver so in can be used later, in
        // the web worker message callback.
        resolvers[msgId] = resolve;

        // Posts the message - the ID and the number
        // argument.
        worker.postMessage({
            id: msgId,
            number: number
        });
    });
}

square(10).then((result) =&gt; {
    console.log('square(10)', result);
    // → square(10) 100
});

square(100).then((result) =&gt; {
    console.log('square(100)', result);
    // → square(100) 10000
});

square(1000).then((result) =&gt; {
    console.log('square(1000)', result);
    // → square(1000) 1000000
});</pre></div><p>If we focus on the way<a id="id296" class="indexterm"/> that the <code class="literal">square()</code> function is used, passing a number argument and getting a promise as a return value, we can see that this fits in with our earlier discussion on making code concurrent by default. For example, we can completely remove workers from this scenario and simply change the way the helper function resolves the promise that it returns, and the rest of our code will continue to function unaltered.</p><p>The helper function tactic is just one approach to simplify worker communication using promises. Perhaps we can decide that we don't necessarily want to maintain a bunch of helper functions. Next, we'll look at a more granular approach than helper functions.</p></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec96"/>Extending postMessage()</h2></div></div></div><p>Rather than amassing vast <a id="id297" class="indexterm"/>quantities of helper functions, we can take a more generic route. There's nothing wrong with helper functions; they're direct and to the point. If we reach a point where there are literally hundreds of them, their value would start to depreciate very quickly. The more generic approach is to keep using <code class="literal">worker.postMessage()</code>.</p><p>So let's see if we can make this method return a promise just like our helper function from the previous section. This way, we keep using the granular <code class="literal">postMessage()</code>method, but improve our synchronization semantics. First, here's the worker code:</p><div><pre class="programlisting">addEventListener('message', (e) =&gt; {

    // The result we're posting back to the main
    // thread - it should always contain the
    // message ID.
    var result = { id: e.data.id };

    // Based on the "action", compute the response
    // "value". The options are leave the text alone,
    // convert it to upper case, or convert it to
    // lower case.
    if (e.data.action === 'echo') {
        result.value = e.data.value
    } else if (e.data.action === 'upper') {
        result.value = e.data.value.toUpperCase();
    } else if (e.data.action === 'lower') {
        result.value = e.data.value.toLowerCase();
    }

    // Simulate a longer-running worker by waiting
    // 1 second before posting the response back.
    setTimeout(() =&gt; {
        postMessage(result);
    }, 1000);
});</pre></div><p>This is nothing radically <a id="id298" class="indexterm"/>different from what we've seen so far in our web worker code. Now, in the main thread, we have to figure out how to alter the interface of <code class="literal">Worker</code>. Let's do this now. Then, we'll try posting some messages to this worker and resolving promises as a response:</p><div><pre class="programlisting">// This object holds the resolver functions from promises,
// as results comeback from workers, we look them up here,
// based on ID.
var resolvers = {};

// Keep the original implementation of "postMessage()"
// so we can call it later on, in our custom "postMessage()"
// implementation.
var postMessage = Worker.prototype.postMessage;

// Replace "postMessage()" with our custom implementation.
Worker.prototype.postMessage = function(data) {
    return new Promise((resolve, reject) =&gt; {

        // The ID that's used to tie together a web worker
        // response, and a resolver function.
        var msgId = id.next().value;
    
        // Stores the resolver so in can be used later, in
        // the web worker message callback.
        resolvers[msgId] = resolve;

        // Run the original "Worker.postMessage()"
        // implementation, which takes care of actually
        // posting the message to the worker thread.
        postMessage.call(this, Object.assign({
            id: msgId
        }, data));
    });
};

// Starts our worker...
var worker = new Worker('worker.js');

worker.addEventListener('message', (e) =&gt; {

    // Finds the appropriate resolver function.
    var resolver = resolvers[e.data.id];

    // Deletes it from the "resolvers" object.
    delete resolvers[e.data.id];

    // Pass the worker data to the promise by calling
    // the resolver function.
    resolver(e.data.value);
});

worker.postMessage({
    action: 'echo',
    value: 'Hello World'
}).then((value) =&gt; {
    console.log('echo', `"${value}"`);
    // → echo "Hello World"
});

worker.postMessage({
    action: 'upper',
    value: 'Hello World'
}).then((value) =&gt; {
    console.log('upper', `"${value}"`);
    // → upper "HELLO WORLD"
});

worker.postMessage({
    action: 'lower',
    value: 'Hello World'
}).then((value) =&gt; {
    console.log('lower', `"${value}"`);
    // → lower "hello world"
});</pre></div><p>Well, this is exactly <a id="id299" class="indexterm"/>what we need, right? We can post message data directly to the worker, and the response data is sent back to us through the promise resolution. As an added bonus, we can actually wrap helper functions around this new <code class="literal">postMessage()</code> function implementation if we're so inclined. The main trick involved with making this work is storing a reference to the original <code class="literal">postMessage()</code>. Then, we override the web worker property <code class="literal">postMessage</code>, not the function itself. Finally, we can reuse it to add the necessary reconciliation and promise goodness.</p></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec97"/>Synchronizing worker results</h2></div></div></div><p>The code in the last two <a id="id300" class="indexterm"/>sections has adequately reduced our web worker callback hell to a more tolerable level. In fact, now that we've got a handle on how to encapsulate web worker communication by having <code class="literal">postMessage()</code> return a promise, we're ready to start simplifying any messy worker code that isn't using this approach. The examples that we've looked at, so far, have benefited greatly from promises, they are simple; not having these abstractions wouldn't be the end of the world.</p><p>What about the scenario where we map a collection of data and then reduce the mapped collection? We may recall the map reduce code got a little hairy in <a class="link" href="ch06.html" title="Chapter 6. Practical Parallelism">Chapter 6</a>, <em>Practical Parallelism</em>. This is mostly due to all the worker communication boilerplate code entangled with the code that's trying to execute a map/reduce operation. Let's see if we fair any better using our promise technique. First, we'll create a very basic worker:</p><div><pre class="programlisting">// Returns a map of the input array, by squaring
// each number in the array.
addEventListener('message', (e) =&gt; {
    postMessage({
        id: e.data.id,
        value: e.data.value.map(v =&gt; v * v)
    });
});</pre></div><p>We can use this <a id="id301" class="indexterm"/>worker to pass arrays for mapping. So we'll create two of them and split the workload between the two workers, shown as follows:</p><div><pre class="programlisting">function onMessage(e) {

    // Finds the appropriate resolver function.
    var resolver = resolvers[e.data.id];

    // Deletes it from the "resolvers" object.
    delete resolvers[e.data.id];

    // Pass the worker data to the promise by calling
    // the resolver function.
    resolver(e.data.value);
}

// Starts our workers...
var worker1 = new Worker('worker.js'),
    worker2 = new Worker('worker.js');

// Create some data to process.
var array = new Array(50000)
    .fill(null)
    .map((v, i) =&gt; i);

// Finds the appropriate resolver function to call,
// when the worker responds with data.
worker1.addEventListener('message', onMessage);
worker2.addEventListener('message', onMessage);

// Splits our input data in 2, giving the first half
// to the first worker, and the second half to the
// second worker. At this point, we have two promises.
var promise1 = worker1.postMessage({
    value: array.slice(0, Math.floor(array.length / 2))
});

var promise2 = worker2.postMessage({
    value: array.slice(Math.floor(array.length / 2))
});

// Using "Promise.all()" to synchronize workers is
// much easier than manually trying to reconcile
// through worker callback functions.
Promise.all([ promise1, promise2 ]).then((values) =&gt; {
    console.log('reduced', [].concat(...values)
        .reduce((r, v) =&gt; r + v));
    // → reduced 41665416675000
});</pre></div><p>When this is all we <a id="id302" class="indexterm"/>need to post data to workers, and to synchronize data from two or more workers, we're actually motivated to write concurrent code—it looks the same as the rest of our application code now.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec48"/>Lazy workers</h1></div></div></div><p>It's time for us to look at web workers<a id="id303" class="indexterm"/> from a different angle. The fundamental reason we're using workers in the first place is that we want to compute more than we have in the past in the same amount of time. Doing this, as we now know, involves messaging intricacies, divide and conquer strategies so to speak. We have to get data into and out of the worker, usually as an array.</p><p>Generators help us compute lazily. That is, we don't want to compute something or allocate data in memory until we really need it. Do web workers make this difficult or impossible to achieve? Or can we leverage generators to compute lazily and in parallel?</p><p>In this section, we'll explore ideas related to using generators in web workers. First, we'll look at the overhead issues associated with web workers. Then, we'll write some code that uses generators to pass data in and out of workers. Finally, we'll see if we can lazily pass data through a chain of generators, all residing in web workers.</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec98"/>Reducing overhead</h2></div></div></div><p>The main thread can offload<a id="id304" class="indexterm"/> expensive operations web workers, running them in another thread. This means the DOM is able to paint pending updates and process pending user events. However, we still face the overhead of allocating large arrays and the time taken to update the UI. Despite parallel processing with web workers, our users could still face a slowdown because there's no update to the UI until the entire data set has been processed. Here is a visualization of the general pattern:</p><div><img src="img/B05133_07_04.jpg" alt="Reducing overhead"/></div><p>This is a generic path taken by data with a single worker; the same approach applies when there are multiple workers. With this approach, we can't escape the fact that we need to serialize the data twice, and we have to allocate it twice. These overheads are merely to facilitate the worker communication and have very little to do with the application functionality that we're trying to implement.</p><p>The overhead with arrays and serialization, required for worker communication, generally isn't a big deal. However, with larger collections, we could be faced with real performance issues, stemming from the very mechanism that we use to improve performance. So looking at worker communication from another perspective doesn't hurt, even if it's not necessary at first.</p><p>Here's a variation of the generic<a id="id305" class="indexterm"/> path taken by most workers. Instead of allocating and serializing lots of data upfront, individual items are passed in and out of workers. This gives the UI a chance to update using the data that's been processed, before all of the processed data arrives.</p><div><img src="img/B05133_07_05.jpg" alt="Reducing overhead"/></div></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec99"/>Generating values in workers</h2></div></div></div><p>If we want to update the UI as our <a id="id306" class="indexterm"/>workers generate results, then they can't <a id="id307" class="indexterm"/>package the result set as an array to send back to the main thread after all the computations are done. While this happens, the UI sits there without responding to the user. We want a lazier approach where values are generated one at a time so that the UI can be updated sooner. Let's build an example that sends input to the web worker and sends results back at a much more granular level than what we've seen so far in this book:</p><p>First, we'll create a worker; the code for it is as follows:</p><div><pre class="programlisting">// Eat some CPU cycles...
// Taken from http://adambom.github.io/parallel.js/
function work(n) {
    var i = 0;
    while (++i &lt; n * n) {}
    return i;
}

// Post the result of calling "work()" back to the
// main thread.
addEventListener('message', (e) =&gt; {
    postMessage(work(e.data));
});</pre></div><p>There's nothing<a id="id308" class="indexterm"/> earth-shattering here. It's the same <code class="literal">work()</code> function<a id="id309" class="indexterm"/> that we've already used to intentionally slow-down our code by inefficiently squaring a number. There's no actual generator used inside the worker. This is because we really don't need one, we'll see why in a moment:</p><div><pre class="programlisting">// Creates an "update()" coroutine that continuously
// updates the UI as results are generated from the
// worker.
var update = coroutine(function* () {
    var input;

    while (true) {
        input = yield;
        console.log('result', input.data);
    }
});

// Creates the worker, and assigns the "update()"
// coroutine as the "message" callback handler.
var worker = new Worker('worker.js');
worker.addEventListener('message', update);

// An array of progressively larger numbers.
var array = new Array(10)
    .fill(null)
    .map((v, i) =&gt; i * 10000);

// Iterate over the array, passing each number to the
// worker as an individual message.
for (let item of array) {
    worker.postMessage(item);
}
// → 
// result 1
// result 100000000
// result 400000000
// result 900000000
// result 1600000000
// result 2500000000
// result 3600000000
// result 4900000000
// result 6400000000
// result 8100000000</pre></div><p>Each number that's<a id="id310" class="indexterm"/> passed to our worker is more expensive to process <a id="id311" class="indexterm"/>than the previous number. So overall, processing the entire input array before showing anything to the user would feel as if the application is hanging or broken. But, this is not the case here because although each number is expensive to process, we're posting the results back as they become available.</p><p>We perform the same amount of work as we would perform by passing in an array and getting back an array as output. However, this approach simply changes the order in which things happen. We've introduced cooperative multi-tasking into the picture—compute some data in one task and update the UI in another. The aggregate time taken to complete the work is the same, but to the user, it feels much faster. At the end of the day, the user perceivable performance of our application is the only performance metric that counts.</p><div><div><h3 class="title"><a id="note21"/>Note</h3><p>We passed in the input as individual messages. We could have passed in the input as an array, posted the results individually, and gotten the same effect. However, this would probably amount to nothing more than an unneeded complexity. There's a natural correspondence to the pattern as it is—item in, item out. Don't change it if you don't have to.</p></div></div></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec100"/>Lazy worker chains</h2></div></div></div><p>As we saw in <a class="link" href="ch04.html" title="Chapter 4. Lazy Evaluation with Generators">Chapter 4</a>, <em>Lazy Evaluation with Generators</em> we can assemble chains of generators. This is how we implement complex functionality lazily; an item flows through a chain of generator functions that transform the item before yielding to the next generator until it reaches the caller. Without generators, we would have to allocate a lot of intermediary data structures just for the sake of passing data from one function to the next.</p><p>In the section prior to this one, we saw that a pattern similar to generators was possible with web workers. Since we face a<a id="id312" class="indexterm"/> similar problem here, we don't want to allocate large data structures. We can avoid doing this by passing in items at a more granular level. This has the added benefit of keeping the UI responsive because we're able to update it before the last item arrives from the worker. Given that we can do this much with workers, could we not build on this idea and assemble more complex chains of worker processing nodes?</p><p>For instance, let's say we have a collection of numbers and several transformations. We need to make these transformations in a specific order before we can display them in our UI. Ideally, we would setup a chain of workers where each worker is responsible for performing its designated transformation, then passing the output on to the next worker. Eventually, the main thread gets a value back that it can display in the DOM.</p><p>The problem with this goal is the tricky communication that it involves. Since dedicated workers only communicate with the main thread that created them, it's hardly advantageous to send the results back to the main thread, then onto the next worker in the chain, and so on. Well, it turns out that dedicated workers can directly communicate without involving the main thread. We can use something called channel messaging here. The idea is simple; it involves creating a channel, which has two ports—messages posted on one port and received on the other.</p><p>We've been using messaging channels and ports all along. They're baked into web workers. This is where the message event and  <code class="literal">postMessage()</code> method pattern comes from.</p><p>The following is a visualization<a id="id313" class="indexterm"/> of how we would go about connecting our web workers using channels and ports:</p><div><img src="img/B05133_07_06.jpg" alt="Lazy worker chains"/></div><p>As we can see, each channel uses two messaging ports. The first port is used to post messages, whereas the second is used to receive message events. The only time the main thread is used is when the processing chain is first kicked off by posting a message to the first channel and when the message is received from the third channel.</p><p>Instead of letting the six ports required for worker communication intimidate us, let's write some code; maybe, it'll look a little more approachable there. First we'll create the workers used in the chain. Actually, they're two instances of the same worker. Here's the code:</p><div><pre class="programlisting">addEventListener('message', (e) =&gt; {

    // Get the ports used to send and receive messages.
    var [ port1, port2 ] = e.ports;

    // Listen for incoming messages of the first port.
    port1.addEventListener('message', (e) =&gt; {

        // Respond on the second port with the result of
        // calling "work()".
        port2.postMessage(work(e.data));
    });

    // Starts both ports.
    port1.start();
    port2.start();
});</pre></div><p>This is interesting. In this <a id="id314" class="indexterm"/>worker, we have message ports to work with. The first port is used to receive input, and the second port is used to send output. The <code class="literal">work()</code> function simply squares the given number using our now familiar approach of wasting CPU cycles to see how workers behave. What we want to do in our main thread is to create two instances of this worker so that we can pass the first instance a number to square. Then, without passing the result back to the main thread, it passes the result to the next worker, and the number is squared again. The communication paths should closely mimic the previous diagram. Let's look at some code that connects workers using messaging channels:</p><div><pre class="programlisting">// Starts our workers...
var worker1 = new Worker('worker.js');
var worker2 = new Worker('worker.js');

// Creates the message channels necessary to communicate
// between the 2 workers.
var channel1 = new MessageChannel();
var channel2 = new MessageChannel();
var channel3 = new MessageChannel();

// Our "update()" coroutine logs worker responses as they're
// delivered.
var update = coroutine(function* () {
    var input;

    while (true) {
        input = yield;
        console.log('result', input.data);
    }
});

// Connects "channel1" and "channel2" using "worker1".
worker1.postMessage(null, [
    channel1.port2,
    channel2.port1
]);

// Connects "channel2" and "channel3" using "worker2".
worker2.postMessage(null, [
    channel2.port2,
    channel3.port1
]);

// Connects our coroutine "update()" to any messages
// received on "channel3".
channel3.port2.addEventListener('message', update);
channel3.port2.start();

// Our input data - an array of numbers.
var array = new Array(25)
    .fill(null)
    .map((v, i) =&gt; i * 10);

// Posts each array item to "channel1".
for (let item of array) {
    channel1.port1.postMessage(item);
}</pre></div><p>In addition to the data that we <a id="id315" class="indexterm"/>want to send to the worker, we can also send a list of message ports that we want to transfer to the worker context. This is what we do with the first two messages sent to the worker. The message data is <code class="literal">null</code> because we're not doing anything with it. In fact, these are the only messages we're sending directly to the worker. The rest of the communication happens through the message channels that we've created. The expensive computation happens on the worker because that's where the message handler resides.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec49"/>Using Parallel.js</h1></div></div></div><p>The aim of <a id="id316" class="indexterm"/>the <code class="literal">Parallel.js</code> library is to make interacting with web workers as seamless as possible. In fact, it handles one of the key goals of this book—it hides the concurrency mechanism and allows us to focus on the application that we're building.</p><p>In this section, we'll look at the approach taken by <code class="literal">Parallel.js</code> for worker communication and the general approach of passing code to workers. Then, we'll walk through some code that uses <code class="literal">Parallel.js</code> to spawn new worker processes. Lastly, we'll explore the built-in map/reduce capabilities that the library has to offer.</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec101"/>How it works</h2></div></div></div><p>All the workers that<a id="id317" class="indexterm"/> we've used so far in this book have been our own creation. We implemented message event handling in our workers that computed some value, then posted a response. With <code class="literal">Parallel.js</code>, we don't implement workers. Instead, we implement functions, which are then passed to workers that are managed by the library.</p><p>This takes care of a few headaches for us. All our code is implemented in the main thread, meaning that it's easier to use the functions that we've implemented in the main thread because we don't need to import them into web workers using <code class="literal">importScripts()</code>. We also don't need to manually start web workers by creating them with a script path. Instead, we let <code class="literal">Parallel.js</code> spawn new workers for us, and then, we can tell the workers what to do by passing functions and data to them. So, how does this work, exactly?</p><p>Workers need a script argument. Without a valid script, workers simply do not work. <code class="literal">Parallel.js</code> has a straightforward <code class="literal">eval</code> script. This is what's passed to any worker that the library creates. Then, the API within the main thread assembles code that's to be evaluated within the worker and sends it over whenever we need to communicate with workers.</p><p>This is feasible because <code class="literal">Parallel.js</code> doesn't aim to expose a plethora of functionality backed by workers. Instead, the aim is to make the worker communication mechanism as seamless as possible while providing minimal functionality. This makes it easy to build only the concurrency functionality that's relevant to our application and not a host of other functions that we'll never use.</p><p>Here is an illustration of how<a id="id318" class="indexterm"/> we pass data and code into a worker using <code class="literal">Parallel.js</code> and its <code class="literal">eval</code> script:</p><div><img src="img/B05133_07_07.jpg" alt="How it works"/></div></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec102"/>Spawning workers</h2></div></div></div><p>The <code class="literal">Parallel.js</code> library has the notion of a job. The primary input to a job is the data that the job is going to <a id="id319" class="indexterm"/>process. The creation of a job isn't directly tied to the creation of a background worker. Workers are distinct from <code class="literal">Parallel.js</code> jobs; we don't interact directly with workers when using the library. Once we have our job instance, and it's supplied with our data, we use a job method to invoke workers.</p><p>The most basic method is <code class="literal">spawn()</code>, which takes a function as an argument and runs it in a web worker. The function that we pass to it can return results, and these are then resolved as a thenable object that's returned by <code class="literal">spawn()</code>. Let's look at some code that uses <code class="literal">Parallel.js</code> to spawn <a id="id320" class="indexterm"/>new job backed by a web worker:</p><div><pre class="programlisting">// An input array of numbers.
var array = new Array(2500)
    .fill(null)
    .map((v, i) =&gt; i);

// Creates a new parallel job. No workers have been
// created at this point - we only pass the constructor
// the data we're working with.
var job = new Parallel(array);

// Start a timer for our "spawn()" job.
console.time(`${array.length} items`);

// Creates a new web worker, passing it our data and
// this function. We're slowly mapping each number in
// the array to it's square.
job.spawn((coll) =&gt; {
    return coll.map((n) =&gt; {
        var i = 0;
        while (++i &lt; n * n) {}
        return i;
    });

// The return value of "spawn()" is a thenable. Meaning
// we can assign a "then()" callback function, just as
// though a promise were returned.
}).then((results) =&gt; {
    console.timeEnd(`${array.length} items`);
    // → 2500 items: 3408.078ms
});</pre></div><p>Well now, that's <a id="id321" class="indexterm"/>pretty cool; we don't have to worry about any of the monotonous web worker life-cycle tasks. We have some data and some function that we want to apply to the data, and we want to run it in parallel with other work taking place on the page. The cherry on the top is the familiar thenable that's returned from the <code class="literal">spawn()</code> method. It fits right into our concurrent application, where everything else is treated as a promise.</p><p>We log how long it takes for our function to process the input data we give it. We only spawn a single web worker for this task, so the result is reached in the same amount of time as it would have been, were it computed in the main thread. Aside from freeing up the main thread to handle DOM events and repainting, there's no objective performance gain. We'll see if we can use a different method to up the concurrency level.</p><div><div><h3 class="title"><a id="note22"/>Note</h3><p>The worker created by <code class="literal">spawn()</code> is immediately terminated when we're done with it. This frees up memory for us. However, there's no concurrency level governing the use of <code class="literal">spawn()</code>, we can call it 100 times in a row if we like.</p></div></div></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec103"/>Mapping and reducing</h2></div></div></div><p>In the last section, we <a id="id322" class="indexterm"/>spawned a worker thread using the <code class="literal">spawn()</code> method. <code class="literal">Parallel.js</code> also <a id="id323" class="indexterm"/>has a <code class="literal">map()</code> method and a <code class="literal">reduce()</code> method. The idea is to make things easier for us. By passing <code class="literal">map()</code> a function, the library will automatically apply it to each item in the job data. Similar semantics apply with the <code class="literal">reduce()</code> method. Let's take a look at how this works by writing some code:</p><div><pre class="programlisting">// An input array of numbers.
var array = new Array(2500)
    .fill(null)
    .map((v, i) =&gt; i);

// Creates a new parallel job. No workers have been
// created at this point - we only pass the constructor
// the data we're working with.
var job1 = new Parallel(array);

// Start a timer for our "spawn()" job.
console.time('job1');

// The problem here is that Parallel.js will
// create a new worker for every array element, resulting
// in parallel slowdown.
job1.map((n) =&gt; {
    var i = 0;
    while (++i &lt; n * n) {}
    return i;
}).reduce((pair) =&gt; {

    // Reduces the array items to a sum.
    return pair[0] + pair[1];
}).then((data) =&gt; {
    console.log('job1 reduced', data);
    // → job1 reduced 5205208751

    console.timeEnd('job1');
    // → job1: 59443.863ms
});</pre></div><p>Ouch! This is quite the performance hit—what's going on here? What we're seeing here is a phenomenon called <a id="id324" class="indexterm"/>parallel slowdown. This slowdown takes place when there's too much parallel<a id="id325" class="indexterm"/> communication overhead. The reason this is happening in <a id="id326" class="indexterm"/>this particular example is due to the way <code class="literal">Parallel.js</code> processes arrays in <code class="literal">map()</code>. Each array item goes through a worker. This doesn't mean that 'there are <code class="literal">2500</code> workers created—one for each element in the array. The number of created workers maxes out at four or the <code class="literal">navigator.hardwareConcurrency</code> value—similar semantics we looked at earlier in this book.</p><p>The real overhead comes from messages sent to and received from the workers—5000 messages! This is obviously not optimal, as evidenced by the timer in the code. Let's see if we can make a drastic improvement on these numbers while keeping roughly the same code structure:</p><div><pre class="programlisting">// A faster implementation.
var job2 = new Parallel(array);
    
console.time('job2');

// Before mapping the array, split the array into chunks
// of smaller arrays. This way, each Parallel.js worker is
// processing an array instead of an array item. This avoids
// sending thousands of web worker messages.
job2.spawn((data) =&gt; {
    var index = 0,
        size = 1000,
        results = [];

    while (true) {
        let chunk = data.slice(index, index + size);

        if (chunk.length) {
            results.push(chunk);
            index += size;
        } else {
            return results;
        }
    }
}).map((array) =&gt; {

    // Returns a mapping of the array chunk.
    return array.map((n) =&gt; {
        var i = 0;
        while (++i &lt; n * n) {}
        return i;
    });
}).reduce((pair) =&gt; {

    // Reduces array chunks, or numbers, to a sum.
    return (Array.isArray(pair[0]) ?
            pair[0].reduce((r, v) =&gt; r + v) : pair[0]) +
        (Array.isArray(pair[1]) ?
            pair[1].reduce((r, v) =&gt; r + v) : pair[1]);
}).then((data) =&gt; {
    console.log('job2 reduced', data);
    // → job2 reduced 5205208751

    console.timeEnd('job2');
    // → job2: 2723.661ms
});</pre></div><p>Here, we can see that the <a id="id327" class="indexterm"/>same results<a id="id328" class="indexterm"/> are generated, and much faster. The difference is that we start things off by slicing the array into chunks of smaller arrays. These arrays are the items that get passed to the workers, instead of individual numbers. So the mapping job has to change slightly as well, instead of squaring a number, it's mapping a smaller array to an array of squares. The reduce logic is slightly more complex, but overall, our approach is still the same. Most importantly, we've removed the heavy<a id="id329" class="indexterm"/> message-passing bottleneck that was <a id="id330" class="indexterm"/>causing unacceptable performance flaws in the first implementation.</p><div><div><h3 class="title"><a id="note23"/>Note</h3><p>Just like the <code class="literal">spawn()</code> method cleans up the worker when it returns, so too do the <code class="literal">map()</code> and <code class="literal">reduce()</code> <code class="literal">Parallel.js</code> methods. The downside to freeing workers is that they need to be recreated whenever these methods are called. We'll address this challenge in the next section.</p></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec50"/>Worker pools</h1></div></div></div><p>The final section of this chapter <a id="id331" class="indexterm"/>covers the concept of worker pools. In the preceding section on <code class="literal">Parallel.js</code>, we ran up against an issue where workers were frequently created and terminated. This is a lot of overhead. If we know the level of concurrency we're capable of operating at, then why not allocate a statically-sized pool of workers that can take on work?</p><p>The first design task for creating a worker pool is to allocate the workers. The next step is to schedule the jobs as they come in by distributing them to available workers in the pool. Lastly, we'll need to account for busy states when all the workers are busy. Let's do this.</p><div><div><div><div><h2 class="title"><a id="ch07lvl2sec104"/>Allocating pools</h2></div></div></div><p>Before we think about allocating<a id="id332" class="indexterm"/> pools of worker threads, we need to look at <a id="id333" class="indexterm"/>the overarching worker pool abstraction. How do we want it to look and behave? Ideally, we want the pool abstraction to look and behave like a plain dedicated worker. We can post a message to the pool and get a promise in response. So while we can't directly extend the Worker prototype, we can create a new abstraction that closely resembles the Worker API.</p><p>Let's look at some <a id="id334" class="indexterm"/>code now. Here's the initial abstraction that<a id="id335" class="indexterm"/> we'll use:</p><div><pre class="programlisting">// Represents a "pool" of web worker threads, hidden behind
// the interface of a single web worker interface.
function WorkerPool(script) {

    // The level of concurrency, or, the number of web
    // workers to create. This uses the 
    // "hardwareConcurrency" property if it exists.
    // Otherwise, it defaults to 4, since this is
    // a reasonable guess at the most common CPU topology.
    var concurrency = navigator.hardwareConcurrency || 4;

    // The worker instances themselves are stored in a Map,
    // as keys. We'll see why in a moment.
    var workers = this.workers = new Map();

    // The queue exists for messages that are posted while,
    // all workers are busy. So this may never actually be
    // used.
    var queue = this.queue = [];

    // Used below for creating the worker instances, and 
    // adding event listeners.
    var worker;

    for (var i = 0; i &lt; concurrency; i++) {
        worker = new Worker(script);
        worker.addEventListener('message', function(e) {

            // We use the "get()" method to lookup the
            // "resolve()" function of the promise. The
            // worker is the key. We call the resolver with
            // the data returned from the worker, and
            // can now reset this to null. This is important
            // because it signifies that the worker is free
            // to take on more work.
            workers.get(this)(e.data);
            workers.set(this, null);

            // If there's queued data, we get the first
            // "data" and "resolver" from the queue. Before
            // we call "postMessage()" with the data, we
            // update the "workers" map with the new
            // "resolve()" function.
            if (queue.length) {
                var [ data, resolver ] = queue.shift();
                workers.set(this, resolver);
                this.postMessage(data);
            }
        }.bind(worker));

        // This is the initial setting of the worker, as a
        // key, in the "workers" map. It's value is null,
        // meaning there's no resolve function, and it can
        // take on work.
        this.workers.set(worker, null);
    }
}</pre></div><p>When a new <code class="literal">WorkerPool</code> is created, the given script is used to spawn all the workers within the pool. The <code class="literal">workers</code> property is a <code class="literal">Map</code> instance, and the worker instances themselves are the <a id="id336" class="indexterm"/>keys. The reason we store the workers as map keys <a id="id337" class="indexterm"/>is so that we can easily lookup the appropriate resolver function to call.</p><p>When a given worker responds, the <code class="literal">message</code> event handler that we've added to each worker is called, and this is where we find the resolver function that's waiting to be called. There's no chance of us calling the wrong resolver because a given worker doesn't take on new work until it's finished with its current task.</p></div><div><div><div><div><h2 class="title"><a id="ch07lvl2sec105"/>Scheduling jobs</h2></div></div></div><p>Now we'll implement the <code class="literal">postMessage()</code> method. This is what the caller will use to post a message to one of the<a id="id338" class="indexterm"/> workers in the pool. The caller doesn't know which worker fulfills their request, nor do they care. They get a promise as a return value, and it's resolved with the worker response as the value:</p><div><pre class="programlisting">WorkerPool.prototype.postMessage = function(data) {

    // The "workers" Map instance, where all the web workers
    // are stored.
    var workers = this.workers;

    // The "queue" where messages are placed when all the
    // workers are busy.
    var queue = this.queue;

    // Try finding an available worker.
    var worker = this.getWorker();

    // The promise is immediately passed back to the caller,
    // even if there's no worker available.
    return new Promise(function(resolve) {

        // If a worker is found, we can update the map,
        // using the worker as the key, and the "resolve()"
        // function as the value. If there's no worker, then
        // the message data, along with the "resolve()"
        // function get pushed to the "queue".
        if (worker) {
            workers.set(worker, resolve);
            worker.postMessage(data);
        } else {
            queue.push([ data, resolve ]);
        }
    });
};</pre></div><p>It's the promise executor function that takes care of actually finding the first available worker and posting our message there. When an available worker is found, we also set the worker's resolver function in our <code class="literal">workers</code> map. If there are no available <code class="literal">workers</code> in the pool, the posted message goes into the <code class="literal">queue</code>. This queue is emptied in the <code class="literal">message</code> event handler. This is because when a worker comes back with a message, it means the worker is free to take on more work, and it checks if there's anything queued before returning to an idle state.</p><p>The <code class="literal">getWorker()</code> method is a simple helper that finds the next available worker for us. We know a worker is available to take on a task if its <code class="literal">resolver </code>function is set to null in the <code class="literal">workers</code> map. Lastly, let's<a id="id339" class="indexterm"/> see this worker pool in action:</p><div><pre class="programlisting">// Create a new pool, and a workload counter.
var pool = new WorkerPool('worker.js');
var workload = 0;

document.getElementById('work')
    .addEventListener('click', function(e) {

        // Get the data we're going to pass to the
        // worker, and create a timer for this workload.
        var amount = +document.getElementById('amount').value,
            timer = 'Workload ' + (++workload);

        console.time(timer);

        // Pass the message to the pool, and when the promise
        // resolves, stop the timer.
        pool.postMessage(amount).then(function(result) {
            console.timeEnd(timer);
        });

        // If messages are getting queued, our pool is 
        // overworked display a warning.
        if (pool.queue.length) {
            console.warn('Worker pool is getting busy...');
        }
    });</pre></div><p>In this usage scenario, we have a couple of form controls that send parameterized work to the worker. The larger the number, the longer the work will take; it uses our standard <code class="literal">work()</code> function that slowly squares numbers. If we use a large number and frequently click the button that posts the message to the pool, then eventually, we'll exhaust the pool. If 'this is the case, we will<a id="id340" class="indexterm"/> display a warning. However, this is just for troubleshooting purposes—the posted messages aren't lost when the pool is busy, they're simply queued.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch07lvl1sec51"/>Summary</h1></div></div></div><p>The focus of this chapter has been removing obtrusive concurrency semantics from our code. It simply raises the likelihood of our application's success because we'll have code that's easy to maintain and build upon. The first issue that we tackled was writing concurrent code by making everything concurrent. When there's no guesswork involved, our code is consistent and less susceptible to concurrency bugs.</p><p>Then, we looked at various approaches we can take to abstract web worker communication. Helper functions are one option and so is extending the <code class="literal">postMessage()</code> method. We then addressed some of the limitations of web workers when we need our UI to be responsive. Even though our large dataset is processed faster, we still have the issue of updating the UI. This is done by treating web workers as generators.</p><p>We don't have to write all these JavaScript parallelization tools ourselves. We spent some time looking at the various capabilities and limitations of the <code class="literal">Parallel.js</code> library. We wrapped up the chapter with a look at web worker pools. These remove a lot of overhead related to worker creation and termination, and they drastically simplify how tasks are distributed and results are reconciled.</p><p>That does it for our concurrency topics in the front-end. Now it's time to shift gears and look at JavaScript concurrency in the back-end with NodeJS.</p></div></body></html>