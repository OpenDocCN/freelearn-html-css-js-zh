- en: Service Worker Caching Patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The internet is great, until you are offline or have poor connectivity. Then
    it becomes an act of futility as you wait for a page to load that never seems
    to materialize. Eventually, the request times out and the browser displays a message
    letting you know you're offline—Chrome is known for its cute offline dinosaur.
  prefs: []
  type: TYPE_NORMAL
- en: Most web traffic comes from smartphones, and many of those connections are made
    over a cellular connection (GPRS). Cellular networks are great when they work,
    but often a clean connection to the internet is not guaranteed.
  prefs: []
  type: TYPE_NORMAL
- en: Even in the United States, reliable LTE networks are not ubiquitous. There are
    several locations near my house where I have no cell coverage. Imagine what it
    might be like in a less developed area.
  prefs: []
  type: TYPE_NORMAL
- en: This is where service workers and the Cache API can help you out. The combination
    of these two features enables you to make the network optional. A service worker
    has several events that you can leverage to craft a web server in the browser.
  prefs: []
  type: TYPE_NORMAL
- en: 'The topics that will be covered in this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: How the service worker cache works
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common service worker caching strategies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How the service worker cache works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The service worker sits between the browser and the network. By adding a `fetch`
    event handler, you can determine how the request is handled. All network requests
    pass through the service worker''s fetch event handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00071.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: This gives you a hook, or way to inject logic into the workflow, to intercept
    requests and determine how and where the response is returned.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the service worker, you can do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Pass the request to the network, the traditional method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Return a cached response, bypassing the network altogether
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a custom response
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When the network fails, you can program the service worker to return a response
    from the cache, even if it is a *fallback* response. Because the service worker
    can return responses from the cache, your pages can load instantly if they are
    cached:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00072.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, the service worker is programmed to intercept all
    network requests, and can return a response from either the cache or the network.
  prefs: []
  type: TYPE_NORMAL
- en: Because the service worker runs locally, it is always available. It can decide
    the best way to return a response based on the conditions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the service worker living within the context
    of the browser, providing a proxy to handle requests, even when the network is
    unavailable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00073.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: When utilizing a service worker and the network is unavailable, your website
    can still function if you have valid cached responses. Even if a page is not cached,
    you can create a response so that the customer has something relevant to interact
    with. Later in the book, I will go over how you can queue the user's actions and
    update the server when the network is available.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows how the service worker can use cached resources
    when the network is unavailable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00074.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Service worker events
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A service worker has several events. You can use these to manage your application's
    cache. We have already looked at using the *install* and *activate* events to
    precache responses in Chapter 5,  *The Service Worker Life Cycle*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The all-star service worker event is `fetch`. This event fires each time a
    network-addressable asset (URL) is requested. By adding a `fetch` event handler
    to your service worker, you can intercept all network requests, triggering a workflow
    to determine how to respond:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As you learned [Chapter 6](part0123.html#3L9L60-f12cdcca08b54960b3d271452dc7667d), *Mastering
    the Cache API – Managing Web Assets in a Podcast Application*, you can use the
    Fetch API's custom `request` and `response` objects to inspect requests and create
    or clone network responses.
  prefs: []
  type: TYPE_NORMAL
- en: The event variable supplied by the `fetch` event handler has a request property.
    This property is a `request` object. You can use the `request` object to determine
    how you will return the response. In this chapter, you will learn several caching
    strategies that you can apply to make your progressive web application work faster, and offline.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing how to use the `fetch` event to maximize performance using the application's
    cache is the key to providing the best user experience possible.
  prefs: []
  type: TYPE_NORMAL
- en: Caching patterns and strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Service worker events give you gateways to the service worker life cycle in
    order to apply your caching strategy. But there is more to this than just checking
    whether a valid response has been cached or is passing the request to the network.
    You should have a plan of how your application will use the service worker cache,
    events, and the network to deliver the best experience.
  prefs: []
  type: TYPE_NORMAL
- en: This means that you need to have a collection of common patterns and strategies
    to build your application logic upon. The rest of the chapter will review common
    caching patterns that you can use to build your applications.
  prefs: []
  type: TYPE_NORMAL
- en: Strategies are the combination of guidelines and example code that you can use
    to build your applications. As you continue through this book, you will see these
    strategies used in the PodStr and PWA Tickets applications.
  prefs: []
  type: TYPE_NORMAL
- en: Precaching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the key aspects of the PRPL pattern, which we will learn more about in
    a later chapter, is to store application assets when the application is installed.
    When a user accesses an initial entry point to a web application, a background
    process is triggered that will automatically load additional assets that will
    later be needed as different aspects of the site are rendered. This is known as
    precaching, or priming your application's cache for better performance in the
    future.
  prefs: []
  type: TYPE_NORMAL
- en: 'Service workers make this practice easy to manage. You can take advantage of
    the `install` and `activate` events, as well as when a service worker is initially
    triggered. The common practice is to use the `install` event when a new service
    worker is registered to precache a list of well-known assets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'There are two types of precache strategies you need to understand: precaching
    as a dependency and not as a dependency.'
  prefs: []
  type: TYPE_NORMAL
- en: Installing as a dependency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When precaching application assets, there are certain assets you know will
    be used rather quickly or frequently. You can consider these mission-critical.
    And while the initial page load or app shell load may trigger network requests
    for these assets, causing them to be cached, there will probably be other assets
    that you want to ensure are cached early in the application-loading process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00075.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'These assets should be precached as a dependency of the `install` event completing.
    In other words, these assets must complete caching before the `install` event
    closes, which means you should use the `event.waitUntil` method to hold the process
    open. By doing so, you delay any active events from triggering until these assets
    are completely cached:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Installing not as a dependency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Precaching is not limited to mission-critical assets. You can most likely identify
    many assets that will be commonly used, but are not mission-critical to your application's
    success. You can still use the service worker `install` event to cache this set
    of assets, but choose not to make them dependent on the event completing. This
    is known as precaching assets without dependency.
  prefs: []
  type: TYPE_NORMAL
- en: In this scenario, you will also trigger the precaching of these network assets,
    but you will not return the `cache.addAll` method in the `event.wait` `until`
    call. The assets will still be added to the cache, but will not hold the `install`
    event open until all of the assets are cached.
  prefs: []
  type: TYPE_NORMAL
- en: 'This technique gives you the ability to minimize the latency of precaching
    assets that might hold the service worker installation up. One of your goals when
    registering a new service worker is to make it available as quickly as possible.
    Requesting assets that may take a little while can hold that process up. This
    means that your service worker cannot take control of any clients until all this
    caching, including the `activate` event, is done, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00076.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'While you trigger this request in the `install` event, the event is not delayed.
    The request will still be cached, but outside of the `event` loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: On activate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `activate` event is the next part of the service worker life cycle chain
    that you can leverage to manage cached assets. It can also be used to cache assets,
    but is more commonly used to perform cache model cleanup.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of focusing on caching assets, the `activate` event is better suited
    to clean up legacy caches. This can eliminate version mismatch issues that can
    break your application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00077.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To implement this strategy, you need to have a discernible version cache-naming
    convention. I recommend adding a version number to all of your named caches. This
    gives you a simple pattern that you can match to determine whether a named cache
    should be removed. Just be aware that any assets that are cached in those named
    caches will also be removed. This is okay, as the new version of the service worker
    typically caches updated versions of these assets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding example code loops through all the named caches and checks whether
    the cache belongs to the current service worker. The version variable has the
    version number pattern we are looking for. My personal preference is to declare
    a `const` value at the beginning of the service worker:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: I add a `v` to the value to further indicate that it is a version number, but
    that is more of a mental tool to appeal to my personal preferences. Feel free
    to use any sort of versioning pattern you like. Semantic versioning or even a
    random hash or GUID would also work well here.
  prefs: []
  type: TYPE_NORMAL
- en: The main point is to have a unique pattern that you can identify in your cache
    names. Creating a variable is useful because it can be appended to the cache name
    to make cleanup easier to manage.
  prefs: []
  type: TYPE_NORMAL
- en: Real-time caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Caching does not need to be limited to the service worker installation events.
    While you should precache your common assets, there are probably many resources
    that are dynamic in nature. Some example in podcast applications are the individual
    podcasts and podcast episode pages.
  prefs: []
  type: TYPE_NORMAL
- en: Each podcast contains unique properties, such as a title, description, and logo.
    Each episode also has a unique title, description, possibly an image, and, of
    course, the audio file.
  prefs: []
  type: TYPE_NORMAL
- en: These are very dynamic and fluid pieces of data that create many opportunities
    for new pages and page assets, as well as updates to these same pages and assets.
    The service worker `fetch` event handler gives you the hook to intercept all requests
    to the network so you can determine whether those assets are properly locally cached
    before hitting the internet.
  prefs: []
  type: TYPE_NORMAL
- en: This basic pattern gives you the ability to instantly load assets that were
    previously cached without worrying about network connectivity. There are many
    variations of this pattern, as you will see in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: On user interaction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first dynamic caching strategy is in response to a user interaction, such
    as clicking a button. Instead of this being explicitly caught by the service worker
    `fetch` event, it can be managed from the client JavaScript. This takes advantage
    of the client''s (browser) access to the Client API:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00078.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The podcast application episode page has a button that the user can select to
    cause the episode's MP3 file to be stored offline. This is part of the listen-later
    functionality, something I love to use in the Stitcher app!
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example code is a function that is executed when the user clicks
    the Listen Later button on an episode page. A `fetch` is made to the API and the
    response is cached in the `LISTEN_LATER` cache:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: To make this feature complete, a similar method would be used to cache the episode's
    MP3 file. You would also want to persist something you can use to visually indicate
    that the episode is saved for later if the user opens the episode page later.
    You would also want to maintain a local list of saved episodes. This can be done
    using `IndexedDB`.
  prefs: []
  type: TYPE_NORMAL
- en: On network response
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When a request returns from the network, you can intercept this part of the
    `fetch` process and handle it based on your application's logic. The most common
    thing to do is to cache the response while returning a copy to the client.
  prefs: []
  type: TYPE_NORMAL
- en: 'This also extends the core pattern of on-demand asset caching. It''s important
    to note that when you intercept a request from the network, you should clone the
    response before caching it. A response can only be used once:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00079.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The `clone` method creates a deep copy of the response, allowing you to do
    something else with the response. The most common use of the `clone` method is
    to create a copy so that one can be cached and the other returned to the client,
    as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Stale while revalidating
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next phase of our basic network-caching strategy is to return a previously
    cached version to the client while making a network request for the latest version.
  prefs: []
  type: TYPE_NORMAL
- en: 'This strategy is very helpful when you need to return a response quickly, but
    the freshness of the data is not the biggest requirement. For example, a podcast
    episode does not change its details much, if at all. Returning a cached version
    of the page and its images would not mean that the user is missing out on fresh
    data. The following diagram shows the interactions involved in this process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00080.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'But maybe you want to make sure that the user has the latest content. You can
    return the cached response instantly, while making a new request to the network
    and caching that response. This will replace any previously cached data for the
    next time the page is requested, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: On push notification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'User activity and network requests are not the only times you can cache a network
    resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00081.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'You can also use a `push` message to initiate caching responses, as shown in
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: In this strategy, the `push` event handler determines the type of message action.
    If it is a notice to update the application, it initiates the process. The preceding
    code example is a bit of an oversimplification, but it shows the important parts.
  prefs: []
  type: TYPE_NORMAL
- en: The `push` message body should have some sort of property indicating the action
    that should be taken. In this case, it triggers an update workflow. Included in
    the message is a property, `urls`, which is an array of all the URLs that should
    be updated or cached.
  prefs: []
  type: TYPE_NORMAL
- en: The `cache.addAll` method makes the code simple, since it will perform all the
    `fetch` requests and cache the responses for you.
  prefs: []
  type: TYPE_NORMAL
- en: You should always notify the user that a `push` notification has been received
    and the application is being updated. In this situation, you may also want to
    prompt the user to reload the app if they are currently using it. You can check
    to see whether there are any active clients while you are updating the cache,
    and notify them of the updating process. You will learn more about `push` notifications
    in a future chapter.
  prefs: []
  type: TYPE_NORMAL
- en: On background sync
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A more advanced caching pattern would be to use the Background Sync API. We'll
    talk about this in more detail in a later chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The core idea is to wrap all of your network request in a background sync wrapper.
    Here, you would create a request tag and cue it up to be processed as soon as
    the network is available.
  prefs: []
  type: TYPE_NORMAL
- en: This adds a new layer of complexity to using the service worker fetch, but can
    be very valuable if you need to maintain an asynchronous dataset with the server.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are connected to the network, any request passed to the Background Sync
    API will immediately be executed as normal. If you are not connected, it''s added
    to a queue and executed when the device regains connectivity. The following image
    shows the interactions involved in this process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00082.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'At that point, a `sync` event triggers, which could be used to initiate a cache
    update, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In this example, a `background sync` tag has been created for a specific podcast.
    If that tag triggers the `sync` event, the corresponding podcast details page
    is added to the dynamic cache.
  prefs: []
  type: TYPE_NORMAL
- en: Cache only
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When a network resource is precached, you can choose to implement a policy of
    only using a cached version of the asset. This is known as the cache-only strategy.
  prefs: []
  type: TYPE_NORMAL
- en: When you know a resource can be safely cached long term, you can reduce more
    overhead in your application by eliminating unnecessary network chatter.
  prefs: []
  type: TYPE_NORMAL
- en: Retrieving these resources from the cache also means that the application can
    load faster and, of course, load offline. Just make sure they don't become too
    stale.
  prefs: []
  type: TYPE_NORMAL
- en: Here, any request for a network resource will be retrieved only from the cache
    and no network response will be used. This can be very valuable for long-term
    static resources, such as application core JavaScript and CSS files. You could
    also apply it to images such as your site's logo and font files.
  prefs: []
  type: TYPE_NORMAL
- en: If you are employing the cache-only strategy, I advise having a routine automatically
    triggered when your service worker is executed. This routine should periodically check
    for new response versions to ensure that you have the most up-to-date data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, make sure that these resources are static or they could potentially break
    your application. If you choose to make them static, I advise adding these resources
    to a service worker version change before deploying them to your server. The following
    image shows the the interactions involved in this process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00083.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The cache-only strategy pairs well with either of the precache strategies discussed
    earlier in the chapter. Precaching cache-only resources should ensure that they
    are available from the cache, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In this code example, the `fetch` event handler only responds with a match from
    the cache. If one does not exist, the client will receive a `not found` (404 status
    code) response.
  prefs: []
  type: TYPE_NORMAL
- en: Network only
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The complete opposite of cache-only is to only request a resource from the network.
    In this scenario, you will identify network resources that should always be requested
    from the server.
  prefs: []
  type: TYPE_NORMAL
- en: 'The strategy should be employed on data that changes very frequently. For example,
    a stock ticker application would want to make sure that the request to update
    stock prices is made immediately and not from a local cache. Stale data in this
    scenario can cost you a fortune. The following image shows the interactions involved
    in this process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00084.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'You should identify the nature of any file or network resources you might need
    to access, and ensure that the data is constantly being updated. You can intercept
    these requests and apply the proper strategy based on routes and patterns. To
    do so, I would advise you to have some unique identifier in these assets'' URLs,
    as shown in the following code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Cache falling back to network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most common pattern I see employed in service workers is the cache falling
    back to the network. It's very popular because checking for an asset's presence
    in your cache means that it can return immediately. If it does not, you still
    have the network fallback retrieving it as fast as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Any asset that is not precached or previously cached from the same pattern
    would be accessible, assuming you are online. The following image shows the interactions
    involved:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00085.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: I say that this is probably the most common pattern used because any asset that
    is not precached could comfortably fit into this pattern. The podcast application
    uses this pattern for all the individual podcast and episode pages. This makes
    them accessible as soon as possible, but we don't want to precache every single
    file and image ahead of time, only on-demand.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of this pattern being executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'It seems pointless to execute this pattern without caching the network response.
    The following code shows how I recommend you apply this strategy; I call it "cache
    falling back to the network", caching the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This is the more complete version of this pattern. Now, the next time the resource
    is requested, it will come from the cache. But if it was not previously cached,
    it can be retrieved from the network.
  prefs: []
  type: TYPE_NORMAL
- en: Cache and network race
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another interesting caching pattern, of the variation of the cache falling
    back to the network pattern, is a cache and network race pattern. This is where
    you will simultaneously request the resource from the cache and the network. The
    fastest response wins. While the cache should be the winner, it may not always
    win. This pattern also gives you the opportunity to retrieve the network version
    a little bit faster if there is no cached version. The following image shows the
    interactions involved in this process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00086.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The drawback to this pattern is that you will always make a network request
    even if it''s not needed. This will increase your network traffic. But you could
    also look at it as a way to ensure you''ve got at least some of the freshest content
    cached every single time. It can also be viewed as a variation of the stale while
    revalidating strategy. The following code shows how to implement the cache and
    network race pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Note that there is a custom `promiseAny` function. This is because of a limitation
    of the `Promise.race` method. When a `Promise.race` method is used and any of
    the supplied promises throws an exception, the entire process fails.
  prefs: []
  type: TYPE_NORMAL
- en: This pattern depends on at least one promise resolving a response. The `promiseAny` function
    is a modification to the `Promise.race` method, except it will not fail if a supplied
    promise fails. It assumes that one of the promises will succeed and return the
    winner.
  prefs: []
  type: TYPE_NORMAL
- en: Network falling back to cache
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have a time-sensitive network resource that you always want to hit the
    network, you should also consider using the network falling back to cache strategy.
    Here, you will always try to access the network, but if the network is inaccessible,
    then you have the built-in option to retrieve the most recently cached version
    of the file.
  prefs: []
  type: TYPE_NORMAL
- en: 'If it is critical that the resource is fresh, I advise that you visually alert
    the customer of the time that is associated with that response. The following
    image shows the interactions involved in this process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00087.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'This pattern can also be to provide a fallback for any asset that is inaccessible
    over the network, which we will see in the next pattern. The following code shows
    how to implement the network falling back to cache pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Generic fallback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next step from the network falling back to the cache is to have a generic
    fallback for all requests. You should use this when no response was available
    either in the cache or from the network.
  prefs: []
  type: TYPE_NORMAL
- en: You can see this pattern employed across the Podstr application for podcast
    episodes and their associated images.
  prefs: []
  type: TYPE_NORMAL
- en: The trick here is to precache a fallback response for these particular network
    assets. I also advise that you apply this strategy by matching route variations
    and not individual URLs.
  prefs: []
  type: TYPE_NORMAL
- en: In the Podstr podcast application, there are generic fallbacks for the podcast
    pages, episode pages, and podcast logos. I identified each of these as dynamic
    resources that cannot be precached.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, if you can't access the resource, that means that it is not found
    or the device is offline. I think it's important that you have some logic in place
    to determine the difference. If the application is offline, you want to visually
    indicate that somehow, but if the resource is truly not found, you may want to
    return a slightly different response.
  prefs: []
  type: TYPE_NORMAL
- en: 'I think Flipkart does a fantastic job of this. When the application is offline,
    they greyscale the entire UI. This is a very clear indication to the end user
    that the device is offline, which means that they may not necessarily be able
    to access the information, and that any information they receive may not be current.
    The following screenshot shows an example of this greyscaling:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00088.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you receive an error `404` message, then you can return a Not Found page
    and use that to your advantage as well. The following image shows the interactions
    involved in this pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00089.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Maybe you will choose to direct them to a related resource, or provide a sitemap,
    as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Service worker templating
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A concept you should embrace about service workers is that they can act like
    a web server in the browser. Traditionally, web servers have used runtime rendering
    platforms, such as ASP.NET, PHP, Ruby on Rails, and content management systems
    such as WordPress, Drupal, and Joomla!. These systems are rendering engines more
    than anything else. You can perform HTML rendering inside of a service worker.
  prefs: []
  type: TYPE_NORMAL
- en: Single-page applications have become very popular this decade. They effectively
    take ownership of this rendering process from the server. Today, it is popular
    to preload application templates, whether you're using mustache, handlebars, or
    larger frameworks such as Angular and React. All of these are essentially just
    HTML rendering systems. The difference between the server side and the client
    side is where the rendering takes place. Because you can intercept network requests
    in a service worker, the rendering process can be moved from the client UI or
    the server to the service worker.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this pattern, you will most likely precache the page or component templates
    ahead of time and make network requests to an API to return data, typically formatted
    in JSON. When you retrieve the new JSON, you will then render the markup in the
    service worker and return the HTML to the client. The following image shows the
    interactions involved in this pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00090.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: My personal technique is to use mustache because it is simple and fast. The
    overall technique is a little bit advanced, but once you have a working pattern,
    I think you'll see that it's easier to implement.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, the `fetch` event handler looks for any request to the podcast
    episode routes. When an episode request is made, it is intercepted and a new custom
    request created. Instead of requesting the HTML from the server, the service worker
    will create a request to an API to retrieve the JSON.
  prefs: []
  type: TYPE_NORMAL
- en: In theory, the request for the JSON should be smaller than a request for the
    HTML. The smaller packet should be loaded slightly faster. The real question is
    can the small request be retrieved and rendered faster than a request for prerendered
    HTML? This is an answer I cannot give you. It will require some experimentation
    with your application's pages and API to determine which one is the best solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'For small pieces of data, such as the episode page, chances are that the service
    worker rendering will be slightly slower. But if your page contains a lot of information
    that is repeatable—such as the kind of information that you often see in line-of-business
    applications—this technique could improve your overall performance. The following
    code shows how you can implement this pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Once the API request returns the service worker logic, it then loads the content
    template and renders it to HTML. This HTML is then returned to the client in a
    custom `response` object.
  prefs: []
  type: TYPE_NORMAL
- en: An even more advanced way to use the strategy is to use it in concert with caching
    a response. This way, you render the response once, cache it, and check to see
    whether it's cached the next time.
  prefs: []
  type: TYPE_NORMAL
- en: This pattern may not be optimal for every scenario, but it should be considered
    if you have pages with large, repeating datasets and wish to take advantage of
    any speed gains.
  prefs: []
  type: TYPE_NORMAL
- en: The scenario I believe this pattern offers the most benefit for is dynamically
    rendered markup where data changes frequently. Progressive web apps, such as the
    Podstr application, may not realize performance gains, but a line-of-business
    application can.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These strategies should serve as your service worker fetching and caching workflow.
    The reason there are so many strategies is that there are many scenarios for application
    assets. How you apply these strategies is up to you, and they may require some
    experimentation to determine the best strategy for each asset type.
  prefs: []
  type: TYPE_NORMAL
- en: These strategies may not be the exact patterns you need for your application,
    but they will serve as the foundation for all your caching needs. You can use
    these as starting points that you can extend, mix, and match to create the best
    strategies for your application.
  prefs: []
  type: TYPE_NORMAL
