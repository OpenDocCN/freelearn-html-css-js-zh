<html><head></head><body>
		<div><h1 class="chapter-number" id="_idParaDest-210"><a id="_idTextAnchor211"/>13</h1>
			<h1 id="_idParaDest-211"><a id="_idTextAnchor212"/>A CI/CD Pipeline for Your Microservices</h1>
			<p><strong class="bold">Continuous integration</strong> (<strong class="bold">CI</strong>) and <strong class="bold">continuous delivery/deployment</strong> (<strong class="bold">CD</strong>) are fundamental <a id="_idIndexMarker1008"/>practices in modern software development, forming <a id="_idIndexMarker1009"/>the backbone of efficient DevOps workflows. Together, they automate and streamline the processes of integrating code changes, testing, and deploying applications, ensuring that software is always in a deployable state.</p>
			<p>One of the modern software development requirements for developers is to at least understand and have essential skills for building pipelines and working with different automation systems.</p>
			<p>This chapter is about understanding and applying CI/CD to your microservices. Developing these fundamental DevOps skills will help you stay aligned with modern development practices.</p>
			<p>We’ll cover the following topics:</p>
			<ul>
				<li>The essentials of CI/CD processes</li>
				<li>Working with Azure Cloud</li>
				<li>Working with GitHub actions</li>
				<li>Building a pipeline</li>
			</ul>
			<p>You don’t need any previous experience of CI/CD to cover and understand the current chapter.</p>
			<h1 id="_idParaDest-212"><a id="_idTextAnchor213"/>The essentials of CI/CD processes</h1>
			<p>CI and CD are essential <a id="_idIndexMarker1010"/>practices in Node.js microservice development to streamline both the development and release processes. CI automates the integration of code changes into the main branch, ensuring each update is tested and validated through automated testing. This reduces the risk of integration issues and helps maintain code quality.</p>
			<p>In the CD pipeline, every successful build from CI is automatically deployed to production or staging environments. This automation significantly reduces the time between development <a id="_idIndexMarker1011"/>and release, allowing teams to quickly iterate on features and address issues.</p>
			<h2 id="_idParaDest-213"><a id="_idTextAnchor214"/>Understanding CI</h2>
			<p>CI is the practice of <a id="_idIndexMarker1012"/>frequently integrating code changes into a shared repository. This process is typically automated, with code being merged and tested multiple times a day. The main goals of CI are to detect integration issues early, reduce the chances of bugs reaching production, and ensure that new code is always compatible with the existing code base.</p>
			<p>As developers, we commit our code changes frequently (often several times a day) to a shared repository. This reduces the chances of conflicts and integration issues. When we have automated systems such as CI, after every commit, an automated build process is triggered. The code is compiled, and necessary dependencies are resolved. This ensures that the code base remains in a buildable state at all times. A successful build is an indication that the code base is in a healthy state and can proceed to the next steps, such as testing.</p>
			<p>Automated tests are executed after the build process. These tests can include unit tests, integration tests, and sometimes even end-to-end tests. The goal is to catch any bugs or issues early in the development cycle. If the build or tests fail, developers receive immediate feedback. This allows them to address issues quickly before they become bigger problems.</p>
			<p>Every time a new code change is committed, an automated build process is triggered. This process compiles the code, resolves dependencies, and packages the application if necessary.</p>
			<p>CI encourages the use of a single shared repository, which acts as the <em class="italic">single source of truth</em> for the project. This repository contains the most up-to-date and stable version of the code base, ensuring that all team members are working from the same foundation. This practice especially helps in maintaining consistency across the team.</p>
			<p>Now, let’s try to cover the benefits of CI:</p>
			<ul>
				<li><strong class="bold">Early bug detection</strong>: By<a id="_idIndexMarker1013"/> integrating code changes frequently and running automated tests with each integration, CI allows teams to detect bugs and issues early in the development process. This early detection reduces the cost and complexity of fixing bugs.</li>
				<li><strong class="bold">Reduced integration conflicts</strong>: Frequent integration of code changes means that conflicts are detected and resolved quickly.</li>
				<li><strong class="bold">Faster development cycles</strong>: Automated builds and tests free up developer time by eliminating the need for manual testing and build processes. This leads to faster development cycles and quicker delivery of new features and bug fixes.</li>
				<li><strong class="bold">Improved code quality</strong>: Automated testing as part of CI ensures that only code that passes a predefined set of tests is integrated into the mainline. This improves the overall quality and stability of the code base.</li>
				<li><strong class="bold">Enhanced collaboration</strong>: CI encourages collaboration among team members by making it easier to integrate and share code. This fosters a culture of transparency and collective ownership of the code base.</li>
				<li><strong class="bold">Continuous feedback</strong>: Continuous feedback loops provide developers with immediate information about the impact of their changes. This helps in maintaining high code <a id="_idIndexMarker1014"/>quality and reduces the time spent on debugging and troubleshooting.</li>
			</ul>
			<p>A CI workflow helps the team to catch bugs early, reduce integration challenges, and improve collaboration among team members. By automating the process of testing and building, CI ensures that the code base remains stable and ready for further development or deployment, promoting a faster and more reliable release cycle. Here is how it works:</p>
			<ol>
				<li><strong class="bold">Developer makes changes</strong>: Step one is about making changes. A developer writes new code or modifies<a id="_idIndexMarker1015"/> existing code on their local machine. Once the changes are complete, they commit the changes to the <strong class="bold">version control system</strong> (<strong class="bold">VCS</strong>), such<a id="_idIndexMarker1016"/> as Git.</li>
				<li><strong class="bold">Code is pushed to the repository</strong>: The developer pushes the committed changes to the shared repository. This triggers the CI process.</li>
				<li><strong class="bold">CI server detects changes</strong>: A CI server (e.g., Jenkins, Travis CI, CircleCI, or GitHub Actions) monitors the repository for new changes. When a change is detected, the CI server automatically triggers a build process.</li>
				<li><strong class="bold">Build is automated</strong>: The CI server pulls the latest code and initiates the build process. This involves compiling the code, resolving dependencies, and creating build artifacts if necessary. Tools such as Maven, Gradle, and Ant are used to automate the build process, manage dependencies, and compile the code.</li>
				<li><strong class="bold">Testing is automated</strong>: After a successful build, the CI server runs automated tests. These tests can include unit tests, integration tests, and other types of tests specific to the project. If the tests pass, the CI process continues. If any test fails, the process is halted, and the developer is notified of the failure. JUnit, NUnit, Mocha, Jest, and Selenium are examples of testing frameworks used to write and execute automated tests.</li>
				<li><strong class="bold">Feedback is given to developers</strong>: The CI server provides feedback to the developer, typically through notifications or a web interface. If the build or tests fail, the feedback includes details about the failure, helping the developer to quickly identify and fix the issue.</li>
				<li><strong class="bold">Changes are merged to mainline</strong>: Once the build and tests pass, the changes are merged into the mainline or master branch of the repository. This branch always represents the latest stable version of the code.</li>
				<li><strong class="bold">Builds are deployed</strong>: In some cases, successful builds might be automatically deployed to a staging environment for further testing. This can be part of a CD pipeline.</li>
			</ol>
			<p>The CI workflow is designed<a id="_idIndexMarker1017"/> to automate the integration of code changes, ensuring that new updates are quickly tested and validated before being merged into the mainline. By following this structured process, teams can catch issues early, reduce integration headaches, and deliver high-quality code more efficiently.</p>
			<p>Several tools and platforms play an important role in implementing CI in software development projects. These tools ensure that code integration, building, and testing processes are automated and efficient. VCSs such as Git and Subversion, manage and track changes in the code base, while CI servers such as Jenkins and GitHub Actions automate the build and test process. Build tools such as Maven and Gradle handle dependencies and compilation, and testing frameworks such as Mocha and Jest enable automated testing, ensuring <a id="_idIndexMarker1018"/>code quality at every stage of development.</p>
			<h2 id="_idParaDest-214"><a id="_idTextAnchor215"/>Understanding CD</h2>
			<p>CD is a software <a id="_idIndexMarker1019"/>engineering practice that enables teams to develop and release software in shorter, more frequent cycles, ensuring it can be deployed at any moment with confidence. As an evolution of CI, CD emphasizes not just building and testing code but also automating the deployment process to production environments, allowing for faster and more reliable releases.</p>
			<p>Here are the core principles of CD:</p>
			<ul>
				<li><strong class="bold">Automated testing</strong>: Every change <a id="_idIndexMarker1020"/>goes through an automated testing process to ensure that it is production-ready.</li>
				<li><strong class="bold">Automated deployment</strong>: The deployment process is automated, reducing the risks and errors associated with manual deployments.</li>
				<li><strong class="bold">Incremental updates</strong>: Software is released in small, manageable chunks rather than large, monolithic updates.</li>
				<li><strong class="bold">Environment parity</strong>: The testing, staging, and production environments are kept as similar as possible to avoid unexpected issues during deployment.</li>
				<li><strong class="bold">Continuous feedback</strong>: Constant monitoring and feedback from the production environment allow for quick detection and resolution of issues.</li>
			</ul>
			<p>That is great, but how do we apply it to our Node.js microservices? Applying CD to a Node.js microservice architecture involves several steps.</p>
			<h2 id="_idParaDest-215"><a id="_idTextAnchor216"/>Integrating CI/CD into microservices</h2>
			<p>Integrating CI/CD into <a id="_idIndexMarker1021"/>microservices ensures seamless, automated <a id="_idIndexMarker1022"/>deployment and testing of independent services, enabling faster development cycles and consistent, reliable updates. This approach enhances scalability and agility by streamlining the release process across distributed microservice architectures. Here is how we can integrate it in terms of Node.js microservices:</p>
			<ol>
				<li>First, you need to set up CI. You can use a CI <a id="_idIndexMarker1023"/>tool such as <strong class="bold">GitHub Actions</strong>, <strong class="bold">Jenkins</strong>, or another <a id="_idIndexMarker1024"/>tool to automate the process of building, testing, and packaging your Node.js microservices. Make sure that your CI pipeline runs unit tests, integration tests, and static code analysis on every commit.</li>
				<li>Use Docker to containerize each Node.js microservice. This ensures that the service runs consistently across different environments. Define a Docker file for each microservice to specify the dependencies, environment variables, and startup commands.</li>
				<li>The next step is writing automated tests for each microservice, covering unit tests, integration tests, and end-to-end tests. Use a test framework such as <strong class="bold">Mocha</strong>, <strong class="bold">Jest</strong>, or <strong class="bold">Supertest</strong> to <a id="_idIndexMarker1025"/>write<a id="_idIndexMarker1026"/> and <a id="_idIndexMarker1027"/>run your tests.</li>
				<li>In the end, ensure your CI pipeline runs these tests on every code change.</li>
				<li>The second huge step is to set up a CD pipeline. Extend your CI pipeline to deploy your microservices to a staging environment automatically. This can be done using the previously mentioned tools such as GitHub Actions, Jenkins, or other tools. Use a<a id="_idIndexMarker1028"/> deployment<a id="_idIndexMarker1029"/> tool such as <strong class="bold">Kubernetes</strong>, <strong class="bold">Docker Swarm</strong>, or <strong class="bold">AWS ECS</strong> (<strong class="bold">Elastic Container Service</strong>) to<a id="_idIndexMarker1030"/> manage your containers in the staging and production environments.</li>
				<li>Automate the deployment process by defining scripts that push the Docker images to a container registry (such as Docker Hub or AWS ECR) and update the services in the staging environment.</li>
				<li>Ensure that your local, testing, staging, and production environments are as similar as possible. This reduces the chances of environment-specific bugs.</li>
				<li>To manage different configurations for each environment, don’t forget to use environment variables.</li>
				<li>Implement monitoring and logging for your microservices using tools such as Prometheus, Grafana, ELK Stack, or Datadog. Set up alerts to notify your team of any issues in the production environment.</li>
				<li>Use deployment strategies such as canary releases or blue-green deployments to minimize the risk when deploying new versions of your microservices. This allows you to test new versions with a small percentage of users before rolling them out to the entire user base.</li>
				<li>Monitor the performance and logs of your services in production. Gather feedback from users and automatically roll back if a deployment causes issues.</li>
				<li>Continuously iterate on your processes and tools to improve your CD pipeline. By following these steps, you can effectively implement CD in your Node.js microservice development process, allowing for faster, safer, and more reliable deployments.</li>
			</ol>
			<p>CI and CD are closely related concepts in modern software development, but they focus on different stages of the software development life cycle. Here’s how they differ.</p>
			<p>The main focus of CI is integrating code changes from multiple developers into a shared repository, multiple <a id="_idIndexMarker1031"/>times a<a id="_idIndexMarker1032"/> day. It also ensures that the code is always in a deployable state by catching integration issues early. Hence, a CI pipeline focuses on integrating and testing code. It includes stages such as code linting, unit tests, integration tests, and sometimes code coverage reports.</p>
			<p>On the other hand, CD builds on CI by automating the delivery of code changes to various environments, such as staging and production, after they pass the CI pipeline. The primary goal of CD is to then ensure that code is always ready to be released to production, and releases can happen frequently and reliably. A CD pipeline extends the CI pipeline to include steps for deploying the code to various environments. This can include deployment scripts, environment configuration, and automated rollback mechanisms.</p>
			<p>In essence, CI is the <a id="_idIndexMarker1033"/>foundation, and CD extends it to cover the <a id="_idIndexMarker1034"/>deployment aspect, allowing for continuous delivery of new features and updates to end users.</p>
			<h1 id="_idParaDest-216"><a id="_idTextAnchor217"/>Working with Azure Cloud</h1>
			<p>The <strong class="bold">cloud</strong> refers to a<a id="_idIndexMarker1035"/> network of remote servers hosted on the internet, which are used to store, manage, and process data, rather than relying on a local server or personal computer. It allows businesses and individuals to access computing resources on-demand, such as storage, computing power, databases, and more, from anywhere in the world.</p>
			<p>Azure is Microsoft‘s cloud computing platform, providing a wide range of services such as virtual machines, databases, AI tools, and more. It enables developers and businesses to build, deploy, and manage applications through a global network of Microsoft-managed data centers. Azure offers flexibility, scalability, and cost-effectiveness, making it suitable for everything from small startups to large enterprises.</p>
			<p>Using <strong class="bold">Azure cloud</strong> provides several advantages, including seamless integration with Microsoft‘s ecosystem, high availability, and robust security features. It also supports hybrid cloud environments, allowing businesses to connect their on-premises infrastructure with the cloud. Azure’s global presence ensures low latency and compliance with regional regulations. Additionally, it offers advanced analytics, AI, and machine learning services, empowering businesses to innovate and stay competitive in the digital age.</p>
			<p>To make our example as simple as possible, we will work on the <code>Account</code> microservice from <a href="B09148_05.xhtml#_idTextAnchor074"><em class="italic">Chapter 5</em></a>. We will begin by obtaining all the resources necessary for our example.</p>
			<p>Our <code>Account</code> service stores data in the Postgres database. We will deploy our application to Azure, but you can use any cloud infrastructure you want.</p>
			<p>First, we need to create an <strong class="bold">Azure Resource Group</strong> to deploy our application. We can do that with the <a id="_idIndexMarker1036"/>following steps:</p>
			<ol>
				<li>First, let’s create a Postgres resource to store data on Azure. Go to <a href="http://portal.azure.com">http://portal.azure.com</a> and register to get a free account if you haven’t registered yet. Using a free subscription, you can get $200 of free credit toward Azure products and services, plus twelve months of popular free services.</li>
				<li>The next step is to set up Azure resources using the Azure portal and create a resource group:<ol><li class="upper-roman">Log in to the Azure portal.</li><li class="upper-roman">In the left sidebar, select <strong class="bold">Resource Groups</strong>.</li><li class="upper-roman">Click <strong class="bold">Create</strong>.</li><li class="upper-roman">Fill in the <a id="_idIndexMarker1037"/>necessary details, such as the subscription, resource group name, and region, then click <strong class="bold">Review + create</strong> (<em class="italic">Figure 13</em><em class="italic">.1</em>):</li></ol></li>
			</ol>
			<div><div><img alt="Figure 13.1: Creating a resource group in Azure" src="img/B09148_13_001.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.1: Creating a resource group in Azure</p>
			<ol>
				<li value="3">The next step is to create an App Service plan:<ol><li class="upper-roman">In the Azure portal, search for <code>App Service plans</code> in the search bar and select the top result.</li><li class="upper-roman">Click <strong class="bold">Create</strong>.</li><li class="upper-roman">Choose your subscription, select the resource group you just created, and enter a name for your App Service plan.</li><li class="upper-roman">Under <strong class="bold">Operating System</strong>, select <strong class="bold">Linux</strong>.</li><li class="upper-roman">Choose a pricing tier (e.g., <strong class="bold">B1</strong> for a basic plan).</li><li class="upper-roman">Click <strong class="bold">Review + </strong><strong class="bold">create</strong>.</li></ol><p class="list-inset">Creating an App Service plan in Azure is an essential step when deploying web apps, APIs, and other workloads using Azure App Services. The App Service plan defines the underlying infrastructure that powers your web app, API, or function app. It determines how your application is hosted, including the amount of CPU (processing power), memory (RAM), storage (disk space), and networking capacity it uses.</p><p class="list-inset">By creating an App Service plan, you specify the resources and capacity needed to run your application, ensuring it has the necessary performance to handle the expected load. It<a id="_idIndexMarker1038"/> directly influences the cost of running your application in Azure by giving the following two options:</p><ul><li><strong class="bold">Pricing tier</strong>: The plan you choose determines the pricing tier, which affects the cost based on the resources allocated. Azure offers various pricing tiers, from free and shared tiers for small apps to premium tiers for high-performance, production-grade apps.</li><li><strong class="bold">Scaling options</strong>: An App Service plan also defines the scaling options for your application. You can scale up (increase the size of the instance) or scale out (increase the number of instances) based on your application’s needs. Different pricing tiers offer different scaling capabilities.</li></ul><p class="list-inset"><em class="italic">Figure 13</em><em class="italic">.2</em> shows how to create an App Service plan in Azure:</p></li>
			</ol>
			<div><div><img alt="Figure 13.2: Creating an App Service Plan in Azure" src="img/B09148_13_002.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.2: Creating an App Service Plan in Azure</p>
			<ol>
				<li value="4">The next<a id="_idIndexMarker1039"/> step is creating a web app:<ol><li class="upper-roman">In the Azure portal, search for <code>App Services</code> and select the top result.</li><li class="upper-roman">Click <strong class="bold">Create</strong> and select <strong class="bold">Web App</strong>.</li><li class="upper-roman">Choose your subscription, select your resource group, and enter a name for your web app. Make sure you have selected a unique name for your web app.</li><li class="upper-roman">For <strong class="bold">Publish</strong>, select <strong class="bold">Code</strong>.</li><li class="upper-roman">For the <strong class="bold">Runtime stack</strong>, select <strong class="bold">Node 20 LTS</strong>. (Select the node version you think is better for your needs).</li><li class="upper-roman">For <strong class="bold">Operating System</strong>, choose <strong class="bold">Linux</strong>.</li><li class="upper-roman">Under <strong class="bold">Region</strong>, select the region closest to you or your users.</li><li class="upper-roman">Under <strong class="bold">App Service Plan</strong>, select the plan you created earlier.</li><li class="upper-roman">Click <strong class="bold">Review + create</strong> and then <strong class="bold">Create</strong>. See <em class="italic">Figure 13</em><em class="italic">.3</em>:</li></ol></li>
			</ol>
			<div><div><img alt="Figure 13.3: Creating a web app in Azure" src="img/B09148_13_003.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.3: Creating a web app in Azure</p>
			<ol>
				<li value="5">Next, create<a id="_idIndexMarker1040"/> an Azure Cosmos DB for the MongoDB API:<ol><li class="upper-roman">In the Azure portal, search for <code>Azure Cosmos DB</code> and select <strong class="bold">Create</strong>.</li><li class="upper-roman">Azure will ask you to select the type of resource, which will either be  a requesting <strong class="bold">unit database account</strong> or <strong class="bold">vCore cluster</strong>. vCore Cluster is a recommended resource by Microsoft.</li><li class="upper-roman">Under <strong class="bold">API</strong>, choose <strong class="bold">Azure Cosmos DB </strong><strong class="bold">for MongoDB</strong>.</li><li class="upper-roman">Enter your <strong class="bold">Subscription</strong>, <strong class="bold">Resource Group</strong>, <strong class="bold">Account Name</strong>, and other necessary details.</li><li class="upper-roman">Click <strong class="bold">Review + create</strong> and <a id="_idIndexMarker1041"/>then <strong class="bold">Create</strong>:</li></ol></li>
			</ol>
			<div><div><img alt="Figure 13.4: Selecting Azure Cosmos DB for MongoDB" src="img/B09148_13_004.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.4: Selecting Azure Cosmos DB for MongoDB</p>
			<p class="list-inset">You can see the Azure Cosmos DB account creation page in the following figure:</p>
			<div><div><img alt="Figure 13.5: The Azure Cosmos DB account creation page" src="img/B09148_13_005.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.5: The Azure Cosmos DB account creation page</p>
			<ol>
				<li value="6">Finally, let us <a id="_idIndexMarker1042"/>obtain a MongoDB connection string:<ol><li class="upper-roman">Once the Cosmos DB account is created, go to the <strong class="bold">Overview</strong> page.</li><li class="upper-roman">Click on <strong class="bold">Connection String</strong> under the <strong class="bold">Settings</strong> section.</li><li class="upper-roman">Click the eye icon.</li><li class="upper-roman">Copy <strong class="bold">Primary </strong><strong class="bold">Connection String</strong>:</li></ol></li>
			</ol>
			<div><div><img alt="Figure 13.6:﻿ Connection string page in Azure" src="img/B09148_13_006.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.6: Connection string page in Azure</p>
			<p class="list-inset">We’re done with resource obtaining. It is time for configuration.</p>
			<ol>
				<li value="7">Now, let’s <a id="_idIndexMarker1043"/>configure the Azure web app to use MongoDB. For that, navigate to your web app:<ol><li class="upper-roman">In the Azure portal, go to <code>MONGODB_URL</code>) and <strong class="bold">Value</strong> (paste the MongoDB connection string you copied earlier).</li><li class="upper-roman">Click <strong class="bold">OK</strong> and then <strong class="bold">Save</strong>.</li></ol></li>
			</ol>
			<p>Finally, it’s time to prepare your Node.js application. Ensure your Node.js application is set up to read the MongoDB connection string from environment variables. Here are the steps to achieve it:</p>
			<ol>
				<li>Go to the <code>src/config/config.js</code> file and change the <code>createConfig</code> function<a id="_idIndexMarker1044"/> like so:<pre class="source-code">
 function createConfig(configPath) {
        dotenv.config({ path: configPath });
        const { value: envVars, error } = envVarsSchema
            .prefs({ errors: { label: 'key' } })
            .validate({
                PORT: process.env.PORT || dotenv
                      .config({ path: configPath })
                      .parsed.PORT,
                MONGODB_URL: process.env.MONGODB_URL
                      || dotenv.config({
                      path: configPath }).parsed
                      .MONGODB_URL
            });
        if (error) {
            throw new Error(`Config validation error:
              ${error.message}`);
        }
        return {
            port: envVars.PORT,
            mongo: {
                url: envVars.MONGODB_URL,
            } }; }</pre></li>				<li>When we run our Node.js application, it automatically connects to a port number equal to <code>3001</code> (depending on what you encoded in the <code>.env</code> file). We updated the <code>.env</code> file by default to use <code>PORT=443</code>. Here is what it looks like:<pre class="source-code">
PORT=443
MONGODB_URL=mongodb://localhost:27017/account-microservice</pre></li>				<li>We also applied minor changes to the <code>src/index.js</code> file to support the <code>winston</code> library <a id="_idIndexMarker1045"/>and to use the port from the process:<pre class="source-code">
async function execute() {
    logger.info('preparing account service ...');
    const configPath = path.join(__dirname,
      '../configs/.env');
    const appConfig = createConfig(configPath);
    logger.info({configPath:configPath});
    await db.connect(appConfig);
    const port = process.env.PORT || appConfig.port;
    const server = app.listen(port, () =&gt; {
        logger.info('account service started',
        { port: port });
    });
    const closeServer = () =&gt; {
        if (server) {
            server.close(() =&gt; {
                logger.error('server closed');
                process.exit(1);
            });
        } else {
            process.exit(1);
        }  };</pre><p class="list-inset">As you might guess, for both previous examples, we used <code>process.env</code>. Using <code>process.env.PORT</code> and <code>process.env.MONGODB_URL</code> in Node.js applications is a best practice for managing environment-specific configurations.</p><p class="list-inset">Node.js applications often need to run in different environments (development, testing, staging, production), each with its own set of configurations. Using environment variables allows you to customize behavior based on the environment without changing the code. Now, let’s take a closer look at the environment variables used in our code:</p><ul><li><code>process.env.PORT</code> is used to define the port number on which the Node.js <a id="_idIndexMarker1046"/>application will listen for incoming requests. By using an environment variable for the port, you can easily run the application on different ports depending on the environment. For example, in a development environment, you might want to run it on port <code>3000</code>, while in production, the application might need to run on a port assigned by a hosting provider (e.g., Azure, Heroku). Cloud providers often assign dynamic ports to applications. By using <code>process.env.PORT</code>, your application can adapt to whatever port is assigned at runtime.</li><li><code>process.env.MONGODB_URL</code>, on the other hand, is used to define the connection string for your MongoDB database. Storing sensitive information such as database connection strings in environment variables keeps them out of your source code, which is a security best practice. This prevents accidental exposure in VCSs (e.g., Git). Different environments may use different databases or database servers. For example, a development environment might use a local MongoDB instance, while production uses a managed MongoDB service such as MongoDB Atlas. By using <code>process.env.MONGODB_URL</code>, you can easily switch between these without changing your code.</li></ul></li>				<li>After successful deployment, Azure should run your application. That is why you need to update the <code>package.json</code> file to have the <code>start</code> script, like the following:<pre class="source-code">
"scripts": {
    "start": "node src/index.js",
   ...other commands }</pre></li>			</ol>
			<p>But how about the package installation process? As you know, we don’t publish <code>node_modules</code>, but it should be on the server to run your application properly. To handle node module installation and execute the start command from <code>package.json</code>, you <a id="_idIndexMarker1047"/>can follow the following steps:</p>
			<ol>
				<li>Go to <strong class="bold">App Services</strong> from the Azure portal.</li>
				<li>Select your web app.</li>
				<li>Navigate to <strong class="bold">Settings</strong>.</li>
				<li>Select <strong class="bold">Configuration</strong>.</li>
				<li>Go to <strong class="bold">General Settings</strong>.</li>
				<li>Go to <code>npm install &amp;&amp; </code><code>npm start</code>:</li>
			</ol>
			<div><div><img alt="Figure 13.7:﻿ Startup command for an Azure web app" src="img/B09148_13_007.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.7: Startup command for an Azure web app</p>
			<p>Of course, this is not the only option for running Node.js applications properly but for this example, it is <a id="_idIndexMarker1048"/>more than enough.</p>
			<p>Now, everything is ready. We can implement our pipeline using GitHub Actions.</p>
			<h1 id="_idParaDest-217"><a id="_idTextAnchor218"/>Working with GitHub Actions</h1>
			<p><strong class="bold">GitHub Actions</strong> is a powerful<a id="_idIndexMarker1049"/> feature of GitHub that allows you to automate, customize, and execute software development workflows directly in your GitHub repository. It’s designed to help you build, test, and deploy your code right from GitHub. GitHub Actions is a tool that helps you automate tasks within your software development life cycle. For our case, we’ll create a workflow that automatically deploys your Node.js microservice to Azure whenever you push changes to the main branch.</p>
			<p>First, create an account if you haven’t yet. After account creation, create a repository that will store your source code. Next, let’s look at some key features of GitHub Actions:</p>
			<ul>
				<li><strong class="bold">Automation of workflows</strong>: GitHub<a id="_idIndexMarker1050"/> Actions enables you to automate tasks such as running tests, building applications, deploying to cloud services, and more whenever specific events occur in your repository (e.g., a push to a branch, a pull request, or the creation of an issue). You can also use GitHub Actions to run linting tools or static analysis on your code, ensuring that code quality standards are maintained.</li>
				<li><code>.github/workflows/</code> directory of your repository. These files describe the automated processes you want to run.</li>
				<li><strong class="bold">Event-driven</strong>: Actions can be triggered by various GitHub events, such as pushes, pull requests, issue creation, or on a scheduled basis. This flexibility allows you to create workflows that are finely tuned to your development process.</li>
				<li><strong class="bold">Built-in CI/CD</strong>: GitHub Actions provides built-in support for CI and CD. You can use it to automatically test your code and deploy it to production or a cloud service such as AWS, Azure, or Heroku after every commit.</li>
				<li><strong class="bold">Reusable actions</strong>: You can reuse actions created by the community or share your own actions across projects. GitHub has a marketplace where you can find actions for various tasks such as setting up languages, deploying to cloud services, and more.</li>
				<li><strong class="bold">Secrets management</strong>: You can securely manage and use sensitive information such as API keys, tokens, and other credentials in your workflows without exposing them in your code.</li>
				<li><strong class="bold">Scheduling tasks</strong>: You can use GitHub Actions to run scripts or maintenance tasks, such as nightly <a id="_idIndexMarker1051"/>builds or database backups, on a schedule.</li>
			</ul>
			<p>GitHub Actions integrates seamlessly with other GitHub features, such as <em class="italic">Issues</em>, <em class="italic">Pull Requests</em>, and <em class="italic">Packages</em>, making it easy to create workflows that encompass the full development <a id="_idIndexMarker1052"/>life cycle.</p>
			<p>Now let’s look at Secrets in GitHub Actions.</p>
			<h2 id="_idParaDest-218"><a id="_idTextAnchor219"/>Understanding Secrets</h2>
			<p><strong class="bold">Secrets</strong> in GitHub <a id="_idIndexMarker1053"/>Actions are encrypted environment variables that you<a id="_idIndexMarker1054"/> use in your workflows. They are stored securely and can be accessed within your workflows without exposing sensitive information.</p>
			<p>To securely pass your Azure credentials (such as the publish profile) to GitHub Actions, you need to add them as <strong class="bold">Secrets</strong>. Here is how you can do it:</p>
			<ol>
				<li>Go to the Azure portal and navigate to your web app.</li>
				<li>On the web app’s <strong class="bold">Overview</strong> page, look for the <strong class="bold">Get Publish Profile</strong> button and download the publish profile file. It’s an XML file that contains the credentials your GitHub Actions workflow will use to deploy the app. Don’t forget to change <strong class="bold">Platform settings</strong> from your Azure web app’s <strong class="bold">Settings-Configuration</strong> tab.</li>
				<li>Once you do it, you will be able to download the publish profile (<em class="italic">Figure 13</em><em class="italic">.8</em>).</li>
				<li>Now go to the <code>&lt;web_app_name&gt;.PublishSettings</code> (it is <code>account-microservice-webapp.PublishSettings</code> in our case).</li>
			</ol>
			<p>Providing an Azure publish profile to GitHub Actions is essential for automating the deployment of your application to Azure. The publish profile contains credentials that GitHub Actions uses to authenticate and authorize the deployment to your Azure resources. This ensures that only authorized processes can deploy your application.</p>
			<p>It also includes all the necessary settings for deploying your application to a specific Azure App Service or other resources. It simplifies the configuration, avoiding manually defining all the deployment details in your workflow.</p>
			<p>Using a publish profile in GitHub Actions allows you to securely store and manage the credentials as secrets within your GitHub repository. This prevents exposing sensitive information in your<a id="_idIndexMarker1055"/> workflow files. Here is what platform settings should look like <a id="_idIndexMarker1056"/>to download the publish profile:</p>
			<div><div><img alt="Figure 13.8:﻿ Platform settings to download the publish profile" src="img/B09148_13_008.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.8: Platform settings to download the publish profile</p>
			<p>Let’s create Secrets in GitHub:</p>
			<ol>
				<li>Go to your GitHub repository.</li>
				<li>Navigate to <strong class="bold">Settings</strong> | <strong class="bold">Secrets</strong> | <strong class="bold">Actions</strong>.</li>
				<li>Add the following secrets:<ul><li><code>AZURE_WEBAPP_PUBLISH_PROFILE</code>: The entire contents of the publish profile from Azure (<em class="italic">Figure 13.9</em>).</li><li><code>MONGODB_URL</code>: At this point, you should paste the MongoDB connection string that you copied earlier. If you have not yet retrieved it, please do so now before<a id="_idIndexMarker1057"/> continuing. Here <a id="_idIndexMarker1058"/>is how we can do it:</li></ul></li>
			</ol>
			<div><div><img alt="Figure 13.9:﻿ Adding the Azure web app’s publish profile" src="img/B09148_13_009.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.9: Adding the Azure web app’s publish profile</p>
			<p>Using Secrets is crucial because it prevents sensitive data from being exposed in your repository’s code or logs. Only authorized workflows can access these secrets.</p>
			<p>We have now<a id="_idIndexMarker1059"/> provided <a id="_idIndexMarker1060"/>all the secret information to GitHub, so let’s focus on building a simple pipeline using GitHub Actions.</p>
			<h2 id="_idParaDest-219"><a id="_idTextAnchor220"/>Building a pipeline</h2>
			<p>While GitHub Actions<a id="_idIndexMarker1061"/> doesn’t explicitly use the term <strong class="bold">pipeline</strong> in its <a id="_idIndexMarker1062"/>documentation, a pipeline is a broader concept that represents the sequence of processes that code goes through from development to production. In many CI/CD tools, a pipeline typically consists of multiple stages (such as build, test, and deploy) that are executed in a specific order.</p>
			<p>A <code>.github/workflows/</code> directory of a repository. Workflows are triggered by events, such as pushes to the repository, pull requests, or scheduled events. Each workflow can have multiple jobs that run in parallel or sequentially, and each job can have multiple steps that execute commands or actions.</p>
			<p>A workflow is defined in a <code>.yml</code> file. Here is how we define it:</p>
			<ol>
				<li>To create this file, you should open your web browser and go to your GitHub repository. Inside your repository, click on the <strong class="bold">Add file</strong> button, then choose <strong class="bold">Create </strong><strong class="bold">new file</strong>.</li>
				<li>Name the file <code>.github/workflows/azure-deploy.yml</code>. This will create the necessary directory structure and file. Commit the <code>azure-deploy.yml</code> file and push it to your GitHub repository.</li>
				<li>The <code>azure-deploy.yml</code> file consists of multiple steps. For a more complete example, check our GitHub repository (<code>Ch13/.github/workflows/azure-deploy.yml</code>). Here is our first step:<pre class="source-code">
name: CI/CD Pipeline
on:
  push:
    branches:
      - main  # The workflow will trigger on pushes to the main branch</pre><p class="list-inset">The GitHub Actions workflow file, named <code>CI/CD Pipeline</code>, is set up to automatically trigger whenever there is a push to the <code>main</code> branch of the repository. This means that any changes committed and pushed to the <code>main</code> branch will activate the defined workflow. The <code>on: push:</code> section specifies the event that starts the workflow – in this case, a push event to the <code>main</code> branch. This setup is commonly used for CI/CD, ensuring that updates to the <code>main</code> branch automatically go through the build, test, and deployment processes defined in the workflow.</p></li>				<li>Let’s continue by<a id="_idIndexMarker1064"/> discussing the next lines in our <a id="_idIndexMarker1065"/>workflow file:<pre class="source-code">
jobs:
  security-scan:
    name: Run Security Scan
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '20'
    - name: Install dependencies
      run: npm install
    - name: Run npm audit
      run: npm audit --audit-level=high</pre><p class="list-inset">This part of the GitHub Actions workflow defines a job named <code>security-scan</code>, which is responsible for running a security scan on your code base. The job will execute on the latest version of Ubuntu, as specified by <code>runs-on: ubuntu-latest</code>.</p><p class="list-inset">Within this job, several steps are outlined. The first step, <code>Checkout code</code>, uses the <code>actions/checkout@v3</code> action to clone the repository’s code into the workflow’s environment. Next, the <code>Set up Node.js</code> step sets up Node.js version 20 in the environment using the <code>actions/setup-node@v3</code> action. After the environment is ready, the <code>Install dependencies</code> step runs <code>npm install</code> to install all required Node.js packages. Finally, the <code>Run npm audit</code> step executes the <code>npm audit --audit-level=high</code> command, which checks for security vulnerabilities in the installed packages, focusing on those with a high severity level. This job ensures that your application is scanned for critical security issues as part of the CI/CD pipeline.</p></li>				<li>The following code of the GitHub Actions workflow defines a job called <code>check-dependencies</code>, which is designed to check whether any dependencies in your project are outdated. The <a id="_idIndexMarker1066"/>job will run on the latest version <a id="_idIndexMarker1067"/>of Ubuntu, as indicated by <code>runs-on: ubuntu-latest</code>:<pre class="source-code">
check-dependencies:
    name: Check Dependencies
    runs-on: ubuntu-latest
    needs: security-scan
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    - name: Install dependencies
      run: npm install
    - name: Check for outdated dependencies
      run: npm outdated</pre><p class="list-inset">The <code>needs: security-scan</code> line specifies that this job will only run after the <code>security-scan</code> job has successfully completed. This creates a dependency between the two jobs, ensuring that the security scan must pass before checking for outdated dependencies.</p><p class="list-inset">The job contains several steps. First, the <code>Checkout code</code> step uses the <code>actions/checkout@v3</code> action to clone the repository’s code into the environment. Then, the <code>Install dependencies</code> step runs <code>npm install</code> to install all the necessary Node.js packages for the project. Finally, the <code>Check for outdated dependencies</code> step runs <code>npm outdated</code>, which lists any dependencies that have newer versions available. This job helps maintain the health of your project by ensuring that you are aware of any outdated packages that might need updating.</p></li>				<li>The following part of the GitHub Actions workflow defines a job named <code>test</code>, which is<a id="_idIndexMarker1068"/> responsible for running tests on your code base. The<a id="_idIndexMarker1069"/> job runs on the latest version of Ubuntu, as specified by <code>runs-on: ubuntu-latest</code>:<pre class="source-code">
test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: check-dependencies
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '20'
    - name: Install dependencies
      run: npm install
    - name: Run tests
      run: npm test</pre><p class="list-inset">The <code>needs: check-dependencies</code> line indicates that this job will only start after the <code>check-dependencies</code> job has successfully completed. This ensures that all dependencies are up-to-date before tests are run, which is important for ensuring consistency and reliability in your testing process.</p><p class="list-inset">The job consists of several steps. First, the <code>Checkout code</code> step uses the <code>actions/checkout@v3</code> action to clone the repository’s code into the workflow environment. Then, the <code>Set up Node.js</code> step configures Node.js version 20 in the environment using the <code>actions/setup-node@v3</code> action. Following this, the <code>Install dependencies</code> step runs <code>npm install</code> to install the necessary packages for the project. Finally, the <code>Run tests</code> step executes the <code>npm test</code> command, which runs the test suite defined in your project. This job ensures that your code is tested in a controlled environment, catching any issues before changes are merged or deployed.</p></li>				<li>The following part <a id="_idIndexMarker1070"/>of the workflow is responsible for<a id="_idIndexMarker1071"/> deploying your application to the Azure web app after the tests have been completed. The job runs on an Ubuntu-based virtual machine provided by GitHub Actions. Before deployment, the workflow checks out the latest version of your code to ensure that the most recent changes are included:<pre class="source-code">
deploy:
   name: Deploy to Azure Web App
   runs-on: ubuntu-latest
   needs: test  # Run this job after testing succeeds
   steps:
   - name: Checkout code
     uses: actions/checkout@v3
   - name: Clean up unnecessary files
     run: |
       rm -rf .git
       rm -rf .github
       rm -rf _actions
       rm -rf _PipelineMapping
       rm -rf _temp
   - name: Deploy to Azure Web App
     uses: azure/webapps-deploy@v3
     with:
       app-name: 'account-microservice-webapp'  # Matches the "msdeploySite" in your publish profile
       publish-profile: ${{ secrets.AZURE_WEBAPP_PUBLISH_PROFILE }}  # Ensure this secret contains the publish profile XML content
       package: ${{ github.workspace }}</pre></li>				<li>In preparation for deployment, the workflow cleans up unnecessary files and directories, such <a id="_idIndexMarker1072"/>as the <code>.git</code> folder (which contains<a id="_idIndexMarker1073"/> the repository’s Git history), the <code>.github</code> folder (used for GitHub-specific configurations), and other temporary or internal folders that aren’t needed in the deployed application. This cleanup helps reduce the deployment package size and eliminates any files that aren’t required for the application to run.</li>
				<li>Finally, the workflow uses the <code>azure/webapps-deploy@v3</code> action to deploy the application to the specified Azure web app. The <code>app-name</code> configuration is set to match the site name in your Azure publish profile, and the <code>publish-profile</code> secret contains the necessary credentials. The package to be deployed is set to the entire workspace, ensuring that the cleaned-up code is what gets deployed.</li>
			</ol>
			<p>Once you push your changes, GitHub Actions will automatically trigger the workflow. Monitor the deployment process in the <strong class="bold">Actions</strong> tab of your GitHub repository:</p>
			<div><div><img alt="Figure 13.10:﻿ GitHub Actions workflow" src="img/B09148_13_010.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.10: GitHub Actions workflow</p>
			<p>Here is <a id="_idIndexMarker1074"/>what<a id="_idIndexMarker1075"/> success deployment logs look like:</p>
			<pre class="source-code">
{
  id: '77ef5e3e-161d-4b4c-afb2-e44d537ec921',
   *******
  is_temp: false,
  is_readonly: true,
  url: 'https://account-microservice-webapp.scm.azurewebsites.net/api/deployments/77ef5e3e-161d-4b4c-afb2-e44d537ec921',
  log_url: 'https://account-microservice-webapp.scm.azurewebsites.net/api/deployments/77ef5e3e-161d-4b4c-afb2-e44d537ec921/log',
  site_name: 'account-microservice-webapp',
  build_summary: { errors: [], warnings: [] }}
Deploy logs can be viewed at https://account-microservice-webapp.scm.azurewebsites.net/api/deployments/77ef5e3e-161d-4b4c-afb2-e44d537ec921/log
Successfully deployed web package to App Service.
App Service Application URL: https://account-microservice-webapp.azurewebsites.net</pre>			<p>Once deployment succeeds, you can check the deployed files using a simple FTPS connection. To connect to your server using an FTP client, you can use any FTP client tools you want. We use FileZilla, which is free and easy to use. You can download it from <a href="https://filezilla-project.org/">https://filezilla-project.org/</a>.</p>
			<p>To find FTP <a id="_idIndexMarker1076"/>credentials for <a id="_idIndexMarker1077"/>your server, follow these steps:</p>
			<ol>
				<li>Go to the Azure portal.</li>
				<li>Select <strong class="bold">App Services</strong>.</li>
				<li>Find your web app.</li>
				<li>Got to <strong class="bold">Deployment</strong> | <strong class="bold">Deployment Center</strong></li>
				<li>Select the <strong class="bold">FTPS credentials</strong> tab. See <em class="italic">Figure 13</em><em class="italic">.11</em>:</li>
			</ol>
			<div><div><img alt="Figure 13.11:﻿ FTPS credentials tab for an Azure web app" src="img/B09148_13_011.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.11: FTPS credentials tab for an Azure web app</p>
			<p>Now you can use these credentials to connect to the server. Here is what it looks like after connecting and navigating to the <code>wwwroot</code> folder:</p>
			<div><div><img alt="Figure 13.12:﻿ FTP view of the deployed repository" src="img/B09148_13_012.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.12: FTP view of the deployed repository</p>
			<p>Now we’re ready to test whether things are working or not. As you might guess, after investigating the <a id="_idIndexMarker1078"/>Account microservice’s source code, we added<a id="_idIndexMarker1079"/> a simple middleware to <code>app.js</code>:</p>
			<pre class="source-code">
..............
// Define a route for the welcome page
app.get('/welcome', (req, res) =&gt; {
    res.send('&lt;h1&gt;Welcome to Express.js Application!&lt;/h1&gt;');
});
..............</pre>			<p>Just go to the Azure portal, select your web app, and in the <strong class="bold">Overview</strong> section, you will find the default domain:</p>
			<div><div><img alt="Figure 13.13:﻿ Domains section for an Azure web app" src="img/B09148_13_013.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.13: Domains section for an Azure web app</p>
			<p>Open any browser and type <code>&lt;Default_domain&gt;/welcome</code> as the URL:</p>
			<div><div><img alt="Figure 13.14:﻿ Welcome page for the deployed Node.js application" src="img/B09148_13_014.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.14: Welcome page for the deployed Node.js application</p>
			<p>To test whether it is <a id="_idIndexMarker1080"/>possible to connect to MongoDB and create <a id="_idIndexMarker1081"/>account information, follow these steps:</p>
			<ol>
				<li>Open Postman.</li>
				<li>Click on the <strong class="bold">+</strong> button to create a new tab.</li>
				<li>Select <code>&lt;default_domain&gt;/v1/accounts</code> template (it is <code>https://account-microservice-webapp.azurewebsites.net/v1/accounts</code> for us).</li>
				<li>Go to the <strong class="bold">Body</strong> section and select <strong class="bold">raw</strong> | <strong class="bold">Json</strong>.</li>
				<li>Paste your payload to create an account and click <strong class="bold">Send</strong>.</li>
			</ol>
			<p>Here is what it looks like for us:</p>
			<div><div><img alt="Figure 13.15:﻿ Creating an account using Postman" src="img/B09148_13_015.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.15: Creating an account using Postman</p>
			<p>To test whether it is<a id="_idIndexMarker1082"/> possible to retrieve account information, follow <a id="_idIndexMarker1083"/>these steps:</p>
			<ol>
				<li>Open Postman.</li>
				<li>Click on the <strong class="bold">+</strong> button to create a new tab.</li>
				<li>Select <code>&lt;default_domain&gt;/v1/accounts</code> template (it is <code>https://account-microservice-webapp.azurewebsites.net/v1/accounts</code> for us).</li>
				<li>Click <strong class="bold">Send</strong>.</li>
			</ol>
			<p>Here is what it looks like for us:</p>
			<div><div><img alt="Figure 13.16:﻿ Retrieving account information" src="img/B09148_13_016.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 13.16: Retrieving account information</p>
			<p>In this section, we explored the process of deploying an application to Azure and testing its functionalities. We walked through how to verify that everything is working as expected using Postman, ensuring your application is ready for production environments. Now you <a id="_idIndexMarker1084"/>have a solid understanding of how<a id="_idIndexMarker1085"/> to deploy and validate your microservice in the cloud.</p>
			<h1 id="_idParaDest-220"><a id="_idTextAnchor221"/>Summary</h1>
			<p>In this chapter, we embarked on a comprehensive exploration of CI/CD processes, emphasizing their critical role in modern software development. We began by understanding the fundamentals of CI and CD and how they streamline the process of integrating and deploying code changes.</p>
			<p>Our journey continued with an in-depth look at working with Azure Cloud, where we discussed how to leverage its robust infrastructure for deploying and managing applications. We then delved into GitHub Actions, a powerful tool for automating workflows, enabling us to build, test, and deploy our code efficiently.</p>
			<p>Most of the chapter was dedicated to building a CI/CD pipeline. We walked through the steps necessary to create a seamless and automated pipeline, ensuring that our applications are always in a state ready for deployment.</p>
			<p>In this book, we have covered everything you need to start building microservices with JavaScript. From designing the basic structure to deploying and monitoring your services, each chapter has given you practical steps and knowledge to help you create flexible and efficient applications. Now, you’re ready to take on real projects using microservices, which can make your systems easier to scale, update, and manage.</p>
			<p>However, remember that microservices are not a silver bullet. The best design depends on many factors, including the size of your project, team structure, and business needs. As you continue learning and practicing, stay curious and keep in mind that technology is always changing. Enjoy your journey in the world of microservices!</p>
			<p>Keep going and may you code for a lifetime. Until we meet again.</p>
		</div>
	</body></html>