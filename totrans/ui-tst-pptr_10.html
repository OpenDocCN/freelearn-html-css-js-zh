<html><head></head><body>
		<div><h1 id="_idParaDest-153"><em class="italic"><a id="_idTextAnchor167"/>Chapter 10</em>: Evaluating and Improving the Performance of a Website</h1>
			<p>Many things can make a website a success or a complete failure. In <a href="B16113_09_Final_SK_ePub.xhtml#_idTextAnchor156"><em class="italic">Chapter 9</em></a>, <em class="italic">Scraping tools</em>, we talked about a real estate website that can't be launched without content. On many websites, content is the number-one feature. <a href="http://Amazon.com">Amazon.com</a> could be the best website in the world, but if it doesn't have the book you are looking for, you will go somewhere else. </p>
			<p>For other websites, functionality is the number-one feature. A website such as <a href="http://Trello.com">Trello.com</a> is a success because you can move cards from one list to another easily and intuitively. But functionality is not only about rich web pages. If we go back to the Amazon website, the website is pretty straightforward. It doesn't use any cool UI framework, but it has a great search and well-planned navigation. </p>
			<p>The website design can also be considered a feature. While some websites such as <a href="http://www.google.com">www.google.com</a> might look simple and focused on delivering content, you can see that other websites, such as <a href="http://www.apple.com">www.apple.com</a>, invest a lot in design. You can see that design is the number-one feature on <a href="http://www.apple.com">www.apple.com</a>.</p>
			<p>But most websites will share the same feature: <strong class="bold">speed</strong>. <strong class="bold">Speed is a feature</strong>. When planning a website, the stakeholders might argue whether they want to invest in a rich client or not. They can discuss whether they should hire a designer or not. But if you ask about the speed, there is only one answer: "We need the website to be fast."</p>
			<p>In this chapter, we will learn how to use performance metrics to solve several issues that can arise with websites. We will look at functionality, speed, and how we can measure these key performance points with Google Lighthouse.</p>
			<p>We will cover the following topics in this chapter:</p>
			<ul>
				<li>The issue of performance</li>
				<li>Getting started with Google Lighthouse</li>
				<li>Tracing pages</li>
				<li>Analyzing code coverage</li>
			</ul>
			<p>By the end of this chapter, you will be able to implement performance metrics on your website and help the development team improve the website's performance.</p>
			<p>Let's get started.</p>
			<h1 id="_idParaDest-154"><a id="_idTextAnchor168"/>Technical requirements</h1>
			<p>You will find all the code of this chapter on the GitHub repository (<a href="https://github.com/PacktPublishing/UI-Testing-with-Puppeteer">https://github.com/PacktPublishing/UI-Testing-with-Puppeteer</a>) under the <code>Chapter10</code> directory. Remember to run <code>npm install</code> on that directory, and then go to the <code>Chapter10/vuejs-firebase-shopping-cart</code> directory and run <code>npm install</code> again.</p>
			<h1 id="_idParaDest-155"><a id="_idTextAnchor169"/>The Issue of Performance</h1>
			<p>As I mentioned<a id="_idIndexMarker520"/> in the introduction, speed is a feature. You might be asked to make a simple website, but no one, ever, will tell you to make a slow website. Websites need to be fast. <strong class="bold">Performance is the key to success</strong>. Performance increases user satisfaction; it results in high conversion rates and higher revenue. Let me share some facts with you:</p>
			<ul>
				<li>Rebuilding Pinterest pages for performance increased conversion rates by 15% (<a href="https://www.hardkoded.com/ui-testing-with-puppeteer/pinterest-case">https://www.hardkoded.com/ui-testing-with-puppeteer/pinterest-case</a>).</li>
				<li>By reducing the response size of the JSON needed for displaying comments, Instagram saw increased impressions (<a href="https://www.hardkoded.com/ui-testing-with-puppeteer/instagram-case">https://www.hardkoded.com/ui-testing-with-puppeteer/instagram-case</a>).</li>
				<li>Walmart saw a 1% increase in revenue for every 100 ms improvement in page load (<a href="https://www.hardkoded.com/ui-testing-with-puppeteer/walmart-case">https://www.hardkoded.com/ui-testing-with-puppeteer/walmart-case</a>).</li>
			</ul>
			<p>As you can see, performance puts money in your pocket.</p>
			<p>There is one more thing on which I'm sure you will agree with me: No matter the website, no matter what they sell or offer, performance is the number-one feature in the mobile experience. When you are on the street, you don't care about the style; you don't care about functionality. The first thing you need is the website to load, and load fast. You need to measure the performance on mobile.</p>
			<p>The problem with this feature is that, in general, people don't know how to measure speed. If we go back to the other features, they are easy to measure. It's easy to discuss content. Content is easy to measure:</p>
			<ul>
				<li>I want to ship the website with content.</li>
				<li>How many items?</li>
				<li>Over 1,000.</li>
			</ul>
			<p>Functionality is, in general, something you can write down on a spec:</p>
			<ul>
				<li>I want an e-commerce site with an outstanding search experience.</li>
				<li>What does that mean?</li>
				<li>It should <a id="_idIndexMarker521"/>support typos, and I should be able to search for part of a word.</li>
			</ul>
			<p>Design is about whether you want to put effort into the look and feel or not:</p>
			<ul>
				<li>We need a website with a great design.</li>
				<li>OK, we need three designers.</li>
				<li>Perfect.</li>
			</ul>
			<p>But speed is hard to discuss:</p>
			<ul>
				<li>The website needs to be fast.</li>
				<li>How fast?</li>
				<li>I don't know… fast?</li>
				<li>But how fast do you think it should be? </li>
				<li>I don't know… faster?</li>
			</ul>
			<p>The second problem is that we tend to react to performance issues. We don't realize something needs to be fast until we realize it's slow.</p>
			<p>Third, speed is a matter of expectation and comparison. The user would say that the website is slow. They would also say that they use Google Drive and that it's way faster. The developer would reply that the website seems fast in their opinion, and, of course, that they don't have Google's budget.</p>
			<p>And the last problem is that we don't know how to test the website's performance. We would get a bug report from a user, saying that the website is slow, and the QA analyst would grab that bug report to validate it, but what's the tool that the analyst has to validate that issue? Going to the website and checking whether it "feels" slow to them.</p>
			<p>That is the perfect cocktail for a disaster: No way to measure, no plan—it's all about feelings and different expectations.</p>
			<p>We won't be able to solve all these problems in just one chapter in a web automation book. But, we will see some strategies and tools to help you and your team to measure and improve your <a id="_idIndexMarker522"/>website's performance. Let me share some tips with you to get started.</p>
			<p>First, <strong class="bold">choose what you need to measure</strong>. If it's the entire website, that's OK. But I would start with the most popular pages first. Begin with the home page. Then, continue with the main workflow of the website. For instance, for an e-commerce website, you would want to test the product details and the checkout page. Ask the people in charge of analytics what pages bring more conversions, and focus on those pages.</p>
			<p>Second, <strong class="bold">define the maximum amount of time a page can take to load</strong>. You could say that the home page should never take more than 30 seconds to load, under any circumstances. This is an excellent use for <em class="italic">Checkly</em>, the platform we saw in <a href="B16113_06_Final_SK_ePub.xhtml#_idTextAnchor104"><em class="italic">Chapter 6</em></a>, <em class="italic">Executing and Injecting JavaScript</em>. You could code a test to check that the page doesn't take more than 30 seconds to load in production and keep that check running on <em class="italic">Checkly</em>. We will see how to implement this later in this chapter. Once you have set up that check, you and your team can set more strict goals. For instance, the search page should never take more than a second to load.</p>
			<p>Third, <strong class="bold">measure performance degradation</strong>. Many times, setting a limit is hard, and it can become a guessing game. You can start by measuring how the performance evolves over time. Is the website becoming faster or slower? Are we getting better or worse? This is a great approach, but it requires a little bit more work. You need to start storing data over time and build something to visualize that information.</p>
			<p>And lastly, use the tools you learned in this book. We talked about Checkly, but remember all the emulation techniques we learned back in <a href="B16113_08_Final_SK_ePub.xhtml#_idTextAnchor137"><em class="italic">Chapter 8</em></a>, <em class="italic">Environments emulation</em>? You can set different goals for different network speeds.</p>
			<p>This is all you can do<a id="_idIndexMarker523"/> to measure a website's performance. In this chapter, I want to show you which tools you have to implement these ideas. Let's start with Google Lighthouse, a tool we can use to measure several important metrics.</p>
			<h1 id="_idParaDest-156"><a id="_idTextAnchor170"/>Getting started with Google Lighthouse</h1>
			<p>As we saw in<a id="_idIndexMarker524"/> the previous section, it's not easy to determine how fast "fast" is. Google came up with an idea. They built Lighthouse, "<em class="italic">an open-source, automated tool for improving the quality of web pages. You can run it against any web page, public or requiring authentication. It has audits for performance, accessibility, progressive web apps, SEO and more</em>" (<a href="https://www.hardkoded.com/ui-testing-with-puppeteer/lighthouse">https://www.hardkoded.com/ui-testing-with-puppeteer/lighthouse</a>).</p>
			<p>Lighthouse will grab the website you choose, apply a list of metrics and recommendations it finds important, and give you a score from 0 to 100. It will analyze the website under<a id="_idIndexMarker525"/> five categories:</p>
			<ul>
				<li><strong class="bold">Performance</strong>: The most popular category. Lighthouse will measure how optimized the website is, that is, how fast it gets ready for user interaction.</li>
				<li><strong class="bold">Accessibility</strong>: I would love to see developers paying more attention to this category. Here, Lighthouse will evaluate how accessible the website is.</li>
				<li><strong class="bold">Best practices</strong>: This is another popular category. Lighthouse will evaluate a few good practices to incorporate into the website.</li>
				<li><strong class="bold">SEO</strong>: This category is used a lot by people in charge of marketing. Some companies even have SEO experts looking at this. This category is about how optimized the website is for search engines. You might agree or not on how the other categories are measured, but here Google is telling you: "This is how we measure your website." You will want a score of 100 if you want to secure your spot on the first page of Google.</li>
				<li><strong class="bold">Progressive Web App</strong>: If the website is a progressive web app, this category will evaluate aspects of that progressive web app.<p class="callout-heading">Important Note</p><p class="callout"><strong class="bold">Progressive web apps</strong> (<strong class="bold">PWAs</strong>) are websites <a id="_idIndexMarker526"/>prepared to be installed as native applications. Many PWAs have offline capabilities and try to get close to a native app experience.</p></li>
			</ul>
			<p>In this chapter, we<a id="_idIndexMarker527"/> will focus only on the Performance category. But before getting into the details of the performance category, let's see how we can run this tool. Lighthouse comes in four flavors, which we will cover in the following sections.</p>
			<h2 id="_idParaDest-157"><a id="_idTextAnchor171"/>As part of Chrome DevTools</h2>
			<p>If you open <a id="_idIndexMarker528"/>DevTools, you will find a <strong class="bold">Lighthouse</strong> tab. If <a id="_idIndexMarker529"/>you can't find it, you can add it by clicking on the three dots in the tool's right corner, then going to <strong class="bold">More tools</strong>, and then finding the <strong class="bold">Lighthouse</strong> options. You should see something like this:</p>
			<div><div><img src="img/Figure_10.01_B16113.jpg" alt="Lighthouse inside DevTools&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption"> </p>
			<p class="figure-caption">Lighthouse inside DevTools</p>
			<p>You should now<a id="_idIndexMarker530"/> have the tab there with all the options to generate<a id="_idIndexMarker531"/> the report. The process will run Lighthouse locally, which is good, but that would mean that the Lighthouse results will be based on your hardware, CPU, available RAM, network speed, and so on.</p>
			<h2 id="_idParaDest-158"><a id="_idTextAnchor172"/>Using PageSpeed Insights</h2>
			<p>Google<a id="_idIndexMarker532"/> saw<a id="_idIndexMarker533"/> that results might fluctuate based on your hardware, so they made a PageSpeed Insights (<a href="https://www.hardkoded.com/ui-testing-with-puppeteer/pagespeed">https://www.hardkoded.com/ui-testing-with-puppeteer/pagespeed</a>) where you can run Lighthouse using Google's hardware. That would make it more stable, but you could get different results even using Google's hardware.</p>
			<h2 id="_idParaDest-159"><a id="_idTextAnchor173"/>Using the command line</h2>
			<p>You can also use <a id="_idIndexMarker534"/>Lighthouse from the command<a id="_idIndexMarker535"/> line. I wasn't that excited about having Lighthouse in the command line first. But then I realized that it's way more productive to use it from the command line than opening a browser, going to DevTools, and so on.</p>
			<p>You can install the<a id="_idIndexMarker536"/> Lighthouse <code>-g</code> flag like this:</p>
			<pre>npm install -g lighthouse</pre>
			<p class="callout-heading">NPM global modules</p>
			<p class="callout">When you run <code>npm install</code> with the <code>-g</code> flag, the module will be installed in a shared directory rather than in the <code>node_modules</code> folder, and it will be accessible by any app. Additionally, if the module provides an executable command, it will be accessible from the command line like this Lighthouse module.</p>
			<p>Once installed, you will be able to launch <code>lighthouse</code> from the command line, passing the URL and, additionally, extra command-line arguments such as <code>--view</code>, which will launch the report after evaluating the website. </p>
			<p>With this line of code, you will be able to see the Lighthouse result for <a href="http://www.packtpub.com">www.packtpub.com</a>:</p>
			<pre>lighthouse https://www.packtpub.com/ --view</pre>
			<p>Wondering what the result is? We'll get there.</p>
			<p>The last option available is one that we will use a lot, and it's using the node module as part of our code.</p>
			<h2 id="_idParaDest-160"><a id="_idTextAnchor174"/>Using the node module</h2>
			<p>We will<a id="_idIndexMarker537"/> be <a id="_idIndexMarker538"/>able to use Lighthouse in our unit tests using the node module. Let's take a look at the example from the Lighthouse repository (<a href="https://www.hardkoded.com/ui-testing-with-puppeteer/lighthouse-programmatically">https://www.hardkoded.com/ui-testing-with-puppeteer/lighthouse-programmatically</a>):</p>
			<pre>const fs = require('fs');
const lighthouse = require('lighthouse');
const chromeLauncher = require('chrome-launcher');
(async () =&gt; {
  const chrome = await chromeLauncher.launch({chromeFlags: ['--headless']});
  const options = {logLevel: 'info', output: 'html', onlyCategories: ['performance'], port: chrome.port};
  const runnerResult = await lighthouse('https://example.com', options);
  const reportHtml = runnerResult.report;
  fs.writeFileSync('lhreport.html', reportHtml);
  console.log('Report is done for', runnerResult.lhr.finalUrl);
  console.log('Performance score was', runnerResult.lhr.categories.performance.score * 100);
  await chrome.kill();
})();</pre>
			<p>The code is not <a id="_idIndexMarker539"/>very<a id="_idIndexMarker540"/> complicated. We launch a Chrome browser using the <code>chrome-launcher</code> module. Then we launch <code>lighthouse</code>, passing a URL and a set of options. The <code>lighthouse</code> function will return an object, I called it <code>runnerResult</code>, which contains a <code>report</code> property with the report as HTML and also a property called <code>lhr</code> (Lighthouse result) with all the results as an object. We will use that property to assert the minimum values we want to get.</p>
			<p>Now that we know how to launch Lighthouse, let's see how the report looks. In order to avoid hurting feelings, we will run Lighthouse against the very same Lighthouse website: <a href="https://www.hardkoded.com/ui-testing-with-puppeteer/lighthouse">https://www.hardkoded.com/ui-testing-with-puppeteer/lighthouse</a>. Let's see whether it is as fast as they say. As I mentioned before, I felt really comfortable with the command-line tool, so I will run this command:</p>
			<pre>lighthouse https://developers.google.com/web/tools/lighthouse --view</pre>
			<p>After running<a id="_idIndexMarker541"/> that, I got a new tab in my browser with <a id="_idIndexMarker542"/>the following result:</p>
			<div><div><img src="img/Figure_10.02_B16113.jpg" alt="Lighthouse result&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Lighthouse result</p>
			<p>To be honest, I picked a Google website on purpose. As you can see in the screenshot, the results can be rough. A score of 55 doesn't mean that your site is terrible. It just means that the website can be improved a lot.</p>
			<p>You also have to keep in mind that a single company made this scoring system and, although many companies use it as a marketing number to show off how good the score is, this is not the final word. It's just one way to measure the performance of your website.</p>
			<p>Another thing to keep in mind is that although it measures many things, its focus is on the time taken to load the page, and you should know that performance is more than that.</p>
			<p>Let's dive into<a id="_idIndexMarker543"/> the<a id="_idIndexMarker544"/> performance category details.</p>
			<h2 id="_idParaDest-161"><a id="_idTextAnchor175"/>The performance category</h2>
			<p>Each category in <a id="_idIndexMarker545"/>Lighthouse consists of three sections: metrics, opportunities, and diagnostics. Although only the metrics are used for the category score, it is by implementing the opportunities and looking at the diagnostics that you will improve the metrics.</p>
			<p>Each category has its own set of metrics, opportunities, and diagnostics. In particular, the performance category has 6 metrics, 17 opportunities, and 13 diagnostics.</p>
			<p>Let's take a look at the performance metrics.</p>
			<h3>Performance metrics</h3>
			<p>The first<a id="_idIndexMarker546"/> metric is <strong class="bold">First Contentful Paint</strong>. It has a weight of 15% on the overall performance score. According to Google, this metric "<em class="italic">measures how long it takes the browser to render the first piece of DOM content after a user navigates to your page. Images, non-white &lt;canvas&gt; elements, and SVGs on your page are considered DOM content; anything inside an iframe isn't included</em>." You will get a green score if this metric is under 2 seconds. You can read more about this metric and how to improve the score at <a href="https://web.dev/first-contentful-paint/">https://web.dev/first-contentful-paint/</a>.</p>
			<p>The second metric is <strong class="bold">Speed Index</strong>. It has a weight of 15% on the overall performance score. According to Google, this metric "<em class="italic">measures how quickly content is visually displayed during page load. Lighthouse first captures a video of the page loading in the browser and computes the visual progression between frames. Lighthouse then uses the </em>Speedline Node.js module<em class="italic"> to generate the Speed Index score</em>." You will get a green score if this metric is under 4.3 seconds. You can read more about this metric and how to improve the score at <a href="https://web.dev/speed-index/">https://web.dev/speed-index/</a>.</p>
			<p>With a weight of 25%, the third metric is <strong class="bold">Largest Contentful Paint</strong> and is one of the most important metrics. According to Google, this metric "<em class="italic">measures the render time of the largest image or text block visible within the viewport</em>." You will get a green score if this metric is under 2.5 seconds. If you are interested in how they get to know what the "largest contentful element" is, check out their article at <a href="https://web.dev/lcp/">https://web.dev/lcp/</a>.</p>
			<p>The fourth metric is <strong class="bold">Time to Interactive</strong>. It has a weight of 15% on the overall performance score. According to Google, this metric "<em class="italic">measures how long it takes a page to become fully interactive</em>." You will get a green score if this metric is under 3.8 seconds. You can read more about this metric and how to improve the score at <a href="https://web.dev/interactive/">https://web.dev/interactive/</a>.</p>
			<p>The fifth metric is <strong class="bold">Total Blocking Time</strong>, which is the second metric with a weight of 25% on the overall performance score. According to Google, this metric "<em class="italic">measures the total amount of time that a page is blocked from responding to user input, such as mouse clicks, screen taps, or keyboard presses</em>." You will get a green score if this metric is <a id="_idIndexMarker547"/>under 300 milliseconds. You can read more about this metric and how to improve the score at <a href="https://web.dev/lighthouse-total-blocking-time/">https://web.dev/lighthouse-total-blocking-time/</a>.</p>
			<p>With a weight of just 5%, the last metric is <strong class="bold">Cumulative Layout Shift</strong>. According to Google, this metric "<em class="italic">measures the sum total of all individual layout shift scores for every unexpected layout shift that occurs during the entire lifespan of the page</em>." You will get a green mark if the score is under 0.1. You can read more about this metric and how to improve the score at <a href="https://web.dev/cls">https://web.dev/cls</a>.</p>
			<p>I came to a few conclusions after digging into all these metrics. First, it's clear that they were made by web performance professionals. It would have been impossible for me to build all these metrics in my daily job. The research behind these metrics is impressive.</p>
			<p>On the other side, when you look at the weights and thresholds, while they look well thought out, they might sound quite arbitrary. Why is total blocking time more important than time to interactive? Or why do I get a green mark on a speed index under 4.3 seconds? Why not 4.2? Why not 4.4? But this is better than nothing.</p>
			<p>You might also have had the feeling of this being too complicated or hard to understand. Some concepts, such as <strong class="bold">Largest Contentful Paint</strong>, sound like rocket science, at least to me. That's why you might find it easier to understand and follow the opportunities section of the report.</p>
			<h3>Performance opportunities</h3>
			<p>Opportunities are<a id="_idIndexMarker548"/> calls to action. These are not just simple recommendations. Here, Lighthouse will get to the point: "If you do this, you might get this bump in performance."</p>
			<p>As I mentioned before, there are 17 opportunities under the performance category. We won't cover all of them. But I would like to go through a few of them so you get an idea of what this section is about.</p>
			<p>Let's cover only the opportunities shown when we process the Lighthouse website. These are the opportunities I got in my report:</p>
			<div><div><img src="img/Figure_10.03_B16113.jpg" alt="Performance opportunities for the Lighthouse website&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Performance opportunities for the Lighthouse website</p>
			<p>Here, we have five opportunities. Let's unpack them:</p>
			<ul>
				<li><strong class="bold">Properly size images</strong>: Lighthouse found images that are bigger than the size shown on the page.</li>
				<li><strong class="bold">Serve images in next-gen formats</strong>: Here, Lighthouse checks whether you are using JPEG or PNG files instead of "next-gen" formats such as WebP. I'm not particularly a fan of this opportunity. Although WebP is supported in most popular browsers these days, it is not a popular format in general yet.</li>
				<li><strong class="bold">Eliminate render-blocking resources</strong>: I think this is a critical opportunity. Here, Lighthouse found that many resources are blocking the first paint of the page. Paying attention to this opportunity would improve your metrics considerably.</li>
				<li><strong class="bold">Remove unused JavaScript</strong>: Lighthouse found JavaScript code that is not being used. Although this would be easy to detect by Lighthouse, this issue is not that easy to solve by developers. Developers these days use bundlers to pack all their JavaScript code, and shrinking the final code to only the code that the page needs can be challenging.</li>
				<li><strong class="bold">Remove unused CSS</strong>: This opportunity is similar to the previous one, but it's related to CSS styles.</li>
			</ul>
			<p>I love this section because Lighthouse doesn't just tell you what the opportunities are; it also gives details showing you where the opportunity is and what would be the performance bump. Let's<a id="_idIndexMarker549"/> see, for instance, what we get when we click on the <strong class="bold">Properly size images</strong> row:</p>
			<div><div><img src="img/Figure_10.04_B16113.jpg" alt="Properly size images section&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Properly size images section</p>
			<p>As you can see there, Lighthouse is showing us which images we can improve and what the potential <a id="_idIndexMarker550"/>savings we could get are. You will get the same kind of details on every opportunity.</p>
			<p>The last section within a Lighthouse category is the diagnostics.</p>
			<h3>Performance Diagnostics</h3>
			<p>I see the<a id="_idIndexMarker551"/> diagnostics section as a list of things you should consider to improve your website. As I mentioned before, the performance category has 13 diagnostics, but you will see this number change over time. </p>
			<p>This is how the diagnostics section looks:</p>
			<div><div><img src="img/Figure_10.05_B16113.jpg" alt="Performance diagnostics for the Lighthouse website&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Performance diagnostics for the Lighthouse website</p>
			<p>As you can see, you will have the same level of detail as in the opportunities section, but these diagnostics sound more like recommendations to improve over time on your website. For instance, let's take a look at the <strong class="bold">Minimize main-thread work</strong> section:</p>
			<div><div><img src="img/Figure_10.06_B16113.jpg" alt="Minimize main-thread work section&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Minimize main-thread work section</p>
			<p>As you can see, it<a id="_idIndexMarker552"/> seems to make sense what the diagnostics section reports. There is some script evaluation that is taking 1,490 ms. But that doesn't sound like a call to action. It's more something to consider if you need to improve the website's performance.</p>
			<p>Now that we have learned about what Lighthouse is, let's see how we can test our website's performance by adding Lighthouse to our tests.</p>
			<h2 id="_idParaDest-162"><a id="_idTextAnchor176"/>Using Lighthouse for testing</h2>
			<p>Let's be clear, Lighthouse is not a testing tool. It's a tool used more for <a id="_idIndexMarker553"/>developers to check their websites' performance. But, as we mentioned many times in this book, the role of QA is to honor the customer. It's to ensure that the customer gets the best product the team can deliver. We will use Lighthouse to ensure that the customer will get the fastest website we can deliver.</p>
			<p>I can think of three ways we can test a Lighthouse report:</p>
			<ul>
				<li>Ensure that a page has a minimum performance score.</li>
				<li>Ensure that a metric is below a threshold.</li>
				<li>Ensure that an opportunity is not found.</li>
			</ul>
			<p>Let's begin by checking the performance score. </p>
			<h3>Ensure that a page has a minimum performance score</h3>
			<p>The first test we can make <a id="_idIndexMarker554"/>using Lighthouse is making sure that our page performance won't degrade over time. We will check that our page never falls below a specific score. How can we pick the minimum score? As we want to be sure that our website won't degrade over time, let's see the current performance score and enforce that. Let's go to the <code>vuejs-firebase-shopping-cart</code> directory, under <code>Chapter10</code> of the repository, and we will run <code>npm run serve</code> and launch the web application:</p>
			<pre>npm run serve</pre>
			<p>That command should start the website. Once started, let's open another terminal and run Lighthouse on the home page:</p>
			<pre>lighthouse http://localhost:8080/--view</pre>
			<p>The result of that process was a score of 30 for performance. We can set our target score at 25. Time to write our test.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">As Lighthouse runs locally, you might get different results on different machines. You should consider that when picking your score goal.</p>
			<p>We are going to add our test in the <code>homepage.tests.js</code> file. But before creating the test, we need to install the <code>lighthouse</code> module by running the following command:</p>
			<pre>npm install lighthouse</pre>
			<p>That will get us Lighthouse in our tests. The next step is importing the lighthouse module using the <code>require</code> function. Let's add this line at the top of the file:</p>
			<pre>const lighthouse = require('lighthouse');</pre>
			<p>This will make Lighthouse available in our tests. Now, let's see how our test would look:</p>
			<pre>it('Should have a good performance score', async() =&gt; {
  const result = await lighthouse(config.baseURL, {
    port: (new URL(browser.wsEndpoint())).port,
    onlyCategories: ['performance']
  });
  
  expect(result.lhr.categories.performance.score &gt;= 0.25).to.be.true;
});</pre>
			<p>We solved the test using<a id="_idIndexMarker555"/> only two statements. We first call <code>lighthouse</code>, passing the URL we want to process, in this case, <code>config.baseURL</code>, and then we pass an <code>options</code> object. There we are passing the <code>port</code> it has to use to connect to the browser that Puppeteer is using. We get it by doing <code>new URL(browser.wsEndpoint())).port</code>, and then we tell Lighthouse we only want to process the <code>performance</code> category. We won't cover all the available options here. You can take a look at the full list of options at <a href="https://www.hardkoded.com/ui-testing-with-puppeteer/lighthouse-configuration">https://www.hardkoded.com/ui-testing-with-puppeteer/lighthouse-configuration</a>.</p>
			<p>In the next line, we just assert that the score of the performance category is greater or equal to 0.25. When you see the report, scores are in the range of 0 to 100. But in the JSON object, the range is from 0 to 1. That's why we need to use 0.25 instead of 25.</p>
			<p>The next test is checking for specific metrics.</p>
			<h3>Ensure that a metric is below a threshold</h3>
			<p>We can also be more specific. We could say that, for instance, regardless of the performance score we want to check, <strong class="bold">First Contentful Paint</strong> should never take longer than 30 seconds. Our code will be similar to our previous test:</p>
			<pre>it('Should have a good first contentful paint metric', async() =&gt; {
  const result = await lighthouse(config.baseURL, {
    port: (new URL(browser.wsEndpoint())).port,
    onlyCategories: ['performance']
  });
  
  expect(result.lhr.audits['first-contentful-paint'].numericValue).lessThan(30000);
});</pre>
			<p>Here, we <a id="_idIndexMarker556"/>can see that the <code>lhr</code> object also contains an <code>audits</code> dictionary with all the metrics. We can grab the <code>first-contentful-paint</code> entry call and check that <code>numericValue</code> (in milliseconds) is under 30,000 (30 seconds expressed in milliseconds).</p>
			<p>How can we know what the available metrics are? The easiest way is to add a breakpoint in your test and add a watch to see the value of <code>result.lhr</code>. You will see something like this:</p>
			<div><div><img src="img/Figure_10.07_B16113.jpg" alt="result.lhr content&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Result.lhr content</p>
			<p>There you will be able to see<a id="_idIndexMarker557"/> not only the available entries but also <code>numericUnit</code>, among many other properties.</p>
			<p>Based on this example, making sure that an opportunity is not found will be easy.</p>
			<h3>Ensure that an opportunity is not found</h3>
			<p>I think this is the most solid way to use Lighthouse. We introduced some arbitrary numbers in our previous examples, 30 for the score and 30 seconds for the metric. Now, let's say we don't want to get a certain opportunity; for instance, we don't want any images of the wrong size. We can look at the audits and try to find an entry with the name <code>user-responsive-images</code>. With that entry, we can write the following test:</p>
			<pre>it('Should have properly sized images', async() =&gt; {
  const result = await lighthouse(config.baseURL, {
    port: (new URL(browser.wsEndpoint())).port,
    onlyCategories: ['performance']
  });
  
  result.lhr.audits['uses-responsive-images'].numericValue.should.equal(0); 
});</pre>
			<p>The code is the same as the previous example, but here, we assert that the metric value should be 0. That will mean that all the images are properly sized.</p>
			<p>It's impressive all we can do with<a id="_idIndexMarker558"/> Lighthouse, but to be honest, you won't see many teams applying these ideas to their project. If you get to test your website's performance using Lighthouse, you will add a lot of value to your team.</p>
			<p>Lighthouse is kind of a black box that you call, get values, and act in response. But what if you want to build your own metric? What if you want to analyze the performance of a page in a more granular way? Let's now explore all the <strong class="bold">tracing</strong> features Puppeteer offers.</p>
			<h1 id="_idParaDest-163"><a id="_idTextAnchor177"/>Tracing Pages</h1>
			<p>In this section, we will <a id="_idIndexMarker559"/>cover how to get performance information using the <code>tracing </code>object you can find on the <strong class="bold">page.tracing</strong> property. I saw this question more than once on Stack Overflow: How can I get the Performance tab's information using Puppeteer? The answer is: You can get all that information from the tracing result. There is a high chance that you will get a reply like: "Yes, I say that, but the result is too complex." And yes, the tracing result is quite complicated. But we will try to see what we can get from that object in this section.</p>
			<p>If you open DevTools, you<a id="_idIndexMarker560"/> should see a <strong class="bold">Performance</strong> tab like this one:</p>
			<div><div><img src="img/Figure_10.08_B16113.jpg" alt="Performance tab&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Performance tab</p>
			<p>As you can see, the <strong class="bold">Performance</strong> tab is not processing information all the time because it's a costly process. You need to start "recording" the tracing, Chrome will begin collecting lots of data from the browser, and then you have to stop the tracing process.</p>
			<p>If you click on the second button, which looks like a reload, it will automatically reload the page and start the tracing. If you click on that button and then stop the tracing when the page loads, you will get something like this:</p>
			<div><div><img src="img/Figure_10.09_B16113.jpg" alt="Performance result&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Performance result</p>
			<p>The level of detail<a id="_idIndexMarker561"/> of that panel is impressive. You get to see every paint action, every HTML parsing, every JavaScript execution, everything the browser did to render the page there.</p>
			<p>We can get the same using the <code>tracing</code> object. Let's create a test called <code>Should have a good first contentful paint metric using tracing</code> in our<code> homepage.tests.js</code> file, but we will add only the tracing calls for now:</p>
			<pre>it('Should have a good first contentful paint metric using tracing', async() =&gt; {
  await page.tracing.start({ screenshots: true, path: './homepagetracing.json' });
  await page.goto(config.baseURL);
  await page.tracing.stop();
});</pre>
			<p>The code is straightforward. We start the tracing, we go to the page, and we stop the tracing.</p>
			<p>The <code>start</code> function expects an <code>options</code> object, which has three properties:</p>
			<ul>
				<li>The <code>screenshots</code> property will determine whether we want Chromium to take screenshots during the tracing.</li>
				<li>If you set the <code>path</code> property, the tracing result will be written in that JSON file.</li>
				<li>Finally, you'll find a <code>categories</code> property, where you will be able to pass an array of properties you want to trace.</li>
			</ul>
			<p>There is no fixed list of <a id="_idIndexMarker562"/>categories, but these are the categories I find more relevant to us:</p>
			<ul>
				<li>Under the <strong class="bold">rail</strong> category, we will find many useful traces such as <strong class="bold">domInteractive</strong>, <strong class="bold">firstPaint</strong>, and <strong class="bold">firstContentfulPaint</strong>.</li>
				<li>If you set <code>screenshots</code> to <code>true</code>, you will find all the screenshots under the <strong class="bold">disabled-by-default-devtools.screenshot</strong> category.</li>
				<li>You will find that lots of entries will come under the <strong class="bold">devtools.timeline</strong> category. This category represents one of those items you see in the performance timeline.</li>
			</ul>
			<p>When you call the <code>stop</code> function, you will get the result in the file you passed to the <code>start</code> function, and, whether you passed a path or not, the <code>stop</code> function will return the result as a <code>Buffer</code>.</p>
			<p>The resulting JSON will be an object with two properties: A <code>metadata</code> object with information about the trace and the browser, and a <code>traceEvents</code> array, with all the trace information.</p>
			<p>In my simple test example, <code>traceEvents</code> gave me <code>16,693</code>. That was just for navigating to the page. I think now you get why this can be scary for some users.</p>
			<p>The shape of each trace event might vary based on the category. But you will find these properties:</p>
			<ul>
				<li><code>cat</code> will tell you the categories for the event, separated by commas.</li>
				<li><code>name</code> will give you the name of the event, as you would see it in the <strong class="bold">Performance</strong> tab.</li>
				<li><code>ts</code> will give you the tracking clock, expressed in microseconds (1 microsecond is 0.000001 seconds). Most events are relative to the beginning of the trace.</li>
				<li><code>pid</code> is the process ID. I don't think you will care about that.</li>
				<li><code>tid</code> is the thread ID. You won't care about that either.</li>
				<li><code>args</code> will give you an object with specific information for that event type. For instance, you will get the URL and the HTTP method of a request. For a screenshot, you will get the image in Base64 format.</li>
			</ul>
			<p>With all this information, let's code our first contentful paint test using tracing values. We are going<a id="_idIndexMarker563"/> to write a test that will start the tracing, navigate to a page, and then evaluate the results. It would be something like this:</p>
			<pre>it('Should have a good first contentful paint metric using tracing', async() =&gt; {
  await page.tracing.start({ screenshots: true, path: './homepagetracing.json' });
  await page.goto(config.baseURL);
  const trace = await page.tracing.stop();
  const result = JSON.parse(trace);
  const baseEvent = result.traceEvents.filter(i=&gt; i.name == 'TracingStartedInBrowser')[0].ts;
  const firstContentfulPaint =result.traceEvents.filter(i=&gt; i.name == 'firstContentfulPaint')[0].ts;
  expect((firstContentfulPaint - baseEvent) / 1000).lessThan(500);
});</pre>
			<p>We have some tricks to explain here. After stopping the trace, we get the result and parse it. That will give us the <code>result</code> with a <code>traceEvents</code> property. As <code>ts</code> is based on the beginning of the trace, we need to find the <code>baseEvent</code>, looking for an event with the name <code>TracingStartedInBrowser</code>. Then we look for the event with the name <code>firstContentfulPaint</code>, and finally, we calculate the difference. As it's in microseconds, we need to divide it by 1,000, so we can compare it with our target goal of 500 ms.</p>
			<p>Notice that in this example, our goal is 500 ms versus the 30 seconds we used in the Lighthouse example. This is because, by default, Lighthouse performs several runs emulating different conditions.</p>
			<p>Another thing we could do here is export the screenshots generated by the tracing tool for later analysis. We<a id="_idIndexMarker564"/> can add something like this at the end of the test:</p>
			<pre>const traceScreenshots = result.traceEvents.filter(x =&gt; (
    x.cat === 'disabled-by-default-devtools.screenshot' &amp;&amp;
    x.name === 'Screenshot' &amp;&amp;
    x.args  &amp;&amp;
    x.args.snapshot
));
traceScreenshots.forEach(function(snap) {
  fs.writeFile(`./hometrace-${snap.ts - baseEvent}.png`, snap.args.snapshot, 'base64', function(err) {});
});</pre>
			<p>There, we are filtering screenshots events with a valid screenshot, and then we just write all those Base64 snapshots to the filesystem. With that, you will see how the page was being rendered during the loading process. You would even code your own first contentful paint algorithm with those images.</p>
			<p>Now you might be wondering whether you should use Lighthouse or Puppeteer's tracing. I think there are some pros and cons to every approach. Lighthouse is easy to use, and as we saw, it gives us metrics that would take us lots of effort to build by ourselves. With Lighthouse, you just call the <code>lighthouse</code> function and evaluate the results. But it can be slow, even if you select only one category.</p>
			<p>On the other hand, Puppeteer's tracing can be hard to read and process, but if you know how to take the metric you need from the tracing result, it will be way faster than Lighthouse. Another important difference is that Lighthouse only evaluates the page load, whereas with Puppeteer's tracing, you could start the tracing at any moment. For instance, you could go to a page, start the tracing, click on a button, and then evaluate what the browser did to process that click. At the end of the day, it's about picking the right tool for your job.</p>
			<p>Lighthouse also gives us two<a id="_idIndexMarker565"/> interesting metrics: <strong class="bold">Remove unused JavaScript</strong> and <strong class="bold">Remove unused CSS</strong>. Let's see how we can solve those metrics using Puppeteer.</p>
			<h1 id="_idParaDest-164"><a id="_idTextAnchor178"/>Analyzing code coverage</h1>
			<p>In this last section, we<a id="_idIndexMarker566"/> will see how we can get code coverage using the <code>Coverage</code> class from Puppeteer. Code coverage is a metric that can be applied to any piece of code. To get the code coverage of a piece of code, you need some kind of tool to trace which lines of code are being executed, execute that code, and get the tracing result. It's like the performance tracing, but instead of measuring time, it measures executed lines of code.</p>
			<p>You can see the code coverage on a page on Chrome using the <strong class="bold">Coverage</strong> tab. I didn't have that tab by default, so I needed to add it using the <strong class="bold">More tools</strong> option, as in the following screenshot:</p>
			<div><div><img src="img/Figure_10.10_B16113.jpg" alt="Coverage tab&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Coverage tab</p>
			<p>The <strong class="bold">Coverage</strong> tab works like the <strong class="bold">Performance</strong> tab. You need to start the tracing, run the page, or perform<a id="_idIndexMarker567"/> an action, then stop the tracing to get the results.</p>
			<p>The result will be something like what we see in the preceding screenshot: A list of resources with the total bytes of that resources and the unused bytes. At the bottom of the window, we can see that over 90% of the code was used (executed) during the tracing. That's pretty good. We could write a test to ensure that we will always have a code coverage of over 90%.</p>
			<p>The JavaScript and the CSS code coverage have two sets of functions in Puppeteer. If you want to get the JavaScript code coverage, you need to run <code>startJSCoverage</code> to start the coverage and <code>stopJSCoverage</code> to stop it. <code>startJSCoverage</code> supports an <code>options</code> argument with two properties:</p>
			<ul>
				<li><code>resetOnNavigation</code> is a Boolean property we can use to tell Puppeteer to start over with the tracing if navigation was detected.</li>
				<li><code>reportAnonymousScripts</code> is a Boolean property we can use to tell Puppeteer to ignore, or not, dynamically generated JavaScript code.</li>
			</ul>
			<p>If we want to get CSS coverage, we need to use the <code>startCSSCoverage</code> and <code>stopCSSCoverage</code> functions. <code>startCSSCoverage</code> also expects an <code>options</code> argument, but, in this case, it only has the <code>resetOnNavigation</code> property.</p>
			<p>Once we run the coverage, both <code>stopCSSCoverage</code> and <code>stopJSCoverage</code> will return the same type of value. Both will return an array of objects with these properties:</p>
			<ul>
				<li><code>url</code> will give us the resource URL.</li>
				<li><code>content</code> will be the CSS or the script content.</li>
				<li><code>ranges</code>, which will contain an array of objects telling us which were the portion of code that has been executed. Each entry will contain two properties, <code>start</code> and <code>end</code>, telling us where that text range starts and ends.</li>
			</ul>
			<p>Now we have all this<a id="_idIndexMarker568"/> information, we can write our code coverage test. Let's take a look at it:</p>
			<pre>it('It should have good coverage', async() =&gt; {
  await Promise.all([page.coverage.startJSCoverage(), page.coverage.startCSSCoverage()]);
  await page.goto(config.baseURL);
  const [jsCoverage, cssCoverage] = await Promise.all([
      page.coverage.stopJSCoverage(),
      page.coverage.stopCSSCoverage()
  ]);
  let totalBytes = 0;
  let usedBytes = 0;
  const coverageTotals = [...jsCoverage, ...cssCoverage];
  for (const entry of coverageTotals) {
      totalBytes += entry.text.length;
      for (const range of entry.ranges) usedBytes += range.end - range.start - 1;
  }
  const percentUnused = parseInt((usedBytes / totalBytes) * 100, 10);
  expect(percentUnused).greaterThan(90);
});</pre>
			<p>We start our test by starting both code coverages. We put <code>startJSCoverage</code> and <code>startCSSCoverage</code> inside <code>Promise.all</code>, so we wait for both coverages to be confirmed. Then we go to the page, and after that, we stop both coverages. That will give us two arrays <a id="_idIndexMarker569"/>that we can join (because they share the same shape) using <code>[...jsCoverage, ...cssCoverage]</code>.</p>
			<p>Once we have both coverages, we get the total size of the resource by using <code>entry.text.length</code>, and then we get the size of the coverage by adding the length of all the ranges.</p>
			<p>The result will give us the total code coverage of our tracing, which we will check whether it's over 90%.</p>
			<p>The pros and cons of this solution compared with Lighthouse are the same as we saw in the previous section. On one side we have Lighthouse, which gives us all the numbers already cooked. But here, we have more control over what we want to measure. This test was quite simple, but you could improve it by filtering out all the resources you don't want to measure. You can also download that result to a file and share it with your team if the test fails.</p>
			<p>Now it's time to wrap up this chapter and this book.</p>
			<h1 id="_idParaDest-165"><a id="_idTextAnchor179"/>Summary</h1>
			<p>If you get to apply performance tests in your team, you will be on a whole new level.</p>
			<p>We started the chapter by talking about Lighthouse. We only covered the Performance category. But now that you know how it works, I encourage you to keep digging into the other categories and think about how to create tests for that. I would love to see more tests about accessibility. </p>
			<p>We also learned how to use Lighthouse in our tests. That's not something you will see quite often. You will be able to test very complex metrics using two lines of code.</p>
			<p>Most developers would run away from Puppeteer's tracing results. Although what you can get from there is way more than what we covered, we learned the foundations of such a powerful tool in this chapter.</p>
			<p>The size of a page is critical for performance; that's why we learned about code coverage and how to measure it.</p>
			<p>And this is also a wrap on this book. When I planned this book, my goal was to write a book that would cover the entire Puppeteer API, without being a reference book. And I think we accomplished that goal. We learned how to write high-quality end-to-end tests using Puppeteer and, at the same time, we covered most of the Puppeteer API.</p>
			<p>With this goal in mind, we covered topics that were not strictly related to unit testing. We talked about PDF generation and Web Scraping. We also covered topics that many people would run away from, such as the tracing model.</p>
			<p>If you read this book from cover to cover, I can assure you that you will know way more about Puppeteer than the average user of this library.</p>
			<p>But I also hope you learned more than just a Node package. In this book, we also learned about the foundations of the web, and how to write good tests. We talked about the internet ecosystem, scraping ethics, and web performance. You have also empowered your role. QA is more than just about testing web pages. It's about honoring your users by delivering high-quality software they can enjoy using.</p>
		</div>
	</body></html>