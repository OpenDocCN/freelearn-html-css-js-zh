<html><head></head><body>
		<div><h1 id="_idParaDest-312" class="chapter-number"><a id="_idTextAnchor320"/>12</h1>
			<h1 id="_idParaDest-313"><a id="_idTextAnchor321"/> Data Persistence with MongoDB</h1>
			<p>In this chapter, we will explain how MongoDB works and why it is a great starting point for a web application. We will learn how to install MongoDB locally using containers with Docker and Docker Compose and also how to use external MongoDB instances.</p>
			<p>We will explore how to use Mongoose to interact with MongoDB, and we will migrate our application to use MongoDB instead of a JSON file,  we will use tests to grant that the migration was properly done and we didn’t introduce any regression.</p>
			<p>In summary, here are the main topics that we will explore in this chapter:</p>
			<ul>
				<li>How to set up MongoDB locally using containers with Docker and Docker Compose</li>
				<li>How to use an <strong class="bold">Object–relational mapping</strong> (<strong class="bold">ORM</strong>) library such as Mongoose to interact with MongoDB</li>
				<li>How to migrate our application to use MongoDB instead of a JSON file</li>
				<li>How to test any application using MongoDB</li>
				<li>How to use environment variables to store sensitive information and how to load them in Node.js</li>
			</ul>
			<p>By the end of this chapter, you will be comfortable using MongoDB in your Node.js projects, and you will know how to use tests to plan more complicated features such as a database migration.</p>
			<h1 id="_idParaDest-314"><a id="_idTextAnchor322"/>Technical requirements</h1>
			<p>The code files for the chapter can be found at <a href="https://github.com/PacktPublishing/NodeJS-for-Beginners">https://github.com/PacktPublishing/NodeJS-for-Beginners</a>.</p>
			<p>Check out the code in action video for this chapter on <a href="https://youtu.be/0CHOQ35c-_Y">https://youtu.be/0CHOQ35c-_Y</a></p>
			<p>To start working on this chapter, we need to download the project from  <a href="https://github.com/PacktPublishing/NodeJS-for-Beginners/archive/refs/heads/main.zip">https://github.com/PacktPublishing/NodeJS-for-Beginners/archive/refs/heads/main.zip</a> and access the <code>step2</code> folder.</p>
			<h1 id="_idParaDest-315"><a id="_idTextAnchor323"/>What is MongoDB?</h1>
			<p>If you are familiar with relational<a id="_idIndexMarker706"/> databases, you will find MongoDB very different. MongoDB is a document-oriented database, which means that it stores data in documents instead of tables. A document is a set of key-value pairs, and it is the basic unit of data in MongoDB. Documents are similar to JSON objects, and they are stored in a collection. A collection is a group of documents that have the same structure. In MongoDB, documents are stored in <strong class="bold">Binary JSON</strong> (<strong class="bold">BSON</strong>), a binary representation of JSON<a id="_idIndexMarker707"/> documents.</p>
			<div><div><img src="img/B21678_12_1.jpg" alt="Figure 12.1 – A SQL data structure compared to a MongoDB data structure"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.1 – A SQL data structure compared to a MongoDB data structure</p>
			<p>In the preceding diagram, we can see the difference between a relational database and a document-oriented database more clearly.</p>
			<h2 id="_idParaDest-316"><a id="_idTextAnchor324"/>Versions</h2>
			<p>There are several versions<a id="_idIndexMarker708"/> of MongoDB, but the most popular is MongoDB Community Server. In our project, we will also use MongoDB Community Server as well, at no extra cost to us.</p>
			<p>In <a href="B21678_16.xhtml#_idTextAnchor416"><em class="italic">Chapter 16</em></a>, we will explore more versions of MongoDB when we deploy our application to the cloud.</p>
			<p>If you want to know more about the different<a id="_idIndexMarker709"/> versions of MongoDB, you can check out the following link: <a href="https://www.mongodb.com/try/download/community">https://www.mongodb.com/try/download/community</a></p>
			<p>In the next section, we will explain how to install MongoDB locally using containers with Docker and Docker Compose, as well as how to use external MongoDB instances.</p>
			<h1 id="_idParaDest-317"><a id="_idTextAnchor325"/>Setting up MongoDB</h1>
			<p>There are several ways to install<a id="_idIndexMarker710"/> MongoDB, but we will use Docker Compose to install it locally. Docker Compose is a tool for defining and running multi-container Docker applications. With Docker Compose, we will be able to run MongoDB and our web application in different containers. If you are not familiar with Docker, there is a fantastic guide from MongoDB (<a href="https://www.mongodb.com/compatibility/docker">https://www.mongodb.com/compatibility/docker</a>) that can help you get a deeper understanding.</p>
			<h2 id="_idParaDest-318"><a id="_idTextAnchor326"/>Installing Docker</h2>
			<p>If you don’t have Docker<a id="_idIndexMarker711"/> installed, you can follow<a id="_idIndexMarker712"/> the instructions at <a href="https://docs.docker.com/get-docker/">https://docs.docker.com/get-docker/</a>, depending on your operating system.</p>
			<h3>Checking the installation</h3>
			<p>Let’s check that Docker<a id="_idIndexMarker713"/> is installed correctly. Open a terminal and run the following command:</p>
			<pre class="console">
docker --version</pre>			<p>You should see the version installed – in my case, 24.0.2:</p>
			<pre class="console">
Docker version 24.0.2, build cb74dfc</pre>			<p>We can also check that Docker Compose is installed correctly. Open a terminal and run the following command:</p>
			<pre class="console">
docker-compose --version</pre>			<p>You should see something<a id="_idIndexMarker714"/> like this:</p>
			<pre class="console">
Docker Compose version v2.19.1</pre>			<h2 id="_idParaDest-319"><a id="_idTextAnchor327"/>Running MongoDB with a container</h2>
			<p>The beauty of Docker<a id="_idIndexMarker715"/> is that we can<a id="_idIndexMarker716"/> run MongoDB in a container. A container is a standard unit of software that packages up code and all its dependencies. That way, we can create a MongoDB container and run it on our local machine, and we don’t have to install MongoDB locally. When we don’t need the container anymore, we can stop it and remove it.</p>
			<p>In our case, we will use Mongo 7.0.0, which is the latest version of MongoDB. We will use the official image of MongoDB, which is available on Docker Hub. You can find more information about this image at the following link: <a href="https://hub.docker.com/_/mongo">https://hub.docker.com/_/mongo</a>.</p>
			<p>To run MongoDB in a container, we will use the following command:</p>
			<pre class="console">
docker run --name whispering-database -p 27017:27017 -d mongo:7.0.0</pre>			<p>This command will create a container with the name <code>whispering-database</code>, and it will map port <code>27017</code> of the container to port <code>27017</code> of the host machine. The <code>-d</code> flag means that the container will run in the background.</p>
			<p>The output should be something like this:</p>
			<pre class="console">
Unable to find image 'mongo:7.0.0' locally
7.0.0: Pulling from library/mongo
99de9192b4af: Pull complete
18b9e63943e7: Pull complete
ccf1fde52048: Pull complete
8317989437cb: Pull complete
1bde6bf8acc1: Pull complete
11fb005be9eb: Pull complete
81a254c162fc: Pull complete
2a574922bf90: Pull complete
22659e13b0a2: Pull complete
Digest: sha256:a89d79ddc5187f57b1270f87ec581b7cc6fd697efa12b8 f1af72f3c4888d72b5
Status: Downloaded newer image for mongo:7.0.0
27ead2313a72c0cb0d2d1bf18ef2a37062a63851ebc9355359dbc1a4741ac168</pre>			<p>As shown in the<a id="_idIndexMarker717"/> output, the image<a id="_idIndexMarker718"/> was not found locally, so it was downloaded from Docker Hub. You might get an error, if the port 2701 is already in use, as the container can’t take control over. You can easily check this by following these steps (<a href="https://kb.vmware.com/s/article/1003971">https://kb.vmware.com/s/article/1003971</a>).If everything goes well, the container is running in the background, so we can check that it is running with the following command:</p>
			<pre class="console">
docker ps</pre>			<p>The output should be something like this:</p>
			<pre class="console">
CONTAINER ID   IMAGE         COMMAND                  CREATED         STATUS         PORTS                      NAMES
7d28f8c555b9   mongo:7.0.0   "docker-entrypoint.s…"   7 seconds ago   Up 6 seconds   0.0.0.0:27017-&gt;27017/tcp   whispering-database</pre>			<p>You can stop the container with the following command:</p>
			<pre class="console">
docker stop whispering-database</pre>			<p>And you can remove the container with the following command:</p>
			<pre class="console">
docker rm whispering-database</pre>			<p>If you removed the container, you can always<a id="_idIndexMarker719"/> create a new container<a id="_idIndexMarker720"/> again with the following command:</p>
			<pre class="console">
docker run --name whispering-database -p 27017:27017 -d mongo:7.0.0</pre>			<h2 id="_idParaDest-320"><a id="_idTextAnchor328"/>Running MongoDB with Docker Compose</h2>
			<p>An alternative to<a id="_idIndexMarker721"/> running MongoDB<a id="_idIndexMarker722"/> with a container is to use Docker Compose. Docker Compose is a tool to define and run multi-container Docker applications using a YAML file. One of the advantages of using Docker Compose is that we can define the configuration of the container in a YAML file, so we don’t have to remember the commands to run the container.</p>
			<p>Let’s create a <code>docker-compose.yml</code> file with the following content for our project:</p>
			<pre class="source-code">
version: '3.8'
services:
  database:
    container_name: whispering-database
    image: mongo:7.0
    ports:
      - '27017:27017'
    volumes:
      - db-storage:/data/db
volumes:
  db-storage:</pre>			<p>In this file, we define a service called <code>database</code> that uses the <code>mongo:7.0</code> image. We also map port <code>27017</code> of the container to port <code>27017</code> of the host machine. Finally, we define a volume called <code>db-storage</code> that will be used to store the data of the database, so we don’t lose it when we stop the container.</p>
			<p>In order to run the container in the background, we have to run the following command:</p>
			<pre class="console">
docker-compose up -d</pre>			<p>The output should be something like this:</p>
			<pre class="console">
[+] Running 1/1
✓ database Pulled                         1.8s
[+] Running 3/3
✓ Network app_default       Created     0.1s
✓ Volume "app_db-storage"   Created     0.0s
✓ Container app-database-1  Started     0.5s</pre>			<p>Your containers are now ready to use, but you can stop them by running the following command in the same folder:</p>
			<pre class="console">
docker-compose down</pre>			<p>In the next section, we will learn how<a id="_idIndexMarker723"/> to include the<a id="_idIndexMarker724"/> Docker-related commands to the <code>package.json</code> as npm scripts.</p>
			<h2 id="_idParaDest-321"><a id="_idTextAnchor329"/>Adding Docker commands to package.json</h2>
			<p>Sometimes, it is hard<a id="_idIndexMarker725"/> to remember<a id="_idIndexMarker726"/> the docker compose commands, so we can add them to the <code>package.json</code> file. Add the following scripts:</p>
			<pre class="source-code">
"scripts": {
    "start": "node index.js",
    "test": "jest",
    "test:coverage": "jest --coverage",
    "lint": "standard",
    "lint:fix": "standard --fix",
    "infra:start": "docker-compose up -d --build",
    "infra:stop": "docker-compose down --remove-orphans"
}</pre>			<p>Then, we can<a id="_idIndexMarker727"/> use <code>npm run infra:start</code> and <code>npm run infra:stop</code> to manage<a id="_idIndexMarker728"/> the project database on our local machine.</p>
			<h2 id="_idParaDest-322"><a id="_idTextAnchor330"/>Connecting to MongoDB</h2>
			<p>There are two ways to connect to<a id="_idIndexMarker729"/> MongoDB – using the <code>mongo</code> shell or port <code>27017</code>. In this section, we will explain how to connect to MongoDB using both ways.</p>
			<p>We can connect to MongoDB using the <code>mongo</code> shell with the following command if we use Docker:</p>
			<pre class="console">
npm run infra:start
docker exec -it whispering-database /bin/bash</pre>			<p>You can see now that we are inside the container, as an alternative you can use directly the docker compose command to access the container <code>docker-compose exec database /bin/bash</code>. Now, we can connect to MongoDB with the following command:</p>
			<pre class="console">
mongod</pre>			<p>You should see something like this:</p>
			<pre class="console">
root@7d515e1c8f85:/# mongod
{"t":{"$date":"2023-08-19T13:45:08.554+00:00"},"s":"I",  "c":"CONTROL",  "id":23285,   "ctx":"main","msg":"Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'"}
{"t":{"$date":"2023-08-19T13:45:08.556+00:00"},"s":"I",  "c":"NETWORK",  "id":4915701, "ctx":"main","msg":"Initialized wire specification","attr":{"spec":{"incomingExternalClient":{"minWire Version":0,"maxWireVersion":21},"incomingInternalClient":{"minWire Version":0,"maxWireVersion":21},"outgoing":{"minWireVersion":6,"maxWire Version":21},"isInternalClient":true}}}</pre>			<p>This way, we can access a <code>mongo</code> shell directly if needed. In the following sections, we will explain how to connect<a id="_idIndexMarker730"/> to MongoDB using port <code>27017</code>.</p>
			<h2 id="_idParaDest-323"><a id="_idTextAnchor331"/>Other ways to install MongoDB</h2>
			<p>If you don’t want to use<a id="_idIndexMarker731"/> Docker Compose, you can install MongoDB locally. You can find the instructions<a id="_idIndexMarker732"/> for your operating system at the following link: <a href="https://docs.mongodb.com/manual/administration/install-community/">https://docs.mongodb.com/manual/administration/install-community/</a>.</p>
			<p>Remember that you can also<a id="_idIndexMarker733"/> use MongoDB Atlas (<a href="https://www.mongodb.com/atlas">https://www.mongodb.com/atlas</a>) or any other cloud provider that offers MongoDB as a service.</p>
			<p>Now that we have MongoDB running, we can start using it, but first, we need to understand how to use secrets in Node.js so that we can pass the connection string to the application in a safe mode. So, in the next section, we will explain how to load secrets in Node.js.</p>
			<h1 id="_idParaDest-324"><a id="_idTextAnchor332"/>How to load secrets in Node.js</h1>
			<p>Our application will need<a id="_idIndexMarker734"/> to connect to MongoDB, so we need to store the connection string in a safe place. You should never store secrets in your code; a very common practice is to store them in environment variables. In this section, we will explain how to load secrets from environment variables in Node.js.</p>
			<h2 id="_idParaDest-325"><a id="_idTextAnchor333"/>Environment variables</h2>
			<p>Environment variables are variables<a id="_idIndexMarker735"/> that are set in the environment<a id="_idIndexMarker736"/> in which the process runs. They are usually set in the operating system, but we can also set them in the terminal. We can access the environment variables in Node.js using the <code>process.env</code> object:</p>
			<pre class="source-code">
console.log(process.env.MY_SECRET)</pre>			<p>You can set an environment variable in the terminal with the following command:</p>
			<pre class="console">
export MY_SECRET=secret</pre>			<p>Then, you can run your application with the following command:</p>
			<pre class="console">
node index.js</pre>			<p>Alternatively, you can set the environment variable in the same command:</p>
			<pre class="console">
MY_SECRET=secret node index.js</pre>			<p class="callout-heading">Important note</p>
			<p class="callout">If you are using Windows you might need to use a different approach to handle environmental variables<a id="_idIndexMarker737"/> in the terminal. Read (<a href="https://www3.ntu.edu.sg/home/ehchua/programming/howto/Environment_Variables.html">https://www3.ntu.edu.sg/home/ehchua/programming/howto/Environment_Variables.html</a>) for additional information.</p>
			<p>In the next section, we will learn how to use a. <code>.env</code> file to manage the secrets in a more ergonomic way.</p>
			<h2 id="_idParaDest-326"><a id="_idTextAnchor334"/>The .env file</h2>
			<p>While using<a id="_idIndexMarker738"/> environmental varaibles<a id="_idIndexMarker739"/> directly in the terminal  is a very common practice, it is not very convenient. We can use a file called <code>.env</code> to store our environment variables. We can create a <code>.env</code> file with the following content:</p>
			<pre class="source-code">
MY_SECRET=secret</pre>			<p>Then, we can<a id="_idIndexMarker740"/> use the <code>dotenv</code> package (<a href="https://www.npmjs.com/package/dotenv">https://www.npmjs.com/package/dotenv</a>) to load the environment variables from the <code>.env</code> file, but it’s worth mentioning that Node.js 20.6.0 introduced<a id="_idIndexMarker741"/> support for loading environment variables from a <code>.env</code> file, so we don’t need to use third-party packages anymore (<a href="https://github.com/nodejs/node/releases/tag/v20.6.0">https://github.com/nodejs/node/releases/tag/v20.6.0</a>).</p>
			<p class="callout-heading">Warning</p>
			<p class="callout">We should never commit the <code>.env</code> file to the repository because it contains secrets. You can include the <code>.env</code> file into the <code>.gitignore</code> file  to avoid commit the .env file along the project source code.</p>
			<h2 id="_idParaDest-327"><a id="_idTextAnchor335"/>dotenv</h2>
			<p>The most common<a id="_idIndexMarker742"/> way to load<a id="_idIndexMarker743"/> environment variables<a id="_idIndexMarker744"/> from a <code>.env</code> file is to use the <code>dotenv</code> package (<a href="https://www.npmjs.com/package/dotenv">https://www.npmjs.com/package/dotenv</a>). We can install it with the following command:</p>
			<pre class="console">
npm install dotenv@16</pre>			<p>Then, we can load the environment variables from the <code>.env</code> file with the following code:</p>
			<pre class="source-code">
import 'dotenv/config'</pre>			<p>Alternatively, we can do it directly using the <code>--</code><code>require</code> flag:</p>
			<pre class="console">
node --require dotenv/config index.js</pre>			<p>In the next section, we will explain how to use <strong class="bold">Object-Relational Mapping</strong> (<strong class="bold">ORM</strong>) to interact with MongoDB and how this can make our life easier when building a web application for the first time.</p>
			<h1 id="_idParaDest-328"><a id="_idTextAnchor336"/>Using an ORM – Mongoose</h1>
			<p>We can use MongoDB<a id="_idIndexMarker745"/> directly, but<a id="_idIndexMarker746"/> it will require a bigger understanding and more code to interact with the database. As the objective of this book is to learn Node.js, we will use an ORM to interact with MongoDB. An ORM is a library that allows us to interact with a database using objects instead of SQL queries. In this section, we will<a id="_idIndexMarker747"/> use Mongoose (<a href="https://mongoosejs.com/">https://mongoosejs.com/</a>). Alternatively, you can use MongoDB Node.js Driver, which is the official <a id="_idIndexMarker748"/>MongoDB driver (<a href="https://docs.mongodb.com/drivers/node/">https://docs.mongodb.com/drivers/node/</a>) for Node.js. The official<a id="_idIndexMarker749"/> documentation can be found at <a href="https://mongoosejs.com/docs/guide.html">https://mongoosejs.com/docs/guide.html</a>.</p>
			<p>Mongoose offers several features<a id="_idIndexMarker750"/> that are quite convenient for a web application:</p>
			<ul>
				<li><strong class="bold">Schema validation</strong>: We can define the schema of the documents, and Mongoose will validate the data before saving it to the database</li>
				<li><strong class="bold">Model</strong>: We can define a model for each collection, and we can use it to interact with the database</li>
				<li><strong class="bold">Middleware</strong>: We can define middleware functions that will be executed before or after certain events – for example, we can define a middleware function that will be executed before saving a document to the database</li>
				<li><strong class="bold">Plugins</strong>: We can use plugins to extend the functionality of Mongoose</li>
			</ul>
			<p>Also, if you are new to Node.js or MongoDB, you will find Mongoose easier to use than MongoDB directly, and there are plenty of tutorials and resources that you can use to get used to it quickly.</p>
			<p class="callout-heading">Info</p>
			<p class="callout">Mongo has a huge ecosystem, and it might be a bit overwhelming at the beginning, but you can find a curated list of awesome MongoDB resources at <a href="https://github.com/ramnes/awesome-mongodb">https://github.com/ramnes/awesome-mongodb</a>.</p>
			<p>Now that we have MongoDB running and are familiar with the environment variables, we can start using Mongoose in our project. In the next section, we will explain how to migrate from local file storage to MongoDB.</p>
			<h1 id="_idParaDest-329"><a id="_idTextAnchor337"/>Migrating a web application to MongoDB</h1>
			<p>We already added MongoDB<a id="_idIndexMarker751"/> to our project using Docker Compose and npm commands, but we have not started using it yet. In this section, we will migrate a web application to MongoDB.</p>
			<h2 id="_idParaDest-330"><a id="_idTextAnchor338"/>Installing dependencies</h2>
			<p>We will install<a id="_idIndexMarker752"/> the following dependencies:</p>
			<pre class="console">
npm install mongoose@7.4 dotenv@16</pre>			<h2 id="_idParaDest-331"><a id="_idTextAnchor339"/>Managing the secrets</h2>
			<p>We will create a <code>.env</code> file with<a id="_idIndexMarker753"/> the following<a id="_idIndexMarker754"/> content:</p>
			<pre class="console">
MONGODB_URI=mongodb://localhost:27017/whispering-database
PORT=3000</pre>			<p>Then, we will load the environment variables from the <code>.env</code> file with the following code into <code>index.js</code>:</p>
			<pre class="source-code">
import { app } from './server.js'
import mongoose from 'mongoose'
const port = process.env.PORT
try {
  await mongoose.connect(process.env.MONGODB_URI);
  console.log('Connected to MongoDB')
  app.listen(port, () =&gt; {
    console.log(`Running in http://localhost:${port}`)
  })
} catch (error) {
  console.error(error)
}</pre>			<p>We have included the <code>mongoose</code> package<a id="_idIndexMarker755"/> and have connected to MongoDB using the <code>MONGODB_URI</code> environment<a id="_idIndexMarker756"/> variable. We have also included the <code>PORT</code> environment variable to run the application in a different port.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">As you can see, the database must be running before we open the HTTP server connection. This is because we need to connect to the database to retrieve the information for our response to the HTTP requests.</p>
			<p>Now, we need to update the npm scripts to use <code>dotenv</code>:</p>
			<pre class="source-code">
"scripts": {
    "start": "node --require dotenv/config index.js",
    "test": "jest --setupFiles dotenv/config",
    "test:coverage": "jest --coverage --setupFiles dotenv/config",
    "lint": "standard",
    "lint:fix": "standard --fix",
    "infra:start": "docker-compose up -d --build",
    "infra:stop": "docker-compose down"
}</pre>			<p>Now, we can run the application with the following command:</p>
			<pre class="console">
npm run infra:start
npm run start</pre>			<p>We should see the following output:</p>
			<pre class="console">
Connected to MongoDB
Running in http://localhost:3000</pre>			<p>If the database<a id="_idIndexMarker757"/> is not running, we will see<a id="_idIndexMarker758"/> a similar error:</p>
			<pre class="source-code">
MongooseServerSelectionError: connect ECONNREFUSED ::1:27017, connect 
ECONNREFUSED 127.0.0.1:27017
    at _handleConnectionErrors (node_modules/mongoose/lib/connection.js:788:11)
    at NativeConnection.openUri (node_modules/mongoose/lib/connection.js:763:11)
    at async file:///index.js:7:4 {
  reason: TopologyDescription {
    type: 'Unknown',
    servers: Map(1) { 'localhost:27017' =&gt; [ServerDescription] },
    stale: false,
    compatible: true,
    heartbeatFrequencyMS: 10000,
    localThresholdMS: 15,
    setName: null,
    maxElectionId: null,
    maxSetVersion: null,
    commonWireVersion: 0,
    logicalSessionTimeoutMinutes: null
  },
  code: undefined
}</pre>			<p>Basically, it tells us that<a id="_idIndexMarker759"/> it cannot connect<a id="_idIndexMarker760"/> to the database; you can generate the same errors just by running the following:</p>
			<pre class="console">
npm run infra:stop
npm run start</pre>			<p>In the next section we will start to work on the data layer migration.</p>
			<h2 id="_idParaDest-332"><a id="_idTextAnchor340"/>Migrating the data layer</h2>
			<p>We want to refactor<a id="_idIndexMarker761"/> the <code>store.js</code> file to use MongoDB<a id="_idIndexMarker762"/> instead of a JSON file. Just to keep things simple, we will add the schema and model to the same file, but this can be changed later when we introduce authentication in the next chapter.</p>
			<p>It is considered good practice to encapsulate the database-related code in specific files, with the idea of providing an interface that can later be used by other parts of our code to make changes in the data layer, without the need to understand how the data layer is implemented under the hood. This kind of abstraction is a very popular solution and will bring you a lot of support if you decide to migrate or combine other storage systems in the future. So, we will create a new file called <code>database.js</code> and explore together in the following paragraphs how it is structured and what is achieved in each statement. The file content is the following:</p>
			<pre class="source-code">
import mongoose from 'mongoose'
mongoose.set('toJSON', {
  virtuals: true,
  transform: (doc, converted) =&gt; {
    delete converted._id
    delete converted.__v
  }
})
const whisperSchema = new mongoose.Schema({
  message: String
})
const Whisper = mongoose.model('Whisper', whisperSchema)
export {
  Whisper
}</pre>			<p><strong class="bold">Creating </strong><strong class="bold">the schema</strong></p>
			<p>The first step is to <a id="_idIndexMarker763"/>create the schema, which is the definition<a id="_idIndexMarker764"/> of the structure of the documents that we are going to store in the database. In our case, we only have one field called <code>message</code>, which is a string:</p>
			<pre class="source-code">
const whisperSchema = new mongoose.Schema({
  message: String
})</pre>			<p><strong class="bold">Creating </strong><strong class="bold">the model</strong></p>
			<p>The second step is to create the model, which is a class that we use to interact with the database. In our case, we will use the <code>Whisper</code> model to interact with the <code>whispers</code> collection:</p>
			<pre class="source-code">
const Whisper = mongoose.model('Whisper', whisperSchema)</pre>			<p><strong class="bold">Transformers</strong></p>
			<p>One of the things that we have to do is to remove the <code>_id</code> and <code>__v</code> fields from the response. We can change this behavior globally so that we don’t have to do it for every method, using the <code>toJSON</code> method:</p>
			<pre class="source-code">
mongoose.set('toJSON', {
  virtuals: true,
  transform: (doc, converted) =&gt; {
    delete converted._id;
    delete converted.__v;
  }
});</pre>			<p>This means we start with the following data structure:</p>
			<pre class="source-code">
{
  "_id": "5dff03d3218b91425b9d6fab",
  "message": "I love MongoDB!",
  "__v": 0
}</pre>			<p>Then, we move on to the following data structure:</p>
			<pre class="source-code">
{
  "id": "5dff03d3218b91425b9d6fab",
  "message": "I love MongoDB!"
}</pre>			<p><strong class="bold">Refactored methods</strong></p>
			<p>The key in this migration is to keep<a id="_idIndexMarker765"/> the same interface <a id="_idIndexMarker766"/>so that we don’t have to change the behavior of the functions that we export. We will use the same data I/O, but we will use Mongoose to interact with MongoDB:</p>
			<pre class="source-code">
import {
  Whisper
} from './database.js'
const getAll = () =&gt; Whisper.find()
const getById = id =&gt; Whisper.findById({ _id: id })
const create = async (message) =&gt; {
  const whisper = new Whisper({ message })
  await whisper.save()
  return whisper
}
const updateById = async (id, message) =&gt; Whisper.findOneAndUpdate({ _id: id }, { message }, { new: false })
const deleteById = async (id) =&gt; Whisper.deleteOne({ _id: id })
export { getAll, getById, create, updateById, deleteById }</pre>			<p>As you can see, we keep the same input and output in every method (<code>getAll</code>, <code>getById</code>, <code>create</code>, <code>updateById</code>, <code>deleteById</code>), so we don’t have to change the behavior of the functions that we export.</p>
			<p>This is the effect that<a id="_idIndexMarker767"/> we discussed<a id="_idIndexMarker768"/> in the previous chapter; we can change the implementation of the methods, but we don’t have to change the interface. This is the power of abstraction.</p>
			<p>So, even if you want to change the database in the future, you don’t have to change the interface of the methods; you just have to change the implementation and the code still works. This is because the business logic is not coupled to the database interface.</p>
			<p><strong class="bold">Removing the old </strong><strong class="bold">database file</strong></p>
			<p>Now, we can remove the <code>db.json</code> file because we are not using it anymore.</p>
			<p><strong class="bold">Improve </strong><strong class="bold">the routes</strong></p>
			<p>In the previous chapter, we used numerical IDs, just to keep the code more simple, so now, we need to change the routes to use the MongoDB IDs, which are alphanumerical strings. We only need to remove the references to <code>parseInt</code> in the <code>server.js</code> file. The change is from <code>parseInt(req.params.id)</code> to <code>req.params.id</code>. You can even use <em class="italic">Find and Replace</em> to change all the references to <code>parseInt</code> in the file.</p>
			<p><strong class="bold">Running </strong><strong class="bold">the application</strong></p>
			<p>At this point, you can just enjoy the migration by running the following:</p>
			<pre class="console">
npm run infra:start
npm run start</pre>			<p>And if you go to <code>http://localhost:3000</code>, you can see the application working with MongoDB without any change in the interface.</p>
			<p>Now, we are certain<a id="_idIndexMarker769"/> that the application<a id="_idIndexMarker770"/> is working as expected, but we shouldn’t forget to properly test these changes. So, in the next section, we will refactor the tests to use MongoDB, and we will be able to move to the next chapter once all the tests are passing (green) as the refactor will be completed.</p>
			<h1 id="_idParaDest-333"><a id="_idTextAnchor341"/>Testing our MongoDB integration layer</h1>
			<p>Yes, we have made the migration<a id="_idIndexMarker771"/> and everything seems to be running fine, but we need to ensure that the tests work as expected. Currently, the tests use the filesystem to store data, so we need to change the tests to make them use MongoDB.</p>
			<h2 id="_idParaDest-334"><a id="_idTextAnchor342"/>Update the utilities</h2>
			<p>We will edit the <code>test/utils.js</code> file to use MongoDB<a id="_idIndexMarker772"/> instead of the filesystem. As we are now using MongoDB, we need to load the fixtures in the database to know the IDs. So now, the fixtures will keep the same structure, but they will be stored and collected in the database using <code>populateDb</code> and the new <code>getFixtures</code> function:</p>
			<pre class="source-code">
import mongoose from 'mongoose'
import {
  Whisper
} from '../database.js'
const ensureDbConnection = async () =&gt; {
   try {
        if (mongoose.connection.readyState !== 1) {
            await mongoose.connect(process.env.MONGODB_URI);
        }
    } catch (error) {
        console.error('Error connecting to the database:', error);
        throw error; // Re-throw the error for handling at a higher level
    }
}
const closeDbConnection = async () =&gt; {
    if (mongoose.connection.readyState === 1) {
        await mongoose.disconnect()
    }
}
const restoreDb = () =&gt; Whisper.deleteMany({})
const populateDb = () =&gt; Whisper.insertMany([{ message: 'test' }, { message: 'hello world' }])
const getFixtures = async () =&gt; {
    const data = await Whisper.find()
    const whispers = JSON.parse(JSON.stringify(data))
    const inventedId = '64e0e5c75a4a3c715b7c1074'
    const existingId = data[0].id
    return { inventedId, existingId, whispers }
}
const normalize = (data) =&gt; JSON.parse(JSON.stringify(data))
export { restoreDb, populateDb, getFixtures, ensureDbConnection, normalize, closeDbConnection }</pre>			<p>Now, we can delete<a id="_idIndexMarker773"/> the <code>test/fixtures.js</code> file because we are not using it anymore.</p>
			<h2 id="_idParaDest-335"><a id="_idTextAnchor343"/>Refactoring the test suite</h2>
			<p>So far, we have more tests<a id="_idIndexMarker774"/> than the ones that we really need. We can remove specific tests for the stores, as they are already covered by the integration tests, and we can remove the <code>test/store.test.js</code> file.</p>
			<p>As part of the migration, we need to make some changes in how the tests are prepared to be executed. As a database is an external service, we need to control certain aspects before we execute the test. For example, we need a proper database connection working before we execute any test, as this can be a failure cause for the tests but is not related to the code that we are testing. Also, we need to be sure that the database has specific data stored in it so that our tests can be executed independently multiple times, without polluting the execution context between executions with the modifications that we make in the database. This can be achieved by adding certain steps before any specific test is executed, with methods such as <code>beforeAll</code>, <code>beforeEach</code>, <code>afterAll</code>, and <code>afterEach</code>, which are part of the Jest methods available to us. Now, let’s update the tests to use the new functions. We will update the <code>test/server.test.js</code> file to use the new functions:</p>
			<pre class="source-code">
import supertest from 'supertest'
import { app } from '../server'
import { getById } from '../store.js'
import { restoreDb, populateDb, getFixtures,
ensureDbConnection, normalize, closeDbConnection } from './utils.js'
let whispers
let inventedId
let existingId
describe('Server', () =&gt; {
  beforeAll(ensureDbConnection)
  beforeEach(async () =&gt; {
    await restoreDb()
    await populateDb(whispers)
    const fixtures = await getFixtures()
    whispers = fixtures.whispers
    inventedId = fixtures.inventedId
    existingId = fixtures.existingId
  })
  afterAll(closeDbConnection)
  //... unchanged tests
})</pre>			<p>In the next section, we will finish<a id="_idIndexMarker775"/> updating the test suite cases, as MongoDB introduced small differences that we need to take into account when querying data in the test context.</p>
			<h2 id="_idParaDest-336"><a id="_idTextAnchor344"/>Some tests must change</h2>
			<p>Just to keep it simple, for the scope<a id="_idIndexMarker776"/> of the book, some tests have to change. All the tests that are use store will be refactored as follows.</p>
			<p>When creating or updating whispers, we will check in the database that the whispers are stored correctly. In order to properly compare the data, we will use the <code>normalize</code> function. That way, we can compare the data without the <code>_id</code> and <code>__v</code> fields and in a normalized way, as we do when converting data to JSON while sending the HTTP response:</p>
			<pre class="source-code">
it('Should return a 201 when the whisper is created', async () =&gt; {
    const newWhisper = { message: 'This is a new whisper' }
    const response = await supertest(app)
    .post('/api/v1/whisper')
    .send({ message: newWhisper.message })
    expect(response.status).toBe(201)
    expect(response.body.message).toEqual(newWhisper.message)
    // Database changes
    const storedWhisper = await getById(response.body.id)
    expect(normalize(storedWhisper).message).toStrictEqual(newWhisper.message)
})
it('Should return a 200 when the whisper is updated', async () =&gt; {
    const response = await supertest(app)
    .put(`/api/v1/whisper/${existingId}`)
    .send({ message: 'Whisper updated' })
    expect(response.status).toBe(200)
    // Database changes
    const storedWhisper = await getById(existingId)
    expect(normalize(storedWhisper)).toStrictEqual({ id: existingId, message: 'Whisper updated' })
})</pre>			<p>When deleting a whisper, we need to check that the whisper is not in the database anymore. Previously, we checked that the database returned <code>undefined</code> when not found; using MongoDB, we will get <code>null</code> instead, so we need to change the test as follows:</p>
			<pre class="source-code">
it('Should return a 200 when the whisper is deleted', async () =&gt; {
    const response = await supertest(app).delete(`/api/v1/whisper/${existingId}`)
    expect(response.status).toBe(200)
    // Database changes
    const storedWhisper = await getById(existingId)
    expect(storedWhisper).toBe(null)
})</pre>			<p>As we finished to refactor<a id="_idIndexMarker777"/> the tests, it is a great moment to review the testing coverage. In this section we will review this in detail.</p>
			<h2 id="_idParaDest-337"><a id="_idTextAnchor345"/>Checking the coverage</h2>
			<p>Now, we can run the tests<a id="_idIndexMarker778"/> and check the coverage:</p>
			<pre class="console">
npm run infra:start
npm run test:coverage</pre>			<p>The output should be similar:</p>
			<pre class="console">
--------------|---------|----------|---------|---------|-------------------
File          | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s
--------------|---------|----------|---------|---------|-------------------
All files     |   97.43 |    85.71 |   94.44 |   97.18 |
app          |   96.66 |      100 |   91.66 |   96.42 |
  database.js |     100 |      100 |     100 |     100 |
  server.js   |   95.34 |      100 |   83.33 |   95.34 | 11-12
  store.js    |     100 |      100 |     100 |     100 |
app/tests    |     100 |       50 |     100 |     100 |
  utils.js    |     100 |       50 |     100 |     100 | 7-12
--------------|---------|----------|---------|---------|-------------------
Test Suites: 1 passed, 1 total
Tests:       13 passed, 13 total
Snapshots:   0 total
Time:        1.945 s, estimated 2 s
Ran all test suites.</pre>			<p>Basically, we have the same coverage<a id="_idIndexMarker779"/> as before, but we have removed some tests, and the <code>store.js</code> file is covered up to 100%.</p>
			<p>As we can see, there is a line that is not covered (<em class="italic">11–12</em>), in <code>server.js</code>. In the previous chapter, we added a new route to render the template in <code>GET /about</code>, but we forgot to add proper tests. So, let’s add the following test:</p>
			<pre class="source-code">
describe('/about', () =&gt; {
    it('Should return a 200 with the total whispers in the platform', async () =&gt; {
        const response = await supertest(app).get('/about')
        expect(response.status).toBe(200)
        expect(response.text).toContain(`Currently there are ${whispers.length} whispers available`)
    })
})</pre>			<p>If you run the tests again, you will see that the line is covered now and the coverage has increased to 100%. We can also improve the scoring by removing from the coverage report the <code>tests</code> folder, which we can do by adding the following line to the <code>jest.config.js</code> file:</p>
			<pre class="source-code">
export default {
  modulePathIgnorePatterns: ['&lt;rootDir&gt;/node_test/'],
  "coveragePathIgnorePatterns": [
    "&lt;rootDir&gt;/tests/"
  ]
}</pre>			<p>It is very important to keep a clear scope on what files you need to track or not for your coverage report; otherwise, the code coverage will become just a metric that won’t guide you to focus on the most critical application parts. It is quite common to read articles about the frustration associated with a 100% coverage target, when, in most cases, we don’t need to aim for that big number, and we should be clear on what parts of the code don’t need to be tested.</p>
			<p>No matter whether you work<a id="_idIndexMarker780"/> alone or in a team, having precise metrics will increase the developer experience for all the humans involved in a project. As you can see, the coverage is now 100%, as we ignored the files that we are not planning to test:</p>
			<pre class="console">
PASS  tests/server.test.js
  Server
    GET /about
      ✓ Should return a 200 with the total whispers in the platform (61 ms)
    GET /api/v1/whisper
      ✓ Should return an empty array when there's no data (19 ms)
      ✓ Should return all the whispers (14 ms)
    GET /api/v1/whisper/:id
      ✓ Should return a 404 when the whisper doesn't exist (14 ms)
      ✓ Should return a whisper details (12 ms)
    POST /api/v1/whisper
      ✓ Should return a 400 when the body is empty (27 ms)
      ✓ Should return a 400 when the body is invalid (9 ms)
      ✓ Should return a 201 when the whisper is created (17 ms)
    PUT /api/v1/whisper/:id
      ✓ Should return a 400 when the body is empty (9 ms)
      ✓ Should return a 400 when the body is invalid (9 ms)
      ✓ Should return a 404 when the whisper doesn't exist (11 ms)
      ✓ Should return a 200 when the whisper is updated (18 ms)
    DELETE /api/v1/whisper/:id
      ✓ Should return a 404 when the whisper doesn't exist (10 ms)
      ✓ Should return a 200 when the whisper is deleted (13 ms)
-------------|---------|----------|---------|---------|-------------------
File         | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s
-------------|---------|----------|---------|---------|-------------------
All files    |     100 |      100 |     100 |     100 |
database.js |     100 |      100 |     100 |     100 |
server.js   |     100 |      100 |     100 |     100 |
store.js    |     100 |      100 |     100 |     100 |
-------------|---------|----------|---------|---------|-------------------
Test Suites: 1 passed, 1 total
Tests:       14 passed, 14 total
Snapshots:   0 total
Time:        2.024 s, estimated 3 s
Ran all test suites.</pre>			<p class="callout-heading">Information</p>
			<p class="callout">If you are having issues running the project in this chapter while following the steps, or you tried an alternative approach, you can use the <code>step3</code> folder from the source code that you downloaded at the beginning of the chapter to compare and fix possible bugs more easily.</p>
			<p>Now, that we have finished<a id="_idIndexMarker781"/> with the migration, it is time to do a recap in the next section.</p>
			<h1 id="_idParaDest-338"><a id="_idTextAnchor346"/>Summary</h1>
			<p>In this chapter, we learned how MongoDB is different from other databases. We learned how to install MongoDB locally using containers, with Docker and Docker Compose.</p>
			<p>Additionally, we explored how we can manage sensitive information in our application using environment variables and the <code>dotenv</code> package. We also learned how to use Mongoose to interact with MongoDB.</p>
			<p>Finally, we migrated our application to use MongoDB instead of a JSON file. This gave us the opportunity to properly learn how to refactor and reorganize our previous code. This migration also made it easy to maintain and deploy the application, as data is stored and queried as an external source. This will help us to scale a lot in the future, as we can connect multiple replicas of our backend to the same database instance. We also learned how to test our application using MongoDB, and we used this testing approach to ensure that the migration was completed successfully.</p>
			<p>In the next chapter, we will introduce authentication and authorization to our application. We will use JWT to authenticate users and use middleware to protect the routes that require authentication. Also, we will refactor code to use a database to store users and use <code>bcrypt</code> library to hash the passwords. Finally, multiple users will be able to use our application, which will include private whispers.</p>
			<h1 id="_idParaDest-339"><a id="_idTextAnchor347"/>Further reading</h1>
			<ul>
				<li>Fireship | MongoDB in 100 Seconds: <a href="https://www.youtube.com/watch?v=-bt_y4Loofg">https://www.youtube.com/watch?v=-bt_y4Loofg</a></li>
				<li>I Would Never Use an ORM, by Matteo Collina: <a href="https://www.youtube.com/watch?v=qfRQ5zhYuJE">https://www.youtube.com/watch?v=qfRQ5zhYuJE</a></li>
				<li>MongoDB in 5 Minutes with Eliot Horowitz: <a href="https://www.youtube.com/watch?v=EE8ZTQxa0AM">https://www.youtube.com/watch?v=EE8ZTQxa0AM</a></li>
				<li>MongoDB Explained in 10 Minutes | SQL vs NoSQL | Jumpstart: <a href="https://www.youtube.com/watch?v=RGfFpQF0NpE">https://www.youtube.com/watch?v=RGfFpQF0NpE</a></li>
			</ul>
		</div>
	</body></html>