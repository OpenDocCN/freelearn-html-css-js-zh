<html><head></head><body>
		<div id="_idContainer083">
			<h1 id="_idParaDest-312" class="chapter-number"><a id="_idTextAnchor320"/>12</h1>
			<h1 id="_idParaDest-313"><a id="_idTextAnchor321"/> Data Persistence with MongoDB</h1>
			<p>In this chapter, we will explain how MongoDB works and why it is a great starting point for a web application. We will learn how to install MongoDB locally using containers with Docker and Docker Compose and also how to use external <span class="No-Break">MongoDB instances.</span></p>
			<p>We will explore how to use Mongoose to interact with MongoDB, and we will migrate our application to use MongoDB instead of a JSON file,  we will use tests to grant that the migration was properly done and we didn’t introduce <span class="No-Break">any regression.</span></p>
			<p>In summary, here are the main topics that we will explore in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>How to set up MongoDB locally using containers with Docker and <span class="No-Break">Docker Compose</span></li>
				<li>How to use an <strong class="bold">Object–relational mapping</strong> (<strong class="bold">ORM</strong>) library such as Mongoose to interact <span class="No-Break">with MongoDB</span></li>
				<li>How to migrate our application to use MongoDB instead of a <span class="No-Break">JSON file</span></li>
				<li>How to test any application <span class="No-Break">using MongoDB</span></li>
				<li>How to use environment variables to store sensitive information and how to load them <span class="No-Break">in Node.js</span></li>
			</ul>
			<p>By the end of this chapter, you will be comfortable using MongoDB in your Node.js projects, and you will know how to use tests to plan more complicated features such as a <span class="No-Break">database migration.</span></p>
			<h1 id="_idParaDest-314"><a id="_idTextAnchor322"/>Technical requirements</h1>
			<p>The code files for the chapter can be found <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/NodeJS-for-Beginners"><span class="No-Break">https://github.com/PacktPublishing/NodeJS-for-Beginners</span></a><span class="No-Break">.</span></p>
			<p>Check out the code in action video for this chapter <span class="No-Break">on </span><a href="https://youtu.be/0CHOQ35c-_Y"><span class="No-Break">https://youtu.be/0CHOQ35c-_Y</span></a></p>
			<p>To start working on this chapter, we need to download the project from  <a href="https://github.com/PacktPublishing/NodeJS-for-Beginners/archive/refs/heads/main.zip">https://github.com/PacktPublishing/NodeJS-for-Beginners/archive/refs/heads/main.zip</a> and access the <span class="No-Break"><strong class="source-inline">step2</strong></span><span class="No-Break"> folder.</span></p>
			<h1 id="_idParaDest-315"><a id="_idTextAnchor323"/>What is MongoDB?</h1>
			<p>If you are familiar with relational<a id="_idIndexMarker706"/> databases, you will find MongoDB very different. MongoDB is a document-oriented database, which means that it stores data in documents instead of tables. A document is a set of key-value pairs, and it is the basic unit of data in MongoDB. Documents are similar to JSON objects, and they are stored in a collection. A collection is a group of documents that have the same structure. In MongoDB, documents are stored in <strong class="bold">Binary JSON</strong> (<strong class="bold">BSON</strong>), a binary representation of <span class="No-Break">JSON</span><span class="No-Break"><a id="_idIndexMarker707"/></span><span class="No-Break"> documents.</span></p>
			<div>
				<div id="_idContainer082" class="IMG---Figure">
					<img src="image/B21678_12_1.jpg" alt="Figure 12.1 – A SQL data structure compared to a MongoDB data structure"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.1 – A SQL data structure compared to a MongoDB data structure</p>
			<p>In the preceding diagram, we can see the difference between a relational database and a document-oriented database <span class="No-Break">more clearly.</span></p>
			<h2 id="_idParaDest-316"><a id="_idTextAnchor324"/>Versions</h2>
			<p>There are several versions<a id="_idIndexMarker708"/> of MongoDB, but the most popular is MongoDB Community Server. In our project, we will also use MongoDB Community Server as well, at no extra cost <span class="No-Break">to us.</span></p>
			<p>In <a href="B21678_16.xhtml#_idTextAnchor416"><span class="No-Break"><em class="italic">Chapter 16</em></span></a>, we will explore more versions of MongoDB when we deploy our application to <span class="No-Break">the cloud.</span></p>
			<p>If you want to know more about the different<a id="_idIndexMarker709"/> versions of MongoDB, you can check out the following <span class="No-Break">link: </span><a href="https://www.mongodb.com/try/download/community"><span class="No-Break">https://www.mongodb.com/try/download/community</span></a></p>
			<p>In the next section, we will explain how to install MongoDB locally using containers with Docker and Docker Compose, as well as how to use external <span class="No-Break">MongoDB instances.</span></p>
			<h1 id="_idParaDest-317"><a id="_idTextAnchor325"/>Setting up MongoDB</h1>
			<p>There are several ways to install<a id="_idIndexMarker710"/> MongoDB, but we will use Docker Compose to install it locally. Docker Compose is a tool for defining and running multi-container Docker applications. With Docker Compose, we will be able to run MongoDB and our web application in different containers. If you are not familiar with Docker, there is a fantastic guide from MongoDB (<a href="https://www.mongodb.com/compatibility/docker">https://www.mongodb.com/compatibility/docker</a>) that can help you get a <span class="No-Break">deeper understanding.</span></p>
			<h2 id="_idParaDest-318"><a id="_idTextAnchor326"/>Installing Docker</h2>
			<p>If you don’t have Docker<a id="_idIndexMarker711"/> installed, you can follow<a id="_idIndexMarker712"/> the instructions at <a href="https://docs.docker.com/get-docker/">https://docs.docker.com/get-docker/</a>, depending on your <span class="No-Break">operating system.</span></p>
			<h3>Checking the installation</h3>
			<p>Let’s check that Docker<a id="_idIndexMarker713"/> is installed correctly. Open a terminal and run the <span class="No-Break">following command:</span></p>
			<pre class="console">
docker --version</pre>			<p>You should see the version installed – in my <span class="No-Break">case, 24.0.2:</span></p>
			<pre class="console">
Docker version 24.0.2, build cb74dfc</pre>			<p>We can also check that Docker Compose is installed correctly. Open a terminal and run the <span class="No-Break">following command:</span></p>
			<pre class="console">
docker-compose --version</pre>			<p>You should see something<a id="_idIndexMarker714"/> <span class="No-Break">like this:</span></p>
			<pre class="console">
Docker Compose version v2.19.1</pre>			<h2 id="_idParaDest-319"><a id="_idTextAnchor327"/>Running MongoDB with a container</h2>
			<p>The beauty of Docker<a id="_idIndexMarker715"/> is that we can<a id="_idIndexMarker716"/> run MongoDB in a container. A container is a standard unit of software that packages up code and all its dependencies. That way, we can create a MongoDB container and run it on our local machine, and we don’t have to install MongoDB locally. When we don’t need the container anymore, we can stop it and <span class="No-Break">remove it.</span></p>
			<p>In our case, we will use Mongo 7.0.0, which is the latest version of MongoDB. We will use the official image of MongoDB, which is available on Docker Hub. You can find more information about this image at the following <span class="No-Break">link: </span><a href="https://hub.docker.com/_/mongo"><span class="No-Break">https://hub.docker.com/_/mongo</span></a><span class="No-Break">.</span></p>
			<p>To run MongoDB in a container, we will use the <span class="No-Break">following command:</span></p>
			<pre class="console">
docker run --name whispering-database -p 27017:27017 -d mongo:7.0.0</pre>			<p>This command will create a container with the name <strong class="source-inline">whispering-database</strong>, and it will map port <strong class="source-inline">27017</strong> of the container to port <strong class="source-inline">27017</strong> of the host machine. The <strong class="source-inline">-d</strong> flag means that the container will run in <span class="No-Break">the background.</span></p>
			<p>The output should be something <span class="No-Break">like this:</span></p>
			<pre class="console">
Unable to find image 'mongo:7.0.0' locally
7.0.0: Pulling from library/mongo
99de9192b4af: Pull complete
18b9e63943e7: Pull complete
ccf1fde52048: Pull complete
8317989437cb: Pull complete
1bde6bf8acc1: Pull complete
11fb005be9eb: Pull complete
81a254c162fc: Pull complete
2a574922bf90: Pull complete
22659e13b0a2: Pull complete
Digest: sha256:a89d79ddc5187f57b1270f87ec581b7cc6fd697efa12b8 f1af72f3c4888d72b5
Status: Downloaded newer image for mongo:7.0.0
27ead2313a72c0cb0d2d1bf18ef2a37062a63851ebc9355359dbc1a4741ac168</pre>			<p>As shown in the<a id="_idIndexMarker717"/> output, the image<a id="_idIndexMarker718"/> was not found locally, so it was downloaded from Docker Hub. You might get an error, if the port 2701 is already in use, as the container can’t take control over. You can easily check this by following these steps (<a href="https://kb.vmware.com/s/article/1003971">https://kb.vmware.com/s/article/1003971</a>).If everything goes well, the container is running in the background, so we can check that it is running with the <span class="No-Break">following command:</span></p>
			<pre class="console">
docker ps</pre>			<p>The output should be something <span class="No-Break">like this:</span></p>
			<pre class="console">
CONTAINER ID   IMAGE         COMMAND                  CREATED         STATUS         PORTS                      NAMES
7d28f8c555b9   mongo:7.0.0   "docker-entrypoint.s…"   7 seconds ago   Up 6 seconds   0.0.0.0:27017-&gt;27017/tcp   whispering-database</pre>			<p>You can stop the container with the <span class="No-Break">following command:</span></p>
			<pre class="console">
docker stop whispering-database</pre>			<p>And you can remove the container with the <span class="No-Break">following command:</span></p>
			<pre class="console">
docker rm whispering-database</pre>			<p>If you removed the container, you can always<a id="_idIndexMarker719"/> create a new container<a id="_idIndexMarker720"/> again with the <span class="No-Break">following command:</span></p>
			<pre class="console">
docker run --name whispering-database -p 27017:27017 -d mongo:7.0.0</pre>			<h2 id="_idParaDest-320"><a id="_idTextAnchor328"/>Running MongoDB with Docker Compose</h2>
			<p>An alternative to<a id="_idIndexMarker721"/> running MongoDB<a id="_idIndexMarker722"/> with a container is to use Docker Compose. Docker Compose is a tool to define and run multi-container Docker applications using a YAML file. One of the advantages of using Docker Compose is that we can define the configuration of the container in a YAML file, so we don’t have to remember the commands to run <span class="No-Break">the container.</span></p>
			<p>Let’s create a <strong class="source-inline">docker-compose.yml</strong> file with the following content for <span class="No-Break">our project:</span></p>
			<pre class="source-code">
version: '3.8'
services:
  database:
    container_name: whispering-database
    image: mongo:7.0
    ports:
      - '27017:27017'
    volumes:
      - db-storage:/data/db
volumes:
  db-storage:</pre>			<p>In this file, we define a service called <strong class="source-inline">database</strong> that uses the <strong class="source-inline">mongo:7.0</strong> image. We also map port <strong class="source-inline">27017</strong> of the container to port <strong class="source-inline">27017</strong> of the host machine. Finally, we define a volume called <strong class="source-inline">db-storage</strong> that will be used to store the data of the database, so we don’t lose it when we stop <span class="No-Break">the container.</span></p>
			<p>In order to run the container in the background, we have to run the <span class="No-Break">following command:</span></p>
			<pre class="console">
docker-compose up -d</pre>			<p>The output should be something <span class="No-Break">like this:</span></p>
			<pre class="console">
[+] Running 1/1
✓ database Pulled                         1.8s
[+] Running 3/3
✓ Network app_default       Created     0.1s
✓ Volume "app_db-storage"   Created     0.0s
✓ Container app-database-1  Started     0.5s</pre>			<p>Your containers are now ready to use, but you can stop them by running the following command in the <span class="No-Break">same folder:</span></p>
			<pre class="console">
docker-compose down</pre>			<p>In the next section, we will learn how<a id="_idIndexMarker723"/> to include the<a id="_idIndexMarker724"/> Docker-related commands to the <strong class="source-inline">package.json</strong> as <span class="No-Break">npm scripts.</span></p>
			<h2 id="_idParaDest-321"><a id="_idTextAnchor329"/>Adding Docker commands to package.json</h2>
			<p>Sometimes, it is hard<a id="_idIndexMarker725"/> to remember<a id="_idIndexMarker726"/> the docker compose commands, so we can add them to the <strong class="source-inline">package.json</strong> file. Add the <span class="No-Break">following scripts:</span></p>
			<pre class="source-code">
"scripts": {
    "start": "node index.js",
    "test": "jest",
    "test:coverage": "jest --coverage",
    "lint": "standard",
    "lint:fix": "standard --fix",
    "infra:start": "docker-compose up -d --build",
    "infra:stop": "docker-compose down --remove-orphans"
}</pre>			<p>Then, we can<a id="_idIndexMarker727"/> use <strong class="source-inline">npm run infra:start</strong> and <strong class="source-inline">npm run infra:stop</strong> to manage<a id="_idIndexMarker728"/> the project database on our <span class="No-Break">local machine.</span></p>
			<h2 id="_idParaDest-322"><a id="_idTextAnchor330"/>Connecting to MongoDB</h2>
			<p>There are two ways to connect to<a id="_idIndexMarker729"/> MongoDB – using the <strong class="source-inline">mongo</strong> shell or port <strong class="source-inline">27017</strong>. In this section, we will explain how to connect to MongoDB using <span class="No-Break">both ways.</span></p>
			<p>We can connect to MongoDB using the <strong class="source-inline">mongo</strong> shell with the following command if we <span class="No-Break">use Docker:</span></p>
			<pre class="console">
npm run infra:start
docker exec -it whispering-database /bin/bash</pre>			<p>You can see now that we are inside the container, as an alternative you can use directly the docker compose command to access the container <strong class="source-inline">docker-compose exec database /bin/bash</strong>. Now, we can connect to MongoDB with the <span class="No-Break">following command:</span></p>
			<pre class="console">
mongod</pre>			<p>You should see something <span class="No-Break">like this:</span></p>
			<pre class="console">
root@7d515e1c8f85:/# mongod
{"t":{"$date":"2023-08-19T13:45:08.554+00:00"},"s":"I",  "c":"CONTROL",  "id":23285,   "ctx":"main","msg":"Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'"}
{"t":{"$date":"2023-08-19T13:45:08.556+00:00"},"s":"I",  "c":"NETWORK",  "id":4915701, "ctx":"main","msg":"Initialized wire specification","attr":{"spec":{"incomingExternalClient":{"minWire Version":0,"maxWireVersion":21},"incomingInternalClient":{"minWire Version":0,"maxWireVersion":21},"outgoing":{"minWireVersion":6,"maxWire Version":21},"isInternalClient":true}}}</pre>			<p>This way, we can access a <strong class="source-inline">mongo</strong> shell directly if needed. In the following sections, we will explain how to connect<a id="_idIndexMarker730"/> to MongoDB using <span class="No-Break">port </span><span class="No-Break"><strong class="source-inline">27017</strong></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-323"><a id="_idTextAnchor331"/>Other ways to install MongoDB</h2>
			<p>If you don’t want to use<a id="_idIndexMarker731"/> Docker Compose, you can install MongoDB locally. You can find the instructions<a id="_idIndexMarker732"/> for your operating system at the following <span class="No-Break">link: </span><a href="https://docs.mongodb.com/manual/administration/install-community/"><span class="No-Break">https://docs.mongodb.com/manual/administration/install-community/</span></a><span class="No-Break">.</span></p>
			<p>Remember that you can also<a id="_idIndexMarker733"/> use MongoDB Atlas (<a href="https://www.mongodb.com/atlas">https://www.mongodb.com/atlas</a>) or any other cloud provider that offers MongoDB as <span class="No-Break">a service.</span></p>
			<p>Now that we have MongoDB running, we can start using it, but first, we need to understand how to use secrets in Node.js so that we can pass the connection string to the application in a safe mode. So, in the next section, we will explain how to load secrets <span class="No-Break">in Node.js.</span></p>
			<h1 id="_idParaDest-324"><a id="_idTextAnchor332"/>How to load secrets in Node.js</h1>
			<p>Our application will need<a id="_idIndexMarker734"/> to connect to MongoDB, so we need to store the connection string in a safe place. You should never store secrets in your code; a very common practice is to store them in environment variables. In this section, we will explain how to load secrets from environment variables <span class="No-Break">in Node.js.</span></p>
			<h2 id="_idParaDest-325"><a id="_idTextAnchor333"/>Environment variables</h2>
			<p>Environment variables are variables<a id="_idIndexMarker735"/> that are set in the environment<a id="_idIndexMarker736"/> in which the process runs. They are usually set in the operating system, but we can also set them in the terminal. We can access the environment variables in Node.js using the <span class="No-Break"><strong class="source-inline">process.env</strong></span><span class="No-Break"> object:</span></p>
			<pre class="source-code">
console.log(process.env.MY_SECRET)</pre>			<p>You can set an environment variable in the terminal with the <span class="No-Break">following command:</span></p>
			<pre class="console">
export MY_SECRET=secret</pre>			<p>Then, you can run your application with the <span class="No-Break">following command:</span></p>
			<pre class="console">
node index.js</pre>			<p>Alternatively, you can set the environment variable in the <span class="No-Break">same command:</span></p>
			<pre class="console">
MY_SECRET=secret node index.js</pre>			<p class="callout-heading">Important note</p>
			<p class="callout">If you are using Windows you might need to use a different approach to handle environmental variables<a id="_idIndexMarker737"/> in the terminal. Read (<a href="https://www3.ntu.edu.sg/home/ehchua/programming/howto/Environment_Variables.html">https://www3.ntu.edu.sg/home/ehchua/programming/howto/Environment_Variables.html</a>) for <span class="No-Break">additional information.</span></p>
			<p>In the next section, we will learn how to use a. <strong class="source-inline">.env</strong> file to manage the secrets in a more <span class="No-Break">ergonomic way.</span></p>
			<h2 id="_idParaDest-326"><a id="_idTextAnchor334"/>The .env file</h2>
			<p>While using<a id="_idIndexMarker738"/> environmental varaibles<a id="_idIndexMarker739"/> directly in the terminal  is a very common practice, it is not very convenient. We can use a file called <strong class="source-inline">.env</strong> to store our environment variables. We can create a <strong class="source-inline">.env</strong> file with the <span class="No-Break">following content:</span></p>
			<pre class="source-code">
MY_SECRET=secret</pre>			<p>Then, we can<a id="_idIndexMarker740"/> use the <strong class="source-inline">dotenv</strong> package (<a href="https://www.npmjs.com/package/dotenv">https://www.npmjs.com/package/dotenv</a>) to load the environment variables from the <strong class="source-inline">.env</strong> file, but it’s worth mentioning that Node.js 20.6.0 introduced<a id="_idIndexMarker741"/> support for loading environment variables from a <strong class="source-inline">.env</strong> file, so we don’t need to use third-party packages <span class="No-Break">anymore (</span><a href="https://github.com/nodejs/node/releases/tag/v20.6.0"><span class="No-Break">https://github.com/nodejs/node/releases/tag/v20.6.0</span></a><span class="No-Break">).</span></p>
			<p class="callout-heading">Warning</p>
			<p class="callout">We should never commit the <strong class="source-inline">.env</strong> file to the repository because it contains secrets. You can include the <strong class="source-inline">.env</strong> file into the <strong class="source-inline">.gitignore</strong> file  to avoid commit the .env file along the project <span class="No-Break">source code.</span></p>
			<h2 id="_idParaDest-327"><a id="_idTextAnchor335"/>dotenv</h2>
			<p>The most common<a id="_idIndexMarker742"/> way to load<a id="_idIndexMarker743"/> environment variables<a id="_idIndexMarker744"/> from a <strong class="source-inline">.env</strong> file is to use the <strong class="source-inline">dotenv</strong> package (<a href="https://www.npmjs.com/package/dotenv">https://www.npmjs.com/package/dotenv</a>). We can install it with the <span class="No-Break">following command:</span></p>
			<pre class="console">
npm install dotenv@16</pre>			<p>Then, we can load the environment variables from the <strong class="source-inline">.env</strong> file with the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
import 'dotenv/config'</pre>			<p>Alternatively, we can do it directly using the <strong class="source-inline">--</strong><span class="No-Break"><strong class="source-inline">require</strong></span><span class="No-Break"> flag:</span></p>
			<pre class="console">
node --require dotenv/config index.js</pre>			<p>In the next section, we will explain how to use <strong class="bold">Object-Relational Mapping</strong> (<strong class="bold">ORM</strong>) to interact with MongoDB and how this can make our life easier when building a web application for the <span class="No-Break">first time.</span></p>
			<h1 id="_idParaDest-328"><a id="_idTextAnchor336"/>Using an ORM – Mongoose</h1>
			<p>We can use MongoDB<a id="_idIndexMarker745"/> directly, but<a id="_idIndexMarker746"/> it will require a bigger understanding and more code to interact with the database. As the objective of this book is to learn Node.js, we will use an ORM to interact with MongoDB. An ORM is a library that allows us to interact with a database using objects instead of SQL queries. In this section, we will<a id="_idIndexMarker747"/> use Mongoose (<a href="https://mongoosejs.com/">https://mongoosejs.com/</a>). Alternatively, you can use MongoDB Node.js Driver, which is the official <a id="_idIndexMarker748"/>MongoDB driver (<a href="https://docs.mongodb.com/drivers/node/">https://docs.mongodb.com/drivers/node/</a>) for Node.js. The official<a id="_idIndexMarker749"/> documentation can be found <span class="No-Break">at </span><a href="https://mongoosejs.com/docs/guide.html"><span class="No-Break">https://mongoosejs.com/docs/guide.html</span></a><span class="No-Break">.</span></p>
			<p>Mongoose offers several features<a id="_idIndexMarker750"/> that are quite convenient for a <span class="No-Break">web application:</span></p>
			<ul>
				<li><strong class="bold">Schema validation</strong>: We can define the schema of the documents, and Mongoose will validate the data before saving it to <span class="No-Break">the database</span></li>
				<li><strong class="bold">Model</strong>: We can define a model for each collection, and we can use it to interact with <span class="No-Break">the database</span></li>
				<li><strong class="bold">Middleware</strong>: We can define middleware functions that will be executed before or after certain events – for example, we can define a middleware function that will be executed before saving a document to <span class="No-Break">the database</span></li>
				<li><strong class="bold">Plugins</strong>: We can use plugins to extend the functionality <span class="No-Break">of Mongoose</span></li>
			</ul>
			<p>Also, if you are new to Node.js or MongoDB, you will find Mongoose easier to use than MongoDB directly, and there are plenty of tutorials and resources that you can use to get used to <span class="No-Break">it quickly.</span></p>
			<p class="callout-heading">Info</p>
			<p class="callout">Mongo has a huge ecosystem, and it might be a bit overwhelming at the beginning, but you can find a curated list of awesome MongoDB resources <span class="No-Break">at </span><a href="https://github.com/ramnes/awesome-mongodb"><span class="No-Break">https://github.com/ramnes/awesome-mongodb</span></a><span class="No-Break">.</span></p>
			<p>Now that we have MongoDB running and are familiar with the environment variables, we can start using Mongoose in our project. In the next section, we will explain how to migrate from local file storage <span class="No-Break">to MongoDB.</span></p>
			<h1 id="_idParaDest-329"><a id="_idTextAnchor337"/>Migrating a web application to MongoDB</h1>
			<p>We already added MongoDB<a id="_idIndexMarker751"/> to our project using Docker Compose and npm commands, but we have not started using it yet. In this section, we will migrate a web application <span class="No-Break">to MongoDB.</span></p>
			<h2 id="_idParaDest-330"><a id="_idTextAnchor338"/>Installing dependencies</h2>
			<p>We will install<a id="_idIndexMarker752"/> the <span class="No-Break">following dependencies:</span></p>
			<pre class="console">
npm install mongoose@7.4 dotenv@16</pre>			<h2 id="_idParaDest-331"><a id="_idTextAnchor339"/>Managing the secrets</h2>
			<p>We will create a <strong class="source-inline">.env</strong> file with<a id="_idIndexMarker753"/> the <span class="No-Break">following</span><span class="No-Break"><a id="_idIndexMarker754"/></span><span class="No-Break"> content:</span></p>
			<pre class="console">
MONGODB_URI=mongodb://localhost:27017/whispering-database
PORT=3000</pre>			<p>Then, we will load the environment variables from the <strong class="source-inline">.env</strong> file with the following code <span class="No-Break">into </span><span class="No-Break"><strong class="source-inline">index.js</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
import { app } from './server.js'
import mongoose from 'mongoose'
const port = process.env.PORT
try {
  await mongoose.connect(process.env.MONGODB_URI);
  console.log('Connected to MongoDB')
  app.listen(port, () =&gt; {
    console.log(`Running in http://localhost:${port}`)
  })
} catch (error) {
  console.error(error)
}</pre>			<p>We have included the <strong class="source-inline">mongoose</strong> package<a id="_idIndexMarker755"/> and have connected to MongoDB using the <strong class="source-inline">MONGODB_URI</strong> environment<a id="_idIndexMarker756"/> variable. We have also included the <strong class="source-inline">PORT</strong> environment variable to run the application in a <span class="No-Break">different port.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">As you can see, the database must be running before we open the HTTP server connection. This is because we need to connect to the database to retrieve the information for our response to the <span class="No-Break">HTTP requests.</span></p>
			<p>Now, we need to update the npm scripts to <span class="No-Break">use </span><span class="No-Break"><strong class="source-inline">dotenv</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
"scripts": {
    "start": "node --require dotenv/config index.js",
    "test": "jest --setupFiles dotenv/config",
    "test:coverage": "jest --coverage --setupFiles dotenv/config",
    "lint": "standard",
    "lint:fix": "standard --fix",
    "infra:start": "docker-compose up -d --build",
    "infra:stop": "docker-compose down"
}</pre>			<p>Now, we can run the application with the <span class="No-Break">following command:</span></p>
			<pre class="console">
npm run infra:start
npm run start</pre>			<p>We should see the <span class="No-Break">following output:</span></p>
			<pre class="console">
Connected to MongoDB
Running in http://localhost:3000</pre>			<p>If the database<a id="_idIndexMarker757"/> is not running, we will see<a id="_idIndexMarker758"/> a <span class="No-Break">similar error:</span></p>
			<pre class="source-code">
MongooseServerSelectionError: connect ECONNREFUSED ::1:27017, connect 
ECONNREFUSED 127.0.0.1:27017
    at _handleConnectionErrors (node_modules/mongoose/lib/connection.js:788:11)
    at NativeConnection.openUri (node_modules/mongoose/lib/connection.js:763:11)
    at async file:///index.js:7:4 {
  reason: TopologyDescription {
    type: 'Unknown',
    servers: Map(1) { 'localhost:27017' =&gt; [ServerDescription] },
    stale: false,
    compatible: true,
    heartbeatFrequencyMS: 10000,
    localThresholdMS: 15,
    setName: null,
    maxElectionId: null,
    maxSetVersion: null,
    commonWireVersion: 0,
    logicalSessionTimeoutMinutes: null
  },
  code: undefined
}</pre>			<p>Basically, it tells us that<a id="_idIndexMarker759"/> it cannot connect<a id="_idIndexMarker760"/> to the database; you can generate the same errors just by running <span class="No-Break">the following:</span></p>
			<pre class="console">
npm run infra:stop
npm run start</pre>			<p>In the next section we will start to work on the data <span class="No-Break">layer migration.</span></p>
			<h2 id="_idParaDest-332"><a id="_idTextAnchor340"/>Migrating the data layer</h2>
			<p>We want to refactor<a id="_idIndexMarker761"/> the <strong class="source-inline">store.js</strong> file to use MongoDB<a id="_idIndexMarker762"/> instead of a JSON file. Just to keep things simple, we will add the schema and model to the same file, but this can be changed later when we introduce authentication in the <span class="No-Break">next chapter.</span></p>
			<p>It is considered good practice to encapsulate the database-related code in specific files, with the idea of providing an interface that can later be used by other parts of our code to make changes in the data layer, without the need to understand how the data layer is implemented under the hood. This kind of abstraction is a very popular solution and will bring you a lot of support if you decide to migrate or combine other storage systems in the future. So, we will create a new file called <strong class="source-inline">database.js</strong> and explore together in the following paragraphs how it is structured and what is achieved in each statement. The file content is <span class="No-Break">the following:</span></p>
			<pre class="source-code">
import mongoose from 'mongoose'
mongoose.set('toJSON', {
  virtuals: true,
  transform: (doc, converted) =&gt; {
    delete converted._id
    delete converted.__v
  }
})
const whisperSchema = new mongoose.Schema({
  message: String
})
const Whisper = mongoose.model('Whisper', whisperSchema)
export {
  Whisper
}</pre>			<p><strong class="bold">Creating </strong><span class="No-Break"><strong class="bold">the schema</strong></span></p>
			<p>The first step is to <a id="_idIndexMarker763"/>create the schema, which is the definition<a id="_idIndexMarker764"/> of the structure of the documents that we are going to store in the database. In our case, we only have one field called <strong class="source-inline">message</strong>, which is <span class="No-Break">a string:</span></p>
			<pre class="source-code">
const whisperSchema = new mongoose.Schema({
  message: String
})</pre>			<p><strong class="bold">Creating </strong><span class="No-Break"><strong class="bold">the model</strong></span></p>
			<p>The second step is to create the model, which is a class that we use to interact with the database. In our case, we will use the <strong class="source-inline">Whisper</strong> model to interact with the <span class="No-Break"><strong class="source-inline">whispers</strong></span><span class="No-Break"> collection:</span></p>
			<pre class="source-code">
const Whisper = mongoose.model('Whisper', whisperSchema)</pre>			<p><span class="No-Break"><strong class="bold">Transformers</strong></span></p>
			<p>One of the things that we have to do is to remove the <strong class="source-inline">_id</strong> and <strong class="source-inline">__v</strong> fields from the response. We can change this behavior globally so that we don’t have to do it for every method, using the <span class="No-Break"><strong class="source-inline">toJSON</strong></span><span class="No-Break"> method:</span></p>
			<pre class="source-code">
mongoose.set('toJSON', {
  virtuals: true,
  transform: (doc, converted) =&gt; {
    delete converted._id;
    delete converted.__v;
  }
});</pre>			<p>This means we start with the following <span class="No-Break">data structure:</span></p>
			<pre class="source-code">
{
  "_id": "5dff03d3218b91425b9d6fab",
  "message": "I love MongoDB!",
  "__v": 0
}</pre>			<p>Then, we move on to the following <span class="No-Break">data structure:</span></p>
			<pre class="source-code">
{
  "id": "5dff03d3218b91425b9d6fab",
  "message": "I love MongoDB!"
}</pre>			<p><span class="No-Break"><strong class="bold">Refactored methods</strong></span></p>
			<p>The key in this migration is to keep<a id="_idIndexMarker765"/> the same interface <a id="_idIndexMarker766"/>so that we don’t have to change the behavior of the functions that we export. We will use the same data I/O, but we will use Mongoose to interact <span class="No-Break">with MongoDB:</span></p>
			<pre class="source-code">
import {
  Whisper
} from './database.js'
const getAll = () =&gt; Whisper.find()
const getById = id =&gt; Whisper.findById({ _id: id })
const create = async (message) =&gt; {
  const whisper = new Whisper({ message })
  await whisper.save()
  return whisper
}
const updateById = async (id, message) =&gt; Whisper.findOneAndUpdate({ _id: id }, { message }, { new: false })
const deleteById = async (id) =&gt; Whisper.deleteOne({ _id: id })
export { getAll, getById, create, updateById, deleteById }</pre>			<p>As you can see, we keep the same input and output in every method (<strong class="source-inline">getAll</strong>, <strong class="source-inline">getById</strong>, <strong class="source-inline">create</strong>, <strong class="source-inline">updateById</strong>, <strong class="source-inline">deleteById</strong>), so we don’t have to change the behavior of the functions that <span class="No-Break">we export.</span></p>
			<p>This is the effect that<a id="_idIndexMarker767"/> we discussed<a id="_idIndexMarker768"/> in the previous chapter; we can change the implementation of the methods, but we don’t have to change the interface. This is the power <span class="No-Break">of abstraction.</span></p>
			<p>So, even if you want to change the database in the future, you don’t have to change the interface of the methods; you just have to change the implementation and the code still works. This is because the business logic is not coupled to the <span class="No-Break">database interface.</span></p>
			<p><strong class="bold">Removing the old </strong><span class="No-Break"><strong class="bold">database file</strong></span></p>
			<p>Now, we can remove the <strong class="source-inline">db.json</strong> file because we are not using <span class="No-Break">it anymore.</span></p>
			<p><strong class="bold">Improve </strong><span class="No-Break"><strong class="bold">the routes</strong></span></p>
			<p>In the previous chapter, we used numerical IDs, just to keep the code more simple, so now, we need to change the routes to use the MongoDB IDs, which are alphanumerical strings. We only need to remove the references to <strong class="source-inline">parseInt</strong> in the <strong class="source-inline">server.js</strong> file. The change is from <strong class="source-inline">parseInt(req.params.id)</strong> to <strong class="source-inline">req.params.id</strong>. You can even use <em class="italic">Find and Replace</em> to change all the references to <strong class="source-inline">parseInt</strong> in <span class="No-Break">the file.</span></p>
			<p><strong class="bold">Running </strong><span class="No-Break"><strong class="bold">the application</strong></span></p>
			<p>At this point, you can just enjoy the migration by running <span class="No-Break">the following:</span></p>
			<pre class="console">
npm run infra:start
npm run start</pre>			<p>And if you go to <strong class="source-inline">http://localhost:3000</strong>, you can see the application working with MongoDB without any change in <span class="No-Break">the interface.</span></p>
			<p>Now, we are certain<a id="_idIndexMarker769"/> that the application<a id="_idIndexMarker770"/> is working as expected, but we shouldn’t forget to properly test these changes. So, in the next section, we will refactor the tests to use MongoDB, and we will be able to move to the next chapter once all the tests are passing (green) as the refactor will <span class="No-Break">be completed.</span></p>
			<h1 id="_idParaDest-333"><a id="_idTextAnchor341"/>Testing our MongoDB integration layer</h1>
			<p>Yes, we have made the migration<a id="_idIndexMarker771"/> and everything seems to be running fine, but we need to ensure that the tests work as expected. Currently, the tests use the filesystem to store data, so we need to change the tests to make them <span class="No-Break">use MongoDB.</span></p>
			<h2 id="_idParaDest-334"><a id="_idTextAnchor342"/>Update the utilities</h2>
			<p>We will edit the <strong class="source-inline">test/utils.js</strong> file to use MongoDB<a id="_idIndexMarker772"/> instead of the filesystem. As we are now using MongoDB, we need to load the fixtures in the database to know the IDs. So now, the fixtures will keep the same structure, but they will be stored and collected in the database using <strong class="source-inline">populateDb</strong> and the new <span class="No-Break"><strong class="source-inline">getFixtures</strong></span><span class="No-Break"> function:</span></p>
			<pre class="source-code">
import mongoose from 'mongoose'
import {
  Whisper
} from '../database.js'
const ensureDbConnection = async () =&gt; {
   try {
        if (mongoose.connection.readyState !== 1) {
            await mongoose.connect(process.env.MONGODB_URI);
        }
    } catch (error) {
        console.error('Error connecting to the database:', error);
        throw error; // Re-throw the error for handling at a higher level
    }
}
const closeDbConnection = async () =&gt; {
    if (mongoose.connection.readyState === 1) {
        await mongoose.disconnect()
    }
}
const restoreDb = () =&gt; Whisper.deleteMany({})
const populateDb = () =&gt; Whisper.insertMany([{ message: 'test' }, { message: 'hello world' }])
const getFixtures = async () =&gt; {
    const data = await Whisper.find()
    const whispers = JSON.parse(JSON.stringify(data))
    const inventedId = '64e0e5c75a4a3c715b7c1074'
    const existingId = data[0].id
    return { inventedId, existingId, whispers }
}
const normalize = (data) =&gt; JSON.parse(JSON.stringify(data))
export { restoreDb, populateDb, getFixtures, ensureDbConnection, normalize, closeDbConnection }</pre>			<p>Now, we can delete<a id="_idIndexMarker773"/> the <strong class="source-inline">test/fixtures.js</strong> file because we are not using <span class="No-Break">it anymore.</span></p>
			<h2 id="_idParaDest-335"><a id="_idTextAnchor343"/>Refactoring the test suite</h2>
			<p>So far, we have more tests<a id="_idIndexMarker774"/> than the ones that we really need. We can remove specific tests for the stores, as they are already covered by the integration tests, and we can remove the <span class="No-Break"><strong class="source-inline">test/store.test.js</strong></span><span class="No-Break"> file.</span></p>
			<p>As part of the migration, we need to make some changes in how the tests are prepared to be executed. As a database is an external service, we need to control certain aspects before we execute the test. For example, we need a proper database connection working before we execute any test, as this can be a failure cause for the tests but is not related to the code that we are testing. Also, we need to be sure that the database has specific data stored in it so that our tests can be executed independently multiple times, without polluting the execution context between executions with the modifications that we make in the database. This can be achieved by adding certain steps before any specific test is executed, with methods such as <strong class="source-inline">beforeAll</strong>, <strong class="source-inline">beforeEach</strong>, <strong class="source-inline">afterAll</strong>, and <strong class="source-inline">afterEach</strong>, which are part of the Jest methods available to us. Now, let’s update the tests to use the new functions. We will update the <strong class="source-inline">test/server.test.js</strong> file to use the <span class="No-Break">new functions:</span></p>
			<pre class="source-code">
import supertest from 'supertest'
import { app } from '../server'
import { getById } from '../store.js'
import { restoreDb, populateDb, getFixtures,
ensureDbConnection, normalize, closeDbConnection } from './utils.js'
let whispers
let inventedId
let existingId
describe('Server', () =&gt; {
  beforeAll(ensureDbConnection)
  beforeEach(async () =&gt; {
    await restoreDb()
    await populateDb(whispers)
    const fixtures = await getFixtures()
    whispers = fixtures.whispers
    inventedId = fixtures.inventedId
    existingId = fixtures.existingId
  })
  afterAll(closeDbConnection)
  //... unchanged tests
})</pre>			<p>In the next section, we will finish<a id="_idIndexMarker775"/> updating the test suite cases, as MongoDB introduced small differences that we need to take into account when querying data in the <span class="No-Break">test context.</span></p>
			<h2 id="_idParaDest-336"><a id="_idTextAnchor344"/>Some tests must change</h2>
			<p>Just to keep it simple, for the scope<a id="_idIndexMarker776"/> of the book, some tests have to change. All the tests that are use store will be refactored <span class="No-Break">as follows.</span></p>
			<p>When creating or updating whispers, we will check in the database that the whispers are stored correctly. In order to properly compare the data, we will use the <strong class="source-inline">normalize</strong> function. That way, we can compare the data without the <strong class="source-inline">_id</strong> and <strong class="source-inline">__v</strong> fields and in a normalized way, as we do when converting data to JSON while sending the <span class="No-Break">HTTP response:</span></p>
			<pre class="source-code">
it('Should return a 201 when the whisper is created', async () =&gt; {
    const newWhisper = { message: 'This is a new whisper' }
    const response = await supertest(app)
    .post('/api/v1/whisper')
    .send({ message: newWhisper.message })
    expect(response.status).toBe(201)
    expect(response.body.message).toEqual(newWhisper.message)
    // Database changes
    const storedWhisper = await getById(response.body.id)
    expect(normalize(storedWhisper).message).toStrictEqual(newWhisper.message)
})
it('Should return a 200 when the whisper is updated', async () =&gt; {
    const response = await supertest(app)
    .put(`/api/v1/whisper/${existingId}`)
    .send({ message: 'Whisper updated' })
    expect(response.status).toBe(200)
    // Database changes
    const storedWhisper = await getById(existingId)
    expect(normalize(storedWhisper)).toStrictEqual({ id: existingId, message: 'Whisper updated' })
})</pre>			<p>When deleting a whisper, we need to check that the whisper is not in the database anymore. Previously, we checked that the database returned <strong class="source-inline">undefined</strong> when not found; using MongoDB, we will get <strong class="source-inline">null</strong> instead, so we need to change the test <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
it('Should return a 200 when the whisper is deleted', async () =&gt; {
    const response = await supertest(app).delete(`/api/v1/whisper/${existingId}`)
    expect(response.status).toBe(200)
    // Database changes
    const storedWhisper = await getById(existingId)
    expect(storedWhisper).toBe(null)
})</pre>			<p>As we finished to refactor<a id="_idIndexMarker777"/> the tests, it is a great moment to review the testing coverage. In this section we will review this <span class="No-Break">in detail.</span></p>
			<h2 id="_idParaDest-337"><a id="_idTextAnchor345"/>Checking the coverage</h2>
			<p>Now, we can run the tests<a id="_idIndexMarker778"/> and check <span class="No-Break">the coverage:</span></p>
			<pre class="console">
npm run infra:start
npm run test:coverage</pre>			<p>The output should <span class="No-Break">be similar:</span></p>
			<pre class="console">
--------------|---------|----------|---------|---------|-------------------
File          | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s
--------------|---------|----------|---------|---------|-------------------
All files     |   97.43 |    85.71 |   94.44 |   97.18 |
app          |   96.66 |      100 |   91.66 |   96.42 |
  database.js |     100 |      100 |     100 |     100 |
  server.js   |   95.34 |      100 |   83.33 |   95.34 | 11-12
  store.js    |     100 |      100 |     100 |     100 |
app/tests    |     100 |       50 |     100 |     100 |
  utils.js    |     100 |       50 |     100 |     100 | 7-12
--------------|---------|----------|---------|---------|-------------------
Test Suites: 1 passed, 1 total
Tests:       13 passed, 13 total
Snapshots:   0 total
Time:        1.945 s, estimated 2 s
Ran all test suites.</pre>			<p>Basically, we have the same coverage<a id="_idIndexMarker779"/> as before, but we have removed some tests, and the <strong class="source-inline">store.js</strong> file is covered up <span class="No-Break">to 100%.</span></p>
			<p>As we can see, there is a line that is not covered (<em class="italic">11–12</em>), in <strong class="source-inline">server.js</strong>. In the previous chapter, we added a new route to render the template in <strong class="source-inline">GET /about</strong>, but we forgot to add proper tests. So, let’s add the <span class="No-Break">following test:</span></p>
			<pre class="source-code">
describe('/about', () =&gt; {
    it('Should return a 200 with the total whispers in the platform', async () =&gt; {
        const response = await supertest(app).get('/about')
        expect(response.status).toBe(200)
        expect(response.text).toContain(`Currently there are ${whispers.length} whispers available`)
    })
})</pre>			<p>If you run the tests again, you will see that the line is covered now and the coverage has increased to 100%. We can also improve the scoring by removing from the coverage report the <strong class="source-inline">tests</strong> folder, which we can do by adding the following line to the <span class="No-Break"><strong class="source-inline">jest.config.js</strong></span><span class="No-Break"> file:</span></p>
			<pre class="source-code">
export default {
  modulePathIgnorePatterns: ['&lt;rootDir&gt;/node_test/'],
  "coveragePathIgnorePatterns": [
    "&lt;rootDir&gt;/tests/"
  ]
}</pre>			<p>It is very important to keep a clear scope on what files you need to track or not for your coverage report; otherwise, the code coverage will become just a metric that won’t guide you to focus on the most critical application parts. It is quite common to read articles about the frustration associated with a 100% coverage target, when, in most cases, we don’t need to aim for that big number, and we should be clear on what parts of the code don’t need to <span class="No-Break">be tested.</span></p>
			<p>No matter whether you work<a id="_idIndexMarker780"/> alone or in a team, having precise metrics will increase the developer experience for all the humans involved in a project. As you can see, the coverage is now 100%, as we ignored the files that we are not planning <span class="No-Break">to test:</span></p>
			<pre class="console">
PASS  tests/server.test.js
  Server
    GET /about
      ✓ Should return a 200 with the total whispers in the platform (61 ms)
    GET /api/v1/whisper
      ✓ Should return an empty array when there's no data (19 ms)
      ✓ Should return all the whispers (14 ms)
    GET /api/v1/whisper/:id
      ✓ Should return a 404 when the whisper doesn't exist (14 ms)
      ✓ Should return a whisper details (12 ms)
    POST /api/v1/whisper
      ✓ Should return a 400 when the body is empty (27 ms)
      ✓ Should return a 400 when the body is invalid (9 ms)
      ✓ Should return a 201 when the whisper is created (17 ms)
    PUT /api/v1/whisper/:id
      ✓ Should return a 400 when the body is empty (9 ms)
      ✓ Should return a 400 when the body is invalid (9 ms)
      ✓ Should return a 404 when the whisper doesn't exist (11 ms)
      ✓ Should return a 200 when the whisper is updated (18 ms)
    DELETE /api/v1/whisper/:id
      ✓ Should return a 404 when the whisper doesn't exist (10 ms)
      ✓ Should return a 200 when the whisper is deleted (13 ms)
-------------|---------|----------|---------|---------|-------------------
File         | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s
-------------|---------|----------|---------|---------|-------------------
All files    |     100 |      100 |     100 |     100 |
database.js |     100 |      100 |     100 |     100 |
server.js   |     100 |      100 |     100 |     100 |
store.js    |     100 |      100 |     100 |     100 |
-------------|---------|----------|---------|---------|-------------------
Test Suites: 1 passed, 1 total
Tests:       14 passed, 14 total
Snapshots:   0 total
Time:        2.024 s, estimated 3 s
Ran all test suites.</pre>			<p class="callout-heading">Information</p>
			<p class="callout">If you are having issues running the project in this chapter while following the steps, or you tried an alternative approach, you can use the <strong class="source-inline">step3</strong> folder from the source code that you downloaded at the beginning of the chapter to compare and fix possible bugs <span class="No-Break">more easily.</span></p>
			<p>Now, that we have finished<a id="_idIndexMarker781"/> with the migration, it is time to do a recap in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-338"><a id="_idTextAnchor346"/>Summary</h1>
			<p>In this chapter, we learned how MongoDB is different from other databases. We learned how to install MongoDB locally using containers, with Docker and <span class="No-Break">Docker Compose.</span></p>
			<p>Additionally, we explored how we can manage sensitive information in our application using environment variables and the <strong class="source-inline">dotenv</strong> package. We also learned how to use Mongoose to interact <span class="No-Break">with MongoDB.</span></p>
			<p>Finally, we migrated our application to use MongoDB instead of a JSON file. This gave us the opportunity to properly learn how to refactor and reorganize our previous code. This migration also made it easy to maintain and deploy the application, as data is stored and queried as an external source. This will help us to scale a lot in the future, as we can connect multiple replicas of our backend to the same database instance. We also learned how to test our application using MongoDB, and we used this testing approach to ensure that the migration was <span class="No-Break">completed successfully.</span></p>
			<p>In the next chapter, we will introduce authentication and authorization to our application. We will use JWT to authenticate users and use middleware to protect the routes that require authentication. Also, we will refactor code to use a database to store users and use <strong class="source-inline">bcrypt</strong> library to hash the passwords. Finally, multiple users will be able to use our application, which will include <span class="No-Break">private whispers.</span></p>
			<h1 id="_idParaDest-339"><a id="_idTextAnchor347"/>Further reading</h1>
			<ul>
				<li>Fireship | MongoDB in 100 <span class="No-Break">Seconds: </span><a href="https://www.youtube.com/watch?v=-bt_y4Loofg"><span class="No-Break">https://www.youtube.com/watch?v=-bt_y4Loofg</span></a></li>
				<li>I Would Never Use an ORM, by Matteo <span class="No-Break">Collina: </span><a href="https://www.youtube.com/watch?v=qfRQ5zhYuJE"><span class="No-Break">https://www.youtube.com/watch?v=qfRQ5zhYuJE</span></a></li>
				<li>MongoDB in 5 Minutes with Eliot <span class="No-Break">Horowitz: </span><a href="https://www.youtube.com/watch?v=EE8ZTQxa0AM"><span class="No-Break">https://www.youtube.com/watch?v=EE8ZTQxa0AM</span></a></li>
				<li>MongoDB Explained in 10 Minutes | SQL vs NoSQL | <span class="No-Break">Jumpstart: </span><a href="https://www.youtube.com/watch?v=RGfFpQF0NpE"><span class="No-Break">https://www.youtube.com/watch?v=RGfFpQF0NpE</span></a></li>
			</ul>
		</div>
	</body></html>