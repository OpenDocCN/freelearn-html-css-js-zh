<html><head></head><body>
		<div id="_idContainer114">
			<h1 id="_idParaDest-203" class="chapter-number"><a id="_idTextAnchor204"/>11</h1>
			<h1 id="_idParaDest-204"><a id="_idTextAnchor205"/>Caching and Asynchronous Messaging in Microservices</h1>
			<p>When working with microservices architecture and Node.js, you need to master caching and asynchronous messaging to build the next generation of <span class="No-Break">successful applications.</span></p>
			<p>We’ll start this chapter by understanding better how to work with caching and asynchronous messaging in microservices with Node.js. Caching and asynchronous messaging are two important techniques used in microservices architecture to improve performance, scalability, and decoupling. Caching involves storing frequently accessed data in a cache to improve response times and reduce the load on the underlying data sources. Asynchronous messaging enables loose coupling and scalability in microservices by decoupling services through message queues or <span class="No-Break">publish-subscribe patterns.</span></p>
			<p>By the end of this chapter, you will have learned how to work with caching and asynchronous messaging <span class="No-Break">in Node.js.</span></p>
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>Client-side caching and <span class="No-Break">edge caching</span></li>
				<li>Microservice-level caching and database <span class="No-Break">query caching</span></li>
				<li>Message queues <span class="No-Break">and publish-subscribe</span></li>
				<li><span class="No-Break">Event-driven architecture</span></li>
			</ul>
			<h1 id="_idParaDest-205"><a id="_idTextAnchor206"/>Client-side caching and edge caching</h1>
			<p>In this section, we’re going to show you how to work with client-side caching and edge caching. Client-side caching and edge caching are strategies used to improve performance and reduce the load on servers by storing and serving content closer to <span class="No-Break">the user.</span></p>
			<h2 id="_idParaDest-206"><a id="_idTextAnchor207"/>Client-side caching</h2>
			<p><strong class="bold">Client-side caching</strong> involves storing<a id="_idIndexMarker891"/> resources (e.g., HTML pages, stylesheets, scripts, images) on the client device (such as a web browser) to avoid repeated requests to <span class="No-Break">the server.</span></p>
			<p>Here are some of <span class="No-Break">its</span><span class="No-Break"><a id="_idIndexMarker892"/></span><span class="No-Break"> advantages:</span></p>
			<ul>
				<li>Client-side caching reduces server load by serving cached content directly from the client. This means that client-side caching can improve the performance and efficiency of both the web server and the web browser. By serving cached content directly from the client, the web server does not have to process and send the same data repeatedly to the same or different users. This reduces the server load, meaning the amount of work or requests that the server has to handle at any <span class="No-Break">given time.</span></li>
				<li>It improves page load times for subsequent visits. This means that client-side caching can enhance the user experience by making the web pages load faster when the user visits them again. By storing a copy of a web page in the browser memory, the browser does not have to request and download the same web page again from <span class="No-Break">the server.</span></li>
				<li>It enhances user experience by minimizing network requests. This means that client-side caching can reduce the number and size of network requests that the browser has to make to the server. Network requests are the messages that the browser and the server exchange to communicate and transfer data. Network requests can take time and consume bandwidth, depending on the distance, speed, and quality of the connection. By minimizing network requests, client-side caching can save time and bandwidth as well as avoid potential errors or delays that might occur <span class="No-Break">during communication.</span></li>
				<li>An API contract outlines the rules and specifications for how services should interact. In the context of client-side caching, an API contract can outline the rules and specifications for how services should interact with the cached data stored on the client’s device, such as <span class="No-Break">the browser.</span></li>
				<li>The caching behavior is controlled by HTTP headers, such as <strong class="bold">Cache-Control</strong> and <strong class="bold">Expires</strong>. This means that<a id="_idIndexMarker893"/> client-side caching<a id="_idIndexMarker894"/> can be configured and customized by using certain HTTP headers that specify for how long and under what conditions the data can be cached. HTTP headers are the metadata that accompany the HTTP requests<a id="_idIndexMarker895"/> and responses between the client and <span class="No-Break">the server.</span></li>
			</ul>
			<p><span class="No-Break"><em class="italic">Figure 11</em></span><em class="italic">.1</em> illustrates <span class="No-Break">client-side caching:</span></p>
			<div>
				<div id="_idContainer112" class="IMG---Figure">
					<img src="image/B14980_11_01.jpg" alt="Figure 11.1: Client-side caching"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.1: Client-side caching</p>
			<p>We have learned the basics of client-side caching; now, let’s move on to <span class="No-Break">edge caching.</span></p>
			<h2 id="_idParaDest-207"><a id="_idTextAnchor208"/>Edge caching</h2>
			<p><strong class="bold">Edge caching</strong>, or <strong class="bold">content delivery network</strong> (<strong class="bold">CDN</strong>) caching, involves caching content on servers strategically <a id="_idIndexMarker896"/>positioned at the<a id="_idIndexMarker897"/> edge of the network (closer to users) to reduce latency and improve content <span class="No-Break">delivery speed.</span></p>
			<p>Here are some of <span class="No-Break">its</span><span class="No-Break"><a id="_idIndexMarker898"/></span><span class="No-Break"> advantages:</span></p>
			<ul>
				<li>Edge caching minimizes latency by serving content from servers closer to the user. This means that edge caching can reduce the time it takes for the data to travel from the server to the user. <strong class="bold">Latency</strong> is the delay or lag that occurs <a id="_idIndexMarker899"/>when data is transferred over a network. Latency can affect the performance and user experience of web applications, especially for dynamic or interactive content. By serving content from servers closer to the user, edge caching can minimize latency and improve the speed and responsiveness of <span class="No-Break">web applications.</span></li>
				<li>It distributes content globally, reducing the load on the origin server. This means that edge caching can improve the scalability and reliability of the web application by spreading the data across multiple servers around the world. This reduces the load on the origin server, meaning the main server that hosts the original data and <span class="No-Break">application logic.</span></li>
				<li>It enhances scalability and reliability. This means that edge caching can improve the ability of the web application to handle more traffic and requests without compromising the quality and availability of the service. By distributing the data across multiple servers around the world, edge caching can reduce the dependency and load on the central server, which might have limited resources <span class="No-Break">and capacity.</span></li>
				<li>CDN providers deploy servers worldwide, and content is cached on these servers for quick retrieval. This means that edge caching is often implemented by using a CDN, which is a network of servers distributed across the globe that can store and deliver data to users. A CDN provider is a company that offers CDN services to web applications and websites. By using a CDN provider, web applications and websites can cache their data on the CDN servers, which are closer to the users than the original server. This way, when a user requests the data, it can be retrieved quickly<a id="_idIndexMarker900"/> from the CDN server, rather than from the <span class="No-Break">original server.</span></li>
			</ul>
			<p>Remember, it is important to apply the caching strategies while working <span class="No-Break">with microservices.</span></p>
			<p>In summary, client-side<a id="_idIndexMarker901"/> caching and edge caching are powerful techniques for optimizing web performance, reducing server loads, and enhancing the overall user experience. Understanding cache control headers, cache invalidation strategies, and leveraging CDNs is crucial for <span class="No-Break">effective implementation.</span></p>
			<p>With the understanding of these concepts, let’s now move on to microservice-level caching and database <span class="No-Break">query caching.</span></p>
			<h1 id="_idParaDest-208"><a id="_idTextAnchor209"/>Microservice-level caching and database query caching</h1>
			<p>Microservice-level aching and database query caching are strategies employed to enhance the performance and scalability of microservices by reducing the need for repeated computations and <span class="No-Break">database queries.</span></p>
			<h2 id="_idParaDest-209"><a id="_idTextAnchor210"/>Microservice-level caching</h2>
			<p><strong class="bold">Microservice-level caching</strong> involves storing<a id="_idIndexMarker902"/> and retrieving frequently accessed data within individual microservices to avoid redundant computations or external calls. Each microservice maintains its own cache, and caching decisions are made within the <span class="No-Break">microservice boundaries.</span></p>
			<p>Caching can allow microservices<a id="_idIndexMarker903"/> to improve fault tolerance, which is the ability of a system to continue functioning despite failures or errors. Caching can act as a buffer during temporary service outages or network issues, which can affect the availability and performance of microservices. Caching<a id="_idIndexMarker904"/> can help microservices to do <span class="No-Break">the following:</span></p>
			<ul>
				<li>It can reduce the dependency on external services or databases that might be slow, unreliable, or unavailable due to network problems or maintenance. By storing the data in a cache, microservices can avoid making unnecessary or repeated requests to the original data source and instead serve the data from <span class="No-Break">the cache.</span></li>
				<li>It can handle spikes in traffic or demand that might overload the system or cause bottlenecks. By storing the data in a cache, microservices can reduce the load on the system and improve the response time and throughput of <span class="No-Break">the system.</span></li>
				<li>It can recover from failures or errors that might cause data loss or corruption. By storing the data in a cache, microservices can preserve the data and restore it from the cache if the original<a id="_idIndexMarker905"/> data source is compromised <span class="No-Break">or damaged.</span></li>
			</ul>
			<p>Here are some<a id="_idIndexMarker906"/> of its <span class="No-Break">use cases:</span></p>
			<ul>
				<li>Caching results of computationally <span class="No-Break">expensive operations.</span></li>
				<li>Storing frequently accessed <span class="No-Break">static data.</span></li>
				<li>Reducing the load on downstream microservices <span class="No-Break">or databases.</span></li>
			</ul>
			<p>Here are some key considerations <a id="_idIndexMarker907"/>for <span class="No-Break">microservice-level caching:</span></p>
			<ul>
				<li><strong class="bold">Granularity</strong>: Determine the appropriate granularity for caching whether it’s at the level of individual API endpoints, specific operations, or <span class="No-Break">entire datasets.</span></li>
				<li><strong class="bold">Cache invalidation</strong>: Implement strategies to invalidate or update the cache when underlying data changes to <span class="No-Break">ensure consistency.</span></li>
				<li><strong class="bold">Cache eviction</strong>: Define policies for removing stale or less frequently used items from the cache to manage <span class="No-Break">memory efficiently.</span></li>
				<li><strong class="bold">Time-to-live</strong> (<strong class="bold">TTL</strong>): Set time-to-live values for cached items to control how long they are <span class="No-Break">considered valid.</span></li>
			</ul>
			<p>Here are the benefits<a id="_idIndexMarker908"/> of <span class="No-Break">microservice-level caching:</span></p>
			<ul>
				<li><strong class="bold">Improved performance</strong>: It reduces response times by serving cached data locally without making redundant calls to downstream services <span class="No-Break">or databases.</span></li>
				<li><strong class="bold">Increased scalability</strong>: It reduces the load on backend services, enhancing overall <span class="No-Break">system scalability.</span></li>
				<li><strong class="bold">Resilience</strong>: It provides a level of resilience by allowing microservices to continue functioning even when downstream services are <span class="No-Break">temporarily unavailable.</span></li>
			</ul>
			<p>In this section, we have learned some of the concepts, use cases, and key considerations of <span class="No-Break">microservice-level caching.</span></p>
			<p>With these concepts learned, we can continue with database <span class="No-Break">query caching.</span></p>
			<h2 id="_idParaDest-210"><a id="_idTextAnchor211"/>Database query caching</h2>
			<p><strong class="bold">Database query caching</strong> is a technique that stores the results<a id="_idIndexMarker909"/> of frequently executed queries<a id="_idIndexMarker910"/> in a temporary memory, called a cache, for faster access. When a query is requested, the database first checks whether the query result is already in the cache. If it is, the database returns the cached result without having to execute the query again. Database query caching can improve the performance and efficiency of the database by reducing the workload and response time of <span class="No-Break">the database.</span></p>
			<p>Here are some<a id="_idIndexMarker911"/> of its <span class="No-Break">use cases:</span></p>
			<ul>
				<li>Caching the results of <span class="No-Break">read-heavy queries.</span></li>
				<li>Avoiding redundant database access for static or slowly <span class="No-Break">changing data.</span></li>
				<li>Offloading the database by serving cached results for <span class="No-Break">common queries.</span></li>
			</ul>
			<p>Here are some key considerations<a id="_idIndexMarker912"/> for database <span class="No-Break">query caching:</span></p>
			<ul>
				<li><strong class="bold">Query identifiers</strong>: Use unique identifiers for queries to manage and reference cached <span class="No-Break">results effectively.</span></li>
				<li><strong class="bold">Cache invalidation</strong>: Implement strategies to invalidate the cache when underlying data changes to maintain <span class="No-Break">data consistency.</span></li>
				<li><strong class="bold">Query complexity</strong>: Consider the complexity and cost of queries when deciding which ones <span class="No-Break">to cache.</span></li>
			</ul>
			<p>Here are the benefits<a id="_idIndexMarker913"/> of database <span class="No-Break">query caching:</span></p>
			<ul>
				<li><strong class="bold">Reduced database load</strong>: Caching query results reduces the need for repeated, resource-intensive <span class="No-Break">database access.</span></li>
				<li><strong class="bold">Lower latency</strong>: It improves response times by serving cached results instead of re-executing queries against <span class="No-Break">the database.</span></li>
				<li><strong class="bold">Improved scalability</strong>: It enhances the scalability of the overall system by reducing the load<a id="_idIndexMarker914"/> on <span class="No-Break">the database.</span></li>
			</ul>
			<p>In summary, microservice-level caching and database query caching are essential techniques for optimizing microservices architectures. By strategically caching data at both the microservice and database layers, organizations can achieve improved performance, scalability, and responsiveness in their <span class="No-Break">distributed systems.</span></p>
			<p>Now, we can continue to the next section, in which we will talk about message queues <span class="No-Break">and publish-subscribe.</span></p>
			<h1 id="_idParaDest-211"><a id="_idTextAnchor212"/>Message queues and publish-subscribe</h1>
			<p>Message queues and publish-subscribe (Pub/Sub) are communication patterns commonly used in microservices<a id="_idIndexMarker915"/> architectures to facilitate asynchronous communication <span class="No-Break">between services.</span></p>
			<h2 id="_idParaDest-212"><a id="_idTextAnchor213"/>Message queues</h2>
			<p>A <strong class="bold">message queue</strong> is a communication mechanism<a id="_idIndexMarker916"/> that allows microservices to send and receive messages asynchronously. Messages are placed in a queue by the sender and processed by <span class="No-Break">the receiver.</span></p>
			<p>Here are some<a id="_idIndexMarker917"/> of its <span class="No-Break">use cases:</span></p>
			<ul>
				<li><strong class="bold">Task distribution</strong>: A web application that processes user-uploaded files. Each file processing task is placed in a message queue, and multiple worker processes consume tasks from the queue to handle file <span class="No-Break">processing concurrently.</span></li>
				<li><strong class="bold">Event sourcing</strong>: A system that maintains a log of events to capture changes in state. Events are published to a message queue, and various microservices subscribe to these events to update their <span class="No-Break">own state.</span></li>
				<li><strong class="bold">Microservices communication</strong>: A system with multiple microservices where one microservice generates an event (e.g., user registration) and publishes it to a message queue. Other microservices interested in this event can subscribe to the queue to perform <span class="No-Break">related actions.</span></li>
				<li><strong class="bold">Load leveling</strong>: A system with a peak load of requests. Instead of overwhelming a service, incoming requests are placed in a message queue. Workers consume requests from the queue, allowing the system to handle peaks <span class="No-Break">more gracefully.</span></li>
				<li><strong class="bold">Scalability</strong>: A system where certain components have varying processing loads. By using a message queue, these components can scale independently based on their own demand, ensuring efficient <span class="No-Break">resource utilization.</span></li>
				<li><strong class="bold">Background processing</strong>: An e-commerce platform that sends order confirmation emails. Instead of sending emails synchronously during the checkout process, the system places email tasks in a message queue, and a separate service process and sends <span class="No-Break">the emails.</span></li>
				<li><strong class="bold">Cross-application integration</strong>: A company using multiple software applications (e.g., CRM, ERP). Integrating these applications can be achieved by placing messages in a queue when specific events occur in one application, triggering actions in <span class="No-Break">another application.</span></li>
				<li><strong class="bold">Workflow orchestration</strong>: An order processing system where each step (e.g., order validation, payment processing, shipping) is a separate task. Each step publishes a message to a queue upon completion, triggering the next step in <span class="No-Break">the workflow.</span></li>
				<li><strong class="bold">Delayed or scheduled tasks</strong>: A system that allows users to schedule emails to be sent at a later time. The email content and recipient details are placed in a message queue with a scheduled <span class="No-Break">delivery time.</span></li>
				<li><strong class="bold">Log and event aggregation</strong>: Distributed applications generate logs and events. Instead of relying on individual logs, events are sent to a message queue and a centralized logging <a id="_idIndexMarker918"/>service consumes and aggregates them <span class="No-Break">for analysis.</span></li>
			</ul>
			<p>The following are some<a id="_idIndexMarker919"/> of its <span class="No-Break">key components:</span></p>
			<ul>
				<li><strong class="bold">Queue</strong>: A storage mechanism where messages are temporarily held until they are consumed by <span class="No-Break">a service.</span></li>
				<li><strong class="bold">Producer</strong>: A microservice responsible for sending messages to <span class="No-Break">the queue.</span></li>
				<li><strong class="bold">Consumer</strong>: A microservice that retrieves<a id="_idIndexMarker920"/> and processes messages from <span class="No-Break">the queue.</span></li>
			</ul>
			<p>Here are some of <span class="No-Break">its</span><span class="No-Break"><a id="_idIndexMarker921"/></span><span class="No-Break"> advantages:</span></p>
			<ul>
				<li><strong class="bold">Decoupling</strong>: It allows services to be decoupled, as the sender and receiver are not directly dependent on <span class="No-Break">each other.</span></li>
				<li><strong class="bold">Asynchronous processing</strong>: It enables asynchronous communication, which can improve system responsiveness <span class="No-Break">and scalability.</span></li>
				<li><strong class="bold">Load balancing</strong>: It distributes the processing load by allowing multiple instances of a service to consume messages from <span class="No-Break">the queue.</span></li>
			</ul>
			<p><span class="No-Break"><em class="italic">Figure 11</em></span><em class="italic">.2</em> illustrates <span class="No-Break">message queues:</span></p>
			<div>
				<div id="_idContainer113" class="IMG---Figure">
					<img src="image/B14980_11_02.jpg" alt="Figure 11.2: Message queues"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.2: Message queues</p>
			<p>Having these concepts in mind can help create a better architecture for <span class="No-Break">message queues.</span></p>
			<p>We can continue now <span class="No-Break">with publish-subscribe.</span></p>
			<h2 id="_idParaDest-213"><a id="_idTextAnchor214"/>Publish-subscribe (Pub/Sub)</h2>
			<p><strong class="bold">Pub/Sub</strong> is a messaging<a id="_idIndexMarker922"/> pattern where a microservice (the publisher) broadcasts messages to multiple subscribers. Subscribers express interest in certain types of messages and receive <span class="No-Break">relevant notifications.</span></p>
			<p>Here are some<a id="_idIndexMarker923"/> of its <span class="No-Break">use cases:</span></p>
			<ul>
				<li><strong class="bold">Real-time updates</strong>: A social media platform notifying users about new posts, comments, or likes <span class="No-Break">in real-time.</span></li>
				<li><strong class="bold">Event notification</strong>: A payment gateway notifying multiple services about a successful <span class="No-Break">payment transaction.</span></li>
				<li><strong class="bold">Distributed systems coordination</strong>: A microservices architecture where changes in user authentication trigger updates in various services, such as user profiles, permissions, <span class="No-Break">and analytics.</span></li>
				<li><strong class="bold">Cross-cutting concerns</strong>: Publishing events related to system logs, errors, or performance metrics, allowing multiple services to subscribe and <span class="No-Break">react accordingly.</span></li>
				<li><strong class="bold">Workflow orchestration</strong>: The orchestration of a series of tasks <span class="No-Break">or processes.</span></li>
				<li><strong class="bold">Cross-application integration</strong>: An ecosystem of applications (CRM, ERP, Analytics) where changes in one application trigger actions in others, ensuring <span class="No-Break">data consistency.</span></li>
				<li><strong class="bold">IoT device communication</strong>: Smart home devices publishing events related to status changes (e.g., temperature, motion detection) and multiple applications subscribing to these events for automation <span class="No-Break">or monitoring</span></li>
				<li><strong class="bold">User notifications</strong>: A messaging application publishing events for new messages, and different clients (web, mobile, desktop) subscribing to receive <span class="No-Break">real-time notifications.</span></li>
				<li><strong class="bold">Log aggregation and analytics</strong>: Services publishing events related to user interactions, and an analytics service subscribing to these events for centralized analysis <span class="No-Break">and reporting.</span></li>
				<li><strong class="bold">Multi-tenant systems</strong>: A <strong class="bold">software as a service</strong> (<strong class="bold">SaaS</strong>) platform where different organizations<a id="_idIndexMarker924"/> subscribe to events related to their specific data <span class="No-Break">or customizations.</span></li>
				<li><strong class="bold">Chat applications</strong>: Users subscribing to chat channels or rooms, and messages being published to the relevant channels for <span class="No-Break">real-time delivery.</span></li>
				<li><strong class="bold">Dynamic configuration updates</strong>: Services subscribing to configuration change events, ensuring that they dynamically<a id="_idIndexMarker925"/> adjust their behavior based <span class="No-Break">on changes.</span></li>
			</ul>
			<p>Here are some<a id="_idIndexMarker926"/> of its <span class="No-Break">key components:</span></p>
			<ul>
				<li><strong class="bold">Publisher</strong>: A microservice responsible for broadcasting messages to <span class="No-Break">the system.</span></li>
				<li><strong class="bold">Topic</strong>: Logical channels or categories to which messages <span class="No-Break">are published.</span></li>
				<li><strong class="bold">Subscriber</strong>: A microservice that expresses interest in specific topics and receives <span class="No-Break">relevant </span><span class="No-Break"><a id="_idIndexMarker927"/></span><span class="No-Break">messages.</span></li>
			</ul>
			<p>The following are some<a id="_idIndexMarker928"/> of <span class="No-Break">its advantages:</span></p>
			<ul>
				<li><strong class="bold">Scalability</strong>: It is well-suited for scenarios where multiple services need to react to the same event or type <span class="No-Break">of information.</span></li>
				<li><strong class="bold">Flexibility</strong>: It allows services to subscribe to specific topics of interest, receiving only the messages <span class="No-Break">they need.</span></li>
				<li><strong class="bold">Event-driven architecture</strong>: It supports the creation of event-driven systems where services can react to changes <span class="No-Break">in state.</span></li>
			</ul>
			<p>You need to learn these concepts fast in order to keep updated with the latest patterns <span class="No-Break">in microservices.</span></p>
			<p>In summary, message queues<a id="_idIndexMarker929"/> and Pub/Sub patterns are fundamental to building resilient, scalable, and loosely coupled microservices architectures. The choice between them depends on the specific requirements of the system and the<a id="_idIndexMarker930"/> desired communication<a id="_idIndexMarker931"/> patterns <span class="No-Break">between services.</span></p>
			<p>In the next section, we will learn about <span class="No-Break">event-driven architecture.</span></p>
			<h1 id="_idParaDest-214"><a id="_idTextAnchor215"/>Event-driven architecture</h1>
			<p><strong class="bold">Event-driven architecture</strong> (<strong class="bold">EDA</strong>) is a design paradigm that emphasizes<a id="_idIndexMarker932"/> the production, detection, consumption, and reaction to events in a system. In the context of microservices, event-driven architecture provides a flexible and scalable approach to handle communication and coordination <span class="No-Break">between services.</span></p>
			<p>Here is the use case<a id="_idIndexMarker933"/> of <span class="No-Break">event-driven architecture:</span></p>
			<ul>
				<li><strong class="bold">Event sourcing</strong>: Storing changes to the state of an application as a sequence of events. This helps in reconstructing the current state <span class="No-Break">and auditing.</span></li>
				<li><strong class="bold">Real-time updates</strong>: Broadcasting real-time updates to multiple services or clients in response to <span class="No-Break">certain events.</span></li>
				<li><strong class="bold">Workflow orchestration</strong>: Coordinating the execution of business processes across <span class="No-Break">multiple microservices.</span></li>
				<li><strong class="bold">Log and monitoring events</strong>: Capturing events related to system logs, errors, or performance metrics for <span class="No-Break">monitoring purposes.</span></li>
			</ul>
			<p>The following are its <span class="No-Break">key</span><span class="No-Break"><a id="_idIndexMarker934"/></span><span class="No-Break"> concepts:</span></p>
			<ul>
				<li><strong class="bold">Events</strong>: Events represent occurrences or state changes in a system. Examples include user actions, system alerts, or changes <span class="No-Break">in data.</span></li>
				<li><strong class="bold">Event producer</strong>: Microservices that generate and emit events are known as event producers. They publish events<a id="_idIndexMarker935"/> to a message broker or <span class="No-Break">event bus.</span></li>
				<li><strong class="bold">Event consumer</strong>: Microservices that subscribe to and process events are event consumers. They react to events based on <span class="No-Break">predefined logic.</span></li>
				<li><strong class="bold">Event bus or message broker</strong>: This acts as a communication channel that facilitates the distribution<a id="_idIndexMarker936"/> of events from producers <span class="No-Break">to consumers.</span></li>
			</ul>
			<p>The following are the advantages<a id="_idIndexMarker937"/> of <span class="No-Break">event-driven architecture:</span></p>
			<ul>
				<li><strong class="bold">Decoupling</strong>: Microservices become loosely coupled as they communicate through events. This reduces dependencies <span class="No-Break">between services.</span></li>
				<li><strong class="bold">Scalability</strong>: It allows for easy scalability, as services can be added or removed without affecting the <span class="No-Break">entire system.</span></li>
				<li><strong class="bold">Flexibility</strong>: It supports flexibility in system design, as services can be added or <span class="No-Break">modified independently.</span></li>
				<li><strong class="bold">Asynchronicity</strong>: It enables asynchronous communication between services, promoting responsiveness <span class="No-Break">and agility.</span></li>
			</ul>
			<p>Here is the implementation<a id="_idIndexMarker938"/> of <span class="No-Break">event-driven architecture:</span></p>
			<ul>
				<li><strong class="bold">Message brokers</strong>: Systems often use message<a id="_idIndexMarker939"/> brokers such as <strong class="bold">Kafka</strong>, <strong class="bold">RabbitMQ</strong>, or <strong class="bold">Apache Pulsar</strong> as the underlying infrastructure<a id="_idIndexMarker940"/> to manage the flow<a id="_idIndexMarker941"/> <span class="No-Break">of events.</span></li>
				<li><strong class="bold">Event schema</strong>: Defining a clear schema for events helps to ensure consistency and understanding between producers <span class="No-Break">and consumers.</span></li>
				<li><strong class="bold">Event handlers</strong>: Microservices have event handlers that subscribe to specific types of events and execute predefined logic <span class="No-Break">in response.</span></li>
				<li><strong class="bold">Event-driven microservices</strong>: Each microservice in the system can act as both a producer and a consumer of events, interacting with other services based <span class="No-Break">on events.</span></li>
			</ul>
			<p>In summary, event-driven architecture is a powerful paradigm for building resilient and scalable microservices systems. It enables a more responsive and adaptable architecture by fostering loose coupling between microservices, allowing them to evolve independently. Properly implemented, EDA contributes to a more agile and efficient <span class="No-Break">microservices ecosystem.</span></p>
			<h1 id="_idParaDest-215"><a id="_idTextAnchor216"/>Summary</h1>
			<p>In this chapter, we have learned a lot about microservices, how to deal with caching, and the different types <span class="No-Break">of caching.</span></p>
			<p>In summary, caching and asynchronous messaging are two techniques that can improve the performance, scalability, and reliability of microservice-based applications. Caching is the process of storing frequently accessed or expensive data in a temporary storage area, such as <strong class="bold">Redis</strong>, to reduce the latency and the load on the primary data source. Asynchronous messaging is the process of exchanging data between microservices or clients in a non-blocking and event-driven manner, using a message broker such as <strong class="bold">Amazon SQS</strong> or <strong class="bold">Amazon SNS</strong>. Caching and asynchronous messaging can help to overcome some of the challenges of microservices, such as complexity, eventual consistency, and network failures. However, they also require careful design and trade-offs, such as data freshness, data synchronization, and <span class="No-Break">message ordering.</span></p>
			<p>In the next chapter, we are going to learn about ensuring data security with the saga pattern, encryption, and <span class="No-Break">security measures.</span></p>
			<h1 id="_idParaDest-216"><a id="_idTextAnchor217"/>Quiz time</h1>
			<ul>
				<li>What is client-side caching and <span class="No-Break">edge caching?</span></li>
				<li>What is <span class="No-Break">microservice-level caching?</span></li>
				<li>What are message queues <span class="No-Break">and publish-subscribe?</span></li>
				<li>What is <span class="No-Break">event-driven architecture?</span></li>
			</ul>
		</div>
	</body></html>