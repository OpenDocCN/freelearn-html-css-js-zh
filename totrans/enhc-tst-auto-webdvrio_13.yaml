- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Multiverses – Cross-Browser Testing and Cross-Environment Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will begin adding the mutant power of horizontal scaling
    to browser operating systems and other platforms. This is in contrast to vertical
    scaling, which involves adding more tests to our suites, such as adding more floors
    to a superhero base that’s hiding in plain sight. Horizontal scaling is like expanding
    to more buildings up and down the city block. Our tests can run in multiple browsers,
    versions, operating systems, and other platforms. What this means is that if we
    are using a Mac as opposed to a Windows PC, then we will be confident that our
    applications and tests run well on our chosen browser. Chrome is typically the
    target browser because of the large number of users on both Windows and Mac. But
    many Mac users prefer Safari and Windows users prefer Edge. So, how do we ensure
    these combinations get tested?
  prefs: []
  type: TYPE_NORMAL
- en: That’s where the standalone Selenium WebDriver service becomes useful. This
    service is used to automate the testing process across various browsers and platforms,
    which helps in identifying issues that might occur in specific environments. Utilizing
    this service can be a creative solution to streamline the test automation framework
    as it allows for more comprehensive testing coverage with less manual effort.
    However, it can also become quickly overwhelming.
  prefs: []
  type: TYPE_NORMAL
- en: Think of this as a crossover between the multiple superhero universes. We will
    be extending testing beyond Chrome to Edge on a Windows machine as well as extending
    Chrome to Safari on a Mac. Then, we will use cloud-based solutions for various
    combinations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main topics in this chapter are:'
  prefs: []
  type: TYPE_NORMAL
- en: Horizontal scaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using built-in functionality via the wdio config file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using LambdaTest online to automate browser testing grid
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Selenium Standalone server to locally build the testing grid
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoiding the rabbit hole of horizontal scaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling environment-specific logic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Horizontal scaling – cross-browser testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are three ways in which you can do cross-browser testing for your projects:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the built-in functionality via the `wdio` config file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using LambdaTest online to automate the browser testing grid
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Selenium Standalone server to locally build the testing grid
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although we will discuss all three ways, in this book, our examples will be
    completed using the built-in functionality provided by the `wdio` config file.
  prefs: []
  type: TYPE_NORMAL
- en: Using built-in functionality via the wdio config file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cross-browser testing involves setting up the testing environment, writing tests
    using Jasmine syntax in TypeScript, and running the tests on different browsers.
    This is accomplished in the config file of WebdriverIO in the capabilities section.
    We will extend from Chrome to Edge in the capabilities section. This also controls
    how many concurrent browsers will be launched in parallel with the **maxInstances**
    parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Extending the wdio config file so that it supports multiple browsers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Set up `wdio.conf.ts` so that it defines your test settings and browser capabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In the `Services` section, we must provide the drivers to interact with the
    browsers. `chromedriver` runs the Chrome browser, which we have been using all
    along. To drive Safari, `safaridriver` will be used. Keep in mind that the number
    of concurrent browsers that can be used is limited to the resources available
    to the local machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of the type of test that can be run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we must execute the test in multiple browsers by running this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This will execute the preceding example test on all browsers configured in the
    `wdio.conf` file’s capabilities section, namely Chrome, Safari, and Edge.
  prefs: []
  type: TYPE_NORMAL
- en: Handling browser-specific issues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If your application has browser-specific code or issues, you can use conditional
    checks or feature detection to handle them gracefully.
  prefs: []
  type: TYPE_NORMAL
- en: Test responsiveness
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Besides functional testing, ensure that your application is responsive and works
    well on different screen sizes and devices. This will require some next-level
    platform support. Companies such as LambdaTest, Browser Stack, and Sauce Labs
    provide custom environment configurations to ensure our application runs correctly
    under different architectures. These include iOS and Android mobile devices, tablets,
    and laptops of differing screen sizes. It is here that trying to maintain all
    these physical devices with the latest updates can become unfeasible.
  prefs: []
  type: TYPE_NORMAL
- en: Using LambdaTest online to automate the browser testing grid
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cross-browser testing with LambdaTest allows you to test your web applications
    or websites across a wide range of browsers and operating systems. LambdaTest
    is a cloud-based platform that provides real browsers that run on virtual machines,
    enabling you to perform comprehensive testing without the need to set up physical
    devices or virtual machines locally.
  prefs: []
  type: TYPE_NORMAL
- en: 'To perform cross-browser testing with LambdaTest, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you need to sign up for a LambdaTest account. Once you’ve registered,
    you can access the LambdaTest dashboard:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13\. 1 – LambdaTest dashboard](img/B19395_13_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13\. 1 – LambdaTest dashboard
  prefs: []
  type: TYPE_NORMAL
- en: 'On the LambdaTest dashboard, you can select the browsers and operating systems
    you want to test your website on. A large variety of browsers and versions are
    available, including Chrome, Safari, and Edge on different operating systems such
    as Windows and macOS, as well as iOS and Android mobile devices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 13.2 – LambdaTest browser, operating system, and screen resolution
    selections](img/B19395_13_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.2 – LambdaTest browser, operating system, and screen resolution selections
  prefs: []
  type: TYPE_NORMAL
- en: You can choose to run tests on either the *live interactive testing* environment
    or the *automated screenshot* *testing* environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Live interactive testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this mode, you can interact with browsers in real time, just like using
    a physical device:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.3 – LambdaTest live interactive testing for manual testers](img/B19395_13_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.3 – LambdaTest live interactive testing for manual testers
  prefs: []
  type: TYPE_NORMAL
- en: You can navigate your website, perform actions, and manually check for multiple
    issues. Interactive live testing is a pivotal feature in modern test automation
    frameworks that aligns well with a focus on inspecting tests mid-execution.
  prefs: []
  type: TYPE_NORMAL
- en: The live interactive testing feature provided by LambdaTest allows testers to
    interact with a website or web application in a real-time environment. This mirrors
    the experience a user would have on a physical device.
  prefs: []
  type: TYPE_NORMAL
- en: Automated screenshot testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this mode, LambdaTest takes screenshots of your website on different browsers
    and operating systems automatically. This is useful for quick checks and to see
    how your website looks on various configurations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.4 – Automated screenshot testing](img/B19395_13_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.4 – Automated screenshot testing
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve selected the browsers and testing mode, you can enter your website’s
    URL in LambdaTest and start the testing process. The platform will open virtual
    machines with the chosen browsers and load your website for testing.
  prefs: []
  type: TYPE_NORMAL
- en: During the testing process, you can inspect elements, use developer tools, and
    debug any issues you encounter. You can also take screenshots and save them for
    further analysis and reporting.
  prefs: []
  type: TYPE_NORMAL
- en: LambdaTest provides detailed test reports, including screenshots and logs, which
    can help you identify any discrepancies across browsers and operating system configurations.
    You can share these with your team to discuss and address any issues that are
    found during cross-browser testing.
  prefs: []
  type: TYPE_NORMAL
- en: They also offer integrations with various testing and collaboration tools, making
    it easier to incorporate cross-browser testing seamlessly into your existing development
    workflow. By using LambdaTest for cross-browser testing, you can ensure that your
    web application performs consistently and optimally across different browsers
    and operating systems.
  prefs: []
  type: TYPE_NORMAL
- en: Using Selenium Standalone server to locally build the testing grid
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cross-browser testing with Selenium Standalone server allows you to test web
    applications or websites across multiple browsers and operating systems using
    the Selenium WebDriver API. The standalone server acts as a hub that connects
    to different browsers and executes test scripts on them.
  prefs: []
  type: TYPE_NORMAL
- en: 'To perform cross-browser testing with the Selenium Standalone server, follow
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the Selenium Standalone server JAR file from the official Selenium
    website and run it on your machine or a dedicated server. This server acts as
    a central hub that manages browser sessions and receives test commands from your
    test scripts.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install the browsers you want to test on the machine where the Selenium Standalone
    server is running. Ensure that you have the necessary browser drivers installed
    for each browser (for example, ChromeDriver for Chrome, GeckoDriver for Edge)
    and that they have been added to your system’s PATH.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Develop your test scripts using your preferred programming language and Selenium
    WebDriver bindings (for example, JavaScript, Python, C#, and so on). In your test
    scripts, set the desired capabilities to specify the browser and operating system
    configurations you want to test. The desired capabilities define which browser,
    browser version, and operating system Selenium Standalone server should use for
    the test. Use the Selenium WebDriver API to request a new browser session from
    the Selenium Standalone server, specifying the desired capabilities. The server
    will then launch the specified browser on the configured machine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the browser session has been established, your test scripts can interact
    with the web elements by using WebDriver commands. You can navigate pages, click
    buttons, fill out forms, and perform other actions to test the functionality and
    user interface of your web application. During the test’s execution, the server
    will collect test results, logs, and any errors that were encountered during cross-browser
    testing.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-environment testing with a shared configuration file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Cross-environment testing involves configuring WebdriverIO to run tests on
    different environments, such as test and staging. Occasionally, this might include
    development as well as production environments. This approach allows you to ensure
    compatibility and functionality across different environments, helping you catch
    potential issues early in the development process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.5 – Three wdio conf files sharing a common config file](img/B19395_13_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.5 – Three wdio conf files sharing a common config file
  prefs: []
  type: TYPE_NORMAL
- en: But we don’t want to repeat all the settings in multiple files. Fortunately,
    WebdriverIO allows us to share values across all environments. We created a `shared.conf`
    file that holds all the settings that are shared across all environments. If any
    settings need to be changed, we can make the necessary changes in a single location.
  prefs: []
  type: TYPE_NORMAL
- en: The way this is accomplished is by creating individual files for each operating
    system and environment, such as `windows.conf` and `mac.conf`. We will do this
    in a cloud environment with `lambdatest.conf` shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `wdio.shared.conf.ts` configuration file, define multiple environments
    (for example, development, test, and production) with the appropriate settings
    for each environment. Here’s an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Regardless of the operating system, every browser will navigate to the same
    URLs without having the information copied multiple times.
  prefs: []
  type: TYPE_NORMAL
- en: This can be quite complex for a project on local machines with potentially different
    resources and configurations. So, the next step is to leverage cloud resources
    to ensure all testing configurations are consistent, such as on LambdaTest. This
    is how the `shared.conf` file is used in `windows.conf`, `mac.conf`, and a cloud-based
    service such as `lambdatest.conf`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of a `windows.conf.ts` or `mac.conf.ts` file using
    the `shared.conf.ts` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: However, `LambdaTest.conf.ts` or other cloud-based services (SauceLabs, BrowserStack,
    and so on) will require different sets of configurations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of a cloud-based service using the `shared.conf`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In this example, we use the `baseUrl` variable to select the appropriate environment
    based on the`"Env=uat"` environment variable that’s set when running the tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `baseUrl` from the configuration to navigate to different URLs for each
    environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'From the command line, we can change the environments the tests run against.
    In this example, we are running against `uat`, which is `the-internet`, and `dev`,
    which is `candymapperr2.com` on Windows on Chrome and Edge browsers. Lastly, the
    `prod` example runs against `candymapper.com` on Mac on Chrome and Safari:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'From this, we can see how we might start getting to a point where we’re trying
    to support large combinations of operating systems, browsers, and even older versions.
    This level of architecture support alone will not be sustainable, so the next
    logical step is to move testing to the cloud. This brings us some unique advantages.
    The console output of the tests is still available when it’s run in a cloud environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.6 – Results from the terminal window in LambdaTest](img/B19395_13_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.6 – Results from the terminal window in LambdaTest
  prefs: []
  type: TYPE_NORMAL
- en: 'In the cloud, the test cases can be assigned to run in multiple browsers, versions,
    and operating systems, but without the need to configure and support the underlying
    architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 13.7 – Results of the test cases in multiple operating systems and
    browsers in the cloud](img/B19395_13_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.7 – Results of the test cases in multiple operating systems and browsers
    in the cloud
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows the multiple browsers and operating systems that
    we can run against. Now, if we were to click on a single item, we could dive deeper
    into the details of a particular system and run results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.8 – Test run on Safari V.15 on Mac Monteray in the cloud](img/B19395_13_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.8 – Test run on Safari V.15 on Mac Monteray in the cloud
  prefs: []
  type: TYPE_NORMAL
- en: 'And while screen captures are nice, it’s even better to watch an entire video
    that’s been recorded. This provides a clear look into the interactions of a test
    run:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.9 – A video still of the test case running in LambdaTest](img/B19395_13_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.9 – A video still of the test case running in LambdaTest
  prefs: []
  type: TYPE_NORMAL
- en: Again, video storage space and cleanup are less time-consuming. The costs can
    be compared to having one or two team members dedicated to developing, enhancing,
    and maintaining such large files generated on-site becoming prohibitive when they
    could be spending more time writing more test cases, analyzing results, and writing
    defects.
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding the rabbit hole of horizontal scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is important to the 80/20 rule and the rule of threes in mind. We do not
    want to try to support 80% of the popular browser and operating system combinations
    when our customers are using only 20%. It may sound pro-active to try to support
    Safari on Mac when our customers only use Chrome on Windows. Attempting to do
    a regression test in a new browser on every environment becomes logarithmically
    impossible. You may not have the time to execute all test cases on all browsers
    and all environments. We only want to test on the browsers that are used by more
    of our users, so that might be a maximum combination of three: one browser in
    two operating systems or two browsers in one operating system. In addition, time
    can be taken away from creating new tests if we are trying to determine the root
    cause of why one test runs in one browser or operating system and fails in another.'
  prefs: []
  type: TYPE_NORMAL
- en: Handling environment-specific logic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If your application has environment-specific code or issues, use conditional
    checks or feature detection to handle them gracefully:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Rule of thumb
  prefs: []
  type: TYPE_NORMAL
- en: Try not to get bogged down in getting All-Pass on every browser and operating
    system. Expand to one additional browser, then one additional operating system.
    It is best to only perform smoke testing on peripheral configurations. It can
    easily consume your time supporting logarithmically.
  prefs: []
  type: TYPE_NORMAL
- en: 'What if we have a new field that has been added to our testing environment
    but does not exist in production? Can we build a test that will support both?
    At this point, we can introduce a new set of `IfExist()` custom commands. Each
    base method, including `click()`, `setValue()`, and `select()`, will have a corresponding
    function: `clickIfExist()`, `setValueIfExist()`, and `selectIfExist()`, respectively.
    We can also add a `verifyIfExist()` method. The goal is that rather than have
    separate versions of every test for each environment, we have one set of tests
    that is highly likely to reach the endpoint of the journey, even if there are
    minor differences along the way.'
  prefs: []
  type: TYPE_NORMAL
- en: The multiverse – one test, two environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The advantage is that these `IfExist()` methods will not stop the test if the
    object doesn’t exist. Our tests can now be executed in a test environment where
    new functionality exists, as well as a production environment where the functionality
    is yet to be pushed. For example, a page may ask for a month to be selected from
    a list on a long survey navigation path. In the staging environment, this requires
    the **Next** button to be explicitly clicked to move to the page. However, in
    QA, the **Next** button is removed and the page implicitly moves on once the user
    selects an item from the list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'There are two approaches to this implementation. First, we could enhance the
    `clickadv()` method with an optional property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'However, this leads to code that is less clear about the intention, with the
    potential of a magic Boolean argument being used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Instead, let’s create an alternative function with `ifExists` appended. This
    function uses the automation switchboard to tell the initial wrapper to act differently
    if the element does not exist:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Second, we store the state of the element when we check that it is valid. We
    will also save the locator of the element if it has not already been saved in
    the `beforeCommand` hook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we return immediately from the `clickAdv()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can add the feature just by adding `IfExists`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We can do the same to enhance the `setValueAdv()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We must do the same to create `selectValueAdvIfExists`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Now, we can have tests that are robust enough to run in slightly different test
    environments and still get to the conclusion of an end-to-end test.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, in the following figure, we have two websites:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.10 – Production versus pre-production environments where a button
    element has been removed](img/B19395_13_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.10 – Production versus pre-production environments where a button
    element has been removed
  prefs: []
  type: TYPE_NORMAL
- en: The production site on the left has a **GET IN TOUCH** button that scrolls down
    the page to a customer detail input support page.
  prefs: []
  type: TYPE_NORMAL
- en: On the right is the new release of the site. Note that this site doesn’t include
    the **GET IN** **TOUCH** button.
  prefs: []
  type: TYPE_NORMAL
- en: With the option to click the button only if it exists without failing the test,
    we can begin to have tests that are more flexible in slightly differing environments.
    If the button only exists in one environment, the test can continue to execute
    without failing in both. This changes our focus from maintaining test cases to
    having an increased chance of reaching the end path. Finally, even if the method
    fails because the locator is different, the next few steps will execute on the
    wrong page and still bring the test to a halt for maintenance.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our epic journey, we’ve unlocked a new superpower for our scripts by integrating
    the automation switchboard. This newfound capability ensures that our scripts
    remain as adaptable as the ever-evolving world of superheroes. They can now seamlessly
    operate across various browsers and operating systems, making them as versatile
    as a superhero’s toolkit.
  prefs: []
  type: TYPE_NORMAL
- en: As we turn the page to the next thrilling chapter, get ready to witness our
    web hero, WebdriverIO, taking flight into the clouds of cloud-based test automation
    and scheduling. Just like a superhero soaring through the skies, we’ll delve into
    the extraordinary realm of executing tests in the cloud. This chapter promises
    to be a riveting adventure, showcasing the incredible potential of our superheroic
    scripts as they conquer new heights and challenges in the world of testing.
  prefs: []
  type: TYPE_NORMAL
