<html><head></head><body>
		<div><h1 id="_idParaDest-217" class="chapter-number"><a id="_idTextAnchor218"/>12</h1>
			<h1 id="_idParaDest-218"><a id="_idTextAnchor219"/>Ensuring Data Security with the Saga Pattern, Encryption, and Security Measures</h1>
			<p>When working with microservices architecture and Node.js, you need to have a better understanding of data security with the Saga pattern and learn about encryption and security measures.</p>
			<p>We’ll start this chapter by understanding better how to ensure data security with the Saga pattern, encryption, and security measures in microservices with Node.js. The Saga pattern, data encryption, and security are essential aspects to consider when designing and implementing microservices. The Saga pattern is a technique used to manage distributed transactions across multiple microservices.</p>
			<p>By the end of this chapter, you will have learned how to ensure data security with the Saga pattern, encryption, and security measures in Node.js.</p>
			<p>In this chapter, we’re going to cover the following main topics:</p>
			<ul>
				<li>Compensating actions and Saga orchestration</li>
				<li>Event-driven communication and Sagas and state</li>
				<li>Transport layer security (TLS) and data encryption at rest</li>
				<li>Encryption algorithms and key management</li>
				<li>Authentication, authorization, input validation, secure coding practices, and API rate limiting</li>
			</ul>
			<p>In the following section, we’re going to learn how to work with compensating actions and Saga orchestration. Compensating actions and Saga orchestration are both concepts used in microservices architecture.</p>
			<h1 id="_idParaDest-219"><a id="_idTextAnchor220"/>Compensating actions and Saga orchestration</h1>
			<p>Microservices often need to have transactional behavior across multiple services. Compensating actions and Saga orchestration are two concepts related to the Saga pattern, which is a way to manage data consistency across microservices in distributed transaction scenarios.</p>
			<h2 id="_idParaDest-220"><a id="_idTextAnchor221"/>Compensating actions</h2>
			<p><strong class="bold">Compensating actions</strong> are used to undo the effects<a id="_idIndexMarker942"/> of a failed operation in a microservices architecture. They are often needed when an operation consists of multiple steps that are eventually consistent, meaning that the system might be in an inconsistent state until all steps are completed. If one or more of the steps fail, the system should revert to a consistent state by applying compensating actions that revert changes made by the previous steps. For example, if an operation involves reserving a hotel room, booking a flight, and charging a credit card, and the flight booking fails, the compensating actions would be to cancel the hotel reservation and refund the credit card. Compensating actions are usually implemented as separate transactions triggered by an error or a timeout. They can also be idempotent, meaning that they can be executed multiple times without changing the outcome.</p>
			<p>Unlike in a monolithic system where traditional database transactions can be used, this is not possible in a distributed system where each microservice can have its own database.</p>
			<p>Let’s take a look at one of the most common use cases of compensating actions. In microservices, compensating actions are crucial when a complex transaction involves multiple steps across different services, and a failure occurs at any point. Instead of rolling back the entire transaction, compensating actions are triggered to revert changes made during the transaction.</p>
			<p>For example, consider an e-commerce system where a user places an order and several microservices are involved (order creation, inventory deduction, payment processing). If payment fails, compensating actions might involve canceling the order, adding inventory back, and refunding the user.</p>
			<p>The following are some key considerations<a id="_idIndexMarker943"/> for compensating actions:</p>
			<ul>
				<li><strong class="bold">Idempotency</strong>: Compensating actions must be designed to be idempotent, ensuring that executing them multiple times has the same effect as executing them once.</li>
				<li><strong class="bold">Atomicity</strong>: Each compensating action should be atomic and independent of others to ensure proper<a id="_idIndexMarker944"/> handling.</li>
			</ul>
			<p><strong class="bold">Failure scenarios</strong> for compensating actions in microservices<a id="_idIndexMarker945"/> are situations where<a id="_idIndexMarker946"/> the compensating actions themselves fail or are not executed properly. This can lead to data inconsistency, resource leakage, or business logic errors. Some examples<a id="_idIndexMarker947"/> of failure scenarios are the following:</p>
			<ul>
				<li><strong class="bold">Network failures</strong>: If the network connection between the services is unreliable or slow, compensating actions might not be able to reach the target services or might be delayed. This can result in partial or duplicate execution of the compensating actions, causing data corruption or inconsistency.</li>
				<li><strong class="bold">Service failures</strong>: If the target service is unavailable or crashes during the execution of the compensating action, the compensating action might not be completed or might be rolled back. This can leave the system in an inconsistent state or cause resource leakage.</li>
				<li><strong class="bold">Business logic failures</strong>: If the compensating action violates some business rules or constraints, the compensating action might fail or cause unwanted side effects. For example, if the compensating action tries to cancel a hotel reservation that has already been checked in, the compensating action might fail or incur a penalty fee.</li>
				<li><strong class="bold">Data conflicts</strong>: If the data that the compensating action tries to modify has been changed by another concurrent operation, the compensating action might fail or overwrite the new data. This can cause data loss or inconsistency.</li>
			</ul>
			<p>To handle these failure scenarios, some possible solutions<a id="_idIndexMarker948"/> include the following:</p>
			<ul>
				<li><strong class="bold">Retry mechanism</strong>: The compensating action can be retried a certain number of times or until a timeout is reached, in case of transient failures or network delays. The retry mechanism should also handle idempotency and concurrency issues, such as using unique identifiers or version numbers to avoid duplicate or conflicting updates.</li>
				<li><strong class="bold">Fallback mechanism</strong>: The compensating action can have a fallback option that provides an alternative way to undo the original operation, in case of permanent failures or service unavailability. The fallback mechanism should also ensure data consistency and business logic correctness, such as using a manual process or a third-party service to perform the compensating action.</li>
				<li><strong class="bold">Compensation chain</strong>: The compensating action can trigger another compensating action in case of failure, forming a chain of compensations that eventually restores the system to a consistent state. The compensation chain should also avoid circular dependencies and infinite loops, such as using a termination condition or a maximum <a id="_idIndexMarker949"/>depth limit to stop the chain.</li>
			</ul>
			<p>Compensating transactions come to the rescue in such situations. They are a way to undo the previous operations in case of a failure. For example, if you’re creating an order and you’ve deducted an item from inventory, but the payment service fails due to some reason, you would want to compensate for the deducted item and add it back to the inventory. This undo operation is the compensating action.</p>
			<p>We have learned the basics of compensating actions, so now, let’s move on to Saga orchestration.</p>
			<h2 id="_idParaDest-221"><a id="_idTextAnchor222"/>Saga orchestration</h2>
			<p><strong class="bold">Saga</strong> is a design pattern to manage transactions<a id="_idIndexMarker950"/> across multiple microservices. <strong class="bold">Saga orchestration</strong> is a specific way to implement the Saga pattern. In this approach, a central service (the “orchestrator”) manages the sequence of steps for the transaction and tells each service what to do and when. It also handles failures and triggers compensating actions when necessary. The advantage is that this simplifies error handling as Saga orchestration is centralized and provides consistency across transactions. However, it also creates a dependency on the orchestrator service, which can become a bottleneck.</p>
			<p>The most common use case of Saga orchestration is in scenarios where a business process spans multiple microservices, whereby a Saga ensures that each step in the process is either fully completed or compensated for in case of failure.</p>
			<p>For example, in the context of an e-commerce system, a Saga might involve multiple steps: creating an order, deducting inventory, processing payment, and shipping. If any step fails, compensating actions<a id="_idIndexMarker951"/> are triggered to revert changes made during the preceding steps.</p>
			<p>The two types of Saga patterns are as follows:</p>
			<ul>
				<li><strong class="bold">Choreography</strong>: In choreography-based Sagas, each microservice<a id="_idIndexMarker952"/> involved knows<a id="_idIndexMarker953"/> how to initiate its part of the Saga and communicate with others to achieve the overall business process.</li>
				<li><strong class="bold">Orchestration</strong>: In orchestration-based Sagas, there is a central<a id="_idIndexMarker954"/> component (orchestrator) that coordinates the sequence of steps<a id="_idIndexMarker955"/> in the Saga, instructing microservices when to execute their parts.</li>
			</ul>
			<p>Both approaches have their advantages and disadvantages, depending on the complexity, reliability, and scalability of the system.</p>
			<p>The following are some key considerations<a id="_idIndexMarker956"/> for Saga orchestration:</p>
			<ul>
				<li><strong class="bold">Sagas versus transactions</strong>: Sagas are different from traditional <strong class="bold">ACID</strong> (<strong class="bold">Atomicity</strong>, <strong class="bold">Consistency</strong>, <strong class="bold">Isolation</strong>, <strong class="bold">Durability</strong>) transactions as they focus on distributed<a id="_idIndexMarker957"/> and long-running processes rather than short-lived, isolated transactions.</li>
				<li><strong class="bold">Compensating transactions</strong>: The ability to compensate for failures is a critical aspect of Sagas, ensuring that the system remains consistent even if individual steps fail.</li>
			</ul>
			<p>Saga orchestration is a technique to manage data consistency across microservices in distributed transaction scenarios. It uses a central coordinator to execute and compensate transactions.</p>
			<p>A Saga may face the following<a id="_idIndexMarker958"/> challenges:</p>
			<ul>
				<li><strong class="bold">Consistency</strong>: Ensuring that the system remains consistent even in the presence of failures. To solve this, the Saga can use techniques such as versioning, locking, or timestamps to prevent or resolve data conflicts.</li>
				<li><strong class="bold">Durability</strong>: Handling scenarios where the system fails at different points in the Saga and ensuring that the state is recoverable. To solve this, the Saga can use techniques such as retries, timeouts, circuit breakers, or compensating transactions to recover<a id="_idIndexMarker959"/> from failures and restore data consistency (<a href="https://research.aimultiple.com/facial-recognition-challenges/">https://research.aimultiple.com/facial-recognition-challenges/</a>).</li>
				<li><strong class="bold">Complexity</strong>: Implementing and managing Sagas introduces complexity, and proper tooling and patterns are needed. To solve this, the Saga can use tools and frameworks that support the Saga pattern, such as Axon, Eventuate, or Camunda.</li>
			</ul>
			<p>In general, both concepts serve to ensure data consistency and handle failures in a distributed system environment. It’s also important to note that choosing an approach depends on the specific needs of your application and team capacity. Both have their advantages and trade-offs.</p>
			<p>Here is some sample Saga orchestration<a id="_idIndexMarker960"/> code for e-commerce in Node.js (divided into code blocks).</p>
			<p>Let us go step by step, starting with the initiation of a service with default dependencies and constants:</p>
			<pre class="source-code">
// Orchestator service
const express = require('express');
const KafkaBroker = require('./kafkaHandler/kafkaBroker');
const app = express();
const port = 3000;
// Kafka producer and consumer
const kafkaBroker = new KafkaBroker();
const producer = kafkaBroker.getProducer();
const consumer = kafkaBroker.getConsumer();
// Order state
const orderState = {
  PENDING: 'PENDING',
  APPROVED: 'APPROVED',
  REJECTED: 'REJECTED',
  CANCELLED: 'CANCELLED'
};
// Order database (mock)
const orders = {};</pre>
			<p>Next, we’ll create API endpoints<a id="_idIndexMarker961"/> with their functionalities:</p>
			<pre class="source-code">
// Create a new order
app.post('/order', (req, res) =&gt; {
  // Generate a random order ID and get the order details
  const orderId = Math.floor(Math.random() * 10000);
  const order = req.body;
  // Set the order status to pending and save it
  order.status = orderState.PENDING;
  orders[orderId] = order;
  // Send a message to the order service to start the saga
  producer.send([{
    topic: 'order',
    messages: JSON.stringify({
      type: 'ORDER_CREATED',
      payload: {
        orderId: orderId,
        order: order
      }
    })
  }]);
  // Return the order ID and status
  res.json({
    orderId: orderId,
    status: order.status
  });
});</pre>
			<p>With the following code block, we can<a id="_idIndexMarker962"/> handle messages from the order service:</p>
			<pre class="source-code">
// Handle the messages from the order service
consumer.on('message', (message) =&gt; {
  // Parse the message value and get the event type and payload
  const event = JSON.parse(message.value);
  const { type, payload } = event;
  // Get the order ID and order from the payload
  const { orderId, order } = payload;
  // Find the order in the database
  const currentOrder = orders[orderId];
  // Check if the order exists and is not already cancelled
  if (currentOrder &amp;&amp; currentOrder.status !== orderState.CANCELLED) {
    // Handle the event type
    switch (type) {
      // The order service has approved the order
      case 'ORDER_APPROVED':
        // Set the order status to approved and send a message to the payment service
        currentOrder.status = orderState.APPROVED;
        producer.send([{
          topic: 'payment',
          messages: JSON.stringify({
            type: 'PAYMENT_REQUESTED',
            payload: {
              orderId: orderId,
              order: order
            }
          })
        }]);
        break;
      // The order service has rejected the order
      case 'ORDER_REJECTED':
        // Set the order status to rejected
        currentOrder.status = orderState.REJECTED;
        break;
      // The payment service has charged the payment
      case 'PAYMENT_APPROVED':
        // Send a message to the stock service to reserve the items
        producer.send([{
          topic: 'stock',
          messages: JSON.stringify({
            type: 'STOCK_REQUESTED',
            payload: {
              orderId: orderId,
              order: order
            }
          })
        }]);
        break;
      // The payment service has failed to charge the payment
      case 'PAYMENT_REJECTED':
        // Send a message to the order service to reject the order
        producer.send([{
          topic: 'order',
          messages: JSON.stringify({
            type: 'ORDER_REJECTED',
            payload: {
              orderId: orderId,
              order: order
            }
          })
        }]);
        break;
      // The stock service has reserved the items
      case 'STOCK_APPROVED':
        // The saga is completed successfully
        console.log('Saga completed successfully');
        break;
      // The stock service has failed to reserve the items
      case 'STOCK_REJECTED':
        // Send a message to the payment service to refund the payment
        producer.send([{
          topic: 'payment',
          messages: JSON.stringify({
            type: 'PAYMENT_REFUNDED',
            payload: {
              orderId: orderId,
              order: order
            }
          })
        }]);
        // Send a message to the order service to reject the order
        producer.send([{
          topic: 'order',
          messages: JSON.stringify({
            type: 'ORDER_REJECTED',
            payload: {
              orderId: orderId,
              order: order
            }
          })
        }]);
        break;
      default:
        // Unknown event type
        console.error('Unknown event type:', type);
    }
  } else {
    // The order is not found or already cancelled
    console.error('Order not found or already cancelled:', orderId);
  }
});</pre>
			<p>Finally, we’ll start the server<a id="_idIndexMarker963"/> on the selected port:</p>
			<pre class="source-code">
// Start the server
app.listen(port, () =&gt; {
  console.log(`Orchestrator service listening at http://localhost:${port}`);
});</pre>
			<p>The output of this code depends<a id="_idIndexMarker964"/> on the input and the events that occur in the order processing saga. The code is an example of an orchestrator service in Node.js that uses Kafka as a message broker to coordinate order, payment, and stock services. The code defines the following steps:</p>
			<ul>
				<li>When a new order is created, the orchestrator service assigns a random order ID, sets the order status to <code>pending</code>, saves it in a mock database, and sends a message to the order service to start the Saga.</li>
				<li>When the orchestrator service receives a message from the order service, it checks the event type and the order ID and finds the corresponding order in the database. If the order exists and is not already cancelled, it performs the following actions based on the event type:<ul><li>If the order service has approved the order, the orchestrator service sets the order status to <code>approved</code> and sends a message to the payment service to request the payment.</li><li>If the order service has rejected the order, the orchestrator service sets the order status to <code>rejected</code> and does nothing else.</li><li>If the payment service has charged the payment, the orchestrator service sends a message to the stock service to reserve the items.</li><li>If the payment service has failed to charge the payment, the orchestrator service sends a message to the order service to reject the order.</li><li>If the stock service has reserved the items, the orchestrator service logs that the saga is completed successfully and does nothing else.</li><li>If the stock service has failed to reserve the items, the orchestrator service sends a message to the payment service to refund the payment and a message to the order service to reject the order.</li></ul></li>
				<li>If the event type is unknown, the orchestrator service logs an error and does nothing else.</li>
				<li>If the order is not found or already cancelled, the orchestrator service logs an error and does nothing else.</li>
			</ul>
			<p>The code also defines a route to create a new order and a listener to start the server. This code’s output would be the console<a id="_idIndexMarker965"/> logs and the JSON responses sent or received by the orchestrator service.</p>
			<p><em class="italic">Figure 12</em><em class="italic">.1</em> illustrates Saga orchestration:</p>
			<div><div><img src="img/B14980_12_01.jpg" alt="Figure 12.1: Saga orchestration (image by Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.1: Saga orchestration (image by Freepik)</p>
			<p>In summary, compensating actions and Saga orchestration are essential patterns in microservices architecture, enabling the design of robust and resilient distributed systems. They provide mechanisms to handle failures and maintain data consistency in scenarios where traditional ACID<a id="_idIndexMarker966"/> transactions are not applicable.</p>
			<p>With an understanding of these concepts, let’s now move to event-driven communication and Sagas and state.</p>
			<h1 id="_idParaDest-222"><a id="_idTextAnchor223"/>Event-driven communication and Sagas with state</h1>
			<p>Event-driven communication and Sagas and state refer to software and system development concepts, particularly within the realm of microservices architecture.</p>
			<h2 id="_idParaDest-223"><a id="_idTextAnchor224"/>Event-driven communication</h2>
			<p><strong class="bold">Event-driven communication</strong> is a communication<a id="_idIndexMarker967"/> paradigm between software components where one component changes its state and emits an event to notify other components. The advantage of this communication model is that it helps reduce system connectivity and enhances reactivity, scalability, and flexibility.</p>
			<p>A use case of event-driven communication is that in a distributed system of microservices, event-driven communication is valuable for loosely coupling services and enabling asynchronous, real-time interactions.</p>
			<p>For instance, in an e-commerce<a id="_idIndexMarker968"/> system, when a user places an order, the <code>OrderPlaced</code> event. The <strong class="bold">inventory service and payment service</strong>, which are interested parties, can subscribe<a id="_idIndexMarker969"/> to this event and take appropriate actions.</p>
			<p>The following are key characteristics<a id="_idIndexMarker970"/> of event-driven communication:</p>
			<ul>
				<li><strong class="bold">Publishers and subscribers</strong>: Microservices act as publishers when generating events and as subscribers when reacting to events of interest.</li>
				<li><strong class="bold">Decoupling</strong>: Event-driven communication promotes loose coupling between microservices, allowing them to evolve independently.</li>
			</ul>
			<p>Event-driven communication is a way of exchanging data between microservices or clients based on events, which are discrete messages that represent changes in the state of the system.</p>
			<p>Challenges with event-driven communication<a id="_idIndexMarker971"/> are illustrated here:</p>
			<ul>
				<li><strong class="bold">Eventual consistency</strong>: As events are processed asynchronously, ensuring eventual consistency across microservices can be challenging. To solve this, event-driven communication can use techniques such as versioning, locking, or timestamps to prevent or resolve data conflicts.</li>
				<li><strong class="bold">Message ordering</strong>: Maintaining the correct order of events is crucial in certain scenarios.</li>
			</ul>
			<p>Here is a simple example of event-driven communication in Node.js, using the built-in <code>http</code> module and the <code>EventEmitter</code> class:</p>
			<pre class="source-code">
// Import the http and events modules
const http = require('http');
const EventEmitter = require('events');
// Create a custom event emitter class
class MyEmitter extends EventEmitter {}
// Create an instance of the custom event emitter
const myEmitter = new MyEmitter();
// Define an event listener for the 'hello' event
myEmitter.on('hello', (name) =&gt; {
  console.log('Hello, ' + name);
});
// Create a simple web server
const server = http.createServer((req, res) =&gt; {
  // Get the query parameter from the request URL
  const url = new URL(req.url, 'http://localhost:3000');
  const name = url.searchParams.get('name');
  // Emit the 'hello' event with the query parameter as the argument
  myEmitter.emit('hello', name);
  // Send a response to the client
  res.end('Event emitted');
});
// Start the server on port 3000
server.listen(3000, () =&gt; {
  console.log('Server listening on port 3000');
});</pre>
			<p>Event-driven communication is a paradigm<a id="_idIndexMarker972"/> where microservices communicate with each other through the generation and consumption of events. Events represent state changes or occurrences within a microservices ecosystem.</p>
			<p>With these concepts learned, we can continue with Sagas and state.</p>
			<h2 id="_idParaDest-224"><a id="_idTextAnchor225"/>Sagas with state</h2>
			<p>In the context of microservices, a <strong class="bold">Saga</strong><strong class="bold"><a id="_idIndexMarker973"/></strong><strong class="bold"> with state</strong> refers to a long-running business process (Saga) that involves a sequence of steps, each with its associated state. The state of the Saga determines the next steps to be taken.</p>
			<p>A common use case of Sagas and state is in complex business processes that span multiple microservices and involve multiple steps with an associated state.</p>
			<p>An example of Sagas and state is as follows. Consider the process of booking a flight. The Saga may involve steps such as seat selection, payment, and confirmation. The state of the Saga (e.g., <code>SeatSelected</code>, <code>PaymentProcessed</code>) determines the next steps in the process.</p>
			<p>Some of its key characteristics <a id="_idIndexMarker974"/>are as follows:</p>
			<ul>
				<li><strong class="bold">Stateful steps</strong>: Each step in the Saga maintains its state, and the overall Saga progresses based on the combination of these states.</li>
				<li><strong class="bold">Compensating actions</strong>: If there is a failure, compensating actions are executed to revert the effects of the preceding steps.</li>
				<li><strong class="bold">Coordination</strong>: There is a need for coordination<a id="_idIndexMarker975"/> to ensure that steps are executed in the correct sequence.</li>
			</ul>
			<p>Saga and state are two important concepts in microservices architecture.</p>
			<p>The following are challenges<a id="_idIndexMarker976"/> for Sagas and state:</p>
			<ul>
				<li><strong class="bold">State management</strong>: Managing and persisting the state of Sagas becomes crucial for reliability.</li>
				<li><strong class="bold">Compensation logic</strong>: Designing and implementing compensating actions for each step requires careful consideration.</li>
			</ul>
			<p>In summary, in microservices architecture, Sagas are used to manage transactions that span multiple services. Each Saga represents a high-level business transaction, which involves steps that need to be performed in multiple services. It manages and oversees these processes, ensuring they either all succeed or undergo a compensating transaction in case of failure, maintaining data consistency<a id="_idIndexMarker977"/> across services. State usually refers to the information maintained by software components during their life cycle. This can involve user info, system configurations, or other operation-critical data.</p>
			<p>Now, we can continue to the next section, in which we will talk about TLS and data encryption at rest.</p>
			<h1 id="_idParaDest-225"><a id="_idTextAnchor226"/>Transport layer security (TLS) and data encryption at rest</h1>
			<p><strong class="bold">Transport layer security</strong> (<strong class="bold">TLS</strong>) is a protocol that provides privacy<a id="_idIndexMarker978"/> and data integrity between two communicating applications. Data encryption at rest is the process of encoding and securing data stored in databases, filesystems, or disk storage. In contrast, data in motion is generally protected by networking protocols, such as TLS.</p>
			<h2 id="_idParaDest-226"><a id="_idTextAnchor227"/>TLS</h2>
			<p><strong class="bold">TLS</strong> is a cryptographic protocol that ensures <a id="_idIndexMarker979"/>secure communication over a computer network. It is widely used to secure data transmission between a client and a server, protecting it from eavesdropping, tampering, and forgery.</p>
			<p>One important use case of TLS is in microservices, where TLS is crucial for securing communication between services over the network. It establishes a secure channel by encrypting data during transmission.</p>
			<p>To implement TLS, each microservice<a id="_idIndexMarker980"/> can be configured to support <strong class="bold">HTTPS</strong>, the secure version of HTTP. TLS certificates are used to encrypt the communication channel, and <strong class="bold">mutual TLS</strong> (<strong class="bold">mTLS</strong>) can be implemented for service-to-service<a id="_idIndexMarker981"/> authentication.</p>
			<p>The following are key considerations<a id="_idIndexMarker982"/> for TLS:</p>
			<ul>
				<li><strong class="bold">Encryption</strong>: TLS ensures that data transmitted between microservices is encrypted, preventing unauthorized access.</li>
				<li><strong class="bold">Authentication</strong>: mTLS adds an extra layer of security by requiring both parties to authenticate each other, enhancing the overall security posture.</li>
				<li><strong class="bold">Certificates and public key infrastructure (PKI)</strong>: Certificates and PK) are related concepts that enable secure and authenticated communication over the internet. A certificate is a digital document that contains information about the identity of a user, device, or service, as well as a public key that can be used for encryption and digital signatures. A PKI is a system that manages the creation, distribution, verification, and revocation<a id="_idIndexMarker983"/> of certificates, using trusted entities called <strong class="bold">certificate authorities</strong> (<strong class="bold">CAs</strong>). A PKI ensures that the certificates are valid and trustworthy and that the public keys are linked to the correct owners.</li>
				<li><strong class="bold">TLS handshake</strong>: A TLS handshake is a process that establishes a secure and encrypted connection between a client and a server over the internet.</li>
			</ul>
			<p>TLS is a protocol that provides secure and reliable communication over the internet.</p>
			<p>Some challenges<a id="_idIndexMarker984"/> to TLS are as follows:</p>
			<ul>
				<li><strong class="bold">Certificate management</strong>: Proper management of TLS certificates, including issuance, renewal, and revocation, is crucial. Some solutions are to use a centralized and automated certificate management solution that can discover, inventory, monitor, renew, and revoke certificates across your network.</li>
				<li><strong class="bold">Performance overhead</strong>: While the overhead is minimal, the encryption and decryption process in TLS introduces some computational load. One solution is to use the latest version of TLS (TLS 1.3), which offers faster and more secure connections than previous versions.</li>
				<li><strong class="bold">Algorithm agility</strong>: Algorithm agility is the ability to change or replace cryptographic algorithms without affecting the functionality or security of a system. It is an important aspect of crypto-agility, which is the broader concept of adapting to changes in the cryptographic landscape. Algorithm agility can help mitigate the challenges of TLS, which is a protocol that provides secure and authenticated communication over the internet.</li>
				<li><strong class="bold">Security of private keys</strong>: The security of private keys on TLS is a topic that concerns how to protect cryptographic keys that are used to establish and secure TLS connections. Private keys are secret keys that are used to decrypt data that is encrypted with the corresponding public keys. If the private keys are compromised, an attacker can intercept, modify, or impersonate<a id="_idIndexMarker985"/> the TLS traffic, leading to data breaches, identity theft, or <strong class="bold">man-in-the-middle</strong> (<strong class="bold">MitM</strong>) attacks.</li>
			</ul>
			<p><em class="italic">Figure 12</em><em class="italic">.2</em> illustrates<a id="_idIndexMarker986"/> TLS:</p>
			<div><div><img src="img/B14980_12_02.jpg" alt="Figure 12.2: TLS (image by Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.2: TLS (image by Freepik)</p>
			<p>TLS is used to create a secure environment for web browsing, e-commerce, and other types of internet traffic. It does this by encrypting the data being sent between the client and server, thus preventing potential eavesdroppers from gaining access to sensitive information.</p>
			<p>We can continue now with data encryption at rest.</p>
			<h2 id="_idParaDest-227"><a id="_idTextAnchor228"/>Data encryption at rest</h2>
			<p>Data encryption at rest involves securing<a id="_idIndexMarker987"/> data when it is stored in databases, filesystems, or any other persistent storage. It prevents unauthorized access to data even if physical storage media are compromised.</p>
			<p>In microservices, data encryption at rest is vital for protecting sensitive information stored in databases or other persistent storage solutions.</p>
			<p>To implement data encryption at rest, use encryption algorithms to encrypt data before it is stored. This can be done at the application level or by utilizing features provided by the database or storage system.</p>
			<p>Here are some key considerations<a id="_idIndexMarker988"/> for data encryption at rest:</p>
			<ul>
				<li><strong class="bold">Key management</strong>: Proper key management is essential to ensure that encryption keys are securely stored and managed.</li>
				<li><strong class="bold">Granular encryption</strong>: Depending on sensitivity, consider encrypting specific fields or columns rather than entire datasets for better performance.</li>
			</ul>
			<p>Data encryption at rest is the process of protecting data that is stored on physical media, such as disks or tapes, from unauthorized access or theft.</p>
			<p>The following are challenges<a id="_idIndexMarker989"/> to data encryption at rest:</p>
			<ul>
				<li><strong class="bold">Key life-cycle management</strong>: Managing the life cycle of encryption keys, including generation, rotation, and disposal, can be complex. A solution is to use a centralized and automated certificate management solution that can discover, inventory, monitor, renew, and revoke certificates across your network.</li>
				<li><strong class="bold">Performance impact</strong>: Encrypting and decrypting data at rest can introduce some performance overhead, which needs to be considered. A solution is to use the latest version of TLS (TLS 1.3), which offers faster and more secure connections than previous versions.</li>
			</ul>
			<p>With data at rest encryption, even if an unauthorized party were to gain access to the physical storage, the data would be unreadable without the encryption keys. This process is crucial in ensuring the protection of personal or sensitive information when stored digitally. Combining these techniques allows for comprehensive security both in the transmission and storage of sensitive data.</p>
			<p>In summary, implementing both TLS <a id="_idIndexMarker990"/>for data in transit and encryption at rest provides a layered security approach, safeguarding data throughout its life cycle in a microservices architecture. It is essential to stay updated on security best practices and continuously monitor and adapt security measures based on evolving threats and technologies.</p>
			<p>In the next section, we will learn about encryption algorithms and key management.</p>
			<h1 id="_idParaDest-228"><a id="_idTextAnchor229"/>Encryption algorithms and key management</h1>
			<p>Encryption algorithms and key management are crucial components of information security.</p>
			<h2 id="_idParaDest-229"><a id="_idTextAnchor230"/>Encryption algorithms</h2>
			<p><strong class="bold">Encryption algorithms</strong> are methods of transforming<a id="_idIndexMarker991"/> data into a secret code that can only be deciphered by authorized parties.</p>
			<p>There are several types<a id="_idIndexMarker992"/> of encryption algorithms, including the following:</p>
			<ul>
				<li><strong class="bold">Symmetric algorithms</strong>: The same key is used to encrypt<a id="_idIndexMarker993"/> and decrypt<a id="_idIndexMarker994"/> data. Examples include <strong class="bold">Advanced Encryption Standard</strong> (<strong class="bold">AES</strong>), <strong class="bold">Data Encryption Standard</strong> (<strong class="bold">DES</strong>), <strong class="bold">Triple DES</strong> (<strong class="bold">3DES</strong>), Blowfish, and <strong class="bold">Rivest Cipher 4</strong> (<strong class="bold">RC4</strong>). Here is a brief<a id="_idIndexMarker995"/> summary of each<a id="_idIndexMarker996"/> algorithm:<ul><li><strong class="bold">AES</strong> is the current standard for symmetric<a id="_idIndexMarker997"/> encryption, which means that the same key is used to encrypt and decrypt the data. AES can use different key sizes, such as 128, 192, or 256 bits, and operates on 128-bit blocks of data. AES is considered to be very secure and efficient and is widely used in various applications and protocols, such as HTTPS, VPN, and Wi-Fi.</li><li><strong class="bold">DES</strong> is the predecessor of AES and <a id="_idIndexMarker998"/>was the first standard for symmetric encryption. DES uses a 56-bit key and operates on 64-bit blocks of data. DES is no longer considered secure as its key size is too small and can be cracked by brute-force attacks. DES was officially withdrawn as a standard in 2005.</li><li><strong class="bold">3DES</strong> is a variation of DES that applies<a id="_idIndexMarker999"/> the DES algorithm three times with different keys, effectively increasing the key size to 112 or 168 bits. 3DES is more secure than DES but still suffers from some vulnerabilities, such as its small block size and its slow performance. 3DES is still used in some legacy systems but is not recommended for new applications.</li><li><strong class="bold">Blowfish</strong> is a symmetric encryption algorithm<a id="_idIndexMarker1000"/> that was designed by Bruce Schneier as an alternative to DES. Blowfish can use variable key sizes, up to 448 bits, and operates on 64-bit blocks of data. Blowfish is considered to be secure and fast but has not been widely adopted as a standard. Blowfish is mostly used in some software applications, such as password managers and file encryption tools.</li><li><strong class="bold">RC4</strong> is a symmetric encryption algorithm<a id="_idIndexMarker1001"/> that was designed by Ron Rivest as a stream cipher, which means that it encrypts data 1 bit or byte at a time, rather than in blocks. RC4 can use variable key sizes, up to 256 bits, and is very simple and fast. However, RC4 has been found to have several weaknesses<a id="_idIndexMarker1002"/> and vulnerabilities and is no longer considered secure. RC4 was widely used in some protocols, such as <strong class="bold">Secure Sockets Layer</strong> (<strong class="bold">SSL</strong>), TLS, and <strong class="bold">Wired Equivalent Privacy</strong> (<strong class="bold">WEP</strong>), but has been deprecated or replaced <a id="_idIndexMarker1003"/>by newer algorithms.</li></ul></li>
				<li><strong class="bold">Asymmetric algorithms</strong>: Different keys are used to encrypt<a id="_idIndexMarker1004"/> and decrypt data.</li>
			</ul>
			<p>Encryption algorithms are widely <a id="_idIndexMarker1005"/>used to protect data in transit and at rest, such as online communications, web transactions, and cloud storage. Let’s take a closer look at these:</p>
			<ul>
				<li><strong class="bold">Symmetric encryption</strong>: Symmetric encryption uses a single key<a id="_idIndexMarker1006"/> for both encryption and decryption. It is fast and suitable for bulk data. A use case and example algorithm are as follows:<ul><li><em class="italic">Use case</em>: Protecting data in transit within a microservices architecture.</li><li><em class="italic">Example </em><em class="italic">algorithm</em>: AES.</li></ul></li>
				<li><strong class="bold">Asymmetric encryption</strong>: Asymmetric encryption uses a pair of public<a id="_idIndexMarker1007"/> and private keys. Data encrypted with one key can only be decrypted by the other key in the pair. A use case and example algorithm are as follows:<ul><li><em class="italic">Use case</em>: Securely exchanging secret<a id="_idIndexMarker1008"/> keys for symmetric encryption.</li><li><em class="italic">Example algorithm</em>: <strong class="bold">Rivest-Shamir-Adleman</strong> (<strong class="bold">RSA</strong>).</li></ul></li>
				<li><strong class="bold">Hash functions</strong>: Hash functions create a fixed-size<a id="_idIndexMarker1009"/> output (hash) from variable-size input. They are used for integrity verification. A use case and example algorithm are as follows:<ul><li><em class="italic">Use case</em>: Verifying the integrity of data<a id="_idIndexMarker1010"/> or creating digital signatures.</li><li><em class="italic">Example algorithm</em>: <strong class="bold">Secure Hash Algorithm </strong><strong class="bold">256-bit</strong> (<strong class="bold">SHA-256</strong>).</li></ul></li>
				<li><strong class="bold">Elliptic-curve cryptography (ECC)</strong>: ECC uses the mathematics of elliptic<a id="_idIndexMarker1011"/> curves to provide strong security with shorter key lengths compared to traditional asymmetric algorithms. A use case and example algorithm are as follows:<ul><li><em class="italic">Use case</em>: Efficient asymmetric<a id="_idIndexMarker1012"/> encryption for resource-constrained environments.</li><li><em class="italic">Example algorithm</em>: <strong class="bold">Elliptic Curve </strong><strong class="bold">Diffie-Hellman</strong> (<strong class="bold">ECDH</strong>).</li></ul></li>
			</ul>
			<p><em class="italic">Figure 12</em><em class="italic">.3</em> illustrates encryption algorithms:</p>
			<div><div><img src="img/B14980_12_03.jpg" alt="Figure 12.3: Encryption (image by macrovector on Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.3: Encryption (image by macrovector on Freepik)</p>
			<p>You need to master these<a id="_idIndexMarker1013"/> concepts for better data encryption.</p>
			<p>Now, we can continue with key management.</p>
			<h2 id="_idParaDest-230"><a id="_idTextAnchor231"/>Key management</h2>
			<p><strong class="bold">Key management</strong> involves the entire life cycle<a id="_idIndexMarker1014"/> of cryptographic keys and other key-related materials. Key management in microservices is the process of generating, storing, rotating, and revoking encryption keys that are used to protect data and communication among microservices. Let’s look at this in more detail, along with some examples of best practices and considerations:</p>
			<ul>
				<li><strong class="bold">Key generation</strong>: Key generation is the process<a id="_idIndexMarker1015"/> of creating keys for cryptography. Keys are used to encrypt and decrypt data so that only authorized parties can access it.<ul><li><em class="italic">Best practice</em>: Use cryptographically secure random number generators to create strong keys.</li><li><em class="italic">Considerations</em>: Key length and algorithm choice impact security. Longer keys generally provide stronger security.</li></ul></li>
				<li><strong class="bold">Key storage</strong>: Key storage is the process of keeping encryption keys safe and accessible for authorized parties. Encryption keys are used to protect data and communication from unauthorized access or theft.<ul><li><em class="italic">Best practice</em>: Store encryption keys<a id="_idIndexMarker1016"/> securely, avoiding hardcoding them in source code or configuration files.</li><li><em class="italic">Considerations</em>: Utilize <strong class="bold">hardware security modules</strong> (<strong class="bold">HSMs</strong>) for enhanced key protection.</li></ul></li>
				<li><strong class="bold">Key distribution</strong>: Key distribution is the process of delivering encryption keys to parties who wish to exchange secure encrypted data. Encryption keys are used to protect data and communication from unauthorized access or theft.<ul><li><em class="italic">Best practice</em>: Securely distribute keys in asymmetric<a id="_idIndexMarker1017"/> encryption scenarios. Use key exchange protocols such as <strong class="bold">Diffie-Hellman</strong>.</li><li><em class="italic">Considerations</em>: Protect against MitM attacks during key exchange. A MitM attack is a type of cyberattack where an attacker secretly intercepts and modifies the communication between<a id="_idIndexMarker1018"/> two parties who think they are directly talking to each other.</li></ul></li>
				<li><strong class="bold">Key rotation</strong>: Key rotation is the process of changing encryption keys periodically to reduce the risk of compromise or exposure.<ul><li><em class="italic">Best practice</em>: Regularly rotate keys to minimize the impact of a compromised key.</li><li><em class="italic">Considerations</em>: Coordinate key rotation across microservices to avoid disruption.</li></ul></li>
				<li><strong class="bold">Key revocation</strong>: Key revocation is the process of declaring that an encryption key is no longer valid and should not be used for encryption or decryption.<ul><li><em class="italic">Best practice</em>: Implement processes for revoking compromised keys.</li><li><em class="italic">Considerations</em>: Rapidly revoke and replace keys if a compromise is suspected.</li></ul></li>
				<li><strong class="bold">Secrets management</strong>: Secrets management is the process of securely and efficiently managing the creation, rotation, revocation, and storage of digital authorization credentials.<ul><li><em class="italic">Best practice</em>: Use dedicated secrets management solutions for secure storage, retrieval, and rotation of keys and other sensitive information.</li><li><em class="italic">Considerations</em>: Integrate with solutions that support key life-cycle management.</li></ul></li>
				<li><strong class="bold">Monitoring and auditing</strong>: Monitoring and auditing are two related but distinct processes that are essential for ensuring the effectiveness and compliance of an organization’s operations, systems, and data.<ul><li><em class="italic">Best practice</em>: Implement robust monitoring and auditing of key usage.</li><li><em class="italic">Considerations</em>: Detect and respond to unusual or unauthorized key access.</li></ul></li>
				<li><strong class="bold">Crypto-agility</strong>: Crypto-agility is the ability of a system to switch between different cryptographic algorithms, keys, and parameters without disrupting the system’s functionality or security.<ul><li><em class="italic">Best practice</em>: Design systems with crypto-agility to facilitate the adoption of new algorithms or key lengths.</li><li><em class="italic">Considerations</em>: Stay informed about developments in cryptography and be prepared to transition<a id="_idIndexMarker1019"/> to stronger algorithms.</li></ul></li>
			</ul>
			<p>Key management is important because if keys are<a id="_idIndexMarker1020"/> compromised, the data protected by those keys is also compromised. Therefore, <strong class="bold">key management systems</strong> (<strong class="bold">KMSs</strong>) are designed to protect against key compromises.</p>
			<p>In summary, encryption algorithms<a id="_idIndexMarker1021"/> and key management<a id="_idIndexMarker1022"/> are foundational elements of microservices security. Choosing appropriate algorithms and implementing sound key management practices are critical for protecting sensitive information and ensuring the overall security of a microservices architecture.</p>
			<p>Now, let’s move on to the next section, in which we will discuss authentication and authorization, input validation, secure coding practices, and API rate limiting.</p>
			<h1 id="_idParaDest-231"><a id="_idTextAnchor232"/>Authentication, authorization, input validation, secure coding practices, and API rate limiting</h1>
			<p>In this section, we will discuss some of the core principles of secure software development and API management.</p>
			<h2 id="_idParaDest-232"><a id="_idTextAnchor233"/>Authentication</h2>
			<p><strong class="bold">Authentication</strong> is the process of verifying the identity <a id="_idIndexMarker1023"/>of a user, device, or system. It often involves a username and password but can include any other method of demonstrating identity, such as biometrics.</p>
			<p>Best practices for authentication<a id="_idIndexMarker1024"/> are as follows:</p>
			<ul>
				<li>Use strong<a id="_idIndexMarker1025"/> authentication<a id="_idIndexMarker1026"/> mechanisms such as <strong class="bold">Open Authorization 2.0</strong> (<strong class="bold">OAuth 2.0</strong>) or <strong class="bold">JSON Web </strong><strong class="bold">Token</strong> (<strong class="bold">JWT</strong>).</li>
				<li>Implement <strong class="bold">multi-factor authentication</strong> (<strong class="bold">MFA</strong>) for added <a id="_idIndexMarker1027"/>security.</li>
				<li>Centralize authentication to a dedicated service when possible.</li>
			</ul>
			<p>The following are some key considerations<a id="_idIndexMarker1028"/> for authentication:</p>
			<ul>
				<li>Ensure secure transmission of credentials.</li>
				<li>Regularly audit and monitor authentication logs.</li>
			</ul>
			<p>Authentication is the process of verifying the identity of a user or a process before granting access to confidential data or systems.</p>
			<p><em class="italic">Figure 12</em><em class="italic">.4</em> illustrates authentication and authorization:</p>
			<div><div><img src="img/B14980_12_04.jpg" alt="Figure 12.4: Authorization and authentication (image by vectorjuice on Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 12.4: Authorization and authentication (image by vectorjuice on Freepik)</p>
			<h2 id="_idParaDest-233"><a id="_idTextAnchor234"/>Authorization</h2>
			<p>Once a user’s identity is verified, <strong class="bold">authorization</strong> determines what permissions<a id="_idIndexMarker1029"/> the user has—that is, what they are allowed to do. This could include access to certain files, the ability to perform certain functions, and so on.</p>
			<p>The following <a id="_idIndexMarker1030"/>are best practices<a id="_idIndexMarker1031"/> for authorization:</p>
			<ul>
				<li>Adopt the <strong class="bold">principle of least </strong><strong class="bold">privilege</strong> (<strong class="bold">PoLP</strong>).</li>
				<li>Use <strong class="bold">role-based access control</strong> (<strong class="bold">RBAC</strong>) for fine-grained<a id="_idIndexMarker1032"/> authorization.</li>
				<li>Regularly review and <a id="_idIndexMarker1033"/>update access permissions.</li>
			</ul>
			<p>Some key considerations<a id="_idIndexMarker1034"/> for authorization are as follows:</p>
			<ul>
				<li>Implement proper session management.</li>
				<li>Use <strong class="bold">attribute-based access control</strong> (<strong class="bold">ABAC</strong>) for more dynamic<a id="_idIndexMarker1035"/> authorization.</li>
			</ul>
			<p>Authorization is the process of granting or denying access to resources, based on the identity and privileges of the requester. Authorization can be applied to different types of resources, such as files, databases, networks, or applications.</p>
			<h2 id="_idParaDest-234"><a id="_idTextAnchor235"/>Input validation</h2>
			<p>This is a process used<a id="_idIndexMarker1036"/> to ensure that data being input into an application or API is valid and secure before it is processed. This can help prevent things such as SQL injection attacks or data corruption.</p>
			<p>The following are best practices<a id="_idIndexMarker1037"/> for input validation:</p>
			<ul>
				<li>Validate and sanitize all user inputs, both on the client and server sides.</li>
				<li>Use parameterized queries to prevent SQL injection.</li>
				<li>Apply input validation on both frontend and backend components.</li>
			</ul>
			<p>Some key considerations<a id="_idIndexMarker1038"/> for input validation are as follows:</p>
			<ul>
				<li>Implement whitelist validation to accept only known and expected inputs.</li>
				<li>Regularly update and patch components to address known vulnerabilities.</li>
			</ul>
			<p>Input validation is the process of checking data that users enter into a website or an application, to make sure that it is correct, complete, and secure.</p>
			<h2 id="_idParaDest-235"><a id="_idTextAnchor236"/>Secure coding practices</h2>
			<p>These are guidelines or standards for writing<a id="_idIndexMarker1039"/> code in a manner that avoids common security vulnerabilities. This could include things such as proper error handling, strong encryption usage, and more.</p>
			<p>Best practices for secure coding practices<a id="_idIndexMarker1040"/> are as follows:</p>
			<ul>
				<li>Follow PoLP when assigning permissions to services.</li>
				<li>Use secure coding frameworks and libraries.</li>
				<li>Conduct regular security code reviews.</li>
			</ul>
			<p>The following are some key considerations<a id="_idIndexMarker1041"/> for secure coding practices:</p>
			<ul>
				<li>Train developers in secure coding practices.</li>
				<li>Implement secure coding guidelines and enforce them.</li>
			</ul>
			<p>Secure coding practices are guidelines and standards that help developers write code that is secure, reliable, and resistant to common vulnerabilities and attacks.</p>
			<h2 id="_idParaDest-236"><a id="_idTextAnchor237"/>API rate limiting</h2>
			<p><strong class="bold">API rate limiting</strong> is the process of limiting the number <a id="_idIndexMarker1042"/>of requests that a client (user or system) can make to an API in a certain amount of time. This helps protect the API from being overloaded and can also be a method of security to prevent things such as brute-force attacks.</p>
			<p>Best practices for API rate limiting<a id="_idIndexMarker1043"/> are as follows:</p>
			<ul>
				<li>Implement rate limiting<a id="_idIndexMarker1044"/> to prevent abuse and protect against <strong class="bold">distributed denial-of-service</strong> (<strong class="bold">DDoS</strong>) attacks.</li>
				<li>Use token buckets or sliding window algorithms (for rate limiting).</li>
			</ul>
			<p class="callout-heading">The Sliding Window technique</p>
			<p class="callout">The <strong class="bold">Sliding Window</strong> technique is a computational approach<a id="_idIndexMarker1045"/> used to optimize certain problems involving arrays, strings, or other data structures. It aims to reduce the use of nested loops and replace them with a single loop, thereby improving time complexity.)</p>
			<ul>
				<li>Provide clear error<a id="_idIndexMarker1046"/> messages when rate limits are exceeded.</li>
			</ul>
			<p>The following are some<a id="_idIndexMarker1047"/> key considerations for API rate limiting:</p>
			<ul>
				<li>Differentiate rate limits based on user roles or API endpoints.</li>
				<li>Implement adaptive rate limiting to respond dynamically to traffic patterns.</li>
			</ul>
			<p>All these practices help improve the reliability and security of software applications and web services.</p>
			<p>In summary, by integrating<a id="_idIndexMarker1048"/> these security practices<a id="_idIndexMarker1049"/> into the development life cycle of microservices, organizations can significantly enhance the security posture of their systems. Regular security assessments, training, and a proactive approach to addressing emerging threats are key components of a robust microservices security strategy.</p>
			<h1 id="_idParaDest-237"><a id="_idTextAnchor238"/>Summary</h1>
			<p>In this chapter, we have learned a lot about microservices and how to ensure data security in a microservices architecture involves implementing various measures, including the use of the Saga pattern, encryption, and additional security measures.</p>
			<p>In summary, by combining the Saga pattern, encryption, and additional security measures, you create a robust defense against various security threats in a microservices environment. Regularly reassess and update security practices to stay ahead of emerging threats.</p>
			<p>Data security is of paramount significance, especially in our modern, data-driven era. Protecting sensitive information from unauthorized access, use, disclosure, disruption, modification, or destruction requires strategic measures. We looked at three ways to ensure data security—by implementing the Saga pattern, encryption, and additional security measures.</p>
			<p>In the next chapter, we are going to learn about monitoring microservices in Node.js.</p>
			<h1 id="_idParaDest-238"><a id="_idTextAnchor239"/>Quiz time</h1>
			<ul>
				<li>What are some key considerations for compensating actions?</li>
				<li>What is a saga orchestration?</li>
				<li>What is event-driven communication?</li>
				<li>What are encryption algorithms?</li>
			</ul>
		</div>
	

		<div><h1 id="_idParaDest-239" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor240"/>Part 4: Monitoring and Logging in Microservices with Node.js</h1>
			<p>In this part, we will talk about monitoring and logging in microservices and how to interpret and analyze logging data in microservices in Node.js.</p>
			<p>The part contains the following chapters:</p>
			<ul>
				<li><a href="B14980_13.xhtml#_idTextAnchor241"><em class="italic">Chapter 13</em></a>, <em class="italic">Monitoring Microservices in Node.js</em></li>
				<li><a href="B14980_14.xhtml#_idTextAnchor261"><em class="italic">Chapter 14</em></a>, <em class="italic">Logging in Microservices with Node.js</em></li>
				<li><a href="B14980_15.xhtml#_idTextAnchor276"><em class="italic">Chapter 15</em></a>, <em class="italic">Interpreting Monitoring Data in Microservices</em></li>
				<li><a href="B14980_16.xhtml#_idTextAnchor285"><em class="italic">Chapter 16</em></a>, <em class="italic">Analyzing Log Data in Microservices with Node.js</em></li>
			</ul>
		</div>
		<div><div></div>
		</div>
		<div><div></div>
		</div>
		<div><div></div>
		</div>
		<div><div></div>
		</div>
		<div><div></div>
		</div>
		<div><div></div>
		</div>
		<div><div></div>
		</div>
		<div><div></div>
		</div>
		<div><div></div>
		</div>
		<div><div></div>
		</div>
	</body></html>