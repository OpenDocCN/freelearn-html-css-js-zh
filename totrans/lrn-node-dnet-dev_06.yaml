- en: Chapter 6. Testing Node.js Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have only been testing our code by exercising it manually. This isn't
    a very sustainable approach as our application becomes larger. Ideally, we should
    regularly exercise all the functionality of our application to check for regressions.
    This would quickly become prohibitively time-consuming if we continued to use
    only manual testing. It is much more effective to maintain a suite of automated
    tests. These also bring many other benefits, for example, acting as documentation
    of our code for other developers.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Writing automated unit tests for our application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing new libraries to help us write more descriptive tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Seeing how to create and use test doubles in JavaScript
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercising our application's web interface using HTTP client tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding full-stack integration tests using browser automation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establishing a structure for writing further tests as we expand our codebase
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writing a simple test in Node.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Node.js comes with a built-in module called `assert` that can be used for testing.
    We can use it to write a simple test for the games service that we wrote in [Chapter
    5](part0030.xhtml#aid-SJGS1 "Chapter 5. Creating Dynamic Websites") *, Building
    Dynamic Websites*. We add the following code under `gameServiceTest.js`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note that the `assert.equal` function takes the actual value as the first argument
    and the expected value as the second argument. This is the opposite way around
    to JUnit's built-in `Assert.Equals`, and the classic-style `Assert.AreEqual` in
    NUnit. It's important to get these parameters the right way around so that they
    appear correctly in error messages when an assertion fails.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Given, When, Then**'
  prefs: []
  type: TYPE_NORMAL
- en: The *Given*, *When*, and *Then* comments in the preceding test are not specific
    to JavaScript or any of the test frameworks we'll be using, but are generally
    a good tool for structuring tests to keep them focused and readable.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now verify our code using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: An exit code of `0` indicates that our test completed successfully without any
    errors. Although we haven't been following test-driven development (writing a
    failing test first before adding any new code), it's still important to see each
    test fail to confirm that it's testing something. Try altering the `availableTo`
    function in `services/games.js` to return an empty array, and run the test again.
  prefs: []
  type: TYPE_NORMAL
- en: Not only do we now get a non-zero exit code, but we also get an error containing
    our assertion failure. Our test output still isn't particular compelling, though.
    Also, the lack of structure in our test script will make it harder to navigate
    as we add more tests. We can address both of these issues by making use of one
    of the testing libraries available for JavaScript.
  prefs: []
  type: TYPE_NORMAL
- en: Structuring the codebase for tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we write more tests for our application, we'll benefit from having more structure
    to our tests. It's common to have at least one test file per production module.
    It will also be useful to have a way of running all of our tests and seeing the
    overall result.
  prefs: []
  type: TYPE_NORMAL
- en: We're going to start adding tests under a `test` directory. From this point
    on in the book, we're also going to keep all of our application code under a `src`
    directory. This will make it easier to navigate our codebase and to keep production
    and test code separate.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you''re following along with the book at this point, you should move `app.js`
    and all the folders (apart from the `bin` folder) under a new `src` directory,
    and update the startup script as follows in `bin/www`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Writing BDD-style tests with Mocha
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From C# or Java, you may be most familiar with the xUnit-style of tests used
    by NUnit, JUnit, and so on. This style structures tests into classes, and turns
    method names into test names. This can be a bit restrictive, and isn't common
    in JavaScript testing. JavaScript test frameworks make use of the less structured,
    and more dynamic, nature of the language to allow more flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: There are several different styles for writing tests in JavaScript. The most
    common is the so-called **behavior-driven development** (**BDD**) style in which
    we describe the behavior of our application in plain English. This is the default
    style of the most popular JavaScript testing frameworks. It is also common in
    frameworks for other programming platforms, most notably RSpec for Ruby.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll be using a popular test framework named Mocha. Let''s first add this
    to our application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `--save-dev` adds Mocha to our `package.json` file as a **development
    dependency**. This indicates that it''s not needed in our production code, and
    `npm` doesn''t need to install it in production environments. We''ll also update
    this file to let `npm` run our tests using Mocha, by adding a test script as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This tells `npm` to execute scripts under the `/test/` directory as tests using
    Mocha when we run `npm test` from the command line.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Mocha and Jasmine**'
  prefs: []
  type: TYPE_NORMAL
- en: There are a large number of different testing frameworks available for JavaScript.
    The most well-established are Jasmine and Mocha. They have comparable features
    and both support the same syntax for writing tests. They are both well-documented,
    and switching between the two is easy.
  prefs: []
  type: TYPE_NORMAL
- en: Jasmine was originally aimed more at testing client-side JavaScript in the browser.
    Mocha was originally more focused on testing server-side Node.js code.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, both frameworks are well-suited for either environment. Jasmine also
    has more *batteries included*, which can make it quicker to get started with.
    Mocha delegates more features to other libraries, giving the user more choice
    about how they prefer to write tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we just need to add some tests! Mocha provides global functions named `describe`
    and `it` for structuring our tests. These functions each take two arguments: a
    string describing the behavior of our application and a callback defining the
    tests for that behavior. The following code snippet shows our previous test rewritten
    using Mocha. We add the following code under `test/services/games.js`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now try running the previous test using `npm test`. You should see output like
    the following (the exact appearance will depend on what console you are using):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Writing BDD-style tests with Mocha](img/image00217.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Note how we get a much more descriptive output of our tests. Also note the
    use of nested describe callbacks in our test to build up a description of our
    application. The benefit of this becomes clearer as we add more tests. Try adding
    the following test after the first test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the tests again using `npm test`. This time, we get a test failure from
    Mocha:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Writing BDD-style tests with Mocha](img/image00218.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Resetting state between tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our second test fails because it retrieves two games from the service. But this
    is not because our production code is failing to filter games correctly. In fact,
    there are two games created by the first user. One of these has been carried over
    from the previous test.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s important for tests to be independent and isolated from each other. To
    this end, we need to clean up any state between tests. In this case, we want to
    delete all the games we created. The games service doesn''t give us a method for
    clearing all games. We can only remove individual games after retrieving them.
    There are a few options available to us here:'
  prefs: []
  type: TYPE_NORMAL
- en: We could keep track of all the games we create during each test and delete them
    all at the end. This might seem the most obvious solution, but it's a bit fragile.
    It would be easy to miss a single game that might cause confusing test failures
    later.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We could rewrite the games service module to export a function for creating
    a new service, and instantiate a new service for each test. In general, it's a
    good idea to try and isolate tests by creating fresh objects under each test.
    However, this is only useful if the object doesn't store any external state. We
    may well want to change the implementation of the games service later, to store
    data externally in a persistent datastore.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We could add a clear method to the games service to wipe out all its data. It's
    not wrong to create methods like this for the purposes of supporting tests. However,
    it's preferable to interact with the application via its existing API if possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The games service does offer a way of retrieving all current games. We just
    need to pass in a user ID that doesn''t match the setter of any game. We can then
    go through and delete all games. We want to do this before every test, which we
    can do using Mocha''s `beforeEach` hook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: If we re-run our tests, they now both pass correctly. There is also an `afterEach`
    hook in Mocha, which we could have used instead. This would have worked, but it's
    safer for tests to defend themselves by cleaning up first, rather than relying
    on other tests to clean up after themselves.
  prefs: []
  type: TYPE_NORMAL
- en: Using Chai for assertions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another way to make our tests more descriptive is how we write our assertions.
    Although the built-in Node.js assert module has been useful so far, it is a bit
    limited. It only contains a small number of simple methods for basic assertions.
  prefs: []
  type: TYPE_NORMAL
- en: You may have experience of Fluent Assertions or NUnit's Constraint model in
    .NET, or AssertJ in Java. Compared to these, the Node.js assert module might seem
    quite primitive.
  prefs: []
  type: TYPE_NORMAL
- en: There are several assertion frameworks available for JavaScript. We'll be using
    Chai ([http://chaijs.com](http://chaijs.com)), which supports three different
    styles for writing assertions. The `assert` style follows the traditional xUnit
    assertions, as in JUnit, or the classic model of NUnit. The `should` and `expect`
    styles provide a natural language interface for building more descriptive assertions.
  prefs: []
  type: TYPE_NORMAL
- en: Any of these styles is a perfectly valid choice for writing test assertions.
    The important thing is to pick a style for your codebase and use it consistently.
    We will be using Chai's `expect` syntax throughout this book. This is one of the
    more common styles in JavaScript testing. The Jasmine test framework has built-in
    assertions that follow a similar style.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s first install Chai by running the following on the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then update our tests to use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The change isn't particularly dramatic at this point as we're only making simple
    assertions. But the natural language interface will allow us to specify more detailed
    assertions in a descriptive way.
  prefs: []
  type: TYPE_NORMAL
- en: Creating test doubles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are more tests we could write for the games service, but let''s look
    at a different module for now. How would we go about testing our `users` middleware?
    The following code is from `middleware/users.js`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to test this class, we will need to pass in arguments for the `req`,
    `res`, and `next` parameters with which our code interacts. We don''t have a real
    request, response, or middleware pipeline available, so we need to create some
    stand-in values instead. Stand-in values such as this are generally called **test
    doubles**. Our code reads an attribute from the request and calls the cookie method
    on the response. We can create test doubles for these as follows, in a new test
    script under `test/middleware/users.js`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Here, we simply create a plain JavaScript object to represent the request. This
    allows us to verify that the production code reads from, and writes to, the request
    properties correctly. We just pass in the minimum possible input for the response
    object and the `next` function to allow the code to execute. This is very easy
    to do in JavaScript, partly because it is not statically typed. Creating test
    doubles like this in C# or Java can be a lot more work as the compiler will insist
    on the test doubles matching the corresponding parameter types.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need to test that our middleware calls the next middleware in the chain,
    as this is important behavior. This is slightly more complex than just creating
    an object with simple properties. We can still create a suitable test double by
    defining a new function that records when it is called (this kind of test double
    is called a **spy**):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This works perfectly well, but will become more cumbersome if we want to test
    more complex calls, for example, if we want to check for multiple calls or make
    further assertions about the arguments passed in. We can simplify this by making
    use of a framework to create test doubles for us.
  prefs: []
  type: TYPE_NORMAL
- en: Creating test doubles using Sinon.JS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Sinon.JS is a framework for creating all kinds of test doubles. Let''s first
    install it into our application by running the following on the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s simplify our previous test and write a more complex test using test
    doubles created by Sinon.JS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Sinon.JS spies keep track of the details of all calls made to them and provide
    a convenient API for checking these. This allows us to keep our test code simple
    and readable. There are many more properties than just the `called` and `calledWith`
    user here. Take a look at the Sinon.JS documentation at [http://sinonjs.org/docs/#spies-api](http://sinonjs.org/docs/#spies-api)
    to see some of the other ways we can verify the calls made against a spy.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Spies, stubs, and mocks**'
  prefs: []
  type: TYPE_NORMAL
- en: If you read more of the Sinon.JS documentation, you'll see that it's very explicit
    about the difference between spies, stubs, and mocks. This is in contrast to most
    popular test double frameworks in Java and .NET, which tend to call all test doubles
    by the same name (typically mock or fake). In reality though, most instances of
    test doubles typically only act as a spy (used for verifying side-effects) or
    a stub (used for providing data, or throwing exceptions to test error-handling).
    A true mock verifies a specific sequence of calls and returns specific data to
    the code under test. Although some of the early mocking frameworks in Java and
    .NET only supported this type of test double (now sometimes called a *strict mock*),
    it isn't common practice anymore. This is because it quite tightly couples test
    and production code and makes refactoring more difficult. It's especially rare
    to have more than one mock (as opposed to just a stub or spy) in a single test.
  prefs: []
  type: TYPE_NORMAL
- en: Testing an Express application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While using Sinon.JS makes our tests neater, they still depend on the details
    of the Express middleware API and how we're using it. This might be appropriate
    for our middleware module as we want to ensure that it fulfills a particular contract
    (especially calling `next` and setting `request.user`). For most middleware, though,
    especially our routes, this approach would couple our tests too closely to our
    implementation.
  prefs: []
  type: TYPE_NORMAL
- en: It would be better to test the actual behavior of each route by making HTTP
    requests to it and examining the responses, rather than checking for specific
    low-level interactions with the request and response objects. This gives us more
    flexibility to change our implementation and refactor our code, without needing
    to change the tests. Thus, our tests can support this process (by catching regressions)
    rather than hindering it (by having to be updated to match our implementation).
  prefs: []
  type: TYPE_NORMAL
- en: On other platforms, testing a whole application can be quite a heavyweight process.
    It is possible to start up a server in process, for example, using Jetty in Java
    or Katana in .NET. Newer application frameworks, such as Spring Boot or NancyFx,
    also make this process easier. These are still likely to be relatively slow and
    resource-intensive tests, though.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Node.js, starting up an application server is easy and very lightweight.
    We just use the same `http.createServer` call as we''ve seen before, and pass
    it an application. To test our route in isolation, we''ll bootstrap a new application
    containing just this route. Let''s see how we can use this to test the delete
    endpoint of our games route. We add the following code under `test/routes/games.js`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This might seem like quite a lot of code, but remember that we're firing up
    an entire application here. Also, most of this code will be reused for multiple
    tests. Let's work through what it does.
  prefs: []
  type: TYPE_NORMAL
- en: The `before` callback creates our server, just as we saw in [Chapter 2](part0018.xhtml#aid-H5A41
    "Chapter 2. Getting Started with Node.js") *, Getting Started with Node.js*, listening
    on a special port for use by our tests. It also sets up some stub middleware to
    simulate a current user on the request. The `afterEach` callback clears up any
    created games (as we saw before in the test of the games service). Note that since
    we're running in the same process, we can trivially interact with the same data
    layer that our application is using. Finally, the `after` function asks the server
    to stop listening for connections.
  prefs: []
  type: TYPE_NORMAL
- en: 'The test itself is very simple: we just create a game set by the current user
    (as in our service tests before) and then issue a request to delete it. This makes
    use of our own `makeRequest` function, which simply calls through to Node''s `http.request`.
    We can then inspect the response object to check for the appropriate status code,
    and check the service for the desired effect.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Writing asynchronous tests in Mocha**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice that our test and all of the callbacks to Mocha''s hook functions discussed
    above (except for afterEach) take a `done` parameter. This is because all of these
    tests perform some asynchronous work. Mocha makes it very easy to write asynchronous
    tests or hooks: you just make your callback function take a single parameter (called
    `done` by convention), and call it when processing is complete. If it''s not called
    within a timeout (which defaults to 2 seconds but can be changed), then Mocha
    fails the test.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s run our tests again using the `npm test` command. Notice that all of
    the tests still finish very quickly (tens of milliseconds on my machine), even
    though we''re starting up our whole server-side application. You may also notice
    the output is a bit messy due to log output from the server. We can easily suppress
    this by updating app.js as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The `''env''` property of an Express application comes from the `NODE_ENV`
    environment variable (or defaults to development if this is not present). This
    is useful for differentiating between production and development environments.
    Since it defaults to `development`, we also need to set it to something else in
    order to suppress this logging in our tests. We can do this by updating our test
    script in `package.json` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Simplifying tests using SuperAgent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While our tests are fast, and setting up the server is quite straightforward,
    we do have quite a lot of code for making requests to the server and handling
    responses. This would become more complex if we needed to make a wider variety
    of requests, or were interested in more than just the response status code or
    headers.
  prefs: []
  type: TYPE_NORMAL
- en: We can simplify our tests by using a library that provides a simpler API for
    communicating with the server. SuperAgent ([https://visionmedia.github.io/superagent/](https://visionmedia.github.io/superagent/))
    is a JavaScript library that provides a fluent, readable syntax for making HTTP
    requests. This can be used for Ajax requests in the browser, or for requests in
    a Node.js application as we're doing here.
  prefs: []
  type: TYPE_NORMAL
- en: We'll make use of SuperAgent through a lightweight wrapper called SuperTest
    ([https://github.com/visionmedia/supertest](https://github.com/visionmedia/supertest)),
    which makes testing Node.js-based HTTP applications even more convenient.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we add SuperTest into our application using `npm`, by running the following
    on the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can rewrite our tests as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: SuperTest and SuperAgent take care of starting up the server for our application,
    and provide a much simpler API for making requests. Note the use of a request
    **agent**, which represents a single browser session.
  prefs: []
  type: TYPE_NORMAL
- en: SuperAgent provides a number of functions (`get`, `post`, `delete`, and so on)
    for making HTTP requests. These can be chained with calls to the `expect` function
    (not to be confused with Chai's `expect`) to verify properties of the response,
    such as the status code. We can also pass in a callback to make specific checks
    about the response, or verify side-effects (as we do in the previous example).
  prefs: []
  type: TYPE_NORMAL
- en: Note that it is important to always call the `end` function to make sure any
    expectation errors are thrown and fail the test. We can pass Mocha's `done` callback
    to end the test when the request is completed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we''ve simplified our test code, we can easily add more tests for
    our routes. For example, let''s add some tests to cover the negative cases of
    our delete endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Full-stack testing with PhantomJS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have now written unit tests for logic at the core of our application and
    integration tests for our server-side routes. We don't yet have any automated
    tests that cover our views and client-side scripts as our manual testing throughout
    the previous chapters did.
  prefs: []
  type: TYPE_NORMAL
- en: We can write unit tests for client-side scripts using Mocha. However, all of
    our current client-side scripts interact with the server, so aren't good candidates
    for unit testing. Our manual tests are really full-stack tests of our whole application,
    including the interaction between the server and the client.
  prefs: []
  type: TYPE_NORMAL
- en: In order to achieve this in an automated test, we will need to use some form
    of browser automation. **PhantomJS** is a headless browser with a JavaScript API
    that allows us to automate it directly. We can write a simple test for our game
    page using this.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we''ll install PhantomJS within our project by running the following
    on the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: PhantomJS is not a Node.js module. It is a standalone, headless web browser.
    The npm module is just a convenient way of installing it and making it a dependency
    of the project. PhantomJS cannot be invoked from Node.js, except to execute it
    as a separate child process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can implement a test as follows, under `integration-test/game.js`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Make sure the application is running (using `npm start`), then execute the
    test by running the following on the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Let's take a look through the code to understand how it works. Note that we're
    running in the browser environment here rather than Node.js, so fall back to the
    ECMAScript 5 syntax (for example, `var` instead of `let`, and no arrow functions).
  prefs: []
  type: TYPE_NORMAL
- en: The omitted `withGame` method (which you can find in the book's companion code)
    uses PhantomJS to load the index view and submit a new game, then clears PhantomJS's
    cookies and opens the game as a new user, before invoking the callback passed
    to `withGame`.
  prefs: []
  type: TYPE_NORMAL
- en: In our test, we create a game to guess the word *example*, then invoke JavaScript
    within the page to make assertions about its contents. The `getText` function
    uses PhantomJS's `page.evaluate` function to run some JavaScript within the context
    of the page, and return a value. Note that the callback function passed to `page.evaluate`
    does not have access to the wider execution context of our script. We can, however,
    specify additional arguments to the `page.evaluate` call, which is how we pass
    in the selector for jQuery.
  prefs: []
  type: TYPE_NORMAL
- en: We then use `page.evaluate` again to set up a callback each time an Ajax request
    completes. Here, we use `window.callPhantom`, which executes within the context
    of the page, and triggers `page.onCallback`, which executes within the context
    of our test.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we use `page.sendEvent` to trigger a keyboard event in the browser.
    Note that this is not the same as using pure JavaScript within the browser to
    trigger a DOM event, but is an instruction directly to PhantomJS to simulate the
    `keypress` event as if it had come from the user.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we put all this together, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We use `page.sendEvent` to simulate pressing a keyboard key
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This causes our production code to send off an Ajax request
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When this request completes, `window.callPhantom` is invoked in the context
    of the browser
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This causes PhantomJS to invoke our `page.onCallback` function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We then use jQuery within `page.evaluate` (via `getText`) to retrieve values
    from the page
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The remaining contents of the file (`verify` and `handleError`) ensure that
    PhantomJS writes all errors to the console and sets an appropriate exit code in
    the case of a failure.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned how to write unit tests in Node.js, used Mocha
    and Chai to write more descriptive tests, created test doubles using Sinon.JS,
    written application level tests using SuperAgent and SuperTest, and implemented
    a full-stack test in PhantomJS.
  prefs: []
  type: TYPE_NORMAL
- en: Although we have tests at each layer of our application now, we haven't yet
    covered all of our code. It would be useful to find any gaps where we should write
    more tests. We also have to invoke a few different commands to run all of our
    unit and integration tests. In the next chapter, we'll see how to automate these
    and other processes as part of a continuous integration build.
  prefs: []
  type: TYPE_NORMAL
