<html><head></head><body>
		<div><h1 id="_idParaDest-94" class="chapter-number"><a id="_idTextAnchor095"/>5</h1>
			<h1 id="_idParaDest-95"><a id="_idTextAnchor096"/>Knowing the Infrastructure of Microservices in Node.js</h1>
			<p>Understanding the infrastructure of microservices in Node.js is crucial for building scalable and maintainable applications. Microservices architecture breaks down a monolithic application into smaller, independently deployable services that communicate with each other over a network.</p>
			<p>We’ll start this chapter by covering the infrastructure of microservices in Node.js for microservices development. The infrastructure for microservices in Node.js should be designed carefully while considering factors such as scalability, reliability, security, and ease of maintenance. Node.js is a popular choice for implementing microservices due to its non-blocking, event-driven architecture, which aligns well with the demands of distributed systems. However, the choice of technologies and tools should be based on the specific requirements of your project.</p>
			<p>By the end of this chapter, you will understand the infrastructure of microservices in Node.js for microservices development and how to apply the concepts in your everyday work.</p>
			<p>In this chapter, we’re going to cover the following main topics:</p>
			<ul>
				<li>Service discovery and API gateways</li>
				<li>Load balancing and service orchestration</li>
				<li>Containerization and orchestration and centralized logging and monitoring</li>
				<li>Distributed tracing and event-driven communication</li>
				<li>Database integration and continuous integration and deployment</li>
			</ul>
			<h1 id="_idParaDest-96"><a id="_idTextAnchor097"/>Service discovery and API gateways</h1>
			<p>In this section, we’re going to learn about services that need to discover and communicate with each other dynamically and how these services can help you create the next generation of applications while you exceed in your work. Service discovery and API gateways<a id="_idIndexMarker243"/> are <a id="_idIndexMarker244"/>critical components in the infrastructure of microservices architecture. They play essential roles in ensuring that microservices can communicate with each other effectively and that clients can access the services seamlessly.</p>
			<p>We’ll explore these concepts in more detail in the following subsections.</p>
			<h2 id="_idParaDest-97"><a id="_idTextAnchor098"/>Service discovery</h2>
			<p><strong class="bold">Service discovery</strong> is the <a id="_idIndexMarker245"/>process by which microservices locate and communicate with each other in a dynamic and distributed environment. As microservices can be deployed and scaled independently, their network locations (IP addresses and ports) can change frequently. Service discovery mechanisms solve this challenge by maintaining an up-to-date registry of available services and their locations.</p>
			<p>Here’s how service <a id="_idIndexMarker246"/>discovery works:</p>
			<ul>
				<li><strong class="bold">Service registry</strong>: A service registry<a id="_idIndexMarker247"/> is a centralized database or service that keeps track of the available microservices and their network locations. Examples of service registries<a id="_idIndexMarker248"/> include <strong class="bold">Consul</strong> (designed to simplify the development and operation of microservices-based applications by providing features such as service discovery, health checking, and key-value storage), <strong class="bold">etcd</strong> (an open<a id="_idIndexMarker249"/> source distributed key-value store and configuration management system that is often used for building highly available, distributed systems), and <strong class="bold">Netflix Eureka</strong> (an open source service discovery and<a id="_idIndexMarker250"/> registration server that is part of the Netflix <strong class="bold">Open Source Software</strong> (<strong class="bold">OSS</strong>) ecosystem). Eureka <a id="_idIndexMarker251"/>was originally developed by Netflix to manage and monitor the availability of services in a microservices architecture. It provides a simple and efficient way for microservices to locate and communicate with each other in a dynamic and distributed environment.</li>
				<li><strong class="bold">Registration</strong>: When a<a id="_idIndexMarker252"/> microservice starts up, it registers itself with the service registry, providing information about its location, health, and available endpoints.</li>
				<li><strong class="bold">Lookup</strong>: When one microservice needs to communicate with another, it queries the service registry to discover the location of the target microservice.</li>
				<li><strong class="bold">Load balancing</strong>: Service discovery often includes load balancing, where incoming requests are distributed among multiple instances of the same microservice to ensure high<a id="_idIndexMarker253"/> availability and scalability.</li>
			</ul>
			<p>Knowing how these concepts and tools work can help you and your team build better software and contribute to high-quality code, security, and compatibility.</p>
			<p><em class="italic">Figure 5</em><em class="italic">.1</em> illustrates the process of service discovery:</p>
			<div><div><img src="img/B14980_05_01.jpg" alt="Figure 5.1: Service discovery (image by vectorjuice on Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.1: Service discovery (image by vectorjuice on Freepik)</p>
			<p>Service discovery, with<a id="_idIndexMarker254"/> its tools and concepts, can lead to a higher understanding of microservices, which can also help you learn how to coordinate with your team of developers.</p>
			<p>In the next section, we’ll learn about API gateways.</p>
			<h2 id="_idParaDest-98"><a id="_idTextAnchor099"/>API gateways</h2>
			<p>An <strong class="bold">API gateway</strong> is a server<a id="_idIndexMarker255"/> or service that acts as an entry point for clients (such as web browsers, mobile apps, or other microservices) to access the functionalities of a microservices-based application.</p>
			<p>It serves several essential purposes, such as the following:</p>
			<ul>
				<li><strong class="bold">Routing</strong>: The<a id="_idIndexMarker256"/> API gateway routes client requests to the appropriate microservices based on the request’s URL or other criteria. It acts as a reverse proxy, forwarding requests to the relevant service.</li>
				<li><strong class="bold">Load balancing</strong>: In addition<a id="_idIndexMarker257"/> to service discovery, the API gateway often performs load balancing to evenly distribute incoming requests among multiple instances of a microservice.</li>
				<li><strong class="bold">Authentication and authorization</strong>: The API gateway can handle <a id="_idIndexMarker258"/>authentication and authorization, ensuring that only authorized users or systems can access specific endpoints.</li>
				<li><strong class="bold">Request transformation</strong>: Request transformation <a id="_idIndexMarker259"/>can modify or transform incoming requests and outgoing responses to match the expected formats of microservices, abstracting away differences between services.</li>
				<li><strong class="bold">Caching</strong>: API gateways <a id="_idIndexMarker260"/>can cache responses to reduce the load on microservices and improve response times for frequently requested data.</li>
				<li><strong class="bold">Logging and monitoring</strong>: Centralized<a id="_idIndexMarker261"/> logging and monitoring can be implemented via the API gateway to collect data on incoming requests and responses, providing visibility into system behavior.</li>
				<li><strong class="bold">Security</strong>: API gateways <a id="_idIndexMarker262"/>can provide security features such as rate limiting, DDoS<a id="_idIndexMarker263"/> protection, and <strong class="bold">web application firewall</strong> (<strong class="bold">WAF</strong>) capabilities.</li>
				<li><strong class="bold">Versioning</strong>: API gateways<a id="_idIndexMarker264"/> can support versioning of APIs, allowing for backward compatibility as services evolve.</li>
			</ul>
			<p>When we develop microservices in Node.js, we can use these tools and concepts to increase the efficiency and effectiveness of developers in creating software.</p>
			<p><strong class="bold">NGINX</strong> can function as<a id="_idIndexMarker265"/> an API gateway, providing a unified entry point for clients to interact with different microservices. This involves the following aspects:</p>
			<ul>
				<li><strong class="bold">API routing</strong>: NGINX can <a id="_idIndexMarker266"/>route requests to specific microservices based on the API endpoint. This simplifies the client experience by presenting a single entry point for various microservices.</li>
				<li><strong class="bold">Security</strong>: NGINX can handle <a id="_idIndexMarker267"/>authentication, authorization, and SSL termination, enhancing the security of microservices by centralizing these concerns.</li>
			</ul>
			<p><strong class="bold">Authentication</strong> is the process of <a id="_idIndexMarker268"/>verifying the identity of a user, service, or system. In a microservices architecture, each service must handle authentication to ensure that only authorized entities can access its resources.</p>
			<p>The following are some techniques for authentication:</p>
			<ul>
				<li><strong class="bold">JSON Web Tokens</strong> (<strong class="bold">JWTs</strong>): You can <a id="_idIndexMarker269"/>use JWTs to<a id="_idIndexMarker270"/> encode user information and create tokens that can be verified by each microservice. Then, you can verify tokens in each microservice before processing requests.</li>
				<li><strong class="bold">OAuth 2.0</strong>: You can implement <a id="_idIndexMarker271"/>OAuth 2.0<a id="_idIndexMarker272"/> for secure, token-based authentication. OAuth allows third-party services to access resources on behalf of a user.</li>
				<li><code>Passport.js</code><a id="_idIndexMarker274"/> library to implement authentication strategies in Node.js. It supports various authentication mechanisms, including local authentication, OAuth, and OpenID Connect.<p class="list-inset">Here’s an example of this when using a JWT:</p><pre class="source-code">
const jwt = require('jsonwebtoken');</pre><pre class="source-code">
// Middleware for authenticating requests</pre><pre class="source-code">
function authenticateToken(req, res, next) {</pre><pre class="source-code">
  const token = req.header('Authorization');</pre><pre class="source-code">
  if (!token) return res.sendStatus(401);</pre><pre class="source-code">
  jwt.verify(token, 'your-secret-key', (err, user) =&gt; {</pre><pre class="source-code">
    if (err) return res.sendStatus(403);</pre><pre class="source-code">
    req.user = user;</pre><pre class="source-code">
    next();</pre><pre class="source-code">
  });</pre><pre class="source-code">
}</pre><pre class="source-code">
// Example route that requires authentication</pre><pre class="source-code">
app.get('/api/resource', authenticateToken, (req, res) =&gt; {</pre><pre class="source-code">
  // Process the request for authenticated users</pre><pre class="source-code">
  res.json({ message: 'Access granted!' });</pre><pre class="source-code">
});</pre></li>
			</ul>
			<p><strong class="bold">Authorization</strong> is the <a id="_idIndexMarker275"/>process of determining what actions a user or service is allowed to perform. It is usually based on the authenticated user’s role or specific permissions.</p>
			<p>The following techniques can be used for authorization:</p>
			<ul>
				<li><strong class="bold">Role-based access control</strong> (<strong class="bold">RBAC</strong>): You <a id="_idIndexMarker276"/>can<a id="_idIndexMarker277"/> assign roles to users and define permissions associated with each role. You can also check the user’s role before allowing access to certain resources.</li>
				<li><strong class="bold">Claims-based authorization</strong>: You can<a id="_idIndexMarker278"/> use claims embedded in tokens to convey<a id="_idIndexMarker279"/> information about the user’s permissions. Microservices can then be authorized based on these claims.</li>
				<li><strong class="bold">Middleware for authorization</strong>: You can<a id="_idIndexMarker280"/> implement middleware functions in <a id="_idIndexMarker281"/>each microservice to check whether the authenticated user has the required permissions.<p class="list-inset">Here’s an example of this using RBAC:</p><pre class="source-code">
// Middleware for role-based authorization</pre><pre class="source-code">
function authorize(role) {</pre><pre class="source-code">
  return (req, res, next) =&gt; {</pre><pre class="source-code">
    if (req.user &amp;&amp; req.user.role === role) {</pre><pre class="source-code">
      return next(); // User has the required role</pre><pre class="source-code">
    }</pre><pre class="source-code">
    res.status(403).send('Forbidden'); // User does not have the required role</pre><pre class="source-code">
  };</pre><pre class="source-code">
}</pre><pre class="source-code">
// Example route that requires a specific role</pre><pre class="source-code">
app.get('/api/admin/resource', authenticateToken, authorize('admin'), (req, res) =&gt; {</pre><pre class="source-code">
  // Process the request for users with the 'admin' role</pre><pre class="source-code">
  res.json({ message: 'Admin access granted!' });</pre><pre class="source-code">
});</pre></li>
			</ul>
			<p><em class="italic">Figure 5</em><em class="italic">.2</em> illustrates the concept of an <a id="_idIndexMarker282"/>API gateway:</p>
			<div><div><img src="img/B14980_05_02.jpg" alt="Figure 5.2: API gateway"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.2: API gateway</p>
			<p>In summary, service discovery<a id="_idIndexMarker283"/> and API gateways are integral components of microservices infrastructure, enabling effective communication between services and providing a unified entry point for clients. These components enhance the scalability, reliability, security, and manageability of microservices-based applications, making them easier to develop and maintain.</p>
			<p>Now that we understand these concepts, let’s learn about load balancing and service orchestration.</p>
			<h1 id="_idParaDest-99"><a id="_idTextAnchor100"/>Load balancing and service orchestration</h1>
			<p>Load balancing <a id="_idIndexMarker284"/>and service orchestration<a id="_idIndexMarker285"/> are essential components in the architecture of microservices-based applications. They both contribute to the scalability, availability, and efficient operation of a distributed system.</p>
			<h2 id="_idParaDest-100"><a id="_idTextAnchor101"/>Load balancing</h2>
			<p><strong class="bold">Load balancing</strong> is the<a id="_idIndexMarker286"/> practice of distributing incoming network traffic across multiple instances of a service to ensure that no single instance is overwhelmed with requests, thereby optimizing resource utilization and improving system reliability.</p>
			<p>In a microservices architecture, load<a id="_idIndexMarker287"/> balancing is crucial because it helps achieve the following:</p>
			<ul>
				<li><strong class="bold">High availability</strong>: Load <a id="_idIndexMarker288"/>balancers distribute traffic evenly across healthy service instances. If one instance fails or becomes overloaded, traffic is automatically redirected to other instances, ensuring uninterrupted service.</li>
				<li><strong class="bold">Scalability</strong>: As the <a id="_idIndexMarker289"/>demand for a microservice increases, additional instances can be added, and the load balancer will automatically distribute traffic to these new instances, effectively scaling the application horizontally.</li>
				<li><strong class="bold">Resource utilization</strong>: Load<a id="_idIndexMarker290"/> balancers can monitor the health and performance of service instances and make routing decisions based on factors such as response times and server load. This ensures that each instance is used efficiently.</li>
				<li><strong class="bold">Failover</strong>: Load<a id="_idIndexMarker291"/> balancers can detect when a service instance becomes unhealthy and stop sending traffic to it. This helps in isolating issues and maintaining the overall system’s integrity.</li>
			</ul>
			<p>Some common load balancing strategies are as follows:</p>
			<ul>
				<li><strong class="bold">Round-robin</strong>: This is a<a id="_idIndexMarker292"/> simple and widely used <a id="_idIndexMarker293"/>load balancing algorithm that distributes incoming network traffic or requests evenly across a group of backend servers or resources.</li>
				<li><strong class="bold">Least connections</strong>: This is a<a id="_idIndexMarker294"/> load balancing algorithm<a id="_idIndexMarker295"/> that’s used by load balancers to distribute incoming network traffic or requests to a group of backend servers or resources.</li>
				<li><strong class="bold">IP hashing</strong>: Also known<a id="_idIndexMarker296"/> as <em class="italic">IP-based load balancing</em> or <em class="italic">IP hash load balancing</em>, PI hashing is a technique that’s used by load balancers to <a id="_idIndexMarker297"/>distribute incoming network traffic or requests to a group of backend servers or resources based on the source or destination IP address of the requests</li>
				<li><strong class="bold">Weighted distribution</strong>: This <a id="_idIndexMarker298"/>refers to the practice of <a id="_idIndexMarker299"/>allocating resources or traffic among different instances or replicas of a microservice based on their relative weights.</li>
			</ul>
			<p>Load balancing is crucial in microservices architectures where multiple instances of a service may exist. NGINX supports the following:</p>
			<ul>
				<li><strong class="bold">Round-robin load balancing</strong>: Distributes<a id="_idIndexMarker300"/> incoming requests evenly among the available microservice instances.</li>
				<li><strong class="bold">Health checks</strong>: NGINX can perform health checks<a id="_idIndexMarker301"/> to identify and route traffic away from unhealthy instances, ensuring better reliability.</li>
			</ul>
			<p>NGINX acts as a <strong class="bold">reverse proxy</strong>, sitting between client applications and microservices. This offers several advantages:</p>
			<ul>
				<li><strong class="bold">Load balancing</strong>: NGINX can<a id="_idIndexMarker302"/> distribute incoming requests among multiple instances of a microservice, ensuring even load distribution and improved system performance.</li>
				<li><strong class="bold">Routing</strong>: NGINX can route requests to different microservices based on factors such as URL paths, headers, or other parameters. This enables efficient handling of various functionalities distributed across microservices.</li>
			</ul>
			<p><em class="italic">Figure 5</em><em class="italic">.3</em> illustrates load balancing:</p>
			<div><div><img src="img/B14980_05_03.jpg" alt="Figure 5.3: Load balancing (image by vectorjuice on Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.3: Load balancing (image by vectorjuice on Freepik)</p>
			<p>Popular load balancing solutions include hardware load balancers and software-based solutions such as <a id="_idIndexMarker303"/>NGINX and HAProxy, as well <a id="_idIndexMarker304"/>as cloud-based load balancers provided by cloud service providers.</p>
			<p>With these concepts covered, next, we’ll look at service orchestration.</p>
			<h2 id="_idParaDest-101"><a id="_idTextAnchor102"/>Service orchestration</h2>
			<p><strong class="bold">Service orchestration</strong> involves <a id="_idIndexMarker305"/>coordinating and managing the execution of multiple microservices to fulfill a specific business process or workflow. It ensures that the individual services work together harmoniously to achieve a higher-level objective.</p>
			<p>Here’s how <a id="_idIndexMarker306"/>service orchestration contributes to a microservices architecture:</p>
			<ul>
				<li><strong class="bold">Complex workflow handling</strong>: Microservices often need to collaborate to perform complex tasks or workflows. Service orchestration defines the sequence of microservices to be executed and manages their interactions to complete the workflow.</li>
				<li><strong class="bold">Centralized control</strong>: Service orchestration typically involves a central orchestrator component that coordinates the execution of microservices, thereby handling error recovery and ensuring the correct order of operations.</li>
				<li><strong class="bold">Asynchronous communication</strong>: Microservices can communicate with each other through asynchronous message passing, enabling loosely coupled interactions. Service orchestration manages the messaging and data flow between services.</li>
				<li><strong class="bold">Long-running processes</strong>: For long-running processes that span multiple microservices, service orchestration ensures that steps are executed in the correct order and that data consistency is maintained.</li>
				<li><strong class="bold">Dynamic scaling</strong>: Service orchestration can dynamically scale microservices based on the workload, ensuring that resources are allocated optimally to handle varying demands.</li>
			</ul>
			<p>Service orchestration can be implemented using various tools and patterns, including workflow engines, message queues, and choreography-based approaches. Tools such as Apache Camel, Netflix Conductor, and Kubernetes-based orchestration solutions are commonly used in microservices environments.</p>
			<p class="callout-heading">Additional information</p>
			<p class="callout"><em class="italic">Apache Camel</em> is an<a id="_idIndexMarker307"/> open source integration framework that provides a lightweight, easy-to-use platform for routing and mediating message exchanges between different systems. You can access its<a id="_idIndexMarker308"/> documentation at <a href="https://camel.apache.org/docs/">https://camel.apache.org/docs/</a>.</p>
			<p class="callout"><em class="italic">Netflix Conductor</em> allows <a id="_idIndexMarker309"/>developers to design, execute, and manage complex <a id="_idIndexMarker310"/>workflows in a scalable and reliable manner. You can access its documentation at <a href="https://orkes.io/content/">https://orkes.io/content/</a>.</p>
			<p class="callout"><em class="italic">Kubernetes orchestration</em> is a <a id="_idIndexMarker311"/>platform for container orchestration that allows you to build application services that span multiple containers, schedule containers across a cluster, scale those containers, and<a id="_idIndexMarker312"/> manage their health over time. You can access its documentation at <a href="https://kubernetes.io/docs/home/supported-doc-versions">https://kubernetes.io/docs/home/supported-doc-versions</a>.</p>
			<p><em class="italic">Figure 5</em><em class="italic">.4</em> depicts service orchestration:</p>
			<div><div><img src="img/B14980_05_04.jpg" alt="Figure 5.4: Service orchestration (image by Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.4: Service orchestration (image by Freepik)</p>
			<p>In summary, load balancing and service orchestration are fundamental components of microservices architecture. Load balancing ensures the efficient distribution of traffic and resource utilization, while service orchestration manages the coordination and execution of microservices to complete complex workflows and business processes. Together, these components contribute to the scalability, availability, and reliability of microservices-based applications.</p>
			<p>Now, we can continue to the next section, in which we will talk about containerization and orchestration and centralized logging and monitoring.</p>
			<h1 id="_idParaDest-102"><a id="_idTextAnchor103"/>Containerization and orchestration and centralized logging and monitoring</h1>
			<p>Containerization <a id="_idIndexMarker313"/>and orchestration<a id="_idIndexMarker314"/> and centralized logging and monitoring are two critical components in the infrastructure of microservices-based applications. They play pivotal roles in ensuring the efficient deployment, management, and monitoring of microservices.</p>
			<p>We’ll start with containerization and orchestration.</p>
			<h2 id="_idParaDest-103"><a id="_idTextAnchor104"/>Containerization and orchestration</h2>
			<p><strong class="bold">Containerization</strong> involves<a id="_idIndexMarker315"/> packaging an application and its dependencies into a standardized unit called<a id="_idIndexMarker316"/> a <strong class="bold">container</strong>.</p>
			<p>Orchestration refers to the process of automatically managing containerized applications. It involves deploying, scaling, load balancing, and maintaining containers across a cluster of machines. Kubernetes is the most popular container orchestration platform, but others, such as Docker Swarm and Apache Mesos, also exist.</p>
			<p>Here’s how containerization and orchestration benefit microservices:</p>
			<ul>
				<li><strong class="bold">Isolation</strong>: Containers provide process isolation, ensuring that microservices do not interfere with each other, making it easier to maintain consistent environments.</li>
				<li><strong class="bold">Portability</strong>: Containers can run on any platform that supports containerization, making it possible to move microservices across development, testing, and production environments seamlessly.</li>
				<li><strong class="bold">Resource efficiency</strong>: Orchestration platforms such as Kubernetes automate the deployment and scaling of containers, optimizing resource utilization and ensuring that microservices have the required resources when needed.</li>
				<li><strong class="bold">High availability</strong>: Orchestration platforms monitor the health of microservices and can automatically replace failed instances, ensuring high availability and fault tolerance.</li>
				<li><strong class="bold">Scaling</strong>: Microservices can be easily scaled up or down by adjusting the number of container replicas. This is crucial for handling variable workloads.</li>
			</ul>
			<p>Containers<a id="_idIndexMarker317"/> encapsulate the application code, runtime, system libraries, and settings, ensuring consistency and portability across different environments.</p>
			<p class="callout-heading">Additional information</p>
			<p class="callout"><strong class="bold">Docker</strong> is an <a id="_idIndexMarker318"/>open-source platform that allows you to automate the deployment, scaling, and management of applications using containerization and is a widely used containerization platform.</p>
			<p><em class="italic">Figure 5</em><em class="italic">.5</em> illustrates containerization and orchestration:</p>
			<div><div><img src="img/B14980_05_05.jpg" alt="Figure 5.5: Full-stack development process (image by vectorjuice on Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.5: Full-stack development process (image by vectorjuice on Freepik)</p>
			<p>Containerization<a id="_idIndexMarker319"/> and orchestration<a id="_idIndexMarker320"/> can help ship software that will run on every platform and in every system. By automatically managing containerization, you can achieve greater versatility in deployment.</p>
			<p>In the next section, we will talk about centralized logging and monitoring.</p>
			<h2 id="_idParaDest-104"><a id="_idTextAnchor105"/>Centralized logging and monitoring</h2>
			<p><strong class="bold">Centralized logging and monitoring systems</strong> collect<a id="_idIndexMarker321"/> and analyze <a id="_idIndexMarker322"/>data from microservices and their environments. These systems help in diagnosing issues, optimizing performance, and ensuring the health of microservices- applications.</p>
			<p>Let’s look at some of the common components of these systems include:</p>
			<ul>
				<li><strong class="bold">Log collectors</strong>: These are <a id="_idIndexMarker323"/>agents or services that gather logs generated by microservices and forward them to a central location.</li>
				<li><strong class="bold">Log aggregators</strong>: These are <a id="_idIndexMarker324"/>systems that consolidate logs from various sources, making it easier to search, analyze, and visualize log data. Examples include Elasticsearch, Fluentd, and Logstash.</li>
				<li><strong class="bold">Metrics and monitoring</strong>: Tools such <a id="_idIndexMarker325"/>as Prometheus and Grafana (two popular open source tools used for monitoring and visualizing metrics and time series data) are used to collect and display real-time performance metrics from microservices. They provide insights into the behavior of the application and its components.</li>
				<li><strong class="bold">Alerting</strong>: Monitoring<a id="_idIndexMarker326"/> systems can generate alerts based on predefined thresholds, allowing operations teams to respond to issues promptly.</li>
				<li><strong class="bold">Tracing</strong>: Distributed <a id="_idIndexMarker327"/>tracing tools such as Jaeger and Zipkin (two distributed tracing systems that are used to monitor and troubleshoot complex, microservices-based architectures) help track the flow of requests across microservices, making it easier to identify bottlenecks and latency issues.</li>
			</ul>
			<p class="callout-heading">Additional information</p>
			<p class="callout"><em class="italic">Elasticsearch</em> is a <a id="_idIndexMarker328"/>highly scalable open source search and analytics engine built on top of Apache Lucene. You can access <a id="_idIndexMarker329"/>its documentation at <a href="https://www.elastic.co/guide/index.html">https://www.elastic.co/guide/index.html</a>.</p>
			<p class="callout"><em class="italic">Fluentd</em> is an <a id="_idIndexMarker330"/>open source data collector designed to unify data collection and consumption for <a id="_idIndexMarker331"/>better analysis and insights. You can access its documentation at <a href="https://docs.fluentd.org/">https://docs.fluentd.org/</a>.</p>
			<p class="callout"><em class="italic">Logstash</em> is an<a id="_idIndexMarker332"/> open source data processing pipeline that allows you to collect, process, and ingest data from various sources into different output destinations (ELK Stack). You can access its <a id="_idIndexMarker333"/>documentation at <a href="https://www.elastic.co/guide/en/logstash/current/introduction.html">https://www.elastic.co/guide/en/logstash/current/introduction.html</a>.</p>
			<p>Centralized logging and monitoring offer several<a id="_idIndexMarker334"/> benefits, including improved visibility, scalability, access to historical data, and increased efficiency in managing and analyzing logs and metrics.</p>
			<p><em class="italic">Figure 5</em><em class="italic">.6</em> illustrates centralized logging and monitoring:</p>
			<div><div><img src="img/B14980_05_06.jpg" alt="Figure 5.6: Centralized logging and monitoring (image by pch.vector on Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.6: Centralized logging and monitoring (image by pch.vector on Freepik)</p>
			<p>In summary, containerization and orchestration provide a scalable and efficient way to manage microservices, while centralized logging and monitoring ensure that these services operate reliably and can be effectively maintained. Together, these components form a robust foundation for microservices-based applications.</p>
			<p>In the next section, we will learn about distributed tracing and event-driven communication.</p>
			<h1 id="_idParaDest-105"><a id="_idTextAnchor106"/>Distributed tracing and event-driven communication</h1>
			<p>Distributed tracing<a id="_idIndexMarker335"/> and event-driven <a id="_idIndexMarker336"/>communication are two crucial concepts in the world of microservices and distributed systems. They address challenges related to monitoring and coordinating interactions between microservices. Let’s dive into these concepts.</p>
			<h2 id="_idParaDest-106"><a id="_idTextAnchor107"/>Distributed tracing</h2>
			<p><strong class="bold">Distributed tracing</strong> is <a id="_idIndexMarker337"/>a technique that’s used to track and monitor requests as they traverse multiple microservices in a distributed system. It provides end-to-end visibility into the flow of a request, allowing you to identify performance bottlenecks, troubleshoot issues, and optimize the system’s behavior.</p>
			<p>Here’s how distributed tracing works:</p>
			<ul>
				<li><strong class="bold">Instrumentation</strong>: Each<a id="_idIndexMarker338"/> microservice in your architecture is instrumented to generate trace data. This typically involves adding trace headers to incoming requests and recording timing information for various operations within the service.</li>
				<li><strong class="bold">Trace context</strong>: The trace context is propagated along with the request as it moves from one microservice to another. This context includes a unique trace ID and span ID, which allows you to correlate activities across services.</li>
				<li><strong class="bold">Centralized collector</strong>: Trace data from all microservices is sent to a centralized collector or storage system. Popular options include Zipkin, Jaeger, and the Elastic Stack.</li>
				<li><strong class="bold">Visualization and analysis</strong>: Once the trace data has been collected, you can visualize it using specialized tools. This allows you to see the entire journey of a request, including service-to-service communication and the time spent at each step.</li>
				<li><strong class="bold">Improved customer experience</strong>: Once the trace data has been collected, you can visualize it using specialized tools. This allows you to see the entire journey of a request, including service-to-service communication and the time spent at each step.</li>
			</ul>
			<p>Distributed tracing<a id="_idIndexMarker339"/> is a powerful tool for performance optimization, root cause analysis, dependency mapping, and capacity planning in distributed systems. It provides detailed visibility into the behavior and performance of your applications, allowing you to make data-driven decisions for improving system performance and reliability.</p>
			<p>In the next section, we will talk about event-driven communication.</p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor108"/>Event-driven communication</h2>
			<p><strong class="bold">Event-driven communication</strong> is a<a id="_idIndexMarker340"/> messaging pattern where microservices communicate asynchronously through the exchange of events or messages. This approach decouples services, allowing them to work independently and react to events triggered by other services.</p>
			<p>Here’s how event-driven <a id="_idIndexMarker341"/>communication works:</p>
			<ul>
				<li><strong class="bold">Event producers</strong>: These are <a id="_idIndexMarker342"/>microservices that generate events or messages and publish them to a message broker or event bus. Events can represent various actions or state changes.</li>
				<li><strong class="bold">Event consumers</strong>: These are <a id="_idIndexMarker343"/>microservices that subscribe to specific events and react to them. They perform actions based on the information contained in the events.</li>
				<li><strong class="bold">Message brokers</strong>: These are <a id="_idIndexMarker344"/>middleware components that facilitate the exchange of messages between producers and consumers. Popular message brokers include Apache Kafka, RabbitMQ, and AWS SNS/SQS.</li>
			</ul>
			<p>In summary, distributed tracing enhances your ability to monitor and diagnose the behavior of microservices, while event-driven communication fosters loose coupling and scalability in a microservices architecture. These concepts are valuable for building resilient and responsive distributed systems.</p>
			<p>In the next section, we are going to talk about database integration and continuous integration and deployment.</p>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor109"/>Database integration and continuous integration and deployment</h1>
			<p>Database integration and <strong class="bold">continuous integration/continuous deployment</strong> (<strong class="bold">CI/CD</strong>) are <a id="_idIndexMarker345"/>critical aspects of a microservices architecture. They ensure that data is managed effectively and that changes to microservices are deployed efficiently and reliably.</p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor110"/>Database integration</h2>
			<p>In a microservices <a id="_idIndexMarker346"/>architecture, each microservice typically has its own database or data store. This separation of data is known as <em class="italic">database </em><em class="italic">per service</em>.</p>
			<p>Here are some key considerations for database <a id="_idIndexMarker347"/>integration in microservices:</p>
			<ul>
				<li><strong class="bold">Data consistency</strong>: To ensure data consistency, three <a id="_idIndexMarker348"/>approaches are commonly used – two-phase commits, distributed transactions, and eventual consistency:<ul><li><strong class="bold">Two-phase commits</strong>: <strong class="bold">Two-phase commit</strong> (<strong class="bold">2PC</strong>) is <a id="_idIndexMarker349"/>a protocol that ensures atomicity and consistency in distributed transactions. It involves coordinating multiple participants or resources to decide whether to commit or abort a transaction. The protocol consists of two phases: a preparation phase and a commit phase. In the preparation phase, each participant informs the coordinator whether it can successfully commit the transaction. In the commit phase, the coordinator sends a commit message to all participants if everyone agrees to commit, or an abort message if anyone disagrees. This ensures that all participants either commit or abort the transaction together.</li><li><strong class="bold">Distributed transactions</strong>: Distributed transactions<a id="_idIndexMarker350"/> involve multiple independent systems or databases that participate in a single transaction. A transaction within a distributed environment has the same properties as a local transaction, including <strong class="bold">Atomicity, Consistency, Isolation, and Durability</strong> (<strong class="bold">ACID</strong>) properties. Distributed transaction<a id="_idIndexMarker351"/> management systems handle the coordination and synchronization between participating nodes to ensure the consistency of the entire transaction. These systems may employ protocols such as 2PC to coordinate the actions of the participants.</li><li><strong class="bold">Eventual consistency</strong>: Eventual consistency<a id="_idIndexMarker352"/> is a consistency model that’s used in distributed systems. It relaxes the strict consistency requirements of traditional ACID databases to provide high availability, scalability, and tolerance to network partitions. In an eventually consistent system, updates to replicated data occur asynchronously, allowing different replicas to diverge temporarily. However, the system guarantees that eventually, all replicas will converge to a consistent state. This approach prioritizes availability and performance over strict consistency, making it suitable for scenarios where data can tolerate temporary inconsistencies.</li></ul><p class="list-inset">Each approach has<a id="_idIndexMarker353"/> its advantages and trade-offs, depending on the specific requirements of the system. Two-phase commits and distributed transactions provide strong consistency guarantees but can introduce additional overhead and complexity due to coordination between participants. On the other hand, eventual consistency prioritizes availability and scalability but may lead to temporary data inconsistencies. The choice of approach depends on factors such as the system’s workload, performance requirements, and the level of consistency needed in the application.</p></li>
				<li><strong class="bold">APIs for data access</strong>: Defining clear<a id="_idIndexMarker354"/> APIs for accessing and modifying data in each microservice’s database helps maintain control over data interactions.</li>
				<li><strong class="bold">Data synchronization</strong>: This<a id="_idIndexMarker355"/> involves implementing data synchronization mechanisms or using event-driven architecture to propagate changes in one microservice’s data to others who may be interested.</li>
				<li><strong class="bold">Caching</strong>: You can use caching<a id="_idIndexMarker356"/> strategies to improve data retrieval performance and reduce the load on databases.</li>
				<li><strong class="bold">Polyglot persistence</strong>: This involves<a id="_idIndexMarker357"/> choosing the right database technology for each microservice’s specific data storage needs. Different microservices may use different types of databases (for example, relational, NoSQL, and so on) based on their requirements.</li>
				<li><strong class="bold">Data ownership</strong>: You must <a id="_idIndexMarker358"/>clearly define which microservice is the authoritative source for specific types of data and ensure that data ownership is<a id="_idIndexMarker359"/> clear to prevent conflicts.</li>
			</ul>
			<p>Database integration refers to strategies and techniques for managing data across these distributed databases and ensuring that data consistency and integrity are maintained.</p>
			<p><em class="italic">Figure 5</em><em class="italic">.7</em> presents an example of database integration:</p>
			<div><div><img src="img/B14980_05_07.jpg" alt="Figure 5.7: Database integration (image from Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.7: Database integration (image from Freepik)</p>
			<p>Database as a<a id="_idIndexMarker360"/> service can help developers develop faster while focusing on a single microservice and creating the best user experience for different users.</p>
			<p>In the next section, we will learn more about CI/CD.</p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor111"/>CI/CD</h2>
			<p><strong class="bold">CI/CD</strong> is a<a id="_idIndexMarker361"/> set of practices and tools that enable the automated building, testing, and deployment of software changes, including those in microservices. CI/CD pipelines streamline the process of delivering updates to microservices-based applications and ensure that changes are integrated and tested seamlessly.</p>
			<p>Here are some key aspects of <a id="_idIndexMarker362"/>CI/CD in a microservices environment:</p>
			<ul>
				<li><strong class="bold">Automated builds</strong>: Automate<a id="_idIndexMarker363"/> the process of building microservices and their dependencies whenever changes are pushed to a version control system (for example, Git).</li>
				<li><strong class="bold">Automated testing</strong>: Run<a id="_idIndexMarker364"/> automated tests, including unit tests, integration tests, and end-to-end tests, to ensure that changes do not introduce regressions.</li>
				<li><strong class="bold">Artifact repository</strong>: Store <a id="_idIndexMarker365"/>built artifacts (for example, Docker images) in a repository for easy access during deployment.</li>
				<li><strong class="bold">Deployment automation</strong>: Automate <a id="_idIndexMarker366"/>the deployment process to staging and production environments, including rolling updates, blue-green deployments, or canary releases. All these strategies are used in deployment automation to ensure smooth and safe application releases.</li>
				<li><strong class="bold">Infrastructure as Code</strong> (<strong class="bold">IaC</strong>): Define<a id="_idIndexMarker367"/> infrastructure components (for example, containers and virtual machines) as code to ensure consistent environments across stages.</li>
				<li><strong class="bold">Monitoring and rollback</strong>: Integrate <a id="_idIndexMarker368"/>monitoring and alerting into the CI/CD pipeline to detect issues in production and enable rollback if necessary.</li>
				<li><strong class="bold">Versioning</strong>: Manage <a id="_idIndexMarker369"/>versions of microservices and their dependencies to ensure that changes are tracked and can be rolled back if needed.</li>
			</ul>
			<p>CI/CD pipelines help microservices teams deliver software changes quickly and reliably, reducing manual intervention and the risk of human error. They promote a culture of continuous improvement and allow teams to release new features and bug fixes more frequently.</p>
			<p><em class="italic">Figure 5</em><em class="italic">.8</em> illustrates the process of CI/CD:</p>
			<div><div><img src="img/B14980_05_08.jpg" alt="Figure 5.8: CI/CD (image by vectorjuice on Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.8: CI/CD (image by vectorjuice on Freepik)</p>
			<p>In summary, database<a id="_idIndexMarker370"/> integration strategies help manage data in a microservices architecture, ensuring consistency and coordination, while CI/CD pipelines streamline the development and deployment of microservices, enabling rapid and reliable software delivery. Both aspects are critical for the success of microservices-based applications.</p>
			<h1 id="_idParaDest-111"><a id="_idTextAnchor112"/>Summary</h1>
			<p>In this chapter, we learned a lot about services that need to discover and communicate with each other dynamically, load balancing and service orchestration, containerization and orchestration and centralized logging and monitoring, distributed tracing and event-driven communication, and database integration and CI/CD.</p>
			<p>Building the infrastructure for microservices in Node.js involves carefully selecting and integrating these components and tools based on your specific requirements. It’s important to consider scalability, fault tolerance, observability, and ease of management when designing and implementing the infrastructure for your microservices architecture.</p>
			<p>The infrastructure of microservices in Node.js is a critical foundation for developing scalable, distributed applications. It encompasses various components and practices that enable the effective operation of microservices-based systems.</p>
			<p>This infrastructure is designed to handle the complexities of microservices architecture, ensuring they can work together cohesively, scale efficiently, and remain resilient in the face of failures. Node.js, with its non-blocking, event-driven architecture, is a popular choice for implementing microservices, making this infrastructure even more powerful and adaptable.</p>
			<p>In the next chapter, we are going to learn how to design microservices architecture in Node.js.</p>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor113"/>Quiz time</h1>
			<ul>
				<li>What is service discovery?</li>
				<li>What are API gateways?</li>
				<li>What is load balancing?</li>
				<li>What is containerization?</li>
			</ul>
		</div>
	</body></html>