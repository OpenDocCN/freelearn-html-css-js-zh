<html><head></head><body>
		<div id="_idContainer071">
			<h1 id="_idParaDest-94" class="chapter-number"><a id="_idTextAnchor095"/>5</h1>
			<h1 id="_idParaDest-95"><a id="_idTextAnchor096"/>Knowing the Infrastructure of Microservices in Node.js</h1>
			<p>Understanding the infrastructure of microservices in Node.js is crucial for building scalable and maintainable applications. Microservices architecture breaks down a monolithic application into smaller, independently deployable services that communicate with each other over <span class="No-Break">a network.</span></p>
			<p>We’ll start this chapter by covering the infrastructure of microservices in Node.js for microservices development. The infrastructure for microservices in Node.js should be designed carefully while considering factors such as scalability, reliability, security, and ease of maintenance. Node.js is a popular choice for implementing microservices due to its non-blocking, event-driven architecture, which aligns well with the demands of distributed systems. However, the choice of technologies and tools should be based on the specific requirements of <span class="No-Break">your project.</span></p>
			<p>By the end of this chapter, you will understand the infrastructure of microservices in Node.js for microservices development and how to apply the concepts in your <span class="No-Break">everyday work.</span></p>
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>Service discovery and <span class="No-Break">API gateways</span></li>
				<li>Load balancing and <span class="No-Break">service orchestration</span></li>
				<li>Containerization and orchestration and centralized logging <span class="No-Break">and monitoring</span></li>
				<li>Distributed tracing and <span class="No-Break">event-driven communication</span></li>
				<li>Database integration and continuous integration <span class="No-Break">and deployment</span></li>
			</ul>
			<h1 id="_idParaDest-96"><a id="_idTextAnchor097"/>Service discovery and API gateways</h1>
			<p>In this section, we’re going to learn about services that need to discover and communicate with each other dynamically and how these services can help you create the next generation of applications while you exceed in your work. Service discovery and API gateways<a id="_idIndexMarker243"/> are <a id="_idIndexMarker244"/>critical components in the infrastructure of microservices architecture. They play essential roles in ensuring that microservices can communicate with each other effectively and that clients can access the <span class="No-Break">services seamlessly.</span></p>
			<p>We’ll explore these concepts in more detail in the <span class="No-Break">following subsections.</span></p>
			<h2 id="_idParaDest-97"><a id="_idTextAnchor098"/>Service discovery</h2>
			<p><strong class="bold">Service discovery</strong> is the <a id="_idIndexMarker245"/>process by which microservices locate and communicate with each other in a dynamic and distributed environment. As microservices can be deployed and scaled independently, their network locations (IP addresses and ports) can change frequently. Service discovery mechanisms solve this challenge by maintaining an up-to-date registry of available services and <span class="No-Break">their locations.</span></p>
			<p>Here’s how service <a id="_idIndexMarker246"/><span class="No-Break">discovery works:</span></p>
			<ul>
				<li><strong class="bold">Service registry</strong>: A service registry<a id="_idIndexMarker247"/> is a centralized database or service that keeps track of the available microservices and their network locations. Examples of service registries<a id="_idIndexMarker248"/> include <strong class="bold">Consul</strong> (designed to simplify the development and operation of microservices-based applications by providing features such as service discovery, health checking, and key-value storage), <strong class="bold">etcd</strong> (an open<a id="_idIndexMarker249"/> source distributed key-value store and configuration management system that is often used for building highly available, distributed systems), and <strong class="bold">Netflix Eureka</strong> (an open source service discovery and<a id="_idIndexMarker250"/> registration server that is part of the Netflix <strong class="bold">Open Source Software</strong> (<strong class="bold">OSS</strong>) ecosystem). Eureka <a id="_idIndexMarker251"/>was originally developed by Netflix to manage and monitor the availability of services in a microservices architecture. It provides a simple and efficient way for microservices to locate and communicate with each other in a dynamic and <span class="No-Break">distributed environment.</span></li>
				<li><strong class="bold">Registration</strong>: When a<a id="_idIndexMarker252"/> microservice starts up, it registers itself with the service registry, providing information about its location, health, and <span class="No-Break">available endpoints.</span></li>
				<li><strong class="bold">Lookup</strong>: When one microservice needs to communicate with another, it queries the service registry to discover the location of the <span class="No-Break">target microservice.</span></li>
				<li><strong class="bold">Load balancing</strong>: Service discovery often includes load balancing, where incoming requests are distributed among multiple instances of the same microservice to ensure high<a id="_idIndexMarker253"/> availability <span class="No-Break">and scalability.</span></li>
			</ul>
			<p>Knowing how these concepts and tools work can help you and your team build better software and contribute to high-quality code, security, <span class="No-Break">and compatibility.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.1</em> illustrates the process of <span class="No-Break">service discovery:</span></p>
			<div>
				<div id="_idContainer063" class="IMG---Figure">
					<img src="image/B14980_05_01.jpg" alt="Figure 5.1: Service discovery (image by vectorjuice on Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.1: Service discovery (image by vectorjuice on Freepik)</p>
			<p>Service discovery, with<a id="_idIndexMarker254"/> its tools and concepts, can lead to a higher understanding of microservices, which can also help you learn how to coordinate with your team <span class="No-Break">of developers.</span></p>
			<p>In the next section, we’ll learn about <span class="No-Break">API gateways.</span></p>
			<h2 id="_idParaDest-98"><a id="_idTextAnchor099"/>API gateways</h2>
			<p>An <strong class="bold">API gateway</strong> is a server<a id="_idIndexMarker255"/> or service that acts as an entry point for clients (such as web browsers, mobile apps, or other microservices) to access the functionalities of a <span class="No-Break">microservices-based application.</span></p>
			<p>It serves several essential purposes, such as <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Routing</strong>: The<a id="_idIndexMarker256"/> API gateway routes client requests to the appropriate microservices based on the request’s URL or other criteria. It acts as a reverse proxy, forwarding requests to the <span class="No-Break">relevant service.</span></li>
				<li><strong class="bold">Load balancing</strong>: In addition<a id="_idIndexMarker257"/> to service discovery, the API gateway often performs load balancing to evenly distribute incoming requests among multiple instances of <span class="No-Break">a microservice.</span></li>
				<li><strong class="bold">Authentication and authorization</strong>: The API gateway can handle <a id="_idIndexMarker258"/>authentication and authorization, ensuring that only authorized users or systems can access <span class="No-Break">specific endpoints.</span></li>
				<li><strong class="bold">Request transformation</strong>: Request transformation <a id="_idIndexMarker259"/>can modify or transform incoming requests and outgoing responses to match the expected formats of microservices, abstracting away differences <span class="No-Break">between services.</span></li>
				<li><strong class="bold">Caching</strong>: API gateways <a id="_idIndexMarker260"/>can cache responses to reduce the load on microservices and improve response times for frequently <span class="No-Break">requested data.</span></li>
				<li><strong class="bold">Logging and monitoring</strong>: Centralized<a id="_idIndexMarker261"/> logging and monitoring can be implemented via the API gateway to collect data on incoming requests and responses, providing visibility into <span class="No-Break">system behavior.</span></li>
				<li><strong class="bold">Security</strong>: API gateways <a id="_idIndexMarker262"/>can provide security features such as rate limiting, DDoS<a id="_idIndexMarker263"/> protection, and <strong class="bold">web application firewall</strong> (<span class="No-Break"><strong class="bold">WAF</strong></span><span class="No-Break">) capabilities.</span></li>
				<li><strong class="bold">Versioning</strong>: API gateways<a id="_idIndexMarker264"/> can support versioning of APIs, allowing for backward compatibility as <span class="No-Break">services evolve.</span></li>
			</ul>
			<p>When we develop microservices in Node.js, we can use these tools and concepts to increase the efficiency and effectiveness of developers in <span class="No-Break">creating software.</span></p>
			<p><strong class="bold">NGINX</strong> can function as<a id="_idIndexMarker265"/> an API gateway, providing a unified entry point for clients to interact with different microservices. This involves the <span class="No-Break">following aspects:</span></p>
			<ul>
				<li><strong class="bold">API routing</strong>: NGINX can <a id="_idIndexMarker266"/>route requests to specific microservices based on the API endpoint. This simplifies the client experience by presenting a single entry point for <span class="No-Break">various microservices.</span></li>
				<li><strong class="bold">Security</strong>: NGINX can handle <a id="_idIndexMarker267"/>authentication, authorization, and SSL termination, enhancing the security of microservices by centralizing <span class="No-Break">these concerns.</span></li>
			</ul>
			<p><strong class="bold">Authentication</strong> is the process of <a id="_idIndexMarker268"/>verifying the identity of a user, service, or system. In a microservices architecture, each service must handle authentication to ensure that only authorized entities can access <span class="No-Break">its resources.</span></p>
			<p>The following are some techniques <span class="No-Break">for authentication:</span></p>
			<ul>
				<li><strong class="bold">JSON Web Tokens</strong> (<strong class="bold">JWTs</strong>): You can <a id="_idIndexMarker269"/>use JWTs to<a id="_idIndexMarker270"/> encode user information and create tokens that can be verified by each microservice. Then, you can verify tokens in each microservice before <span class="No-Break">processing requests.</span></li>
				<li><strong class="bold">OAuth 2.0</strong>: You can implement <a id="_idIndexMarker271"/>OAuth 2.0<a id="_idIndexMarker272"/> for secure, token-based authentication. OAuth allows third-party services to access resources on behalf of <span class="No-Break">a user.</span></li>
				<li><strong class="bold">Passport.js</strong>: You can leverage the <a id="_idIndexMarker273"/><strong class="source-inline">Passport.js</strong><a id="_idIndexMarker274"/> library to implement authentication strategies in Node.js. It supports various authentication mechanisms, including local authentication, OAuth, and <span class="No-Break">OpenID Connect.</span><p class="list-inset">Here’s an example of this when using <span class="No-Break">a JWT:</span></p><pre class="source-code">
const jwt = require('jsonwebtoken');</pre><pre class="source-code">
// Middleware for authenticating requests</pre><pre class="source-code">
function authenticateToken(req, res, next) {</pre><pre class="source-code">
  const token = req.header('Authorization');</pre><pre class="source-code">
  if (!token) return res.sendStatus(401);</pre><pre class="source-code">
  jwt.verify(token, 'your-secret-key', (err, user) =&gt; {</pre><pre class="source-code">
    if (err) return res.sendStatus(403);</pre><pre class="source-code">
    req.user = user;</pre><pre class="source-code">
    next();</pre><pre class="source-code">
  });</pre><pre class="source-code">
}</pre><pre class="source-code">
// Example route that requires authentication</pre><pre class="source-code">
app.get('/api/resource', authenticateToken, (req, res) =&gt; {</pre><pre class="source-code">
  // Process the request for authenticated users</pre><pre class="source-code">
  res.json({ message: 'Access granted!' });</pre><pre class="source-code">
});</pre></li>
			</ul>
			<p><strong class="bold">Authorization</strong> is the <a id="_idIndexMarker275"/>process of determining what actions a user or service is allowed to perform. It is usually based on the authenticated user’s role or <span class="No-Break">specific permissions.</span></p>
			<p>The following techniques can be used <span class="No-Break">for authorization:</span></p>
			<ul>
				<li><strong class="bold">Role-based access control</strong> (<strong class="bold">RBAC</strong>): You <a id="_idIndexMarker276"/>can<a id="_idIndexMarker277"/> assign roles to users and define permissions associated with each role. You can also check the user’s role before allowing access to <span class="No-Break">certain resources.</span></li>
				<li><strong class="bold">Claims-based authorization</strong>: You can<a id="_idIndexMarker278"/> use claims embedded in tokens to convey<a id="_idIndexMarker279"/> information about the user’s permissions. Microservices can then be authorized based on <span class="No-Break">these claims.</span></li>
				<li><strong class="bold">Middleware for authorization</strong>: You can<a id="_idIndexMarker280"/> implement middleware functions in <a id="_idIndexMarker281"/>each microservice to check whether the authenticated user has the <span class="No-Break">required permissions.</span><p class="list-inset">Here’s an example of this <span class="No-Break">using RBAC:</span></p><pre class="source-code">
// Middleware for role-based authorization</pre><pre class="source-code">
function authorize(role) {</pre><pre class="source-code">
  return (req, res, next) =&gt; {</pre><pre class="source-code">
    if (req.user &amp;&amp; req.user.role === role) {</pre><pre class="source-code">
      return next(); // User has the required role</pre><pre class="source-code">
    }</pre><pre class="source-code">
    res.status(403).send('Forbidden'); // User does not have the required role</pre><pre class="source-code">
  };</pre><pre class="source-code">
}</pre><pre class="source-code">
// Example route that requires a specific role</pre><pre class="source-code">
app.get('/api/admin/resource', authenticateToken, authorize('admin'), (req, res) =&gt; {</pre><pre class="source-code">
  // Process the request for users with the 'admin' role</pre><pre class="source-code">
  res.json({ message: 'Admin access granted!' });</pre><pre class="source-code">
});</pre></li>
			</ul>
			<p><span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.2</em> illustrates the concept of an <a id="_idIndexMarker282"/><span class="No-Break">API gateway:</span></p>
			<div>
				<div id="_idContainer064" class="IMG---Figure">
					<img src="image/B14980_05_02.jpg" alt="Figure 5.2: API gateway"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.2: API gateway</p>
			<p>In summary, service discovery<a id="_idIndexMarker283"/> and API gateways are integral components of microservices infrastructure, enabling effective communication between services and providing a unified entry point for clients. These components enhance the scalability, reliability, security, and manageability of microservices-based applications, making them easier to develop <span class="No-Break">and maintain.</span></p>
			<p>Now that we understand these concepts, let’s learn about load balancing and <span class="No-Break">service orchestration.</span></p>
			<h1 id="_idParaDest-99"><a id="_idTextAnchor100"/>Load balancing and service orchestration</h1>
			<p>Load balancing <a id="_idIndexMarker284"/>and service orchestration<a id="_idIndexMarker285"/> are essential components in the architecture of microservices-based applications. They both contribute to the scalability, availability, and efficient operation of a <span class="No-Break">distributed system.</span></p>
			<h2 id="_idParaDest-100"><a id="_idTextAnchor101"/>Load balancing</h2>
			<p><strong class="bold">Load balancing</strong> is the<a id="_idIndexMarker286"/> practice of distributing incoming network traffic across multiple instances of a service to ensure that no single instance is overwhelmed with requests, thereby optimizing resource utilization and improving <span class="No-Break">system reliability.</span></p>
			<p>In a microservices architecture, load<a id="_idIndexMarker287"/> balancing is crucial because it helps achieve <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">High availability</strong>: Load <a id="_idIndexMarker288"/>balancers distribute traffic evenly across healthy service instances. If one instance fails or becomes overloaded, traffic is automatically redirected to other instances, ensuring <span class="No-Break">uninterrupted service.</span></li>
				<li><strong class="bold">Scalability</strong>: As the <a id="_idIndexMarker289"/>demand for a microservice increases, additional instances can be added, and the load balancer will automatically distribute traffic to these new instances, effectively scaling the <span class="No-Break">application horizontally.</span></li>
				<li><strong class="bold">Resource utilization</strong>: Load<a id="_idIndexMarker290"/> balancers can monitor the health and performance of service instances and make routing decisions based on factors such as response times and server load. This ensures that each instance is <span class="No-Break">used efficiently.</span></li>
				<li><strong class="bold">Failover</strong>: Load<a id="_idIndexMarker291"/> balancers can detect when a service instance becomes unhealthy and stop sending traffic to it. This helps in isolating issues and maintaining the overall <span class="No-Break">system’s integrity.</span></li>
			</ul>
			<p>Some common load balancing strategies are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Round-robin</strong>: This is a<a id="_idIndexMarker292"/> simple and widely used <a id="_idIndexMarker293"/>load balancing algorithm that distributes incoming network traffic or requests evenly across a group of backend servers <span class="No-Break">or resources.</span></li>
				<li><strong class="bold">Least connections</strong>: This is a<a id="_idIndexMarker294"/> load balancing algorithm<a id="_idIndexMarker295"/> that’s used by load balancers to distribute incoming network traffic or requests to a group of backend servers <span class="No-Break">or resources.</span></li>
				<li><strong class="bold">IP hashing</strong>: Also known<a id="_idIndexMarker296"/> as <em class="italic">IP-based load balancing</em> or <em class="italic">IP hash load balancing</em>, PI hashing is a technique that’s used by load balancers to <a id="_idIndexMarker297"/>distribute incoming network traffic or requests to a group of backend servers or resources based on the source or destination IP address of <span class="No-Break">the requests</span></li>
				<li><strong class="bold">Weighted distribution</strong>: This <a id="_idIndexMarker298"/>refers to the practice of <a id="_idIndexMarker299"/>allocating resources or traffic among different instances or replicas of a microservice based on their <span class="No-Break">relative weights.</span></li>
			</ul>
			<p>Load balancing is crucial in microservices architectures where multiple instances of a service may exist. NGINX supports <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Round-robin load balancing</strong>: Distributes<a id="_idIndexMarker300"/> incoming requests evenly among the available <span class="No-Break">microservice instances.</span></li>
				<li><strong class="bold">Health checks</strong>: NGINX can perform health checks<a id="_idIndexMarker301"/> to identify and route traffic away from unhealthy instances, ensuring <span class="No-Break">better reliability.</span></li>
			</ul>
			<p>NGINX acts as a <strong class="bold">reverse proxy</strong>, sitting between client applications and microservices. This offers <span class="No-Break">several advantages:</span></p>
			<ul>
				<li><strong class="bold">Load balancing</strong>: NGINX can<a id="_idIndexMarker302"/> distribute incoming requests among multiple instances of a microservice, ensuring even load distribution and improved <span class="No-Break">system performance.</span></li>
				<li><strong class="bold">Routing</strong>: NGINX can route requests to different microservices based on factors such as URL paths, headers, or other parameters. This enables efficient handling of various functionalities distributed <span class="No-Break">across microservices.</span></li>
			</ul>
			<p><span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.3</em> illustrates <span class="No-Break">load balancing:</span></p>
			<div>
				<div id="_idContainer065" class="IMG---Figure">
					<img src="image/B14980_05_03.jpg" alt="Figure 5.3: Load balancing (image by vectorjuice on Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.3: Load balancing (image by vectorjuice on Freepik)</p>
			<p>Popular load balancing solutions include hardware load balancers and software-based solutions such as <a id="_idIndexMarker303"/>NGINX and HAProxy, as well <a id="_idIndexMarker304"/>as cloud-based load balancers provided by cloud <span class="No-Break">service providers.</span></p>
			<p>With these concepts covered, next, we’ll look at <span class="No-Break">service orchestration.</span></p>
			<h2 id="_idParaDest-101"><a id="_idTextAnchor102"/>Service orchestration</h2>
			<p><strong class="bold">Service orchestration</strong> involves <a id="_idIndexMarker305"/>coordinating and managing the execution of multiple microservices to fulfill a specific business process or workflow. It ensures that the individual services work together harmoniously to achieve a <span class="No-Break">higher-level objective.</span></p>
			<p>Here’s how <a id="_idIndexMarker306"/>service orchestration contributes to a <span class="No-Break">microservices architecture:</span></p>
			<ul>
				<li><strong class="bold">Complex workflow handling</strong>: Microservices often need to collaborate to perform complex tasks or workflows. Service orchestration defines the sequence of microservices to be executed and manages their interactions to complete <span class="No-Break">the workflow.</span></li>
				<li><strong class="bold">Centralized control</strong>: Service orchestration typically involves a central orchestrator component that coordinates the execution of microservices, thereby handling error recovery and ensuring the correct order <span class="No-Break">of operations.</span></li>
				<li><strong class="bold">Asynchronous communication</strong>: Microservices can communicate with each other through asynchronous message passing, enabling loosely coupled interactions. Service orchestration manages the messaging and data flow <span class="No-Break">between services.</span></li>
				<li><strong class="bold">Long-running processes</strong>: For long-running processes that span multiple microservices, service orchestration ensures that steps are executed in the correct order and that data consistency <span class="No-Break">is maintained.</span></li>
				<li><strong class="bold">Dynamic scaling</strong>: Service orchestration can dynamically scale microservices based on the workload, ensuring that resources are allocated optimally to handle <span class="No-Break">varying demands.</span></li>
			</ul>
			<p>Service orchestration can be implemented using various tools and patterns, including workflow engines, message queues, and choreography-based approaches. Tools such as Apache Camel, Netflix Conductor, and Kubernetes-based orchestration solutions are commonly used in <span class="No-Break">microservices environments.</span></p>
			<p class="callout-heading">Additional information</p>
			<p class="callout"><em class="italic">Apache Camel</em> is an<a id="_idIndexMarker307"/> open source integration framework that provides a lightweight, easy-to-use platform for routing and mediating message exchanges between different systems. You can access its<a id="_idIndexMarker308"/> documentation <span class="No-Break">at </span><a href="https://camel.apache.org/docs/"><span class="No-Break">https://camel.apache.org/docs/</span></a><span class="No-Break">.</span></p>
			<p class="callout"><em class="italic">Netflix Conductor</em> allows <a id="_idIndexMarker309"/>developers to design, execute, and manage complex <a id="_idIndexMarker310"/>workflows in a scalable and reliable manner. You can access its documentation <span class="No-Break">at </span><a href="https://orkes.io/content/"><span class="No-Break">https://orkes.io/content/</span></a><span class="No-Break">.</span></p>
			<p class="callout"><em class="italic">Kubernetes orchestration</em> is a <a id="_idIndexMarker311"/>platform for container orchestration that allows you to build application services that span multiple containers, schedule containers across a cluster, scale those containers, and<a id="_idIndexMarker312"/> manage their health over time. You can access its documentation <span class="No-Break">at </span><a href="https://kubernetes.io/docs/home/supported-doc-versions"><span class="No-Break">https://kubernetes.io/docs/home/supported-doc-versions</span></a><span class="No-Break">.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.4</em> depicts <span class="No-Break">service orchestration:</span></p>
			<div>
				<div id="_idContainer066" class="IMG---Figure">
					<img src="image/B14980_05_04.jpg" alt="Figure 5.4: Service orchestration (image by Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.4: Service orchestration (image by Freepik)</p>
			<p>In summary, load balancing and service orchestration are fundamental components of microservices architecture. Load balancing ensures the efficient distribution of traffic and resource utilization, while service orchestration manages the coordination and execution of microservices to complete complex workflows and business processes. Together, these components contribute to the scalability, availability, and reliability of <span class="No-Break">microservices-based applications.</span></p>
			<p>Now, we can continue to the next section, in which we will talk about containerization and orchestration and centralized logging <span class="No-Break">and monitoring.</span></p>
			<h1 id="_idParaDest-102"><a id="_idTextAnchor103"/>Containerization and orchestration and centralized logging and monitoring</h1>
			<p>Containerization <a id="_idIndexMarker313"/>and orchestration<a id="_idIndexMarker314"/> and centralized logging and monitoring are two critical components in the infrastructure of microservices-based applications. They play pivotal roles in ensuring the efficient deployment, management, and monitoring <span class="No-Break">of microservices.</span></p>
			<p>We’ll start with containerization <span class="No-Break">and orchestration.</span></p>
			<h2 id="_idParaDest-103"><a id="_idTextAnchor104"/>Containerization and orchestration</h2>
			<p><strong class="bold">Containerization</strong> involves<a id="_idIndexMarker315"/> packaging an application and its dependencies into a standardized unit called<a id="_idIndexMarker316"/> <span class="No-Break">a </span><span class="No-Break"><strong class="bold">container</strong></span><span class="No-Break">.</span></p>
			<p>Orchestration refers to the process of automatically managing containerized applications. It involves deploying, scaling, load balancing, and maintaining containers across a cluster of machines. Kubernetes is the most popular container orchestration platform, but others, such as Docker Swarm and Apache Mesos, <span class="No-Break">also exist.</span></p>
			<p>Here’s how containerization and orchestration <span class="No-Break">benefit microservices:</span></p>
			<ul>
				<li><strong class="bold">Isolation</strong>: Containers provide process isolation, ensuring that microservices do not interfere with each other, making it easier to maintain <span class="No-Break">consistent environments.</span></li>
				<li><strong class="bold">Portability</strong>: Containers can run on any platform that supports containerization, making it possible to move microservices across development, testing, and production <span class="No-Break">environments seamlessly.</span></li>
				<li><strong class="bold">Resource efficiency</strong>: Orchestration platforms such as Kubernetes automate the deployment and scaling of containers, optimizing resource utilization and ensuring that microservices have the required resources <span class="No-Break">when needed.</span></li>
				<li><strong class="bold">High availability</strong>: Orchestration platforms monitor the health of microservices and can automatically replace failed instances, ensuring high availability and <span class="No-Break">fault tolerance.</span></li>
				<li><strong class="bold">Scaling</strong>: Microservices can be easily scaled up or down by adjusting the number of container replicas. This is crucial for handling <span class="No-Break">variable workloads.</span></li>
			</ul>
			<p>Containers<a id="_idIndexMarker317"/> encapsulate the application code, runtime, system libraries, and settings, ensuring consistency and portability across <span class="No-Break">different environments.</span></p>
			<p class="callout-heading">Additional information</p>
			<p class="callout"><strong class="bold">Docker</strong> is an <a id="_idIndexMarker318"/>open-source platform that allows you to automate the deployment, scaling, and management of applications using containerization and is a widely used <span class="No-Break">containerization platform.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.5</em> illustrates containerization <span class="No-Break">and orchestration:</span></p>
			<div>
				<div id="_idContainer067" class="IMG---Figure">
					<img src="image/B14980_05_05.jpg" alt="Figure 5.5: Full-stack development process (image by vectorjuice on Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.5: Full-stack development process (image by vectorjuice on Freepik)</p>
			<p>Containerization<a id="_idIndexMarker319"/> and orchestration<a id="_idIndexMarker320"/> can help ship software that will run on every platform and in every system. By automatically managing containerization, you can achieve greater versatility <span class="No-Break">in deployment.</span></p>
			<p>In the next section, we will talk about centralized logging <span class="No-Break">and monitoring.</span></p>
			<h2 id="_idParaDest-104"><a id="_idTextAnchor105"/>Centralized logging and monitoring</h2>
			<p><strong class="bold">Centralized logging and monitoring systems</strong> collect<a id="_idIndexMarker321"/> and analyze <a id="_idIndexMarker322"/>data from microservices and their environments. These systems help in diagnosing issues, optimizing performance, and ensuring the health of <span class="No-Break">microservices- applications.</span></p>
			<p>Let’s look at some of the common components of these <span class="No-Break">systems include:</span></p>
			<ul>
				<li><strong class="bold">Log collectors</strong>: These are <a id="_idIndexMarker323"/>agents or services that gather logs generated by microservices and forward them to a <span class="No-Break">central location.</span></li>
				<li><strong class="bold">Log aggregators</strong>: These are <a id="_idIndexMarker324"/>systems that consolidate logs from various sources, making it easier to search, analyze, and visualize log data. Examples include Elasticsearch, Fluentd, <span class="No-Break">and Logstash.</span></li>
				<li><strong class="bold">Metrics and monitoring</strong>: Tools such <a id="_idIndexMarker325"/>as Prometheus and Grafana (two popular open source tools used for monitoring and visualizing metrics and time series data) are used to collect and display real-time performance metrics from microservices. They provide insights into the behavior of the application and <span class="No-Break">its components.</span></li>
				<li><strong class="bold">Alerting</strong>: Monitoring<a id="_idIndexMarker326"/> systems can generate alerts based on predefined thresholds, allowing operations teams to respond to <span class="No-Break">issues promptly.</span></li>
				<li><strong class="bold">Tracing</strong>: Distributed <a id="_idIndexMarker327"/>tracing tools such as Jaeger and Zipkin (two distributed tracing systems that are used to monitor and troubleshoot complex, microservices-based architectures) help track the flow of requests across microservices, making it easier to identify bottlenecks and <span class="No-Break">latency issues.</span></li>
			</ul>
			<p class="callout-heading">Additional information</p>
			<p class="callout"><em class="italic">Elasticsearch</em> is a <a id="_idIndexMarker328"/>highly scalable open source search and analytics engine built on top of Apache Lucene. You can access <a id="_idIndexMarker329"/>its documentation <span class="No-Break">at </span><a href="https://www.elastic.co/guide/index.html"><span class="No-Break">https://www.elastic.co/guide/index.html</span></a><span class="No-Break">.</span></p>
			<p class="callout"><em class="italic">Fluentd</em> is an <a id="_idIndexMarker330"/>open source data collector designed to unify data collection and consumption for <a id="_idIndexMarker331"/>better analysis and insights. You can access its documentation <span class="No-Break">at </span><a href="https://docs.fluentd.org/"><span class="No-Break">https://docs.fluentd.org/</span></a><span class="No-Break">.</span></p>
			<p class="callout"><em class="italic">Logstash</em> is an<a id="_idIndexMarker332"/> open source data processing pipeline that allows you to collect, process, and ingest data from various sources into different output destinations (ELK Stack). You can access its <a id="_idIndexMarker333"/>documentation <span class="No-Break">at </span><a href="https://www.elastic.co/guide/en/logstash/current/introduction.html"><span class="No-Break">https://www.elastic.co/guide/en/logstash/current/introduction.html</span></a><span class="No-Break">.</span></p>
			<p>Centralized logging and monitoring offer several<a id="_idIndexMarker334"/> benefits, including improved visibility, scalability, access to historical data, and increased efficiency in managing and analyzing logs <span class="No-Break">and metrics.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.6</em> illustrates centralized logging <span class="No-Break">and monitoring:</span></p>
			<div>
				<div id="_idContainer068" class="IMG---Figure">
					<img src="image/B14980_05_06.jpg" alt="Figure 5.6: Centralized logging and monitoring (image by pch.vector on Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.6: Centralized logging and monitoring (image by pch.vector on Freepik)</p>
			<p>In summary, containerization and orchestration provide a scalable and efficient way to manage microservices, while centralized logging and monitoring ensure that these services operate reliably and can be effectively maintained. Together, these components form a robust foundation for <span class="No-Break">microservices-based applications.</span></p>
			<p>In the next section, we will learn about distributed tracing and <span class="No-Break">event-driven communication.</span></p>
			<h1 id="_idParaDest-105"><a id="_idTextAnchor106"/>Distributed tracing and event-driven communication</h1>
			<p>Distributed tracing<a id="_idIndexMarker335"/> and event-driven <a id="_idIndexMarker336"/>communication are two crucial concepts in the world of microservices and distributed systems. They address challenges related to monitoring and coordinating interactions between microservices. Let’s dive into <span class="No-Break">these concepts.</span></p>
			<h2 id="_idParaDest-106"><a id="_idTextAnchor107"/>Distributed tracing</h2>
			<p><strong class="bold">Distributed tracing</strong> is <a id="_idIndexMarker337"/>a technique that’s used to track and monitor requests as they traverse multiple microservices in a distributed system. It provides end-to-end visibility into the flow of a request, allowing you to identify performance bottlenecks, troubleshoot issues, and optimize the <span class="No-Break">system’s behavior.</span></p>
			<p>Here’s how distributed <span class="No-Break">tracing works:</span></p>
			<ul>
				<li><strong class="bold">Instrumentation</strong>: Each<a id="_idIndexMarker338"/> microservice in your architecture is instrumented to generate trace data. This typically involves adding trace headers to incoming requests and recording timing information for various operations within <span class="No-Break">the service.</span></li>
				<li><strong class="bold">Trace context</strong>: The trace context is propagated along with the request as it moves from one microservice to another. This context includes a unique trace ID and span ID, which allows you to correlate activities <span class="No-Break">across services.</span></li>
				<li><strong class="bold">Centralized collector</strong>: Trace data from all microservices is sent to a centralized collector or storage system. Popular options include Zipkin, Jaeger, and the <span class="No-Break">Elastic Stack.</span></li>
				<li><strong class="bold">Visualization and analysis</strong>: Once the trace data has been collected, you can visualize it using specialized tools. This allows you to see the entire journey of a request, including service-to-service communication and the time spent at <span class="No-Break">each step.</span></li>
				<li><strong class="bold">Improved customer experience</strong>: Once the trace data has been collected, you can visualize it using specialized tools. This allows you to see the entire journey of a request, including service-to-service communication and the time spent at <span class="No-Break">each step.</span></li>
			</ul>
			<p>Distributed tracing<a id="_idIndexMarker339"/> is a powerful tool for performance optimization, root cause analysis, dependency mapping, and capacity planning in distributed systems. It provides detailed visibility into the behavior and performance of your applications, allowing you to make data-driven decisions for improving system performance <span class="No-Break">and reliability.</span></p>
			<p>In the next section, we will talk about <span class="No-Break">event-driven communication.</span></p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor108"/>Event-driven communication</h2>
			<p><strong class="bold">Event-driven communication</strong> is a<a id="_idIndexMarker340"/> messaging pattern where microservices communicate asynchronously through the exchange of events or messages. This approach decouples services, allowing them to work independently and react to events triggered by <span class="No-Break">other services.</span></p>
			<p>Here’s how event-driven <a id="_idIndexMarker341"/><span class="No-Break">communication works:</span></p>
			<ul>
				<li><strong class="bold">Event producers</strong>: These are <a id="_idIndexMarker342"/>microservices that generate events or messages and publish them to a message broker or event bus. Events can represent various actions or <span class="No-Break">state changes.</span></li>
				<li><strong class="bold">Event consumers</strong>: These are <a id="_idIndexMarker343"/>microservices that subscribe to specific events and react to them. They perform actions based on the information contained in <span class="No-Break">the events.</span></li>
				<li><strong class="bold">Message brokers</strong>: These are <a id="_idIndexMarker344"/>middleware components that facilitate the exchange of messages between producers and consumers. Popular message brokers include Apache Kafka, RabbitMQ, and <span class="No-Break">AWS SNS/SQS.</span></li>
			</ul>
			<p>In summary, distributed tracing enhances your ability to monitor and diagnose the behavior of microservices, while event-driven communication fosters loose coupling and scalability in a microservices architecture. These concepts are valuable for building resilient and responsive <span class="No-Break">distributed systems.</span></p>
			<p>In the next section, we are going to talk about database integration and continuous integration <span class="No-Break">and deployment.</span></p>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor109"/>Database integration and continuous integration and deployment</h1>
			<p>Database integration and <strong class="bold">continuous integration/continuous deployment</strong> (<strong class="bold">CI/CD</strong>) are <a id="_idIndexMarker345"/>critical aspects of a microservices architecture. They ensure that data is managed effectively and that changes to microservices are deployed efficiently <span class="No-Break">and reliably.</span></p>
			<h2 id="_idParaDest-109"><a id="_idTextAnchor110"/>Database integration</h2>
			<p>In a microservices <a id="_idIndexMarker346"/>architecture, each microservice typically has its own database or data store. This separation of data is known as <em class="italic">database </em><span class="No-Break"><em class="italic">per service</em></span><span class="No-Break">.</span></p>
			<p>Here are some key considerations for database <a id="_idIndexMarker347"/>integration <span class="No-Break">in microservices:</span></p>
			<ul>
				<li><strong class="bold">Data consistency</strong>: To ensure data consistency, three <a id="_idIndexMarker348"/>approaches are commonly used – two-phase commits, distributed transactions, and <span class="No-Break">eventual consistency:</span><ul><li><strong class="bold">Two-phase commits</strong>: <strong class="bold">Two-phase commit</strong> (<strong class="bold">2PC</strong>) is <a id="_idIndexMarker349"/>a protocol that ensures atomicity and consistency in distributed transactions. It involves coordinating multiple participants or resources to decide whether to commit or abort a transaction. The protocol consists of two phases: a preparation phase and a commit phase. In the preparation phase, each participant informs the coordinator whether it can successfully commit the transaction. In the commit phase, the coordinator sends a commit message to all participants if everyone agrees to commit, or an abort message if anyone disagrees. This ensures that all participants either commit or abort the <span class="No-Break">transaction together.</span></li><li><strong class="bold">Distributed transactions</strong>: Distributed transactions<a id="_idIndexMarker350"/> involve multiple independent systems or databases that participate in a single transaction. A transaction within a distributed environment has the same properties as a local transaction, including <strong class="bold">Atomicity, Consistency, Isolation, and Durability</strong> (<strong class="bold">ACID</strong>) properties. Distributed transaction<a id="_idIndexMarker351"/> management systems handle the coordination and synchronization between participating nodes to ensure the consistency of the entire transaction. These systems may employ protocols such as 2PC to coordinate the actions of <span class="No-Break">the participants.</span></li><li><strong class="bold">Eventual consistency</strong>: Eventual consistency<a id="_idIndexMarker352"/> is a consistency model that’s used in distributed systems. It relaxes the strict consistency requirements of traditional ACID databases to provide high availability, scalability, and tolerance to network partitions. In an eventually consistent system, updates to replicated data occur asynchronously, allowing different replicas to diverge temporarily. However, the system guarantees that eventually, all replicas will converge to a consistent state. This approach prioritizes availability and performance over strict consistency, making it suitable for scenarios where data can tolerate <span class="No-Break">temporary inconsistencies.</span></li></ul><p class="list-inset">Each approach has<a id="_idIndexMarker353"/> its advantages and trade-offs, depending on the specific requirements of the system. Two-phase commits and distributed transactions provide strong consistency guarantees but can introduce additional overhead and complexity due to coordination between participants. On the other hand, eventual consistency prioritizes availability and scalability but may lead to temporary data inconsistencies. The choice of approach depends on factors such as the system’s workload, performance requirements, and the level of consistency needed in <span class="No-Break">the application.</span></p></li>
				<li><strong class="bold">APIs for data access</strong>: Defining clear<a id="_idIndexMarker354"/> APIs for accessing and modifying data in each microservice’s database helps maintain control over <span class="No-Break">data interactions.</span></li>
				<li><strong class="bold">Data synchronization</strong>: This<a id="_idIndexMarker355"/> involves implementing data synchronization mechanisms or using event-driven architecture to propagate changes in one microservice’s data to others who may <span class="No-Break">be interested.</span></li>
				<li><strong class="bold">Caching</strong>: You can use caching<a id="_idIndexMarker356"/> strategies to improve data retrieval performance and reduce the load <span class="No-Break">on databases.</span></li>
				<li><strong class="bold">Polyglot persistence</strong>: This involves<a id="_idIndexMarker357"/> choosing the right database technology for each microservice’s specific data storage needs. Different microservices may use different types of databases (for example, relational, NoSQL, and so on) based on <span class="No-Break">their requirements.</span></li>
				<li><strong class="bold">Data ownership</strong>: You must <a id="_idIndexMarker358"/>clearly define which microservice is the authoritative source for specific types of data and ensure that data ownership is<a id="_idIndexMarker359"/> clear to <span class="No-Break">prevent conflicts.</span></li>
			</ul>
			<p>Database integration refers to strategies and techniques for managing data across these distributed databases and ensuring that data consistency and integrity <span class="No-Break">are maintained.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.7</em> presents an example of <span class="No-Break">database integration:</span></p>
			<div>
				<div id="_idContainer069" class="IMG---Figure">
					<img src="image/B14980_05_07.jpg" alt="Figure 5.7: Database integration (image from Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.7: Database integration (image from Freepik)</p>
			<p>Database as a<a id="_idIndexMarker360"/> service can help developers develop faster while focusing on a single microservice and creating the best user experience for <span class="No-Break">different users.</span></p>
			<p>In the next section, we will learn more <span class="No-Break">about CI/CD.</span></p>
			<h2 id="_idParaDest-110"><a id="_idTextAnchor111"/>CI/CD</h2>
			<p><strong class="bold">CI/CD</strong> is a<a id="_idIndexMarker361"/> set of practices and tools that enable the automated building, testing, and deployment of software changes, including those in microservices. CI/CD pipelines streamline the process of delivering updates to microservices-based applications and ensure that changes are integrated and <span class="No-Break">tested seamlessly.</span></p>
			<p>Here are some key aspects of <a id="_idIndexMarker362"/>CI/CD in a <span class="No-Break">microservices environment:</span></p>
			<ul>
				<li><strong class="bold">Automated builds</strong>: Automate<a id="_idIndexMarker363"/> the process of building microservices and their dependencies whenever changes are pushed to a version control system (for <span class="No-Break">example, Git).</span></li>
				<li><strong class="bold">Automated testing</strong>: Run<a id="_idIndexMarker364"/> automated tests, including unit tests, integration tests, and end-to-end tests, to ensure that changes do not <span class="No-Break">introduce regressions.</span></li>
				<li><strong class="bold">Artifact repository</strong>: Store <a id="_idIndexMarker365"/>built artifacts (for example, Docker images) in a repository for easy access <span class="No-Break">during deployment.</span></li>
				<li><strong class="bold">Deployment automation</strong>: Automate <a id="_idIndexMarker366"/>the deployment process to staging and production environments, including rolling updates, blue-green deployments, or canary releases. All these strategies are used in deployment automation to ensure smooth and safe <span class="No-Break">application releases.</span></li>
				<li><strong class="bold">Infrastructure as Code</strong> (<strong class="bold">IaC</strong>): Define<a id="_idIndexMarker367"/> infrastructure components (for example, containers and virtual machines) as code to ensure consistent environments <span class="No-Break">across stages.</span></li>
				<li><strong class="bold">Monitoring and rollback</strong>: Integrate <a id="_idIndexMarker368"/>monitoring and alerting into the CI/CD pipeline to detect issues in production and enable rollback <span class="No-Break">if necessary.</span></li>
				<li><strong class="bold">Versioning</strong>: Manage <a id="_idIndexMarker369"/>versions of microservices and their dependencies to ensure that changes are tracked and can be rolled back <span class="No-Break">if needed.</span></li>
			</ul>
			<p>CI/CD pipelines help microservices teams deliver software changes quickly and reliably, reducing manual intervention and the risk of human error. They promote a culture of continuous improvement and allow teams to release new features and bug fixes <span class="No-Break">more frequently.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 5</em></span><em class="italic">.8</em> illustrates the process <span class="No-Break">of CI/CD:</span></p>
			<div>
				<div id="_idContainer070" class="IMG---Figure">
					<img src="image/B14980_05_08.jpg" alt="Figure 5.8: CI/CD (image by vectorjuice on Freepik)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.8: CI/CD (image by vectorjuice on Freepik)</p>
			<p>In summary, database<a id="_idIndexMarker370"/> integration strategies help manage data in a microservices architecture, ensuring consistency and coordination, while CI/CD pipelines streamline the development and deployment of microservices, enabling rapid and reliable software delivery. Both aspects are critical for the success of <span class="No-Break">microservices-based applications.</span></p>
			<h1 id="_idParaDest-111"><a id="_idTextAnchor112"/>Summary</h1>
			<p>In this chapter, we learned a lot about services that need to discover and communicate with each other dynamically, load balancing and service orchestration, containerization and orchestration and centralized logging and monitoring, distributed tracing and event-driven communication, and database integration <span class="No-Break">and CI/CD.</span></p>
			<p>Building the infrastructure for microservices in Node.js involves carefully selecting and integrating these components and tools based on your specific requirements. It’s important to consider scalability, fault tolerance, observability, and ease of management when designing and implementing the infrastructure for your <span class="No-Break">microservices architecture.</span></p>
			<p>The infrastructure of microservices in Node.js is a critical foundation for developing scalable, distributed applications. It encompasses various components and practices that enable the effective operation of <span class="No-Break">microservices-based systems.</span></p>
			<p>This infrastructure is designed to handle the complexities of microservices architecture, ensuring they can work together cohesively, scale efficiently, and remain resilient in the face of failures. Node.js, with its non-blocking, event-driven architecture, is a popular choice for implementing microservices, making this infrastructure even more powerful <span class="No-Break">and adaptable.</span></p>
			<p>In the next chapter, we are going to learn how to design microservices architecture <span class="No-Break">in Node.js.</span></p>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor113"/>Quiz time</h1>
			<ul>
				<li>What is <span class="No-Break">service discovery?</span></li>
				<li>What are <span class="No-Break">API gateways?</span></li>
				<li>What is <span class="No-Break">load balancing?</span></li>
				<li>What <span class="No-Break">is containerization?</span></li>
			</ul>
		</div>
	</body></html>