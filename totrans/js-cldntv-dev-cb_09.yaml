- en: Optimizing Performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, the following recipes will be covered:'
  prefs: []
  type: TYPE_NORMAL
- en: Tuning Function as a Service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Batching requests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leveraging asynchronous non-blocking IO
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grouping events in stream processors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autoscaling DynamoDB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilizing cache-control
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leveraging session consistency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloud-native turns performance testing, tuning, and optimization on their heads.
    Many of the fully-managed, serverless cloud services that are leveraged have implicit
    scalability. These services are purchased per request and will automatically scale
    to meet peak and unexpected demands. For these resources, it is much less necessary
    to perform upfront performance testing; instead, we optimize for observability,
    as discussed in [Chapter 7](64a4c0f7-3b2d-4638-a52c-f72953ff66d9.xhtml), *Optimizing
    Observability*, and continuously tune based on the information gathered from continuous
    testing in production. We also leverage continuous deployment to push necessary
    improvements. This worth-based development approach helps ensure that we are focusing
    our efforts on the highest value improvements.
  prefs: []
  type: TYPE_NORMAL
- en: Still, there are resources, such as some stream processors and data stores,
    that rely heavily on explicitly defined batch sizes and read/write capacities.
    For crucial services, these resources must be sufficiently allocated to ensure
    peak data processing volumes do not overwhelm them. The recipes in this chapter
    will therefore focus on performance optimization techniques that are worth applying
    upfront in the design and development process to help ensure services are not
    working against themselves.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning Function as a Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tuning functions is very different from traditional service tuning because there
    are so few explicit knobs to turn. There are also many implications of the short
    life cycle of a function that turns traditional techniques and frameworks into
    anti-patterns. The following recipe explains a common memory mistake, discusses
    the cold start implications of traditional language and library choices, and will
    show you how to package a JavaScript function with **webpack** to minimize download
    time.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create the project from the following template:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Navigate to the `cncb-tuning-faas` directory, `cd cncb-tuning-faas`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Review the file named `serverless.yml` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Review the file named `webpack.config.js` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Install the dependencies with `npm install`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the tests with `npm test`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the contents generated in the `.serverless` directory, note the ZIP file
    per function, and then unzip each to see the contents.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the stack, `npm run dp:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the stack and resources in the AWS Console and note the code size in
    the Lambda console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most obvious knob we have for tuning **Function as a Service** (**FaaS**)
    is `memorySize` allocation. This setting drives the price calculation as well.
    Unfortunately, the correlation with price tends to be counter-intuitive and can
    result in decisions that actually increase costs, while also reducing performance.
    The way AWS Lambda pricing works is if you double the memory allocation but consequently
    cut the execution time in half, the price is the same. The corollary is that if
    you cut memory allocation in half and consequently double the execution time,
    you are spending the same amount of money for less performance. It works this
    way because memory allocation actually correlates to the machine instance size
    that a function is executed on. More memory allocation means that the function
    will also have a faster CPU and more network IO throughput. In short, *do not
    skimp on memory allocation*.
  prefs: []
  type: TYPE_NORMAL
- en: A major concern and source of confusion with Function as a Service is cold start
    times. For asynchronous functions, such as processing a Kinesis Stream, cold start
    times are not as concerning. This is because cold start frequency is lower as
    functions tend to be reused for several hours for each shard. However, minimizing
    cold start times for synchronous functions behind an API Gateway is very important,
    because multiple functions are started to accommodate concurrent load. As a result,
    cold start times could impact the end user experience.
  prefs: []
  type: TYPE_NORMAL
- en: The first thing that impacts cold start time is the size of the function package
    that must be downloaded to the container. This is one reason that allocating more
    memory and hence more network IO throughput improves the performance of a function.
    It is also important to minimize the size of the package that must be downloaded.
    We will discuss how to use webpack to optimize JavaScript functions shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next thing that impacts cold start times is the choice of language or runtime.
    Scripting languages, such as JavaScript and Python, do very little at startup
    and thus have very little impact on cold start times. Conversely, Java must do
    work at startup to load classes and prepare the JVM. As the number of classes
    increases, the impact on cold starts also increases. This leads to the next impact
    on cold start times: the choice of libraries and frameworks, such as **object
    relation mapping** (**ORM**) and dependency injection frameworks, and connection
    pooling libraries. These tend to do a lot of work at startup because they were
    designed to work in long running servers.'
  prefs: []
  type: TYPE_NORMAL
- en: A common issue among FaaS developers using Java is the improvement of cold start
    times for functions written with Spring and Hibernate; however these tools were
    not designed for FaaS in the first place. I have programmed in Java for over 20
    years, from when it first appeared in the 1990s. I was skeptical about changing
    to JavaScript at first, but this cookbook is testament to its fit with cloud-native
    and serverless architecture. It is worth noting, however, that polyglot programming
    is the best policy; use the right programming language for a specific service,
    but understand the implications of it when using it with Faas.
  prefs: []
  type: TYPE_NORMAL
- en: To minimize a JavaScript function's package size, we leverage webpack for the
    same reasons we use it to minimize downloads to browsers. Webpack performs tree
    shaking, which removes unused code to reduce package size. In the `serverless.yml`
    file, we include the `serverless-webpack` plugin and configure it to package functions
    individually. Packaging functions individually allows us to maximize the benefits
    of tree shaking. The `webpack.config.js` file further controls the packaging process.
    The `serverless-webpack` plugin provides the `slsw.lib.entries` utility so that
    we do not need to duplicate the function names to define all the `entry` points.
    We also turn off the `minimize` feature, which uglifies the code. We do this to
    avoid including source maps for debugging, which significantly increases the package
    size. We also exclude all of the external libraries in the `node_modules` folder
    and configure the plugin to `includeModules`, which includes those that are actually
    used as runtime. One special exception is the `aws-sdk` module, which is never
    included because it is already available in the function container. The end result
    is a lean function package that contains only what is necessary.
  prefs: []
  type: TYPE_NORMAL
- en: Batching requests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The design of a stream processor must account for the volume of data it will
    receive. The data should be processed in real time and the processor should not
    fall behind. The following recipe demonstrates how to use DynamoDB batch writes
    to help ensure sufficient throughput.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before starting this recipe, you will need an AWS Kinesis Stream, such as the
    one created in the *Creating an event stream* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create the project from the following template:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Navigate to the `cncb-frp-batching` directory, `cd cncb-frp-batching`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the file named `serverless.yml`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Review the file named `handler.js` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Install the dependencies with `npm install`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the tests with `npm test -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the contents generated in the `.serverless` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the stack, `npm run dp:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the stack and resources in the AWS Console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Invoke the `simulate` function with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the following `listener` function logs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Finally, remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If a stream processor receives a batch of 1,000 events, will it execute faster
    if it has to make 1,000 requests to the database or just 100 requests? The answer
    of course depends on many variables, but in general, making fewer calls over the
    network is better because it minimizes the impact of network latency. To this
    end, services such as DynamoDB and Elasticsearchprovide APIs that allow batches
    of commands to be submitted in a single request. In this recipe, we use DynamoDB's
    `batchWrite` operation. To prepare a batch, we simply add a `batch` step to the
    pipeline and specify the `WRITE_BATCH_SIZE`. This performance improvement is very
    simple to add, but it is important to keep in mind that batching requests increase
    the rate at which DynamoDB's write capacity is consumed. Therefore, it is necessary
    to include the `WRITE_BATCH_SIZE` in the `ratelimit` calculation and increase
    the write capacity accordingly, as discussed in the *Implementing backpressure
    and rate limiting* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Another important thing to note is that these batch requests are not treated
    as a single transaction. Some commands may succeed and others may fail in a single
    request; it is therefore necessary to inspect the response for `UnprocessedItems`
    that needs to be resubmitted. In this recipe, we treat each batch as a **unit
    of work** (**uow**) and raise a fault for the entire batch, as discussed in the
    *Handling faults* recipe. This is a good, safe place to start before tuning the
    logic to retry only the commands that fail. Note that, ultimately, you would only
    raise a fault when the maximum number of retries has been attempted.
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging asynchronous non-blocking IO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The design of a stream processor must account for the volume of data it will
    receive. The data should be processed in real-time and the processor should not
    fall behind. The following recipe demonstrates how to leverage asynchronous, non-blocking
    IO to process data in parallel to help ensure sufficient throughput.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create the project from the following template:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Navigate to the `cncb-frp-async-non-blocking-io` directory, `cd cncb-frp-async-non-blocking-io`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the file named `serverless.yml`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Review the file named `handler.js` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Install the dependencies with `npm install`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the tests with `npm test -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the contents generated in the `.serverless` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the stack `npm run dp:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the stack and resources in the AWS Console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Invoke the `simulate` function with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the following `listener` function logs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Finally, remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Asynchronous non-blocking IO* is extremely valuable for maximizing throughput.
    Without it, a stream processor will block and do nothing until an external call
    has completed. This recipe demonstrates how to use a `parallel` step to control
    the number of concurrent calls that can execute. As an example of the impact this
    can have, I once had a script that read from S3 and would take well over an hour
    to process, but once I added a `parallel` step with a setting of 16, the script
    executed in just five minutes. The improvement was so significant that Datadog
    contacted me, almost immediately, to see if we had a runaway process.'
  prefs: []
  type: TYPE_NORMAL
- en: To allow concurrent calls, we simply add a `parallel` step to the pipeline after
    an external call step and specify the `PARALLEL` amount. This performance improvement
    is very simple to add, but it is important to keep in mind that parallel requests
    increase the rate at which DynamoDB's write capacity is consumed. It is therefore
    necessary to include the `PARALLEL` amount in the `ratelimit` calculation and
    increase the write capacity accordingly, as discussed in the *Implementing backpressure
    and rate limiting* recipe. Further performance improvements may be achieved by
    combining parallel execution with grouping and batching.
  prefs: []
  type: TYPE_NORMAL
- en: Grouping events in stream processors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The design of a stream processor must account for the volume of data it will
    receive. The data should be processed in real-time and the processor should not
    fall behind. The following recipe demonstrates how grouping related data in a
    stream can help ensure sufficient throughput.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create the project from the following template:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Navigate to the `cncb-frp-grouping` directory, `cd cncb-frp-grouping`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the file named `serverless.yml`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Review the file named `handler.js` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Install the dependencies with `npm install`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the tests with `npm test -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the contents generated in the `.serverless` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the stack `npm run dp:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the stack and resources in the AWS Console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Invoke the `simulate` function with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the following `listener` function logs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Finally, remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *Batching requests* recipe demonstrates how to minimize the overhead of
    network IO by batching multiple unrelated commands into a single request. Another
    way to minimize network IO is to simply reduce the number of commands that need
    to be executed by grouping related events, and only executing a single command
    per grouping. For example, we might perform a calculation per group or just sample
    some of the data. In this recipe, we grouped events by the `partitionKey`. We
    can group events by any data in the events, but the best results are achieved
    when the grouping is relative to the partition key; this is because the partition
    key ensures that related events are sent to the same shard.
  prefs: []
  type: TYPE_NORMAL
- en: The `group` step makes it straightforward to reduce related events into groups
    based on the content of the events. For more complicated logic, a `reduce` step
    can be used directly. Next, we map each group to a unit of work (`groupUow`) that
    must succeed or fail together, as discussed in the *Handling faults* recipe. Finally,
    as shown in the preceding example, we write the `last` event of each group. Note
    from the logs that grouping results in significantly fewer writes; for this specific
    run, there were 4,500 events simulated and only 25 writes. Further performance
    improvements may be achieved by combining grouping with batching and parallel
    invocations.
  prefs: []
  type: TYPE_NORMAL
- en: Autoscaling DynamoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloud-native, with FaaS and serverless, minimize the amount of effort that is
    needed to scale the infrastructure that supports the service layer. However, we
    now need to focus on tuning the stream processors and minimize any throttling
    of the target data store. The following recipe demonstrates how to use DynamoDB
    autoscaling to help ensure that enough capacity is allocated to provide sufficient
    throughput and avoid throttling.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create the project from the following template:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Navigate to the `cncb-dynamodb-autoscaling` directory, `cd cncb-dynamodb-autoscaling`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Review the file named `serverless.yml` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Review the file named `handler.js`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install the dependencies with `npm install`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the tests with `npm test -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the contents generated in the `.serverless` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the stack `npm run dp:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the stack and resources in the AWS Console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Invoke the `simulate` function multiple times with the following command to
    trigger autoscaling, `sls invoke -f simulate -r us-east-1 -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Take a look at the following `listener` function logs with the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Watch the Write capacity and Throttled write requests metrics on the DynamoDB
    Metrics tab in the AWS Console to see the autoscaling increment meet the demand,
    and then scale down at `night` and back up again in the `morning`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the *Implementing backpressure and rate limiting* recipe, we see how it is
    important for stream processors to minimize throttling to maximize throughput.
    In this chapter, we have discussed techniques to optimize throughput, such as
    batching, grouping and asynchronous non-blocking requests, which all increase
    the data store capacity that must be allocated. However, while we do need to ensure
    that we have sufficient capacity, we also want to minimize wasted capacity, and
    autoscaling helps us achieve that. Autoscaling can address demand that grows over
    time to an expected peak, predictable demand, such as known events, and unpredictable
    demand.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we use the `serverless-dynamodb-autoscaling-plugin` to define
    the `autoscaling` policies on a per table basis. For both the `read` and `write`
    capacity, we specify the `minimum` and `maximum` capacity and the desired `usage`
    percentage. This `usage` percentage defines the amount of headroom we would like
    to have so that we can increase capacity early enough to help ensure that additional
    capacity is allocated before we reach 100 percent utilization and begin to throttle.
    We can also schedule autoscaling `actions` at specific times. In this recipe,
    we scale down at `night` to minimize waste and then scale back up in the `morning`
    before typical demand arrives.
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing cache-control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Autonomous, cloud-native services maintain their own materialized views and
    store this replicated data in highly-available and extremely performant cloud-native
    databases. When combined with the performance of an API Gateway and FaaS, it is
    typically unnecessary to add a traditional caching mechanism to achieve the desired
    performance for a user-facing, **backend-for-frontend** (**BFF**) service. That
    being said, this doesn't mean we shouldn't take advantage of the CDN, such as
    CloudFront, that is already wrapping a service. The following recipe will therefore
    show you how to utilize cache-control headers and leverage a CDN to improve performance
    for end users, as well as reduce the load on a service.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create the project from the following template:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Navigate to the `cncb-cache-control` directory, `cd cncb-cache-control`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the file named `serverless.yml`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Review the file named `handler.js` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Install the dependencies with `npm install`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the tests with `npm test`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the contents generated in the `.serverless` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Deploy the stack, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Deploying a CloudFront distribution can often take upwards of 20 minutes.
  prefs: []
  type: TYPE_NORMAL
- en: Review the stack and resources in the AWS Console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Invoke the endpoint shown in the stack output with the following `curl` command
    multiple times to see the difference in performance for the cached results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Finally, remove the stack once you are finished with `npm run rm:lcl -- -s $MY_STAGE`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this related recipe we focus on the service side of the equation. Cloud-native
    databases, such as DynamoDB, respond in the low 10s of milliseconds, and the overall
    latency across AWS API Gateway and AWS Lambda for a BFF service should typically
    execute in the low 100s of milliseconds. So long as the database capacity is set
    appropriately and throttling is minimized, it would be hard to make a noticeable
    improvement in this performance from the end user's perspective. The only way
    to really improve on this is to not have to make a request at all.
  prefs: []
  type: TYPE_NORMAL
- en: This is a case where cloud-native can really be counter-intuitive. Traditionally,
    to improve performance, we would need to increase the amount of infrastructure
    and add an expensive caching layer between the code and the database. In other
    words, we would need to spend a lot more money to improve performance. However,
    in this recipe, we are leveraging an extremely low-cost edge cache to both improve
    performance and lower cost. By adding `Cache-Control` headers, such as `max-age`,
    to our responses, we can tell a browser not to repeat a request and also tell
    the CDN to reuse a response for other users. As a result, we reduce load on the
    API Gateway and the function and reduce the necessary capacity for the database,
    which reduces the cost for all of these services. It is also good practice to
    explicitly control which actions should store `no-cache`, for example the `PUT`,
    `POST`, and `DELETE` methods.
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging session consistency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The design of a cloud-native frontend application must account for the fact
    that the system should be eventually consistent. For example, in a traditional
    frontend application, it is not uncommon to save data and then immediately execute
    a query to retrieve that same data. However, in an eventually consistent system,
    it is very likely that the query would not find the data on the first try. Instead,
    cloud-native frontends leverage the fact that single page applications can—at
    minimum—cache data locally for the duration of the user's session. This approach
    is referred to as session consistency. The following recipe demonstrates how to
    use the popular Apollo Client ([https://www.apollographql.com/client](https://www.apollographql.com/client))
    with ReactJS to improve perceived performance and reduce load on the system by
    implementing **session consistency**.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create the `service` and `spa` projects from the following templates:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Deploy the `service` with the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Navigate to the `cncb-session-consistency-spa` directory, `cd ../cncb-session-consistency-spa`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Review the file named `src/index.js` with the following content and update
    the `uri` with the value output by the `service` stack, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Review the file named `src/App.js` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Install the dependencies with `npm install`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the app locally with `npm start`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Browse to `http://localhost:3000`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add and update several things to notice how the query results update.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, remove the service stack once you are finished, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we use a GraphQL BFF that is similar to the one we created in
    the *Implementing a GraphQL CRUD BFF* recipe. The focus here is on the frontend
    application, which we create with ReactJS and the Apollo Client, and specifically
    on how to cache our interactions with the service. First, we create the `ApolloClient`
    in the `src/index.js` file and initialize it with the endpoint for the service
    and, most importantly, the `InMemoryCache` object.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we implement the user interface in the `src/App.js` file. The screen displays
    a list of things that are returned from the `things` query. The Apollo Client
    will automatically cache the results of the query. The mutation that updates the
    individual objects will automatically update the cache and thus trigger the screen
    to re-render. Note that adding new data requires more effort. The `AddThing` function
    uses the mutation's `update` feature to keep the cache in sync and trigger a re-render.
    The `update` function receives a reference to the cache and the object that was
    returned from the mutation. We then call `readQuery` to read the query from the
    cache, append the new object to the query results, and finally update the cache
    by calling `writeQuery`.
  prefs: []
  type: TYPE_NORMAL
- en: The end result is a very low-latency user experience because we are optimizing
    the number of requests that are performed, the amount of data that is transferred,
    and the amount of memory that is used. Most importantly, for both new and updated
    data, we are not throwing away anything that was created on the client side and
    replacing it with the same, retrieved values—after all, it is just unnecessary
    work. We already have the data, so why should we throw it away and retrieve it
    again? We also cannot be certain that the data is consistent on the service side—unless
    we perform a consistent read that is slower, costs more and, as stated, is unnecessary.
    Session consistency becomes even more valuable for multi-regional deployments
    in the event of a regional failure. As we will discuss in [Chapter 10](7ddedd13-fcee-4091-8566-02c9814cb782.xhtml),
    *Deploying to Multiple Regions*, eventually consistent, cloud-native systems are
    very tolerant of regional failure because they are already tolerant of eventual
    consistency, which can be more protracted during a failover. Therefore, session
    consistency helps make a regional failure transparent to the end user. For any
    data that must remain available during a regional failure, we can take session
    consistency a step further and persist the user session in local storage.
  prefs: []
  type: TYPE_NORMAL
