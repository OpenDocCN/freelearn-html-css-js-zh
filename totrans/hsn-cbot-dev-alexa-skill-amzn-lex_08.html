<html><head></head><body>
        

                            
                    <h1 class="header-title">Improving the User Experience for Your Bots</h1>
                
            
            
                
<p>After having learned how to create Alexa Skills and Lex chatbots, we will now learn how we can improve the user experience. This is important, as adding images to your Lex chatbot or having a better voice model for Alexa can make a huge difference to whether the user enjoys interacting with your chatbot. Adding these features will also make your chatbots stand out from the basic, text-only chatbots.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>Adding response cards to Lex chatbots</li>
<li>Using phrase slots to create a more refined voice model for Alexa Skills</li>
<li>Using utterance monitoring with Amazon Lex to refine interaction models</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>In this chapter, we will be modifying our existing Lambda functions, so we'll be deploying them using the local development setup that we created <a href="ac448944-0559-408e-a9c4-972933a03611.xhtml" target="_blank">Chapter 2</a>, <em>Getting Started with AWS and Amazon CLI</em>.</p>
<p>All of the code and data required for this chapter can be found at <a href="http://bit.ly/chatbot-ch8">http://bit.ly/chatbot-ch8</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Response cards in Amazon Lex</h1>
                
            
            
                
<p>Cards give you a way to offer a richer in-conversation experience than just text messages by integrating buttons, images, and more. Cards can be used for many purposes, such as displaying product information, asking the message recipient to choose from a predetermined set of options, and showing search results. If you are integrating your cards into Slack or Facebook, then they will be shown on those platforms:</p>
<div><img src="img/01ef9d44-c468-47f8-9e93-a2f5a66064fe.png" style=""/></div>
<p>Example cards in Facebook</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a card</h1>
                
            
            
                
<p>To create a card, we need to change the format of the response that we are sending back to Lex. This means we need to change the functions in <kbd>LexResponses</kbd> by passing in a <kbd>responseCard</kbd> attribute. We can then add this <kbd>responseCard</kbd> to the <kbd>dialogAction</kbd> object. If we don't pass in a response card parameter, we still want the function to work so we default it to <kbd>null</kbd>:</p>
<pre class="SourceCode">elicitIntent({ message, sessionAttributes = {}, responseCard = null }) {<br/>  return {<br/>    sessionAttributes,<br/>    dialogAction: {<br/>      type: 'ElicitIntent',<br/>      message: { contentType: 'PlainText', content: message },<br/>      responseCard<br/>    },<br/>  };<br/>}</pre>
<p>This needs to be done for <kbd>elicitSlot</kbd>, <kbd>close</kbd>, <kbd>elicitIntent</kbd>, and <kbd>confirmIntent</kbd>, but not for <kbd>delegate</kbd> as that function doesn't send messages.</p>
<p>To add a response card, we need to make sure that the response is also in the correct format. To make this easier for ourselves, we can make a new function inside <kbd>LexResponses</kbd> called <kbd>createCardFormat</kbd>. This will take a single attribute of cards, which is an array of objects containing a <kbd>title</kbd>, <kbd>subtitle</kbd>, <kbd>imageUrl</kbd>, <kbd>linkUrl</kbd>, and <kbd>buttons</kbd>:</p>
<pre class="SourceCode">createCardFormat(cards) {<br/> return {<br/>   version: 1,<br/>   contentType: "application/vnd.amazonaws.card.generic",<br/>   genericAttachments: cards.map(({ title, subtitle, imageUrl, linkUrl, buttons }) =&gt; {<br/>     return {<br/>       title,<br/>       subtitle,<br/>       imageUrl,<br/>       attachmentLinkUrl: linkUrl,<br/>       buttons: buttons.map(({ text, value }) =&gt; {<br/>         return { text, value };<br/>       })<br/>     };<br/>   })<br/> }<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Using cards in chats</h1>
                
            
            
                
<p>With our modified <kbd>LexResponses</kbd> class, we can now start adding cards to our existing Lex Lambdas. One obvious place to use cards is in the shopping app to display the items we found based on the user's search. This means we are going to alter our <kbd>productFind</kbd> Lambda.</p>
<p>After we create the message telling the user how many of the items we have in stock (line 77 of <kbd>productFind</kbd>/<kbd>index.js</kbd>), we can create our first card.</p>
<p>This is going to be a single card with a title of the item, a subtitle of the stock, an image, and <kbd>Add to Cart</kbd> and <kbd>Not Now</kbd> buttons:</p>
<pre class="SourceCode">let responseCard = Lex.createCardFormat([{<br/>    title: `${size}, ${colour}${type === 'trousers' ? ', ' + length : ''}${type}`,<br/>    subTitle: `${item.stock} in stock`,<br/>    imageUrl: item.imageUrl,<br/>    buttons: [<br/>        { text: 'Add to Cart', value: 'Yes' },<br/>        { text: 'Not Now', value: 'No' }]<br/>    }<br/>]);</pre>
<p>As you can see, we are giving the buttons a different value to their text. This allows the response we receive to be different from the button that the user clicks.</p>
<p>You may have noticed that we have also added an image using <kbd>item.imageURL</kbd> but this never existed in our original data. We need to go through and add this to each of the items in the stock data. Luckily, we can use the same image for the different sizes of clothes. The stock data with images is available to download at <a href="http://bit.ly/chatbot-ch8">bit.ly/chatbot-ch8</a>.</p>
<p>When we deploy these changes, we can test it out in the Lex chat window. We can go through the normal <kbd>productFind</kbd> flow up to the point where we are shown the product selected. When we are told how many are in stock, we are also shown a card displaying the information:</p>
<div><img class="alignnone size-full wp-image-276 image-border" src="img/4393720f-7b1f-46aa-9e1a-1190ccbf44a8.png" style=""/></div>
<p>Chat card</p>
<p>If we have the Facebook or Slack integrations hooked up from the previous chapters, then our new cards should work on there too. Lex does a lot of clever logic to translate the card into the correct format needed for each platform and then uses them in the replies. It should be noted that Facebook crops the images to a 1:1.9 ratio, so selecting your images with that in mind is a good idea:</p>
<div><img src="img/ef8c6998-4329-493d-bf3f-f5428ee288be.png" style=""/></div>
<p>Facebook card</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Alexa search queries</h1>
                
            
            
                
<p>Alexa is great when you know the sort of responses that your users are going to be saying, but what if they ask for something you aren't expecting? Even using custom slot types can be limiting, which could result in a user's request being incorrectly handled. Luckily, Amazon has introduced the Search Query slot type.</p>
<p>This slot type for Alexa is designed to be able to take a much wider range of values so that you can handle more requests.</p>
<p>We're going to add a new intent onto our existing Weather Gods skill that uses a Search Query slot type to allow users to search for places in a city. We'll be using Google Maps API to power the backend.</p>
<p>Go to your Alexa developer's console and open the <kbd>WeatherGods</kbd> skill. Add a new intent called <kbd>searchIntent</kbd> and we can start by creating the different slots that we'll be using. Create two slots, one called <kbd>query</kbd> and the other called <kbd>city</kbd>. Our query slot can be given a slot type of AMAZON.SearchQuery and our city slot will be AMAZON.US_CITY:</p>
<div><img class="alignnone size-full wp-image-440 image-border" src="img/701adf1a-5e6a-467c-ac4c-de7438360c94.png" style=""/></div>
<p>Search slots</p>
<p>With the slots completed, we can start populating the utterances. Unfortunately, we can't have a search query slot in an utterance with another slot so we'll have to fill one slot at a time. We should allow a user to ask about a city or ask a query to start the intent:</p>
<div><img src="img/aba3813d-d8f6-45fc-97c8-1383604cd57a.png" style=""/></div>
<p>Utterances for search query</p>
<p>Now that we have our slots and utterances completed, we can modify our existing <kbd>weatherGods</kbd> Lambda to handle the new intent. Find the Lambda in your editor, open the <kbd>index.js</kbd> file, and go into the <kbd>handlers</kbd> object.</p>
<p>Inside the <kbd>handlers</kbd> object, we need to add a new handler called <kbd>searchIntent</kbd>. This handler will start by getting the city and query slot values and checking whether they exist. If they don't, we'll ask the user to tell us the missing information. We check <kbd>cityValue</kbd> first, so we can specify the city when we ask for the query:</p>
<pre class="SourceCode">const SearchHandler = {<br/>    canHandle(handlerInput) {<br/>        return handlerInput.requestEnvelope.request.type === 'IntentRequest' &amp;&amp;<br/>            handlerInput.requestEnvelope.request.intent.name === 'searchIntent';<br/>    },<br/>    async handle(handlerInput) {<br/>        const { slots } = handlerInput.requestEnvelope.request.intent;<br/>        let { city, query } = slots;<br/>        let cityValue = city.value;<br/>        let queryValue = query.value;<br/>        if (!cityValue) {<br/>            let slotToElicit = 'city';<br/>            let speechOutput = `What city are you looking in?`;<br/>            return handlerInput.responseBuilder<br/>                .speak(speechOutput)<br/>                .addElicitSlotDirective(slotToElicit)<br/>                .getResponse();<br/>        }<br/>        if (!queryValue) {<br/>            let slotToElicit = 'query';<br/>            let speechOutput = `What are you looking for in ${cityValue}`;<br/>            return handlerInput.responseBuilder<br/>                .speak(speechOutput)<br/>                .addElicitSlotDirective(slotToElicit)<br/>                .getResponse();<br/>        }<br/>    }<br/>}</pre>
<p>If we have both the city and query values, then we can use these to make a request to Google's Maps API.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Google Cloud Platform</h1>
                
            
            
                
<p>To use Google Maps API, we need to set up a Google Cloud Platform developers account. We can get one by going to <a href="https://cloud.google.com/">cloud.google.com/</a> and clicking Try free. You need to sign in to a Google account, confirm terms and conditions, and then enter payment information. Don't worry; you get $300 of free credit when you start, so you shouldn't get billed any time soon.</p>
<p>To start, we need to create a project by clicking Select a project in the upper-left corner and then choosing NEW PROJECT. Now we can name our new project <kbd>WeatherGodsAPI</kbd> and click CREATE.</p>
<p>With our project created, we need to check that it is selected in the upper-left corner of the page and then we can start to set up this project. In the search box, we can search for <kbd>Places API</kbd> and enable it for this project:</p>
<div><img class="alignnone size-full wp-image-439 image-border" src="img/f61fe323-d4bc-4822-83c7-d33f324e06ea.png" style=""/></div>
<p>Places API</p>
<p>Once the Places API has been enabled on this project, we need to generate an API key so we can access it from our Lambda. Click on Credentials and, from the Create Credentials drop-down menu, select API Key:</p>
<div><img class="alignnone size-full wp-image-437 image-border" src="img/374b1877-cdf4-402d-b6d9-f53da14d5abd.png" style=""/></div>
<p>Creating an API key</p>
<p>You need to copy this API key, as we'll be using it in our Lambda.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Continuing Lambda building</h1>
                
            
            
                
<p>We now have an API key that we can use to hit the Google Places API. Copy it and open your Lambda in the Lambda console. Scroll down to Environment variables, and create a new variable with a key of GOOGLE_API_KEY, and paste the API key as the value. Make sure not to remove the other API key, which is for <kbd>openWeatherMaps</kbd>:</p>
<div><img class="alignnone size-full wp-image-442 image-border" src="img/7374ea69-a4d1-45fe-a4a3-95b836298239.png" style=""/></div>
<p>Storing environment variables</p>
<p>With our Google API key stored as an environment variable, we can create our request that we'll be sending to Google. The format of the API request URL is this:</p>
<pre class="SourceCode">https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input={YOUR SEARCH}&amp;inputtype=textquery&amp;fields=formatted_address,name&amp;key={YOUR API KEY}</pre>
<p>To make it easier for ourselves, we can store most sections of this as constants, even the Google API key. In our <kbd>index.js</kbd> file, we can add these constants to the top of the file:</p>
<pre class="SourceCode">const GOOGLE_API_KEY = process.env.GOOGLE_API_KEY;<br/>const googleURL = 'https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input=';<br/>const queryString = '&amp;inputtype=textquery&amp;fields=formatted_address,name&amp;key=';</pre>
<p>With these constants accessible, the only part that we need to generate is our search. To do this, we can take our <kbd>queryValue</kbd> and our <kbd>cityValue</kbd> and turn it into a search phrase. This can be done by joining <kbd>{queryValue}</kbd> and  <kbd>{cityValue}</kbd> into a basic sentence. Because we are inserting this into a URL, we need to use <kbd>%20</kbd> instead of spaces and then we can build our request:</p>
<pre class="SourceCode">let completeURL = googleURL + [queryValue, 'in', cityValue].join('%20') + queryString + GOOGLE_API_KEY;</pre>
<p class="mce-root"/>
<p>With our request URL built, we can make our request to Google. To catch any errors, we can use our <kbd>to</kbd> method and then check that there are no errors and that there is a <kbd>response.data</kbd> field. If we didn't get what we expect, we can tell the user that we couldn't find that information:</p>
<pre class="SourceCode">if (err || !res || !res.data) {<br/>    let apology = `unfortunately I couldn't find that for you`;<br/>    return handlerInput.responseBuilder<br/>        .speak(apology)<br/>        .getResponse();<br/>}</pre>
<p>If our request did successfully return some data, then we can build a response for the user. First, we can tell them how many of their query there are in that city, and then we can list the names of each of those places:</p>
<pre class="SourceCode">let data = res.data;<br/>let info = `There's ${data.candidates.length} ${query.value}${data.candidates.length === 1 ? "" : 's'} in ${city.value}.<br/>${data.candidates.map(candidate =&gt; `the ${candidate.name}`)}`;<br/>return handlerInput.responseBuilder<br/>    .speak(info)<br/>    .withShouldEndSession(false)<br/>    .getResponse();</pre>
<p>We've now completed our updated Lambda and can deploy it to AWS using our build script from <a href="ac448944-0559-408e-a9c4-972933a03611.xhtml" target="_blank">Chapter 2</a>, <em>Getting Started with AWS and Amazon CLI</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Rebuilding the skill and testing</h1>
                
            
            
                
<p>Back in our skill in the Alexa Console, we can check our modified skill and make sure to save it and rebuild it. When it has finished building, we can click Test to try it out. You can test the old intents that we built in <a href="7567de44-8fd8-4f0a-b304-adfe6006e0a3.xhtml" target="_blank">Chapter 4</a>, <em>Connecting your Alexa Skill to External APIs</em>, and they should all work as before, but we really want to test our new intent.</p>
<p>You can now ask the weather gods what there is in Manchester and say that you're looking for a Catholic cathedral, and your skill will ask Google for Catholic cathedral in Manchester. It should tell you there is one called Salford Cathedral.</p>
<p class="mce-root"/>
<p>While this is good, we could have used a custom slot type and listed lots of things that a user might ask for. This is where search queries are really useful: they can handle far less common requests. We can ask for Saint Paul's primary school in Manchester, and we'll get a result. There is no way we could have created a custom slot that would be large enough to include every school name:</p>
<div><img class="alignnone size-full wp-image-282 image-border" src="img/bf5dc87b-fb31-43eb-89fe-968144e108be.png" style=""/></div>
<p>Testing search query</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Lex utterance monitoring</h1>
                
            
            
                
<p>When you create your intents and generate the list of utterances, you try your best to cover everything that a user might say. Unfortunately, people often come up with unique ways of saying something that you've not thought of. In this case, the user will get an "<em>I don't understand</em>" message from Lex. This obviously isn't great for providing a good user experience.</p>
<p>Luckily, Lex has built-in monitoring to allow you to see the utterances that the users have been saying. To get to these, we need to click on the Monitoring tab in Lex. Lex utterances are stored for a specific chatbot version, so we need to select a value from the dropdown next to our chatbot name.</p>
<p>You should now have a screen of graphs showing the Lex usage. This can be useful, but we're looking for the tables of utterances, found in the menu on the left:</p>
<div><img class="alignnone size-full wp-image-441 image-border" src="img/f910f7dd-78ba-4d85-bfe7-d3ae09682177.png" style=""/></div>
<p>Utterance monitoring</p>
<p>You should now see a table with a toggle in the center for Detected/Missed. The Detected utterances can be useful for seeing how most of your users are interacting with the chatbot. This can help you work out which areas you can develop to improve your chatbot for the largest portion of your audience.</p>
<p>If you don't see any utterances, then there are a few things to check. You need to make sure that in the general settings of the chatbot, COPPA is set to No. Next, you should try changing the version of the chatbot (next to the chatbot name) as utterances are saved to a specific version. Utterances show up in these tables if they are between 24 hours and 15 days old. If you still don't see any utterances, then you may just need to wait until you have utterances within this range.</p>
<p>Utterance monitoring is very useful when users have said something that Lex couldn't match to one of your example utterances. The Missed utterances give you a list of all of the utterances where this has happened. Although some of them will be gibberish or typos, some of them will be valid utterances that you might not have thought about:</p>
<div><img src="img/313bf545-433f-4bac-bb04-bbcf38ef9a05.png" style=""/></div>
<p>Missed utterances</p>
<p>Looking through the missed intents, you may realize that the user has typed an utterance that you hadn't thought of. You can easily add this to your intent by selecting the missed utterance and then selecting the intent from the dropdown that is just above the table. This saves manually copying and pasting the utterances into the intents.</p>
<p>Once you've moved all of the valid missed utterances into the correct intents, you need to make sure you build and deploy your updated chatbot.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we've looked into three ways to improve the user experience of both Alexa Skills and Lex chatbots.</p>
<p>We started by creating cards in Lex chats to increase the visual information provided to a user. These cards are a great way to make your Lex chatbots stand out from just text-based chatbots.</p>
<p>We then moved over to Alexa, where we learned about Search Query slots. This slot type allows users to enter a wider range of values to fill a slot than we could allow using custom slot types.</p>
<p class="mce-root"/>
<p>The final tool we learned to use to improve the user experience was <em>utterance monitoring</em>. Seeing what your users are really saying to your chatbot helps you increase the example utterances for each intent. This results in a chatbot that can successfully handle a wider range of user utterances.</p>
<p>All of these things will provide more information or reduce the chance that the chatbots can't handle a user's requests.</p>
<p>In the final chapter we'll discuss a few of the best ways to continue your learning. We'll also talk about the future of chatbots and how they will become part of our everyday lives.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Questions</h1>
                
            
            
                
<ol>
<li class="Compact">What are the benefits of using cards in Lex conversations?</li>
<li class="Compact">Do you need to use an image in a Lex card?</li>
<li class="Compact">Why would you choose to use search query slot type over a default or custom slot type?</li>
<li class="Compact">Can you populate a search query slot from the user utterance?</li>
<li class="Compact">How can you find out which Lex utterances weren't matched to an intent?</li>
</ol>


            

            
        
    </body></html>