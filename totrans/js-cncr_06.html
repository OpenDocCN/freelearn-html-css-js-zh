<html><head></head><body><div class="chapter" title="Chapter&#xA0;6.&#xA0;Practical Parallelism"><div class="titlepage"><div><div><h1 class="title"><a id="ch06"/>Chapter 6. Practical Parallelism</h1></div></div></div><p>In the previous chapter, we walked through the basic capabilities of web workers. We used web workers for true parallelism in the browser because they map to real threads, which, in turn, map to separate CPUs. This chapter builds on the last, providing some motivation for designing parallel code in the first place.</p><p>We'll start with a brief look at some ideas borrowed from functional programming, and how they're a nice fit for concurrency problems. Then, we'll tackle the problem of parallel validity by either making the decision to compute in parallel, or to simply run on one CPU. Then, we'll go in depth on some concurrency problems that would benefit from tasks running in parallel. We'll also address the problem of keeping the DOM responsive using workers.</p><div class="section" title="Functional programming"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec41"/>Functional programming</h1></div></div></div><p>Functions are obviously central to functional programming. But then, so is the data that flows through our application. In fact, the data and its movement in a program is probably just as important as the implementation of the functions themselves, at least as far application design is concerned.</p><p>There's a strong affinity between functional programming and concurrent programming. In this section, we'll look at why this is, and how we can apply functional programming techniques that can result in stronger concurrent code.</p><div class="section" title="Data in, data out"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec81"/>Data in, data out</h2></div></div></div><p>Functional programming is just as powerful as other programming paradigms. It's a different way of tackling the same problems. We use a different set of tools. For example, functions are the building blocks, and we'll use them to build our abstractions around data transformations. Imperative programming, on the other hand, use constructs, such as classes to build abstractions. The fundamental difference is that classes and objects like to encapsulate the state of something, while functions are data in, data out.</p><p>For example, let's say we had a user object with an <code class="literal">enabled</code> property. The idea is that the <code class="literal">enabled</code> property has a value at any given time, which can change at any given time. In other words, the user changes state. If we were to pass this object around to different areas of our application, then the state is also passed along with it. It's encapsulated as a property. Any one of these components that ends up with a reference to the user object can change it, and then pass it somewhere else. And so on, and so on. Here's an illustration that shows how a function can change the state of a user before passing it off to another component:</p><div class="mediaobject"><img src="graphics/B05133_06_01.jpg" alt="Data in, data out"/></div><p>It's not like this in functional programming. State isn't encapsulated inside objects and passed around from component to component; not because doing so is inherently bad, but because it's just a different way of addressing the problem. Where state encapsulation is a goal of object-oriented programming, getting from point A to point B and transforming data along the way is what functional programming is all about. There's no point C—once the function has done its job, it doesn't care about the state of the data. Here's a functional alternative to the preceding diagram:</p><div class="mediaobject"><img src="graphics/B05133_06_02.jpg" alt="Data in, data out"/></div><p>As we can see, the functional approach creates a new object with the updated property value. The function takes data as input and returns new data as output. In other words, it doesn't modify the input. It's a simple idea, but one with important consequences, such as immutability.</p></div><div class="section" title="Immutability"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec82"/>Immutability</h2></div></div></div><p>Immutable data is a key functional programming concept and one that fits nicely into concurrent programming. JavaScript is a multi-paradigm language. That is, it's functional, but it can also be imperative. Some functional programming languages strictly enforce immutability—you simply cannot change the state of an object. It's actually nice to have the flexibility of choosing when to keep data immutable and when it makes sense not to.</p><p>In the last diagram of the previous section, it was shown that the <code class="literal">enable()</code> function actually returns a brand new object with a property value that's different from the input value. This is done to avoid mutating the input value. Although, this may seem wasteful— constantly creating objects on the fly, but it really isn't. Consider all the bookkeeping code that we don't have to write when an object never changes. </p><p>For example, if the <code class="literal">enabled</code> property of a user is mutable, then this means any component that uses this object needs to constantly check the <code class="literal">enabled</code> property. Here's an idea of what this looks like:</p><div class="mediaobject"><img src="graphics/B05133_06_03.jpg" alt="Immutability"/></div><p>This check needs to happen whenever a component wants to show the user. We actually need to perform this same check using the functional approach. However, the only valid starting point with the functional approach is the create path. If something else in our system can change the <code class="literal">enabled</code> property, then we have both the create and modify paths to worry about. Eliminating the modify path also eliminates a host of other complexities. These are called side-effects.</p><p>Side-effects and concurrency don't get along well. In fact, it's the very idea that an object can change at all that makes concurrency hard. For example, let's say we have two threads that want to access our user object. They first need to acquire access to it, and it might already be locked. Here's a visualization of the idea:</p><div class="mediaobject"><img src="graphics/B05133_06_04.jpg" alt="Immutability"/></div><p>Here, we can see that the first thread locks the user object, preventing other threads from accessing it. The second thread needs to wait until it's unlocked before it can continue. This is called resource contention, and it diminishes the whole purpose of utilizing multiple CPUs. The threads aren't truly running in parallel if they're waiting for access to some kind of resource. Immutability side-steps the resource contention issue because there's no need to lock resources that don't change. Here's what the functional approach looks like using two threads:</p><div class="mediaobject"><img src="graphics/B05133_06_05.jpg" alt="Immutability"/></div><p>When objects don't change state, any number of threads can access them concurrently without any risk of corrupting the state of an object due to out-of-order operations and without wasting valuable CPU time waiting on resources.</p></div><div class="section" title="Referential transparency and time"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec83"/>Referential transparency and time</h2></div></div></div><p>Functions that take immutable data as input have something called referential transparency. This means that given the same object as input, no matter how many times it's called, the function will always return the same result. This is a useful property because it means that temporal factors are removed from the picture. That is, the only factor that can change the result of the function's output, is its input—not when it's called relative to other functions.</p><p>Put another way, referentially-transparent functions don't produce side-effects because they work with immutable data. And because of this, the lack of time being a factor for function output, they're well-suited in a concurrent context. Let's take a look at a function that isn't referentially-transparent:</p><div class="informalexample"><pre class="programlisting">// Returns the "name" of the given user object,
// but only if it's "enabled". This means that
// the function is referentially-transparent if
// the user passed to it never update the
// "enabled" property.
function getName(user) {
    if (user.enabled) {
        return user.name;
    }
}

// Toggles the value of the passed-in "user.enabled"
// property. Functions like these that change the
// state of objects make referential transparency
// difficult to achieve.
function updateUser(user) {
    user.enabled = !user.enabled;
}

// Our user object.
var user = {
    name: 'ES6',
    enabled: false
};

console.log('name when disabled', `"${getName(user)}"`);
// → name when disabled "undefined"

// Mutates the user state. Now passing this object
// to functions means that they're no longer
// referentially-transparent, because they could
// produce different output based on this update.
updateUser(user);

console.log('name when enabled', `"${getName(user)}"`);
// → name when enabled "ES6"</pre></div><p>The way the <code class="literal">getName()</code> function works depends on the state of the <code class="literal">user</code> object that's passed to it. If the user object is enabled, we return the name. Otherwise, we don't return anything. This means that the function isn't referentially transparent if it passes mutable data structures, which is the case in the preceding example. The <code class="literal">enabled</code> property changes, and so does the result of the function. Let's fix this situation and make it referentially-transparent with the following code:</p><div class="informalexample"><pre class="programlisting">// The referentially-transparent version of "updateUser()",
// which doesn't actually update anything. It creates a
// new object with all the same property values as the
// object that was passed in, except for the "enabled"
// property value we're changing.
function updateUserRT(user) {
    return Object.assign({}, user, {
        enabled: !user.enabled
    });
}

// This approach doesn't change anything about "user",
// meaning that any functions that use "user" as input,
// remain referentially-transparent.
var updatedUser = updateUserRT(user);

// We can call referentially-transparent functions at
// any time, and expect to get the same result. When
// there's no side-effects on our data, concurrency gets
// much easier.
setTimeout(() =&gt; {
    console.log('still enabled', `"${getName(user)}"`);
    // → still enabled "ES6"
}, 1000);

console.log('updated user', `"${getName(updatedUser)}"`);
// → updated user "undefined"</pre></div><p>As we can see, the <code class="literal">updateUserRT()</code> function doesn't actually change the data. It creates a copy that includes the updated property value. This means that we're safe to call <code class="literal">updateUser()</code> with the original user object as input at any time.</p><p>This functional programming technique helps us write concurrent code because the order in which we execute operations isn't a factor. Ordering asynchronous operations is hard. Immutable data leads to referential transparency, which leads to stronger concurrency semantics.</p></div></div></div>
<div class="section" title="Do we need to go parallel?"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec42"/>Do we need to go parallel?</h1></div></div></div><p>Parallelism can be hugely beneficial to us for the right sort of problems. Creating workers and synchronizing the communication between them to carry out tasks isn't free. For example, we could have this nice, well thought-out parallel code that utilizes four CPU cores. But it turns out that the time spent executing the boilerplate code to facilitate this parallelism exceeds the cost of simply processing the data in a single thread.</p><p>In this section, we'll address the issues associated with validating the data that we're processing and determining the hardware capabilities of the system. We'll always want to have a synchronous fallback option for the scenarios where parallel execution simply doesn't make sense. When we decide to go parallel, our next job is to figure out exactly how the work gets distributed to workers. All of these checks are performed at runtime.</p><div class="section" title="How big is the data?"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec84"/>How big is the data?</h2></div></div></div><p>Sometimes, going parallel just isn't worthwhile. The idea with parallelism is to compute more in less time. This gets our results faster, ultimately leading to a more responsive user experience. Having said that, there are scenarios where the data that we process simply does not justify the use of threads. Even some large collections of data may not stand to benefit from parallelization.</p><p>The two factors that determine how suitable a given operation is for parallel execution are the size of the data and the time complexity of the operation that we perform on each item in the collection. Put differently, if we have an array with thousands of objects in it, but the computation performed on each object is cheap, then there's no real motivation to go parallel. Likewise, we can have an array with very few objects, but the operation is expensive. Again, we may not benefit from subdividing the work into smaller tasks then distributing them to worker threads.</p><p>The static factor is the computation that we perform on individual items. At design time, we have to have a general idea of whether the code is expensive or cheap in terms of CPU cycles. This might require some static analysis, some quick benchmarks, or just a glance mixed with know-how and intuition. When we devise our criteria for determining whether a given operation is well-suited for parallel execution or not, we need to combine the computation itself with the size of the data.</p><p>Let's take a look at an example that uses different performance characteristics to determine whether or not a given function should be executed in parallel:</p><div class="informalexample"><pre class="programlisting">// This function determines whether or not an
// operation should be performed in parallel.
// It takes as arguments - the data to process,
// and a boolean flag, indicating that the task
// performed on each item in the data is expensive
// or not.
function isConcurrent(data, expensiveTask) {
    var size,
        isSet = data instanceof Set,
        isMap = data instanceof Map;

    // Figures out the size of the data, depending
    // on the type of "data".
    if (Array.isArray(data)) {
        size = data.length
    } else if (isSet || isMap) {
        size = data.size;
    } else {        
        size = Object.keys(data).length;
    }

    // Determine whether or not the size of the
    // data surpasses a the parallel processing
    // threshold. The threshold depends on the
    // "expensiveTask" value.
    return size &gt;= (expensiveTask ? 100 : 1000);
}

var data = new Array(138);

console.log('array with expensive task',
    isConcurrent(data, true));
// → array with expensive task true

console.log('array with inexpensive task',
    isConcurrent(data, false));
// → array with inexpensive task false

data = new Set(new Array(100000)
    .fill(null)
    .map((x, i) =&gt; i));

console.log('huge set with inexpensive task',
    isConcurrent(data, false));
// → huge set with inexpensive task true</pre></div><p>This function is handy because it's an easy preflight check for us to perform—either it's parallel or isn't. If it's not, then we can take the short path of simply computing the result and returning it to the caller. If it's parallel, then we'll move onto the next stage of figuring out how to subdivide the operation into smaller tasks.</p><p>The <code class="literal">isParallel()</code> function takes into consideration not only the size of the data, but also the cost of performing a computation on any one of data items. This lets us fine-tune the concurrency of our application. If there's too much overhead, we can increase the parallel processing threshold. If we've made some changes to our code that make a previously inexpensive function, expensive. We just need to change the <code class="literal">expensiveTask</code> flag in this scenario.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note15"/>Note</h3><p>What happens when our code runs in the main thread just as often as it runs in a worker thread? Does this mean that we have to write our task code twice: once for sequential code and again for our workers? We obviously want to avoid this, so we need to keep our task code modular. It needs to be usable both in the main thread and worker threads.</p></div></div></div><div class="section" title="Hardware concurrency capabilities"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec85"/>Hardware concurrency capabilities</h2></div></div></div><p>Another high-level check that we'll perform in our concurrent applications is the concurrency capabilities of the hardware that we're running on. This informs us how many web workers to create. For example, there's really nothing for us to gain by creating 32 web workers on a system where there are only four CPU cores. On this system, four web workers would be more appropriate. So, how do we get this number?</p><p>Let's create a generic function that figures this out for us:</p><div class="informalexample"><pre class="programlisting">// Returns the the ideal number of web workers
// to create.
function getConcurrency(defaultLevel = 4) {

    // If the "navigator.hardwareConcurrency" property
    // exists, we use that. Otherwise, we return the
    // "defaultLevel" value, which is a sane guess
    // at the actual hardware concurrency level.
    return Number.isInteger(navigator.hardwareConcurrency) ?
        navigator.hardwareConcurrency : defaultLevel;
}

console.log('concurrency level', getConcurrency());
// → concurrency level 8</pre></div><p>Since not all browsers implement the <code class="literal">navigator.hardwareConcurrency</code> property, we have to take this into consideration. If we don't know the exact hardware concurrency level, we have to make a guess. Here, we say that four is the most common CPU core count that we're likely to encounter. And since this is a default argument value, it is used for both: special-case handling by the caller and easy global changes.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note16"/>Note</h3><p>There are other techniques that attempt to measure the concurrency level by spawning worker threads and sampling the rate at which data is returned. This is an interesting technique, but not suitable for production applications because of the overhead and general uncertainty that's involved. In other words, using a static value that covers the majority of our user's systems is good enough.</p></div></div></div><div class="section" title="Creating tasks and assigning work"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec86"/>Creating tasks and assigning work</h2></div></div></div><p>Once we've decided that a given operation should be performed in parallel, and we know how many workers to create based on the concurrency level, it's time to create some tasks, and assign them to workers. Essentially, this means slicing up the input data into smaller chunks and passing these to the workers that apply our task to a subset of the data.</p><p>In the preceding chapter, we saw our first example of taking input data and diving it into tasks. Once the work was divided, we spawned a new worker and terminated it when the task was complete. Creating and terminating threads like this may not be the ideal approach depending on the type of application we're building. For example, if we occasionally run an expensive operation that would benefit from parallel processing, then it might make sense to spawn workers on demand. However, if we frequently process things in parallel, then it might make more sense to spawn threads when the application starts, and reuse them for processing many types of tasks. Here is an illustration of how many operations can share the same set of workers for different tasks:</p><div class="mediaobject"><img src="graphics/B05133_06_06.jpg" alt="Creating tasks and assigning work"/></div><p>This configuration allows operations to send messages to worker threads that are already running and get results back. There's no overhead associated with spawning new workers and cleaning them up when we're done with them. There is still the problem of reconciliation. We've split the operation into smaller tasks, each returning their own result. However, the operation is expected to return a single result. So when we split work into smaller tasks, we also need a way to join the task results back into a cohesive whole.</p><p>Let's write a generic function that handles the boilerplate aspects of splitting work into tasks and bringing the results together for reconciliation. While we're at it, let's also have this function determine whether the operation should be parallelized, or it should run synchronously in the main thread. First, let's look at the task itself that we'll want to run in parallel against each chunk of our data, as it's sliced up:</p><div class="informalexample"><pre class="programlisting">// Simple function that returns the sum
// of the provided arguments.
function sum(...numbers) {
    return numbers
        .reduce((result, item) =&gt; result + item);
}</pre></div><p>This task is kept separate from our worker code and other parts of our application that run in the main thread. The reason is that we'll want to use this function in both: the main thread and the worker threads. Now, we'll make a worker that can import this function, and use it with any data that gets passed to the worker in a message:</p><div class="informalexample"><pre class="programlisting">// Loads the generic task that's executed by
// this worker.
importScripts('task.js') if (chunk.length) {;

addEventListener('message', (e) =&gt; {

    // If we get a message for a "sum" task,
    // then we call our "sum()" task, and post
    // the result, along with the operation ID.
    if (e.data.task === 'sum') {
        postMessage({
            id: e.data.id,
            value: sum(...e.data.chunk)
        });
    }
});</pre></div><p>Earlier in the chapter, we implemented two utility functions. The <code class="literal">isConcurrent()</code> function determines the utility of running an operation as a set of smaller tasks in parallel. The other function, <code class="literal">getConcurrency()</code>, determines the level of concurrency that we should be running at. We'll use these two functions here, and we'll introduce two new utility functions. In fact, these are generators that will help us later on. Let's take a look at this:</p><div class="informalexample"><pre class="programlisting">// This generator creates a set of workers that match
// the concurrency level of the system. Then, as the
// caller iterates over the generator, the next worker
// is yielded, until the end is reached, then we start
// again from the beginning. It's like a round-robin
// for selecting workers to send messages to.
function* genWorkers() {
    var concurrency = getConcurrency();
    var workers = new Array(concurrency);
    var index = 0;

    // Creates the workers, storing each in the "workers"
    // array.
    for (let i = 0; i &lt; concurrency; i++) {
        workers[i] = new Worker('worker.js');

        // When we get a result back from a worker, we
        // place it in the appropriate response, based
        // on ID.
        workers[i].addEventListener('message', (e) =&gt; {
            var result = results[e.data.id];

            result.values.push(e.data.value);

            // If we've received the expected number of
            // responses, we can call the operation
            // callback, passing the responses as arguments.
            // We can also delete the response, since we're
            // done with it now.
            if (result.values.length === result.size) {
                result.done(...result.values);
                delete results[e.data.id];
            }
        });
    }

    // Continue yielding workers as long as they're
    // asked for.
    while (true) {
        yield workers[index] ?
            workers[index++] : workers[index = 0];
    }
}

// Creates the global "workers" generator.
var workers = genWorkers();

// This will generate unique IDs. We need them to
// map tasks executed by web workers to the larger
// operation that created them.
function* genID() {
    var id = 0;

    while (true) {
        yield id++;
    }
}

// Creates the global "id" generator.
var id = genID();</pre></div><p>With these two generators in place—<code class="literal">workers</code> and <code class="literal">id</code>—we're now ready to implement our <code class="literal">parallel()</code> higher-order function. The idea is to take a function as input along with some other parameters that allows us to tune the behavior of the parallelization and return a new function that we can simply invoke as normal throughout our app. Let's take a look at this function now:</p><div class="informalexample"><pre class="programlisting">// Builds a function that when called, runs the given task
// in workers by splitting up the data into chunks.
function parallel(expensive, taskName, taskFunc, doneFunc) {

    // The function that's returned takes the data to 
    // process as an argument, as well as the chunk size,
    // which has a default value.
    return function(data, size=250) {

        // If the data isn't large enough, and the
        // function isn't expensive, just run it in the
        // main thread.
        if (!isConcurrent(data, expensive)) {
            if (typeof taskFunc === 'function') {
                return taskFunc(data);
            } else {
                throw new Error('missing task function');
            }
        else {
            // A unique identifier for this call. Used
            // when reconciling the worker results.
            var operationID = id.next().value;

            // Used to track the position of the data
            // as we slice it into chunks.
            var index = 0;
            var chunk;

            // The global "results" object gets an
            // object with data about this operation.
            // The "size" property represents the
            // number of results we can expect back.
            // The "done" property is the callback
            // function that all the results are
            // passed to. And "values" holds the
            // results as they come in from the
            // workers.
            results[operationID] = {
                size: 0,
                done: doneFunc,
                values: []
            };
                
            while(true) {
                // Gets the next worker.
                let worker = workers.next().value;

                // Slice a chunk off the input data.
                chunk = data.slice(index, 
                    index + size);
                index += size;

                // If there's a chunk to process, we
                // can increment the size of the
                // expected results and post a
                // message to the worker. If there's
                // no chunk, we're done.
                if (chunk.length) {
                    results[operationID].size++;

                    worker.postMessage({
                        id: operationID,
                        task: taskName,
                        chunk: chunk
                    });
                } else {
                    break;
                }
            }
        }
    };
}

// Creates an array to process, filled with integers.
var array = new Array(2000)
    .fill(null)
    .map((v, i) =&gt; i);

// Creates a "sumConcurrent()" function that when called,
// will process the input data in workers.
var sumConcurrent = parallel(true, 'sum', sum,
    function(...results) {
        console.log('results', 
            results.reduce((r, v) =&gt; r + v));
    });

sumConcurrent(array);</pre></div><p>Now we can use the <code class="literal">parallel()</code> function to build concurrent functions that are called all throughout our application. For example, the <code class="literal">sumConcurrent()</code> function can be used whenever we have to compute the sum of large inputs. The only thing that's different is the input data.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note17"/>Note</h3><p>An obvious limitation here is that we only have a single callback function that we can specify when the parallelized function completes. This and, well, there's a lot of book-keeping to be done here—having IDs to reconcile tasks with their operations is kind of painful; this feels as if we're implementing promises. This is because that's essentially what we're doing here. The next chapter dives into more detail on combining promises with workers to avoid messy abstractions, such as the one that we just implemented.</p></div></div></div></div>
<div class="section" title="Candidate problems"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec43"/>Candidate problems</h1></div></div></div><p>In the previous section, you learned to create a generic function that will decide, on the fly, how to divide and conquer using workers, or whether it's more beneficial to simply call the function in the main thread. Now that we have a generic parallelization mechanism in place, what kind of problems can we solve? In this section, we'll address the most typical concurrency scenarios that will benefit from a solid concurrency architecture.</p><div class="section" title="Embarrassingly parallel"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec87"/>Embarrassingly parallel</h2></div></div></div><p>A problem is embarrassingly parallel  when it's obvious how the larger task can be broken down into smaller tasks. These smaller tasks don't depend on one another, which makes it even easier to start off a task that takes input and produces output without relying on the state of other workers. This again comes back to the functional programming, and the idea of referential transparency and no side-effects.</p><p>These are the types of problems we want to solve with concurrency—at least at first, during the difficult first implementation of our application. These are the low-hanging-fruit as far as concurrency problems go, and they should be easy for us to tackle without risking our ability to deliver functionality.</p><p>The last example that we implemented in the preceding section was an embarrassingly parallel problem, where we simply needed each subtask to add up the input values and return them. Global search, when the collection is large and unstructured, is another example of something that takes little effort on our part to divide into smaller tasks and reconcile them into a result. Searching large text inputs is a similar example. Mapping and reducing are yet another example of something that takes relatively little effort to parallelize.</p></div><div class="section" title="Searching collections"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec88"/>Searching collections</h2></div></div></div><p>Some collections are sorted. These collections can be searched efficiently because binary search algorithms are able to avoid large sections of data simply based on the premise that the data is sorted. However, there are other times when we work with collections that are largely unstructured or unsorted. In other cases, the time complexity is likely to be O(n) because every item in the collection needs to be checked as no assumptions can be made.</p><p>Large strings of text are a good example of a collection that's unstructured. If we were to search this text for a substring, there'd be no way to avoid searching a section of the text based on what we've found so far—the whole search space needs to be covered. We also need to count the number of substring occurrences in a large body of text. This is an embarrassingly parallel problem. Let's write some code that counts the number of substring occurrences in string input. We'll reuse the parallel utilities that we created in the previous section, in particular, the <code class="literal">parallel()</code> function. Here's the task that we'll use:</p><div class="informalexample"><pre class="programlisting">// Counts the number of times "item" appears in 
// "collection".
function count(collection, item) {
    var index = 0,
        occurrences = 0;

    while(true) {

        // Find the first index.
        index = collection.indexOf(item, index);

        // If we found something, increment the count, and
        // increment the starting index for the next
        // iteration. If nothing is found, break the loop.
        if (index &gt; -1) {
            occurrences += 1;
            index += 1;
        } else {
            break;
        }
    }

    // Returns the number of occurrences found.
    return occurrences;
}</pre></div><p>Now let's create a block of text for us to search and a parallel function to search it with:</p><div class="informalexample"><pre class="programlisting">// Unstructured text where we might need to find patterns.
var string = `
Lorem ipsum dolor sit amet, mei zril aperiam sanctus id, duo wisi
aeque molestiae ex. Utinam pertinacia ne nam, eu sed cibo senserit.
Te eius timeam docendi quo, vel aeque prompta philosophia id, nec
ut nibh accusamus vituperata. Id fuisset qualisque cotidieque sed,
eu verterem recusabo eam, te agam legimus interpretaris nam. Eos
graeco vivendo et, at vis simul primis.`;

// Constucts a new function - "stringCount()" using our 
// "parallel()" utility. Logs the number of string 
// occurrances by reducing the worker counts into a result.
var stringCount = parallel(true, 'count', count, 
    function(...results) {
        console.log('string',
            results.reduce((r, v) =&gt; r + v));
    });

// Kicks off the substring counting operation.
stringCount(string, 20, 'en');</pre></div><p>Here, we're splitting the input string into 20 character chunks, and searching for the input value <code class="literal">en</code>. There's 3 results found. Let's see if we can use this task, along with our parallel worker utilities and count the number of times an item appears in an array.</p><div class="informalexample"><pre class="programlisting">// Creates an array of 10,000 integers between 1 and 5.
var array = new Array(10000)
    .fill(null)
    .map(() =&gt; {
        return Math.floor(Math.random() * (5 - 1)) + 1;
    });

// Creates a parallel function that uess the "count" task,
// to count the number of occurances in the array.
var arrayCount = parallel(true, 'count', count, function(...results) {
    console.log('array', results.reduce((r, v) =&gt; r + v));
    });

// We're looking for the number 2 - there's probably lots of
//these.
arrayCount(array, 1000, 2);</pre></div><p>Since we're generating this 10,000 element array using random integers, the output will differ with each run. However, what's nice about our parallel worker utilities is that we were able to call <code class="literal">arrayCount()</code> with a substantially larger chunk size.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note18"/>Note</h3><p>You may have noticed that we're <span class="emphasis"><em>filtering</em></span> the input, not <span class="emphasis"><em>finding</em></span> a specific item within. This is an example of an embarrassingly parallel problem versus something that's a lot more difficult to solve using concurrency. Our worker nodes in the previous filtering code don't need to communicate with one another. If we have several worker nodes looking for a single item, we would inevitably face an early-termination scenario.</p><p>But to handle early termination, we need workers that'd somehow communicate with one another. This isn't necessarily a bad thing, just more shared state and more concurrency complexity. Its decisions like these that become relevant in concurrent programming—do we optimize elsewhere to avoid certain concurrency challenges?</p></div></div></div><div class="section" title="Mapping and reducing"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec89"/>Mapping and reducing</h2></div></div></div><p>The <code class="literal">Array</code> primitive in JavaScript already has a <code class="literal">map()</code> method. As we now know, there are two key factors that impact the scalability and performance of running a given operation against a given set of input data. It's the size of the data multiplied by the complexity of any task that's applied to each item within this data. These constraints can cause problems for our application if we're shoving tons of data into one array, then processing each array item with expensive code.</p><p>Let's see whether the approach that we've used for the past couple of code examples can help us map one array to another without having to worry about the native <code class="literal">Array.map()</code> method running on a single CPU—a potential bottleneck. We'll also address the issue of reducing large collections. It's a similar issue to mapping, only we use the <code class="literal">Array.reduce()</code> method. Here are the task functions:</p><div class="informalexample"><pre class="programlisting">// A basic mapping that "plucks" the given
// "prop" from each item in the array.
function pluck(array, prop) {
    return array.map((x) =&gt; x[prop]);
}

// Returns the result of reducing the sum
// of the array items.
function sum(array) {
    return array.reduce((r, v) =&gt; r + v);
}</pre></div><p>Now we have generic functions that can be invoked from anywhere—the main thread or from within a worker. We won't look at the worker code again because it uses the same pattern as the examples before this one. It figures out which task to invoke, and it handles formatting the response that's sent back to the main thread. Let's go ahead and use the <code class="literal">parallel()</code> utility to create a concurrent map and a concurrent reduce function:</p><div class="informalexample"><pre class="programlisting">// Creates an array of 75,000 objects.
var array = new Array(75000)
    .fill(null)
    .map((v, i) =&gt; {
        return {
            id: i,
            enabled: true
        };
    });

// Creates a concurrent version of the "sum()"
// function.
var sumConcurrent = parallel(true, 'sum', sum,
    function(...results) {
        console.log('total', sum(results));
    });

// Creates a concurrent version of the "pluck()"
// function. When the parallel jobs complete, we
// pass the results to "sumConcurrent()".
var pluckConcurrent = parallel(true, 'pluck', pluck, 
    function(...results) {
        sumConcurrent([].concat(...results));
    });

// Kicks off the concurrent pluck operation.
pluckConcurrent(array, 1000, 'id');</pre></div><p>Here, we create 75 tasks that are handed out to workers (75000/1000). Depending on our concurrency level, this means we'll have several property values being plucked from array items simultaneously. The reduce job works the same way; we sum the mapped collections concurrently. We still need to perform summation in the <code class="literal">sumConcurrent()</code> callback, but it's very few.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note19"/>Note</h3><p>We need to exercise caution when performing concurrent reduce jobs. Mapping is straightforward because we're creating what amounts to a clone of the original array in terms of size and ordering. It's just the values that differ. Reducing could be dependent on the result as it currently stands. Put differently, as each array item makes its way through the reduce function, the result, as it's being built-up, can change the final result outcome. Concurrency makes this difficult, but in this previous example, the problem was embarrassingly parallel—not all reduce jobs are.</p></div></div></div></div>
<div class="section" title="Keeping the DOM responsive"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec44"/>Keeping the DOM responsive</h1></div></div></div><p>So far in this chapter, the focus has been data-centric—taking input and transforming it by using web workers to divide and conquer. This isn't the only use of worker threads; we can also use them to keep the DOM responsive for our users.</p><p>In this section, we'll introduce a concept that's used in Linux kernel development to split events into phases for optimal performance. Then, we'll address the challenge of communicating between the DOM and our workers and vice-versa.</p><div class="section" title="Bottom halves"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec90"/>Bottom halves</h2></div></div></div><p>The Linux kernel has the concept of top-halves and bottom-halves. This idea is used by the hardware interrupt request machinery. The problem is that hardware interrupts happen all the time, and it's this kernel's job to make sure they're all captured and processed in a timely-manor. To do this effectively, the kernel splits the task of processing a hardware interrupt into two halves—the top and bottom half.</p><p>It's the job of the top-half to respond to external stimuli, such as a mouse click or a keystroke. However, there are severe limitations imposed on the top-half, and this is on purpose. The top-half portion of processing a hardware interrupt request can only schedule the real work—the invocation of all the other system components—for a later time. This later work is done in the bottom-half. The side-effect of this approach is that interrupts are handled swiftly at a low level, allowing more flexibility in terms of prioritizing events.</p><p>What does kernel development have to do with JavaScript and concurrency? Well, it turns out that we can borrow these ideas, and have our "bottom-half" work be delegated to a worker. Our event-handling code that responds to the DOM events wouldn't actually do anything except for pass the message to the worker. This ensures that the main thread is only doing what it absolutely needs to do without any extra processing. This means that if the web worker comes back with something to display, it can do so immediately. Remember, the main thread includes the rendering engine, which blocks our code from running and vice-versa. </p><p>Here's a visualization of top and bottom halves processing external stimuli:</p><div class="mediaobject"><img src="graphics/B05133_06_07.jpg" alt="Bottom halves"/></div><p>JavaScript is<a id="id277" class="indexterm"/> run-to-completion, which we're well aware at this<a id="id278" class="indexterm"/> point. This means that the less time spent in the top-half is time that's spent responding to users by updating the screen. At the same time, JavaScript is also run-to-completion within the web worker where our bottom-halves run. This means that the same limitation applies here; if our worker gets 100 messages sent to it in a short period of time, they're processed in <span class="strong"><strong>first</strong></span> <span class="strong"><strong>in</strong></span> <span class="strong"><strong>first</strong></span> <span class="strong"><strong>out</strong></span> (<span class="strong"><strong>FIFO)</strong></span>
<a id="id279" class="indexterm"/> order.</p><p>The difference is that since this code isn't running in the main thread, the UI components still respond when the user interacts with them. This is such a crucial factor in the perception of a quality product that it's worth the time investigating top-halves and bottom-halves. We now just need to figure out an implementation.</p></div><div class="section" title="Translating DOM manipulation"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec91"/>Translating DOM manipulation</h2></div></div></div><p>If we treat web workers as the <a id="id280" class="indexterm"/>bottom-halves of our application, then we need a way to manipulate the DOM while spending as little time as possible in the top-half. That is, it's up to the worker to figure out what needs to change in the DOM tree and then to notify the main thread. Then, all that the main thread has to do is translate between the posted message and the required DOM API call. There's no fiddling around with data between receiving these messages and handing control off to the DOM; milliseconds are precious in the main thread.</p><p>Let's see how easy this is to implement. We'll start with the worker implementation that sends the DOM manipulation messages to the main thread when it wants to update something in the UI:</p><div class="informalexample"><pre class="programlisting">// Keeps track of how many list items we've rendered
// so far.
var counter = 0;

// Sends a message to the main thread with all the
// necessary DOM manipulation data.
function appendChild(settings) {
    postMessage(settings);

    // We've rendered all our items, we're done.
    if (counter === 3) {
        return;
    }

    // Schedule the next "appendChild()" message.
    setTimeout(() =&gt; {
        appendChild({
            action: 'appendChild',
            node: 'ul',
            type: 'li',
            content: `Item ${++counter}`
        });
    }, 1000);
}

// Schedules the first "appendChild()" message. This
// includes the data necessary to simply render the
// DOM in the main thread.
setTimeout(() =&gt; {
    appendChild({
        action: 'appendChild',
        node: 'ul',
        type: 'li',
        content: `Item ${++counter}`
    });
}, 1000);</pre></div><p>This work posts three <a id="id281" class="indexterm"/>messages back to the main thread. They're timed using <code class="literal">setTimeout()</code>, so we can expect to see a new list item be rendered every second until all three are displayed. Now, let's take a look at how the main thread code makes sense of these messages:</p><div class="informalexample"><pre class="programlisting">// Starts the worker (the bottom-half).
var worker = new Worker('worker.js');

worker.addEventListener('message', (e) =&gt; {

    // If we get a message for the "appendChild" action,
    // then we create the new element and append it to the
    // appropriate parent - all this information is found
    // in the message data. This handler does absolutely
    // nothing but talk to the DOM.
    if (e.data.action === 'appendChild') {
        let child = document.createElement(e.data.type);
        child.textContent = e.data.content;

        document.querySelector(e.data.node)
            .appendChild(child);
            }
});</pre></div><p>As we can see, we're giving the top-half (the main thread) very little opportunity to bottleneck, causing the user interactions to freeze. It's quite simple—the only code that's executed here is the <a id="id282" class="indexterm"/>DOM manipulation code. This drastically increases the likelihood of completing quickly, allowing the screen to visibly  update for the user.</p><p>What about the other direction, getting external events into the system without interfering with the main thread? We'll look at this next.</p></div><div class="section" title="Translating DOM events"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec92"/>Translating DOM events</h2></div></div></div><p>As soon as a DOM event is <a id="id283" class="indexterm"/>triggered, we want to hand off control to our web worker. This way, the main thread can continue as if nothing else is happening—everyone is happy. There's a little more to it than this unfortunately. For instance, we can't simply listen to every single event on every single element, forwarding each to the worker that would defeat the purpose of not running code in the main thread if it's constantly responding to events.</p><p>Instead, we only want to listen to the DOM events that the worker cares about. This really is no different from how we would implement any other web application; our components listen to events they're interested in. To implement this with workers, we need a mechanism that tells the main thread to setup a DOM event listener on a particular element. Then, the worker can simply listen to incoming DOM events and react accordingly. Let's take a look at the worker implementation first:</p><div class="informalexample"><pre class="programlisting">// Tell the main thread that we want to be notified
// when the "input" event is triggered on "input
// elements.
postMessage({
    action: 'addEventListener',
    selector: 'input',
    event: 'input'
});

// Tell the main thread that we want to be notified
// when the "click" event is triggered on "button"
// elements.
postMessage({
    action: 'addEventListener',
    selector: 'button',
    event: 'click'
});

// A DOM event was triggered.
addEventListener('message', (e) =&gt; {
    var data = e.data;

    // Log the event differently, depending on where
    // the event was triggered from.
    if (data.selector === 'input') {
        console.log('worker', `typed "${data.value}"`);
    } else if (data.selector === 'button') {
        console.log('worker', 'clicked');
    }
});</pre></div><p>This worker asks the <a id="id284" class="indexterm"/>main thread, who has access to the DOM, to setup two event listeners. It then sets up its own event listener for the DOM events that eventually make their way to the worker. Let's take a look at the DOM code responsible for setting up handlers and forwarding events to the worker:</p><div class="informalexample"><pre class="programlisting">// Starts the worker...
var worker = new Worker('worker.js');

// When we get a message, that means the worker wants
// to listen to a DOM event, so we have to setup
// the proxying.
worker.addEventListener('message', (msg) =&gt; {
    var data = msg.data;

    if (data.action === 'addEventListener') {
        // Find the nodes the worker is looking for.
        var nodes = 
            document.querySelectorAll(data.selector);

        // Add a new event handler for the given "event" to
        // each node we just found. When that event is
        // triggered, we simply post a message back to 
        // the worker containing relevant event data.
        for (let node of nodes) {
            node.addEventListener(data.event, (e) =&gt; {
                worker.postMessage({
                    selector: data.selector,
                    value: e.target.value
                });
            });
        }
    }
});</pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note20"/>Note</h3><p>For the sake of brevity, there's only <a id="id285" class="indexterm"/>a couple of event properties sent back to the worker. We can't send the event object as it is due to serialization limitations in web worker messages. In practice, this same pattern can be used, but we'll probably add more event properties to this, such as <code class="literal">clientX </code>and <code class="literal">clientY</code>.</p></div></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec45"/>Summary</h1></div></div></div><p>The previous chapter introduced us to web workers, highlighting the powerful capabilities of these components. This chapter shifted gears and focused on the "why" aspect of parallelism. We kicked things off by looking at some aspects of functional programming, and how they lend themselves to concurrent programming in JavaScript.</p><p>We looked at the factors involved in determining the viability of executing a given operation concurrently across workers. Sometimes, there's a lot of overhead involved with taking apart a large task and distributing it to workers as smaller tasks. We implemented some generic utilities that can help us with the implementation of concurrent functions, encapsulating some of the associated concurrency boilerplate.</p><p>Not all problems are well-suited for a concurrent solution. The best approach is to work top-down, seeking out the embarrassingly-parallel problems as they're the low-hanging fruit. We then applied this principle to a number of map-reduce problems.</p><p>We wrapped up the chapter with a brief foray into the concept of top and bottom halves. This is a strategy that keeps the main thread clear of pending JavaScript code in an effort to keep the user interface responsive. While we were busy thinking about the types of concurrency problems that we're most likely to encounter, and the best way to solve them, our code complexity went up a notch. The next chapter is about bringing together our three concurrency principles together in a way that puts concurrency first without sacrificing code readability.</p></div></body></html>