- en: Chapter 3. Scaling Node
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like *concurrency* and *parallelism*, *scalability* and *performance* are not
    the same thing.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: '|   | *"The terms "performance" and "scalability" are commonly used interchangeably,
    but the two are distinct: performance measures the speed with which a single request
    can be executed, while scalability measures the ability of a request to maintain
    its performance under increasing load. For example, the performance of a request
    may be reported as generating a valid response within three seconds, but the scalability
    of the request measures the request''s ability to maintain that three-second response
    time as the user load increases."* |   |'
  id: totrans-2
  prefs: []
  type: TYPE_TB
- en: '|   | --*Pro Java EE 5, Steve Haines* |'
  id: totrans-3
  prefs: []
  type: TYPE_TB
- en: It is not unusual for a reviewer to assert that Node cannot scale across cores
    and is, therefore, unable to optimize performance on a given machine. This belief
    is based on two false impressions—that Node is "not good at" CPU-intensive tasks
    and that it *cannot scale* because its process can only leverage a single core.
    These claims are often stretched further into assertions about how Node's claim
    of being nonblocking is false, primarily by imagining locked threads and underutilized
    hardware.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 'Scalable applications remain responsive under increasing load. Scalable applications
    imply that more nodes can be added to, and removed from, a system depending on
    fluctuations in both client connections and resource needs (such as more memory
    or storage space). Node aims to make it easy to conceptualize, describe, and implement
    scalable networked applications. The primary focus is on creating a toolkit to
    build structures out of many nodes connected through evented network streams communicating
    through standard protocols. Distributed systems are concerned with failure more
    than with performance and the question that arises is: how can we swap, add, and
    remove nodes intelligently within a running system?'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Solving the **C10K problem**, which is *the problem of optimizing network sockets
    to handle a large number of clients at the same time* ([https://en.wikipedia.org/wiki/C10k_problem](https://en.wikipedia.org/wiki/C10k_problem))
    is a key design goal for many modern application tools and environments, including
    Node.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: We will look at two common scaling strategies—vertical and horizontal scaling.
    Vertical scaling (*scaling up*) involves increasing the ability of a single server
    to handle increasing load, usually by increasing the number of CPUs, memory, storage
    space, and so on, on a single box. Horizontally scaling systems (*scaling out*)
    respond to a load by adding or subtracting servers or other network resources.
    Deploying a scalable Node solution can be done by utilizing both of these techniques
    either individually or in tandem.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Scaling vertically across multiple cores
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed in [Chapter 1](ch01.html "Chapter 1. Appreciating Node"), *Appreciating
    Node*, `libuv` is used within the Node environment to manage multiple I/O threads.
    The OS itself also schedules threads, distributing the work required by various
    processes. Node provides a way for a developer to take advantage of this OS-level
    scheduling by spawning and forking many processes. In this section, we will learn
    how to distribute your program's tasks across independent processes generally
    and how to distribute a Node server's load across multiple cooperating server
    processes.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Modern software development is no longer the realm of monolithic programs. Modern
    applications are distributed and decoupled. We now build applications that connect
    users with resources distributed across the Internet. Many users are accessing
    shared resources simultaneously. A complex system is easier to understand if the
    whole is understood as a collection of interfaces to programs that solve one or
    a few clearly defined, related problems. In such a system, it is expected (and
    desirable) that processes should not sit idle.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: 'While a single Node process runs on a single core, any number of Node processes
    can be "spun up" through the use of the `child_process` module. Basic usage of
    this module is straightforward: we fetch a `ChildProcess` object and listen for
    data events. This example will call the Unix command `ls`, listing the current
    directory:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here, we use `spawn` on the `ls` process (list directory) and read from the
    resulting readable stream, receiving something like this:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Any number of child processes can be spawned in this way. It is important to
    note here that when a child process is spawned or otherwise created, the OS itself
    assigns the responsibility for that process to a given CPU. Node is not responsible
    for how an OS allocates resources. The upshot is that on a machine with eight
    cores, it is likely that spawning eight processes will result in each being allocated
    to independent processors. In other words, child processes are automatically spread
    by the OS across CPUs, putting the lie to claims that Node cannot take full advantage
    of multicore environments.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Each new Node process (child) is allocated 10 MB of memory and represents a
    new V8 instance that will take at least 30 milliseconds to start up. While it
    is unlikely that you will spawn many thousands of these processes, understanding
    how to query and set OS limits on user-created processes is beneficial. You can
    use `htop` or `top` to report the number of processes currently running, or you
    can use `ps aux | wc –l` from the command line. The Unix command `ulimit` ([http://ss64.com/bash/ulimit.html](http://ss64.com/bash/ulimit.html))
    provides important information on user limits on an OS. Passing `ulimit` the `–u`
    argument will show the maximum number of user processes that can be spawned. Changing
    the limit is accomplished by passing it as an argument—`ulimit –u 8192`.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: 'The `child_process` module represents a class exposing four main methods: `spawn`,
    `fork`, `exec`, and `execFile`. These methods return a `ChildProcess` object that
    extends `EventEmitter`, exposing an interface to child events, and a few functions
    helpful to manage child processes. We''ll take a look at its main methods and
    follow up with a discussion of the common `ChildProcess` interface.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: spawn(command, [arguments], [options])
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This powerful command allows a Node program to start and interact with processes
    spawned via system commands. In the preceding example, we used `spawn` to call
    a native OS process, `ls`, passing that command the arguments `''-lh''` and `''.''`.
    In this way, any process can be started just as one might start it via a command
    line. The method takes three arguments:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '**command**: This is a command to be executed by the OS shell'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**arguments**: These are optional command-line arguments sent as an array'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**options**: This is an optional map of settings for `spawn`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The options for `spawn` allow its behavior to be carefully customized:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '**cwd** (string): By default, this command will understand its current working
    directory to be the same as that of the Node process calling `spawn`. Change that
    setting using this directive.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**env** (object): This is used to pass environment variables to a child process,
    for instance, we spawn a child process with an environment object, such as:'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The child process environment will have access to the values specified in the
    preceding code.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**detached** (Boolean): When a parent process spawns a child process, both
    processes form a group, and the parent process is normally the leader of that
    group. To make a child process the group leader, use `detached`. This allows the
    child process to continue running even after the parent process exits. Because
    the parent process waits for the child process to exit by default, you can call
    `child.unref()` to tell the parent process''s event loop that it should not count
    the child reference and exit if no other work exists.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**uid** (number): Set the uid (user identity) for the child process in terms
    of standard system permissions, such as a uid that has privileges to execute on
    the child process.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gid** (number): Set the gid (group identity) for the child process in terms
    of standard system permissions, such as a gid that has execute privileges on the
    child process.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**stdio** (string or array): Child processes have file descriptors, the first
    three being `process.stdin`, `process.stdout`, and `process.stderr` standard I/O
    descriptors in that order (fds = 0,1,2). This directive allows those descriptors
    to be redefined, inherited, and so on.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Normally, to read the output of the following child process program, a parent
    process would listen on `child.stdout`:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If, instead, we wanted a child to inherit its parent''s `stdio` such that when
    the child writes to `process.stdout`, what is emitted is piped through to the
    parent process''s `process.stdout` stream, we would pass the relevant parent file
    descriptors to the child, overriding its own:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this case, the child's output will pipe straight through to the parent process's
    standard output channel. Also, see `fork`, in the upcoming paragraphs, for more
    information on this kind of pattern.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: 'Each of the three (or more) file descriptors can take one of six values:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '**''pipe''**: This creates a pipe between the child process and the parent
    process. As the first three child file descriptors are already exposed to the
    parent process (`child.stdin`, `child.stdout`, `child.stderr`), this is only necessary
    in more complex child implementations.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**''ipc''**: Create an IPC channel to pass messages between a child process
    and a parent process. A child process can have a maximum of one IPC file descriptor.
    Once this connection is established, the parent process can communicate with the
    child process via `child.send`. If the child sends JSON messages through this
    file descriptor, those emissions can be caught using `child.on("message")`. If
    you are running a Node program as a child, it is likely a better choice to use
    `ChildProcess.fork`, which has this messaging channel built in.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**''ignore''**: The file descriptors 0–2 will have `/dev/null` attached to
    them. For others, the referenced file descriptor will not be set on the child.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A stream object**: This allows the parent to share a stream with the child.
    For demonstration purposes, given a child that will write the same content to
    any provided `Writable` stream, we could do something like this:'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The child will now fetch its content and pipe it to whichever output stream
    it has been sent to:'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**An integer**: This is a file descriptor ID.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**null, undefined**: These are the default values. For file descriptors 0–2
    (`stdin`, `stdout`, `stderr`), a pipe is created. Others default to *ignore*.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition to passing `stdio` settings as an array, certain common groupings
    can be implemented by passing a shortcut string value:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '`''ignore'' = [''ignore'', ''ignore'', ''ignore'']`'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`''pipe'' = [''pipe'', ''pipe'', ''pipe'']`'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`''inherit'' = [process.stdin, process.stdout, process.stderr] or [0,1,2]`'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It should be noted that the ability to spawn any system process means that
    one can use Node to run other application environments installed on the OS. If
    we had the popular PHP language installed, the following would be possible:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Running a more interesting, larger program would be just as easy.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'Apart from the ease with which one can run Java, Ruby, or other programs through
    Node using this technique, asynchronously, we also have here a good answer to
    a persistent criticism of Node: JavaScript is not as fast as other languages for
    crunching numbers or doing other CPU-heavy tasks. This is true in the sense that
    Node is primarily optimized for I/O efficiency and helping with the management
    of high-concurrency applications, and JavaScript is an interpreted language without
    a strong focus on heavy computation.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: However, using `spawn`, one can very easily pass massive computations and long-running
    routines on analytic engines or calculation engines to separate processes in other
    environments. Node's simple event loop will notify the main application when those
    operations are done, seamlessly integrating the resultant data. Meantime, the
    main application is free to keep serving clients.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: fork(modulePath, [arguments], [options])
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Just like `spawn`, `fork` starts a child process but is designed to run Node
    programs with the added benefit of having a communication built in. Rather than
    passing a system command to `fork` as its first argument, we pass the path to
    a Node program. As with `spawn`, command-line options can be sent as a second
    argument, accessible via `process.argv` in the forked child process.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'An optional object can be passed as its third argument, with the following
    parameters:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '**cwd** (string): By default, this command will understand its current working
    directory to be the same as that of the Node process calling `fork`. Change that
    setting using this directive.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**env** (object): This is used to pass environment variables to a child process.
    See `spawn`.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encoding** (string): This sets the encoding of the communication channel.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**execPath** (string): This is the executable used to create the child process.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**silent** (Boolean): By default, a child process for which `fork` has been
    used will have `stdio` associated with that of the parent process (`child.stdout`
    is identical to `parent.stdout`, for example). Setting this option to ''true''
    disables this behavior.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An important difference between `fork` and `spawn` is that the former's child
    process *does not automatically exit* when it is finished. Such a child process
    must explicitly exit when it is done, which is easily accomplished via `process.exit()`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we will create a child process that emits an incrementing
    number every tenth of a second, which its parent process then dumps to the system
    console. First, let''s look at the child program:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Again, this will simply write a steadily increasing number. When forked a child
    process, a child process will inherit the `stdio` stream of its parent, so we
    only need to create the child process in order to get the output in a terminal
    running the parent process:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The silent option can be demonstrated here. The following code turns off any
    output to the terminal:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Creating multiple, parallel processes is easy. Let''s multiply the number of
    children created:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: It should be clear at this point that using `fork`, we are creating many parallel
    execution contexts spread across all machine cores.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: 'This is straightforward enough, but the built-in communication channel that
    `fork` provides makes communicating with child processes for which `fork` has
    been used even easier and cleaner. Consider the following two code snippets:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '**Parent**:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**Child**:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'By executing the parent script, we will see the following in our console:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: exec(command, [options], callback)
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In cases where the complete buffered output of a child process is sufficient,
    with no need to manage data through events, `child_process` offers the `exec`
    method. The method takes three arguments:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '**command**: This is a command-line string. Unlike `spawn` and `fork`, which
    pass arguments to a command via an array, this first argument accepts a full command
    string, such as `ps aux | grep node`.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '**options**: This is optional.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**cwd**: This is a string. Set the working directory for the command process.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**env**: This is an object. It''s a map of key-value pairs that will be exposed
    to the child process.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**encoding**: This is a string. It is the encoding of the child process''s
    data stream. The default value is `''utf8''`.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**timeout**: This is a number. It is the number of milliseconds that we need
    to wait for the process to complete, at which point the child process will be
    sent the **killSignal** signal.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**maxBuffer**: This is a number. It is the maximum number of bytes allowed
    on `stdout` or `stderr`. When this number is exceeded, the process is killed.
    The default value is 200 KB.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**killSignal**: This is a string. The child process receives this signal after
    a **timeout**. The default value is SIGTERM.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**callback**: This receives three arguments: an `Error` object, if any; `stdout`
    (a `Buffer` containing the result); and `stderr` (a `Buffer` containing error
    data, if any). If the process was killed, `Error.signal` will contain the kill
    signal.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: execFile
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use this method when you want the functionality of `exec` but are targeting
    a Node file. Importantly, `execFile` does not spawn a new subshell, which makes
    it slightly less expensive to run.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Communicating with your child process
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All instances of the `ChildProcess` object extend `EventEmitter`, exposing events
    which are useful to manage child data connections. Additionally, `ChildProcess`
    objects expose useful methods of interacting with child processes directly. Let's
    go through these now, beginning with attributes and methods.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: child.connected
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When a child process is disconnected from its parent process via `child.disconnect()`,
    this flag will be set to false.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: child.stdin
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a `Writable` stream corresponding to the child process's standard in.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: child.stdout
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a `Readable` stream corresponding to the child process's standard out.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: child.stderr
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a `Readable` stream corresponding to the child process's standard error.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: child.pid
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is an integer representing the **process ID** (**PID**) assigned to the
    child process.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: child.kill([signal])
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Try to terminate a child process, sending it an optional signal. If no signal
    is specified, the default is SIGTERM (for more about signals, see [http://unixhelp.ed.ac.uk/CGI/man-cgi?signal+7](http://unixhelp.ed.ac.uk/CGI/man-cgi?signal+7)).
    While the method name sounds terminal, it is not guaranteed to kill a process—it
    only sends a signal to a process. Dangerously, if `kill` is attempted on a process
    that has already exited, it is possible that another process, which has been newly
    assigned the PID of the dead process, will receive the signal, with indeterminable
    consequences. You should fire a `close` event, which will receive the signal used
    to close the process.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: child.disconnect()
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When `child.disconnect()` is triggered on a child process belonging to a process
    group that it does not lead, the IPC connection between the child and its parent
    will be severed, resulting in the child dying gracefully as it has no IPC channel
    to keep it alive. You can also call `process.disconnect()` from within the child
    process itself. Once a child process has disconnected, the `connected` flag on
    that child reference will be set to false.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: child.send(message, [sendHandle])
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As we saw in our discussion of `fork`, and when using the `ipc` option on `spawn`,
    child processes can be sent messages via this method. A TCP server or socket object
    can be passed along with the message as a second argument. In this way, a TCP
    server can spread requests across multiple child processes. For example, the following
    server distributes socket handling across a number of child processes equaling
    the total number of CPUs available. Each forked child is given a unique ID, which
    it reports when started. Whenever the TCP server receives a socket, that socket
    is passed as a handle to a random child process. That child process then sends
    a unique response, demonstrating that socket handling is being distributed. The
    following code snippets show this:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '**Parent**:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**Child**:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Start the parent server in a terminal window. In another window, run `telnet
    127.0.0.1 8080`. You should see something similar to the following, with a random
    child ID being displayed on each connection (assuming there exist multiple cores):'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The cluster module
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We saw how spreading work across multiple cores by spawning independent processes
    helps to vertically scale Node applications. The Node API has been further augmented
    with a `cluster` module that formalizes this pattern and extends it. Continuing
    with Node's core purpose of helping to make scalable network software easier to
    build, the particular goal of the `cluster` module is to facilitate the sharing
    of network sockets among many child workers.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the following code creates a cluster of worker processes, all
    sharing the same HTTP connection:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We'll dig into the details shortly. The important thing to note is how this
    program does different things depending on whether it is running as a master process
    or as a child process. On its first execution, it is the master, indicated by
    `cluster.isMaster`. When a master process calls `cluster.fork`, this same program
    is forked as a child process, in this case one child for each CPU. When this program
    is re-executed, in a forking context, `cluster.isWorker` will be `true`, and a
    new HTTP server *running on a shared port* is started. Multiple processes are
    sharing the load for a single server.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Connect to this server with a browser. You will see something like **Hello from
    8**, the integer corresponding to the unique `cluster.worker.id` ID of the worker
    that is assigned the responsibility of handling your request. Balancing across
    all workers is handled automatically such that refreshing your browser a few times
    will result in different worker IDs being displayed.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'The `cluster` API breaks down into two sections: the methods, attributes, and
    events available to the cluster master and those available to the child process.
    As workers in this context are defined using `fork`, the documentation for that
    method of `child_process` can be applied here as well.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: cluster.isMaster
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a Boolean value indicating whether the process is a master.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: cluster.isWorker
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a Boolean value indicating whether the process was forked from a master.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: cluster.worker
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a reference to the current worker object and is only available to a
    child process.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: cluster.workers
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a hash containing references to all active worker objects, keyed by
    the worker ID. Use this to loop through all worker objects. This only exists within
    the master process.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: cluster.setupMaster([settings])
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is a convenient way of passing a map of default arguments when a child
    is forked. If all child processes are going to use `fork` on the same file (as
    is often the case), you will save time by setting it here. The available defaults
    are as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '**exec**: This is a string. The file path to the process file defaults to `__filename`.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**args**: This is an array. Strings are sent as arguments to the child process.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**silent**: This is a Boolean value that determines whether or not to send
    output to the master''s `stdio`.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: cluster.fork([env])
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This creates a new worker process. Only the master process can call this method.
    To expose a map of key-value pairs to the child's process environment, send an
    object to `env`.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: cluster.disconnect([callback])
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is used to terminate all workers in a cluster. Once all the workers have
    died gracefully, the cluster process will itself terminate if it has no further
    events to wait on. To be notified when all child processes have expired, pass
    `callback`.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: cluster events
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This cluster object emits several events:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '**fork**: This is fired when the master tries to use `fork` on a new child.
    This is not the same as `online`. This receives a worker object.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**online**: This is fired when the master receives notification that a child
    is fully bound. This differs from the `fork` event. This receives a worker object.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**listening**: When the worker performs an action that requires a `listen()`
    call (such as starting an HTTP server), this event will be fired in the master.
    The event emits two arguments: a worker object and the address object containing
    the `address`, `port`, and `addressType` of the connection.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**disconnect**: This is called whenever a child disconnects, which can happen
    either through process exit events or after calling `child.kill()`. This will
    fire prior to the `exit` event—they are not the same. This receives a worker object.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**exit**: Whenever a child dies, this event is emitted. It receives three arguments:
    a worker object, the exit code number, and the signal string, such as SIGHUP,
    that caused the process to be killed.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**setup**: This is called after `cluster.setupMaster` has executed.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: worker.id
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is the unique ID assigned to a worker, which also represents the worker's
    key in the `cluster.workers` index.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: worker.process
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a `ChildProcess` object referencing a worker.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: worker.suicide
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: These workers, that have recently had `kill` or `disconnect` called on them,
    will have their `suicide` attribute set to true.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: worker.send(message, [sendHandle])
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: See `child_process.fork()`in the *Scaling vertically across multiple cores*
    section where I describe the `#fork` method.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: worker.kill([signal])
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This kills a worker. The master can check this worker's `suicide` property in
    order to determine whether the death was intentional or accidental. The default
    signal sent is SIGTERM.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: worker.disconnect()
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This instructs a worker to disconnect. Importantly, existing connections to
    the worker are not immediately terminated (as with `kill`) but are allowed to
    exit normally prior to the worker fully disconnecting. Because existing connections
    can stay in existence for a very long time, it is a good habit to regularly check
    whether the worker has actually disconnected, perhaps using timeouts.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'Workers also emit events:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '**message**: See `child_process.fork` in the *Scaling vertically across multiple
    cores* section where I describe the `#fork` method'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**online**: This is identical to `cluster.online` except that the check is
    against only the specified worker'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**listening**: This is identical to `cluster.listening` except that the check
    is against only the specified worker'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**disconnect**: This is identical to `cluster.disconnect` except that the check
    is against only the specified worker'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**exit**: See the `exit` event for `child_process`'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**setup**: This is called after `cluster.setupMaster` has executed'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have a good understanding of how to accomplish vertical scaling
    with Node, let's take a look at some ways to handle horizontal scaling
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Scaling horizontally across different machines
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Because Node is so efficient, most websites or applications can accommodate
    all of their scaling needs in the vertical dimension. As we learned from Eran
    Hammer's experiences at Walmart, Node can handle enormous levels of traffic using
    only a few CPUs and an unexceptional volume of memory.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, horizontal scaling can still be the right choice, even if only
    for architectural reasons. Having one point of failure, no matter how robust,
    still entails some risk. The *parking lot problem* is another consideration that
    Walmart likely faces—during shopping holidays, you will need many thousands of
    parking spots, but during the rest of the year this investment in empty space
    is hard to justify. In terms of servers, the ability to dynamically scale both
    up and down argues against building fixed vertical silos. Adding hardware to a
    running server is also a more complicated process than spinning up and seamlessly
    linking another virtual machine to your application.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we'll look at a few techniques for horizontal scaling, considering
    load balancing using native Node techniques, third-party solutions, and some ideas
    for cross-server communication.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Using Nginx
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Nginx** (pronounced **Engine X**) remains a popular choice for those whose
    architecture benefits from hiding Node servers behind a proxy. Nginx is a very
    popular high-performance web server that is often used as a proxy server. Given
    its design, Nginx is a popular choice with Node developers. According to [http://www.linuxjournal.com/magazine/nginx-high-performance-web-server-and-reverse-proxy](http://www.linuxjournal.com/magazine/nginx-high-performance-web-server-and-reverse-proxy):'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '*"Nginx is able to serve more requests per second with less resources because
    of its architecture. It consists of a master process, which delegates work to
    one or more worker processes. Each worker handles multiple requests in an event-driven
    or asynchronous manner using special functionality from the Linux kernel (epoll/select/poll).
    This allows Nginx to handle a large number of concurrent requests quickly with
    very little overhead."*'
  id: totrans-179
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Its similarity in design to Node is striking: event delegation across processes
    and an evented, asynchronous environment coordinated by the OS delivering high
    concurrency.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: A **proxy** is someone or something acting on behalf of another.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'A *forward* proxy normally works on behalf of clients in a private network,
    brokering requests to an outside network, such as retrieving data from the Internet.
    Early *web providers*, such as AOL, functioned in this way:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '![Using Nginx](img/1403OS_03_01.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
- en: Network administrators often use forward proxies when restrictions on access
    to the outside world (that is, the Internet) are needed. If malware is downloaded
    from a bad website via an e-mail attachment, the administrator might block access
    to that location. Restrictions on access to social networking sites might be imposed
    on an office network. Some countries even restrict access to the general Internet
    in this way.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: 'A *reverse* proxy, not surprisingly, works in the opposite manner, accepting
    requests from a public network and servicing those requests within a private network
    that the client might not have much visibility into. Direct access to servers
    by clients is first delegated to a reverse proxy. This can be shown with the help
    of the following diagram:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '![Using Nginx](img/1403OS_03_02.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
- en: This is the type of proxy we can use to balance requests from clients across
    many Node servers. Client X does not communicate with any given server directly.
    A broker Y is the first point of contact that is able to direct X to a server
    under less load, is located closer to X, or is, in some other way, the best server
    for X to access at the time.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at how Nginx can be used as a proxy, in particular, as a load
    balancer, by deploying such a system on the cloud hosting service **Digital Cloud**.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Deploying an Nginx load balancer on DigitalOcean
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: DigitalOcean is a cloud hosting provider that is inexpensive and easy to set
    up. We will build an Nginx load balancer on this service.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: To sign up, visit [http://www.digitalocean.com](http://www.digitalocean.com).
    The basic package (at the time of writing this) incurs a $5 fee, but promotion
    codes are regularly made available—a simple web search should result in a usable
    code. Create and verify an account to get started.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: DigitalOcean packages are described as droplets with certain characteristics—the
    amount of storage space, transfer limits, and so on. A basic package is sufficient
    for our needs. Also, you will indicate a hosting region and the OS to install
    in your droplet (in this example, we'll use the latest version of Ubuntu). Create
    a droplet and check your e-mail for login instructions. You're done!
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: You will receive full login information for your instance. You can now open
    a terminal and SSH into your box using those login credentials.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: On your initial login, you might want to update your packages. For Ubuntu, you
    would run `apt-get update` and `apt-get upgrade`. Other package managers have
    similar commands (such as `yum update` for RHEL/CentOS).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Before we begin to install, let's change our root password and create a nonroot
    user (it is unsafe to expose the root to external logins and software installs).
    To change your root password, type `passwd` and follow the instructions in your
    terminal. To create a new user, enter `adduser <new user name>` (for example,
    `adduser john`). Follow the instructions mentioned in the upcoming paragraphs.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: 'One more step: we want to give some administrative privileges to our new user
    as we''ll install software as that user. In Unix parlance, you want to give `sudo`
    access to this new user. Instructions on how to do this are easy to find for whichever
    OS you''ve chosen. Essentially, you will want to change the `/etc/sudoers` file.
    Remember to do this using a command such as `visudo`—do not edit the `sudoers`
    file by hand! You may also want to restrict root logins and do other SSH access
    management at this point.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After successfully executing `sudo -i` in your terminal, you will be able to
    enter commands without prefixing each one with `sudo`. The following examples
    assume that you've done this.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll now create an Nginx load balancer frontend for two Node servers. This
    means that we will create three droplets—one for the balancer and two added droplets
    as Node servers. In the end, we will end up with an architecture that looks something
    like this:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '![Deploying an Nginx load balancer on DigitalOcean](img/1403OS_03_05.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
- en: Installing and configuring Nginx
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s install Nginx and Node/npm. If you''re still logged in as root, log
    out and reauthenticate as the new user you''ve just created. To install Nginx
    (on Ubuntu), simply type:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Most other Unix package managers will have Nginx installers. To start Nginx,
    use:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Note
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Full documentation for Nginx can be found at [http://wiki.nginx.org/Configuration](http://wiki.nginx.org/Configuration).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: 'You should now be able to point your browser to the IP you were assigned (check
    your inbox if you''ve forgotten) and see something like this:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '![Installing and configuring Nginx](img/1403OS_03_04.jpg)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
- en: Now, let's set up the two servers that Nginx will balance.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: 'Create an additional two droplets in DigitalOcean. You must *not* install Nginx
    on these servers. Configure permissions on these servers as we did earlier. Now,
    install Node in both droplets. An easy way to manage your Node installation is
    using Tim Caswell''s **Node Version Manager** (**NVM**). NVM is essentially a
    bash script that provides a set of command-line tools facilitating Node version
    management and allowing you to easily switch between versions. To install it,
    use the following command:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, install your preferred Node version (here we ask for the latest release
    of the 0.12 version):'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'You might want to add a command to your `.bashrc` or `.profile` file to ensure
    that a certain node version is used each time you start a shell:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'To test our system, we need to set up Node servers on both of these machines.
    Create the following program file on each server, changing ''**'' to something
    unique on each (such as *one* and *two*):'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Start this file on each server (`node serverfile.js`). Each server will now
    answer on port `8080`.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: You should now be able to reach this server by pointing a browser to each droplet's
    IP:8080\. Once you have two servers responding with distinct messages, we can
    set up the Nginx load balancer.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: 'Load balancing across servers is straightforward with Nginx. You need to simply
    indicate in the Nginx configuration script which **upstream** servers should be
    balanced. The two Node servers we''ve just created are the upstream servers. The
    following diagram describes how Nginx evenly distributes requests across upstream
    servers:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '![Installing and configuring Nginx](img/1403OS_03_03.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
- en: Each request will be handled first by Nginx, which will check its *upstream*
    configuration and, based on how it is configured, will (reverse) proxy requests
    to upstream servers that will actually handle the request.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: You will find the default Nginx server configuration file on your balancer droplet
    at `/etc/nginx/sites-available/default`. In production, you'll most likely want
    to create a custom directory and configuration file, but for our purposes, we'll
    simply modify the default configuration file (you might want to make a backup
    before you start modifying it).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: 'At the top of the Nginx configuration file, we want to define *upstream* servers
    that will be candidates for redirection. This is simply a map with the arbitrary
    key `lb-servers` to be referenced in the server definition that follows:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now that we''ve established the candidate map, we need to configure Nginx such
    that it forwards requests in a balanced way to each of the members of `lb-servers`:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The key line is this one:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Note how the name `lb-servers` matches the name of our upstream definition.
    This should make what is happening clear: an Nginx server listening on port `80`
    will pass the request on to a server definition contained in `lb-servers`. If
    the upstream definition has only one server in it, that server gets all the traffic.
    If several servers are defined, Nginx attempts to distribute traffic evenly among
    them.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is also possible to balance load across several *local servers* using the
    same technique. One would simply run different Node servers on different ports,
    such as `server 127.0.0.1:8001; server 127.0.0.1:8002; ...`.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: 'Go ahead and change the Nginx configuration (consult the `nginx.config` file
    in the code bundle for this book if you get stuck). Once you''ve changed it, restart
    Nginx with the following command:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Or, you can use this command:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Assuming that the other two droplets running Node servers are active, you should
    now be able to point your browser to your Nginx-enabled droplet and see messages
    from those servers!
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Because we will likely want more precise control over how traffic is distributed
    across our upstream servers, there are further directives that can be applied
    to upstream server definitions.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: 'Nginx balances load using a weighted round-robin algorithm. In order to control
    the relative weighting of traffic distribution, we use the **weight** directive:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This definition tells Nginx to distribute twice as much load to the second server
    as to the first. Servers with more memory or CPUs might be favored, for example.
    Another way to use this system is to create an A/B testing scenario, where one
    server containing a proposed new design receives a small fraction of the total
    traffic such that metrics on the testing server (sales, downloads, engagement
    length, and so on) can be compared against the wider average.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'Three other useful directives are available, which work together to manage
    connection failures:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '**max_fails**: This is the number of times communication with a server fails
    prior to marking that server as inoperative. The period of time within which these
    failures must occur is defined by **fail_timeout**.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**fail_timeout**: This is the time slice during which **max_fails** must occur,
    indicating that a server is inoperative. This number also indicates the amount
    of time after a server is marked inoperative that Nginx will again attempt to
    reach the flagged server. Here''s an example:'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '**backup**: A server marked with this directive will only be called when and
    if *all* of the other listed servers are unavailable.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Additionally, there are some directives for the upstream definition that add
    some control over how clients are directed to upstream servers:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '**least_conn**: This passes a request to the server with the least connections.
    This provides a slightly smarter balancing, taking into consideration server load
    as well as weighting.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ip_hash**: The idea here is to create a hash of each connecting IP and to
    ensure that requests from a given client are always passed to the same server.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another commonly used tool for balancing Node servers is the dedicated load
    balancer **HAProxy**, which is available at [http://haproxy.1wt.eu/](http://haproxy.1wt.eu/).
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Load balancing with Node
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For many years, it was recommended that a web server (such as Nginx) be placed
    in front of Node servers. The claim was that mature web servers handle static
    file transfers more efficiently. While this may have been true for earlier Node
    versions (which did suffer from the bugs that new technologies face), it is no
    longer necessarily true in terms of pure speed. Some recent benchmarks bear this
    out: [http://centminmod.com/siegebenchmarks/2013/020313/index.html](http://centminmod.com/siegebenchmarks/2013/020313/index.html).'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: File serving speeds are, of course, not the only reason you might use a proxy
    such as Nginx. It is often true that network topology characteristics make a reverse
    proxy the better choice, especially when the centralization of common services,
    such as compression, makes sense. The point is simply that Node should not be
    excluded solely due to outdated biases about its ability to efficiently serve
    files. Let's look at one example of a purely Node-based proxying and balancing
    solution, `node-http-proxy`.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: Using node-http-proxy
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Node is designed to facilitate the creation of network software, so it comes
    as no surprise that several proxying modules have been developed. The team at
    NodeJitsu has released the proxy they use in production—`http-proxy`. Let's take
    a look at how we would use it to route requests to different Node servers.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike with Nginx, the entirety of our routing stack will exist in Node. Listening
    on port `80`, one Node server will run our proxy. Three scenarios will be covered:
    using a single box to run multiple Node servers on separate ports on the same
    machine; using one box as a pure router proxying to external URLs; and creating
    a basic round-robin load balancer.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: 'As an initial example, let''s look at how to use this module to redirect requests:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: By starting this server on port `80` of our local machine, we are able to redirect
    the user to another URL.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: 'To run several distinct Node servers, each responding to a different URL, on
    a single machine, you simply have to define a router:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'For each of your distinct websites, you can now point your DNS name servers
    (via ANAME or CNAME) to the same endpoint (wherever this Node program is running),
    and they will resolve to different Node servers. This is handy when you want to
    run several websites but don''t want to create a new physical server for each
    one. Another strategy is to handle different paths within the same website on
    different Node servers:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This allows specialized functionality in your application to be handled by uniquely
    configured servers.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: 'Setting up a load balancer is also straightforward. As with Nginx''s `upstream`
    directive, we simply list the servers to be balanced and cycle through them:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Unlike with Nginx, we are responsible for doing the actual balancing. In this
    example, we treat servers equally, cycling through them in order. After the selected
    server is proxied, it is returned to the *rear* of the list.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: It should be clear that this example could be easily extended to accommodate
    other directives, such as Nginx's `weight`.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another good option for proxying Node is James Halliday's `bouncy` module available
    at [https://github.com/substack/bouncy](https://github.com/substack/bouncy).
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: Using message queues
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the best ways to ensure that distributed servers maintain a dependable
    communication channel is to bundle the complexity of remote procedure calls into
    a messaging queue. When one server wishes to send a message to another server,
    the message can simply be placed on this queue—like a "to-do" list for your application—with
    the queue service doing the work of ensuring that messages get delivered as well
    as delivering any important replies back to the original sender.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few enterprise-grade message queues available, many of which deploy
    the **Advanced Message Queuing Protocol** (**AMQP**). We will focus on a very
    stable and well-known implementation: RabbitMQ.'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To install RabbitMQ in your environment, follow the instructions found at [http://www.rabbitmq.com/download.html](http://www.rabbitmq.com/download.html).
    Note that you will also need to install Erlang (the instructions for which can
    be found at the same link).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: 'After installing it, you can start the RabbitMQ server with this command:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'To interact with RabbitMQ using Node, we will use Theo Schlossnagle''s `node-amqp`
    module:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'To use a message queue, one must first create a consumer bound to RabbitMQ
    that will listen for messages published to the queue. The most basic consumer
    will listen for all messages:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We are now listening for messages from the RabbitMQ server bound to port `5672`.
    It should be obvious that the *localhost* can be replaced with a proper server
    address and bound to any number of distributed servers.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: Once this consumer establishes a connection, it will establish the name of the
    queue it will listen to and should `bind` to an **exchange**. In this example,
    we create a topic `exchange` (the default), giving it a unique name. We also indicate
    that we would like to listen for *all* messages via `#`. All that is left to do
    is subscribe to the queue, receiving a message object. We will learn more about
    the message object as we progress. For now, note the important `data` property
    containing the sent messages.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have established a consumer, let''s publish a message to the exchange.
    If all goes well, we will see the sent message appear in our console:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: We have already learned enough to implement useful scaling tools. If we have
    a number of distributed Node processes, even on different physical servers, each
    can reliably send messages to the others via RabbitMQ. Each process needs to simply
    implement an exchange queue subscriber to receive messages and an exchange publisher
    when messages need to be sent.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: 'Three types of exchanges exist: **direct**, **fanout**, and **topic**. The
    differences appear in the way each type of exchange processes **routing keys**—the
    first argument sent to `exchange.publish`.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 'A direct exchange matches routing keys directly. Here''s an example of a queue
    binding:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The preceding queue binding will match *only* messages sent to `room-1`. Because
    no parsing is necessary, direct exchanges are able to process more messages than
    topic exchanges in a set period of time.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'A fanout exchange is indiscriminate: it routes messages to all of the queues
    bound to it, ignoring routing keys. This type of exchange is used for wide broadcasts.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: A topic exchange matches routing keys based on the wildcards `#` and `*`. Unlike
    other types, routing keys for topic exchanges *must* be composed of words separated
    by dots—*animals.dogs.poodle*, for example. A `#` matches *zero or more* words—it
    will match every message (as we saw in the previous example) just like a fanout
    exchange. The other wildcard is `*`, and this matches *exactly one* word.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: Direct and fanout exchanges can be implemented using nearly the same code as
    the given topic exchange example, requiring only that the exchange type be changed,
    and that bind operations be aware of how they will be associated with routing
    keys (fanout subscribers receive all messages, regardless of the key; for a direct
    exchange, the routing key must match directly).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: 'This last example should drive home how topic exchanges work. We will create
    three queues with different matching rules, filtering the messages each queue
    receives from the exchange:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The `node-amqp` module contains further methods to control connections, queues,
    and exchanges, in particular methods of removing queues from exchanges and subscribers
    from queues. Generally, changing the makeup of a running queue on the fly can
    lead to unexpected errors, so use these with caution.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To learn more about the AMQP (and the options available when setting up with
    `node-amqp`), visit [http://www.rabbitmq.com/tutorials/amqp-concepts.html](http://www.rabbitmq.com/tutorials/amqp-concepts.html).
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: Using Node's UDP Module
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**User Datagram Protocol** (**UDP**) is a lightweight core Internet messaging
    protocol, enabling servers to pass around concise *datagrams*. UDP was designed
    with a minimum of protocol overhead, forgoing delivery, ordering, and duplication
    prevention mechanisms in favor of ensuring high performance. UDP is a good choice
    when perfect reliability is not required and high-speed transmission is, as found
    in networked video games and videoconferencing applications. Logging is another
    popular use for UDP.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: This is not to say that UDP is *normally* unreliable. In most applications,
    it delivers messages with high probability. It is simply not suitable when *perfect*
    reliability is needed, such as in a banking application. It is an excellent candidate
    for monitoring and logging applications and for noncritical messaging services.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a UDP server with Node is straightforward:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The bind command takes three arguments:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '**port**: This is the integer port number.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**address**: This is an optional address. If this is not specified, the OS
    will try to listen on all addresses (which is often what you want). You might
    also try using `0.0.0.0` explicitly.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**callback**: This is an optional callback, which receives no arguments.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This socket will now emit a **message** event whenever it receives a datagram
    via port `41234`. The event callback receives the message itself as the first
    parameter and a map of packet information as the second:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '**address**: This is the originating IP'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**family**: This is one of IPv4 or IPv6'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**port**: This is the originating port'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**size**: This is the size of the message in bytes'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This map is similar to the map returned when calling `socket.address()`.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the message and listening events, a UDP socket also emits a `close`
    event and an `error` event, with the latter receiving an `Error` object whenever
    an error occurs. To close a UDP socket (and trigger the `close` event), use `server.close()`.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: 'Sending a message is even easier:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The send method takes the form `client.send(buffer, offset, length, port, host,
    callback)`:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: '**buffer**: This is a buffer containing the datagram to be sent'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**offset**: This is an integer indicating the position in the **buffer** where
    the datagram begins'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**length**: This is the number of bytes in a datagram. In combination with
    **offset**, this value identifies the full datagram within the **buffer**'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**port**: This is an integer identifying the destination port'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**address**: This is a string indicating the destination IP for the datagram'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**callback**: This is an optional callback function called after the send has
    taken place.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The size of a datagram cannot exceed 65,507 bytes, which is equal to *2^16-1*
    (65,535) bytes minus the 8 bytes used by the UDP header minus the 20 bytes used
    by the IP header.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: We now have another candidate for interprocess messaging. It would be rather
    easy to set up a monitoring server for our Node application that listens on a
    UDP socket for program updates and statistics sent from other processes. The protocol
    speed is fast enough for real-time systems, and any packet loss or other UDP hiccups
    would be insignificant taken as a percentage of total volume over time.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: 'Taking the idea of broadcasting further, we can also use the `dgram` module
    to create a multicast server. A "multicast" is simply a one-to-many server broadcast.
    We can broadcast to a range of IPs that have been permanently reserved as multicast
    addresses. The website [http://www.iana.org/assignments/multicast-addresses/multicast-addresses.xhtml](http://www.iana.org/assignments/multicast-addresses/multicast-addresses.xhtml)
    has this to say:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: '*"Host Extensions for IP Multicasting [RFC1112] specifies the extensions required
    of a host implementation of the Internet Protocol (IP) to support multicasting.
    The multicast addresses are in the range 224.0.0.0 through 239.255.255.255."*'
  id: totrans-331
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Additionally, the range between 224.0.0.0 and 224.0.0.255 is further reserved
    for special routing protocols.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: Also, certain port numbers are allocated for use by UDP (and TCP), a list of
    which can be found at [https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers](https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers).
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: The upshot of all this fascinating information is the knowledge that there is
    a block of IPs and ports reserved for UDP and/or multicasting, and we are now
    going to use some of them to implement multicasting over UDP with Node.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: 'The only difference between setting up a multicasting UDP server and a "standard"
    one is the binding of the multicasting server to a special UDP port to indicate
    that we''d like to listen to *all* available network adapters. Our multicasting
    server initialization looks like this:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: After requesting a multicast port binding, we wait for the socket listen event,
    at which point we can configure our server.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: The most important command is `socket.addMembership`, which tells the kernel
    to join the multicast group at `multicastAddress`. Other UDP sockets can now subscribe
    to the multicast group at this address.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: Datagrams hop through networks just like any network packet. The `setMulticastTTL`
    method is used to set the maximum number of hops ("time to live") a datagram is
    allowed to make before it is abandoned and not delivered. The acceptable range
    is 0–255, with the default being one (1) on most systems. This is not usually
    a setting one must worry about, but it is available if deep visibility into network
    topology lends relevance to this aspect of packet delivery.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-340
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you'd also like to allow listening on the *local* interface, use `socket.setBroadcast(true)`
    and `socket.setMulticastLoopback(true)`. This is normally not necessary.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: 'We are eventually going to use this server to broadcast messages to all UDP
    listeners on `multicastAddress`. For now, let''s create two clients that will
    listen for multicasts:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We now have two clients listening to the same multicast port. All that is left
    to do is the multicasting. In this example, we will use `setTimeout` to send a
    counter value every second:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The preceding code will produce something like the following:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We have two clients listening to broadcasts from a specific group. Let''s add
    another client, listening on a different group—let''s say at the multicast address
    `230.3.2.1`:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Because our server currently broadcasts messages to a different address, we
    will need to change our server configuration and add this new address with another
    `addMembership` call:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We can now send messages to *both* addresses:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Of course, nothing stops the client from broadcasting to others in its group
    or even members of *another* group:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Any Node process that has an address on our network interface can now listen
    on a UDP multicast address for messages, providing a fast and elegant interprocess
    communication system.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-357
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at ways in which Node applications can be scaled
    both vertically and horizontally. We learned how to use `spawn` on OS processes
    and to use `fork` on new Node processes. The overview of the `cluster` module
    demonstrated how easy it is to scale across cores using Node and efficiently and
    easily distribute client connections across workers with built-in messaging channels
    to the central (master) hub. We also looked at how horizontally distributed processes
    and servers can communicate using message queues and UDP servers and how these
    servers can be load balanced and proxied using Nginx or using Node modules designed
    for that purpose.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了Node应用程序如何进行垂直和水平扩展的方法。我们学习了如何在操作系统进程中使用`spawn`，以及在新的Node进程中使用`fork`。`cluster`模块的概述展示了使用Node跨核心扩展是多么容易，以及如何通过内置的消息通道高效且轻松地将客户端连接分配给中央（主）枢纽。我们还探讨了水平分布的进程和服务器如何使用消息队列和UDP服务器进行通信，以及这些服务器如何使用Nginx或为该目的设计的Node模块进行负载均衡和代理。
- en: Scaling is not only about servers and load balancing. In the next chapter, we'll
    look at how to scale and manage resources, learn about memory management techniques,
    synchronize data across distributed services, synchronize data-caching strategies,
    and look at how to deal with massive numbers of simultaneous connections.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展不仅关乎服务器和负载均衡。在下一章中，我们将探讨如何扩展和管理资源，了解内存管理技术，同步分布式服务之间的数据，同步数据缓存策略，以及如何处理大量同时连接。
