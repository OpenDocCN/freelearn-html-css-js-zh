["```js\nimport buffer from 'buffer'\nconsole.log(buffer.constansts.MAX_LENGTH) \n```", "```js\nimport { promises as fs } from 'fs'\nimport { gzip } from 'zlib'\nimport { promisify } from 'util'\nconst gzipPromise = promisify(gzip)\nconst filename = process.argv[2]\nasync function main () {\n  const data = await fs.readFile(filename)\n  const gzippedData = await gzipPromise(data)\n  await fs.writeFile(`${filename}.gz`, gzippedData)\n  console.log('File successfully compressed')\n}\nmain() \n```", "```js\nnode gzip-buffer.js <path to file> \n```", "```js\nRangeError [ERR_FS_FILE_TOO_LARGE]: File size (8130792448) is greater than possible Buffer: 2147483647 bytes \n```", "```js\n// gzip-stream.js\nimport { createReadStream, createWriteStream } from 'fs'\nimport { createGzip } from 'zlib'\nconst filename = process.argv[2]\ncreateReadStream(filename)\n  .pipe(createGzip())\n  .pipe(createWriteStream(`${filename}.gz`))\n  .on('finish', () => console.log('File successfully compressed')) \n```", "```js\nimport { createServer } from 'http'\nimport { createWriteStream } from 'fs'\nimport { createGunzip } from 'zlib'\nimport { basename, join } from 'path'\nconst server = createServer((req, res) => {\n  const filename = basename(req.headers['x-filename'])\n  const destFilename = join('received_files', filename)\n  console.log(`File request received: ${filename}`)\n  req\n    .pipe(createGunzip())\n    .pipe(createWriteStream(destFilename))\n    .on('finish', () => {\n      res.writeHead(201, { 'Content-Type': 'text/plain' })\n      res.end('OK\\n')\n      console.log(`File saved: ${destFilename}`)\n    })\n})\nserver.listen(3000, () => console.log('Listening on http://localhost:3000')) \n```", "```js\nimport { request } from 'http'\nimport { createGzip } from 'zlib'\nimport { createReadStream } from 'fs'\nimport { basename } from 'path'\nconst filename = process.argv[2]\nconst serverHost = process.argv[3]\nconst httpRequestOptions = {\n  hostname: serverHost,\n  port: 3000,\n  path: '/',\n  method: 'PUT',\n  headers: {\n    'Content-Type': 'application/octet-stream',\n    'Content-Encoding': 'gzip',\n    'X-Filename': basename(filename)\n  }\n}\nconst req = request(httpRequestOptions, (res) => {\n  console.log(`Server response: ${res.statusCode}`)\n})\ncreateReadStream(filename)\n  .pipe(createGzip())\n  .pipe(req)\n  .on('finish', () => {\n    console.log('File successfully sent')\n  }) \n```", "```js\nnode gzip-receive.js \n```", "```js\nnode gzip-send.js <path to file> localhost \n```", "```js\n// ...\n**import** **{ createCipheriv, randomBytes }** **from****'crypto'**       // (1)\nconst filename = process.argv[2]\nconst serverHost = process.argv[3]\n**const** **secret = Buffer.from(process.argv[****4****],** **'hex'****)**         // (2)\n**const** **iv = randomBytes(****16****)**                                 // (3)\n// ... \n```", "```js\nconst httpRequestOptions = {\n  hostname: serverHost,\n  headers: {\n    'Content-Type': 'application/octet-stream',\n    'Content-Encoding': 'gzip',\n    'X-Filename': basename(filename),\n    **'X-Initialization-Vector'****: iv.toString(****'hex'****)**          // (1)\n  }\n}\n// ...\nconst req = request(httpRequestOptions, (res) => {\n  console.log(`Server response: ${res.statusCode}`)\n})\ncreateReadStream(filename)\n  .pipe(createGzip())\n  **.pipe(createCipheriv(****'aes192'****, secret, iv))**              // (2)\n  .pipe(req)\n// ... \n```", "```js\n// ...\nimport { createDecipheriv, randomBytes } from 'crypto'\nconst secret = randomBytes(24)\nconsole.log(`Generated secret: ${secret.toString('hex')}`) \n```", "```js\nconst server = createServer((req, res) => {\n  const filename = basename(req.headers['x-filename'])\n  **const** **iv = Buffer.from(**\n    **req.headers[****'x-initialization-vector'****],** **'hex'****)**         // (1)\n  const destFilename = join('received_files', filename)\n  console.log(`File request received: ${filename}`)\n  req\n    **.pipe(createDecipheriv(****'aes192'****, secret, iv))**          // (2)\n    .pipe(createGunzip())\n    .pipe(createWriteStream(destFilename))\n    // ... \n```", "```js\nreadable.read([size]) \n```", "```js\nprocess.stdin\n  .on('readable', () => {\n    let chunk\n    console.log('New data available')\n    while ((chunk = process.stdin.read()) !== null) {\n      console.log(\n        `Chunk read (${chunk.length} bytes): \"${chunk.toString()}\"`\n      )\n    }\n  })\n  .on('end', () => console.log('End of stream')) \n```", "```js\ncat <path to a file> | node read-stdin.js \n```", "```js\nprocess.stdin\n  .on('data', (chunk) => {\n    console.log('New data available')\n    console.log(\n      `Chunk read (${chunk.length} bytes): \"${chunk.toString()}\"`\n    )\n  })\n  .on('end', () => console.log('End of stream')) \n```", "```js\nasync function main () {\n  for await (const chunk of process.stdin) {\n    console.log('New data available')\n    console.log(\n      `Chunk read (${chunk.length} bytes): \"${chunk.toString()}\"`\n    )\n  }\n  console.log('End of stream')\n}\nmain() \n```", "```js\nreadable._read(size) \n```", "```js\nreadable.push(chunk) \n```", "```js\nimport { Readable } from 'stream'\nimport Chance from 'chance'\nconst chance = new Chance()\nexport class RandomStream extends Readable {\n  constructor (options) {\n    super(options)\n    this.emittedBytes = 0\n  }\n  _read (size) {\n    const chunk = chance.string({ length: size })          // (1)\n    this.push(chunk, 'utf8')                               // (2)\n    this.emittedBytes += chunk.length\n    if (chance.bool({ likelihood: 5 })) {                  // (3)\n      this.push(null)\n    }\n  }\n} \n```", "```js\n// index.js\nimport { RandomStream } from './random-stream.js'\nconst randomStream = new RandomStream()\nrandomStream\n  .on('data', (chunk) => {\n    console.log(`Chunk received (${chunk.length} bytes): ${chunk.toString()}`)\n  })\n  .on('end', () => {\n    console.log(`Produced ${randomStream.emittedBytes} bytes of random data`)\n  }) \n```", "```js\nimport { Readable } from 'stream'\nimport Chance from 'chance'\nconst chance = new Chance()\nlet emittedBytes = 0\nconst randomStream = new Readable({\n  read (size) {\n    const chunk = chance.string({ length: size })\n    this.push(chunk, 'utf8')\n    emittedBytes += chunk.length\n    if (chance.bool({ likelihood: 5 })) {\n      this.push(null)\n    }\n  }\n})\n// now use randomStream instance directly ... \n```", "```js\nimport { Readable } from 'stream'\nconst mountains = [\n  { name: 'Everest', height: 8848 },\n  { name: 'K2', height: 8611 },\n  { name: 'Kangchenjunga', height: 8586 },\n  { name: 'Lhotse', height: 8516 },\n  { name: 'Makalu', height: 8481 }\n]\nconst mountainsStream = Readable.from(mountains)\nmountainsStream.on('data', (mountain) => {\n  console.log(`${mountain.name.padStart(14)}\\t${mountain.height}m`)\n}) \n```", "```js\n Everest    8848m\n            K2    8611m\n Kangchenjunga    8586m\n        Lhotse    8516m\n        Makalu    8481m \n```", "```js\nwritable.write(chunk, [encoding], [callback]) \n```", "```js\nwritable.end([chunk], [encoding], [callback]) \n```", "```js\n// entropy-server.js\nimport { createServer } from 'http'\nimport Chance from 'chance'\nconst chance = new Chance()\nconst server = createServer((req, res) => {\n  res.writeHead(200, { 'Content-Type': 'text/plain' })     // (1)\n  while (chance.bool({ likelihood: 95 })) {                // (2)\n    res.write(`${chance.string()}\\n`)                      // (3)\n  }\n  res.end('\\n\\n')                                          // (4)\n  res.on('finish', () => console.log('All data sent'))     // (5)\n})\nserver.listen(8080, () => {\n  console.log('listening on http://localhost:8080')\n}) \n```", "```js\ncurl localhost:8080 \n```", "```js\n// ...\nconst server = createServer((req, res) => {\n  res.writeHead(200, { 'Content-Type': 'text/plain' })\n  function generateMore () {                                // (1)\n    while (chance.bool({ likelihood: 95 })) {\n      const randomChunk = chance.string({                   // (2)\n        length: (16 * 1024) - 1\n      })\n      const shouldContinue = res.write(`${randomChunk}\\n`)  // (3)\n      if (!shouldContinue) {\n        console.log('back-pressure')\n        return res.once('drain', generateMore)\n      }\n    }\n    res.end('\\n\\n')\n  }\n  generateMore()\n  res.on('finish', () => console.log('All data sent'))\n})\n// ... \n```", "```js\n{\n  path: <path to a file>\n  content: <string or buffer>\n} \n```", "```js\nimport { Writable } from 'stream'\nimport { promises as fs } from 'fs'\nimport { dirname } from 'path'\nimport mkdirp from 'mkdirp-promise'\nexport class ToFileStream extends Writable {\n  constructor (options) {\n    super({ ...options, objectMode: true })\n  }\n  _write (chunk, encoding, cb) {\n    mkdirp(dirname(chunk.path))\n      .then(() => fs.writeFile(chunk.path, chunk.content))\n      .then(() => cb())\n      .catch(cb)\n  }\n} \n```", "```js\nimport { join } from 'path'\nimport { ToFileStream } from './to-file-stream.js'\nconst tfs = new ToFileStream()\ntfs.write({\n  path: join('files', 'file1.txt'), content: 'Hello' })\ntfs.write({\n  path: join('files', 'file2.txt'), content: 'Node.js' })\ntfs.write({\n  path: join('files', 'file3.txt'), content: 'streams' })\ntfs.end(() => console.log('All files created')) \n```", "```js\n// ...\nconst tfs = new Writable({\n  objectMode: true,\n  write (chunk, encoding, cb) {\n    mkdirp(dirname(chunk.path))\n      .then(() => fs.writeFile(chunk.path, chunk.content))\n      .then(() => cb())\n      .catch(cb)\n  }\n})\n// ... \n```", "```js\nimport { Transform } from 'stream'\nexport class ReplaceStream extends Transform {\n  constructor (searchStr, replaceStr, options) {\n    super({ ...options })\n    this.searchStr = searchStr\n    this.replaceStr = replaceStr\n    this.tail = ''\n  }\n  _transform (chunk, encoding, callback) {\n    const pieces = (this.tail + chunk).split(this.searchStr)  // (1)\n    const lastPiece = pieces[pieces.length - 1]               // (2)\n    const tailLen = this.searchStr.length - 1\n    this.tail = lastPiece.slice(-tailLen)\n    pieces[pieces.length - 1] = lastPiece.slice(0, -tailLen)\n    this.push(pieces.join(this.replaceStr))                   // (3)\n    callback()\n  }\n  _flush (callback) {\n    this.push(this.tail)\n    callback()\n  }\n} \n```", "```js\nimport { ReplaceStream } from './replace-stream.js'\nconst replaceStream = new ReplaceStream('World', 'Node.js')\nreplaceStream.on('data', chunk => console.log(chunk.toString()))\nreplaceStream.write('Hello W')\nreplaceStream.write('orld!')\nreplaceStream.end() \n```", "```js\nHel\nlo Node.js\n! \n```", "```js\nconst searchStr = 'World'\nconst replaceStr = 'Node.js'\nlet tail = ''\nconst replaceStream = new Transform({\n  defaultEncoding: 'utf8',\n  transform (chunk, encoding, cb) {\n    const pieces = (tail + chunk).split(searchStr)\n    const lastPiece = pieces[pieces.length - 1]\n    const tailLen = searchStr.length - 1\n    tail = lastPiece.slice(-tailLen)\n    pieces[pieces.length - 1] = lastPiece.slice(0, -tailLen)\n    this.push(pieces.join(replaceStr))\n    cb()\n  },\n  flush (cb) {\n    this.push(tail)\n    cb()\n  }\n})\n// now write to replaceStream ... \n```", "```js\ntype,country,profit\nHousehold,Namibia,597290.92\nBaby Food,Iceland,808579.10\nMeat,Russia,277305.60\nMeat,Italy,413270.00\nCereal,Malta,174965.25\nMeat,Indonesia,145402.40\nHousehold,Italy,728880.54\n[... many more lines] \n```", "```js\nimport { createReadStream } from 'fs'\nimport parse from 'csv-parse'\nimport { FilterByCountry } from './filter-by-country.js'\nimport { SumProfit } from './sum-profit.js'\nconst csvParser = parse({ columns: true })\ncreateReadStream('data.csv')             // (1)\n  .pipe(csvParser)                       // (2)\n  .pipe(new FilterByCountry('Italy'))    // (3)\n  .pipe(new SumProfit())                 // (4)\n  .pipe(process.stdout)                  // (5) \n```", "```js\nimport { Transform } from 'stream'\nexport class FilterByCountry extends Transform {\n  constructor (country, options = {}) {\n    options.objectMode = true\n    super(options)\n    this.country = country\n  }\n  _transform (record, enc, cb) {\n    if (record.country === this.country) {\n      this.push(record)\n    }\n    cb()\n  }\n} \n```", "```js\nimport { Transform } from 'stream'\nexport class SumProfit extends Transform {\n  constructor (options = {}) {\n    options.objectMode = true\n    super(options)\n    this.total = 0\n  }\n  _transform (record, enc, cb) {\n    this.total += Number.parseFloat(record.profit)\n    cb()\n  }\n  _flush (cb) {\n    this.push(this.total.toString())\n    cb()\n  }\n} \n```", "```js\nimport { PassThrough } from 'stream'\nlet bytesWritten = 0\nconst monitor = new PassThrough()\nmonitor.on('data', (chunk) => {\n  bytesWritten += chunk.length\n})\nmonitor.on('finish', () => {\n  console.log(`${bytesWritten} bytes written`)\n})\nmonitor.write('Hello!')\nmonitor.end() \n```", "```js\ncreateReadStream(filename)\n  .pipe(createGzip())\n  **.pipe(monitor)**\n  .pipe(createWriteStream(`${filename}.gz`)) \n```", "```js\nfunction upload (filename, contentStream) {\n  // ...\n} \n```", "```js\nimport { createReadStream } from 'fs'\nupload('a-picture.jpg', createReadStream('/path/to/a-picture.jpg')) \n```", "```js\nimport { createReadStream } from 'fs'\nimport { createBrotliCompress } from 'zlib'\nimport { PassThrough } from 'stream'\nimport { basename } from 'path'\nimport { upload } from './upload.js'\nconst filepath = process.argv[2]                           // (1)\nconst filename = basename(filepath)\nconst contentStream = new PassThrough()                    // (2)\nupload(`${filename}.br`, contentStream)                    // (3)\n  .then((response) => {\n    console.log(`Server response: ${response.data}`)\n  })\n  .catch((err) => {\n    console.error(err)\n    process.exit(1)\n  })\ncreateReadStream(filepath)                                 // (4)\n  .pipe(createBrotliCompress())\n  .pipe(contentStream) \n```", "```js\nfunction createUploadStream (filename) {\n  // ...\n  // returns a writable stream that can be used to upload data\n} \n```", "```js\nfunction createUploadStream (filename) {\n  const connector = new PassThrough()\n  upload(filename, connector)\n  return connector\n} \n```", "```js\nconst upload = createUploadStream('a-file.txt')\nupload.write('Hello World')\nupload.end() \n```", "```js\nimport lazystream from 'lazystream'\nconst lazyURandom = new lazystream.Readable(function (options) {\n  return fs.createReadStream('/dev/urandom')\n}) \n```", "```js\necho Hello World! | sed s/World/Node.js/g \n```", "```js\nreadable.pipe(writable, [options]) \n```", "```js\n// replace.js\nimport { ReplaceStream } from './replace-stream.js'\nprocess.stdin\n  .pipe(new ReplaceStream(process.argv[2], process.argv[3]))\n  .pipe(process.stdout) \n```", "```js\necho Hello World! | node replace.js World Node.js \n```", "```js\nHello Node.js! \n```", "```js\nstream1\n  .pipe(stream2)\n  .on('error', () => {}) \n```", "```js\nstream1\n  .on('error', () => {})\n  .pipe(stream2)\n  .on('error', () => {}) \n```", "```js\nfunction handleError (err) {\n  console.error(err)\n  stream1.destroy()\n  stream2.destroy()\n}\nstream1\n  .on('error', handleError)\n  .pipe(stream2)\n  .on('error', handleError) \n```", "```js\npipeline(stream1, stream2, stream3, ... , cb) \n```", "```js\nimport { createGzip, createGunzip } from 'zlib'          // (1)\nimport { Transform, pipeline } from 'stream'\nconst uppercasify = new Transform({                      // (2)\n  transform (chunk, enc, cb) {\n    this.push(chunk.toString().toUpperCase())\n    cb()\n  }\n})\npipeline(                                                // (3)\n  process.stdin,\n  createGunzip(),\n  uppercasify,\n  createGzip(),\n  process.stdout,\n  (err) => {                                             // (4)\n    if (err) {\n      console.error(err)\n      process.exit(1)\n    }\n  }\n) \n```", "```js\necho 'Hello World!' | gzip | node uppercasify-gzipped.js | gunzip \n```", "```js\nHELLO WORLD! \n```", "```js\nError: unexpected end of file\n    at Zlib.zlibOnError [as onerror] (zlib.js:180:17) {\n  errno: -5,\n  code: 'Z_BUF_ERROR'\n} \n```", "```js\nimport { createWriteStream, createReadStream } from 'fs'\nimport { Readable, Transform } from 'stream'\nexport function concatFiles (dest, files) {\n  return new Promise((resolve, reject) => {\n    const destStream = createWriteStream(dest)\n    Readable.from(files)                                    // (1)\n      .pipe(new Transform({                                 // (2)\n        objectMode: true,\n        transform (filename, enc, done) {\n          const src = createReadStream(filename)\n          src.pipe(destStream, { end: false })\n          src.on('error', done)\n          src.on('end', done)                               // (3)\n        }\n      }))\n      .on('error', reject)\n      .on('finish', () => {                                 // (4)\n        destStream.end()\n        resolve()\n      })\n  })\n} \n```", "```js\nimport { concatFiles } from './concat-files.js'\nasync function main () {\n  try {\n    await concatFiles(process.argv[2], process.argv.slice(3))\n  } catch (err) {\n    console.error(err)\n    process.exit(1)\n  }\n  console.log('All files concatenated successfully')\n}\nmain() \n```", "```js\nnode concat.js all-together.txt file1.txt file2.txt \n```", "```js\nimport { Transform } from 'stream'\nexport class ParallelStream extends Transform {\n  constructor (userTransform, opts) {                    // (1)\n    super({ objectMode: true, ...opts })\n    this.userTransform = userTransform\n    this.running = 0\n    this.terminateCb = null\n  }\n  _transform (chunk, enc, done) {                        // (2)\n    this.running++\n    this.userTransform(\n      chunk,\n      enc,\n      this.push.bind(this),\n      this._onComplete.bind(this)\n    )\n    done()\n  }\n  _flush (done) {                                        // (3)\n    if (this.running > 0) {\n      this.terminateCb = done\n    } else {\n      done()\n    }\n  }\n  _onComplete (err) {                                    // (4)\n    this.running--\n    if (err) {\n      return this.emit('error', err)\n    }\n    if (this.running === 0) {\n      this.terminateCb && this.terminateCb()\n    }\n  }\n} \n```", "```js\nimport { pipeline } from 'stream'\nimport { createReadStream, createWriteStream } from 'fs'\nimport split from 'split'\nimport superagent from 'superagent'\nimport { ParallelStream } from './parallel-stream.js'\npipeline(\n  createReadStream(process.argv[2]),                       // (1)\n  split(),                                                 // (2)\n  new ParallelStream(                                      // (3)\n    async (url, enc, push, done) => {\n      if (!url) {\n        return done()\n      }\n      try {\n        await superagent.head(url, { timeout: 5 * 1000 })\n        push(`${url} is up\\n`)\n      } catch (err) {\n        push(`${url} is down\\n`)\n      }\n      done()\n    }\n  ),\n  createWriteStream('results.txt'),                        // (4)\n  (err) => {\n    if (err) {\n      console.error(err)\n      process.exit(1)\n    }\n    console.log('All urls have been checked')\n  }\n) \n```", "```js\nnode check-urls.js urls.txt \n```", "```js\nhttps://mario.fyi\nhttps://loige.co\nhttp://thiswillbedownforsure.com \n```", "```js\nhttp://thiswillbedownforsure.com is down\nhttps://mario.fyi is up\nhttps://loige.co is up \n```", "```js\nexport class **LimitedParallelStream** extends Transform {\n  constructor (**concurrency**, userTransform, opts) {\n    super({ ...opts, objectMode: true })\n    **this****.concurrency = concurrency**\n    this.userTransform = userTransform\n    this.running = 0\n    **this****.continueCb =** **null**\n    **this****.terminateCb =** **null**\n  }\n// ... \n```", "```js\n _transform (chunk, enc, done) {\n    this.running++\n    this.userTransform(\n      chunk,\n      enc,\n      this.push.bind(this),\n      this._onComplete.bind(this)\n    )\n    **if** **(****this****.running <** **this****.concurrency) {**\n      **done()**\n    **}** **else** **{**\n      **this****.continueCb = done**\n    **}**\n  } \n```", "```js\n _onComplete (err) {\n    this.running--\n    if (err) {\n      return this.emit('error', err)\n    }\n    **const** **tmpCb =** **this****.continueCb**\n    **this****.continueCb =** **null**\n    **tmpCb && tmpCb()**\n    if (this.running === 0) {\n      this.terminateCb && this.terminateCb()\n    }\n  } \n```", "```js\n//...\nimport parallelTransform from 'parallel-transform'\npipeline(\n  createReadStream(process.argv[2]),\n  split(),\n  parallelTransform(4, async function (url, done) {\n    if (!url) {\n      return done()\n    }\n    console.log(url)\n    try {\n      await request.head(url, { timeout: 5 * 1000 })\n      this.push(`${url} is up\\n`)\n    } catch (err) {\n      this.push(`${url} is down\\n`)\n    }\n    done()\n  }),\n  createWriteStream('results.txt'),\n  (err) => {\n    if (err) {\n      console.error(err)\n      process.exit(1)\n    }\n    console.log('All urls have been checked')\n  }\n) \n```", "```js\nimport { createReadStream, createWriteStream } from 'fs'\nimport { Transform, pipeline } from 'stream'\nimport { strict as assert } from 'assert'\nconst streamA = createReadStream('package.json')\nconst streamB = new Transform({\n  transform (chunk, enc, done) {\n    this.push(chunk.toString().toUpperCase())\n    done()\n  }\n})\nconst streamC = createWriteStream('package-uppercase.json')\nconst pipelineReturn = pipeline(\n  streamA,\n  streamB,\n  streamC,\n  () => {\n    // handle errors here\n  })\nassert.strictEqual(streamC, pipelineReturn) // valid\nconst pipeReturn = streamA.pipe(streamB).pipe(streamC)\nassert.strictEqual(streamC, pipeReturn) // valid \n```", "```js\nconst combinedStream = pumpify(streamA, streamB, streamC) \n```", "```js\nimport { createGzip, createGunzip } from 'zlib'\nimport {\n  createCipheriv,\n  createDecipheriv,\n  scryptSync\n} from 'crypto'\nimport pumpify from 'pumpify'\nfunction createKey (password) {\n  return scryptSync(password, 'salt', 24)\n}\nexport function createCompressAndEncrypt (password, iv) {\n  const key = createKey(password)\n  const combinedStream = pumpify(\n    createGzip(),\n    createCipheriv('aes192', key, iv)\n  )\n  combinedStream.iv = iv\n  return combinedStream\n}\nexport function createDecryptAndDecompress (password, iv) {\n  const key = createKey(password)\n  return pumpify(\n    createDecipheriv('aes192', key, iv),\n    createGunzip()\n  )\n} \n```", "```js\nimport { createReadStream, createWriteStream } from 'fs'\nimport { pipeline } from 'stream'\nimport { randomBytes } from 'crypto'\nimport { createCompressAndEncrypt } from './combined-streams.js'\nconst [,, password, source] = process.argv\nconst iv = randomBytes(16)\nconst destination = `${source}.gz.enc`\npipeline(\n  createReadStream(source),\n  createCompressAndEncrypt(password, iv),\n  createWriteStream(destination),\n  (err) => {\n    if (err) {\n      console.error(err)\n      process.exit(1)\n    }\n    console.log(`${destination} created with iv: ${iv.toString('hex')}`)\n  }\n) \n```", "```js\nnode archive.js mypassword /path/to/a/file.txt \n```", "```js\nimport { createReadStream, createWriteStream } from 'fs'\nimport { createHash } from 'crypto'\nconst filename = process.argv[2]\nconst sha1Stream = createHash('sha1').setEncoding('hex')\nconst md5Stream = createHash('md5').setEncoding('hex')\nconst inputStream = createReadStream(filename)\ninputStream\n  .pipe(sha1Stream)\n  .pipe(createWriteStream(`${filename}.sha1`))\ninputStream\n  .pipe(md5Stream)\n  .pipe(createWriteStream(`${filename}.md5`)) \n```", "```js\nimport { createReadStream, createWriteStream } from 'fs'\nimport split from 'split'\nconst dest = process.argv[2]\nconst sources = process.argv.slice(3) \n```", "```js\nconst destStream = createWriteStream(dest) \n```", "```js\nlet endCount = 0\nfor (const source of sources) {\n  const sourceStream = createReadStream(source, { highWaterMark: 16 })\n  sourceStream.on('end', () => {\n    if (++endCount === sources.length) {\n      destStream.end()\n      console.log(`${dest} created`)\n    }\n  })\n  sourceStream\n    .pipe(split((line) => line + '\\n'))\n    **.pipe(destStream, {** **end****:** **false** **})**\n} \n```", "```js\nnode merge-lines.js <destination> <source1> <source2> <source3> ... \n```", "```js\nimport { fork } from 'child_process'\nimport { connect } from 'net' \n```", "```js\nfunction multiplexChannels (sources, destination) {\n  let openChannels = sources.length\n  for (let i = 0; i < sources.length; i++) {\n    sources[i]\n      .on('readable', function () {                           // (1)\n        let chunk\n        while ((chunk = this.read()) !== null) {\n          const outBuff = Buffer.alloc(1 + 4 + chunk.length)  // (2)\n          outBuff.writeUInt8(i, 0)\n          outBuff.writeUInt32BE(chunk.length, 1)\n          chunk.copy(outBuff, 5)\n          console.log(`Sending packet to channel: ${i}`)\n          destination.write(outBuff)                          // (3)\n        }\n      })\n      .on('end', () => {                                      // (4)\n        if (--openChannels === 0) {\n          destination.end()\n        }\n      })\n  }\n} \n```", "```js\nconst socket = connect(3000, () => {                       // (1)\n  const child = fork(                                      // (2)\n    process.argv[2],\n    process.argv.slice(3),\n    { silent: true }\n  )\n  multiplexChannels([child.stdout, child.stderr], socket)  // (3)\n}) \n```", "```js\nimport { createWriteStream } from 'fs'\nimport { createServer } from 'net'\nfunction demultiplexChannel (source, destinations) {\n  let currentChannel = null\n  let currentLength = null\n  source\n    .on('readable', () => {                                  // (1)\n      let chunk\n      if (currentChannel === null) {                         // (2)\n        chunk = source.read(1)\n        currentChannel = chunk && chunk.readUInt8(0)\n      }\n      if (currentLength === null) {                          // (3)\n        chunk = source.read(4)\n        currentLength = chunk && chunk.readUInt32BE(0)\n        if (currentLength === null) {\n          return null\n        }\n      }\n      chunk = source.read(currentLength)                     // (4)\n      if (chunk === null) {\n        return null\n      }\n      console.log(`Received packet from: ${currentChannel}`)\n      destinations[currentChannel].write(chunk)              // (5)\n      currentChannel = null\n      currentLength = null\n    })\n    .on('end', () => {                                       // (6)\n      destinations.forEach(destination => destination.end())\n      console.log('Source channel closed')\n    })\n} \n```", "```js\nconst server = createServer((socket) => {\n  const stdoutStream = createWriteStream('stdout.log')\n  const stderrStream = createWriteStream('stderr.log')\n  demultiplexChannel(socket, [stdoutStream, stderrStream])\n})\nserver.listen(3000, () => console.log('Server started')) \n```", "```js\nconsole.log('out1')\nconsole.log('out2')\nconsole.error('err1')\nconsole.log('out3')\nconsole.error('err2') \n```", "```js\nnode server.js \n```", "```js\nnode client.js generateData.js \n```"]