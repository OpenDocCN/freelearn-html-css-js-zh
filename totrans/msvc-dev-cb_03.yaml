- en: Inter-service Communication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Service-to-service communication
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making concurrent asynchronous requests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding services using service discovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Server-side load balancing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Client-side load balancing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building event-driven microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evolving APIs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we've covered how to begin breaking a monolithic codebase
    into microservices, as well as best practices for exposing your microservices
    to the public internet. So far, we've assumed that all of our microservices are
    standalone applications that have no dependencies. These simple microservices
    receive requests, retrieve data or write to a database, and return a response
    to clients. This kind of linear workflow is rare in real-world systems. In a real-world
    microservice architecture, services will frequently need to invoke other services
    in order to fulfill a user's request. A typical user request will commonly create
    dozens of requests to services in your system.
  prefs: []
  type: TYPE_NORMAL
- en: Managing the communication between services presents a number of challenges.
    Before a service can speak to another service, it will need to locate it through
    some kind of service-discovery mechanism. When generating requests to a downstream
    service, we also need a way to distribute traffic across the various instances
    of the service that minimizes latency and distributes the load evenly without
    compromising data integrity. We’ll need to consider how to handle service failures
    and prevent them from cascading throughout our system.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes a service will need to communicate with other services asynchronously,
    in these cases, we can use event-driven architectural patterns to create reactive
    workflows. Breaking our system up into multiple services also means that different
    services will evolve their APIs independently, so we'll need ways to handle changes
    that won't break upstream services.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we'll discuss recipes designed to address each of these challenges.
    By the end of this chapter, you'll be able to confidently handle the various kinds
    of interactions we're bound to require in a microservice architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Service-to-service communication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In large-scale systems, problems arise less often in services themselves and
    more often in the communication between services. For this reason, we need to
    carefully consider all of the various challenges in service-to-service communication.
    When discussing service-to-service communication, it''s useful to visualize the
    flow of information in our system. Data flows in both directions–from the client
    (upstream) to the database, or event bus (downstream) in the form of requests,
    and back again in the form of responses. When we refer to upstream services, we
    are describing components of the system that are closer to the user in the flow
    of information. When we refer to downstream services, we are describing components
    of the system that are further away from the user–in other words, the user makes
    a request that is routed to a service that then makes requests to other, downstream
    services, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e9d1a309-4a6c-40b9-b1f9-fb29a57213ea.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagram, the originating **User** is upstream from the **edge-proxy-service**,
    which is upstream from the **auth-service**, **attachment-service**, and **user-service**.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to demonstrate the service-to-service communication, we’ll create
    a simple service that calls another service synchronously using the Spring Boot
    Java framework. Keeping with the example of our fictional messaging application,
    we’ll create a message service that is responsible for sending messages. The message
    service has to invoke the social graph service in order to determine whether the
    sender and recipient of a message are friends before allowing a message to be
    sent. The following simplified diagram illustrates the relationship between services:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f59246e5-43de-47fb-a0ec-04597a6befe0.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, a **POST** request comes in from the user to the **/message**
    endpoint, which is routed to **message-service**. The **message-service** service
    then makes an HTTP **GET** request to the **social-service** service using the
    **/friendships/:id** endpoint. The **social-service** service returns a JSON representation
    of friendships for a user.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create a new Java/Gradle project called `message-service` and add the following
    content to the `build.gradle` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a new package called `com.packtpub.microservices.ch03.message` and a
    new class called `Application`. This will be our service''s entry point:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the model. Create a package called `com.packtpub.microservices.ch03.message.models`
    and a class called `Message`. This is the internal representation of the message.
    There''s a lot missing here. We''re not actually persisting the message in this
    code, as it''s best to keep this example simple:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a new package called `com.packtpub.microservices.ch03.message.controllers`
    and a new class called `MessageController`. At the moment, our controller doesn''t
    do much except accept the request, parse the JSON, and return the message instance,
    as you can see from this code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Test this basic service by running it and trying to send a simple request:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Take a look at the following command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have a basic service working, but it''s pretty dumb and not doing much.
    We won''t go into persistence in this chapter, but let''s add some intelligence
    by checking with the social service to verify that our two users have a friendship
    before allowing the message to be sent. For the purposes of our example, imagine
    we have a working social service that allows us to check for relationships between
    users with requests, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we can consume this service, let''s create a model to store its response.
    In the `com.packtpub.microservices.ch03.message.models` package, create a class
    called `UserFriendships`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Modify `MessageController`, adding a method to get a list of friendships for
    a user, optionally filtering by a username. Note that we''re hardcoding the URL
    in this example, which is a bad practice. We''ll discuss alternatives to this
    in the next recipe. Take a look at the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Modify the `create` method we wrote earlier. If the users are friends, we''ll
    continue and return the message as before; if the users are not friends, the service
    will respond with a `403` indicating that the request is forbidden:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Asynchronous requests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous recipe, we were making a single service invocation per request,
    from the message service to the social service. This has the benefit of being
    incredibly simple to implement and, when using single-threaded languages, such
    as Python, Ruby, or JavaScript, is often the only choice. Performing a network
    call synchronously in this manner is acceptable when you're only doing it once
    per request–it doesn't matter that the call blocks the thread since you can't
    respond to the user until the invocation is complete anyway. When you're making
    multiple requests, however, blocking network calls will severely impact the performance
    and scalability of your application. What we need is an easy way to make use of
    Java's concurrency features.
  prefs: []
  type: TYPE_NORMAL
- en: If you're writing your microservices in Scala, you can take advantage of the
    `Future` type, which is used to represent an asynchronous computation. The **Finagle**
    RPC framework even uses futures as one of its base abstractions for modeling dependent
    RPCs. Java also has futures and the Spring Boot framework has some useful utilities
    that make it easy to wrap network calls, making them asynchronous and therefore
    non-blocking.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, we''ll retool the message service we introduced in the previous
    recipe. Instead of checking to see whether the sender and recipient of a message
    are friends, we''ll now imagine that our app uses an asymmetric following model.
    For a user to message another user, the two users will have to follow each other.
    This requires the message service to make two network calls to the social service,
    checking that the sender follows the recipient and simultaneously checking that
    the recipient follows the sender. The following simplified diagram represents
    the relationship between services:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/06522d1b-7cc6-456f-a624-cfcaef00e7c4.png)'
  prefs: []
  type: TYPE_IMG
- en: Spring Boot has useful tools that we can use to make methods asynchronous using
    Java's `CompletableFuture` type. We'll modify our previous message service to
    make two concurrent calls to the search service.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Open the `MessageController` file and insert the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Replace the `getFriendsForUser` method with a new method, called `isFollowing`.
    We give the new method an `@Async` annotation, which tells Spring Boot that this
    method will be run in a different thread:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Modify the `create` method to make the two service invocations. We''ll need
    to wait until they are both done before deciding how to proceed, but the two service
    calls will be made concurrently:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'For the `@Async` annotation to schedule methods on separate threads, we need
    to configure an `Executor`. This is done in our `Application` class, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Our service now makes concurrent asynchronous calls to the social service in
    order to ensure that the sender and recipient of a message follow each other.
    We customize our `Async` scheduler with `Executor` defined as part of our application's
    configuration. We've configured our `ThreadPoolTaskExecutor` class to limit the
    number of threads to `2` and the queue size to `500`. There are many factors to
    consider when configuring `Executor`, such as the amount of traffic you expect
    your service to receive and the average amount of time it takes for your service
    to serve a request. In this example, we'll leave it with these values.
  prefs: []
  type: TYPE_NORMAL
- en: Service discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before services can invoke each other, they need to be able to find each other
    using some kind of service discovery mechanism. This means being able to translate
    a service name into a network location (IP address and port). Traditional applications
    maintained the network locations of services to send requests to, probably in
    a configuration file (or worse, hardcoded in the application code). This approach
    assumes that network locations are relatively static, which isn't going to be
    the case in modern, cloud-native applications. The topologies of microservice
    architectures are constantly changing. Nodes are being added and removed through
    auto-scaling, and we have to assume that some nodes will fail either completely
    or by serving requests with unacceptably high latency. As a microservice architecture
    grows, you'll need to consider a more feature-rich service-discovery mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: When choosing a service-discovery mechanism, the datastore used to back your
    service registry is extremely important. You want a well-tested, battle-worn system.
    Apache **ZooKeeper** is an open source hierarchical key-value store commonly used
    for distributed locking, service discovery, maintaining configuration information,
    and other distributed coordination tasks. The development of ZooKeeper was in
    part motivated by a paper published by Google in 2006 that described **Chubby**,
    an internally-developed system for distributed lock storage. In this recipe, we'll
    use ZooKeeper to build a service-discovery mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Cloud ZooKeeper is a project that provides easy ZooKeeper integration
    in Spring Boot applications.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For this recipe, there are two sets of steps, as shown in the next sections.
  prefs: []
  type: TYPE_NORMAL
- en: Registering with the service registry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This recipe requires a running ZooKeeper cluster. At a minimum, you will need
    a single ZooKeeper node running locally on your development machine. For instructions
    on installing and running ZooKeeper, please visit the excellent ZooKeeper documentation.
    Take a look at the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, we''ll create a service to handle the creation and retrieval
    of user accounts. Create a new Gradle Java application called `users-service`
    with the following `build.gradle` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Because we''ve declared `spring-boot-starter-zookeeper-discovery` as a dependency,
    we have access to the necessary annotations to tell our application to register
    itself with a ZooKeeper service registry on startup. Create a new class called
    `Application`, which will serve as our service''s entry point:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The application now attempts to connect to a ZooKeeper node, by default running
    on port 2181 on localhost. This default will work for local development, but will
    need to be changed in a production environment anyway. Add a file `src/resources/application.yml`
    with the following contents:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'To give your service a meaningful name in the service registry, modify the
    `application.yml` file and add the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Finding services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have a service being registered with the service registry, we''ll
    create another service to demonstrate using the Spring ZooKeeper `DiscoveryClient`
    to find a running instance of that service:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open our previously created message-service client. Add the following lines
    to `build.gradle`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We''re using an HTTP client developed by Netflix, called **Feign**. Feign allows
    you to declaratively build HTTP clients and supports service discovery by default.
    Create a new file called `UsersClient.java` with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Open the `MessageController.java` file, and add an instance of `UsersClient`
    as a field:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Instead of manually building the URL in the `isFollowing` method, we can use
    the Feign client to automatically get a list of friendships for a user, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Because we're using a service registry, we no longer have to worry about clunky
    configs holding onto hostname values that can change. Furthermore, we're in a
    position to start deciding how we want to distribute the load among available
    instances of a service.
  prefs: []
  type: TYPE_NORMAL
- en: Server-side load balancing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When thinking about distributing load across a cluster of servers running instances
    of an application, it's interesting to consider a brief (and incomplete) history
    of web application architectures. Some of the earliest web applications were static
    HTML pages hosted by a web server, such as Apache or similar web server daemon
    software. Gradually, applications became more dynamic, using technologies such
    as server-side scripts executed through CGI. Even dynamic applications were still
    files hosted and served directly by a web server daemon. This simple architecture
    worked for a long time. Eventually, however, as the amount of traffic an application
    received grew, a way to distribute load among identical stateless instances of
    an application was needed.
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of techniques for load balancing, including round-robin DNS
    or DNS geolocation. The simplest and most common form of load balancing for microservices
    is to use a software program that forwards requests to one of a cluster of backend
    servers. There are a number of different ways load can be distributed, based on
    the specific load-balancing algorithm used by the load balancer we choose. Simple
    load-balancing algorithms include round-robin and random choice. More often, in
    real-world production applications, we'll opt for a load-balancing algorithm that
    takes reported metrics, such as load or the number of active connections, into
    account when choosing a node in a cluster to forward a request to.
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of popular open source applications that can perform effective
    load balancing for microservices. **HAProxy** is a popular open source load balancer
    that can do TCP and HTTP load balancing. NGINX is a popular open source web server
    that can be effectively used as a reverse proxy, application server, load balancer,
    or even HTTP cache. Nowadays, more organizations are in positions to develop microservices
    that are deployed on cloud platforms, such as Amazon Web Services or Google Cloud
    Platform, which each have solutions for server-side load balancing.
  prefs: []
  type: TYPE_NORMAL
- en: AWS provides a load-balancing solution called **Elastic Load Balancing** (**ELB**).
    ELB can be configured to forward traffic to a member of an **Auto Scaling Groups**.
    Auto Scaling Groups are collections of EC2 instances that are treated as a logical
    group. ELB use health checks (TCP or HTTP) that help the load balancer determine
    whether to forward traffic to a particular EC2 instance.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we'll use the AWS CLI tool to create an Auto Scaling Groups
    and attach an ELB to it. We won't cover configuration management or deployment
    in this recipe, so imagine that you have a microservice running on each of the
    EC2 instances in the Auto Scaling Groups.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We'll be using the AWS CLI in this recipe, a command-line utility written in
    Python, that makes interacting with the AWS API easy. We'll assume you have an
    AWS account and have installed and configured the AWS CLI application. Consult
    the AWS documentation ([https://docs.aws.amazon.com/cli/latest/index.html#](https://docs.aws.amazon.com/cli/latest/index.html#))
    for installation instructions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a launch configuration. Launch configurations are templates that our
    Auto Scaling Groups will use for creating new EC2 instances. They contain information
    such as the instance type and size that we want to use when creating new instances.
    Give your launch configuration a unique name–in our case, we''ll simply call it
    `users-service-launch-configuration`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Create an Auto Scaling Groups that uses our new launch configuration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Create an ELB, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Attach the ASG to our load balancer by running the following command line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Client-side load balancing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Server-side load balancing is a well-established and battle-tested way to distribute
    load to an application. It has drawbacks, however, in that there is an upper limit
    to the amount of incoming connections that a single load balancer can handle.
    This can be at least partially solved with round-robin DNS, which would distribute
    load to a number of load balancers, but this configuration can quickly become
    cumbersome and costly. Load balancer applications can also become points of failure
    in an already-complex microservices architecture.
  prefs: []
  type: TYPE_NORMAL
- en: An increasingly popular alternative to server-side load balancing is client-side
    load balancing. In this convention, clients are responsible for distributing requests
    evenly to running instances of a service. Clients can keep track of latency and
    failure rates from nodes and opt to reduce the amount of traffic to nodes that
    are experiencing high latency or high failure rates. This method of load balancing
    can be extremely effective and simple, especially in large-scale applications.
  prefs: []
  type: TYPE_NORMAL
- en: Ribbon is an open source library developed by Netflix that, among other features,
    provides support for client-side load balancing. In this recipe, we'll modify
    our message service to use `ribbon` for client-side load balancing. Instead of
    sending our requests for a user's friendships to a single instance of the users
    service, we'll distribute load to a number of available instances.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Open the `message-service` project and add the following lines to `build.gradle`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Navigate to `src/main/resources/application.yml` and add the following configuration
    for `users-service`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a new Java class called `UsersServiceConfiguration`. This class will
    configure the specific rules we want `ribbon` to follow when deciding how to distribute
    load:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Open `MessageController` and add the following annotation to the `MessageController`
    class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Annotate the `RestTemplate` class to indicate that we want it to use `ribbon`
    load-balancing support, and modify our URL to use the service name, not the hostname
    we had hardcoded previously:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Building event-driven microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, all of our service-to-service communication recipes have involved having
    one service call one or more other services directly. This is necessary when the
    response from the downstream service is required to fulfill the user's request.
    This isn't always required however. In cases when you want to react to an event
    in the system, for example, when you want to send an email or notification or
    when you want to update an analytics store, using an event-driven architecture
    is preferable. In this design, one service produces a message to a broker and
    another application consumes that message and performs an action. This has the
    benefit of decoupling the publisher from the consumer (so your message service
    doesn't have to worry about sending email notifications, for instance) and also
    removing potentially expensive operations off the critical path of the user's
    request. The event-driven architecture also provide some level of fault tolerance
    as consumers can fail, and messages can be replayed to retry any failed operations.
  prefs: []
  type: TYPE_NORMAL
- en: '**Apache Kafka** is an open source stream-processing platform. At its core,
    it is an event broker architected as a distributed transaction log. A full description
    of Apache Kafka is worthy of an entire book in itself—for a great introduction,
    I highly recommend reading the LinkedIn blog post that introduces Kafka ([https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying)).
    The minimum you need to know to follow this recipe is that Kafka is a distributed
    event store that lets you publish messages to categories called **topics**. Another
    process can then consume messages from a topic and react to them.'
  prefs: []
  type: TYPE_NORMAL
- en: Going back to our fictional messaging application, when a user sends a message
    to another user, we want to be able to notify the recipient in a number of ways.
    Depending on the recipient's preferences, we'll probably send an email or a push
    notification or both. In this recipe, we'll modify our message service from previous
    recipes to publish an event to a Kafka topic called **messages**. We'll then build
    a consumer application that listens for events in the message's topic and can
    react by sending the recipient notifications.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spring for Apache Kafka (`spring-kafka`) is a project that makes it easy to
    integrate Spring applications with Apache Kafka. It provides useful abstractions
    for sending and receiving messages.
  prefs: []
  type: TYPE_NORMAL
- en: Note that to follow the steps in this recipe, you will need to have a version
    of Kafka and ZooKeeper running and accessible. Installing and configuring these
    two pieces of software is beyond the scope of this recipe, so please visit the
    respective project websites and follow their wonderfully written guides on getting
    started. In this recipe, we'll assume that you have Kafka running a single broker
    on port `9092` and a single instance of ZooKeeper running on port `2181`.
  prefs: []
  type: TYPE_NORMAL
- en: Message producer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Open the `message-service` project from previous recipes. Modify the `build.gradle`
    file and add the `spring-kafka` project to the list of dependencies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The `spring-kafka` project provides a template for sending messages to a Kafka
    broker. To use the template in our project, we'll need to create a `ProducerFactory`
    interface and provide it to the constructor of the template.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open the `Application.java` file and add the following content. Note that we''re
    hardcoding the network location of the Kafka broker here—in a real application,
    you''d at least place this value in some kind of configuration (preferably respecting
    12 factor conventions):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we can use `KafkaTemplate` in our application, add one to the `MessageController`
    class. Also, use the Jackson `ObjectMapper` class to convert our `Message` instance
    into a JSON string that we''ll publish to the Kafka topic. Open the `MessageController`
    class and add following fields:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have access to the Jackson `ObjectMapper` and the `KafkaTemplate`
    classes, create a method for publishing events. In this example, we''re printing
    out to standard error and standard output. In a real application, you''d configure
    a logger, such as log4j, and use the appropriate log levels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the following line to the `create` method, calling the previously created
    the `publishMessageEvent` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'To test this example, create a message topic using the `kafka-topics.sh` Kafka
    utility (packaged with the Kafka binary distribution), as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Message consumer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we''re publishing message-send events, the next step is to build a
    small consumer application that can react to these events in our system. We''ll
    discuss the scaffolding as it relates to Kafka in this recipe; implementing email
    and push notification functionality is left as an exercise for the reader:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Gradle Java project called `message-notifier` with the following
    `build.gradle` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a new Java class called `Application` with the Spring Boot application
    boilerplate:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Evolving APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: APIs are contracts between clients and servers. Backward-incompatible changes
    to APIs can cause unexpected errors for clients of the service. In a microservices
    architecture, precautions have to be taken to ensure that changes to a service's
    API do not unintentionally cause cascading problems throughout the system.
  prefs: []
  type: TYPE_NORMAL
- en: A popular approach is to version your API, either through the URL or via content
    negotiation in request headers. Because they're generally easier to work with,
    and often easier to cache, URL prefixes or query strings tend to be more common—in
    this case, the API endpoint is either prefixed with a version string (that is,
    `/v1/users`) or called with a query string parameter specifying a version or even
    a date (that is, `/v1/users?version=1.0 or /v1/users?version=20180122`).
  prefs: []
  type: TYPE_NORMAL
- en: With edge proxies or service mesh configurations, it's even possible to run
    multiple versions of software in an environment and route requests based on the
    URL to older or newer versions of a service. This changes the traditional life
    cycle of a service–you can safely decommission a version when it is no longer
    receiving any traffic. This can be useful, especially in the case of a public
    API where you have little control over clients.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices are different than public APIs. The contract between clients and
    the server in a public API is much more long-lived. In a microservices architecture,
    it's easier to track down clients who are using your service and convince them
    to upgrade their code! Nevertheless, API versioning is sometimes necessary. Because
    being able to respond successfully to multiple versions of an API is a maintenance
    burden, we'd like to avoid it for as long as possible. To do this, there are a
    few practices that can be used to avoid making backward-incompatible changes.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using our example application, `pichat`, let''s imagine that we want to change
    the name of the message body from `body` to `message_text`. This presents a problem
    because our message service is designed to accept the following requests:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'In the case of the `GET` requests, the client will expect a JSON object with
    a field called `body` in the response. In the case of the `POST` request, clients
    will be sending payloads as the JSON objects with a field called `body`. We can''t
    simply remove body because that would break existing clients, thus necessitating
    a change to the API version. Instead, we''ll simply add the new field in addition
    to the old one, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Now you can gradually track down clients using these responses; once they've
    all been upgraded, you can safely remove the deprecated field from the JSON response.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
