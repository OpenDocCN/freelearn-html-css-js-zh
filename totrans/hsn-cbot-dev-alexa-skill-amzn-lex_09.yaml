- en: Review and Continued Development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this book, we've covered a wide range of topics and learned skills
    in lots of different areas. We've combined these skills to design and create complex
    chatbots on both the Alexa and Lex platforms.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Recap the skills that we've learned throughout this book
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discuss how to continue your chatbot development exploration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discuss the future of chatbots
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What we've learned
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There have been a lot of skills that have been covered in this book, both technical
    and non-technical.
  prefs: []
  type: TYPE_NORMAL
- en: Conversation design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first topic that was covered was conversation design. This is one of the
    most important sections of this book, as every good chatbot will need to go through
    this design stage. It doesn't matter whether it's going to be an Alexa Skill,
    Lex chatbot, or even a chatbot built using different technology.
  prefs: []
  type: TYPE_NORMAL
- en: When designing a chatbot, we always try to start with a perfect user conversation.
    Starting with a perfect conversation means that the users are likely to have the
    best possible experience with our chatbots.
  prefs: []
  type: TYPE_NORMAL
- en: Using the perfect conversation, we can start to build our flow diagrams. These
    provide more technical structure to the design, allowing us to specify what data
    we're saving, which APIs we're hitting, and triggering one flow from another.
    Creating a set of shorter flow diagrams that link together is incredibly powerful,
    as it provides flexibility to connect new entry points and features as the chatbot
    matures.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Web Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, we were introduced to **Amazon Web Services** (**AWS**) and the tools
    that we have access to. We started by creating an AWS Lambda using the Lambda
    console and then checked it using the built-in testing features.
  prefs: []
  type: TYPE_NORMAL
- en: Although creating Lambdas in the console is great for simple functions, we often
    need more functionality and a more reliable experience. We discussed the two other
    options—**Cloud9** and **local editing**—and we mentioned their advantages and
    their limitations.
  prefs: []
  type: TYPE_NORMAL
- en: Local editing had some great advantages but lacked the ability to easily create
    and update Lambdas. To fix this, we learned about the `aws-cli` and how we can
    use it to control our AWS products. Using the `aws-cli`, we created a build script
    that could take our local files, bundle them together, and deploy them to AWS.
    With this script, we now had a powerful development environment with easy deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Alexa
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Then it was time to start building some chatbots. We started with Alexa and
    learned about the components that make up a chatbot. We learned to use intents,
    utterances, and slots to allow our users to interact with our chatbots.
  prefs: []
  type: TYPE_NORMAL
- en: To power this skill, we needed to create a Lambda to handle the requests. We
    used `alexa-sdk` to make it much easier to create the responses that we would
    be sending back to the user.
  prefs: []
  type: TYPE_NORMAL
- en: With a working Alexa Skill, we learned how to test it using the built-in testing
    tools. This way, we can test it as if we were a user, but with the ability to
    see how our skill is acting in the background.
  prefs: []
  type: TYPE_NORMAL
- en: Once we had tested the chatbot, we were ready to publish it. Alexa Skills need
    to be published to the Alexa Skill Store, and we learned how to follow this process
    to make our skills available to the public.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon S3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To increase the usefulness of all of our chatbots, we needed to be able to access
    large amounts of stored data. To do this, we learned how to create an S3 bucket,
    store data in it, and then access this data from our Lambdas. With this data access,
    we could provide users with a much larger amount of information on the topic that
    they requested.
  prefs: []
  type: TYPE_NORMAL
- en: Using APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We then learned how to access third-party APIs to further improve the usefulness
    of our chatbots. We used the `openWeatherMaps` API as an example and this allowed
    us to access live information that we would never have been able to generate ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: To do this, we also learned about `axios` and making API requests. With these
    skills, you'll be able to make requests to an API to add new features to your
    chatbots. We also looked at the two best ways to handle errors—using `try`/`catch`
    and the `to()` method. We discussed the reasons that you might want to use one
    or the other and why error handling is important.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Lex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building text-based chatbots came next as we learned about Amazon Lex. We saw
    the similarities and differences between Lex and Alexa, and we built on our existing
    knowledge to create our first Lex chatbots.
  prefs: []
  type: TYPE_NORMAL
- en: We learned that each intent can return a hardcoded response or trigger a Lambda.
    Being able to trigger a different Lambda from each intent allowed us to create
    lots of very customized Lambdas to do exactly what we wanted.
  prefs: []
  type: TYPE_NORMAL
- en: When we triggered a Lambda from Lex, it expected a very defined response format.
    Unfortunately, there isn't a `lex-sdk` yet, so we built our own. We saw five different
    response types and created methods for each of them. This allowed us to create
    the required responses much more easily.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamo DB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While S3 is great for storing large amounts of data that probably won't change
    very much, it isn't great for storing data that is regularly changing. To store
    this type of data, we learned about DynamoDB. This is Amazon's non-relational
    database, and it gives us the ability to easily store, access, and update information.
    We used this to store the shopping cart used for an online store.
  prefs: []
  type: TYPE_NORMAL
- en: We created a `Dynamo` class that had methods for getting, writing, updating,
    and deleting these Dynamo tables so that we didn't have to write the long and
    complex code needed every time.
  prefs: []
  type: TYPE_NORMAL
- en: Publishing Lex chatbots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There's no point being able to build an amazing chatbot if your users can't
    access it. We learned to leverage the massive existing user bases of Facebook,
    Slack, and Twilio by integrating our chatbot into those platforms.
  prefs: []
  type: TYPE_NORMAL
- en: We also built an API service that allowed us to integrate our chatbot into a
    much wider range of applications. Building on this API, we created our own frontend
    interface for our chatbot. This was great, as it gave us the ability to make it
    look and work exactly how we wanted it to.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first seven chapters of this book taught us how to create powerful Alexa
    Skills and Lex chatbots by using other services such as S3, DynamoDB, and external
    APIs. In [Chapter 8](78bc7277-515a-4a49-8ace-6726512c3862.xhtml), *Improving User
    Experience for Your Bots*, we looked at some of the advanced features that are
    built into Lex and Alexa.
  prefs: []
  type: TYPE_NORMAL
- en: We first learned how to create information cards for Lex. This allowed us to
    send the user more visual information than the basic messages we were sending
    before. Adding these cards provided a huge boost to the user experience.
  prefs: []
  type: TYPE_NORMAL
- en: Then we learned about phrase slots in Alexa and how they can be used to capture
    information where the options that could be entered are too large to create a
    custom slot type. Being able to capture such a wide range of inputs into a slot
    makes our skills more reliable and robust.
  prefs: []
  type: TYPE_NORMAL
- en: The last thing that we learned about was utterance monitoring in Lex. This is
    where we can look at the utterances that Lex has detected and those that it has
    missed, which gives us an insight into the way that users are interacting with
    our chatbots. This also provides a mechanism to easily add utterances that we've
    missed to our existing intents.
  prefs: []
  type: TYPE_NORMAL
- en: Continuing your learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you've completed this book, you have a great understanding of voice,
    and text-based chatbots. You're able to build complex, multi-flow chatbots that
    integrate other services such as S3, DynamoDB, and external APIs. If you've enjoyed
    learning how to build these systems, then you're in a great position to continue
    your journey.
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of different directions you can go with your learning, and I'll
    outline some possibilities for you—a few specific to Alexa or Lex, and then a
    few that would be great to learn for both Alexa and Lex.
  prefs: []
  type: TYPE_NORMAL
- en: Alexa
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you really enjoyed building skills for Alexa, then there are two directions
    that I would go in with my learning.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Echo Spot and Amazon Echo Show
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Amazon Echo Spot** and **Amazon Echo Show** are Amazon's Alexa devices
    that also have screens. This means that you can provide users with visual information
    as well as voice responses. As with the cards on Lex, having that extra visual
    information can make the user experience much richer.
  prefs: []
  type: TYPE_NORMAL
- en: One big advantage of Echo devices with screens is that you can provide images
    to the user. Trying to tell a user about a product just using voice can be very
    hard but, with an image, the user experience is much smoother. You can also play
    videos, have a slideshow, or create custom displays with lots of varying information.
  prefs: []
  type: TYPE_NORMAL
- en: Building a library of functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you enjoy building Alexa Skills and want to start building more of them,
    then there are going to be times when you want to use the same methods across
    multiple skills. There are two options—just copy the code every time, or create
    a library of method Lambdas. The first one is good for a small number of skills
    but will become annoying as you build more skills.
  prefs: []
  type: TYPE_NORMAL
- en: The second option will take longer to set up but will make building future skills
    much easier. The design for this setup is similar to the way that Lex works, where
    each intent triggers a single Lambda. Unfortunately, this isn't supported already,
    but we can create the same effect using the Lambda Invoke functions. This lets
    us trigger a Lambda from our `handlers` object.
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of this method is that the common intents can trigger the same
    Lambda, reducing repeated code, whilst unique intents can still be built in the
    main handler Lambda.
  prefs: []
  type: TYPE_NORMAL
- en: Lex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you want to learn more skills specific to Lex, then the best direction would
    be learning to integrate it into more services.
  prefs: []
  type: TYPE_NORMAL
- en: There are hundreds of messaging services that Lex doesn't natively support,
    and being able to integrate your chatbot into these services would be a great
    skill to have. You could try integrating you chatbot into Telegram, Twitter, WeChat,
    or any other messaging services. To do this, you'll probably have to map the message
    into the correct format for that specific service. The mapping between formats
    can be quite tricky but is a great skill to learn.
  prefs: []
  type: TYPE_NORMAL
- en: Once you've built a mechanism to integrate Lex into these messaging platforms,
    you can advertise your integration or the fact that you can build a mechanism
    to integrate into the company's own messaging platform. Lots of companies want
    to be able to add chatbots to their existing messaging platform.
  prefs: []
  type: TYPE_NORMAL
- en: Alexa and Lex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Continuing your learning with skills that can be used with both Alexa and Lex
    is probably the best use of your time, and there are many different directions
    to go in.
  prefs: []
  type: TYPE_NORMAL
- en: Improving the build process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you build more Alexa Skills and Lex chatbots, you will become frustrated
    with having to open the Alexa Skills Kit or the Lex console to add a new utterance
    or change an intent. Luckily, there is the `aws-cli` and `ask-cli` that we can
    use to build and update our skills and chatbots without having to go online.
  prefs: []
  type: TYPE_NORMAL
- en: You may remember the `aws-cli` from [Chapter 2](ac448944-0559-408e-a9c4-972933a03611.xhtml),
    *Getting Started with AWS and Amazon CLI*, where we used it to allow us to build
    Lambdas from our local machines. You can also use `aws-cli` to do something similar
    for Lex chatbots, whilst `ask-cli` has similar functionality for Alexa Skills.
    For both of these systems, there is quite a steep learning curve and you'll end
    up reading a lot of documentation, but being able to build a new chatbot or skill
    without ever using a browser is really useful.
  prefs: []
  type: TYPE_NORMAL
- en: You can either have the full structure of the chatbot or skill saved as a file
    on your computer, or you can create a system to generate these files based on
    a more simple config file. The advantage of the latter method is that the config
    files should be a lot easier to read and understand, making it a lot easier to
    figure out what needs to change for your update.
  prefs: []
  type: TYPE_NORMAL
- en: Once you've got this system in place, you should be able to create a new config
    file for a new bot within minutes. If you use this system, there is nothing stopping
    you from still using the online Alexa Skills Kit or Lex console to check, edit,
    and update your skills and chatbots.
  prefs: []
  type: TYPE_NORMAL
- en: If you are considering building chatbots or Alexa Skills as a job, then this
    tool will prove invaluable.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating more AWS services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this book, we have learned how to use S3 and DynamoDB to improve the functionality
    of our skills and chatbots. There are currently over 100 AWS services, and some
    of them could be used to add even more functionality to your chatbots.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few ideas for service integrations:'
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Redshift or Amazon ElastiCache, for a different method for database storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Cognito, for allowing users to sign in to access existing orders and
    chats or to provide results that are adjusted to match their user information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Transcribe and Amazon Simple Email Service, to send the user an email
    with everything they said whilst chatting to Alexa
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the number of services available, what you can build and do with Alexa
    and Lex is limited only by your imagination.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating other APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The number of APIs available online is incredible! Just looking through one
    list of top APIs can give you some incredible ideas. What about a chatbot that
    you can ask about a certain product and it searches eBay for those products, allowing
    you to bid on it without leaving the chat! There's a census API that could be
    used to build an Alexa Skill where you can find out about the population, employment
    stats, economics, number of new houses, and much more about any area in the United
    States.
  prefs: []
  type: TYPE_NORMAL
- en: If you're looking to come up with some ideas for your own chatbots, then I highly
    recommend looking at APIs that are available and what you can do with them. You
    might find a function on one API that combines with a function on another API
    to create an immensely powerful chatbot.
  prefs: []
  type: TYPE_NORMAL
- en: The future of chatbots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chatbots have come a long way over the last decade and are now often found in
    households through Amazon Echo and Google Home. Technologically, they have improved
    in leaps and bounds, with improvements in AI and machine learning resulting in
    better language understanding as well as voice-to-text that power the Echo and
    Google Home devices.
  prefs: []
  type: TYPE_NORMAL
- en: I expect that the growth of chatbots will continue and we'll start seeing them
    used in a huge range of application and through a wide range of devices. As they
    improve, they'll be trusted with increasingly complex and important tasks and
    will completely revolutionize a lot of industries. Industries such as customer
    services are already changing, with chatbots on multiple banking and retail websites
    and phone systems.
  prefs: []
  type: TYPE_NORMAL
- en: Language understanding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To be able to properly respond to someone, you need to understand what they
    are saying so you can build the correct response. This has improved a lot with
    the adoption of machine learning but is far from perfect.
  prefs: []
  type: TYPE_NORMAL
- en: One issue that can occur is that there are two intents with similar utterances,
    or with the same keyword in the utterances. When the user says a similar utterance,
    it matches both of the intents similarly and therefore can't choose which one
    to trigger. A chatbot with an intent with an utterance of `When is the football
    match?` and another intent with `Where is the football match?` is very likely
    to get confused and not be able to handle the request.
  prefs: []
  type: TYPE_NORMAL
- en: Another issue can be with spelling mistakes and typos. Lex currently seems to
    be OK with handling typos and spelling mistakes, but there have been quite a few
    times that these have caused issues.
  prefs: []
  type: TYPE_NORMAL
- en: As machine learning and language understanding improve, I expect to see these
    sorts of issues decrease.
  prefs: []
  type: TYPE_NORMAL
- en: Working with spoken interactions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As with language understanding, being able to respond to a user's request means
    being able to understand what they said. With voice systems, this involves converting
    the spoken sound waves into text. Whilst this can work brilliantly if you happen
    to speak clearly with a neutral accent, there are often issues when people speak
    very quickly or with a strong accent.
  prefs: []
  type: TYPE_NORMAL
- en: When the text is generated from the users with a strong accent, it can often
    be misunderstood, and the text that is produced makes no sense. This then means
    that when it is passed into the language-understanding system, the speech can't
    be matched to an intent. This can be very frustrating for users with a strong
    accent who are unable to interact with these devices. This is a significant hurdle
    to overcome before voice-based chatbots become common in commercial applications.
  prefs: []
  type: TYPE_NORMAL
- en: Improved device interaction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The continued increase of devices and systems that you can interact with through
    voice- and text-based conversation is key to the expansion of chatbots into our
    everyday lives. The great thing is that it's possible to install Alexa software
    onto a Raspberry Pi Zero, a $10 computer chip. This means that adding voice interaction
    to any device can be cheap and relatively simple. Alexa integration can already
    be seen in cars, smart mirrors, smart tables, and much more.
  prefs: []
  type: TYPE_NORMAL
- en: Another sector where I believe that chat interfaces are going to grow significantly
    is in wearables. Bluetooth hands-free systems are becoming smaller and more discrete
    and they could very easily integrate voice chat systems. At any point in your
    day, you could ask Alexa for the weather or the meetings for the day and get an
    instant response. This would overcome the security concerns that some people have
    about voice systems projecting their response for everyone in the room to hear.
  prefs: []
  type: TYPE_NORMAL
- en: Smart watches with built-in voice- and text-based chatbots provide another way
    that we will see chatbots integrated into our lives. The advantage of watches
    over earpieces is that they have screens, allowing the chatbot to display visual
    media or show the user the information, instead of having to say it all. Being
    able to glance at the weather is more convenient than having to listen to the
    weather forecast for the next five days when all you cared about was next Wednesday.
  prefs: []
  type: TYPE_NORMAL
- en: The last wearable that I can imagine using chatbots in the near future is smart
    glasses. Glasses similar to Google Glasses would allow you to receive visual information
    in the same way that a smart watch would, but you wouldn't even need to look down
    at your wrist. The addition of chatbots to an augmented reality system such as
    this could be very powerful.
  prefs: []
  type: TYPE_NORMAL
- en: The most powerful way the chatbots could be integrated into wearables would
    be an integration of multiple systems. Using an earpiece for a voice-based chat,
    but having a smart watch or smart glasses to display the visual information, would
    combine the best of both worlds.
  prefs: []
  type: TYPE_NORMAL
- en: Connected devices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The second obstacle to overcome, before chatbots are commonplace, is the number
    of devices that can be connected to these smart home systems or remotely controlled
    solutions. You can currently get smart light switches, coffee makers, and even
    door locks that you can control through chat interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: In the future, I expect that more and more devices will come out with a similar
    control system. I can imagine a washing machine that you can set and start by
    just talking to Alexa and eventually a kitchen where every device and appliance
    is speech-controlled. Imagine telling Alexa to turn the oven on to 180 degrees
    and to let you know when it gets to the right temperature, all while you sat watching
    TV, and then preparing a turkey and asking Alexa to open the oven so you can put
    it straight in. The oven could then weigh the turkey and set a reminder for 50
    minutes before it will be ready to start preparing the roast potatoes.
  prefs: []
  type: TYPE_NORMAL
- en: As well as domestic appliances with integrated chatbots, I expect to see an
    increase in chatbots in businesses over the next 10-20 years. Bank tellers could
    become a screen with an animation of a person, powered by a voice-based chatbot.
    You could get your fresh meat and cheese from a chatbot that controls a robotic
    delicatessen. These could work in exactly the same way as current human workers,
    asking if that is a large enough piece of the brie wheel whilst holding the knife
    in position.
  prefs: []
  type: TYPE_NORMAL
- en: As well as commercial applications, I expect to see public service information
    begin to integrate chatbots. You arrive at the shopping center car park and want
    to find a particular store. All you need to do is to walk up to one of the information
    signs and ask where the shop is and it'll display the directions on a map, tell
    you how to get there, or even send the directions to your smart watch or smart
    glasses.
  prefs: []
  type: TYPE_NORMAL
- en: Unique voice-based systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To power the sorts of integrations and devices just mentioned, there needs to
    be a change in the way that voice-based chatbots are built. If you want to build
    a system that handles user speech, then your two main options are to build an
    Alexa Skill or a Google Home action. This is great for integrating into devices
    that already run these systems, but companies wouldn't want to run Alexa as your
    bank teller chatbot system.
  prefs: []
  type: TYPE_NORMAL
- en: There needs to be a change in the market with the move to being able to create
    custom voice-based chatbot systems that don't have to be run on Alexa or Google
    Home. This is currently possible through Amazon Lex, as it has been built to handle
    voice interaction, but I hope to see an increase in the range of systems that
    can do this.
  prefs: []
  type: TYPE_NORMAL
- en: General Artificial Intelligence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A lot of the issues that exist with current chatbots will gradually be fixed,
    and their performance will increase incrementally, but the next large step forward
    will be the creation of **general AI**.
  prefs: []
  type: TYPE_NORMAL
- en: General AI is the concept where a single system can handle any request. This
    may sound not too far off with projects such as IBM Watson building a system that
    can dominate Jeopardy and other quiz games, but being able to answer simple questions
    is only part of the challenge.
  prefs: []
  type: TYPE_NORMAL
- en: The issues start when the system has to work out what other information it needs
    to fulfill the request and how to ask for that information. If someone asked you
    to find their class graduation photo, you would probably ask them what school
    they went to and what year they graduated in. You have used your knowledge about
    class photos to decide that you need to ask about school and year to accurately
    find their class photo. Our brains are extremely good at these sorts of tasks,
    but building an AI system that can work this out for every possible request, now
    or in the future, is a daunting task. Building an intent for every possible question
    just isn't possible so the system will need to gather what information it has
    on the topic, work out what else it needs to know to answer the question, and
    then ask for those pieces of data in a human way.
  prefs: []
  type: TYPE_NORMAL
- en: Another issue is with integrating into external systems. Throughout this book,
    we've used APIs to access data that is stored by a third party. To use these APIs,
    we had to have an API key, and, even then, we only had access to the data and
    functionality that we were given through the API. If we wanted to create a chatbot
    that did our weekly supermarket shop, had it delivered to our house, and paid
    for it, we'd need to get an API that allows us to do all of this. Creating an
    API like that is something I expect most supermarkets wouldn't dream of doing.
  prefs: []
  type: TYPE_NORMAL
- en: In my job, integrating into a client's existing system is a major hurdle to
    getting their chatbot functioning. Having a general AI system that has access
    to every API in the world is unrealistic, and, even then, there are systems that
    are not exposed through APIs.
  prefs: []
  type: TYPE_NORMAL
- en: Improving people's opinions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One large hurdle to increased acceptance of chatbots is improving people's opinions
    of chatbots. When chatbots first came out, they were very limited in functionality,
    couldn't deal with many variations in utterance, and often proved to be more frustrating
    than useful. Modern chatbots have improved a lot, but there are a lot of older
    systems that are still very discouraging to use. Even modern chatbot systems have
    their limitation, as we've discussed earlier, and can still end up disappointing
    users with missed intents or misunderstood speech.
  prefs: []
  type: TYPE_NORMAL
- en: As the systems improve, better systems will have better user retention and the
    old systems will be replaced. I expect to see a continual improvement in people's
    opinions about chatbots. As systems like Alexa and Google Home become increasingly
    common in households, younger generations will grow up with chatbots and interacting
    with them will become second nature.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book has given us a practical introduction to chatbots through building
    increasingly complex Alexa Skills and Lex chatbots. We've learned about starting
    from a perfect conversation and creating flow diagrams to visualize the users'
    conversational path with a chatbot. Using these flow diagrams, we've built intents
    using utterances and slots that are handled in Lambdas.
  prefs: []
  type: TYPE_NORMAL
- en: We've improved the features and abilities of our chatbots through the use of
    S3 storage, DynamoDB databases, and external APIs. To improve the user experience,
    we also learned about using SSML to change how Alexa talks with our users, learned
    how to create cards to provide more visual information, and learned about search
    query slot types in Alexa for gathering wider ranges of slot values.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we've discussed a few great ways to build upon what we've already learned
    in this book and what we expect is in store for the future of chatbots.
  prefs: []
  type: TYPE_NORMAL
