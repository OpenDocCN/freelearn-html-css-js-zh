- en: Cameras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we covered the vertex shader, fragment shader, and
    ESSL to a define a lighting model in our 3D scene. In this chapter, we will leverage
    these concepts to learn more about the matrices that we have seen in the source
    code. These matrices represent transformations that, when applied to our scene,
    allow us to display and move things around. In one case, we've already used them
    to set the camera to a distance to see all the objects in our scene, and in another
    case, we've used them to spin our 3D car model.
  prefs: []
  type: TYPE_NORMAL
- en: Even though we have a camera within our 3D application, there is no camera object
    in the WebGL API—only matrices. That is because having matrices instead of a camera
    object gives WebGL the flexibility to represent complex projections and animations.
    In this chapter, we will learn what these matrix transformations mean and how
    we can use them to define and operate a virtual camera.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will look at the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the transformations that the scene undergoes from a 3D world to
    a 2D screen.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning about affine transformations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mapping matrices to ESSL uniforms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with the Model-View and Projection matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appreciating the value of the Normal matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a camera and using it to move around a 3D scene.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WebGL Does Not Have Cameras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'How is it that there are no cameras in a 3D computer-graphics technology? Well,
    let''s rephrase this: WebGL does not have a camera object that you can manipulate.
    However, we can assume that what we render in the `canvas` is what our camera
    captures. In this chapter, we are going to solve the problem of how to represent
    a camera in WebGL. The short answer is that we need 4x4 matrices.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Every time we move our camera around, we will need to update the objects according
    to the new camera position. To do this, we need to systematically process each
    vertex and apply a transformation that produces the new viewing position. Similarly,
    we need to make sure that the object normals and light directions are still consistent
    after the camera has moved. In summary, we need to analyze two different types
    of transformations: vertex (points) and normal (vectors).'
  prefs: []
  type: TYPE_NORMAL
- en: Vertex Transformations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Objects in a WebGL scene go through different transformations before we see
    them on our screen. Each transformation is encoded by a 4x4 matrix. How do we
    multiply vertices that have three components, `(x, y, z)`, by a 4x4 matrix? The
    short answer is that we need to augment the cardinality of our tuples by one dimension.
    Each vertex will then have a fourth component called the Homogeneous coordinate.
    Let's see what they are and why they are useful.
  prefs: []
  type: TYPE_NORMAL
- en: Homogeneous Coordinates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Homogeneous coordinates** are a key component of any computer-graphics program.
    These coordinates make it possible to represent *affine* transformations (such
    as rotation, scaling, shear, and translation) and *projective* transformations
    as 4x4 matrices.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Homogeneous coordinates, vertices have four components: `x`, `y`, `z`, and `w`*.*
    The first three components are the vertex coordinates in **Euclidian Space**.
    The fourth is the perspective component. The four-tuple `(x, y, z, w)` take us
    to a new space: the **Projective Space**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Homogeneous coordinates make it possible to solve a system of linear equations
    where each equation represents a line that is parallel with all the others in
    the system. Remember that in Euclidian Space, a system like that does not have
    solutions, because there are no intersections. However, in Projective Space, this
    system has a solution—the lines will intersect at infinity. This fact is represented
    by the perspective component having a value of `0`. A good analogy of this idea
    is the image of train tracks: parallel lines that converge at the vanishing point
    when you look at them in the distance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aaaad883-8a76-4af7-bb65-2e4fe9fef713.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It''s easy to convert from Homogeneous coordinates to non-Homogeneous, old-fashioned,
    Euclidean coordinates. All you need to do is divide the coordinate by `w`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Consequently, if you want to go from Euclidean to Projective space, you add
    the fourth component, `w`, and make it `1`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, this is what we''ve been doing throughout the first three chapters
    of this book! Let''s go back to one of the shaders we discussed in the last chapter:
    the Phong vertex shader. The code looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Please note that for the `aVertexPosition` attribute, which contains a vertex
    of our geometry, we create a four-tuple from the three-tuple that we receive.
    We do this with the ESSL construct, `vec4()`. ESSL knows that `aVertexPosition` is
    a `vec3` and therefore, we only need the fourth component to create a `vec4`.
  prefs: []
  type: TYPE_NORMAL
- en: Coordinates Transformations
  prefs: []
  type: TYPE_NORMAL
- en: To pass from Homogeneous coordinates to Euclidean coordinates, we divide by `w`*.*
  prefs: []
  type: TYPE_NORMAL
- en: To pass from Euclidean coordinates to Homogeneous coordinates, we add `w = 1`.
  prefs: []
  type: TYPE_NORMAL
- en: Homogeneous coordinates with `w = 0` represent a point at infinity.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one more thing to note about Homogeneous coordinates: while vertices
    have a Homogeneous coordinate, `w = 1`, vectors have a Homogeneous coordinate, `w
    = 0`. This is because in the Phong vertex shader, the line that processes the
    normals looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: To code vertex transformations, we will use Homogeneous coordinates unless indicated
    otherwise. Now, let's see the different transformations that our geometry undergoes
    to be displayed on screen.
  prefs: []
  type: TYPE_NORMAL
- en: Model Transform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We start our analysis from the object-coordinate system. This is the space where
    vertex coordinates are specified. If we want to translate or move objects around,
    we use a matrix that encodes these transformations. This matrix is known as the
    **Model matrix**. Once we multiply the vertices of our object by the Model matrix,
    we obtain new vertex coordinates. These new vertices will determine the position
    of the object in our 3D world.
  prefs: []
  type: TYPE_NORMAL
- en: 'In object coordinates, each object is free to define where its origin is and
    to specify where its vertices are with respect to this origin. In world coordinates,
    the origin is shared by all of the objects. World coordinates allow us to know
    where objects are located with respect to each other. It is with the model transform
    that we determine where the objects are in the 3D world:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1fb7b0ee-7885-45c3-bae4-9be31fcfa2bc.png)'
  prefs: []
  type: TYPE_IMG
- en: View Transform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next transformation, the view transform, shifts the origin of the coordinate
    system to the view origin. The view origin is where our *eye* or *camera* is located
    with respect to the world origin. In other words, the view transform switches
    world coordinates by view coordinates. This transformation is encoded in the **View
    matrix**. We multiply this matrix by the vertex coordinates obtained by the model
    transform. The result of this operation is a new set of vertex coordinates whose
    origin is the view origin. It is in this coordinate system that our camera is
    going to operate.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/005ef6cc-2933-4bb1-9153-f40e9ec6ee5d.png)'
  prefs: []
  type: TYPE_IMG
- en: We will return to this later in the chapter!
  prefs: []
  type: TYPE_NORMAL
- en: Projection Transform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next operation is called the **projection transform**. This operation determines
    how much of the view space will be rendered and how it will be mapped onto the
    computer screen. This region is known as the **frustum** and it is defined by
    six planes (near, far, top, bottom, right, and left planes), as shown in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2385e5e7-aed6-45b2-9087-7baa5b57d092.png)'
  prefs: []
  type: TYPE_IMG
- en: These six planes are encoded in the **Projection matrix**. Any vertices lying
    outside the frustum after applying the transformation are *clipped out* and discarded
    from further processing. Therefore, the frustum *defines* clipping coordinates,
    and the Projection matrix that encodes the frustum *produces* clipping coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: 'The shape and extent of the frustum determines the type of projection from
    the 3D viewing space to the 2D screen. If the far and near planes have the same
    dimensions, the frustum will then determine an *orthographic* projection. Otherwise,
    it will be a *perspective* projection, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5e8adaa6-e7e7-4747-9762-b2903df547a4.png)'
  prefs: []
  type: TYPE_IMG
- en: Up to this point, we are still working with Homogeneous coordinates, so the
    clipping coordinates have four components: `x`, `y`, `z`, and `w`. The clipping
    is done by comparing the `x`, `y`, and `z` components against the Homogeneous
    coordinate, `w`. If any of them is more than, `+w`, or less than, `-w`, then that
    vertex lies outside the frustum and is discarded.
  prefs: []
  type: TYPE_NORMAL
- en: Perspective Division
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once it has been determined how much of the viewing space will be rendered,
    the frustum is mapped into the *near plane* in order to produce a 2D image. The
    near plane is what is going to be rendered on your computer screen.
  prefs: []
  type: TYPE_NORMAL
- en: Different operative systems and displaying devices can have mechanisms to represent
    2D information on screen. To provide robustness for all possible cases, WebGL
    and OpenGL ES provide an intermediate coordinate system that is independent from
    any specific hardware. This space is known as the **Normalized Device Coordinates
    (NDC)**.
  prefs: []
  type: TYPE_NORMAL
- en: Normalized device coordinates are obtained by dividing the clipping coordinates
    by the `w` component. This is why this step is known as *perspective division*.
    Also, please remember that when we divide by the Homogeneous coordinate, we go
    from projective space (4 components) to Euclidean space (3 components), so NDC
    only has three components. In the NDC space, the `x` and `y` coordinates represent
    the location of your vertices on a normalized 2D screen, while the z-coordinate
    encodes depth information, which is the relative location of the objects with
    respect to the near and far planes. Although at this point we are working on a
    2D screen, we still keep the depth information. This will allow WebGL to later
    determine how to display overlapping objects based on their distance from the
    nearest plane. When using normalized device coordinates, the depth is encoded
    in the z-component.
  prefs: []
  type: TYPE_NORMAL
- en: 'The perspective division transforms the viewing frustum into a cube centered
    in the origin with the minimum coordinates of `[-1, -1, -1]` and the maximum coordinates
    of `[1, 1, 1]`. Also, the direction of the z-axis is inverted, as shown in the
    following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4ad69e23-68dd-4781-88f2-974d9c1b4122.png)'
  prefs: []
  type: TYPE_IMG
- en: Viewport Transform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Finally, NDCs are mapped to **viewport coordinates**. This step maps these
    coordinates to the available space in your screen. In WebGL, this space is provided
    by the HTML5 `canvas`, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cb84407b-0550-4cff-b474-35d21601c539.png)'
  prefs: []
  type: TYPE_IMG
- en: Unlike the previous cases, the viewport transform is not generated by a matrix
    transformation. In this case, we use the WebGL viewport function. We will learn
    more about this function later in this chapter. Now, it's time to see how these
    transformations affect normals.
  prefs: []
  type: TYPE_NORMAL
- en: Normal Transformations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Whenever vertices are transformed, **normal vectors** should also be transformed
    so that they point in the right direction. We could consider using the Model-View
    matrix that transforms vertices to do this, but this approach is problematic:
    the Model-View matrix will not always keep the perpendicularity of normals, as
    illustrated by the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/df8dc082-2ebd-496e-a8a9-8eddfd3d3304.png)'
  prefs: []
  type: TYPE_IMG
- en: This problem occurs if there is a unidirectional (one axis) scaling transformation
    or a shearing transformation in the Model-View matrix. In our example, we have
    a triangle that has undergone a scaling transformation on the y-axis. As you can
    see, the `N'` normal is no longer perpendicular after this kind of transformation.
    How do we solve this?
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the Normal Matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are not interested in finding out how we calculate the Normal matrix
    and just want the answer, feel free to jump to the end of this section. Otherwise,
    stick around to see some linear algebra in action!
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with the mathematical definition of perpendicularity. Two vectors
    are perpendicular if their dot product is `0`. In our example, this will be:'
  prefs: []
  type: TYPE_NORMAL
- en: Here, *`S`* is the surface vector and can be calculated as the difference of
    two vertices, as shown in the diagram at the beginning of this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let *`M`* be the Model-View matrix. We can use *`M`* to transform `*S*` as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: This is because `*S*` is the difference of two vertices. We use `*M*` to transform
    vertices onto the viewing space.
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to find a matrix, `*K*`, that allows us to transform normals in a similar
    way. For the `*N*` normal, we want the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the scene to be consistent after obtaining `*N''*` and `*S''*`, these two
    need to keep the perpendicularity that the original vectors `*N*` and `*S*` had.
    This is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Substituting `*N''*` and `*S''*`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A dot product can also be written as a vector multiplication by transposing
    the first vector so that this still holds:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The transpose of a product is the product of the transposes in the reverse
    order:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Grouping the inner terms:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, remember that `![](img/00bae9ac-8ccb-4a47-8de1-1af208c087b6.png)` so `![](img/a116585c-c195-4728-9ab9-787eedfce48a.png)` (again,
    a dot product can be written as a vector multiplication). This means that in the
    previous equation, (`![](img/f425b4f3-3626-49fe-9a88-1c4ee7bf9967.png)`) needs
    to be the Identity matrix, `*I*`, so the original condition of `*N*` and `*S*` being
    perpendicular holds:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Applying a bit of algebra:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `![](img/e6602643-ef8e-4240-bc57-034d777c70e3.png)` | Multiply by the inverse
    of `*M*` on both sides. |'
  prefs: []
  type: TYPE_TB
- en: '| `![](img/61e70e3d-b8ee-4d60-aa72-7a6524de722e.png)` | Because `![](img/81925c34-d45d-44ae-b40f-e82f8bb46d56.png)`*.*
    |'
  prefs: []
  type: TYPE_TB
- en: '| `![](img/ca32723e-31ba-411f-bc04-2726d4b085f5.png)` | Transposing on both
    sides. |'
  prefs: []
  type: TYPE_TB
- en: '| `![](img/e23e25a6-159e-49a5-8578-2f0e783bc3a0.png)` | Double transpose of `*K*` is
    the original matrix `*K*`. |'
  prefs: []
  type: TYPE_TB
- en: 'Conclusions:'
  prefs: []
  type: TYPE_NORMAL
- en: '*`K` *is the correct matrix transform that keeps the normal vectors perpendicular
    to the surface of the object. We call `*K*` the **Normal matrix**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*`K` *is obtained by transposing the inverse of the Model-View matrix (`*M*`,
    in this example).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We need to use *`K` *to multiply the normal vectors so that they keep being
    perpendicular to the surface when transformed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WebGL Implementation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at how we can implement vertex and normal transformations
    in WebGL. The following diagram shows the theory we have learned so far, along
    with the relationships between the steps in the theory and the implementation
    in WebGL:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/800122be-4528-4269-a431-5e723273c0e0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In WebGL, the five transformations that we apply to object coordinates to obtain
    viewport coordinates are grouped into three matrices and one WebGL method:'
  prefs: []
  type: TYPE_NORMAL
- en: The **Model-View **matrix that groups the *model* and *view* transform in one
    single matrix. When we multiply our vertices by this matrix, we end up in view
    coordinates.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Normal matrix **is obtained by inverting and transposing the Model-View
    matrix. This matrix is applied to normal vectors to ensure that they continue
    to be perpendicular to the surface. This is very important in cases such as lighting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Projection matrix **groups the *projection transformation* and *the perspective
    division*, and as a result, we end up in normalized device coordinates.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, we use the `gl.viewport` operation to map NDCs to viewport coordinates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The viewport coordinates originate in the lower-left corner of the HTML5 `canvas`.
  prefs: []
  type: TYPE_NORMAL
- en: JavaScript Matrices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The WebGL JavaScript API does not provide its own methods to perform operations
    on matrices. WebGL simply provides a way to pass matrices to the shaders (as uniforms).
    So, we need to use a JavaScript library that enables us to manipulate matrices
    in JavaScript. In this book, we have used **glMatrix** for all matrix operations.
    However, there are other libraries available online that can do this for you.
  prefs: []
  type: TYPE_NORMAL
- en: glMatrix
  prefs: []
  type: TYPE_NORMAL
- en: We used **glMatrix** for all matrix operations in this book. You can find more
    information about this library at [https://github.com/toji/gl-matrix.](https://github.com/toji/gl-matrix)
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some of the operations that you can perform with **glMatrix**:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Operation** | **Syntax** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| Creation | `const m = mat4.create();` | Creates the `m` matrix. |'
  prefs: []
  type: TYPE_TB
- en: '| Identity | `mat4.identity(m);` | Sets `m` as the Identity matrix of rank
    4. |'
  prefs: []
  type: TYPE_TB
- en: '| Copy | `mat4.copy(target, origin);` | Copies the matrix origin onto the matrix target.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Transpose | `mat4.transpose(target, m);` | Transposes the `m` matrix onto
    the matrix target. |'
  prefs: []
  type: TYPE_TB
- en: '| Invert | `mat4.invert(target, m);` | Inverts `m` onto the matrix target.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Rotate | `mat4.rotate(target, m, r, a);` | Rotates the `m` matrix by `r` radians
    around the `a`  axis (this is a three-element array, `[x, y, z]`) onto the matrix target.
    |'
  prefs: []
  type: TYPE_TB
- en: It's important to note that the **glMatrix** provides many more functions to
    perform other linear algebra operations. To get the full list, visit [http://glmatrix.net/docs/](http://glmatrix.net/docs/).
  prefs: []
  type: TYPE_NORMAL
- en: Mapping JavaScript Matrices to ESSL Uniforms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since the Model-View and Perspective matrices do not change during a single
    rendering step, they are passed as *uniforms* to the shaders. For example, if
    we were applying a translation to an object in our scene, we would have to paint
    the whole object in the new coordinates given by the translation. Painting the
    whole object in the new position is achieved in exactly one rendering step.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, before the rendering step is invoked (by calling `drawArrays` or `drawElements`),
    we need to make sure that the shaders have an updated version of our matrices.
    We already know how to do that for other uniforms, such as light and color properties.
    The method to map JavaScript matrices to uniforms is similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Get a JavaScript reference to the uniform with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the reference to pass the matrix to the shader with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As is the case for other uniforms, ESSL supports two-, three-, and four-dimensional
    matrices: `uniformMatrix[234]fv(reference, transpose, matrix)`. This will load
    2x2, 3x3, or 4x4 matrices (corresponding to 2, 3, or 4 in the command name) of
    floating points into the uniform referenced by `reference`. The type of `reference`
    is `WebGLUniformLocation`. For practical purposes, it is an integer number. According
    to the specification, the transpose value must be set to `false`. The matrix uniforms
    are always of the floating point type (`f`). The matrices are passed as `4`, `9`,
    or `16` element vectors (`v`) and are always specified in a column-major order.
    The matrix parameter can also be of the `Float32Array` type. This is one of JavaScript's
    typed arrays. These arrays are included in the language to provide access to and
    the manipulation of raw binary data, and thus increase efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Working with Matrices in ESSL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's revisit the Phong vertex shader, which was introduced in [Chapter 3](0dcbfd9d-5446-48e9-90c1-841f4d160232.xhtml),
    *Lights*. Please remember that matrices are defined as uniform `mat4`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this shader, we have defined three matrices:'
  prefs: []
  type: TYPE_NORMAL
- en: '`uModelViewMatrix`: The Model-View matrix'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`uProjectionMatrix`: The Projection matrix'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`uNormalMatrix`: The Normal matrix'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In ESSL, the multiplication of matrices is straightforward; that is, you do
    not need to multiply element by element. ESSL knows that you are working with
    matrices, so it performs the multiplications for you:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The last line of this shader assigns a value to the predefined `gl_Position` variable.
    This will contain the clipping coordinates for the vertex that is currently being
    processed by the shader. We need to remember that the shaders work in parallel:
    each vertex is processed by an instance of the vertex shader.'
  prefs: []
  type: TYPE_NORMAL
- en: To obtain the clipping coordinates for a given vertex, we first need to multiply
    the Model-View matrix by the Projection matrix. To achieve this, we multiply from
    right to left, because matrix multiplication is not commutative and order matters.
  prefs: []
  type: TYPE_NORMAL
- en: Also, notice that we needed to augment the `aVertexPosition` attribute by including
    the Homogeneous coordinate. This is because we have defined our geometry in Euclidean
    space. Luckily, ESSL allows us to do this by simply adding the missing component
    and creating a `vec4` on the fly. We need to do this because both the Model-View
    matrix and the Projection matrix are described in Homogeneous coordinates (`4`
    rows by `4` columns).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we''ve seen how to map JavaScript matrices to ESSL uniforms in our
    shaders, let''s talk about how to operate with the three matrices: the Model-View
    matrix, the Normal matrix, and the Projection matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: The Model-View Matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Model-View matrix** allows us to perform *affine transformations* in our
    scene. **Affine** is a mathematical name that describes transformations that do
    *not* change the structure of the object undergoing such transformations. In our
    3D world scene, such transformations are rotation, scaling, reflection shearing,
    and translation. Fortunately, we do not need to understand how to represent such
    transformations with matrices. We just need to use one of the many JavaScript
    matrix libraries that are available online (such as **glMatrix**).
  prefs: []
  type: TYPE_NORMAL
- en: Affine Transformations
  prefs: []
  type: TYPE_NORMAL
- en: You can find more information on how transformation matrices work at [https://en.wikipedia.org/wiki/Affine_transformation](https://en.wikipedia.org/wiki/Affine_transformation).
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the structure of the Model-View matrix will not help you if you
    just want to apply transformations to the scene or to objects in the scene. For
    that effect, simply use a library, such as **glMatrix**, to do the transformations
    on your behalf. However, the structure of this matrix could be invaluable information
    when you are trying to troubleshoot your 3D application. Let's take a look at
    how the Model-View matrix is constructed.
  prefs: []
  type: TYPE_NORMAL
- en: Spatial Encoding of the World
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By default, when you render a scene, you are looking at it from the origin
    of the world in the negative direction of the z-axis. As shown in the following
    diagram, the z-axis is coming out of the screen (which means that you''re looking
    at the negative z-axis):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2cbdaa70-dc4a-437e-9eee-ca17e62fa791.png)'
  prefs: []
  type: TYPE_IMG
- en: From the center of the screen to the right, you will have the positive x-axis,
    and from the center of the screen up, you will have the positive y-axis. This
    is the initial configuration and it is the reference for affine transformations.
  prefs: []
  type: TYPE_NORMAL
- en: In this configuration, the Model-View matrix is the **Identity matrix** of rank
    four.
  prefs: []
  type: TYPE_NORMAL
- en: The first three rows of the Model-View matrix contain information about rotations
    and translations that are affecting the world.
  prefs: []
  type: TYPE_NORMAL
- en: Rotation Matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The intersection of the first three rows with the first three columns defines
    the 3x3 Rotation matrix. This matrix contains information about rotations around
    the standard axis. In the initial configuration, this corresponds to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`[m1, m2, m3]` = `[1, 0, 0]` = x-axis'
  prefs: []
  type: TYPE_NORMAL
- en: '`[m5, m6, m7]` = `[0, 1, 0]` = y-axis'
  prefs: []
  type: TYPE_NORMAL
- en: '`[m9, m10, m11]` = `[0, 0, 1]` = z-axis'
  prefs: []
  type: TYPE_NORMAL
- en: Translation Vector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The intersection of the first three rows with the last column defines a three-component
    Translation vector. This vector indicates how much the origin, and the world,
    have been translated. In the initial configuration, this corresponds to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`[m13, m14, m15]` = `[0, 0, 0]` = origin (no translation)'
  prefs: []
  type: TYPE_NORMAL
- en: The Mysterious Fourth Row
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The fourth row does not have any special meaning.
  prefs: []
  type: TYPE_NORMAL
- en: The `m4`, `m8`, and `m12`elementsare always `0`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `m16`element(the Homogeneous coordinate) will always be `1`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we described at the beginning of this chapter, there are no cameras in WebGL.
    However, all the information that we need to operate a camera (mainly rotations
    and translations) can be extracted from the Model-View matrix itself.
  prefs: []
  type: TYPE_NORMAL
- en: The Camera Matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's say, for a moment, that we *do* have a camera in WebGL. A camera should
    be able to rotate and translate to explore this 3D world. As we saw in the previous
    section, a 4x4 matrix can encode rotations and translations. Therefore, you should
    use one such matrix to represent our hypothetical camera.
  prefs: []
  type: TYPE_NORMAL
- en: Let's assume that our camera is located at the origin of the world and that
    it's oriented so that it's looking toward the negative z-axis direction. This
    is a good starting point; we already know what transformation represents such
    a configuration in WebGL (Identity matrix of rank four).
  prefs: []
  type: TYPE_NORMAL
- en: 'For the sake of analysis, let''s break the problem down into two subproblems:
    camera-translation and camera-rotation. We will have a practical demo for each
    one.'
  prefs: []
  type: TYPE_NORMAL
- en: Camera Translation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s move the camera to `[0, 0, 4]` in world coordinates. This means four
    units from the origin on the positive z-axis. Remember, at this point, we do not
    know about a matrix that moves the camera. We only know how to move the *world* (with
    the Model-View matrix). If we applied:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In such a case, the world would be translated `4` units on the positive z-axis,
    and since the camera position has not been changed, it would be located at `[0,
    0, -4]`, which is exactly the opposite of what we want.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, say that we applied the translation in the opposite direction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: In such a case, the world would be moved `4` units on the negative z-axis and
    then the camera would be located at `[0, 0, 4]` in the new world-coordinate system.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will explore translations in both world space and
    camera space.
  prefs: []
  type: TYPE_NORMAL
- en: 'Time for Action: Translations in World Space vs Camera Space'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s cover an example showcasing these differences in action:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open `ch04_01_model-view-translation.html` in your browser:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/045a2200-5097-476d-aad1-c2d9e1bffa29.png)'
  prefs: []
  type: TYPE_IMG
- en: From a distance, we are looking at the positive z-axis of a cone located at
    the origin of the world. There are three sliders that allow you to translate either
    the world or the camera on the `x`, `y`, and `z` axes, respectively. The world
    space is activated by default.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By looking at the World matrix on the screen, can you tell where the origin
    of the world is? Is it `[0, 0, 0]`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hint
  prefs: []
  type: TYPE_NORMAL
- en: Check where we define translations in the Model-View matrix.
  prefs: []
  type: TYPE_NORMAL
- en: We can think of the `canvas` as the image that our camera sees. If the world's
    center is at `[0, -2, -50]`, where is the camera?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If we want to get closer to the cone, we need to move the center of the world
    toward the camera. We know that the camera is far on the positive z-axis of the
    world, so the translation will occur on the z-axis. Given that we are on world
    coordinates, do we need to increase or decrease the z-axis slider? Go ahead and
    test your answer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Switch to camera coordinates. What is the translation component of this matrix?
    What do you need to do if you want to move the camera closer to the cone? What
    does the final translation look like? What can you conclude?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Try to move the camera on the x-axis and the y-axis. Check what the corresponding
    transformations would be on the Model-View matrix.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '***What just happened?***'
  prefs: []
  type: TYPE_NORMAL
- en: We saw that the camera translation is the inverse of the Model-View matrix translation.
    We also learned where to find translation information in a transformation matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Camera Rotation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similarly, if we want to rotate the camera, say, `45` degrees to the right,
    this would be equivalent to rotating the world `45` degrees to the left. Using **glMatrix** to
    achieve this, we can write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to the previous section where we explored translations, in the *Time
    for Action: Rotations in World Space vs Camera Space* section, we will experiment
    with rotations in both world and camera spaces. Let''s see this behavior in action!'
  prefs: []
  type: TYPE_NORMAL
- en: 'Time for Action: Rotations in World Space vs Camera Space'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s cover an example showing the different rotations in different spaces:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open `ch04_02_model-view-rotation.html` in your browser:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b58a3fc1-8141-4ecf-b641-856e83194a2b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As we did in the previous example, we will see the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A cone at the origin of the world
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The camera is located at `[0, 2, 50]` in world coordinates
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Three sliders that allow us to rotate either the world or the camera
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A matrix where we can see the result of different rotations
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's see what happens to the axis after we apply a rotation. With the **World **coordinates
    selected, rotate the world `90` degrees around the x-axis. What does the Model-View
    matrix look like?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s see where the axes end up after a `90` degree rotation around the x-axis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By looking at the first column, we can see that the x-axis has not changed.
    It's still `[1, 0, 0]`. This makes sense since we are rotating around this axis.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The second column of the matrix indicates where the y-axis is after the rotation.
    In this case, we went from `[0, 1, 0]`, which is the original configuration, to
    `[0, 0, 1]`, which is the axis that is coming out of the screen. This is the z-axis
    in the initial configuration. This makes sense since we are now looking from above,
    down at the cone.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The third column of the matrix indicates the new location of the z-axis. It
    changed from `[0, 0, 1]`, which as we know, is the z-axis in the standard spatial
    configuration (without transforms), to `[0, -1, 0]`, which is the negative portion
    of the y-axis in the original configuration. This makes sense since we rotated
    around the x-axis:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/550f79c0-2aae-40c1-acdd-53533394c9b2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As we''ve just seen, understanding the rotation matrix (the 3x3 upper-left
    corner of the Model-View matrix) is simple: the first 3 columns always tell us
    where the axis is.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Where are the axes in the following transformation? Take a look at the following
    diagram:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/66b15f33-519b-4d5a-b1f8-e3c1ae04d520.png)'
  prefs: []
  type: TYPE_IMG
- en: Check your answer by using the sliders to achieve the rotation that you believe
    produces this matrix.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let's see how rotations work in **Camera **space by changing the coordinates,
    selection.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increase the angle of rotation in the x-axis by incrementing the slider position.
    What do you notice?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the sliders, try different rotations in camera space.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are the rotations *commutative*? That is, do you get the same result if you
    rotate, for example, `5` degrees on the x-axis and `90` degrees on the z-axis,
    compared to the case where you rotate `90` degrees on the z-axis and then `5`
    degrees on the x-axis?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Return to World space. Please remember that when you're in World space, you
    need to reverse the rotations to obtain the same pose, for example, if you were applying
    `5` degrees on the x-axis and `90` degrees on the z-axis, verify that when you
    apply `-5` degrees on the x-axis and `-90` degrees on the z-axis, you obtain the
    same result.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '***What just happened?***'
  prefs: []
  type: TYPE_NORMAL
- en: We've just learned that the Camera matrix rotation is the inverse of the Model-View
    matrix rotation. We've also learned how to identify the orientation of our world
    or camera after analyzing the rotation matrix (3x3 upper-left corner of the correspondent
    transformation matrix).
  prefs: []
  type: TYPE_NORMAL
- en: 'Have a Go: Combining Rotations and Translations'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how we can combine rotations and translations together:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ch04_03_model-view.html` file contains the combination of rotations and
    translations. When you open it your browser, you will see something like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3217cdd4-7f3c-4dfe-9a47-8f5ce6254b89.png)'
  prefs: []
  type: TYPE_IMG
- en: Try different configurations of rotations and translations in both the **World **and **Camera** spaces.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Camera Matrix Is the Inverse of the Model-View Matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These two scenarios help us appreciate that a Camera matrix is the exact opposite
    of the Model-View matrix. In linear algebra, this property is known as the **inverse** of
    a matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'The inverse of a matrix is such that when multiplying it by the original matrix,
    we obtain the Identity matrix. In other words, if `M` is the Model-View matrix
    and `C` is the Camera matrix, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create the Camera matrix using **glMatrix** by writing something like
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Thinking About Matrix Multiplications in WebGL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before moving forward, we should note that in WebGL, matrix operations are written
    in the *reverse order* in which they are applied to the vertices. This is an important
    note that's often confusing for developers new to 3D graphics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s assume, for a moment, that you are writing the code to rotate/move the
    world; that is, you rotate your vertices around the origin and then you move away.
    The final transformation would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: Here, `R` is the 4x4 matrix-encoding pure rotation;  `T` is the 4x4 matrix-encoding
    pure translation, and `v` corresponds to the vertices present in your scene (in
    Homogeneous coordinates).
  prefs: []
  type: TYPE_NORMAL
- en: Now, you should have noticed that the first transformation we apply to the vertices
    is the translation, and then we apply the rotation. Vertices need to be multiplied
    first by the matrix that is to the left. In this scenario, that matrix is `T`.
    Then, the result needs to be multiplied by `R`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This fact is reflected in the order of the operations (here, `modelViewMatrix` is
    the Model-View matrix):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'If we were working in camera coordinates and we wanted to apply the same transformation
    as before, we need to apply a bit of linear algebra first:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `![](img/9939b32a-17f2-4507-9908-c217f9f203e7.png)` | The Model-View `M` matrix
    is the result of multiplying rotation and translation together. |'
  prefs: []
  type: TYPE_TB
- en: '| `![](img/26b36e70-d5d1-4191-aaa2-53d7cf4bbbdf.png)` | We know that the Camera
    matrix is the inverse of the Model-View matrix. |'
  prefs: []
  type: TYPE_TB
- en: '| `![](img/7f5d4ad7-8a38-4b86-ae6d-42d714b82152.png)` | By substitution. |'
  prefs: []
  type: TYPE_TB
- en: '| `![](img/f6ad6044-8aac-4a75-8262-21f97d2c571a.png)` | The inverse of a matrix
    product is the reverse product of the inverses. |'
  prefs: []
  type: TYPE_TB
- en: 'Fortunately, when we''re working in camera coordinates in this chapter''s examples,
    we have the inverse translation and the inverse rotation already calculated in
    the global variables position and rotation. Therefore, we would write something
    such as this in the code (here, `cameraMatrix` is the Camera matrix):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Basic Camera Types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will discuss the following two camera types:'
  prefs: []
  type: TYPE_NORMAL
- en: Orbiting camera
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracking camera
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orbiting Camera
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we've learned how to generate rotations and translations in either world
    or camera coordinates. In both cases, however, we are always generating the rotations
    around the center of the world. This may be ideal when we're orbiting around a
    3D object, such as our car model. In that example, you put the object at the center
    of the world, and then examine the object at different angles (rotation); after
    that, you can move away (translation) to see the result. We will refer to this
    type of camera as an **orbiting camera**.
  prefs: []
  type: TYPE_NORMAL
- en: Tracking Camera
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If we return to the example of the first-person shooting game, we need to have
    a camera that can look up when we want to check whether there are enemies above
    us. We should also be able to look left and right (rotations) and then move in
    the direction in which our camera is pointing (translation). This camera type
    can be designated as a **first-person** camera. This same type is used when the
    game follows the main character. Therefore, it is generally known as a **tracking
    camera**.
  prefs: []
  type: TYPE_NORMAL
- en: To implement first-person cameras, we need to set up the rotations on the camera
    axis instead of using the world origin.
  prefs: []
  type: TYPE_NORMAL
- en: Rotating the Camera Around Its Location
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When multiplying matrices, the order in which we multiply them is relevant.
    Say, for instance, we have two 4x4 matrices. Let `R` be the first matrix and let''s
    assume that this matrix encodes pure rotation; let `T` be the second matrix and
    let''s assume that `T` encodes pure translation. Now:'
  prefs: []
  type: TYPE_NORMAL
- en: In other words, the order of the operations affects the result. It is not the
    same to rotate around the origin and then translate away from it (orbiting camera),
    as compared to translating the origin and then rotating around it (tracking camera)!
    Your success depends on understanding this critical difference.
  prefs: []
  type: TYPE_NORMAL
- en: In order to set the location of the camera as the center for rotations, we need
    to invert the order in which operations are called. This is equivalent to converting
    from an orbiting camera to a tracking camera.
  prefs: []
  type: TYPE_NORMAL
- en: Translating the Camera in the Line of Sight
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With an orbiting camera, the camera will always look toward the center of the
    world. Therefore, we will always use the z-axis to move to and from the object
    we are examining. However, with a tracking camera, since the rotation occurs at
    the camera location, we can end up looking to any position in the world (which
    is ideal if you want to move around and explore it). Thus, we need to know the
    direction in which the camera is pointing in world coordinates (camera axis).
    We will see how to obtain this next.
  prefs: []
  type: TYPE_NORMAL
- en: The Camera Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Just like its counterpart, the Model-View matrix, the Camera matrix encodes
    information about the camera orientation. As we can see in the following diagram,
    the upper-left 3x3 matrix corresponds to the camera axes:'
  prefs: []
  type: TYPE_NORMAL
- en: The first column corresponds to the x-axis of the camera. We will call it `RightVector`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second column is the y-axis of the camera. This will be `UpVector`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third column determines the vector in which the camera can move back and
    forth. This is the z-axis of the camera and we will call it `CameraAxis`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Because the Camera matrix is the inverse of the Model-View matrix, the upper-left
    3x3 rotation matrix contained in the Camera matrix gives us the orientation of
    the camera axes in world space. This is a plus, because it means that we can tell
    the orientation of our camera in world space just by looking at the columns of
    this 3x3 rotation matrix (and we now know what each column means):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eab3b14f-8d24-47d3-b581-e454c012cbc3.png)'
  prefs: []
  type: TYPE_IMG
- en: In the following section, we will play with orbiting and tracking cameras to
    see how we can change the camera position using mouse gestures and sliders. In
    addition, we will look at a graphical representation of the resulting Model-View
    matrix. In this exercise, we will integrate both rotations and translations and
    we will see how they behave under the two basic types of cameras we are studying.
  prefs: []
  type: TYPE_NORMAL
- en: 'Time for Action: Exploring the Showroom'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s cover an example covering various camera types:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the `ch04_04_camera-types.html` file in your browser. You will see something
    like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/fb4de108-cebd-42b7-ac5c-f233ebd5693e.png)'
  prefs: []
  type: TYPE_IMG
- en: Go around the world using the sliders in Trackingmode. Cool, huh?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the camera type to Orbitingmode and do the same.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check that besides the slider controls, both in Trackingand Orbiting mode, you
    can use your mouse and keyboard to move around the world.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In this exercise, we have implemented a camera using two new classes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Camera`: To manipulate the camera.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Controls`: To connect the camera to the `canvas`. The `canvas` will now receive
    mouse and keyboard events and pass them along to the camera.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are curious, you can see the source code of these two classes in the
    `common/js` directory. We have applied the concepts explained in this chapter
    to build these two classes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: So far, we have seen a cone in the center of the world. As we explore, let's
    change it to something more interesting. Open the file `ch04_04_camera-types.html` file
    in your source code editor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Go to the `load` function. Let''s add the car to the scene. Rewrite the contents
    of this function to the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: You will see that we've increased the size of the axis and the floor so that
    we can see them. We need to do this because the car model is a much larger object
    than the original cone.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'There are a few steps we need to take in order to see the car correctly. We
    need to make sure that we have a large enough view volume. Go to the `updateTransforms`
    function and update this line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Replace it with this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Change the type of camera so that when we load the page, we have an orbiting
    camera by default. In the `configure` function, change this line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Replace it with this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Another thing we must consider is the location of the camera. For a large object
    such as this car, we need to be farther away from the center of the world. For
    that purpose, we need to change the home location of `camera.goHome` from `[0,
    2, 50]` to `[0, 25, 300]`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s modify our scene''s lighting so that it better fits into the model we
    are displaying. In the `configure` function, update the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Replace it with this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Save the file with a different name and then load this new file in your browser.
    You should see something like the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3aed3547-ab9c-46ca-978c-38cb4712309b.png)'
  prefs: []
  type: TYPE_IMG
- en: Using the mouse, keyboard, and/or the sliders, explore the new scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use orbiting mode to explore the car from different angles.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: See how the Camera matrix is updated when you move around the scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can see what the final exercise looks like by opening the `ch04_05_car.html` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '***What just happened?***'
  prefs: []
  type: TYPE_NORMAL
- en: We added mouse and keyboard interaction to our scene. We also experimented with
    the two basic camera types: *tracking* and *orbiting* cameras. Finally, we modified
    the settings of our scene to visualize a complex model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Have a Go: Updating Light Positions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we've seen, by moving the camera, we're applying the inverse transformation
    to the world. If we do not update the light position, the light source will be
    located at the same static point, regardless of the final transformation applied
    to the world.
  prefs: []
  type: TYPE_NORMAL
- en: This is very convenient when we're moving around or exploring an object in the
    scene. We can always see whether the light is located on the same axis of the
    camera. This is the case for the exercises in this chapter. Nevertheless, we can
    also simulate the case when the camera movement is independent from the light
    source. To do so, we need to calculate the new light position whenever we move
    the camera.
  prefs: []
  type: TYPE_NORMAL
- en: First, we calculate the light direction. We can do this by simply calculating
    the difference vector between our target and our origin. Say the light source
    is located at `[0, 2, 50]`. If we want to direct our light source toward the origin,
    we calculate the `[0, 0, 0] - [0, 2, 50]` vector *(target - origin)*. This vector
    has the correct orientation of the light when we target the origin. We repeat
    the same procedure if we have a different target that needs to be lit. In that
    case, we just use the coordinates of the target and from them, we subtract the
    location of the light.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we are directing our light source toward the origin, we can find the direction
    of the light just by inverting the light position. As you may have noticed, we
    do this in ESSL in the vertex shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'As `light` is a vector, if we want to update the direction of the light, we
    need to use the Normal matrix, discussed earlier in this chapter, to update this
    vector under any world transformation. This step is optional in the vertex shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In the previous fragment of code, light is augmented to four components, so
    we can use the direct multiplication provided by ESSL. (Remember that `uNormalMatrix` is
    a 4x4 matrix and, as such, the vectors it transforms need to be four-dimensional.)
    Please bear in mind that, as explained at the beginning of this chapter, the Homogeneous
    coordinates of vectors are always set to `0`, while the Homogeneous coordinates
    of vertices are set to `1`.
  prefs: []
  type: TYPE_NORMAL
- en: After the multiplication, we reduce the result to three components before assigning
    the result back to light.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can test the effects of updating the light position by using the `Static
    Light Position` button, provided in the `ch04_05_car.html` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We connect a global variable that keeps track of the state of this button with
    the `uUpdateLight` uniform.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Edit `ch04_05_car.html` and set the light position to a different location.
    To do this, edit the configure function. Go to the following position:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Try different light positions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`[2120, 0, 0]`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`[0, 2120, 0]`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`` `[100, 100, 100]` ``'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For each option, save the file and try it with and without updating the light
    position (use the `Static Light Position` button):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e7f5ba57-bda1-4a0f-93c8-fbb99a68b10d.png)'
  prefs: []
  type: TYPE_IMG
- en: For a better visualization, use an **Orbiting **camera.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Projection matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the beginning of this chapter, we learned that the **Projection matrix**
    combines the projection transformation and the perspective division. These two
    steps take a 3D scene and convert it into a cube, which is then mapped to the
    2D `canvas` by the viewport transformation.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, the Projection matrix determines the geometry of the image that
    is captured by the camera. In a real-world camera, the lens of the camera would
    determine how distorted the final images are. In a WebGL world, we use the Projection
    matrix to simulate that effect. Also, unlike in the real world where our images
    are always affected by perspective, in WebGL, we can pick a different representation
    (such as the orthographic projection).
  prefs: []
  type: TYPE_NORMAL
- en: Field of View
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Projection matrix determines the **field of view** (**FOV**) of the camera,
    that is, how much of the 3D space will be captured by the camera. The field of
    view is a measure given in degrees, and the term is used interchangeably with
    the term **angle of view**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f51e256f-69dd-4828-b355-86e1d7969e46.png)'
  prefs: []
  type: TYPE_IMG
- en: Perspective or Orthogonal Projection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A perspective projection assigns more space to details that are closer to the
    camera than details that are farther away. In other words, the geometry that is
    close to the camera will appear larger than the geometry that is farther from
    it. This is the way our eyes see the real world. Perspective projection allows
    us to assess the distance because it gives our brain a *depth cue*.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, an orthogonal projection uses parallel lines; this means that lines
    will appear to be the same size, regardless of their distance to the camera. Therefore,
    the depth cue is lost when using orthogonal projection.
  prefs: []
  type: TYPE_NORMAL
- en: While perspective projection offers a more realistic view of the scene, orthographic
    is commonly used in engineering as a means to produce object specifications that
    communicate dimensions unambiguously. Each line of one unit length (cm, meter)
    will appear to have the same length everywhere on the drawing. This allows the
    drafter to dimension only a subset of lines and let the reader know that other
    lines of that length on the drawing are also that length in reality. Every parallel
    line in the drawing is also parallel in the object.
  prefs: []
  type: TYPE_NORMAL
- en: If you are looking at a larger scene with buildings, then orthographic rendering
    gives an exact measure of the distance between the buildings and their relative
    sizes.
  prefs: []
  type: TYPE_NORMAL
- en: With perspective mode, lines of identical real-world lengths will appear different
    due to foreshortening. It becomes difficult to judge relative dimensions and object
    size in the distance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using **glMatrix**, we can set up the perspective or the orthogonal projection
    by calling `mat4.perspective` or `mat4.ortho`, respectively. The signatures for
    these methods are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Function** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '| Generates a perspective projection matrix with the given bounds.**Parameters:**'
  prefs: []
  type: TYPE_NORMAL
- en: '`dest`: `mat4` frustum the matrix will be written into'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fovy`: Vertical field of view'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`aspect`: Aspect ratio, typically the `width / height` viewport'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`near`, `far`: Near and far bounds of the frustum'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '| Generates an orthogonal projection matrix with the given bounds:**Parameters:**'
  prefs: []
  type: TYPE_NORMAL
- en: '`dest`: `mat4` frustum the matrix will be written into'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`left`, `right`: Left and right bounds of the frustum'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bottom`, `top`: Bottom and top bounds of the frustum'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`near`, `far`: Near and far bounds of the frustum'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the *Time for Action: Orthographic and Perspective Projections* section,
    we will test how the field of view and the perspective projection affect the image
    that our camera captures. We will experiment with perspective and orthographic
    projections for both orbiting and tracking cameras.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Time for Action: Orthographic and Perspective Projections'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at an example covering the different types of projections:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `ch04_06_projection-modes.html` file in your browser.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This exercise is very similar to the previous one. However, there are two new
    options under Projection Mode: Perspective and Orthogonal Projection. As you can
    see, Perspectiveis activated by default.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the camera type to Orbiting.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the projective mode to Orthographic.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Explore the scene. Notice the lack of the depth cues characteristic of orthogonal
    projections:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d8173bc0-3ec2-4833-85b1-bddb0d1e8d6b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Switch to Perspective mode:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3c05ed7f-ab40-49e3-8132-904154678bb6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Explore the source code. Go to the `updateTransforms` function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Take a look at the parameters we are using to set up the projective view.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Notice that as you increase the field of view (`fov`), your camera will capture
    more of the 3D space. Think of this as the lens of a real-world camera. With a
    wide-angle lens, you capture more space with the tradeoff of deforming the objects
    as they move toward the boundaries of your viewing box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '***What just happened?***'
  prefs: []
  type: TYPE_NORMAL
- en: We experimented with different configurations for the Projection matrix and
    we saw how these configurations produce different results in the scene.
  prefs: []
  type: TYPE_NORMAL
- en: 'Have a Go: Integrating the Model-View and the Projective Transform'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Recall that once we''ve applied the Model-View transformation to the vertices,
    the next step is to transform the view coordinates to NDC coordinates:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d9523810-bf63-4ea2-9b26-7cac86821c59.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We do this by simple multiplication by using ESSL in the vertex shader:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The predefined variable, `gl_Position`, stores the NDC coordinates for each
    vertex of every object defined in the scene.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous multiplication, we augment the shader attribute, `aVertexPosition`,
    to a 4-component vertex because our matrices are 4x4\. Unlike normals, vertices
    have a Homogeneous coordinate equal to one (`w=1`).
  prefs: []
  type: TYPE_NORMAL
- en: 'After this step, WebGL will convert the computed clipping coordinates to normalized
    device coordinates and from there to `canvas` coordinates using the WebGL `viewport` function.
    Let''s see what happens when we change this mapping:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `ch04_06_projection-modes.html` file in your source code editor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go to the `draw` function. This is the rendering function that is invoked every
    time we interact with the scene (by using the mouse, the keyboard, or the widgets
    on the page).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Find the following line:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Try each of the following three operations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: For each option, save the file and open it on your browser.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What do you see? Please note that you can interact with the scene just like
    before.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Structure of the WebGL Examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have improved the structure of the code examples in this chapter. As the
    complexity of our WebGL applications increases, it is wise to have a good, maintainable,
    and clear design. We have saved this section until the end of this chapter so
    that you can use it as a reference when working on the exercises.
  prefs: []
  type: TYPE_NORMAL
- en: Just as in previous exercises, our entry point is the `init` function, which
    is called when the page is loaded. We have included several `scripts` in the `head`
    of our document that point to various components to build our 3D application.
  prefs: []
  type: TYPE_NORMAL
- en: Supporting Objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have created the following components, each one in its own file inside the
    `common/js` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Program.js`: Creates the program using the shader definitions. Provides the
    mapping between JavaScript variables (`program.*`) and program attributes and
    uniforms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Scene.js`: Maintains a list of objects to be rendered. Contains the AJAX/JSON
    functionality to retrieve remote objects. It also allows us to add local objects
    to the scene.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Floor.js`: Defines a grid on the X-Z plane. This object is added to `scene`
    to have a reference to the floor and its properties'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Axis.js`: Represents the axis in world space. When added to `scene`, we will
    have a reference to the origin.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Camera.js`: Creates a camera instance to manipulate the various matrices and
    operations covered in this chapter with a simple interface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`EventEmitter.js`: A simple pub-sub event emitter for decoupling various components
    in our WebGL application. Instead of passing hard references around between unrelated
    functionality, we can leverage the pub-sub pattern to emit and listen to actions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Clock.js`: A simple class that abstracts away the `requestAnimationFrame`
    API to have the entire WebGL application update from a single source of truth
    (such as `clock`).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: requestAnimationFrameThe `window.requestAnimationFrame()` method tells the browser
    that you wish to perform an animation and requests that the browser call a specified
    function to update an animation before the next repaint. This will request that
    your animation function be called before the browser performs the next repaint.
  prefs: []
  type: TYPE_NORMAL
- en: '`Controls.js`: Provides the ability to capture various `canvas` DOM events
    to drive interactions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`utils.js`: Utility functions that we covered in earlier chapters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although we have enough foundation to understand how each components works,
    we will cover each component in [Chapter 9](fe7815dc-66ca-4ee5-9d88-9b7d840509a3.xhtml)*,
    Putting It All Together*. That being said, if you can't wait, feel free to inspect
    the source code to get an idea of what's to come.
  prefs: []
  type: TYPE_NORMAL
- en: Life Cycle Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following functions define the life cycle of a WebGLApp application.
  prefs: []
  type: TYPE_NORMAL
- en: The configure Function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `configure` function sets some parameters of our `gl` context, such as the
    color for clearing the `canvas`. After configuring the necessary states.
  prefs: []
  type: TYPE_NORMAL
- en: The load Function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `load` function sets up objects to be added to our `scene`. For example,
    the two locally-created objects, `floor` and `axis`, are added to `scene` by calling
    the `add` method. After that, a remote object (AJAX call) is loaded using the
    `scene.load` method.
  prefs: []
  type: TYPE_NORMAL
- en: The draw Function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `draw` function calls `updateTransforms` to calculate the matrices for the
    new position (that is, when we move), and then iterates over the objects in `scene` to
    render them. Inside this loop, it calls `setMatrixUniforms` for every object to
    be rendered.
  prefs: []
  type: TYPE_NORMAL
- en: Matrix-Handling Functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Open up `ch04_02_model-view-rotation.html` in your editor. The following are
    the functions that initialize, update, and pass matrices to the shaders.
  prefs: []
  type: TYPE_NORMAL
- en: initTransforms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you can see, the Model-View matrix, the Camera matrix, the Projection matrix,
    and the Normal matrix are set up here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: updateTransforms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In `updateTransforms`, we use the contents of the global variables'' position and rotation to
    update the matrices. This is, of course, as follows::'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: setMatrixUniforms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This function performs the mapping:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s summarize what we''ve learned in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: There is no camera object in WebGL. However, we can build one using the Model-View
    matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3D objects undergo several transformations to be displayed on a 2D screen. These
    transformations are represented as 4x4 matrices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Scene transformations are affine. Affine transformations are constituted by
    a linear transformation followed by a translation. The WebGL groups affine transforms
    into three matrices: the Model-View matrix, the Projection matrix, and the Normal
    matrix, and one WebGL operation: `gl.viewport()`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Affine transforms are applied in projective space, so they can be represented
    by 4x4 matrices. To work in projective space, vertices need to be augmented to
    contain an extra term, namely `w`, which is called the perspective coordinate.
    The four-tuple `(x, y, z, w)` is called Homogeneous coordinates. Homogeneous coordinates
    allow representation of lines that intersect on infinity by making the perspective
    coordinate `w = 0`. Vectors always have a Homogeneous coordinate, `w = 0`, while
    points have a Homogeneous coordinate, namely, `w = 1` (unless they are at infinity,
    in which case `w = 0`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By default, a WebGL scene is viewed from the world origin in the negative direction
    of the z-axis. This can be altered by changing the Model-View matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Camera matrix is the inverse of the Model-View matrix. The camera and world
    operations are opposites. There are two basic types of cameras: *orbiting* and
    *tracking*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normals receive special treatment whenever the object undergoes an affine transform.
    Normals are transformed by the Normal matrix, which can be obtained from the Model-View
    matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Projection matrix allows us to determine two basic projective modes: *orthographic*
    projection and *perspective* projection.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next chapter, we will take what we've learned here about transformations
    to distinguish between global and local transformations. We will look at transformations
    that are *global*, as we've covered here, and transformations that are *local* to
    individual objects in our 3D scene.
  prefs: []
  type: TYPE_NORMAL
