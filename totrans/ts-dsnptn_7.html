<html><head></head><body><div class="chapter" title="Chapter&#xA0;9.&#xA0;The Road to Enterprise Application"><div class="titlepage"><div><div><h1 class="title"><a id="ch09"/>Chapter 9. The Road to Enterprise Application</h1></div></div></div><p>After walking through common design patterns, we have now the basis of code designing. However, software engineering is more about writing beautiful code. While we are trying to keep the code healthy and robust, we still have a lot to do to keep the project and the team healthy, robust, and ready to scale. In this chapter, we'll talk about popular elements in the workflow of web applications, and how to design a workflow that fits your team.</p><p>The first part would be setting up the build steps of our demo project. We'll quickly walk through how to build frontend projects with <span class="emphasis"><em>webpack</em></span>, one of the most popular packaging tools these days. And we'll configure tests, code linter, and then set up continuous integration.</p><p>There are plenty of nice choices when it comes to workflow integration. Personally, I prefer Team Foundation Server for private projects or a combination of GitHub and Travis-CI for open-source projects. While Team Foundation Server (or Visual Studio Team Services as its cloud-based version) provides a one-stop solution for the entire application life cycle, the combination of GitHub and Travis-CI is more popular in the JavaScript community. In this chapter, we are going use the services provided by GitHub and Travis-CI for our workflow.</p><p>Here are what we are going to walk through:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Packaging frontend assets with webpack.</li><li class="listitem" style="list-style-type: disc">Setting up tests and linter.</li><li class="listitem" style="list-style-type: disc">Getting our hands on a Git flow branching model and other Git-related workflow.</li><li class="listitem" style="list-style-type: disc">Connecting a GitHub repository with Travis-CI.</li><li class="listitem" style="list-style-type: disc">A peek into automated deployment.</li></ul></div><div class="section" title="Creating an application"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec53"/>Creating an application</h1></div></div></div><p>We've talked about creating TypeScript applications for both frontend and backend projects in the <a class="link" href="ch01.html" title="Chapter 1. Tools and Frameworks">Chapter 1</a>, <span class="emphasis"><em>Tools and Frameworks</em></span>. And now we are going to create an application that contains two TypeScript projects at the same time.</p><div class="section" title="Decision between SPA and &quot;normal&quot; web applications"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec132"/>Decision between SPA and "normal" web applications</h2></div></div></div><p>Applications for different purposes result in different choices. SPA (single page application) usually delivers a better user experience after being loaded, but it can also lead to trade-offs on SEO and may rely on more complex MV* frameworks like Angular.</p><p>One solution to build SEO-friendly SPA is to build a universal (or isomorphic) application that runs the <span class="emphasis"><em>same</em></span> code on both frontend and backend, but that could introduce even more complexity. Or a reverse proxy could be configured to render automatically generated pages with the help of tools like <span class="emphasis"><em>Phantom</em></span>.</p><p>In this demo project, we'll choose a more traditional web application with multiple pages to build. And here's the file structure of the client project:</p><p>
</p><div class="mediaobject"><img src="graphics/image_09_001.jpg" alt="Decision between SPA and &quot;normal&quot; web applications"/></div><p>
</p></div><div class="section" title="Taking team collaboration into consideration"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec133"/>Taking team collaboration into consideration</h2></div></div></div><p>Before we actually start creating a real-world application, we need to come up with a reasonable application structure. A proper application structure is more than something under which the code compiles and runs. It should be a result, taking how your team members work together into consideration.</p><p>For example, a naming convention is involved in this demo client structure shown earlier: page assets are named after page names instead of their types (for example, <code class="literal">style.scss</code>) or names like <code class="literal">index.ts</code>. And the consideration behind this convention is making it more friendly for file navigation by the keyboard.</p><p>Of course, this consideration is valid only if a significant number of developers in your team are cool with keyboard navigation. Other than operation preferences, the experiences and backgrounds of a team should be seriously considered as well:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Should the "full-stack" mode be enabled for your team?</li><li class="listitem" style="list-style-type: disc">Should the "full-stack" mode be enabled for every engineer in your team?</li><li class="listitem" style="list-style-type: disc">How should you divide work between frontend and backend?</li></ul></div><p>Usually, it's not necessary and not efficient to limit the access of a frontend engineer to client-side development. If it's possible, frontend engineers could take over the controller layer of the backend and leave hardcore business models and logic to engineers that focus more on the backend.</p><p>We are having the client and server-side projects in the same repository for an easier integration during development. But it does not mean everything in the frontend or backend code base should be in this single repository. Instead, multiple modules could be extracted and maintained by different developers in practice. For example, you can have database models and business logic models separated from the controllers on the backend.</p></div></div></div>
<div class="section" title="Building and testing projects"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec54"/>Building and testing projects</h1></div></div></div><p>We have already talked about building and testing TypeScript projects at the beginning of this book. In this section, we will go a little bit further for frontend projects, including the basis of using Webpack to load static assets as well as <span class="strong"><strong>code linting</strong></span>.</p><div class="section" title="Static assets packaging with webpack"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec134"/>Static assets packaging with webpack</h2></div></div></div><p>Modularizing helps code keep a healthy structure and makes it maintainable. However, it could lead to performance issues if development-time code written in <span class="emphasis"><em>small</em></span> modules are directly deployed without bundling for production usage. So static assets packaging becomes a serious topic of frontend engineering.</p><p>Back to the old days, packaging JavaScript files was just about <span class="emphasis"><em>uglifying</em></span> source code and concatenating files together. The project might be modularized as well, but in a <span class="emphasis"><em>global</em></span> way. Then we have libraries like Require.js, with modules no longer automatically exposing themselves to the global scope.</p><p>But as I have mentioned, having the client download module files separately is not ideal for performance; soon we had tools like browserify, and later, webpack - one of the most popular frontend packaging tools these days.</p><div class="section" title="Introduction to webpack"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec36"/>Introduction to webpack</h3></div></div></div><p>Webpack is an integrated packaging tool dedicated (at least at the beginning) to frontend projects. It is designed to package not only JavaScript, but also other static assets in a frontend project. Webpack provides built-in support for both <span class="strong"><strong>asynchronous module definition</strong></span> (<span class="strong"><strong>AMD</strong></span>) and commonjs, and can load ES6 or other types of resources via plugins.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note54"/>Note</h3><p>ES6 module support will get built-in for webpack 2.0, but by the time this chapter is written, you still need plugins like <code class="literal">babel-loader</code> or <code class="literal">ts-loader</code> to make it work. And of course we are going to use <code class="literal">ts-loader</code> later.</p></div></div><p>To install webpack via <code class="literal">npm</code>, execute the following command:</p><pre class="programlisting">
<span class="strong"><strong>$ npm install webpack -g</strong></span>
</pre></div><div class="section" title="Bundling JavaScript"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec37"/>Bundling JavaScript</h3></div></div></div><p>Before we actually use webpack to load TypeScript files, we'll have a quick walk through of bundling JavaScript.</p><p>First, let's create the file <code class="literal">index.js</code> under the directory <code class="literal">client/src/</code> with the following code inside:</p><pre class="programlisting">var Foo = require('./foo'); &#13;
 &#13;
Foo.test(); &#13;
</pre><p>Then create the file <code class="literal">foo.js</code> in the same folder with the following content:</p><pre class="programlisting">exports.test = function test() { &#13;
  console.log('Hello, Webpack!'); &#13;
}; &#13;
</pre><p>Now we can have them bundled as a single file using the webpack command-line interface:</p><pre class="programlisting">
<span class="strong"><strong>$ webpack ./client/src/index.js ./client/out/bundle.js</strong></span>
</pre><p>By viewing the <code class="literal">bundle.js</code> file generated by webpack, you will see that the contents of both <code class="literal">index.js</code> and <code class="literal">foo.js</code> have been wrapped into that single file, together with the bootstrap code of webpack. Of course, we would prefer not to type those file paths in the command line every time, but to use a configuration file instead.</p><p>Webpack provides configuration file support in the form of JavaScript files, which makes it more flexible to generate necessary data like bundle entries automatically. Let's create a simple configuration file that does what the previous command did.</p><p>Create file <code class="literal">client/webpack.config.js</code> with the following lines:</p><pre class="programlisting">'use strict'; &#13;
 &#13;
const Path = require('path'); &#13;
 &#13;
module.exports = { &#13;
  entry: './src/index', &#13;
  output: { &#13;
    path: Path.join(__dirname, 'out'), &#13;
    filename: 'bundle.js' &#13;
  } &#13;
}; &#13;
</pre><p>These are the two things to mention:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">The value of the <code class="literal">entry</code> field is not the filename, but the <span class="emphasis"><em>module id</em></span> (most of the time this is unresolved) instead. This means that you can have the <code class="literal">.js</code> extension omitted, but have to prefix it with <code class="literal">./</code> or <code class="literal">../</code> by default when referencing a file.</li><li class="listitem">The output path is required to be absolute. Building an absolute path with <code class="literal">__dirname</code> ensures it works properly if we are not executing webpack under the same directory as the configuration file.</li></ol></div></div><div class="section" title="Loading TypeScript"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec38"/>Loading TypeScript</h3></div></div></div><p>Now we are going to load and transpile our beloved TypeScript using the webpack plugin <code class="literal">ts-loader</code>. Before updating the configuration, let's install the necessary npm packages:</p><pre class="programlisting">
<span class="strong"><strong>$ npm install typescript ts-loader --save-dev</strong></span>
</pre><p>If things go well, you should have the TypeScript compiler as well as the <code class="literal">ts-loader</code> plugin installed locally. We may also want to rename and update the files <code class="literal">index.js</code> and <code class="literal">foo.js</code> to TypeScript files.</p><p>Rename <code class="literal">index.js</code> to <code class="literal">index.ts</code> and update the module importing syntax:</p><pre class="programlisting">import * as Foo from './foo'; &#13;
 &#13;
Foo.test(); &#13;
</pre><p>Rename <code class="literal">foo.js</code> to <code class="literal">foo.ts</code> and update the module exporting syntax:</p><pre class="programlisting">export function test() { &#13;
  console.log('Hello, Webpack!'); &#13;
} &#13;
</pre><p>Of course, we would want to add the <code class="literal">tsconfig.json</code> file for those TypeScript files (in the folder <code class="literal">client</code>):</p><pre class="programlisting">{ &#13;
  "compilerOptions": { &#13;
    "target": "es5", &#13;
    "module": "commonjs" &#13;
  }, &#13;
  "exclude": [ &#13;
    "out", &#13;
    "node_modules" &#13;
  ] &#13;
} &#13;
</pre><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note55"/>Note</h3><p>The compiler option <code class="literal">outDir</code> is omitted here because it is managed in the webpack configuration file.</p></div></div><p>To make webpack work with TypeScript via <code class="literal">ts-loader</code>, we'll need to tell webpack some information in the configuration file:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Webpack will need to resolve files with <code class="literal">.ts</code> extensions. Webpack has a default extensions list to resolve, including <code class="literal">''</code> (empty string), <code class="literal">'.webpack.js'</code>, <code class="literal">'.web.js'</code>, and <code class="literal">'.js'</code>. We need to add <code class="literal">'.ts'</code> to this list for it to recognize TypeScript files.</li><li class="listitem">Webpack will need to have <code class="literal">ts-loader</code> loading <code class="literal">.ts</code> modules because it does not compile TypeScript itself.</li></ol></div><p>And here is the updated <code class="literal">webpack.config.js</code>:</p><pre class="programlisting">'use strict'; &#13;
 &#13;
const Path = require('path'); &#13;
 &#13;
module.exports = { &#13;
  entry: './src/index', &#13;
  output: { &#13;
    path: Path.join(__dirname, 'bld'), &#13;
    filename: 'bundle.js' &#13;
  }, &#13;
<span class="strong"><strong>  resolve: { &#13;
    extensions: ['', '.webpack.js', '.web.js', '.ts', '.js'] &#13;
  }, &#13;
  module: { &#13;
    loaders: [ &#13;
      { test: /\.ts$/, loader: 'ts-loader' } &#13;
    ] &#13;
  }</strong></span> &#13;
}; &#13;
</pre><p>Now execute the command <code class="literal">webpack</code> under the <code class="literal">client</code> folder again, we should get the compiled and bundled output as expected.</p><p>During development, we can enable <span class="emphasis"><em>transpile mode</em></span> (corresponding to the compiler option <code class="literal">isolatedModules</code>) of TypeScript to have better performance on compiling changing files. But it means we'll need to rely on an IDE or an editor to provide error hints. And remember to make another compilation with transpile mode disabled after debugging to ensure things still work.</p><p>To enable transpile mode, add a <code class="literal">ts</code> field (defined by the <code class="literal">ts-loader</code> plugin) with <code class="literal">transpileOnly</code> set to <code class="literal">true</code>:</p><pre class="programlisting">module.exports = { &#13;
  ... &#13;
  ts: { &#13;
      transpileOnly: true &#13;
  } &#13;
}; &#13;
</pre></div><div class="section" title="Splitting code"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec39"/>Splitting code</h3></div></div></div><p>To take the advantage of code caching across pages, we might want to split the packaged modules as common pieces. The webpack provides a built-in plugin called <code class="literal">CommonsChunkPlugin</code> that can pick out common modules and have them packed separately.</p><p>For example, if we create another file called <code class="literal">bar.ts</code> that imports <code class="literal">foo.ts</code> just like <code class="literal">index.ts</code> does, <code class="literal">foo.ts</code> can be treated as a common chunk and be packed separately:</p><pre class="programlisting">module.exports = { &#13;
 <span class="strong"><strong> entry: ['./src/index', './src/bar'], &#13;
  ... &#13;
  plugins: [ &#13;
    new Webpack.optimize.CommonsChunkPlugin({ &#13;
      name: 'common', &#13;
      filename: 'common.js' &#13;
    }) &#13;
  ]</strong></span> &#13;
}; &#13;
</pre><p>For multi-page applications, it is common to have different pages with different entry scripts. Instead of manually updating the <code class="literal">entry</code> field in the configuration file, we can take advantage of it being JavaScript and generate proper entries automatically. To do so, we might want the help of the npm package <code class="literal">glob</code> for matching page entries:</p><pre class="programlisting">
<span class="strong"><strong>$ npm install glob --saved-dev</strong></span>
</pre><p>And then update the webpack configuration file:</p><pre class="programlisting">const glob = require('glob'); &#13;
 &#13;
module.exports = { &#13;
<span class="strong"><strong>  entry: glob &#13;
    .sync('./src/pages/*/*.ts') &#13;
    .filter(path =&gt; &#13;
      Path.basename(path, '.ts') === &#13;
      Path.basename(Path.dirname(path))</strong></span> &#13;
    ), &#13;
  ... &#13;
}; &#13;
</pre><p>Splitting the code can be rather a complex topic for deep dive, so we'll stop here and let you explore.</p></div><div class="section" title="Loading other static assets"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec40"/>Loading other static assets</h3></div></div></div><p>As we've mentioned, webpack can also be used to load other static assets like stylesheet and its extensions. For example, you can use the combination of <code class="literal">style-loader</code>, <code class="literal">css-loader</code> and <code class="literal">sass-loader</code>/<code class="literal">less-loader</code> to load <code class="literal">.sass</code>/<code class="literal">.less</code> files.</p><p>The configuration is similar to <code class="literal">ts-loader</code> so we'll not spend extra pages for their introductions. For more information, refer to the following URLs:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Embedded stylesheets in webpack: <a class="ulink" href="https://webpack.github.io/docs/stylesheets.html">https://webpack.github.io/docs/stylesheets.html</a></li><li class="listitem" style="list-style-type: disc">SASS loader for webpack: <a class="ulink" href="https://github.com/jtangelder/sass-loader">https://github.com/jtangelder/sass-loader</a></li><li class="listitem" style="list-style-type: disc">LESS loader for webpack: <a class="ulink" href="https://github.com/webpack/less-loader">https://github.com/webpack/less-loader</a></li></ul></div></div></div><div class="section" title="Adding TSLint to projects"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec135"/>Adding TSLint to projects</h2></div></div></div><p>A consistent code style is an important factor of code quality, and linters are our best friends when it comes to code styles (and they also helps with common mistakes). For TypeScript linting, TSLint is currently the simplest choice.</p><p>The installation and configuration of TSLint are easy. To begin with, let's install <code class="literal">tslint</code> as a global command:</p><pre class="programlisting">
<span class="strong"><strong>$ npm install tslint -g</strong></span>
</pre><p>And then we need to initialize a configuration file using the following command under the project root directory:</p><pre class="programlisting">
<span class="strong"><strong>$ tslint --init</strong></span>
</pre><p>TSLint will then generate a default configuration file named <code class="literal">tslint.json</code>, and you may customize it based on your own preferences. And now we can use it to lint our TypeScript source code:</p><pre class="programlisting">
<span class="strong"><strong>$ tslint */src/**/*.ts</strong></span>
</pre></div><div class="section" title="Integrating webpack and tslint command with npm scripts"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec136"/>Integrating webpack and tslint command with npm scripts</h2></div></div></div><p>As we've mentioned before, an advantage of using npm scripts is that they can handle local packages with executables properly by adding <code class="literal">node_modules/.bin</code> to <code class="literal">PATH</code>. And to make our application easier to build and test for other developers, we can have <code class="literal">webpack</code> and <code class="literal">tslint</code> installed as development dependencies and add related scripts to <code class="literal">package.json</code>:</p><pre class="programlisting">"scripts": { &#13;
  "build-client": "cd client &amp;&amp; webpack", &#13;
  "build-server": "tsc --project server", &#13;
  "build": "npm run build-client &amp;&amp; npm run build-server", &#13;
  "lint": "tslint ./*/src/**/*.ts", &#13;
  "test-client": "cd client &amp;&amp; mocha", &#13;
  "test-server": "cd server &amp;&amp; mocha", &#13;
  "test": "npm run lint &amp;&amp; npm run test-client &amp;&amp; npm run test-server" &#13;
} &#13;
</pre></div></div>
<div class="section" title="Version control"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec55"/>Version control</h1></div></div></div><p>Thinking back to my senior high school days, I knew nothing about version control tools. The best thing I could do was to create a daily archive of my code on a USB disk. And yes I did lose one!</p><p>Nowadays, with the boom of version control tools like Git and the availabilities of multiple free services like GitHub and Visual Studio Team Services, managing code with version control tools has become a daily basis for every developer.</p><p>As the most popular version control tool, Git has already been playing an important role in your work or personal projects. In this section, we'll talk about popular practices of using Git in a team.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note56"/>Note</h3><p>Note that I am assuming that you already have the basic knowledge of Git, and know how to make operations like <code class="literal">init</code>, <code class="literal">commit</code>, <code class="literal">push</code>, <code class="literal">pull</code> and <code class="literal">merge</code>. If not, please get hands on and try to understand those operations before continue.</p></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note57"/>Note</h3><p>Check out this quick tutorial at: <a class="ulink" href="https://try.github.io/">https://try.github.io/</a>.</p></div></div><div class="section" title="Git flow"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec137"/>Git flow</h2></div></div></div><p>Version control plays an important a role and it does not only influence the source code management process but also shapes the entire workflow of product development and delivery. Thus a <span class="emphasis"><em>successful</em></span> branching model becomes a serious choice.</p><p>Git flow is a collection of Git extensions that provides high-level repository operations for a branching model raised by Vincent Driessen. The name <span class="emphasis"><em>Git flow</em></span> usually refers to the branching model as well.</p><p>In this branching model, there are two main branches: <code class="literal">master</code> and <code class="literal">develop</code>, as well as three different types of supporting branches: <code class="literal">feature</code>, <code class="literal">hotfix</code> , and <code class="literal">release</code>.</p><p>With the help of Git flow extensions, we can easily apply this branching model without having to remember and type detailed sequences of commands. To install, please check out the installation guide of Git flow at: <a class="ulink" href="https://github.com/nvie/gitflow/wiki/Installation">https://github.com/nvie/gitflow/wiki/Installation</a>.</p><p>Before we can use Git flow to create and merge branches, we'll need to make an initialization:</p><pre class="programlisting">
<span class="strong"><strong>$ git flow init -d</strong></span>
</pre><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note58"/>Note</h3><p>Here <code class="literal">-d</code> stands for using default branch naming conventions. If you would like to customize, you may omit the <code class="literal">-d</code> option and answer the questions about <code class="literal">git flow init</code> command.</p></div></div><p>This will create <code class="literal">master</code> and <code class="literal">develop</code> branches (if not present) and save Git flow-related configuration to the local repository.</p><div class="section" title="Main branches"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec41"/>Main branches</h3></div></div></div><p>The branching model defines two main branches: <code class="literal">master</code> and <code class="literal">develop</code>. Those two branches exist in the lifetime of the current repository:</p><p>
</p><div class="mediaobject"><img src="graphics/image_09_002-1.jpg" alt="Main branches"/></div><p>
</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note59"/>Note</h3><p>The graph in the preceding shows a simplified relationship between <code class="literal">develop</code> and <code class="literal">master</code> branches.</p></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Branch master</strong></span>: The <span class="emphasis"><em>HEAD</em></span> of <code class="literal">master</code> branch should always contain production-ready source code. It means that no daily development is done on <code class="literal">master</code> branch in this branching model, and only commits that are fully tested and can be performed with a fast-forward should be merged into this branch.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Branch develop</strong></span>: The <span class="emphasis"><em>HEAD</em></span> of <code class="literal">develop</code> branch should contain delivered development source code. Changes to <code class="literal">develop</code> branch will finally be merged into <code class="literal">master</code>, but usually not directly. We'll come to that later when we talk about <code class="literal">release</code> branches.</li></ul></div></div><div class="section" title="Supporting branches"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec42"/>Supporting branches</h3></div></div></div><p>There are three types of supporting branches in the branching model of Git flow: <code class="literal">feature</code>, <code class="literal">hotfix</code>, and <code class="literal">release</code>. What they roughly do has already been suggested by their names, and we'll have more details to follow.</p><div class="section" title="Feature branches"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec21"/>Feature branches</h4></div></div></div><p>A feature branch has only direct interactions with the <code class="literal">develop</code> branch, which means it checks out from a <code class="literal">develop</code> branch and merges back to a <code class="literal">develop</code> branch. The feature branches might be the simplest type of branches out of the three.</p><p>To create a feature branch with Git flow, simply execute the following command:</p><pre class="programlisting">
<span class="strong"><strong>$ git flow feature start &lt;feature-name&gt;</strong></span>
</pre><p>Now Git flow will automatically checkout a new branch named after <code class="literal">feature/&lt;feature-name&gt;</code>, and you are ready to start development and commit changes occasionally.</p><p>After completing feature development, Git flow can automatically merge things back to the <code class="literal">develop</code> branch by the following command:</p><pre class="programlisting">
<span class="strong"><strong>$ git flow feature finish &lt;feature-name&gt;</strong></span>
</pre><p>A feature branch is usually started by the developer who is assigned to the development of that very feature and is merged by the developer him or herself, or the owners of the <code class="literal">develop</code> branch (for example, if code review is required).</p></div><div class="section" title="Release branches"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec22"/>Release branches</h4></div></div></div><p>In a single iteration of a product, after finishing the development of features, we usually need a stage for fully testing everything, fixing bugs, and actually getting it ready to be released. And work for this stage will be done on release branches.</p><p>Unlike feature branches, a repository usually has only one active release branch at a time, and it is usually created by the owner of the repository. When the development branch is reaching a state of release and a thorough test is about to begin, we can then create a release branch using the following command:</p><pre class="programlisting">
<span class="strong"><strong>$ git flow release start &lt;version&gt;</strong></span>
</pre><p>From now on, bug fixes that are going to be released in this iteration should be merged or committed to branch <code class="literal">release/&lt;version&gt;</code> and changes to the current <code class="literal">release</code> branch can be merged back to the <code class="literal">develop</code> branch anytime.</p><p>If the test goes well and important bugs have been fixed, we can then finish this release and put it online:</p><pre class="programlisting">
<span class="strong"><strong>$ git flow release finish &lt;version&gt;</strong></span>
</pre><p>After executing this command, Git flow will merge the current release branch to both <code class="literal">master</code> and <code class="literal">develop</code> branches. So in a standard Git flow branching model, the <code class="literal">develop</code> branch will not be merged into the <code class="literal">master</code> directly, though after finishing a release, the content on <code class="literal">develop</code> and <code class="literal">master</code> branches could be identical (if no more changes are made to the <code class="literal">develop</code> branch during the releasing stage).</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note60"/>Note</h3><p>Finishing the current release usually means the end of the iteration, and the decision should be made with serious consideration.</p></div></div></div><div class="section" title="Hotfix branches"><div class="titlepage"><div><div><h4 class="title"><a id="ch09lvl4sec23"/>Hotfix branches</h4></div></div></div><p>Unfortunately, there's a phenomenon in the world of developers: bugs are always harder to find before the code goes live. After releasing, if serious bugs were found, we would have to use hotfixes to make things right.</p><p>A <code class="literal">hotfix</code> branch works kind of like a release branch but lasts shorter (because you would probably want it merged as soon as possible). Unlike feature branches being checked out from <code class="literal">develop</code> branch, a <code class="literal">hotfix</code> branch is checked out from <code class="literal">master</code>. And after getting things done, it should be merged back to both <code class="literal">master</code> and <code class="literal">develop</code> branches, just like a release branch does.</p><p>To create a <code class="literal">hotfix</code> branch, similarly you can execute the following command:</p><pre class="programlisting">
<span class="strong"><strong>$ git flow hotfix start &lt;hotfix-name&gt;</strong></span>
</pre><p>And to finish, execute the following command:</p><pre class="programlisting">
<span class="strong"><strong>$ git flow hotfix finish &lt;hotfix-name&gt;</strong></span>
</pre></div></div><div class="section" title="Summary of Git flow"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec43"/>Summary of Git flow</h3></div></div></div><p>The most valuable idea in Git flow beside the branching model itself is, in my opinion, the clear outline of one iteration. You may not need to follow every step mentioned thus far to use Git flow, but just make it fit your work. For example, for small features that can be done in a single commit, you might not actually need a feature branch. But conversely, Git flow might not bring much value if the iteration itself gets chaotic.</p></div></div><div class="section" title="Pull request based code review"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec138"/>Pull request based code review</h2></div></div></div><p>
<span class="strong"><strong>Code review</strong></span> could be a very important joint of team cooperation. It ensures acceptable quality of the code itself and helps newcomers correct their misunderstanding of the project and accumulate experiences rapidly without taking a wrong path.</p><p>If you have tried to contribute code to open-source projects on GitHub, you must be familiar with pull requests or PR. There are actually tools or IDEs with code reviewing workflow built-in. But with GitHub and other self-hosted services like GitLab, we can get it done smoothly without relying on specific tools.</p><div class="section" title="Configuring branch permissions"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec44"/>Configuring branch permissions</h3></div></div></div><p>Restrictions on accessing specific branches like <code class="literal">master</code> and <code class="literal">develop</code> are not technically necessary. But without those restrictions, developers can easily skip code reviewing because they are just able to do so. In services provided by the Visual Studio Team Foundation Server, we may add a custom check in policy to force code review. But in lighter services like GitHub and GitLab, it might be harder to have similar functionality.</p><p>The easiest way might be to have developers who are more qualified and familiar with the current project have the permissions for writing the <code class="literal">develop</code> branch, and restrict code reviewing in this group verbally. For other developers working on this project, pull requests are now forced for getting changes they merged.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note61"/>Note</h3><p>GitHub requires an organization account to specify push permissions for branches. Besides this, GitHub provides a status API and can add restrictions to merging so that only branches with a valid status can get merged.</p></div></div></div><div class="section" title="Comments and modifications before merge"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec45"/>Comments and modifications before merge</h3></div></div></div><p>A great thing about those popular Git services is that the reviewer and maybe other colleagues of yours may comment on your pull requests or even specific lines of code to raise their concerns or suggestions. And accordingly, you can make modifications to the active pull request and make things a little bit closer to perfect.</p><p>Furthermore, references between issues and pull requests are shown in the conversation. This along with the comments and modification records makes the context of current pull requests clear and traceable.</p></div></div><div class="section" title="Testing before commits"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec139"/>Testing before commits</h2></div></div></div><p>Ideally, we would expect every  commit we make to pass tests and code linting. But because we are human, we can easily forget about running tests before committing changes. And then, if we have already set up continuous integration (we'll come to that shortly) of this project, pushing the changes would make it red. And if your colleague has set up a CI light with an alarm, you would make it flash and sound out.</p><p>To avoid breaking the build constantly, you might want to add a <code class="literal">pre-commit</code> hook to your local repository.</p><div class="section" title="Git hooks"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec46"/>Git hooks</h3></div></div></div><p>Git provides varieties of hooks corresponding to specific phases of an operation or an event. After initializing a Git repository, Git will create hook samples under the directory <code class="literal">.git/hooks</code>.</p><p>Now let's create the file <code class="literal">pre-commit</code> under the directory <code class="literal">.git/hooks</code> with the following content:</p><pre class="programlisting">
<span class="strong"><strong>#!/bin/sh</strong></span>
<span class="strong"><strong>npm run test</strong></span>
</pre><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note62"/>Note</h3><p>The hook file does not have to be a bash file, and it can just be any executable. For example, if you want like to work with a Node.js hook, you can update the shebang as <code class="literal">#!/usr/bin/env node</code> and then write the hook in JavaScript.</p></div></div><p>And now Git will run tests before every commit of changes.</p></div><div class="section" title="Adding pre-commit hook automatically"><div class="titlepage"><div><div><h3 class="title"><a id="ch09lvl3sec47"/>Adding pre-commit hook automatically</h3></div></div></div><p>Adding hooks manually to the local repository could be trivial, but luckily we have npm packages like <code class="literal">pre-commit</code> that will add pre-commit hooks automatically when it's installed (as you usually might need to run <code class="literal">npm install</code> anyway).</p><p>To use the <code class="literal">pre-commit</code> package, just install it as a development dependency:</p><pre class="programlisting">
<span class="strong"><strong>$ npm install pre-commit --save-dev</strong></span>
</pre><p>It will read your <code class="literal">package.json</code> and execute npm scripts listed with the field <code class="literal">pre-commit</code> or <code class="literal">precommit</code>:</p><pre class="programlisting">{ &#13;
  .. &#13;
  "script": { &#13;
    "test": "istanbul cover ..." &#13;
  }, &#13;
  "pre-commit": ["test"] &#13;
} &#13;
</pre><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note63"/>Note</h3><p>At the time of writing, npm package <code class="literal">pre-commit</code> uses symbolic links to create Git hook, which requires administrator privileges on Windows. But failing to create a symbolic link won't stop the <code class="literal">npm install</code> command from completing. So if you are using Windows, you probably might want to ensure <code class="literal">pre-commit</code> is properly installed.</p></div></div></div></div></div>
<div class="section" title="Continuous integration"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec56"/>Continuous integration</h1></div></div></div><p>The<span class="strong"><strong> continuous integration</strong></span> (<span class="strong"><strong>CI</strong></span>) refers to a practice of integrating multiple parts of a project or solution together regularly. Depending on the size of the project, the integration could be taken for every single change or on a timed schedule.</p><p>The main goal of continuous integration is to avoid integration issues, and it also enforces the discipline of frequent automated testing, this helps to find bugs earlier and prevents the degeneration of functionalities.</p><p>There are many solutions or services with continuous integration support. For example, self-hosted services like TFS and Jenkins, or cloud-based services like Visual Studio Team Services, Travis-CI, and AppVeyor. We are going to walk through the basic configuration of Travis-CI with our demo project.</p><div class="section" title="Connecting GitHub repository with Travis-CI"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec140"/>Connecting GitHub repository with Travis-CI</h2></div></div></div><p>We are going to use GitHub as the Git service behind continuous integration. First of all, let's get our GitHub repository and Travis-CI settings ready:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create a correspondent repository as origin and push the local repository to GitHub:<pre class="programlisting">
<span class="strong"><strong>      $ git remote add origin https://github.com/&lt;username&gt;/&lt;repo&gt;.git</strong></span>
<span class="strong"><strong>      $ git push -u origin master</strong></span>
</pre></li><li class="listitem">Sign into Travis-CI with your GitHub account at: <a class="ulink" href="https://travis-ci.org/auth">https://travis-ci.org/auth</a>.</li><li class="listitem">Go to the account page, find the project we are working with, and then flick the repository switch on.</li></ol></div><p>Now the only thing we need to make the continuous integration setup work is a proper Travis-CI configuration file. Travis-CI has built-in support for many languages and runtimes. It provides multiple versions of Node.js and makes it extremely easy to test Node.js projects.</p><p>Create the file <code class="literal">.travis.yml</code> in the root of project with the following content:</p><pre class="programlisting">language: node_js &#13;
node_js: &#13;
  - "4" &#13;
  - "6" &#13;
before_script: &#13;
  - npm run build &#13;
</pre><p>This configuration file tells Travis-CI to test with both Node.js v4 and v6, and execute the command <code class="literal">npm run build</code> before testing (it will run the <code class="literal">npm test</code> command automatically).</p><p>Almost ready! Now add and commit the new <code class="literal">.travis.yml</code> file and push it to <code class="literal">origin</code>. If everything goes well, we should see Travis-CI start the build of this project shortly.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note64"/>Note</h3><p>You might be seeing building status badges everywhere nowadays, and it's easy to add one to the <code class="literal">README.md</code> of your own project. In the project page on Travis-CI, you should see a badge next to the project name. Copy its URL and add it to the <code class="literal">README.md</code> as an image:</p></div></div><pre class="programlisting">![building status](https://api.travis-ci.org/&lt;username&gt;/&lt;repo&gt;.svg) &#13;
</pre></div></div>
<div class="section" title="Deployment automation"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec57"/>Deployment automation</h1></div></div></div><p>Rather than a version control tool, Git is also popular for relatively simple deployment automation. And in this section, we'll get our hands on and configure automated deployment based on Git.</p><div class="section" title="Passive deployment based on Git server side hooks"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec141"/>Passive deployment based on Git server side hooks</h2></div></div></div><p>The idea of passive deployment is simple: when a client pushes commits to the bare repository on the server, a <code class="literal">post-receive</code> hook of Git will be triggered. And thus we can add scripts checking out changes and start deployment.</p><p>The elements involved in the Git deployment solution on both the client and server sides includes:</p><p>
</p><div class="mediaobject"><img src="graphics/image_09_003-1.jpg" alt="Passive deployment based on Git server side hooks"/></div><p>
</p><p>To make this mechanism work, we need to perform the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Create a bare repository on the server with the following command:<pre class="programlisting">
<span class="strong"><strong>      $ mkdir deployment.git</strong></span>
<span class="strong"><strong>      $ cd deployment.git</strong></span>
<span class="strong"><strong>      $ git init --bare</strong></span>
</pre><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note65"/>Note</h3><p>A bare repository usually has the extension <code class="literal">.git</code> and can be treated as a centralized place for sharing purposes. Unlike normal repositories, a bare repository does not have the working copy of source files, and its structure is quite similar to what's inside a <code class="literal">.git</code> directory of a normal repository.</p></div></div></li><li class="listitem">Add <code class="literal">deployment.git</code> as a remote repository of our project, and try to push the <code class="literal">master</code> branch to the <code class="literal">deployment.git</code> repository:<pre class="programlisting">
<span class="strong"><strong>     $ cd ../demo-project</strong></span>
<span class="strong"><strong>     $ git remote add deployment ../deployment.git</strong></span>
<span class="strong"><strong>     $ git push -u deployment master</strong></span>
</pre><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note66"/>Note</h3><p>We are adding a local bare repository as the remote repository in this example. Extra steps might be required to create real remote repositories.</p></div></div></li><li class="listitem">Add a <code class="literal">post-receive</code> hook for the <code class="literal">deployment.git</code> repository. We've already worked with the client side Git hook <code class="literal">pre-commit</code>, and the server side hooks work the same way.</li></ol></div><p>But when it comes to a serious production deployment, how to write the hook could be a hard question to answer. For example, how do we minimize the impact of deploying new builds?</p><p>If we have set up our application with high availability load balancing, it might not be a big issue to have one of them offline for minutes. But certainly not all of them in this case. So here are some basic requirements of the deploy scripts on both the client and server sides:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The deployment should be proceeded in a certain sequence</li><li class="listitem" style="list-style-type: disc">The deployment should stop running services gently</li></ul></div><p>And we can do better by:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Building outside of the previous deployment directory</li><li class="listitem" style="list-style-type: disc">Only trying to stop running services after the newly deployed application is ready to start immediately</li></ul></div></div><div class="section" title="Proactive deployment based on timers or notifications"><div class="titlepage"><div><div><h2 class="title"><a id="ch09lvl2sec142"/>Proactive deployment based on timers or notifications</h2></div></div></div><p>Instead of using Git hooks, we can have other tools pull and build the application automatically as well. In this way, we no longer need the client to push changes to servers separately. And instead, the program on the server will pull changes from a remote repository and complete deployment.</p><p>A notification mechanism is preferred to avoid frequent fetching though, and there are already tools like <a class="ulink" href="">PM2 </a>that have automated deployment built-in. You can also consider building up your own using hooks provided by cloud-based or self-hosted Git services.</p></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch09lvl1sec58"/>Summary</h1></div></div></div><p>In this final chapter, we built the outline of a complete workflow starting with building and testing to continuous integration and automated deployment. We've covered some popular services or tools and provide other options for readers to discover and explore.</p><p>Among the varieties of choice, you might agree that the most appropriate workflow for your team is the workflow that fits the best. Taking people rather than technologies alone into consideration is an important part of software engineering, and it is also the key to keeping the team efficient (and happy, perhaps).</p><p>The sad thing about a team, or a crowd of people is that usually only a few of them can keep the passion burning. We’ve talked about finding the balance point, but that is what we still need to practice. And in most of the cases, expecting every one of your team to find the right point is just unreasonable. When it comes to team projects, we'd better have rules that can be validated automatically instead of conventions that are not testable.</p><p>After reading this book, I hope the reader gets the outlines of the build steps, workflow, and of course knowledge of common design patterns. But rather than the cold explanations of different terms and patterns, there are more important ideas I wanted to deliver:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">We as humans are dull, and should always keep our work divided as controllable pieces, instead of acting like a genius. And that's also why we need to <span class="emphasis"><em>design</em></span> software to make our lives easier.</li><li class="listitem" style="list-style-type: disc">And we are also unreliable, especially at a scale of some mass (like a team).</li><li class="listitem" style="list-style-type: disc">As a learner, always try to understand the reason behind a conclusion or mechanism behind a phenomenon.</li></ul></div></div></body></html>