<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Getting Started with Cloud-Native</h1>
                </header>
            
            <article>
                
<p>In this chapter, the following recipes will be covered:</p>
<ul>
<li>Creating a stack</li>
<li>Creating a function and working with metrics and logs</li>
<li>Creating an event stream and publishing an event</li>
<li>Creating a stream processor</li>
<li>Creating an API Gateway</li>
<li>Deploying a single-page application</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p>Cloud-native is lean. Companies today must continuously experiment with new product ideas so that they can adapt to changing market demands; otherwise, they risk falling behind their competition. To operate at this pace, they must leverage fully managed cloud services and fully-automated deployments to minimize time to market, mitigate operating risks, and empower self-sufficient, full-stack teams to accomplish far more with much less effort.</p>
<p>The recipes in this cookbook demonstrate how to use fully managed, serverless cloud services to develop and deploy lean and autonomous services. This chapter contains bare-boned recipes with no clutter in order to focus on the core aspects of deploying cloud-native components and to establish a solid foundation for the remainder of this cookbook.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a stack</h1>
                </header>
            
            <article>
                
<p>Each autonomous cloud-native service and all its resources are provisioned as a cohesive and self-contained group called a <strong>stack</strong>. On AWS, these are <strong>CloudFormation</strong> stacks. In this recipe, we will use the Serverless Framework to create and manage a bare-bones stack to highlight the steps involved in deploying a cloud-native service.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Before starting this recipe, you will need to follow the instructions in the <em>Preface</em> for configuring your development environment with Node.js, the Serverless Framework, and AWS account credentials.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Create the project from the following template:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch1/create-stack --path cncb-create-stack</pre>
<ol start="2">
<li>Navigate to the <kbd>cncb-create-stack</kbd> directory with <kbd>cd cncb-create-stack</kbd>.</li>
<li>Review the file named <kbd>serverless.yml</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">service: cncb-create-stack<br/><br/>provider:<br/>  name: aws</pre>
<ol start="4">
<li>Review the file named <kbd>package.json</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">{<br/>  "name": "cncb-create-stack",<br/>  "version": "1.0.0",<br/>  "private": true,<br/>  "scripts": {<br/>    "<strong>test</strong>": "sls <strong>package</strong> -r us-east-1 -s test",<br/>    "<strong>dp:lcl</strong>": "sls <strong>deploy</strong> -r us-east-1",<br/>    "<strong>rm:lcl</strong>": "sls <strong>remove</strong> -r us-east-1"<br/>  },<br/>  "devDependencies": {<br/>    "<strong>serverless</strong>": "1.26.0"<br/>  }<br/>}</pre>
<ol start="5">
<li>Install the dependencies with <kbd>npm install</kbd>.</li>
<li>Run the tests with <kbd>npm test</kbd>.</li>
<li>Review the contents generated in the <kbd>.serverless</kbd> directory.</li>
<li>Deploy the stack:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ npm run dp:lcl -- -s $MY_STAGE</strong><br/><br/>&gt; cncb-create-stack@1.0.0 dp:lcl &lt;path-to-your-workspace&gt;/cncb-create-stack<br/>&gt; sls deploy -r us-east-1 "-s" "john"<br/><br/>Serverless: Packaging service...<br/>Serverless: Creating Stack...<br/>Serverless: Checking Stack create progress...<br/>.....<br/>Serverless: Stack create finished...<br/>Serverless: Uploading CloudFormation file to S3...<br/>Serverless: Uploading artifacts...<br/>Serverless: Validating template...<br/>Serverless: Updating Stack...<br/>Service Information<br/>service: cncb-create-stack<br/>stage: john<br/>region: us-east-1<br/>stack: cncb-create-stack-john<br/>api keys:<br/> None<br/>endpoints:<br/> None<br/>functions:<br/> None</pre>
<ol start="9">
<li>Review the stack in the AWS Console:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/3effc87e-5bd7-48fe-86a8-2a3d087cc88a.png" style="width:55.58em;height:46.92em;"/></div>
<ol start="10">
<li>Remove the stack once you have finished with <kbd>npm run rm:lcl -- -s $MY_STAGE</kbd>.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>The <strong>Serverless Framework</strong> (<strong>SLS</strong>) (<a href="https://serverless.com/framework/docs">https://serverless.com/framework/docs</a>) is my tool of choice for deploying cloud resources, regardless of whether or not I am deploying serverless resources, such as functions. SLS is essentially an abstraction layer on top of <strong>infrastructure as code</strong> tools, such as AWS CloudFormation, with extensibility features such as plugins and dynamic variables. We will use SLS in all of our recipes. Each recipe starts by using the SLS feature to <kbd>create</kbd> a new project by cloning a <kbd>template</kbd>. You will ultimately want to create your own templates for jump-starting your own projects.</p>
<p>This first project is as bare bones as we can get. It essentially creates an empty CloudFormation stack. In the <kbd>serverless.yml</kbd> file, we define the <kbd>service</kbd> name and the <kbd>provider</kbd>. The <kbd>service</kbd> name will be combined with the <kbd>stage</kbd>, which we will discuss shortly, to create a unique stack name within your account and <kbd>region</kbd>. I have prefixed all the stacks in our recipes with <kbd>cncb</kbd> to make it easy to filter for these stacks in the AWS Console if you are using a shared account, such as your development or sandbox account at work.</p>
<p>Our next most important tool is <strong>Node Package Manager</strong> (<strong>NPM</strong>) (<a href="https://docs.npmjs.com/">https://docs.npmjs.com/</a>). We will not be packaging any Node modules (also known as libraries), but we will be leveraging NPM's dependency management and scripting features. In the <kbd>package.json</kbd> file, we declared a development dependency on the Serverless Framework and three custom scripts to test, deploy, and remove our stack. The first command we execute is <kbd>npm install</kbd>, which will install all the declared dependencies into the project's <kbd>node_modules</kbd> directory.</p>
<p>Next, we execute the <kbd>npm test</kbd> script. This is one of several standard scripts for which NPM provides a shortcut alias. We have defined the <kbd>test</kbd> script to invoke the <kbd>sls package</kbd> command to assert that everything is configured properly and help us see what is going on under the covers. This command processes the <kbd>serverless.yml</kbd> file and generates a CloudFormation template in the <kbd>.serverless</kbd> directory. One of the advantages of the Serverless Framework is that it embodies best practices and uses a <strong>configuration by exception</strong> approach to take a small amount of declaration in the <kbd>serverless.yml</kbd> files and expand it into a much more verbose CloudFormation template.</p>
<p>Now, we are ready to deploy the stack. As developers, we need to be able to deploy a stack and work on it in isolation from other developers and other environments, such as production. To support this requirement, SLS uses the concept of a <strong>stage</strong>. Stage (<kbd>-s $MY_STAGE</kbd>) and region (<kbd>-r us-east-1</kbd>) are two required command-line options when invoking an SLS command. A stack is deployed into a specific region and the stage is used as a prefix in the stack name to make it unique within an account and region. Using this feature, each developer can <em>deploy</em> (<kbd>dp</kbd>) what I refer to as a <em>local</em> (<kbd>lcl</kbd>) stack with their name as the stage with <kbd>npm run dp:lcl -- -s $MY_STAGE</kbd>. In the examples, I use my name for the stage. We declared the <kbd>$MY_STAGE</kbd> environment variable in the <em>Getting ready</em> section. The double dash (<kbd>--</kbd>) is NPM's way of letting us pass additional options to a custom script. In <a href="390bdaaf-5f53-4d65-8a6c-2e47c815f2b3.xhtml">Chapter 6</a>, <em>Building a Continuous Deployment Pipeline</em>, we will discuss deploying stacks to shared environments, such as <strong>staging</strong> and <strong>production</strong>.</p>
<p>CloudFormation has a limit regarding the template body size in a request to the API. Typical templates easily surpass this limit and must be uploaded to S3 instead. The Serverless Framework handles this complexity for us. In the <kbd>.serverless</kbd> directory, you will notice that there is a <kbd>cloudformation-template-create-stack.json</kbd> file that declares a <kbd>ServerlessDeploymentBucket</kbd>. In the <kbd>sls deploy</kbd> output, you can see that SLS uses this template first and then it uploads the <kbd>cloudformation-template-update-stack.json</kbd> file to the bucket and updates the stack. It's nice to have this problem already solved for us because it is typical to learn about this limit the hard way.</p>
<p>At first glance, creating an empty stack may seem like a silly idea, but in practice it is actually quite useful. In a sense, you can think of CloudFormation as a CRUD tool for cloud resources. CloudFormation keeps track of the state of all the resources in a stack. It knows when a resource is new to a stack and must be created, when a resource has been removed from a stack and must be deleted, and when a resource has changed and must be updated. It also manages the dependencies and ordering between resources. Furthermore, when an update to a stack fails, it rolls back all the changes.</p>
<p>Unfortunately, when deploying a large number of changes, these rollbacks can be very time-consuming and painful when the error is in one of the last resources to be changed. Therefore, it is best to make changes to a stack in small increments. In <a href="390bdaaf-5f53-4d65-8a6c-2e47c815f2b3.xhtml">Chapter 6</a>, <em>Building a Continuous Deployment Pipeline</em>, we will discuss the practices of small batch sizes, task branch workflow, and decoupling deployment from release. For now, if you are creating a new service from a proven template, then initialize the new project and deploy the stack with all the template defaults all the way to production with your first pull request. Then, create a new branch for each incremental change. However, if you are working on an experimental service with no proven starting point, then an empty stack is perfectly reasonable for your first deployment to production.</p>
<p>In your daily development routine, it is important to clean up your local stacks when you have completed work on a task or story. The cost of a development account can creep surprisingly high when orphaned stacks accumulate and are rarely removed. The <kbd>npm run rm:lcl -- -s $MY_STAGE</kbd> script serves this purpose.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a function and working with metrics and logs</h1>
                </header>
            
            <article>
                
<p><strong>Function-as-a-Service</strong> is the cornerstone of cloud-native architecture. Functions enable self-sufficient, full-stack teams to focus on delivering lean business solutions without being weighed down by the complexity of running cloud infrastructure. There are no servers to manage, and functions implicitly scale to meet demand. They are integrated with other value-added cloud services, such as streams, databases, API gateways, logging, and metrics, to further accelerate development. Functions are disposable architecture, which empower teams to experiment with different solutions. This recipe demonstrates how straightforward it is to deploy a function.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Create the project from the following template:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch1/create-function --path cncb-create-function</pre>
<ol start="2">
<li>Navigate to the <kbd>cncb-create-function</kbd> directory with <kbd>cd cncb-create-function</kbd>.</li>
<li>Review the file named <kbd>serverless.yml</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">service: cncb-create-function<br/><br/>provider:<br/>  name: aws<br/>  <strong>runtime</strong>: nodejs8.10<br/>  <strong>environment</strong>:<br/>    V1: value1<br/><br/><strong>functions</strong>:<br/>  hello:<br/>    handler: handler.hello</pre>
<ol start="4">
<li>Review the file named <kbd>handler.js</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">module.exports.<strong>hello</strong> = (event, context, callback) =&gt; {<br/>  console.log('event: %j', event);<br/>  console.log('context: %j', context);<br/>  console.log('env: %j', process.env);<br/>  <br/>  <strong>callback</strong>(null, 'success');<br/>};</pre>
<ol start="5">
<li>Install the dependencies with <kbd>npm install</kbd>.</li>
<li>Run the tests with <kbd>npm test</kbd>.</li>
<li>Review the contents generated in the <kbd>.serverless</kbd> directory.</li>
<li>Deploy the stack: </li>
</ol>
<pre style="padding-left: 30px"><strong>$ npm run dp:lcl -- -s $MY_STAGE</strong><br/><br/>&gt; cncb-create-function@1.0.0 dp:lcl &lt;path-to-your-workspace&gt;/cncb-create-function<br/>&gt; sls deploy -r us-east-1 "-s" "john"<br/><br/>Serverless: Packaging service...<br/>Serverless: Excluding development dependencies...<br/>Serverless: Creating Stack...<br/>Serverless: Checking Stack create progress...<br/>.....<br/>Serverless: Stack create finished...<br/>Serverless: <strong>Uploading</strong> CloudFormation file to S3...<br/>Serverless: <strong>Uploading</strong> artifacts...<br/>Serverless: <strong>Uploading</strong> service .zip file to S3 (881 B)...<br/>Serverless: Validating template...<br/>Serverless: Updating Stack...<br/>Serverless: Checking Stack update progress...<br/>.................<br/>Serverless: Stack update finished...<br/>Service Information<br/>service: cncb-create-function<br/>stage: john<br/>region: us-east-1<br/>stack: cncb-create-function-john<br/>api keys:<br/> None<br/>endpoints:<br/> None<br/>functions:<br/> hello: cncb-create-function-john-hello</pre>
<ol start="9">
<li>Review the stack and function in the AWS Console.</li>
<li>Invoke the function with the following command:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ sls invoke -r us-east-1 -f hello -s $MY_STAGE -d '{"hello":"world"}'</strong><br/>"success"</pre>
<ol start="11">
<li>Review the function metrics in the AWS Console:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/21c0d7ed-059d-417e-a2a9-6c0aa6232cd7.png"/></div>
<ol start="12">
<li>Review the function logs in the AWS Console:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/3a23c0ff-0fd6-4417-94c7-96702e0e6201.png"/></div>
<ol start="13">
<li>Take a look at the logs locally: </li>
</ol>
<pre style="padding-left: 30px"><strong>$ sls logs -f hello -r us-east-1 -s $MY_STAGE</strong><br/>START RequestId: ... Version: $LATEST<br/>2018-03-24 15:48:45 ... event: {"hello":"world"}<br/>2018-03-24 15:48:45 ... context: {"functionName":"cncb-create-function-john-hello","memoryLimitInMB":"1024", ...}<br/>2018-03-24 15:48:45 ... env: {"V1":"value1","TZ":":UTC","AWS_REGION":"us-east-1", "AWS_ACCESS_KEY_ID":"...", ...}<br/>END RequestId: ...<br/>REPORT ... Duration: 3.64 ms Billed Duration: 100 ms ... Max Memory Used: 20 MB    </pre>
<ol start="14">
<li>Remove the stack once you have finished with <kbd>npm run rm:lcl -- -s $MY_STAGE</kbd>.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>The Serverless Framework handles the heavy lifting, which allows us to focus on writing the actual function code. The first thing to note is that we must define the <kbd>runtime: nodejs8.10</kbd> in the <kbd>serverless.yml</kbd> file. Next, we define a function in the <kbd>functions</kbd> section with a name and a handler. All other settings have defaulted, following the <strong>configuration by exception</strong> approach. When you look at the generated CloudFormation template, you will see that over 100 lines were generated from just a handful of lines declared in the <kbd>serverless.yml</kbd> file. A large portion of the generated template is dedicated to defining boilerplate security policies. Dig into the <kbd>.serverless/cloudformation-template-update-stack.json</kbd> file to see the details.</p>
<p>We also define <kbd>environment</kbd> variables in the serverless.yml. This allows the functions to be parameterized per deployment stage. We will cover this in more detail in <a href="390bdaaf-5f53-4d65-8a6c-2e47c815f2b3.xhtml">Chapter 6</a>, <em>Building a Continuous Deployment Pipeline</em>. This also allows settings, such as the debug level, to be temporarily tweaked without redeploying the function.</p>
<p>When we deploy the project, the Serverless Framework packages the function along with its runtime dependencies, as specified in the <kbd>package.json</kbd> file, into a ZIP file. Then, it uploads the ZIP file to the <kbd>ServerlessDeploymentBucket</kbd> so that it can be accessed by CloudFormation. The output of the deployment command shows when this is happening. You can look at the content of the ZIP file in the <kbd>.serverless</kbd> directory or download it from the deployment bucket. We will cover advanced packaging options in <a href="b2c8b5bd-dfe5-461e-a8fa-3e71c94e633c.xhtml">Chapter 9</a>, <em>Optimizing Performance</em>.</p>
<p>The signature of an AWS Lambda function is straightforward. It must export a function that accepts three arguments: an event object, a context object, and a callback function. Our first function will just log the event, content, and the environment variables so that we can peer into the execution environment a little bit. Finally, we must invoke the callback. It is a standard JavaScript callback. We pass an error to the first argument or the successful result to the second argument.</p>
<p>Logging is an important standard feature of <strong>Function as a Service</strong> (<strong>FaaS</strong>). Due to the ephemeral nature of cloud resources, logging in the cloud can be tedious, to put it lightly. In AWS Lambda, console logging is performed asynchronously and recorded in CloudWatch logs. It's a fully-managed logging solution built right in. Take the time to look at the details in the log statements that this function writes. The environment variables are particularly interesting. For example, we can see that each invocation of a function gets a new temporary access key.</p>
<p>Functions also provide a standard set of metrics out-of-the-box, such as invocation count, duration, errors, throttling, and so forth. We will cover this in detail in <a href="64a4c0f7-3b2d-4638-a52c-f72953ff66d9.xhtml">Chapter 7</a>, <em>Optimizing Observability</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating an event stream and publishing an event</h1>
                </header>
            
            <article>
                
<p>Cloud-native services are autonomous. Each service is completely self-sufficient and runs in isolation to minimize the blast radius when any given service experiences a failure. To achieve this isolation, <em>bulkheads</em> must be established between the services. <strong>Event streaming</strong> is one mechanism that is used to create these bulkheads. Autonomous cloud-native services perform all inter-service communication asynchronously via streams to decouple upstream services from downstream services. In <a href="129afdee-aa82-4ba6-9d80-5ec70c4a766e.xhtml">Chapter 2</a>, <em>Applying The Event Sourcing and CQRS Patterns</em>, we will dive deeper into how we create bounded, isolated, and autonomous cloud-native services. This recipe creates the event stream that we will use throughout this cookbook and provides a function for publishing events to the stream.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Create the project from the following template:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch1/event-stream --path cncb-event-stream</pre>
<ol start="2">
<li>Navigate to the <kbd>cncb-event-stream</kbd> directory with <kbd>cd cncb-event-stream</kbd>.</li>
<li>Review the file named <kbd>serverless.yml</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">service: cncb-event-stream<br/><br/>provider:<br/>  name: aws<br/>  runtime: nodejs8.10<br/>  iamRoleStatements:<br/>    - Effect: Allow<br/>      Action:<br/>        - kinesis:PutRecord<br/>      Resource:<br/>        Fn::GetAtt: [ Stream, Arn ]<br/><br/>functions:<br/>  <strong>publish</strong>:<br/>    handler: handler.<strong>publish</strong><br/>    environment:<br/>      <strong>STREAM_NAME</strong>:<br/>        Ref: Stream<br/><br/>resources:<br/>  Resources:<br/>    <strong>Stream</strong>:<br/>      Type: AWS::Kinesis::Stream<br/>      Properties:<br/>        <strong>Name</strong>: ${opt:stage}-${self:service}-s1<br/>        <strong>RetentionPeriodHours</strong>: 24<br/>        <strong>ShardCount</strong>: 1<br/>        <br/>  Outputs:<br/>    <strong>streamName</strong>:<br/>      Value: <br/>        Ref: Stream<br/>    <strong>streamArn</strong>:<br/>      Value: <br/>        Fn::GetAtt: [ Stream, Arn ]</pre>
<ol start="4">
<li>Review the file named <kbd>handler.js</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">const aws = require('aws-sdk');<br/>const uuid = require('uuid');<br/><br/>module.exports.<strong>publish</strong> = (event, context, callback) =&gt; {<br/>  const e = {<br/>    <strong>id</strong>: uuid.v1(),<br/>    <strong>partitionKey</strong>: event.partitionKey || uuid.v4(),<br/>    <strong>timestamp</strong>: Date.now(),<br/>    <strong>tags</strong>: {<br/>      region: process.env.AWS_REGION,<br/>    },<br/>    ...event,<br/>  }<br/><br/>  const params = {<br/>    StreamName: process.env.<strong>STREAM_NAME</strong>,<br/>    PartitionKey: e.<strong>partitionKey</strong>,<br/>    Data: Buffer.from(JSON.stringify(e)),<br/>  };<br/><br/>  const kinesis = new aws.Kinesis();<br/><br/></pre>
<pre style="padding-left: 30px">  kinesis.<strong>putRecord</strong>(params, callback);<br/>};</pre>
<ol start="5">
<li>Install the dependencies with <kbd>npm install</kbd>.</li>
<li>Run the tests with <kbd>npm test</kbd>.</li>
<li>Review the contents generated in the <kbd>.serverless</kbd> directory.</li>
<li>Deploy the stack: </li>
</ol>
<pre style="padding-left: 30px"><strong>$ npm run dp:lcl -- -s $MY_STAGE</strong><br/><br/>&gt; cncb-create-stream@1.0.0 dp:lcl &lt;path-to-your-workspace&gt;/cncb-create-stream<br/>&gt; sls deploy -v -r us-east-1 "-s" "john"<br/><br/>Serverless: Packaging service...<br/>...<br/>Serverless: Stack update finished...<br/>Service Information<br/>service: cncb-event-stream<br/>stage: john<br/>region: us-east-1<br/>stack: cncb-event-stream-john<br/>...<br/>functions:<br/> publish: cncb-event-stream-john-publish<br/><br/>Stack Outputs<br/>PublishLambdaFunctionQualifiedArn: arn:aws:lambda:us-east-1:999999999999:function:cncb-event-stream-john-publish:3<br/><strong>streamArn</strong>: arn:aws:kinesis:us-east-1:999999999999:stream/john-cncb-event-stream-s1<br/><strong>streamName</strong>: john-cncb-event-stream-s1<br/>...</pre>
<ol start="9">
<li>Review the stack, stream, and function in the AWS Console.</li>
<li>Invoke the function with the following command:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ sls invoke -r us-east-1 -f publish -s $MY_STAGE -d '{"type":"thing-created"}'</strong><br/>{<br/>    "ShardId": "shardId-000000000000",<br/>    "SequenceNumber": "49582906351415672136958521359460531895314381358803976194"<br/>}</pre>
<ol start="11">
<li>Take a look at the logs: </li>
</ol>
<pre style="padding-left: 30px"><strong>$ sls logs -f publish -r us-east-1 -s $MY_STAGE</strong><br/>START ...<br/>2018-03-24 23:20:46 ... event: {"type":"thing-created"}<br/>2018-03-24 23:20:46 ... event:<br/>{<br/>  "type":"thing-created",<br/>  "id":"81fd8920-2fdb-11e8-b749-0d2c43ec73d0",<br/>  "partitionKey":"6f4f9a38-61f7-41c9-a3ad-b8c16e42db7c",<br/>  "timestamp":1521948046003,<br/>  "tags":{<br/>    "region":"us-east-1"<br/>  }<br/>}<br/>2018-03-24 23:20:46 ... params: {"StreamName":"john-cncb-event-stream-s1","PartitionKey":"6f4f9a38-61f7-41c9-a3ad-b8c16e42db7c","Data":{"type":"Buffer","data":[...]}}<br/>END ...<br/>REPORT ... Duration: 153.47 ms    Billed Duration: 200 ms ... Max Memory Used: 39 MB    </pre>
<ol start="12">
<li>Remove the stack once you have finished with <kbd>npm run rm:lcl -- -s $MY_STAGE</kbd>.</li>
</ol>
<div class="packt_infobox">This stack is a prerequisite for other recipes, as indicated in the <em>Getting ready</em> section of each recipe. If you are continuing with related recipes, then you can leave this stack running until you complete the related recipes. However, the stream in this stack is not included in the AWS free tier, so you may want to go ahead and remove this stack and recreate it when needed.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>The <kbd>resources</kbd> section of the <kbd>serverless.yml</kbd> file is used to create cloud resources that are used by services. These resources are defined using standard AWS CloudFormation resource types. In this recipe, we are creating an AWS <em>Kinesis</em> stream. We give the stream a name, define the retention period, and specify the number of shards. The Serverless Framework provides a robust mechanism for dynamically replacing variables.</p>
<p>Here, we use the <kbd>${opt:stage}</kbd> option passed in on the command line and the <kbd>${self:service}</kbd> name defined in the <kbd>serverless.yml</kbd> file to create a unique stream name. The standard retention period is 24 hours and the maximum is seven days. For our recipes, one shard will be more than sufficient. We will discuss shards shortly and again in <a href="64a4c0f7-3b2d-4638-a52c-f72953ff66d9.xhtml">Chapter 7</a>, <em>Optimizing Observability</em>, and <a href="b2c8b5bd-dfe5-461e-a8fa-3e71c94e633c.xhtml">Chapter 9</a>, <em>Optimizing Performance</em>.</p>
<p>The <kbd>Outputs</kbd> section of the <kbd>serverless.yml</kbd> file is where we define values, such as generated IDs and names, that we want to use outside of the stack. We output the <strong><span>Amazon Resource Names</span></strong><span> (<strong>ARNs</strong></span>) <kbd>streamName</kbd> <span>and</span> <kbd>streamArn</kbd> <span>so that we can reference them with Serverless Framework variables in other projects. These values are also displayed on the Terminal when a deployment is complete.</span></p>
<p>The <kbd>publish</kbd> function defined in the <kbd>serverless.yml</kbd> file is used to demonstrate how to publish an event to the stream. We are passing the <kbd>STREAM_NAME</kbd> to the function as an environment variable. In the <kbd>iamRoleStatements</kbd> section, we give the function <kbd>kinesis: PutRecord</kbd> permission to allow it to publish events to this specific stream.</p>
<p>The function <kbd>handler.js</kbd> file has runtime dependencies on two external libraries—<kbd>aws-sdk</kbd> and <kbd>uuid</kbd>. The Serverless Framework will automatically include the runtime dependencies, as defined in the <kbd>package.json</kbd> file. Take a look inside the generated <kbd>.serverless/cncb-event-stream.zip</kbd> file. The <kbd>aws-sdk</kbd> is a special case. It is already available in the AWS Lambda <kbd>Node.js</kbd> runtime, and therefore is not included. This is important because <kbd>aws-sdk</kbd> is a large library and the ZIP file size impacts cold start times. We will discuss this in more detail in <a href="b2c8b5bd-dfe5-461e-a8fa-3e71c94e633c.xhtml">Chapter 9</a>, <em>Optimizing Performance</em>.</p>
<p>The <kbd>publish</kbd> function expects to receive an event object as input, such as <kbd>{"type":"thing-created"}</kbd>. We then adorn the event with additional information to conform to our standard event format, which we will discuss shortly. Finally, the function creates the required <kbd>params</kbd> object and then calls <kbd>kinesis.putRecord</kbd> from the <kbd>aws-sdk</kbd>. We will be using this function in this and other recipes to simulate event traffic.</p>
<p>All events in our cloud-native systems will conform to the following <strong>Event structure</strong> to allow for consistent handling across all services. Additional fields are event-type-specific:</p>
<pre style="padding-left: 30px">interface Event {<br/>    id: string;<br/>    type: string;<br/>    timestamp: number;<br/>    partitionKey: string;<br/>    tags: { [key: string]: string };<br/>}</pre>
<ul>
<li><kbd>type</kbd> describes the event, such as <kbd>thing-created</kbd></li>
<li><kbd>timestamp</kbd> is an epoch value, as returned from <kbd>Date.now()</kbd></li>
<li><kbd>id</kbd> should be a V1 UUID, which is time-based</li>
<li><kbd>partitionKey</kbd> should be a V4 UUID, which is random number-based</li>
<li><kbd>tags</kbd> is a hashmap of useful data values that are leveraged for content-based routing and aggregating event metrics</li>
</ul>
<p>It is important to use a <em>V4 UUID</em> for the <kbd>partitionKey</kbd> to avoid hot shards and maximize concurrency. If a <em>V1 UUID</em> were used, then all events produced at the same time would go to the same shard. The <kbd>partitionKey</kbd> will typically be the ID of the domain entity that produced the event, which should use a V4 UUID for the same reason. This has the added benefit of ensuring that all events for the same domain entity are processed through the same shard in the order received.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a stream processor</h1>
                </header>
            
            <article>
                
<p><strong>Stream processors</strong> do most of the heavy lifting in cloud-native services. Autonomous cloud-native services perform all inter-service communication asynchronously via event streaming to decouple upstream services from <strong>downstream services</strong>. <strong>Upstream services</strong> publish events to a stream, with no knowledge of the specific downstream services that will eventually consume the events. Downstream services deploy stream-processing functions to consume events of interest. Stream processors will be covered extensively throughout this cookbook. This recipe demonstrates how to create a function that listens for events from an <strong>AWS Kinesis</strong> stream and provides a quick introduction to using the functional reactive programming paradigm for implementing stream processing.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Before starting this recipe, you will need an AWS Kinesis Stream, such as the one created in the <em>Creating an event stream</em> recipe.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Create the project from the following template:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch1/create-stream-processor --path cncb-create-stream-processor</pre>
<ol start="2">
<li>Navigate to the <kbd>cncb-create-stream-processor</kbd> directory with <kbd>cd cncb-create-stream-processor</kbd>.</li>
<li>Review the file named <kbd>serverless.yml</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">service: cncb-create-stream-processor<br/><br/>provider:<br/>  name: aws<br/>  runtime: nodejs8.10<br/>    <br/>functions:<br/>  <strong>listener</strong>:<br/>    handler: handler.<strong>listener</strong><br/>    events:<br/>      - stream:<br/>          type: kinesis<br/>          arn: <strong>${cf:cncb-event-stream-${opt:stage}.streamArn}</strong><br/>          <strong>batchSize</strong>: 100<br/>          <strong>startingPosition</strong>: TRIM_HORIZON</pre>
<ol start="4">
<li>Review the file named <kbd>handler.js</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">const _ = require('highland');<br/><br/>module.exports.<strong>listener</strong> = (event, context, cb) =&gt; {<br/>  _(event.Records)<br/>    .map(recordToEvent)<br/>    .tap(printEvent)<br/>    .filter(forThingCreated)<br/>    .collect()<br/>    .tap(printCount)<br/>    .toCallback(cb);<br/>};<br/><br/>const <strong>recordToEvent</strong> = r =&gt; JSON.parse(Buffer.from(r.kinesis.data, 'base64'));<br/>const <strong>forThingCreated</strong> = e =&gt; e.type === 'thing-created';<br/><br/>const <strong>printEvent</strong> = e =&gt; console.log('event: %j', e);<br/>const <strong>printCount</strong> = events =&gt; console.log('count: %d', events.length);</pre>
<ol start="5">
<li>Install the dependencies with <kbd>npm install</kbd>.</li>
<li>Run the tests with <kbd>npm test -- -s $MY_STAGE</kbd>.<kbd><br/></kbd></li>
<li>Review the contents generated in the <kbd>.serverless</kbd> directory.</li>
<li>Deploy the stack: </li>
</ol>
<pre style="padding-left: 30px"><strong>$ npm run dp:lcl -- -s $MY_STAGE</strong><br/><br/>&gt; cncb-create-stream-processor@1.0.0 dp:lcl &lt;path-to-your-workspace&gt;/cncb-create-stream-processor<br/>&gt; sls deploy -r us-east-1 "-s" "john"<br/><br/>Serverless: Packaging service...<br/>...<br/>Serverless: Stack update finished...<br/>Service Information<br/>service: cncb-create-stream-processor<br/>stage: john<br/>region: us-east-1<br/>stack: cncb-create-stream-processor-john<br/>...<br/>functions:<br/>  <strong>listener</strong>: cncb-create-stream-processor-john-listener</pre>
<ol start="9">
<li>Review the stack and function in the AWS Console.</li>
<li>Publish an event from a separate Terminal with the following commands:</li>
</ol>
<pre style="padding-left: 30px">$ cd &lt;path-to-your-workspace&gt;/cncb-event-stream<br/><strong>$ sls invoke -r us-east-1 -f publish -s $MY_STAGE -d '{"type":"thing-created"}'</strong><br/>{<br/>    "ShardId": "shardId-000000000000",<br/>    "SequenceNumber": "49582906351415672136958521360120605392824155736450793474"<br/>}</pre>
<ol start="11">
<li>Take a look at the logs from the original Terminal:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ sls logs -f listener -r us-east-1 -s $MY_STAGE</strong><br/>START ...<br/>2018-03-25 00:16:32 ... <strong>event</strong>:<br/>{<br/>  "type":"thing-created",<br/>  "id":"81fd8920-2fdb-11e8-b749-0d2c43ec73d0",<br/>  "partitionKey":"6f4f9a38-61f7-41c9-a3ad-b8c16e42db7c",<br/>  "timestamp":1521948046003,<br/>  "tags":{<br/>    "region":"us-east-1"<br/>  }<br/>}<br/>2018-03-25 00:16:32 ... <strong>event</strong>:<br/>{<br/>  "type":"thing-created",<br/>  "id":"c6f60550-2fdd-11e8-b749-0d2c43ec73d0",<br/>  ...<br/>}<br/>2018-03-25 00:16:32 ... <strong>count</strong>: 2<br/>END ...<br/>REPORT ... Duration: 7.73 ms    Billed Duration: 100 ms ... Max Memory Used: 22 MB    <br/><br/>START ...<br/>2018-03-25 00:22:22 ... <strong>event</strong>:<br/>{<br/>  "type":"thing-created",<br/>  "id":"1c2b5150-2fe4-11e8-b749-0d2c43ec73d0",<br/>  ...<br/>}<br/>2018-03-25 00:22:22 ... <strong>count</strong>: 1<br/>END ...<br/>REPORT ... Duration: 1.34 ms    Billed Duration: 100 ms ... Max Memory Used: 22 MB    <br/> </pre>
<ol start="12">
<li>Remove the stack once you are finished with <kbd>npm run rm:lcl -- -s $MY_STAGE</kbd>.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Stream processors listen for data from a streaming service such as <strong>Kinesis</strong> or <strong>DynamoDB Streams</strong>. Deploying a stream processor is completely declarative. We configure a function with the <kbd>stream</kbd> event type and the pertinent settings, such as the <kbd>type</kbd>, <kbd>arn</kbd>, <kbd>batchSize</kbd>, and <kbd>startingPosition</kbd>. The <kbd>arn</kbd> is set dynamically using a CloudFormation variable, <kbd>${cf:cncb-event-stream-${opt:stage}.streamArn}</kbd>, that references the output value of the <kbd>cnbc-event-stream</kbd> stack.</p>
<div class="packt_infobox"><br/>
Streams are the only resources that are shared between autonomous cloud-native services.</div>
<p>We will discuss batch size and starting position in detail in both <a href="5c400ff6-91da-4782-9369-549622d4a0d1.xhtml">Chapter 8</a>, <em>Designing for Failure</em>, and <a href="b2c8b5bd-dfe5-461e-a8fa-3e71c94e633c.xhtml">Chapter 9</a>, <em>Optimizing Performance</em>. For now, you may have noticed that the new stream processor logged all the events that were published to the stream in the last 24 hours. This is because the <kbd>startingPosition</kbd> is set to <kbd>TRIM_HORIZON</kbd>. If it was set to <kbd>LATEST</kbd>, then it would only receive events that were published after the function was created.</p>
<p>Stream processing is a perfect match for functional reactive programming with Node.js streams. The terminology can be a little confusing because the word <em>stream</em> is overloaded. I like to think of streams as either <em>macro</em> or <em>micro</em>. For example, Kinesis is the <em>macro</em> stream and the code in our stream processor function is the <em>micro</em> stream. My favorite library for implementing the <em>micro</em> stream is <strong>Highland.js</strong> (<a href="https://highlandjs.org">https://highlandjs.org</a>). A popular alternative is <strong>RxJS</strong> (<a href="https://rxjs-dev.firebaseapp.com">https://rxjs-dev.firebaseapp.com</a>). As you can see in this recipe, functional reactive programming is very descriptive and readable. One of the reasons for this is that there are no loops. If you try to implement a stream processor with <em>imperative programming</em>, you will find that it quickly gets very messy. You also lose backpressure, which we will discuss in <a href="5c400ff6-91da-4782-9369-549622d4a0d1.xhtml">Chapter 8</a>, <em>Designing for Failure</em>.</p>
<p>The code in the <kbd>listener</kbd> function creates a pipeline of steps that the data from the Kinesis stream will ultimately flow through. The first step, <kbd>_(event.Records)</kbd>, converts the array of Kinesis records into a Highland.js stream object that will allow each element in the array to be pulled through the stream in turn as the downstream steps are ready to receive the next element. The <kbd>.map(recordToEvent)</kbd> step decodes the Base64 encoded data from the Kinesis record and parses the JSON into an event object. The next step, <kbd>.tap(printEvent)</kbd>, simply logs the event so that we can see what is happening in the recipe.</p>
<p>Kinesis and event streaming, in general, is a member of the high performance, dumb-pipe-smart-endpoints generation of messaging middleware. This means that Kinesis, the dumb pipe, does not waste its processing power on filtering data for the endpoints. Instead, all that logic is spread out across the processing power of the smart endpoints. Our stream processor function is the smart endpoint. To that end, the <kbd>.filter(forThingCreated)</kbd> step is responsible for filtering out the events that the processor is not interested in. All the remaining steps can assume that they are receiving the expected event types.</p>
<p>Our bare-boned stream processor needs something somewhat interesting but simple to do. So, we count and print the number of <kbd>thing-created</kbd> events in the batch. We have filtered out all other event types, so the <kbd>.collect()</kbd> step collects all the remaining events into an array. Then, the <kbd>.tap(printCount)</kbd> step logs the length of the array. Finally, the <kbd>.toCallback(cb)</kbd> step will invoke the callback function once all the data in the batch has been processed. At this point, the Kinesis checkpoint is advanced and the next batch of events is processed. We will cover error handling and how it relates to batches and checkpoints in <a href="5c400ff6-91da-4782-9369-549622d4a0d1.xhtml">Chapter 8</a>, <em>Designing for Failure</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating an API Gateway</h1>
                </header>
            
            <article>
                
<p>An API Gateway is an essential element of cloud-native architecture. It provides a secure and performant perimeter at the boundaries of our cloud-native systems. The boundaries are where the system interacts with everything that is external to the system, including humans and other systems. We will leverage an API Gateway in the recipes that create boundary components such as a <strong>Backend For Frontend</strong> (<strong>BFF</strong>) or an External Service Gateway. This recipe demonstrates how straightforward it is to deploy an API Gateway.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Create the project from the following template:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch1/create-api-gateway --path cncb-create-api-gateway</pre>
<ol start="2">
<li>Navigate to the <kbd>cncb-create-api-gateway</kbd> directory with <kbd>cd cncb-create-api-gateway</kbd>.</li>
<li>Review the file named <kbd>serverless.yml</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">service: cncb-create-api-gateway<br/><br/>provider:<br/>  name: aws<br/>  runtime: nodejs8.10<br/><br/>functions:<br/>  <strong>hello</strong>:<br/>    handler: handler.<strong>hello</strong><br/>    events:<br/>      - <strong>http</strong>:<br/>          <strong>path</strong>: hello<br/>          <strong>method</strong>: get<br/>          cors: true</pre>
<ol start="4">
<li>Review the file named <kbd>handler.js</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">module.exports.<strong>hello</strong> = (event, context, callback) =&gt; {<br/>  console.log('event: %j', event);<br/><br/>  const response = {<br/>    statusCode: 200,<br/>    headers: {<br/>      'Access-Control-Allow-Origin': '*',<br/>    },<br/>    body: JSON.stringify({<br/>      message: 'JavaScript Cloud Native Development Cookbook! Your function executed successfully!',<br/>      input: event,<br/>    }),<br/>  };<br/><br/>  callback(null, response);<br/>};</pre>
<ol start="5">
<li>Install the dependencies with <kbd>npm install</kbd>.</li>
<li>Run the tests with <kbd>npm test</kbd>.<kbd><br/></kbd></li>
<li>Review the contents generated in the <kbd>.serverless</kbd> directory.</li>
<li>Deploy the stack: </li>
</ol>
<pre style="padding-left: 30px"><strong>$ npm run dp:lcl -- -s $MY_STAGE</strong><br/><br/>&gt; cncb-create-api-gateway@1.0.0 dp:lcl &lt;path-to-your-workspace&gt;/cncb-create-api-gateway<br/>&gt; sls deploy -r us-east-1 "-s" "john"<br/><br/>Serverless: Packaging service...<br/>.....<br/>Serverless: Stack update finished...<br/>Service Information<br/>service: cncb-create-api-gateway<br/>stage: john<br/>region: us-east-1<br/>stack: cncb-create-api-gateway-john<br/>api keys:<br/>  None<br/>endpoints:<br/>  GET - <strong>https://k1ro5oasm6.execute-api.us-east-1.amazonaws.com/john/hello</strong><br/>functions:<br/>  hello: cncb-create-api-gateway-john-hello</pre>
<ol start="9">
<li>Review the stack, API, and function in the AWS Console.</li>
<li>Invoke the <kbd>endpoint</kbd> shown in the stack output in the following commands:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ curl -v https://k1ro5oasm6.execute-api.us-east-1.amazonaws.com/john/hello | json_pp</strong><br/><br/>{<br/>   "input" : {<br/>      "body" : null,<br/>      "pathParameters" : null,<br/>      "requestContext" : { ... },<br/>      "resource" : "/hello",<br/>      "headers" : { ... },<br/>      "queryStringParameters" : null,<br/>      "httpMethod" : "GET",<br/>      "stageVariables" : null,<br/>      "isBase64Encoded" : false,<br/>      "path" : "/hello"<br/>   },<br/>   "message" : "JavaScript Cloud Native Development Cookbook! Your function executed successfully!"<br/>}</pre>
<ol start="11">
<li>Take a look at the logs:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ sls logs -f hello -r us-east-1 -s $MY_STAGE</strong><br/><br/>START ...<br/>2018-03-25 01:04:47 ... event: {"resource":"/hello","path":"/hello","httpMethod":"GET","headers":{ ... },"requestContext":{ ... },"body":null,"isBase64Encoded":false}<br/>END <br/>REPORT ... Duration: 2.82 ms    Billed Duration: 100 ms ... Max Memory Used: 20 MB    </pre>
<ol start="12">
<li>Remove the stack once you are finished with <kbd>npm run rm:lcl -- -s $MY_STAGE</kbd>.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Creating an API Gateway is completely declarative. We just configure a function with the <kbd>http</kbd> event type and the pertinent settings, such as the <kbd>path</kbd> and <kbd>method</kbd>. All other settings have defaulted following the <strong>configuration by exception</strong> approach. When you look at the generated <kbd>.serverless/cloudformation-template-update-stack.json</kbd> file, you will see that over 100 lines were generated from just a handful of lines declared in the <kbd>serverless.yml</kbd> file. The API name is calculated based on the combination of the service name declared at the top of the <kbd>serverless.yml</kbd> file and the specified stage. There is a one-to-one mapping between a serverless project and an API Gateway. All the functions in the project declared with an <kbd>http</kbd> event are included in the API.</p>
<p>The signature of the function is the same as all others; however, the contents of the event and the expected response format are specific to the API Gateway service. The <kbd>event</kbd> contains the full contents of the HTTP request including the path, parameters, header, body, and more. The <kbd>response</kbd> requires a <kbd>statusCode</kbd> and options headers and body. The body must be a string, and the header must be an object. I declared the function with the <kbd>cors: true</kbd> setting so that the recipe could include a legitimate set of response headers. We will cover security in detail in <a href="75b256e5-1fe4-4c9e-ab56-28cef7a8a0ab.xhtml">Chapter 5</a>, <em>Securing Cloud-Native Systems</em>. For now, know that security features such as SSL, throttling, and DDoS protection are default features of the AWS API Gateway.</p>
<p>The <kbd>endpoint</kbd> for the API Gateway is declared as a stack output and displayed after the stack is deployed. We will see ways to customize the endpoint in <a href="766f325f-38d5-474b-bac2-79f8af7d01ae.xhtml">Chapter 4</a>, <em>Leveraging the Edge of the Cloud</em>, and in <a href="7ddedd13-fcee-4091-8566-02c9814cb782.xhtml">Chapter 10</a>, <em>Deploying to Multiple Regions</em>. Once you invoke the service, you will be able to see the details of the inputs and outputs, both in the HTTP response as it was coded and then in the function's logs. Take a look at the API Gateway in the AWS Console as well. However, the goal of automation and the <em>Serverless Framework</em> is to eliminate the need to make changes in the console. I looked at the API in the console while writing this book, but other than that I can't remember the last time I actually needed to go into the API Gateway console.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deploying a single-page application</h1>
                </header>
            
            <article>
                
<p>The cloud-native light bulb first turned on in my head when I realized I could deploy a single page application, such as Angular, to an S3 bucket and serve it up globally with no need for servers and load balancers whatsoever. This was my first cloud-native W<em>ow!</em> moment. It was the moment when I began to understand that cloud-native plays by an entirely different set of rules. The combination of S3 and a JavaScript-based UI delivers a web presentation tier with virtually limitless scalability, virtually no cost, and essentially no operation headaches. This recipe demonstrates how straightforward it is to deploy a single-page application.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Create the project from the following template:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch1/deploy-spa --path cncb-deploy-spa</pre>
<ol start="2">
<li>Navigate to the <kbd>cncb-deploy-spa</kbd> directory with <kbd>cd cncb-deploy-spa</kbd>.</li>
<li>Review the file named <kbd>serverless.yml</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">service: cncb-deploy-spa<br/><br/>provider:<br/>  name: aws<br/><br/>plugins:<br/>  - <strong>serverless-spa-deploy</strong><br/><br/>custom:<br/>  <strong>spa</strong>:<br/>    files:<br/>      - source: <strong>./build</strong><br/>        globs: '**/*'<br/>        headers:<br/>          <strong>CacheControl</strong>: max-age=300<br/><br/>resources:<br/>  Resources:<br/>    <strong>WebsiteBucket</strong>:<br/>      Type: AWS::S3::Bucket<br/>      Properties:<br/>        AccessControl: PublicRead<br/>        WebsiteConfiguration:<br/>          IndexDocument: index.html<br/>          ErrorDocument: index.html<br/><br/>  Outputs:<br/>    WebsiteBucketName:<br/>      Value:<br/>        Ref: WebsiteBucket<br/>    <strong>WebsiteURL</strong>:<br/>      Value:<br/>        Fn::GetAtt: [ WebsiteBucket, WebsiteURL ]</pre>
<ol start="4">
<li>Review the file named <kbd>package.json</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">{<br/>  "name": "cncb-deploy-spa",<br/>  "version": "1.0.0",<br/>  "private": true,<br/>  "scripts": {<br/>    <strong>"start": "react-scripts start",</strong><br/>    <strong>"build": "react-scripts build",</strong><br/>    "test": "sls package -r us-east-1 -s test",<br/>    "dp:lcl": "sls deploy -v -r us-east-1",<br/>    "rm:lcl": "sls remove -r us-east-1"<br/>  },<br/>  "dependencies": {<br/>    "react": "16.2.0",<br/>    "react-dom": "16.2.0"<br/>  },<br/>  "devDependencies": {<br/>    "react-scripts": "1.1.1",<br/>    "serverless": "1.26.0",<br/>    "serverless-spa-deploy": "^1.0.0"<br/>  }<br/>}</pre>
<ol start="5">
<li>Install the dependencies with <kbd>npm install</kbd>.</li>
<li>Run the app locally with <kbd>npm start</kbd>.</li>
<li>Run the tests with <kbd>npm test</kbd>.<kbd><br/></kbd></li>
</ol>
<ol start="8">
<li>Review the contents generated in the <kbd>.serverless</kbd> directory.</li>
<li>Build the app with <kbd>npm run build</kbd>.<kbd><br/></kbd></li>
<li>Review the contents generated in the <kbd>build</kbd> directory.</li>
<li>Deploy the stack: </li>
</ol>
<pre style="padding-left: 30px"><strong>$ npm run dp:lcl -- -s $MY_STAGE</strong><br/><br/>&gt; cncb-deploy-spa@1.0.0 dp:lcl &lt;path-to-your-workspace&gt;/cncb-deploy-spa<br/>&gt; sls deploy -v -r us-east-1 "-s" "john"<br/><br/>Serverless: Packaging service...<br/>...<br/>Serverless: Stack update finished...<br/>...<br/>Stack Outputs<br/><strong>WebsiteBucketName</strong>: cncb-deploy-spa-john-websitebucket-1s8hgqtof7la7<br/><strong>WebsiteURL</strong>: http://cncb-deploy-spa-john-websitebucket-1s8hgqtof7la7.s3-website-us-east-1.amazonaws.com<br/>...<br/><strong>Serverless: Path: ./build</strong><br/>Serverless: File: asset-manifest.json (application/json)<br/>Serverless: File: favicon.ico (image/x-icon)<br/>Serverless: File: index.html (text/html)<br/>Serverless: File: manifest.json (application/json)<br/>Serverless: File: service-worker.js (application/javascript)<br/>Serverless: File: static/css/main.c17080f1.css (text/css)<br/>Serverless: File: static/css/main.c17080f1.css.map (application/json)<br/>Serverless: File: static/js/main.ee7b2412.js (application/javascript)<br/>Serverless: File: static/js/main.ee7b2412.js.map (application/json)<br/>Serverless: File: static/media/logo.5d5d9eef.svg (image/svg+xml)</pre>
<ol start="12">
<li>Review the stack and bucket in the AWS Console</li>
<li>Browse to the <kbd>WebsiteURL</kbd> shown in the stack output:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/da5cc4c6-148f-4d68-8592-85bebf07c8f9.png" style="width:55.50em;height:32.42em;"/></div>
<ol start="14">
<li>Remove the stack once you have finished with <kbd>npm run rm:lcl -- -s $MY_STAGE</kbd></li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>The first thing to notice is that we are using all the same development tools for the full stack. This is one of many advantages of using JavaScript for backend development. A single, self-sufficient, full-stack team can develop the frontend application and the BFF service with the same programming language. This can allow for more efficient utilization of team resources.</p>
<p>There are two new standard scripts—<kbd>start</kbd> and <kbd>build</kbd>. <kbd>npm start</kbd> will run the frontend app locally using Node.js as the web server. <kbd>npm run build</kbd> will prepare the application for deployment. I used the <kbd>react-scripts</kbd> library so as not to clutter the example with a detailed ReactJS build process. This recipe uses a small, canned ReactJS example for the same reason. I wanted an app that was just large enough to have something to deploy. ReactJS is not the focus of this recipe or cookbook. There are volumes already written on ReactJS and similar frameworks.</p>
<p>We are creating an S3 bucket, <kbd>WebsiteBucket</kbd>, and configuring it as a website. The stack output displays the <kbd>WebsiteUrl</kbd> used to access the SPA. The SPA will be served from a bucket with no need for servers whatsoever. In this context, we can think of S3 as a global web server.</p>
<p>We are using a Serverless plugin for the first time in this recipe. The <kbd>serverless-spa-deploy</kbd> plugin will upload the SPA files from the <kbd>./build</kbd> directory after the stack is deployed. Note that we are not explicitly naming the bucket. CloudFormation will generate the name with a random suffix. This is important because bucket names must be globally unique. The plugin infers the generated bucket name. The plugin has sensible defaults that can be customized, such as to change the <kbd>CacheControl</kbd> headers for different files. The plugin also empties the bucket, before stack removal.</p>
<div class="packt_infobox">We will build on this architecture in <a href="766f325f-38d5-474b-bac2-79f8af7d01ae.xhtml">Chapter 4</a>, <em>Leveraging the Edge of the Cloud</em>.</div>


            </article>

            
        </section>
    </body></html>