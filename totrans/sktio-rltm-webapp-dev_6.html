<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch06"/>Chapter 6. Deploying and Scaling</h1></div></div></div><p>Running our application on the local server is fine, but making a web application really useful requires deploying it to a public server and making it accessible to others. To run our chat server application on Node.js, along with using protocols such as WebSocket, requires some special considerations. In this chapter, we will take a look at the following:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Things to consider while deploying our application</li><li class="listitem" style="list-style-type: disc">Recommendations for a production-ready deployment</li><li class="listitem" style="list-style-type: disc">Reason why scaling of socket.io applications is different than other web applications</li><li class="listitem" style="list-style-type: disc">How we can scale our chat application</li></ul></div><div><div><div><div><h1 class="title"><a id="ch06lvl1sec44"/>The production environment</h1></div></div></div><p>The first thing we should do before running an application on a production server is to set the environment to <code class="literal">production</code>. Every modern server or framework has separate development and production modes and so<a id="id182" class="indexterm"/> does node. In fact, in node you can set the environment to any name and then have different configurations for that name in your code. To set the environment our node server runs in, we set an environment variable <code class="literal">NODE_ENV</code> to the environment we want to run node in. So, to run node in the <code class="literal">production</code> environment, we use the following line:</p><div><pre class="programlisting">
<strong>$ export NODE_ENV=production</strong>
</pre></div><p>And then run your node application. In <a class="link" href="ch02.html" title="Chapter 2. Getting Started with Node.js">Chapter 2</a>, <em>Getting Started with Node.js</em>, we saw how the first argument in <code class="literal">app.configure</code> is the environment variable we need to configure for:</p><div><pre class="programlisting">app.configure('development', function(){
  app.use(express.errorHandler());
});</pre></div><p>In this snippet we are setting the application to activate <code class="literal">express.errorHandler</code> in the <code class="literal">development</code> environment, which is the default environment. If we have set <code class="literal">NODE_ENV</code> to <code class="literal">production</code>, <code class="literal">express.errorHandler</code> will not be used.<a id="id183" class="indexterm"/>
</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec45"/>Running the application</h1></div></div></div><p>Running the application on the command line using node, like we have been doing until now, works during development; but on a production server where we connect remotely, it is generally not feasible or advisable to keep the console running. There are two ways to handle this, either we run node as a background process redirecting all console output to a file or we run it in a persistent console, to which we can reconnect, using <code class="literal">screen</code> or <code class="literal">byobu</code>.<a id="id184" class="indexterm"/>
</p><p>To run node as a background process, like any other process on Linux, we will use the <code class="literal">&amp;</code> operator and to make sure that it keeps running even after we log out, we will use <code class="literal">nohup</code>:</p><div><pre class="programlisting">
<strong>$ nohup npm start 2&gt;&amp;1 &gt;&gt; npmout.log &amp;</strong>
</pre></div><p>The preceding command will redirect the <code class="literal">stdout</code> and <code class="literal">stderr</code> commands to <code class="literal">npmout.log</code> and will put the npm process in the background.</p><p>Another option is to run node on a long-lasting console, using utilities such as <code class="literal">screen</code> or <code class="literal">byobu</code>. To use this, start <code class="literal">screen</code> and then run your application, as shown here:</p><div><pre class="programlisting">
<strong>$ screen</strong>
<strong>$ npm start</strong>
</pre></div><p>Now we can detach from this screen by using <em>Ctrl</em> +<em>a</em> and then hitting <em>d</em>. This will drop us to the default shell. We can then disconnect. When we connect back to the server, to see the server output, we can attach back to the screen by using the following command:</p><div><pre class="programlisting">
<strong>$ screen -r</strong>
</pre></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec46"/>Keeping it running</h1></div></div></div><p>Not only do we want the application to run when we log out, we want our application to keep running reliably. The production servers are not frequently restarted, and in general we will like to ensure that they come back up as soon as possible when there is a crash, a failure, or an error. For node, generally it means restarting the process as soon as it fails. There are many ways to keep the node server running. In this section we will see two of them:<a id="id185" class="indexterm"/>
</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Monit</li><li class="listitem" style="list-style-type: disc">Forever</li></ul></div><p>Here is how Monit is described <a id="id186" class="indexterm"/>on its website (<a class="ulink" href="http://mmonit.com/monit/">http://mmonit.com/monit/</a>):</p><div><blockquote class="blockquote"><p>Monit is a free open source utility for managing and monitoring processes, programs, files, directories, and filesystems on a UNIX system. Monit conducts automatic maintenance and repair and can execute meaningful causal actions in error situations.</p></blockquote></div><p>Let us begin with installing Monit. On RPM-based or Yum-based systems such as RHEL, Fedora, or CentOS, you can install it using the <a id="id187" class="indexterm"/>
<code class="literal">yum</code> command, as shown here:<a id="id188" class="indexterm"/>
</p><div><pre class="programlisting">
<strong>$ sudo yum install monit</strong>
</pre></div><p>Or on a Debian- or apt-get-based system, you can install Monit using <code class="literal">apt-get</code>:</p><div><pre class="programlisting">
<strong>$ apt-get install monit</strong>
</pre></div><p>For other systems, you can check the installation instructions at the Monit website.</p><p>Once Monit is installed, we can configure it to manage our node application. For this, we will create a configuration file (in our case we will call it <code class="literal">awesome-chat</code>) in <code class="literal">/etc/monit.d/</code> or <code class="literal">/etc/monit/conf.d/</code>, depending on your Monit installation:</p><div><pre class="programlisting">check host objdump with address 127.0.0.1
<strong>    start program = "/bin/sh -c \</strong>
    'NODE_ENV=production \
    node /opt/node_apps/awesome-chat/app.js 2&gt;&amp;1 \
    &gt;&gt; /var/log/awesome-chat.log'"
        as uid nobody and gid nobody
<strong>    stop program  = "/usr/bin/pkill -f \</strong>
  'node /opt/node_apps/awesome-chat/app.js'"
    if failed port 3000 protocol HTTP
        request /
        with timeout 10 seconds
        then restart</pre></div><p>In this file, you should notice the highlighted section. We are emphasizing the program or more importantly, the commands to start/stop our application and then finally configuring Monit to restart the application in case of a failure. This is detected by sending an HTTP request to fetch the page at port <code class="literal">3000</code>.</p><p>That is it; we can start our application with the following command:</p><div><pre class="programlisting">
<strong>$ monit start awesome-chat</strong>
</pre></div><p>And stop it with the following code:</p><div><pre class="programlisting">
<strong>$ monit stop awesome-chat</strong>
</pre></div><p>In case of a crash, Monit <a id="id189" class="indexterm"/>will take care of restarting the application.</p><p>Monit can be used to run and watch any daemon service. It also has a web interface in case you want to check the status, which by default runs on port <code class="literal">2812</code>. You can learn more about Monit on its website and in its manual online.</p><p>Another, more node-specific way to keep our server up and running is <strong>Forever</strong>
<a id="id190" class="indexterm"/> (<a class="ulink" href="https://github.com/nodejitsu/forever">https://github.com/nodejitsu/forever</a>). Forever describes itself as:</p><div><blockquote class="blockquote"><p>A simple CLI tool for ensuring that a given script runs continuously.</p></blockquote></div><p>And that's what is does. Given your node application script, Forever will start it and make sure it keeps running continuously. Since Forever itself is a node application, we will use npm to install it:<a id="id191" class="indexterm"/>
</p><div><pre class="programlisting">
<strong> $ sudo npm install forever -g</strong>
</pre></div><p>Now, to start the application with Forever, it is just a matter of executing the <code class="literal">app.js</code> file with <code class="literal">forever</code>. Just run the following command:</p><div><pre class="programlisting">
<strong>$ forever start app.js</strong>
</pre></div><p>We can see the list of applications running forever with the following command:</p><div><pre class="programlisting">
<strong>$ forever list</strong>
<strong>   0 app.js [ 24597, 24596 ]</strong>
</pre></div><p>To stop the application, use the <code class="literal">forever stop</code> command<a id="id192" class="indexterm"/>:</p><div><pre class="programlisting">
<strong>$ forever stop 0</strong>
</pre></div><p>Visit Forever's github page for understanding more about Forever and its workings.</p><p>There are several other tools on *nix systems to make node run as a daemon. Few of them are as follows</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><a class="ulink" href="http://upstart.ubuntu.com/">http://upstart.ubuntu.com/</a>)</li><li class="listitem" style="list-style-type: disc"><a id="id193" class="indexterm"/>Supervisord (<a class="ulink" href="http://supervisord.org/">http://supervisord.org/</a>)</li><li class="listitem" style="list-style-type: disc"><a id="id194" class="indexterm"/>Daemontools (<a class="ulink" href="http://cr.yp.to/daemontools.html">http://cr.yp.to/daemontools.html</a>)</li></ul></div><p>
</p></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec47"/>Scaling</h1></div></div></div><p>Now that we have <a id="id195" class="indexterm"/>made sure that our application will keep running and also will restart from failures, it's time we start looking at ways to handle millions of users flocking to our chat room. To begin with this, the first step is to put up a load-balancer proxy in front of our server. There are lots of options in this, we can use the Apache HTTP server, Nginx, and so on. All these servers work very well with balancing traditional HTTP traffic, but still have some time to catch up to work with WebSockets. So we will use a server that works on load-balancing TCP/IP itself. <a id="id196" class="indexterm"/>This is <strong>HAProxy</strong> (<a class="ulink" href="http://haproxy.1wt.eu/">http://haproxy.1wt.eu/</a>). This is how HAProxy is described in its official website:</p><div><blockquote class="blockquote"><p>HAProxy is a free, very fast and reliable solution offering high availability, load balancing, and proxying for TCP and HTTP-based applications. It is particularly suited for web sites crawling under very high loads while needing persistence or Layer7 processing. Supporting tens of thousands of connections is clearly realistic with today's hardware.</p></blockquote></div><p>HAProxy works with<a id="id197" class="indexterm"/> frontends and backends. These are configured using the HAProxy configuration file present at <code class="literal">/etc/haproxy/haproxy.cfg</code>. The following file creates a frontend listener at port <code class="literal">80</code> and forwards it to a single server at <code class="literal">3000</code>:</p><div><pre class="programlisting">global
  maxconn 4096

defaults
  environment http

frontend all 0.0.0.0:80
  default_backend www_Node.js

backend www_Node.js
  environment http
  option forwardfor
  server Node.js 127.0.0.1:3000 weight 1 maxconn 10000 check</pre></div><p>In this file, we are defining a frontend listener at <code class="literal">0.0.0.0:80</code> with the default <code class="literal">www_Node.js</code> backend listening at <code class="literal">3000</code> on the same <code class="literal">127.0.0.1</code> server.</p><p>But this configuration is not ready to handle WebSockets. To support and handle WebSockets, refer to the following code block:</p><div><pre class="programlisting">global
  maxconn 4096

defaults
  environment http

frontend all 0.0.0.0:80
<strong>  timeout client 86400000</strong>
  default_backend www_Node.js
<strong>  acl is_websocket hdr(upgrade) -i websocket</strong>
<strong>  acl is_websocket hdr_beg(host) -i ws</strong>

<strong>  use_backend www_</strong>
<strong>Node.js if is_websocket</strong>

backend www_Node.js
  environment http
  option forwardfor
<strong>  timeout server 86400000</strong>
<strong>  timeout connect 4000</strong>
  server Node.js 127.0.0.1:3000 weight 1 maxconn 10000 check</pre></div><p>The first thing we did was to increase the client timeout value, so the client connection doesn't drop off if there is a long inactivity from the client. The <code class="literal">acl</code> lines of code instruct HAProxy to understand and check when we get a <code class="literal">websocket</code> request.<a id="id198" class="indexterm"/>
</p><p>By using the <code class="literal">use_backend</code> instruction, we configure HAProxy to use the <code class="literal">www_Node.js</code> backend to handle the <code class="literal">websocket</code> request. This is useful when you want to serve your static pages from any server, such as Apache HTTP, and want to use node exclusively to handle socket.io.</p><p>Now we come to the part where we would like the request to be handled by more than one node server/process. To do this, first we will tell the proxy to round robin the requests by adding the following instruction to the backend:</p><div><pre class="programlisting">  balance roundrobin</pre></div><p>Then we will add more server entries to the backend:</p><div><pre class="programlisting">  server Node.js 127.0.0.1:4000 weight 1 maxconn 10000 check
  server Node.js 192.168.1.101:3000 weight 1 maxconn 10000 check</pre></div><p>Here we are adding two new node instances: one is a new process listening on port <code class="literal">4000</code> on the same server, while the other one is running on another server, which is accessible to the load-balancer at <code class="literal">192.168.1.101</code> on port <code class="literal">3000</code>.</p><p>We are done configuring the servers and the incoming requests will now be routed between the three node instances that we have configured.</p></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec48"/>The node cluster</h1></div></div></div><p>Node now comes with its own completely rewritten cluster module. Cluster allows node to start multiple processes behind the cluster frontend and monitors and manages them. We will take a quick<a id="id199" class="indexterm"/> look at how to make an application cluster with this module, but note that this is only for creating multiple processes and we must still set up a tool to monitor the cluster master and also a proxy to forward requests to the node server.</p><p>Let us see how we can use the cluster module. The best part about the cluster module is you don't need to actually change your application. Cluster will run a master instance, and we can start multiple instances of our application and they will all listen to a shared port.<a id="id200" class="indexterm"/>
</p><p>Here is the script that we can use for clustering the <code class="literal">app.js</code> file:</p><div><pre class="programlisting">var cluster = require('cluster');

if (cluster.isMaster) {
  var noOfWorkers =
           process.env.NODE_WORKERS || require('os').cpus().length;
  while(workers.length &lt; noOfWorkers) {
    cluster.fork();
  }
} else {
  require('./app.js');
}</pre></div><p>So, what's happening here? The first thing we do is use <code class="literal">require</code> on the <code class="literal">cluster</code> module. In the next line, we are checking whether the instance that is started is the master process or the worker.</p><p>If it is the master process, we check if the <code class="literal">NODE_WORKERS</code> environment variable is set, else we get the number of processors available on the system our server is running on. To set the <code class="literal">NODE_WORKERS</code> environment variable, you can run the following:</p><div><pre class="programlisting">
<strong>$ export NODE_WORKERS=2</strong>
</pre></div><p>The previous command will tell the cluster to start two nodes.</p><p>Now, in the loop, we call <code class="literal">fork</code> on the cluster. This calls <code class="literal">child_process.fork</code> so that the master and the started workers can communicate via IPC.</p><p>When the cluster process is run from <code class="literal">fork</code>, <code class="literal">cluster.isMaster</code> is false and so our <code class="literal">app.js</code> script is in the current worker process.</p><p>In our application, when we call <code class="literal">server.listen(3000)</code>, the worker serializes this and sends over the request to the server, the server checks if it already is listening on that port, and returns the handle for the listener, if it is present. Else, the server starts listening on the port and passes on the handle to the newly created listener.</p><p>Since all our workers request to listen on port <code class="literal">3000</code>, the server will start listening on the port when the first worker starts and will pass on the same handler to all the workers. When a request comes in, it will be handled by any worker that can take it up and process it.</p><p>Since our monitoring tool (Monit or Forever, or others) will now be monitoring only the master process, it becomes the master's responsibility to monitor the workers. This means that the cluster should restart any worker that happens to die. We will do this, by adding the following event handler in the master process:<a id="id201" class="indexterm"/>
</p><div><pre class="programlisting">cluster.on('exit', function (worker, code, signal){
  var exitCode = worker.process.exitCode;
  console.log('worker ' + worker.process.pid +
                               ' died ('+exitCode+'). restarting...');
  cluster.workers[worker.id].delete();
  cluster.fork();
});</pre></div><p>Monitoring of the process is done by listening to the <code class="literal">exit</code> event<a id="id202" class="indexterm"/> on the socket. This is the event that will be triggered when any worker dies. The event handler will get the worker, its exit code, and the signal that caused the process to be killed. In the handler, we log the death and we start a new worker process using <code class="literal">cluster.fork()</code>.</p><p>Now we can start the new clustered application; we'll run <code class="literal">cluster.js</code> instead of <code class="literal">app.js</code>. So change the <code class="literal">start</code> script in <code class="literal">package.json</code> to run <code class="literal">cluster.js</code>:</p><div><pre class="programlisting"> "scripts": {
    "start": "node cluster",
  }</pre></div><p>And then run the application with npm.</p><div><pre class="programlisting">
<strong>npm start</strong>
</pre></div><p>This will start the application and everything will look just as it was. But when you start using it, you'll notice that there are errors while trying to connect to a room, or while sending messages. These errors are because we are using an in-memory store for our Express.js sessions and socket.io uses an in-memory store to store and transfer all the messages.</p></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec49"/>Scaling up the application</h1></div></div></div><p>In the previous section we saw how we can cluster a Node.js app and how it remains restricted due to our application mechanisms. In its current state, the application uses an in-memory store to<a id="id203" class="indexterm"/> keep the session data. This store is local to the Node.js instance and so won't be accessible in any another clustered instance. Also, the data will be lost in a Node.js instance restart. So, what we need is a way to store the session in a persistent store. Also, we want to configure socket.io such that all its instances use a shared pub-sub and data store. The Connect framework has an extension mechanism so a new store can be plugged in, and there is one store that is persistent as well as excels at pub-sub. It is the <strong>Redis</strong>
<strong> Session Store</strong>.<a id="id204" class="indexterm"/>
</p><p>Redis (<a class="ulink" href="http://redis.io/">http://redis.io/</a>) is a high performance, distributed, open source key-value store that can also be used as a queue. We will use Redis and corresponding Redis stores to provide a reliable, distributed, and shared store and pub-sub queue. Please check out the instructions to install the <a id="id205" class="indexterm"/>Redis server on your operating system and start it up.</p><p>Let's make a few changes to our chat application, beginning with <code class="literal">package.json</code>:</p><div><pre class="programlisting">    "connect-redis":"*",
    "redis":"*"</pre></div><p>This will add support for the Connect/Express.js Redis store and the Redis connection client. Let's first get Express.js to use Redis; to do so, edit <code class="literal">app.js</code> by referring to the following code snippet:</p><div><pre class="programlisting">var express = require('express')
  , routes = require('./routes')
  , http = require('http')
  , path = require('path')
  , connect = require('connect')
<strong>  , RedisStore = require('connect-redis')(express);</strong>

var app = express();

<strong>var sessionStore = new RedisStore();</strong>

//Existing Code</pre></div><p>So the two changes we make here are pulling in the Redis session store and then we can replace the session store to be an instance of <code class="literal">RedisStore</code>. That's all that is needed to get Express running using the Redis store.</p><p>The next thing we need to do is get socket.io using Redis. So, let us edit <code class="literal">socket.js</code>:</p><div><pre class="programlisting">var io = require('socket.io')
<strong>  , redis = require('redis')</strong>
<strong>  , RedisStore = require('socket.io/lib/stores/redis')</strong>
<strong>  , pub    = redis.createClient()</strong>
<strong>  , sub    = redis.createClient()</strong>
<strong>  , client = redis.createClient();</strong>

exports.initialize = function (server) {
  io = io.listen(server);

<strong>  io.set('store', new RedisStore({</strong>
<strong>      redisPub : pub</strong>
<strong>    , redisSub : sub</strong>
<strong>    , redisClient : client</strong>
<strong>  }));</strong>

  //Existing Code
}</pre></div><p>The first thing in the preceding code snippet that we are doing is <code class="literal">require ('redis')</code>, which provides the client and <code class="literal">redisStore</code> from socket.io, which provides redis backed for socket.io. Then we create three different Redis clients to use for pub-sub and the data store:</p><div><pre class="programlisting">
<strong>  io.set('store', new RedisStore({</strong>
<strong>      redisPub : pub</strong>
<strong>    , redisSub : sub</strong>
<strong>    , redisClient : client</strong>
<strong>  }));</strong>
</pre></div><p>In the previous <a id="id206" class="indexterm"/>code snippet, we configure socket.io to use Redis for the queue and data store. And we are ready to go! Now run the application again using the following command:</p><div><pre class="programlisting">
<strong>npm start</strong>
</pre></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec50"/>Tips for node in production</h1></div></div></div><p>Here are some tips to help<a id="id207" class="indexterm"/> us execute node in production:</p><div><ol class="orderedlist arabic"><li class="listitem">Run the server in the <code class="literal">production</code> environment.</li><li class="listitem">Never expose the node application directly on the Internet; always use a proxy. Servers such as Apache HTTP, Nginx, and HAProxy have been hardened and made robust over the years in production to make them secure against various kinds of attacks, especially DOS and DDOS. Node is new; it may become stable over time but today it is not recommended to be put directly on the front.</li><li class="listitem">Never run node as root. Well, that is the advice for any application server, and it applies to node too. If we run node as root, there are chances of hackers gaining root access or running some harmful code as root. So, never ever run it as root!</li><li class="listitem">Always run more than one node process. Node is a single-threaded, single-process application server. An error in the application can bring the server down. So, always have more than one process for reliability. Also, thinking in terms of 1+ processes keeps us ready for scaling out when the need comes.</li><li class="listitem">Always use a monitor. Monit, Forever, Upstart pick one you like, but always use it. Better safe than sorry.</li><li class="listitem">Never use <code class="literal">MemoryStore</code> in <code class="literal">production</code>; <code class="literal">MemoryStore</code> is for the <code class="literal">development</code> environment; I recommend using <code class="literal">RedisStore</code> even in <code class="literal">development</code>.<a id="id208" class="indexterm"/></li><li class="listitem">Log all errors. Everything runs fine until it doesn't! And when something goes wrong, logs are your best friend. Try to catch exceptions as close to the cause as possible and log all the relevant information in the context. Don't just log some error message, log all the relevant objects.</li><li class="listitem">Never block unless there is no alternative. Node runs on an event loop, and blocking for one request will cause unwanted overheads and degrade performance for all requests.</li><li class="listitem">Always keep your server, node, and all dependency modules up-to-date.</li></ol></div></div>
<div><div><div><div><h1 class="title"><a id="ch06lvl1sec51"/>Summary</h1></div></div></div><p>In this section, we saw the work involved in putting our application to production. We must remember that these are not the only ways to do it. For every task we did, there are many other ways of doing them, and there is no one solution that fits all scenarios. But now that we know what is expected out of a <code class="literal">production</code> environment, we can research the options and choose one according to our requirements.</p></div></body></html>