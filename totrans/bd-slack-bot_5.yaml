- en: Chapter 5. Understanding and Responding to Natural Language
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've built bots that can play games, store data, and provide useful information.
    The next step isn't information gathering, it's processing. This chapter will
    introduce **natural language processing** (**NLP**) and show how we can use it
    to enhance our bots even further.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: A brief introduction to natural language
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Node implementation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Natural language processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Natural language generation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Displaying data in a natural way
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A brief introduction to natural language
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should always strive to make your bot as helpful as possible. In all the
    bots we've made so far, we've awaited clear instructions via a key word from the
    user and then followed said instructions as far as the bot is capable. What if
    we could infer instructions from users without them actually providing a key word?
    Enter **natural language processing** (**NLP**).
  prefs: []
  type: TYPE_NORMAL
- en: NLP can be described as a field of computer science that strives to understand
    communication and interactions between computers and human (natural) languages.
  prefs: []
  type: TYPE_NORMAL
- en: In layman's terms, NLP is the process of a computer interpreting conversational
    language and responding by executing a command or replying to the user in an equally
    conversational tone.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of NLP projects are digital assistants such as the iPhone's Siri. Users
    can ask questions or give commands and receive answers or confirmation in natural
    language, seemingly from a human.
  prefs: []
  type: TYPE_NORMAL
- en: One of the more famous projects using NLP is IBM's Watson system. In 2011, Watson
    famously competed against human opponents in the TV show Jeopardy! and won first
    place.
  prefs: []
  type: TYPE_NORMAL
- en: The NLP field is a large and complicated one, with many years of research performed
    by prestigious academic institutions and by large technology companies. Watson
    alone took 5 years, $3 million, and a small army of academics and engineers to
    build. In this chapter, the main concepts will briefly be described and a practical
    example given.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s take a step back and see how NLP might benefit our bots. If we
    built a bot that retrieves the weather report, we could imagine the command to
    look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This would return tomorrow's weather report for the city of Amsterdam. What
    if the bot could retrieve the weather report without requiring a command to be
    issued? For instance, if a Slack user were to send the message "Will it rain tomorrow?",
    then the bot would respond with tomorrow's weather report. This is NLP at work;
    it is the breakdown of natural language into instructions that can be interpreted
    by the program as a command.
  prefs: []
  type: TYPE_NORMAL
- en: To help us in our understanding of NLP, we will be using a helper library that
    abstracts the more complicated algorithms away. A good NLP framework is the Python
    language-based **natural language** **toolkit** (**NLTK**) available at [http://www.nltk.org/](http://www.nltk.org/).
  prefs: []
  type: TYPE_NORMAL
- en: Luckily for us, a project to port the major functions of NLTK to Node has been
    functioning for some time and has reached a high enough level of maturity for
    us to use it seamlessly with our existing JavaScript projects. Known as Natural
    ([https://github.com/NaturalNode/natural](https://github.com/NaturalNode/natural)),
    this library will be our key point of entry to the world of NLP.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start by introducing some of the more common NLP algorithms. Afterwards,
    we'll use our newfound knowledge by building a simple weather bot, as outlined
    earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Fundamentals of NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'NLP, at its core, works by splitting a chunk of text (also referred to as a
    corpus) into individual segments or tokens and then analyzing them. These tokens
    might simply be individual words but might also be word contractions. Let''s look
    at how a computer might interpret the phrase: *I have watered the plants*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we were to split this corpus into tokens, it would probably look something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The word `the` in our corpus is unnecessary as it does not help to understand
    the phrase''s intent— the same for the word `have`. We should therefore remove
    the surplus words:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Already, this is starting to look more usable. We have a personal pronoun in
    the form of an actor (`I`), an action or verb (`watered`), and a recipient or
    noun (`plants`). From this, we can deduce exactly which action is enacted to what
    and by whom. Furthermore, by conjugating the verb `watered`, we can establish
    that this action occurred in the past. Consider how the context and meaning of
    the phrase changes when we make minor changes: *We are watering the plant*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'By using the same process as previously, we get the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The meaning of the phrase has dramatically changed: there are multiple actors
    involved, the action is in the present and the recipient is singular. The challenge
    of NLP is the ability to analyze such nuances, arrive at a conclusion with a high
    enough confidence level, and then perform actions based on that conclusion.'
  prefs: []
  type: TYPE_NORMAL
- en: A computer, much like a person, learns this nuance by practice and by picking
    up patterns. A common NLP term is to train your system to recognize context in
    a corpus. By providing a large amount of predefined phrases to our system, we
    can analyze said phrases and look for similar ones in other corpus'. We will talk
    more about how to use this training or classifying technique later.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now look at how we can actually perform the actions explained in the beginning
    of this section, starting with the splitting of a corpus into a series of tokens,
    also known as **tokenizing**.
  prefs: []
  type: TYPE_NORMAL
- en: Tokenizers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Start by creating a new project with `npm init`. Name your bot "weatherbot"
    (or something similar), and install the Slack and Natural APIs with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Copy our `Bot` class from the previous chapters and enter the following in
    `index.js`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Start up your Node process and type a test phrase into Slack:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Tokenizers](img/B05384_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The returned tokenized message
  prefs: []
  type: TYPE_NORMAL
- en: Through the use of tokenization, the bot has split the given phrase into short
    fragments or **tokens**, ignoring punctuation and special characters. Note that
    we are using the native `JSON` object's `stringify` method to convert the JavaScript
    array into a string before sending it to the channel.
  prefs: []
  type: TYPE_NORMAL
- en: 'This particular tokenized algorithm will handle contractions (for example,
    `hasn''t`) by removing the punctuation and splitting the word. Depending on our
    use case, we might want to use a different algorithm. Luckily, `natural` provides
    three different algorithms. Each algorithm returns slightly different results
    for a corpus. To learn more about these algorithms, visit the `natural` GitHub
    page: [https://github.com/NaturalNode/natural#tokenizers](https://github.com/NaturalNode/natural#tokenizers).'
  prefs: []
  type: TYPE_NORMAL
- en: 'A majority of these algorithms use punctuation (spaces, apostrophes, and so
    on) to tokenize phrases, whereas the Treebank algorithm analyses contractions
    (for example, `wanna` and `gimme`) to split them into regular words (`want to`
    and `give me` in the case of `wanna` and `gimme`). Let''s use Treebank for the
    next example, and replace the line where the tokenizer is initialized with the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, return to Slack and try another test message:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Tokenizers](img/B05384_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The Treebank algorithm handles contractions differently
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice two important things here: the `haven''t` contraction was split into
    two parts, the root verb (`have`) and the contracted add-on (`not`). Furthermore,
    the word `cannot` was split into two separate words, making the command easier
    to deal with. This also makes certain slang words like `lemme` and `gotta` easier
    to process. By splitting the contracted word into two, we can more easily infer
    whether the phrase is positive or negative. `Can` by itself means positive; however,
    if it is followed by `not` it changes the context of the phrase to be negative.'
  prefs: []
  type: TYPE_NORMAL
- en: Stemmers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Sometimes, it is useful to find the root or `stem` of a word. In the English
    language, irregular verb conjugations are not uncommon. By deducing the root of
    a verb, we can dramatically decrease the amount of calculations needed to find
    the action of the phrase. Take the verb `searching` for example; for the purpose
    of bots, it would be much easier to process the verb in its root form `search`.
    Here, a stemmer can help us determine said root. Replace the contents of `index.js`
    with the following to demonstrate stemmers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s see what stemming a word returns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Stemmers](img/B05384_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The conjugated versions of a verb are often different from its root
  prefs: []
  type: TYPE_NORMAL
- en: As expected, `searching` is stemmed into `search` but (more interestingly) the
    token `shining` is stemmed into `shine`. This shows that the process of stemming
    is more than simply removing `-ing` from the tail end of a token. Now, we can
    analyze our tokenized and stemmed corpus and pick out certain verbs or actions.
    For instance, after stemming, the phrases *I went swimming* and *I swam*, both
    contain the verb `swim`, which means we only have to search for one term (`swim`)
    rather than two (`swimming` and `swam`).
  prefs: []
  type: TYPE_NORMAL
- en: Stemming also works for removing plurals from words. For instance, `searches`
    stems into `search` and `rains` into `rain`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s combine the concepts of tokenizing and stemming into one program to
    see its effects. Once again, replace `index.js` with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Note that we call `tokenizeAndStem` on `message.text`. This might seem odd,
    until you realize that we have attached the `tokenizeAndStem` method to the `String`
    object's prototype in earlier code, highlighted in the preceding code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Switch over to the Slack client and you should see:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Stemmers](img/B05384_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Tokenizing and stemming to produce useful results
  prefs: []
  type: TYPE_NORMAL
- en: The tokenizer and stemming combination has automatically left out very common
    words such as `it` and `in`, leaving us with a sentence distilled into the most
    important tokens of the original input.
  prefs: []
  type: TYPE_NORMAL
- en: Using just the tokenized and stemmed result, we can infer that the user wishes
    to know about the weather in Amsterdam. Furthermore, we can choose to exclude
    the word `is` from our results. This leaves us with `rain amsterdam`, which is
    enough information for us to make a weather API call.
  prefs: []
  type: TYPE_NORMAL
- en: String distance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A string distance measuring algorithm is a calculation of how similar two strings
    are to one another. The strings `smell` and `bell` can be defined as similar,
    as they share three characters. The strings `bell` and `fell` are even closer,
    as they share three characters and are only one character apart from one another.
    When calculating string distance, the string `fell` will receive a higher ranking
    than `smell` when the distance is measured between them and `bell`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The NPM package `natural` provides three different algorithms for string distance
    calculation: Jaro-Winkler, the Dice coefficient, and the Levenshtein distance.
    Their main differences can be described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dice coefficient**: This calculates the difference between strings and represents
    the difference as a value between zero and one. Zero being completely different
    and one meaning identical.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Jaro-Winkler**: This is similar to the Dice Coefficient, but gives greater
    weighting to similarities at the beginning of the string.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Levenshtein distance**: This calculates the amount of edits or steps required
    to transform one string into another. Zero steps means the strings are identical.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s use the Levenshtein distance algorithm to demonstrate its use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'A popular use for string distances is to perform a fuzzy search, where the
    search returns values that are a low string distance from the requested query.
    String distance calculation can be particularly useful for bots when processing
    a command with a typo in it. For instance, if a user meant to request the weather
    report for Amsterdam by sending the command `weather amsterdam`, but instead typed
    `weater amsterdam`. By calculating the Levenshtein distance between the strings,
    we can make an educated guess as to the user''s intent. Check out the following
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s the result in Slack:'
  prefs: []
  type: TYPE_NORMAL
- en: '![String distance](img/B05384_05_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Calculating string distance can make your bot a lot more user friendly
  prefs: []
  type: TYPE_NORMAL
- en: We set our tolerance to be quite low in this case, allowing for two mistakes
    or `steps` to indicate a hit. In production code, it would make sense to reduce
    the tolerance to only one step.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Be careful when choosing which string similarity algorithm to use, as each might
    determine distance differently. For instance, when using the Jaro-Winkler and
    Dice Coefficient algorithms, a score of 1 indicates that the two strings are identical.
    With the Levenshtein difference, it is the opposite, where 0 means identical and
    the higher the number the larger the string distance.
  prefs: []
  type: TYPE_NORMAL
- en: Inflection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An inflector can be used to convert a noun back and forth from its singular
    and plural forms. This is useful when generating natural language, as the plural
    versions of nouns might not be obvious:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code will output `viri` and `octopus`, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inflectors may also be used to transform numbers into their ordinal forms;
    for example, 1 becomes 1st, 2 becomes 2nd, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This outputs `25th`, `42nd`, and `111th`, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example of the inflector used in a simple bot command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now when asked what day it is, our bot can respond a little more naturally:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Inflection](img/B05384_05_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Inflection can make your bot more personable
  prefs: []
  type: TYPE_NORMAL
- en: 'This leads us to our next topic: how to display data in an easy-to-understand
    way.'
  prefs: []
  type: TYPE_NORMAL
- en: Displaying data in a natural way
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s build our bot''s weather functionality. To do this, we will be using
    a third-party API called **Open Weather Map**. The API is free to use for up to
    60 calls per minute, with further pricing options available. To obtain the API
    key, you will need to sign up here: [https://home.openweathermap.org/users/sign_up](https://home.openweathermap.org/users/sign_up).'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Remember that you can pass variables such as API keys into Node from the command
    line. To run the weather bot, you could use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you signed up and obtained your API key, copy and paste the following
    code into `index.js`, replacing `process.env.WEATHER_API_KEY` with your newly
    acquired Open Weather Map key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Using familiar code, our bot performs the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Initializes the stemmer from the natural package and attaches it to the string
    prototype
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Awaits the `weather` command and uses the `getWeather` function to retrieve
    the Open Weather Map weather data via an **Asynchronous JavaScript and XML** (**AJAX**)
    call
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sends a formatted weather message to the channel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here''s the bot in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Displaying data in a natural way](img/B05384_05_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A simple weatherbot
  prefs: []
  type: TYPE_NORMAL
- en: 'After receiving the command and the place name, the bot sends an AJAX request
    to Open Weather Map with the place name as the argument. In return, we get a JSON
    response that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Note how among the plethora of information we get back there is the full, capitalized
    name of the place and useful information such as minimum and maximum temperature.
    For our bot's initial purpose, we will use the temperature object (`main`), the
    `name` property, and the `description` inside the `weather` object.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a simple bot which responds to the command `weather`, let's
    see if we can use NLP to get more specific answers.
  prefs: []
  type: TYPE_NORMAL
- en: Notice how the Open Weather Map AJAX call was abstracted out into the `getWeather`
    function. This means we can use the same function for both command calls and NLP
    calls.
  prefs: []
  type: TYPE_NORMAL
- en: Before we continue, we should discuss the right use case for NLP techniques.
  prefs: []
  type: TYPE_NORMAL
- en: When to use NLP?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It might be tempting to have weatherbot listen to and process all messages
    sent in the channel. This immediately poses some problems:'
  prefs: []
  type: TYPE_NORMAL
- en: How do we know if the message sent is a query on the weather or is completely
    unrelated?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which geographic location is the query about?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the message a question or a statement? For example, the difference between
    *Is it cold in Amsterdam* and *It is cold in Amsterdam*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Although an NLP-powered solution to the preceding questions could probably
    be found, we have to face facts: it''s likely that our bot will get at least one
    of the above points wrong when listening to generic messages. This will lead the
    bot to either provide bad information or provide unwanted information, thus becoming
    annoying. If there''s one thing we need to avoid at all costs, it''s a bot that
    sends too many wrong messages too often.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s an example of a bot using NLP and completely missing the point of the
    message sent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![When to use NLP?](img/B05384_05_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: A clearly misunderstood message
  prefs: []
  type: TYPE_NORMAL
- en: If a bot were to often mistake your unrelated messages for actual commands,
    you can imagine users disabling your bot very quickly after enabling it.
  prefs: []
  type: TYPE_NORMAL
- en: The best possible solution would be to create a bot that has human-level natural
    language processing. If that sentence doesn't concern you, then consider that
    human-level natural language processing is considered an AI-complete problem.
    Essentially, it is equivalent to attempting to solve the problem of making computers
    as intelligent as humans.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, we should focus on how to make our bot perform as best as possible
    with the resources at hand. We can start by introducing a new rule: use NLP as
    an enhancement for your bot, not as a main feature.'
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of this is to only use NLP techniques when the bot is directly addressed
    in a mention. A mention in a Slack channel is when a user sends a message directly
    to another user in a public channel. This is done by prefacing the user''s name
    with the `@` symbol. Bots can also be mentioned, which means we should be able
    to process the weather command in two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The user prefaces their request with the command `weather`: `weather is it
    raining in Amsterdam`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user uses a mention `@weatherbot is it raining in Amsterdam`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mentions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To implement the second point, we need to revisit our `Bot` class and add mention
    functionality. In the `Bot` class'' constructor, replace the `RTM_CONNECTION_OPENED`
    event listener block with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The only change here is the addition of the bot''s `id` to the `this` object.
    This will help us later. Now, replace the `respondTo` function with this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We've improved the `respondTo` function by first checking whether `this.id`
    exists. If not, it means that we've not yet successfully connected to Slack. Therefore,
    we wait till Slack has connected (remember how we set `this.id` in the constructor
    after connecting) and then proceed. This is the second time we listen for the
    `RTM_CONNECTION_OPENED` event. Luckily, the first time it happens in the `Bot`
    class' constructor, which means this listener will always trigger second as it
    was added later. This ensures that `this.id` is defined once the event triggers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The function now takes either a string (the keywords we''re looking for) or
    an object as its first parameter. In the case of an object, we check to see whether
    the mention property is truthy; if so, we create a regular expression that purposefully
    looks for the mention syntax. When a message is received, a mention takes the
    following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '`<@[USER_ID]>: [REST OF MESSAGE]`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Switch back to `index.js` and let''s try out our new code by replacing the
    previous `respondTo` block of `weather`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now when we mention our bot and pass a city name, we get the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Mentions](img/B05384_05_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Mentions can be used to identify specific behavior
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Mentions are a great way to ensure that the message sent is meant to be a command
    for your bot. When implementing a natural language solution, it is highly recommended
    you use mentions.
  prefs: []
  type: TYPE_NORMAL
- en: Now with mentions in place, let's look at how we're going to answer weather-related
    questions in an NLP way. We briefly talked about classification and the training
    of NLP systems earlier. Let's revisit that topic and see how we can use it for
    our weather bot.
  prefs: []
  type: TYPE_NORMAL
- en: Classifiers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Classification is the process of training your bot to recognize a phrase or
    pattern of words and to associate them with an identifier. To do this, we use
    a classification system built into `natural`. Let''s start with a small example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The first log prints:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The second log prints:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The classifier stems the string to be classified first, and then calculates
    which of the trained phrases it is the most similar to by assigning a weighting
    to each possibility.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can view the weightings by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: To get accurate and reliable results, you must train your bot with potentially
    hundreds of phrases. Luckily, you can also import training data JSON files into
    the classifier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Save your classifier training data by creating a `classifier.json` file in
    your directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Retrieve the same file with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Now let's try and use classifiers to power our weatherbot.
  prefs: []
  type: TYPE_NORMAL
- en: Using trained classifiers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An example `classifier.json` file that contains training data for weather is
    included with this book. For the rest of this chapter, we will assume that the
    file is present and that we are loading it in via the preceding method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Replace your `respondTo` method call with the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the Node process and ask weatherbot a series of natural language questions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using trained classifiers](img/B05384_05_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Weatherbot can now understand conversational language
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the code and see what''s going on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: First, we check to see whether the keyword `set` is used immediately after the
    `@weatherbot` mention. If yes, this sets the following arguments to be the default
    city of the user. We use a simple settings object here, but this could be improved
    by using a data store such as Redis, explained in [Chapter 4](ch04.html "Chapter 4. Using
    Data"), *Using Data*.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see an example of the `set` behavior in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using trained classifiers](img/B05384_05_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Setting a city saves users from having to type in their place name for each
    query
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we attempt to find the place we want to get weather information for:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We expect all weather queries with a place name to follow the pattern `[condition]
    in [place name]`. This means we can make a reasonable assumption that all tokens
    after the word `in` are the place name to use in our AJAX call.
  prefs: []
  type: TYPE_NORMAL
- en: If the word `in` does not appear and there is no set place name, then we send
    back an error message with a best guess example of how to use weatherbot.
  prefs: []
  type: TYPE_NORMAL
- en: This is, of course, not the most ideal way to detect a place name—determining
    which part of the phrase is a place name is notoriously difficult, especially
    when the name in question comprises multiple words like `New York` or `Dar es
    Salaam`. One possible solution would be to train our bot with a series of city
    name classifiers (essentially one training phrase per city). Other solutions include
    the Query GeoParser [http://www2009.eprints.org/239/](http://www2009.eprints.org/239/)
    and the Stanford Named Entity Recognizer [http://nlp.stanford.edu/software/CRF-NER.shtml](http://nlp.stanford.edu/software/CRF-NER.shtml).
  prefs: []
  type: TYPE_NORMAL
- en: 'Next we use the classifier to identify which key words the message should be
    associated with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Some of the classifier''s phrases are added with an array as the second argument,
    for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: This means that the returned value from the `classifier.classify` method is
    a comma-separated string value. We transform it into a JavaScript array by using
    the `Array.split` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we set the typing indicator, which is good practice when making an
    asynchronous call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The value at index 0 of the option object is the state of the question, in this
    case whether the message is related to the temperature, condition, or generic
    weather.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our options are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Temperature**: Send the temperature (in Celsius) to the channel'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Conditions**: Send the weather conditions (for example, raining and windy)
    to the channel'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Weather**: Send both the conditions and temperature to the channel'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is important to understand the underlying concepts of classification and
    training to build a smarter bot. It is, however, possible to abstract the problem
    of obtaining training data by using the third-party service wit.ai ([https://wit.ai/](https://wit.ai/)).
    wit.ai is a free service, created by Facebook, which allows you to train phrases
    (referred to as **entities** by wit.ai) and to retrieve analysis on a given phrase
    easily and quickly via an AJAX request.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, you could use services such as api.ai ([https://api.ai/](https://api.ai/))
    or Microsoft's LUIS ([https://www.luis.ai/](https://www.luis.ai/)). Bear in mind,
    however, that although these services are free and easy to use, it is not guaranteed
    that they will be free or even around in the future. Unless you are attempting
    to build something that requires extremely accurate NLP services, it is almost
    always better to create your own implementation with open source NLP libraries.
    This has the added benefit of controlling and owning your own data, something
    which is not guaranteed when using a third-party service.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how to process language, we should take a look at how to transform
    our data into human understandable natural language.
  prefs: []
  type: TYPE_NORMAL
- en: Natural language generation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Natural language can be defined as a conversational tone in a bot's response.
    The purpose here is not to hide the fact that the bot is not human, but to make
    the information easier to digest.
  prefs: []
  type: TYPE_NORMAL
- en: The `flavorText` variable from the previous snippet is an attempt to make the
    bot's responses sound more natural; in addition, it is a useful technique to cheat
    our way out of performing more complex processing to reach a conversational tone
    in our response.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Natural language generation](img/B05384_05_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Weatherbot's politician-like response
  prefs: []
  type: TYPE_NORMAL
- en: Notice how the first weather query is asking whether it's cold or not. Weatherbot
    gets around giving a yes or no answer by making a generic statement on the temperature
    to every question.
  prefs: []
  type: TYPE_NORMAL
- en: This might seem like a cheat, but it is important to remember a very important
    aspect of NLP. *The more complex the generated language, the more likely it is
    to go wrong.* Generic answers are better than outright wrong answers.
  prefs: []
  type: TYPE_NORMAL
- en: This particular problem could be solved by adding more keywords to our classifiers
    and adding more phrases. Currently, our `classifier.json` file contains 50 phrases
    related to the weather; adding more phrases could get us a clearer idea of what
    is being asked of weatherbot.
  prefs: []
  type: TYPE_NORMAL
- en: This leads us to a very important point in the pursuit of natural language generation.
  prefs: []
  type: TYPE_NORMAL
- en: When should we use natural language generation?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Sparingly, is the answer. Consider Slackbot, Slack''s own in-house bot used
    for setting up new users, amongst other things. Here''s the first thing Slackbot
    says to a new user:'
  prefs: []
  type: TYPE_NORMAL
- en: '![When should we use natural language generation?](img/B05384_05_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The humble bot
  prefs: []
  type: TYPE_NORMAL
- en: Immediately, the bot's restrictions are outlined and no attempts to hide the
    fact that it is not human are made. Natural language generation is at its best
    when used to transform data-intensive constructs such as JSON objects into easy
    to comprehend phrases.
  prefs: []
  type: TYPE_NORMAL
- en: The Turing Test is a famous test developed in 1950 by Alan Turing to assess
    a machine's ability to make itself indistinguishable from a human in a text-only
    sense. Like Slackbot, you should not strive to make your bot Turing Test complete.
    Instead, focus on how your bot can be the most useful and use natural language
    generation to make your bot as easy to use as possible.
  prefs: []
  type: TYPE_NORMAL
- en: The uncanny valley
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The uncanny valley is a term used to describe systems that act and sound like
    humans, but are somehow slightly off. This slight discrepancy actually leads to
    the bot feeling a lot more unnatural, and this is the exact opposite of what we
    are trying to accomplish with natural language generation. Instead, we should
    avoid trying to make the bot perfect in its natural language responses; the chances
    of finding ourselves in the uncanny valley get higher the more human-like we try
    to make a bot sound.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, we should focus on making our bots useful and easy to use, over making
    its responses natural. A good principle to follow is to build your bot to *be
    as smart as a puppy*, a concept championed by Matt Jones ([http://berglondon.com/blog/2010/09/04/b-a-s-a-a-p/](http://berglondon.com/blog/2010/09/04/b-a-s-a-a-p/)):'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Making smart things that don''t try to be too smart and fail, and indeed,
    by design, make endearing failures in their attempts to learn and improve. Like
    puppies."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let's expand our weatherbot to make the generated response sound a little more
    natural (but not too natural).
  prefs: []
  type: TYPE_NORMAL
- en: 'First, edit the `getWeather` function to include `data` as a final argument
    in its callback call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Then add the `data` variable to the callback we assign in the mention `respondsTo`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `switch` statement within the `getWeather` call, replace the `weather`
    case with this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Asking for the weather in a city will now instruct our bot to send this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The uncanny valley](img/B05384_05_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Weatherbot can now be a bit more specific with its reporting
  prefs: []
  type: TYPE_NORMAL
- en: Here, we've simply taken the JSON returned from the AJAX call and formatted
    the data into something a bit more legible by humans. Rainfall is included, but
    only if there actually was any in the last 3 hours (if not, the `rain` property
    is omitted from the returned data). Cloud cover is represented by a percentage,
    which is perfect for us as we can assign predetermined statements (`patchy`, `almost
    completely clear` and `clear skies`) depending on that percentage.
  prefs: []
  type: TYPE_NORMAL
- en: When generating natural language, think of how your data can be presented. Percentages
    are an excellent way of assigning a verbal value. For example, anything between
    80 and 100 percent can use adverbs like `extremely` or `very`, whereas we can
    use `barely` and `very little` for 0 to 20 percent.
  prefs: []
  type: TYPE_NORMAL
- en: For some data sets, a paragraph might be easier to digest rather than a list
    or pure data.
  prefs: []
  type: TYPE_NORMAL
- en: The result is a bot that, in a conversational tone, can give a weatherman-like
    weather report on the area in question.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed what NLP is and how it can be leveraged to make
    a bot seem far more complex than it really is. By using these techniques, natural
    language can be read, processed, and responded to in equally natural tones. We
    also covered the limitations of NLP and understood how to differentiate between
    good and bad uses of NLP.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore the creation of web-based bots, which can
    interact with Slack using webhooks and slash commands.
  prefs: []
  type: TYPE_NORMAL
