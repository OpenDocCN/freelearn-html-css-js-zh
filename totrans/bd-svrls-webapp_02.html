<html><head></head><body>
        

                            
                    <h1 class="header-title">Getting Started with AWS</h1>
                
            
            
                
<p>All major public cloud vendors currently provide serverless products. In this book, the focus will be on AWS, which is often considered the best option with regards to features, costs, and reliability. As we need to use a large number of AWS services throughout the book, this chapter introduces them to help you to get familiar with the building blocks of our sample application.</p>
<p>The main topics covered in this chapter are as follows:</p>
<ul>
<li>Handling user accounts</li>
<li>Using the AWS, CLI, and the SDK services</li>
<li>Deploying your first Lambda function</li>
<li>Other AWS serverless products</li>
<li>The architecture of our sample application</li>
<li>Estimating costs</li>
</ul>
<p>After this chapter, you will be able to start playing with AWS.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Amazon Web Services</h1>
                
            
            
                
<p>AWS is the largest cloud vendor in terms of revenues. Often considered the best with regards to features, it offers great serverless products. This is why we have chosen AWS. If you prefer to use another cloud vendor, the following providers are other great options for serverless:</p>
<ul>
<li><strong>Google Cloud Engine</strong>: This is where you can use Google Cloud Functions for serverless code execution with Node.js, and Google Cloud Datastore as a serverless database. Also, Google has integrated the Firebase platform, which offers many tools and serverless services for mobile and web applications like storage, authentication, and messaging.</li>
<li><strong>Microsoft Azure</strong>: This offers Azure Functions for serverless code execution, supporting C#, Node.js, Python, and PHP.</li>
<li><strong>IBM Cloud</strong>: This offers IBM Bluemix OpenWhisk for serverless code execution, supporting C#, Node.js, Java, and Swift.</li>
</ul>
<p>All code examples in this book were designed for AWS using Node.js. They can be ported to other clouds, but this won't be an easy task. As previously stated in <a href="41e30804-d6ff-4759-9388-5e8734fed26f.xhtml">Chapter 1</a>, <em>Understanding the Serverless Model</em>, one of the disadvantages of serverless is the vendor lock-in. However, you can use this book to learn the concepts and maybe mix services from different vendors. For example, you could use Azure Functions with Amazon SimpleDB.</p>
<p>If you are just starting with AWS and don't have any previous experience, that's not a problem since we'll start right from the basics. You can start by creating a new account at <a href="https://aws.amazon.com">https://aws.amazon.com</a>. For 12 months, you benefit from a free tier (<a href="https://aws.amazon.com/free">https://aws.amazon.com/free</a>) that is designed to enable you to learn and get hands-on experience for free while building demo applications. There are also some services that offer a permanent free tier that goes beyond the 12 months period.</p>
<p>The next sections will cover a selection of services that will be used in this book. Note that AWS has an official categorization of products (<a href="https://aws.amazon.com/products">https://aws.amazon.com/products</a>) that is different from this book's categories. This is because, instead of grouping services in their main field of application, we are grouping them based on how they will be used in our use case. For example, the IoT service will be used for notifications and not to connect devices. Also, Cognito is commonly used in mobile applications, but we will use its security features for a website:</p>
<ul>
<li>Security services
<ul>
<li>AWS IAM</li>
<li>Amazon Cognito</li>
</ul>
</li>
<li>Management
<ul>
<li>AWS SDKs</li>
<li>AWS CLI</li>
<li>AWS CloudFormation</li>
<li>Amazon CloudWatch</li>
</ul>
</li>
<li>Frontend services
<ul>
<li>Amazon S3</li>
<li>Amazon Route 53</li>
<li>Amazon CloudFront</li>
<li>AWS Certificate Manager</li>
</ul>
</li>
<li>Messaging and notifications
<ul>
<li>Amazon SNS</li>
<li>AWS IoT</li>
</ul>
</li>
<li>Backend services
<ul>
<li>AWS Lambda</li>
<li>Amazon API Gateway</li>
</ul>
</li>
<li>Database services
<ul>
<li>Amazon SimpleDB</li>
<li>Amazon DynamoDB</li>
</ul>
</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Handling user accounts and security</h1>
                
            
            
                
<p>We will start covering security topics because you need to know how to properly configure user access and how to give permissions to the tools that we'll use to automate our infrastructure.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">AWS IAM</h1>
                
            
            
                
<p>When you create your AWS account, you receive a root user with full access. It can create/delete and start/stop any service. That's great for learning, but you shouldn't use it when developing a real project. In information security, the principle of least privilege requires that a user or program must be able to access only the information or resources that are necessary for its legitimate purpose. In case your access keys are compromised, the damage will be reduced if the access scope is restricted.</p>
<p>Traceability is another important aspect. You shouldn't share your user with others. It's really important that each person has their own user. AWS offers CloudTrail as a tool to track user activity and API usage.</p>
<p>So, you need to learn how to create user accounts and application keys with restricted access using <strong>Identity and Access Management</strong> (<strong>IAM</strong>). As we don't have applications keys yet, we will configure security using the IAM Management Console.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating users and groups</h1>
                
            
            
                
<p>Take a look at the following steps to learn how to create a user and associate a group to restrict the user access:</p>
<ol>
<li>Browse to the IAM website at <a href="https://console.aws.amazon.com/iam">https://console.aws.amazon.com/iam</a>:</li>
</ol>
<div><img class="image-border" height="363" src="img/513f7b47-e98b-4c31-9b9f-d2920f82284a.png" width="716"/></div>
<ol start="2">
<li>Click on Users in the left-hand side menu.</li>
</ol>
<p> </p>
<ol start="3">
<li>Choose Add user as shown in the following screenshot:</li>
</ol>
<div><img class="image-border" height="195" src="img/3b358138-67d3-4f21-8fe0-0ef34a02cf09.png" width="529"/></div>
<ol start="4">
<li>Type a username. Here, you can add multiple users at once by clicking on the Add another user option.</li>
<li>Check the Programmatic access box to enable API access using the CLI and the SDK.</li>
<li>Click on Next: Permissions, as shown in the following screenshot:</li>
</ol>
<div><img class="image-border" height="327" src="img/4499a64a-687f-4151-b74c-3e4223a7f082.png" width="513"/></div>
<ol start="7">
<li>Now we need to create a group for this user. If you don't have one already, click on Create group:</li>
</ol>
<div><img class="image-border" height="394" src="img/0e0c7185-8c96-44a7-a1a9-721de4acd827.png" style="color: black;font-size: 1em" width="611"/></div>
<ol start="8">
<li>Choose a group name and select a policy. In this example, we will use a <strong>Simple Storage Service</strong> (<strong>S3</strong>) policy with full access. Click on Create group to continue and then click on Next: Review:</li>
</ol>
<p class="CDPAlignCenter CDPAlign" style="color: black;font-size: 1em"><img class="image-border" height="403" src="img/77916f00-bcc4-485d-ab7c-0c883f7d722a.png" width="686"/></p>
<ol start="9">
<li>Review the selected data and click on Create user:</li>
</ol>
<div><img class="image-border" height="426" src="img/78a4cefe-346c-4441-a83d-5d639d6a8360.png" width="704"/></div>
<ol start="10">
<li>Write down the access key ID and secret access key displayed in the Access key ID and Secret access key boxes. They will be needed later to configure the CLI and the SDK:</li>
</ol>
<div><img class="image-border" height="314" src="img/83b69481-113b-436d-8661-34f247c81363.png" width="680"/></div>
<p>In this chapter, we will run examples for S3, SNS, Lambda, and API Gateway. You can take the opportunity and give proper access to each of these services. The <strong>AdministratorAccess</strong> policy type gives full access to all AWS resources and should be avoided if you are using this account to deploy applications to production.</p>
<p> </p>


            

            
        
    

        

                            
                    <h1 class="header-title">Sign in with a non-root user account</h1>
                
            
            
                
<p>The previous user was created with programmatic access only. You can edit the user or create another one to allow access to the Management Console by performing the following steps:</p>
<ol>
<li>On the Add user screen, you need to check the AWS Management Console access option:</li>
</ol>
<div><img class="image-border" height="429" src="img/c7ba1f20-65c0-43ba-b9ed-b0a8277e9368.png" width="724"/></div>
<ol start="2">
<li>You can keep the Autogenerated password and Require password reset options checked. After selecting a group and confirming, you will receive a password and a link to access the AWS account with this non-root user:</li>
</ol>
<div><img class="image-border" height="235" src="img/ed6ccf70-cd3e-47bb-bdff-702bd4967118.png" width="526"/></div>
<ol start="3">
<li>The access link has the format as <kbd>https://your_aws_account_id.signin.aws.amazon.com/console</kbd>. You just need to follow the link and type your new credentials.</li>
<li>If you don't want to disclose the AWS Account ID or if you prefer to use a friendly name, like your company name, you can create an account alias. On the IAM Console Management, select Dashboard and click on Customize:</li>
</ol>
<div><img class="image-border" height="172" src="img/189ae6d3-ca47-4a77-beba-086f140dec1c.png" width="512"/></div>
<ol start="5">
<li>Now, the user can sign in using a link that follows this format: <kbd>https://your_alias.signin.aws.amazon.com/console</kbd></li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">Amazon Cognito</h1>
                
            
            
                
<p>Handling authentication in a secure way is a complex problem, but this use case is so common that many frameworks and services were built dedicated to solve it. Nowadays, you just need to copy a few lines of code and you are good to go.</p>
<p>Cognito is Amazon's solution for this problem. More than solving how you authenticate accounts, it provides an easy way to sync data between different devices. When you log in using a Cognito account, you receive a temporary AWS token that is used to store and retrieve data specific to the user, like preferences, user profile, or saved game data.</p>
<p>We'll explore more about this service through code examples in <a href="5778526b-7b49-48bd-8fc8-f5285baa64c1.xhtml">Chapter 8</a>, <em>Securing the Serverless Application</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Managing AWS resources</h1>
                
            
            
                
<p>All services offered by Amazon are configured through RESTful interfaces named AWS API. You can access them using the following services:</p>
<ul>
<li>AWS Management Console</li>
<li>AWS SDKs</li>
<li>AWS CLI</li>
</ul>
<p>Take look at the following diagram, which depicts the services offered by Amazon:</p>
<div><img class="image-border" height="233" src="img/c6321638-e3db-4d94-967a-43a8765c2437.png" width="355"/></div>
<p>Rough schematic of the AWS architecture</p>


            

            
        
    

        

                            
                    <h1 class="header-title">AWS Management Console</h1>
                
            
            
                
<p>The console is the graphical user interface provided by Amazon and is accessed through the official website at <a href="https://console.aws.amazon.com">https://console.aws.amazon.com</a>. It's the easiest interface for beginners and useful to learn new services, but it's not complete. There are some features that can't be accessed or configured using the console, such as managing your SimpleDB data. Also, in some cases, it requires a lot of manual work. If you have a repetitive task, it's better to automate it using the SDK or the CLI.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">AWS SDKs</h1>
                
            
            
                
<p>The SDK is the best way to manage your AWS resources through reusable code. Using the SDK, you can automate your infrastructure and handle errors using very simple commands. There are SDKs for many different programming languages like Java, Python, Ruby, and others. In this book, we will use exclusively the SDK for Node.js. The official documentation is available at <a href="http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/index.html">http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/index.html</a>.</p>
<p>All code examples in this book use Node.js, which is a cross-platform JavaScript runtime with an event-driven model. Basic knowledge of Node.js is expected from the reader since we will not cover the basics. Also, we will use Node's default package manager, <kbd>npm</kbd>, to install dependencies.</p>
<p>Let's learn about using the SDK for Node.js by performing the following steps:</p>
<ol>
<li>Start a new Node project using <kbd>npm init</kbd> and run the npm command to install the AWS SDK:</li>
</ol>
<pre>
<strong>        npm install aws-sdk --save</strong>
</pre>
<ol start="2">
<li>After installing, you need to set the access keys that will be used by the SDK to connect to AWS. These keys were generated in the previous section, when we created a new user.</li>
<li>The following are a few options to set the credentials:
<ul>
<li>Setting the credentials with hardcoded keys</li>
<li>Loading a JSON file on disk</li>
<li>Setting a credentials file</li>
<li>Setting environment variables</li>
</ul>
</li>
</ol>
<p>You should always avoid hardcoding AWS keys, especially in open source projects on GitHub. You don't want to risk accidentally committing your private keys.</p>
<ol start="4">
<li>I prefer to configure them through environment variables. If you are running on macOS or Linux, add the following lines to the <kbd>~/.bash_profile</kbd> file. Replace <kbd>YOUR-KEY</kbd> and <kbd>YOUR-REGION</kbd> by the real values:</li>
</ol>
<pre>
<strong>        export AWS_ACCESS_KEY_ID=YOUR-KEY</strong><br/><strong>        export AWS_SECRET_ACCESS_KEY=YOUR-KEY</strong><br/><strong>        export AWS_REGION=YOUR-REGION</strong>
</pre>
<ol start="5">
<li>If you are running on Windows, execute the following commands on command prompt as the admin, replacing the values of the keys and region:</li>
</ol>
<pre>
<strong>        setx AWS_ACCESS_KEY_ID YOUR-KEY</strong><br/><strong>        setx AWS_SECRET_ACCESS_KEY YOUR-KEY</strong><br/><strong>        setx AWS_REGION YOUR-REGION</strong>
</pre>
<ol start="6">
<li>If you don't have a preferred region, you can use <kbd>us-east-1</kbd> (Northern Virginia, US East). When you use the AWS Management Console, you can set the region where you are going to manage the resources through the upper-right drop-down menu.</li>
</ol>
<p>Both the configurations are persistent, but they will work only for the next time that you open the command line.</p>
<ol start="7">
<li>You can test your setup creating a new file named <kbd>index.js</kbd> and running the following code to list your S3 buckets. As a simplified definition, you can consider a <strong>bucket</strong> as a repository of files. Now, if you have proper access, this example will return your bucket list or an empty array, if there is none. If you don't have access or had a problem setting the credentials, it will return an error:</li>
</ol>
<pre>
        const AWS = require('aws-sdk');<br/>        const s3 = new AWS.S3();<br/><br/>        s3.listBuckets((err, data) =&gt; {<br/>          if (err) console.log(err, err.stack); // an error occurred<br/>          else console.log(data.Buckets); // successful response<br/>        });
</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">AWS CLI</h1>
                
            
            
                
<p>The CLI is the command-line interface. For experienced users, it's a great tool to access information and manage resources. If you already have Python installed, you just need to run <kbd>pip</kbd>, which is the default package manager for Python, to install the CLI:</p>
<pre>
<strong>    pip install awscli</strong>
</pre>
<p>The configuration of the CLI is very similar to the one used by the SDK. The only difference is that you need to add another environment variable: <kbd>AWS_DEFAULT_REGION</kbd>. You need this because the SDK uses <kbd>AWS_REGION</kbd> instead of the <kbd>AWS_DEFAULT_REGION</kbd> variable.</p>
<p>To test if your setup is correct, you can execute the <kbd>ls</kbd> (list) command to list S3 buckets:</p>
<pre>
<strong>    aws s3 ls</strong>
</pre>
<p>Considering an AWS account with one bucket, the preceding command line derives the following output:</p>
<div><img class="image-border" src="img/12e70c2d-8c24-4ce0-9999-56cfae4ed6c0.png"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">AWS CloudFormation</h1>
                
            
            
                
<p>CloudFormation gives to developers the possibility to script the entire infrastructure using templates. This approach is called as <em>Infrastructure as a Code</em>. It's a powerful feature because it makes it easy to reproduce the configuration of servers and resources into another region or in a different account. Furthermore, you can version control your scripts to help you with the development of your infrastructure. As a quick start, AWS offers many sample templates (<a href="https://aws.amazon.com/cloudformation/aws-cloudformation-templates">https://aws.amazon.com/cloudformation/aws-cloudformation-templates</a>) for common use cases.</p>
<p>In this book, we will not use CloudFormation directly, but in the next chapter, we'll start using the Serverless Framework that extensively uses CloudFormation under the hood to manage resources. That's how you can easily duplicate your solution to different environments, making a production deployment an exact copy of the development or staging environment.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Amazon CloudWatch</h1>
                
            
            
                
<p>CloudWatch is a monitoring service for your AWS resources. It is often used to monitor virtual machines, but it is not restricted to it and plays an important role even when your operation is based only on serverless functions. With CloudWatch, you can monitor errors, throttles, number of invocations, duration, and costs. You can also expand monitoring further with custom plugins.</p>
<p>This subject will be covered in <a href="3c6f35a1-ca69-49db-ba87-f9b37af86ced.xhtml">Chapter 10</a>, <em>Testing, Deploying, and Monitoring</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Frontend services</h1>
                
            
            
                
<p>This section describes the main services related to frontend development. While an introduction is made here, you will find detailed examples in <a href="274d8aba-8e7e-4c5e-b55b-a8e1797d3057.xhtml">Chapter 4</a>, <em>Hosting the Website</em>, when we will host our application frontend using a serverless approach.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Amazon S3</h1>
                
            
            
                
<p><strong>Amazon Simple Storage Service</strong> (<strong>S3</strong>) is a service where you can save any type of file such as images, log files, and backups. Starting here with a bit of nomenclature, Amazon calls each file as an <strong>object</strong> and, to store files, you need a root folder that is called as a <strong>bucket</strong>. In your account, you can have multiple buckets to better organize your data. You can also have folders inside a bucket, but can't have buckets within buckets.</p>
<p>An interesting feature is that each file receives a unique URL in the following format:</p>
<p><kbd>https://s3.amazonaws.com/bucketname/filename</kbd></p>
<p>With this format, the bucket name must be unique through all accounts to guarantee unique URLs. It means that you can't create a bucket with a common name like “my-photos” because it will already be taken. Be creative and count on luck when choosing a name.</p>
<p>You can restrict the file access if it's a backup or another kind of private data, but what we will explore here is to let the files be publicly available to store our frontend data. This is a powerful feature. For example, you can use it to stream videos. You just need to add a <kbd>&lt;video&gt;</kbd> HTML5 tag that references the URL of an mp4 file. For a nice looking player, you could use something like <a href="http://videojs.com">http://videojs.com</a>, which is open source.</p>
<p>We will take advantage of S3 as it is a very cheap storage service and it has the flexibility to share files to build our low cost and serverless frontend. In our bucket, we'll add all static files of our frontend, including HTML, CSS, JavaScript, images, and so on. With proper configuration, which will be detailed in <a href="274d8aba-8e7e-4c5e-b55b-a8e1797d3057.xhtml">Chapter 4</a>, <em>Hosting the Website</em>, it will be ready to serve our content with high availability, scalability, and low costs.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Using S3 with the CLI</h1>
                
            
            
                
<p>The Management Console is very useful to upload and download files from S3, but so is the CLI. Let's play with the CLI in this section to gain more familiarity. We will create a bucket and store a file by performing the following steps. Those will be useful later for the AWS Lambda demo:</p>
<ol>
<li>First, choose a bucket name and use the make-bucket command:</li>
</ol>
<pre>
<strong>        aws s3 mb s3://my-bucket-name</strong>
</pre>
<ol start="2">
<li>Now, create a file named <kbd>test.txt</kbd> and write something to it.</li>
<li>Copy the file to your new bucket setting the <strong>Access Control List</strong> (<strong>ACL</strong>) as public content:</li>
</ol>
<pre>
<strong>        aws s3 cp test.txt s3://my-bucket-name/ --acl public-read</strong>
</pre>
<ol start="4">
<li>List the bucket contents using the following command line:</li>
</ol>
<pre>
<strong>        aws s3 ls s3://my-bucket-name</strong>
</pre>
<ol start="5">
<li>Download the file as <kbd>test2.txt</kbd> by using the following command line:</li>
</ol>
<pre>
<strong>        aws s3 cp s3://my-bucket-name/test.txt test2.txt</strong>
</pre>
<p>For more commands, refer to the official guide at <a href="http://docs.aws.amazon.com/cli/latest/userguide/using-s3-commands.html">http://docs.aws.amazon.com/cli/latest/userguide/using-s3-commands.html</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Amazon Route 53</h1>
                
            
            
                
<p>Route 53 provides a DNS service where you can buy and host your site's domain. You may prefer to buy your domain from another seller, like GoDaddy or Namecheap, but if you want to serve your serverless frontend using AWS services, you need to use Route 53 to host it.</p>
<p>When you configure a subdomain (like in <kbd>mysubdomain.mydomain.com</kbd>), you can set an A record (IP address) or CNAME (alias to another address), but the root domain (<kbd>mydomain.com</kbd>) requires an A record. If you host your frontend using S3, you receive an endpoint to set a CNAME record, but you don't get a fixed IP to set an A record. Since Route 53 is an AWS service, it accepts an S3 endpoint in the A record option and solves this issue.</p>
<p>Configuring your domain requires a simple setup, but it often confuses web developers who are not used to DNS management. This service will receive more attention later, specifically in <a href="274d8aba-8e7e-4c5e-b55b-a8e1797d3057.xhtml">Chapter 4</a>, <em>Hosting the Website</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Amazon CloudFront</h1>
                
            
            
                
<p>CloudFront is a <strong>Content Delivery Network</strong> (<strong>CDN</strong>). It is a special service with the objective of improving your website speed and availability. It achieves this by reducing the distance between users and files using Amazon's infrastructure around the world, which contains more than 60 edge locations, where each one of them can be used to host copies of your files.</p>
<p>A signal traveling at light speed from Sydney (Australia) to New York (USA) takes 53 milliseconds. A ping message needs a roundtrip, covering twice the distance and taking double the time. Also, there are other factors that increase this time: light travels 33% slower on fiber optics (glass), there is no straight line connecting both cities, and equipment like repeaters and switches will slow down transfer speeds. The result is a measured latency between 200 milliseconds and 300 milliseconds. By comparison, providing the content in the same city may reduce the latency to 15 milliseconds.</p>
<p>This difference is usually not significant for most applications. In a serverless website, the cold start delay has a bigger impact. If your use case is very sensitive to high latencies, you should avoid serverless or you can use CloudFront to minimize the impact, at least in the frontend.</p>
<p>To reduce costs, CloudFront won't replicate your content automatically throughout the world. It will replicate only where a demand for it exists. For example, when a request is made from a British city, the DNS will route the request to the nearest edge location and if it does not have yet a local copy of the file, it will be copied temporarily (cached). When another user in a nearby city requests the same file, it will benefit from a lower latency and fast response.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">AWS Certificate Manager</h1>
                
            
            
                
<p>Certificate Manager is a service where you can request free SSL/TLS certificates to make your website support HTTPS. A certificate used to be an expensive purchase for small sites, ranging from US$ 100 to US$ 500 per year. To help make certificates (and HTTPS) accessible to everyone, Let's Encrypt (<a href="https://letsencrypt.org">https://letsencrypt.org</a>) was created as a nonprofit certificate authority company, which operates based on donations and sponsorship. You can get free certificates and they will be accepted by all major browsers.</p>
<p>Following Let's Encrypt, Amazon launched its own service named AWS Certificate Manager. It's restricted to AWS customers, but it's also free and easier to use. Once you issue a new certificate and associate it with a CloudFront distribution, Amazon will also be responsible by automatically renewing the certificate when necessary. We will cover this service in <a href="274d8aba-8e7e-4c5e-b55b-a8e1797d3057.xhtml">Chapter 4</a>, <em>Hosting the Website</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Messaging and notifications</h1>
                
            
            
                
<p>This section covers which services you can use on AWS to send notifications to your users.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Amazon SNS</h1>
                
            
            
                
<p>Amazon <strong>Simple Notification Service</strong> (<strong>SNS</strong>) implements the publish-subscribe messaging pattern. When you create an SNS topic, it becomes available for other services to subscribe to it. If someone publishes a message in this topic, all subscribed services will be alerted.</p>
<p>It's a very simple and powerful service. You can use it to dynamically attach different services that are able to handle a specific kind of notification. For example, an application can send a notification to an SNS topic to alert that you have received a new file to process. You can subscribe to this topic using an HTTP endpoint and SNS will send a message to your web service with the file location that needs processing. Later, you can add another endpoint, using a Lambda function programmed to do another kind of processing.</p>
<p>Let's perform the following steps to create a simple demo using the CLI as an example:</p>
<ol>
<li>Create an SNS topic using the following command line:</li>
</ol>
<pre>
<strong>        aws sns create-topic --name email-alerts</strong>
</pre>
<ol start="2">
<li>The result is an <strong>Amazon Resource Name</strong> (<strong>ARN</strong>) that you need to save. The ARN will be created with a format of this example: <kbd>arn:aws:sns:us-east-1:1234567890:email-alerts</kbd></li>
<li>Subscribe to a topic using the e-mail protocol, so you will receive an e-mail every time that an application publishes to this topic:</li>
</ol>
<pre>
<strong>        aws sns subscribe --topic-arn the_previous_arn --protocol email \<br/>          --notification-endpoint myemail@example.com</strong>
</pre>
<ol start="4">
<li>Open your e-mail account and confirm that you want to subscribe to events.</li>
<li>Publish a test message and see it working by using the following command line:</li>
</ol>
<pre>
<strong>        aws sns publish --topic-arn the_previous_arn --message "test"</strong>
</pre>
<p>For more commands, refer to the official guide at <a href="http://docs.aws.amazon.com/cli/latest/userguide/cli-sqs-queue-sns-topic.html">http://docs.aws.amazon.com/cli/latest/userguide/cli-sqs-queue-sns-topic.html</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">AWS IoT</h1>
                
            
            
                
<p>AWS IoT (Internet of Things) will be used in our solution to handle serverless notifications. Although the name indicates the usage of IoT devices, we will use this service exclusively for users connected through browsers. This is becasuse hooking a web page into a notification service to receive updates, through a subscription mechanism and not data polling, requires the usage of WebSockets, which are supported by IoT and not supported by Amazon SNS. So, although the IoT name may sound as a strange choice, we will use it because it is the only AWS service capable of handling our use case.</p>
<p>AWS IoT implements the publish-subscribe pattern using the <strong>Message Queuing Telemetry Transport</strong> (<strong>MQTT</strong>) protocol. We will see code examples in <a href="ab2add3a-931b-478c-9fbf-039ba2a637a1.xhtml">Chapter 9</a>, <em>Handling Serverless Notifications</em>, while implementing live comments for product review pages of our sample website.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Backend services</h1>
                
            
            
                
<p>In this section, we will go through the services that are needed to build the backend with some practical examples.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">AWS Lambda</h1>
                
            
            
                
<p>Lambda is the flagship product of the serverless concept. The ability to run functions on demand with zero administration and its particular pricing model is the main drive that aroused interest in the developer community. We can say that we have serverless databases, serverless notifications, and serverless frontends, but those are merely extensions of the main feature, that is, serverless code executions.</p>
<p>Lambda currently only supports Node.js (JavaScript), Python, Java, and C# languages, but there is a third-party framework named Apex (<a href="https://github.com/apex/apex">https://github.com/apex/apex</a>) that adds support for Go, Rust, and Clojure by injecting Node.js shims in the deployment build.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a Lambda function</h1>
                
            
            
                
<p>In this book, we will use the Serverless Framework extensively to make the deployment of Lambda functions easier; however, to see how useful the framework is, in this chapter, we will use the AWS Management Console for comparison.</p>
<p>We will now create a Lambda function to process log files. This function will be triggered when a new log file is added to an S3 bucket and the result of the Lambda function is to create an SNS notification if there is an error in the file.</p>
<p>Let's take a look at the following steps, which are necessary to execute:</p>
<ol>
<li>Browse the following link: <a href="https://console.aws.amazon.com/lambda">https://console.aws.amazon.com/lambda</a>. Select Get Started Now to start creating a new function:</li>
</ol>
<div><img class="image-border" height="415" src="img/f854341a-2312-4616-98de-8c9d5b851c83.png" width="710"/></div>
<ol start="2">
<li>AWS offers many templates with sample configuration and code. For example, you could use a template of a Lambda function that processes bounced e-mails. This option is interesting for marketing campaigns to remove e-mail addresses that don't exist. However, in this example, we will select a Blank Function template:</li>
</ol>
<div><img class="image-border" height="387" src="img/9668324f-0ea3-4845-bf0b-0df8897434c2.png" width="705"/></div>
<ol start="3">
<li>A Lambda function can be triggered by many different sources. In the next screen, you will see a list of all available options. Select S3:</li>
</ol>
<div><img class="image-border" height="337" src="img/0da9fbe4-2bc4-4a4a-a0e5-04766d7a7370.png" width="411"/></div>
<ul>
<li>On a side note, take a look at some use cases of the available triggers:
<ul>
<li>Amazon S3: You can select a bucket name with Event type as Object Created (All) and Prefix <kbd>images/</kbd>. In this setting, when you upload an image to this bucket within the images folder, you will trigger a Lambda function for post-processing and image optimization.</li>
<li>SNS: You can use this service to handle notifications. For example, you could create an SNS topic named <kbd>Process Order</kbd> that would be activated by your application when a new order is received. SNS could be configured to send an e-mail for a specific list of employees and trigger a Lambda function to execute some logic.</li>
<li>CloudWatch Logs: This service helps you to monitor your AWS resources and take automated actions. You could trigger Lambda functions to handle alert messages and execute specific actions according to its content.</li>
</ul>
</li>
</ul>
<ol start="4">
<li>After selecting S3, you will be presented with some configuration options. Select the bucket that we have created previously with the CLI. For the Event type, select Object Created (All) to trigger the function whenever a new file is created. For Prefix, type <kbd>logs/</kbd> to consider only files in the logs folder and in the Suffix, type <kbd>txt</kbd> to consider only text files. Finally, check the Enable trigger option and click on Next:
<div><img class="image-border" src="img/92ee7bca-6327-4131-a6b0-56c68a635a6b.png"/></div>
</li>
<li>Type a name for your Lambda function, for example, <kbd>processLog</kbd>, and select the Node.js 6.10 option for Runtime:<br/>
<div><img class="image-border" src="img/1eb4d49e-a633-4373-bdb7-01297d721911.png"/></div>
</li>
<li>Now we need to implement the code that will be executed by the Lambda function using the Edit code inline option. In this example, we are using <kbd>S3.getObject</kbd> to retrieve the file created and <kbd>SNS.publish</kbd> to create a notification if there is the <kbd>error</kbd> word in this file. For the SNS topic ARN, you can use the same that was previously created with the CLI:</li>
</ol>
<pre>
        const AWS = require('aws-sdk');<br/>        const s3 = new AWS.S3();<br/>        const sns = new AWS.SNS();<br/><br/>        exports.handler = (event, context, callback) =&gt; {   <br/>          const bucketName = event.Records[0].s3.bucket.name;<br/>          const objectKey = event.Records[0].s3.object.key;<br/>          const s3Params = { <br/>            Bucket: bucketName, <br/>            Key: objectKey <br/>          };<br/><br/><strong>          s3.getObject(s3Params, (err, data) =&gt; {</strong><br/>            if (err) throw err;   <br/><br/>            // check if file have errors to report<br/>            const fileContent = data.Body.toString();   <br/>            if (fileContent.indexOf('error') !== -1) {         <br/>              const msg = `file ${objectKey} has errors`;<br/>              const snsParams = { <br/>                Message: msg, <br/>                TopicArn: 'my-topic-arn' <br/>              };<br/><strong>              sns.publish(snsParams, callback);</strong><br/>            }<br/>          });<br/>        }; 
</pre>
<p>The <kbd>aws-sdk</kbd> module is available for all Lambda functions. If you want to add another dependency that is not the <kbd>aws-sdk</kbd> module or a core module of Node, you need to upload a ZIP file to AWS containing your function and the module.</p>
<ol start="7">
<li>As we have used the inline option to write the code instead of uploading a ZIP file, the code will be placed inside an <kbd>index.js</kbd> file. Also, the module that we have created exports a function named <kbd>handler</kbd>. In this case, we need to configure the Lambda handler with the <kbd>index.handler</kbd> name. For the Role box, we need to create a new one because a Lambda function can't execute without proper access. Even if you create a Lambda using an administrator account, you must give explicit permissions for which kind of services and resources the Lambda will be able to access:</li>
</ol>
<div><img class="image-border" height="184" src="img/1d76ac0c-dfcf-4a1d-9d5a-4e59b1e4e9f7.png" width="680"/></div>
<ol start="8">
<li>Type a role name for this role and click on Edit to modify the default policy document. Add the following JSON object and finish by clicking on Allow:</li>
</ol>
<p>You will need to replace the S3 and SNS ARNs to your respective ARNs.</p>
<div><img class="image-border" height="385" src="img/ced41b18-bc63-4a07-bb51-36dbb670e89f.png" width="443"/></div>
<p style="padding-left: 90px">Use the following JSON object:</p>
<pre>
        {<br/>          "Version": "2012-10-17",<br/>          "Statement": [<br/>            {<br/>              "Effect": "Allow",<br/>              "Action": ["s3:GetObject"],<br/>              "Resource": "arn:aws:s3:::my-bucket-name/*"<br/>            },<br/>            {<br/>              "Effect": "Allow",<br/>              "Action": ["sns:Publish"],<br/>              "Resource": "arn:aws:sns:us-east-1:1234567890:email-alerts"<br/>            }<br/>          ]<br/>        }
</pre>
<p> </p>
<ol start="9">
<li>The last step is to configure the Advanced settings. Set the amount of RAM memory that should be allocated for this function and the timeout value that AWS must wait for this function to finish its execution. You may need to increase the timeout value depending on the size of the log files that you are going to use for testing:</li>
</ol>
<div><img class="image-border" height="125" src="img/b91066aa-301f-4c99-96e5-dacb0c361b6f.png" width="516"/></div>
<ol start="10">
<li>Click on Next and you will be redirected to a Review page where you need to confirm the function creation.</li>
<li>To test this function, we can use the Management Console, which lets us create custom input events, but, in this case, we can use the CLI to upload a new file and trigger the Lambda function. If the file has the word “error”, you should receive an e-mail message with the file name.</li>
</ol>
<p style="padding-left: 90px">Take a look at the following CLI command to trigger this Lambda function:</p>
<pre>
<strong>        aws s3 cp log1.txt s3://my-bucket-name/logs/</strong>
</pre>
<ol start="12">
<li>If you have any issues, you can try using the Management Console to see the error message that appears. In this case, use the following JSON object as the event trigger, replacing the bucket name:</li>
</ol>
<pre>
        {<br/>          "Records": [<br/>            {<br/>              "s3": {<br/>                "bucket": {<br/>                  "name": "my-bucket-name"<br/>                },<br/>                "object": {<br/>                  "key": "logs/log1.txt"<br/>                }<br/>              }<br/>            }<br/>          ]<br/>        }
</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Amazon API Gateway</h1>
                
            
            
                
<p>API Gateway is a service that helps you to build RESTful APIs. You need to configure your resources, set the supported HTTP verbs and specify what will handle the requests. You can use it to redirect requests to EC2 instances (virtual machines) or external web servers, but what we'll explore here is to use it to trigger Lambda functions.</p>
<p>Besides, API Gateway has other interesting features. For example, after creating your API endpoints, you can use API Gateway to automatically generate a client SDK for many different platforms, where you can easily test and distribute it to be used by third-party developers. Also, you can create third-party API keys to access your content with fine-grained access permissions, request quota limits, and throttling.</p>
<p>In our architecture, API Gateway will act as a thin layer that exists only to expose our Lambda functions to the world. Additionally, you can set security controls to allow only authenticated users to trigger your code. We are going to use this service in the next chapter, where we'll talk about how to configure our endpoints using the Serverless Framework, we will see more in <a href="a225cec3-99da-4be5-8833-f8fdaf0aa819.xhtml">Chapter 6</a>, <em>Developing the Backend</em>, while building our backend code, and lastly, in <a href="5778526b-7b49-48bd-8fc8-f5285baa64c1.xhtml">Chapter 8</a>, <em>Securing the Serverless Application</em>, when our security measures will be explained.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Expose your Lambda function using API Gateway</h1>
                
            
            
                
<p>Let's use the API Gateway to expose our previous Lambda function to be accessible using a URL by performing the following steps:</p>
<ol>
<li>First, go to the API Gateway Management Console by visiting this link <a href="https://console.aws.amazon.com/apigateway">https://console.aws.amazon.com/apigateway</a> and click on Create API.</li>
</ol>
<p> </p>
<ol start="2">
<li>Under the Create new API header, select the New API option and type the API name. For example: <kbd>log-processor</kbd>:</li>
</ol>
<div><img class="image-border" height="357" src="img/4ede3bb0-2593-42d4-9638-e634c7f0409e.png" width="739"/></div>
<ol start="3">
<li>Under Resources, click on the Actions dropdown and choose Create Method:</li>
</ol>
<div><img class="image-border" height="327" src="img/5bcffaf3-00cd-470b-933f-74f4800f3d71.png" width="714"/></div>
<ol start="4">
<li>In the new dropdown, select the POST HTTP verb.</li>
<li>Under - POST - Setup, select Lambda Function as our Integration type. Select the region in which you have deployed our previous Lambda function and its corresponding name and click on Save button:</li>
</ol>
<div><img class="image-border" height="211" src="img/a5d7e640-9e70-420a-b486-e9ddd28995bf.png" width="413"/></div>
<ol start="6">
<li>A popup will request that you allow this method to access the Lambda function. Accept it.</li>
<li>Under Resources, click again in the Actions drop-down and choose Deploy API.</li>
<li>A popup will request a stage to be selected. You can select [New Stage] and name it as <kbd>dev</kbd>:</li>
</ol>
<div><img class="image-border" height="252" src="img/9367e29e-8f6f-4bcb-b38d-a86cfcfcd029.png" width="374"/></div>
<ol start="9">
<li>Click on Deploy. The next screen will show where the API Gateway was deployed. The URL will follow this format, such as <kbd>https://[identifier].execute-api.[region].amazonaws.com/dev</kbd>.</li>
</ol>
<ol start="10">
<li>If you try this URL in your browser, the result will be an authentication error that happens because the browser will try a <kbd>GET</kbd> request that was not defined. As we have defined only a <kbd>POST</kbd> resource, we need another way to test. You can use the API Gateway test feature that is accessible under the Resources feature in the left menu, followed by selecting the <kbd>POST</kbd> verb and clicking on Test.</li>
<li>You need to provide a <strong>Request Body</strong>. In our case, it will be a JSON object with a format similar to a new S3 object event:</li>
</ol>
<pre>
        {<br/>          "Records": [<br/>            {<br/>              "s3": {<br/>                "bucket": {<br/>                  "name": "my-bucket-name"<br/>                },<br/>                "object": {<br/>                  "key": "logs/log1.txt"<br/>                }<br/>              }<br/>            }<br/>          ]<br/>        }
</pre>
<ol start="12">
<li>You just need to change the bucket name for the name that you used previously, and the API Gateway will trigger the Lambda function to process the <kbd>log1.txt</kbd> file that we have uploaded before.</li>
</ol>
<p>Another way to test this integration with the API Gateway is using <strong>Postman</strong>, which is a very popular tool to test any kind of RESTful APIs. Postman can be installed as a Chrome extension or as a macOS application.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Database services</h1>
                
            
            
                
<p>In this section, we will see a brief explanation about the SimpleDB and DynamoDB products. Both of them will be covered in details in <a href="cb2f92df-5bc3-4c8e-8872-fbee58e5b0be.xhtml">Chapter 7</a>, <em>Managing a Serverless Database</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Amazon SimpleDB</h1>
                
            
            
                
<p>SimpleDB is a NoSQL database that can be defined as a serverless database because it scales automatically, it is highly available without needing to pay for provisions, and you are only billed by the seconds that the database engine needs to execute your queries.</p>
<p>You can use SimpleDB to make queries using a SQL-like syntax, but SimpleDB is very limited in terms of functionalities. It's so limited that it only stores string fields! If you store a datetime data type, you need to save it as a string ISO representation to avoid localization issues and to be able to make the <kbd>where</kbd> clauses. If you want to store numbers, use zero-padding. And how can we make <kbd>where</kbd> clauses with negative numbers? It is done by adding a large offset to all numbers to avoid storing negatives! As you can see, building a system on top of SimpleDB can be hard. There are many considerations and you can have performance problems when running with large datasets. Hence, SimpleDB is usually useful only for small projects.</p>
<p>You can see more tips on how to handle data types by following this link: <a href="https://aws.amazon.com/articles/Amazon-SimpleDB/1232">https://aws.amazon.com/articles/Amazon-SimpleDB/1232</a></p>
<p>SimpleDB is the only serverless database offered by AWS. If you want a better serverless solution, you would need to try other cloud providers. You currently have the following options: Google Firebase storage, Google Cloud Datastore, or FaunaDB.</p>
<p>SimpleDB is one of the oldest AWS services, announced in late 2007. However, it continues to be one of very few services that don't have a Management Console. If you want a GUI to easily query and manage your SimpleDB data, you can install a third-party solution. In this case, I suggest the <strong>SdbNavigator</strong> <strong>Chrome Extension</strong> as a good option. You only need to add an access key and a secret key to connect to your database. As a security measure, create a new user account using IAM with restricted privileges to SimpleDB.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Amazon DynamoDB</h1>
                
            
            
                
<p>DynamoDB is a fully managed NoSQL database designed to be highly scalable having a fast and consistent performance. Unlike SimpleDB, DynamoDB has all the common features that you expect in a NoSQL database and can be extensively used in large projects. However, DynamoDB has a flaw for our use case: it is <em>not</em> a serverless database. It requires provisioning of resources, so you <em>can't</em> say that DynamoDB is truly serverless. If you pay for provisioned capacity, you need to worry about the <em>servers</em> because you may end up provisioning more or less than necessary and paying for availability even when no one is using your database.</p>
<p>Fortunately, AWS has a permanent free tier that is very generous. You can serve more than 100 million read/write requests per month for free and this offer is not restricted to new AWS users. Considering this advantage, the low price to grow your user base, the possibility to automate the throughput provisioning, DynamoDB is a good choice for most serverless applications and this is proven by the numerous examples of projects and demos created by the serverless community using DynamoDB. It is very hard to see SimpleDB being used even for small projects, since DynamoDB is free for low usage.</p>
<p>So, even if you have a large project and end up having to pay for provisioned resources that you would not use, DynamoDB requires much less management and can be a cheaper option than running a traditional database solution. For all these reasons, we are going to cover SimpleDB usage in this book, but our sample application will run on DynamoDB.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The serverless architecture of our online store</h1>
                
            
            
                
<p>In this book, we will build a real-world use case of a serverless solution. This sample application is an online store with the following requirements:</p>
<ul>
<li>List of available products</li>
<li>Product details with user rating</li>
<li>Add products to a shopping cart</li>
<li>Create account and login pages</li>
</ul>
<p>We will describe and implement each feature in the next chapters. For a better understanding of the architecture, the following diagram gives a general view of how the different services that we covered in this chapter are organized and how they interact:</p>
<div><img class="image-border" src="img/df96537f-9214-434f-a13a-afb45b22d41e.png"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Estimating costs</h1>
                
            
            
                
<p>In this section, we will estimate the costs of our sample application demo based on some usage assumptions and Amazon's pricing model. All pricing values used here are from mid 2017 and considers the cheapest region, US East (Northern Virginia).</p>
<p>This section covers an example to illustrate how costs are calculated. Since the billing model and prices can change over time, always refer to the official sources to get updated prices before making your own estimations. You can use Amazon's calculator, which is accessible at this link: <a href="http://calculator.s3.amazonaws.com/index.html">http://calculator.s3.amazonaws.com/index.html</a>. If you still have any doubts after reading the instructions, you can always contact Amazon's support for free to get commercial guidance.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Assumptions</h1>
                
            
            
                
<p>For our pricing example, we can assume that our online store will receive the following traffic <em>per month</em>:</p>
<ul>
<li>100,000 page views</li>
<li>1,000 registered user accounts</li>
<li>200 GB of data transferred considering an average page size of 2 MB</li>
<li>5,000,000 code executions (Lambda functions) with an average of 200 milliseconds per request</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Route 53 pricing</h1>
                
            
            
                
<p>We need a hosted zone for our domain name and it costs US$ 0.50 per month. Also, we need to pay US$ 0.40 per million DNS queries to our domain. As this is a prorated cost, 100,000 page views will cost only US$ 0.04.</p>
<p>Total: US$ 0.54</p>


            

            
        
    

        

                            
                    <h1 class="header-title">S3 pricing</h1>
                
            
            
                
<p>Amazon S3 charges you US$ 0.023 per GB/month stored, US$ 0.004 per 10,000 requests to your files, and US$ 0.09 per GB transferred. However, as we are considering the CloudFront usage, transfer costs will be charged by CloudFront prices and will not be considered in S3 billing.</p>
<p>If our website occupies less than 1 GB of static files and has an average per page of 2 MB and 20 files, we can serve 100,000 page views for less than US$ 20. Considering CloudFront, S3 costs will go down to US$ 0.82 while you need to pay for CloudFront usage in another section. Real costs would be even lower because CloudFront caches files and it would not need to make 2,000,000 file requests to S3, but let's skip this detail to reduce the complexity of this estimation.</p>
<p>On a side note, the cost would be much higher if you had to provision machines to handle this number of page views to a static website with the same availability and scalability.</p>
<p>Total: US$ 0.82</p>


            

            
        
    

        

                            
                    <h1 class="header-title">CloudFront pricing</h1>
                
            
            
                
<p>CloudFront is slightly more complicated to price since you need to guess how much traffic comes from each region, as they are priced differently. The following table shows an example of estimation:</p>
<table>
<tbody>
<tr>
<td><strong>Region</strong></td>
<td><strong>Estimated traffic</strong></td>
<td><strong>Cost per GB transferred</strong></td>
<td><strong>Cost per 10,000 HTTPS requests</strong></td>
</tr>
<tr>
<td>North America</td>
<td>70%</td>
<td>US$ 0.085</td>
<td>US$ 0.010</td>
</tr>
<tr>
<td>Europe</td>
<td>15%</td>
<td>US$ 0.085</td>
<td>US$ 0.012</td>
</tr>
<tr>
<td>Asia</td>
<td>10%</td>
<td>US$ 0.140</td>
<td>US$ 0.012</td>
</tr>
<tr>
<td>South America</td>
<td>5%</td>
<td>US$ 0.250</td>
<td>US$ 0.022</td>
</tr>
</tbody>
</table>
<p>As we have estimated 200 GB of files transferred with 2,000,000 requests, the total will be US$ 21.97.</p>
<p>Total: US$ 21.97</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Certificate Manager pricing</h1>
                
            
            
                
<p>Certificate Manager provides SSL/TLS certificates for free. You only need to pay for the AWS resources you create to run your application.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">IAM pricing</h1>
                
            
            
                
<p>There is no charge specifically for IAM usage. You will be charged only by what AWS resources your users are consuming.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Cognito pricing</h1>
                
            
            
                
<p>Each user has an associated profile that costs US$ 0.0055 per month. However, there is a permanent free tier that allows 50,000 monthly active users without charges, which is more than enough for our use case.</p>
<p>Besides that, we are charged for Cognito Syncs of our user profiles. It costs US$ 0.15 for each 10,000 sync operations and US$ 0.15 per GB/month stored. If we estimate 1,000 active and registered users with less than 1 MB per profile, with less than 10 visits per month in average, we can estimate a charge of US$ 0.30.</p>
<p>Total: US$ 0.30</p>


            

            
        
    

        

                            
                    <h1 class="header-title">IoT pricing</h1>
                
            
            
                
<p>IoT charges starts at US$ 5 per million messages exchanged. As each page view will make at least 2 requests, one to connect and another to subscribe to a topic, we can estimate a minimum of 200,000 messages per month. We need to add 1,000 messages if we suppose that 1% of the users will rate the products and we can ignore other requests like disconnect and unsubscribed because they are excluded from billing. In this setting, the total cost would be of US$ 1.01.</p>
<p>Total: US$ 1.01</p>


            

            
        
    

        

                            
                    <h1 class="header-title">SNS pricing</h1>
                
            
            
                
<p>We will use SNS only for internal notifications, when CloudWatch triggers a warning about issues in our infrastructure. SNS charges US$ 2.00 per 100,000 e-mail messages, but it offers a permanent free tier of 1,000 e-mails. So, it will be free for us.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">CloudWatch pricing</h1>
                
            
            
                
<p>CloudWatch charges US$ 0.30 per metric/month and US$ 0.10 per alarm and offers a permanent free tier of 50 metrics and 10 alarms per month. If we create 20 metrics and expect 20 alarms in a month, we can estimate a cost of US$ 1.00.</p>
<p>Total: US$ 1.00</p>
<p> </p>


            

            
        
    

        

                            
                    <h1 class="header-title">API Gateway pricing</h1>
                
            
            
                
<p>API Gateway starts charging US$ 3.50 per million of API calls received and US$ 0.09 per GB transferred out to the Internet. If we assume 5 million requests per month with each response with an average of 1 KB, the total cost of this service will be US$ 17.93.</p>
<p>Total: US$ 17.93</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Lambda pricing</h1>
                
            
            
                
<p>When you create a Lambda function, you need to configure the amount of RAM memory that will be available for use. It ranges from 128 MB to 1.5 GB. Allocating more memory means additional costs. It breaks the philosophy of avoiding provision, but at least it's the only thing you need to worry about. The good practice here is to estimate how much memory each function needs and make some tests before deploying to production. A bad provision may result in errors or higher costs.</p>
<p>Lambda has the following billing model:</p>
<ul>
<li>US$ 0.20 per 1 million requests</li>
<li>US$ 0.00001667 GB-second</li>
</ul>
<p>Running time is counted in fractions of seconds, rounding up to the nearest multiple of 100 milliseconds.</p>
<p>Furthermore, there is a permanent free tier that gives you 1 million requests and 400,000 GB-seconds per month without charges.</p>
<p>In our use case scenario, we have assumed 5 million requests per month with an average of 200 milliseconds per execution. We can also assume that the allocated RAM memory is 512 MB per function:</p>
<ul>
<li><strong>Request charges</strong>: Since 1 million requests are free, you pay for 4 million that will cost US$ 0.80.</li>
<li><strong>Compute charges</strong>: Here, 5 million executions of 200 milliseconds each gives us 1 million seconds. As we are running with a 512 MB capacity, it results in 500,000 GB-seconds, where 400,000 GB-seconds of these are free, resulting in a charge of 100,000 GB-seconds that costs US$ 1.67.</li>
<li><strong>Total</strong>: US$ 2.47</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">SimpleDB pricing</h1>
                
            
            
                
<p>Take a look at the following SimpleDB billing where the free tier is valid for new and existing users:</p>
<ul>
<li>US$ 0.14 per machine-hour (25 hours free)</li>
<li>US$ 0.09 per GB transferred out to the internet (1 GB is free)</li>
<li>US$ 0.25 per GB stored (1 GB is free)</li>
</ul>
<p>Take a look at the following charges:</p>
<ul>
<li><strong>Compute charges</strong>: Considering 5 million requests with an average of 200 milliseconds of execution time, where 50% of this time is waiting for the database engine to execute, we estimate 139 machine hours per month. Discounting 25 free hours, we have an execution cost of US$ 15.96.</li>
<li><strong>Transfer costs</strong>: Since we'll transfer data between SimpleDB and AWS Lambda, there is no transfer cost.</li>
<li><strong>Storage charges</strong>: If we assume a 5 GB database, it results in US$ 1.00, since 1 GB is free.</li>
<li><strong>Total</strong>: US$ 16.96, but this will not be added in the final estimation since we will run our application using DynamoDB.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">DynamoDB</h1>
                
            
            
                
<p>DynamoDB requires you to provision the throughput capacity that you expect your tables to offer. Instead of provisioning hardware, memory, CPU, and other factors, you need to say how many read and write operations you expect and AWS will handle the necessary machine resources to meet your throughput needs with consistent and low-latency performance.</p>
<p>One read capacity unit represents one strongly consistent read per second or two eventually consistent reads per second, where objects have a size up to 4 KB. Regarding the writing capacity, one unit means that you can write one object of size 1 KB per second. Considering these definitions, AWS offers in the permanent free tier 25 read units and 25 write units of throughput capacity, in addition to 25 GB of free storage. It charges as follows:</p>
<ul>
<li>US$ 0.47 per month for every <strong>Write Capacity Unit</strong> (<strong>WCU</strong>)</li>
<li>US$ 0.09 per month for every <strong>Read Capacity Unit</strong> (<strong>RCU</strong>)</li>
<li>US$ 0.25 per GB/month stored</li>
<li>US$ 0.09 GB per GB transferred out to the Internet</li>
</ul>
<p>Since our estimated database will have only 5 GB, we are on the free tier and we will not pay for transferred data because there is no transfer cost to AWS Lambda.</p>
<p>Regarding read/write capacities, we have estimated 5 million requests per month. If we evenly distribute them, we will get two requests per second. In this case, we will consider that it's one read and one write operation per second.</p>
<p>We need to estimate now how many objects are affected by a read and a write operation. For a write operation, we can estimate that we will manipulate 10 items on average and a read operation will scan 100 objects. In this scenario, we would need to reserve 10 WCU and 100 RCU. As we have 25 WCU and 25 RCU for free, we only need to pay for 75 RCU per month, which costs US$ 6.75.</p>
<p>Total: US$ 6.75</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Total pricing</h1>
                
            
            
                
<p>Let's summarize the cost of each service in the following table:</p>
<div><table>
<tbody>
<tr>
<td><strong>Service</strong></td>
<td><strong>Monthly Costs</strong></td>
</tr>
<tr>
<td>Route 53</td>
<td>US$ 0.54</td>
</tr>
<tr>
<td>S3</td>
<td>US$ 0.82</td>
</tr>
<tr>
<td>CloudFront</td>
<td>US$ 21.97</td>
</tr>
<tr>
<td>Cognito</td>
<td>US$ 0.30</td>
</tr>
<tr>
<td>IoT</td>
<td>US$ 1.01</td>
</tr>
<tr>
<td>CloudWatch</td>
<td>US$ 1.00</td>
</tr>
<tr>
<td>API Gateway</td>
<td>US$ 17.93</td>
</tr>
<tr>
<td>Lambda</td>
<td>US$ 2.47</td>
</tr>
<tr>
<td>DynamoDB</td>
<td>US$ 6.75</td>
</tr>
<tr>
<td><strong>Total</strong></td>
<td><strong>US$ 52.79</strong></td>
</tr>
</tbody>
</table>
</div>
<p> </p>
<p>It results in a total cost of ~ US$ 50 per month in infrastructure to serve 100,000 page views. If you have a conversion rate of 1%, you can get 1,000 sales per month, which means that you pay US$ 0.05 in infrastructure for each product that you sell.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, you were introduced to the services that will be used throughout this book. You already know how to create new AWS users with restricted privileges, how to use the AWS CLI and the Node SDK, and what the frontend, backend, and notification services are. This chapter finished showing how each service fits in our sample application architecture and you learned how to estimate its costs.</p>
<p>In the next chapter, you'll be introduced to the Serverless Framework that plays an important role in our development workflow, automating tasks and organizing the code. You'll learn how to configure, deploy Lambda functions, and structure the beginning of our sample application.</p>


            

            
        
    </body></html>