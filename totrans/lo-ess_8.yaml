- en: Chapter 8. Internal Design and Performance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 内部设计和性能
- en: The final chapter of this book looks at the internal design of key Lo-Dash components.
    All previous chapters focused on the external-facing aspects of the library. Now
    that we're well-versed in what's possible with Lo-Dash, it's time to see what's
    under the hood. This isn't an in-depth walkthrough of the Lo-Dash source code.
    The curious reader should by all means look at the code though. We will touch
    the most important pieces of the implementation of Lo-Dash. These are what make
    Lo-Dash perform not only fast but also predictably.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本书最后一章将探讨关键Lo-Dash组件的内部设计。所有前面的章节都专注于库的外部特性。现在我们已经熟悉了Lo-Dash的用途，是时候看看其内部结构了。这并不是对Lo-Dash源代码的深入剖析。不过，好奇的读者当然可以查看代码。我们将触及Lo-Dash实现中最重要的一些部分。这些部分使得Lo-Dash不仅运行速度快，而且可预测。
- en: With these designs in mind, we'll spend the remaining sections of this chapter
    looking at some Lo-Dash code that could be improved. Understanding some of the
    design motivations will hopefully guide you in making your design decisions.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑到这些设计的基础上，我们将在本章剩余的部分中查看一些可以改进的Lo-Dash代码。了解一些设计动机可能会在您做出设计决策时提供指导。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Design principles
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计原则
- en: Improving performance
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高性能
- en: Lazy evaluation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 惰性评估
- en: Caching things
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缓存事项
- en: Design principles
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计原则
- en: Lo-Dash had some fairly modest goals in the beginning. Underscore appealed to
    the masses because of the problems it solved and because its API was coherent
    and easy to use. Lo-Dash's creator, John-David Dalton, wanted to prove that it
    was possible to implement a great API, such as Underscore's, while delivering
    consistency and performance across browsers. Additionally, Lo-Dash has the freedom
    to implement new features that aren't welcomed by Underscore.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Lo-Dash最初设定了一些相当低调的目标。Underscore因其解决的问题以及其API的连贯性和易用性而受到大众的喜爱。Lo-Dash的创造者，John-David
    Dalton，想要证明在提供跨浏览器的连贯性和性能的同时，实现一个像Underscore那样的优秀API是可能的。此外，Lo-Dash有自由去实现Underscore不欢迎的新特性。
- en: In order to prove his point, John-David had to establish some guiding design
    principles. Some of the founding principles are still around today, while others
    have morphed into something else to better support programmers who use the library
    and contribute to it. Lo-Dash is nothing if not adaptable to change.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了证明他的观点，John-David必须建立一些指导设计原则。一些基本原则至今仍然存在，而其他一些则已经演变成其他形式，以更好地支持使用该库并为其做出贡献的程序员。如果没有适应变化的能力，Lo-Dash将什么都不是。
- en: Function compilation to base functions
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 函数编译到基础函数
- en: The earlier versions of Lo-Dash utilized a technique called **function compilation**.
    This means that there were templates of a skeleton function. Then Lo-Dash would
    fill them and create function instances on the fly. These were then exposed through
    the API. The nice thing about this approach is that it is easy to implement a
    ton of variability for one function without the need to implement several versions
    of that function. Being able to implement generic functions like this while keeping
    the code size small meant that Lo-Dash was able to tackle all sorts of different
    use cases, from both a performance perspective and a bug-fixing/consistency perspective.
    However, this approach was holding Lo-Dash back in two ways.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Lo-Dash的早期版本使用了一种称为**函数编译**的技术。这意味着存在一个骨架函数的模板。然后Lo-Dash会填充这些模板，并即时创建函数实例。这些实例随后通过API暴露出来。这种方法的优点是，无需实现该函数的多个版本，就可以轻松地为单个函数实现大量的可变性。能够在保持代码体积小的同时实现这样的通用函数，意味着Lo-Dash能够处理各种不同的用例，从性能角度和错误修复/一致性角度来看。
- en: The first issue with function compilation is the readability of the code—something
    so dynamic isn't all that approachable by developers. This aspect of open source
    goes out the window—you don't get folks reviewing code by scaring them off. The
    second issue is that JavaScript engines are continually improving their ability
    to optimize JavaScript code as it runs. This is also known as **just-in-time**
    (**JIT**) optimization. So between now and the time that Lo-Dash was first conceived,
    browser vendors have come a long way. In such a short time, these improvements
    weren't being fully utilized by Lo-Dash and its approach of function compilation.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 函数编译的第一个问题是代码的可读性——如此动态的东西并不容易被开发者接受。开源的这一方面也就消失了——你不会因为吓跑开发者而得到他们的代码审查。第二个问题是
    JavaScript 引擎在持续改进其优化运行时 JavaScript 代码的能力。这也被称为**即时**（**JIT**）优化。因此，从现在到 Lo-Dash
    首次构思的时间，浏览器供应商已经取得了长足的进步。在如此短的时间内，这些改进并没有被 Lo-Dash 及其函数编译方法充分利用。
- en: In recent versions of Lo-Dash (2.4 and 3.0 in particular), the function compilation
    approach has been replaced with **base functions**. In other words, base functions
    are generic components, used by several publicly-facing functions. The earlier
    versions of the library shied away from abstractions due to the fear that unnecessary
    indirection would mean performance penalty. While it's true that abstractions
    do incur an overhead cost, it turns out that helping the browser perform JIT optimizations
    outweighs this cost.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Lo-Dash 的最新版本（特别是 2.4 和 3.0）中，函数编译方法已被替换为**基础函数**。换句话说，基础函数是通用组件，被多个面向公众的函数所使用。库的早期版本由于担心不必要的间接引用会导致性能损失，因此回避了抽象。虽然抽象确实会产生额外的开销，但帮助浏览器执行
    JIT 优化所带来的好处超过了这种成本。
- en: This doesn't mean that Lo-Dash has abandoned all caution of abstraction overhead.
    The implementation is quite clever and readable, which solves earlier issues of
    comprehending the source. A given base function is probably used in several places,
    which reduces repetitive code. What's more important is the way the base functions
    are structured. A given function that's exposed through the API will do some initial
    work to make sense of the arguments that were passed. Essentially, this is the
    preparation so that more exact arguments can be passed to the base function. This
    results in better predictability for the JavaScript engine. The cost of calling
    a base function is often negated, especially when the same call is made frequently—the
    engine will often inline the function to where it's called.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不意味着 Lo-Dash 放弃了所有关于抽象开销的谨慎。实现方式既巧妙又易于阅读，解决了早期理解源代码的问题。一个特定的基础函数可能被用在多个地方，这减少了重复代码。更重要的是基础函数的结构方式。通过
    API 公开的特定函数将进行一些初步工作，以便理解传递的参数。本质上，这是为了准备将更精确的参数传递给基础函数。这为 JavaScript 引擎提供了更好的可预测性。调用基础函数的成本通常可以忽略不计，尤其是在频繁调用相同函数时——引擎通常会将其内联到调用位置。
- en: So what's the implication here for Lo-Dash programmers? Nothing really. The
    way these internal base functions are structured and used should not impact your
    code at all. This, however, should give some insight into how Lo-Dash is able
    to evolve quickly, based on developer feedback and changing JavaScript technologies.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，这对 Lo-Dash 程序员有什么影响呢？实际上没有。这些内部基础函数的结构和使用方式对你的代码没有任何影响。然而，这应该能让你对 Lo-Dash
    如何根据开发者反馈和不断变化的 JavaScript 技术快速演变有所了解。
- en: Optimizing for the common case
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化常见情况
- en: This principle, **optimize for the common case**, has been with Lo-Dash from
    day one. Sure, subtle implementation details have evolved, but the underlying
    idea remains intact and this will likely always be the case. Think of this as
    the golden rule in Lo-Dash (the unofficial rule). Just as the Linux kernel development
    has a golden rule, called *don't break user space*, think of *optimize for the
    common case* as something to always strive for.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这个原则，“**优化常见情况**”，从 Lo-Dash 诞生之日起就存在。当然，细微的实现细节已经有所演变，但基本理念仍然保持不变，这可能会一直如此。把这看作是
    Lo-Dash 的黄金法则（非官方规则）。正如 Linux 内核开发有一个被称为“*不要破坏用户空间*”的黄金法则一样，把“*优化常见情况*”看作是始终追求的目标。
- en: 'Take the base function approach that''s now used in favor of function compilation.
    We can choose which base function to call based on the arguments the user has
    supplied. For example, a function that accepts a collection could use a base function
    that works only with arrays. It''s optimized for arrays. So, when the function
    that accepts a collection is called, it checks whether it''s dealing with an array
    or not. If it is, it''ll use the faster base function. Here''s an illustration
    of the pattern using pseudo-JavaScript:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 采用现在更受欢迎的基函数方法，而不是函数编译。我们可以根据用户提供的参数选择要调用的基函数。例如，接受集合的函数可以使用仅适用于数组的基函数。它针对数组进行了优化。因此，当调用接受集合的函数时，它会检查是否正在处理数组。如果是，它将使用更快的基函数。以下是一个使用伪
    JavaScript 的模式说明：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The common path is the first path that's tested. The `baseArray()` function
    that is executed is generic enough and used frequently enough to get special treatment
    from the JIT. The strategy is to assume that the common case is passing an array.
    The assumption isn't arbitrary either; it's benchmarked against typical use cases
    during development. The worst case is when we're dealing with a string or when
    a plain object isn't slow, necessarily, it's just not optimized. So these slower
    calls, as infrequent as they are, will be offset by the optimized calls that happen
    all the time.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 常见路径是第一个测试的路径。执行的 `baseArray()` 函数足够通用且使用频率足够高，以至于 JIT 会给予特殊处理。策略是假设常见情况是传递一个数组。这种假设也不是任意的；它在开发过程中与典型用例进行了基准测试。最坏的情况是我们处理字符串或当普通对象不慢时，这并不是说它没有优化。因此，这些较慢的调用，尽管它们很少发生，但会被频繁发生的优化调用所抵消。
- en: The common case can even be tiered. That is, your function is thrown one of
    several cases when called, and all of those possibilities have an order to their
    frequency. For example, if the most common case isn't met, what's the next most
    common case? And so on. The effect of this technique pushes the uncommon code
    down towards the bottom of the function. On its own, this doesn't have a huge
    impact on performance, but when every function in the library consistently follows
    the same common case optimization techniques, the impact is huge.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 常见情况甚至可以分级。也就是说，当函数被调用时，它会抛出一个或多个情况，所有这些可能性都有它们出现频率的顺序。例如，如果最常见的情况没有满足，下一个最常见的情况是什么？以此类推。这种技术的影响是将不常见的代码推向函数的底部。单独来看，这不会对性能产生巨大影响，但当库中的每个函数都持续遵循相同的常见情况优化技术时，影响就非常大了。
- en: Loops are simple
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 循环很简单
- en: Lo-Dash uses a lot of loops in its code. That's because there's a lot of iterating
    over collections. It's also because Lo-Dash does not use certain native functions
    that would otherwise negate the need for a loop. This is the opposite of the stance
    Underscore.js takes on this matter. It prefers the native methods whenever they're
    available. The logic being the JavaScript library shouldn't have to worry about
    iteration performance. Instead, the browser vendor should improve the native method
    performance.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Lo-Dash 在其代码中使用了大量的循环。这是因为有很多集合的迭代。这也是因为 Lo-Dash 不使用某些会消除循环需要的原生函数。这与 Underscore.js
    在这个问题上的立场相反。它更喜欢在可用时使用原生方法。逻辑是，JavaScript 库不需要担心迭代性能。相反，浏览器供应商应该提高原生方法性能。
- en: This approach makes sense, especially when the side effect is writing less code.
    However, Lo-Dash doesn't rely on the browser vendor to deliver performance. We
    can get better performance out of simple `while` loops and this will likely continue
    in the foreseeable future. Native methods are undoubtedly faster than unoptimized
    JavaScript code, but they aren't able to perform the same kind of optimizations
    as we're able to when using pure JavaScript.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法是有意义的，尤其是在副作用是编写更少代码的情况下。然而，Lo-Dash 不依赖于浏览器供应商提供性能。我们可以从简单的 `while` 循环中获得更好的性能，这可能会在可预见的未来继续。原生方法无疑比未优化的
    JavaScript 代码更快，但它们无法执行与我们使用纯 JavaScript 时相同的优化。
- en: Note
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Lo-Dash is a strategic animal. It doesn't like to rely on certain native JavaScript
    methods, but it relies heavily on the JIT abilities of any given JavaScript engine
    for performance, cost balancing in action.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Lo-Dash 是一个策略性的动物。它不喜欢依赖于某些原生 JavaScript 方法，但它非常依赖任何给定 JavaScript 引擎的 JIT 能力来实现性能和成本平衡。
- en: 'Lo-Dash also doesn''t like to rely on `for` loops—`while` loops are preferred.
    The `for` loop is useful when used to iterate over collections, thus enhancing
    code readability. Under these simple circumstances, trying to use a `while` loop
    is just cumbersome. Even though the `while` loop does have a slight performance
    edge over the `for` loop, it''s not really all that noticeable. The performance
    difference is noticeable in the case of several large collections that are frequently
    iterated over. This is the common case that Lo-Dash accounts for. Consider the
    following code:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Lo-Dash 也不喜欢依赖 `for` 循环——更倾向于使用 `while` 循环。`for` 循环在用于遍历集合时很有用，从而增强了代码的可读性。在这些简单情况下，尝试使用
    `while` 循环只是繁琐。尽管 `while` 循环确实比 `for` 循环有轻微的性能优势，但这并不是特别明显。在频繁遍历的几个大型集合的情况下，性能差异是明显的。这是
    Lo-Dash 考虑的常见情况。考虑以下代码：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The difference between the two loops is hardly perceptible. Probably a couple
    of years ago, the lead the `while` loop had over `for` may have been wider, which
    is one reason Lo-Dash is still using `while` loops everywhere. Another reason
    is consistency. Since the `while` loop is nearly identical wherever it's implemented
    in Lo-Dash, you can expect its performance to be predictable throughout. This
    is especially true given that there's not a mixture of `while` loops, `for` loops,
    and native JavaScript methods. Sometimes, predictable performance is better than
    *sometimes it's faster, but I can never be sure*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 两个循环之间的差异几乎不可察觉。可能在大约两年前，`while` 循环相对于 `for` 循环的领先优势可能更大，这也是 Lo-Dash 仍然在所有地方使用
    `while` 循环的一个原因。另一个原因是一致性。由于 `while` 循环在 Lo-Dash 中的实现几乎完全相同，你可以预期其性能在整个过程中是可预测的。这一点在不是
    `while` 循环、`for` 循环和原生 JavaScript 方法混合的情况下尤其正确。有时，可预测的性能比“有时它更快，但我永远无法确定”要好。
- en: Callbacks and function binding
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回调函数和函数绑定
- en: Callbacks are used everywhere in Lo-Dash, both internally and as arguments of
    API functions. So it's important that these functions get executed with as little
    overhead as possible. The big culprit that slows down these function calls is
    the `this` context, that is, the context that the function is bound to. If there's
    no context to consider, then there's clearly less overhead involved, especially
    considering that these callback functions typically get called once per iteration
    if the function is operating on a collection.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 回调函数在 Lo-Dash 中无处不在，无论是内部使用还是作为 API 函数的参数。因此，这些函数以尽可能少的开销执行是很重要的。导致这些函数调用变慢的主要问题是
    `this` 上下文，即函数绑定到的上下文。如果没有上下文需要考虑，那么涉及的开销显然更少，特别是考虑到这些回调函数通常在函数对集合进行操作时每次迭代只被调用一次。
- en: If there's a specific context for the callback function, then we have to use
    `call()` to call the function, since it allows us to set the context. Or if there
    are an unknown number of arguments, we use the `apply()` function, passing the
    context and the arguments as an array. This is especially slow if executed iteratively.
    To help combat these performance hurdles, Lo-Dash uses a base function to help
    construct callback functions.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果回调函数有特定的上下文，那么我们必须使用 `call()` 来调用该函数，因为它允许我们设置上下文。或者如果有未知数量的参数，我们使用 `apply()`
    函数，将上下文和参数作为数组传递。如果迭代执行，这会特别慢。为了帮助克服这些性能障碍，Lo-Dash 使用一个基础函数来帮助构建回调函数。
- en: 'This function is used anywhere where there''s a callback function passed as
    an argument. The first step is to use this function to build a potentially wrapped
    callback function. This initial examination is worth the cost because of the potential
    savings when it has to be called iteratively. Here''s a rough idea of how this
    function works:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数用于任何传递回调函数作为参数的地方。第一步是使用此函数构建一个可能被包装的回调函数。这种初步检查是值得的，因为当它需要迭代调用时，可以节省潜在的时间。以下是这个函数大致工作原理的简要说明：
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This is a gross simplification of what `baseCallback()` is really doing, but
    the general pattern is accurate. The most common cases that build a callback function
    are checked first. The uncommon, slower cases are pushed to the bottom. For example,
    if there's no `thisArg`, we don't have to bind the function; it can just be returned.
    The next case that is checked is whether or not the function has already been
    bound. If it has been, then the `thisArg` value is ignored and the function is
    returned. If neither of these checks passes and the `argCount` argument is supplied,
    we can use `call()`, supplying the exact number of arguments. The preceding pseudocode
    shows the case of only a single argument, but in reality, it checks for several
    exact argument counts.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对`baseCallback()`实际执行内容的粗略简化，但总体模式是准确的。首先检查的是构建回调函数最常见的案例。不常见且较慢的案例被推到后面。例如，如果没有`thisArg`，我们不需要绑定函数；它可以直接返回。接下来检查的是函数是否已经被绑定。如果已经绑定，则忽略`thisArg`值并返回函数。如果这两个检查都不通过，并且提供了`argCount`参数，我们可以使用`call()`，提供确切的参数数量。前面的伪代码显示了只有一个参数的情况，但在现实中，它会检查几个确切的参数数量。
- en: The uncommon case is when `thisArg` is supplied, meaning we have to bind the
    function and we don't know how many arguments are there. So, we use `apply()`,
    the slowest scenario. Other cases `baseCallback()` is able to handle include a
    string or a plain object being passed as `func` instead of a function instance.
    For such cases, there are specific callback functions that get returned and this
    is also checked for early on since it's a common case.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 不常见的案例是当提供了`thisArg`时，这意味着我们必须绑定函数，但我们不知道有多少个参数。因此，我们使用`apply()`，这是最慢的情况。`baseCallback()`能够处理的其它情况包括将字符串或纯对象作为`func`传递而不是函数实例。对于这种情况，会返回特定的回调函数，并且这也会在早期进行检查，因为它是一个常见的案例。
- en: The `alreadyBound()` function is something made up for brevity. Lo-Dash knows
    whether a function is already bound or not by looking at the metadata for that
    function. In this context, metadata refers to data that's attached to the function
    by Lo-Dash, but is completely transparent to the developer. For example, many
    callbacks will track data about the frequency with which they are called. If the
    function becomes *hot*, Lo-Dash will treat it differently than callbacks that
    aren't executed frequently.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`alreadyBound()`函数是为了简洁而编造的。Lo-Dash通过查看该函数的元数据来知道一个函数是否已经被绑定。在这个上下文中，元数据是指由Lo-Dash附加到函数上的数据，但对开发者来说是完全透明的。例如，许多回调会跟踪它们被调用的频率数据。如果函数变得*热点*，Lo-Dash会将其与其他不经常执行的回调区别对待。'
- en: Improving performance
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提高性能
- en: Just because Lo-Dash is designed from the ground up for optimal performance,
    it doesn't mean there are no basic modifications we can make to our Lo-Dash code
    to improve performance. In fact, we can sometimes borrow some Lo-Dash design principles
    and apply them directly to our code that utilizes Lo-Dash.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Lo-Dash从一开始就是为了最佳性能而设计的，但这并不意味着我们无法对我们的Lo-Dash代码进行一些基本的修改来提高性能。实际上，我们有时可以借鉴一些Lo-Dash的设计原则并将其直接应用于使用Lo-Dash的代码中。
- en: Changing the operation order
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 改变操作顺序
- en: 'Using a Lo-Dash wrapper around a value, such as an array, lets us chain together
    many operations on that value. As we saw in [Chapter 6](ch06.html "Chapter 6. Application
    Building Blocks"), *Application Building Blocks*, a wrapper has many advantages
    over stitching together, piecemeal, several statements that call Lo-Dash functions.
    For example, the end result is often more concise and readable code. The different
    orders in which we call these operations in a chain can yield the same result
    and yet have different performance implications. Let''s look at three different
    approaches to filtering a collection that get us the same result:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个值（如数组）周围使用Lo-Dash包装器，让我们可以链式地对该值执行许多操作。正如我们在[第6章](ch06.html "第6章。应用构建块")中看到的，“应用构建块”，与逐个拼接调用Lo-Dash函数的多个语句相比，包装器有许多优势。例如，最终结果通常是更简洁、更易读的代码。我们在链中调用这些操作的顺序可能产生相同的结果，但性能影响却不同。让我们看看三种不同的过滤集合的方法，它们都能得到相同的结果：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `collection` array is quite straightforward. It contains `100` items and
    each item is an object with two properties. The first is a numerical ID. The second
    is a random Boolean value. The goal is to filter out anything that's not `enabled`
    and anything with an `id` value that is less than `75`.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`collection` 数组相当简单。它包含 `100` 个项，每个项都是一个具有两个属性的对象。第一个是一个数值 ID。第二个是一个随机的布尔值。目标是过滤掉任何未
    `启用` 的项以及任何 `id` 值小于 `75` 的项。'
- en: The first approach builds a chain consisting of two `filter()` calls. The first
    `filter()` call removes any disabled items. The second approach removes anything
    with an `id` property whose value is less than `75`. However, the ordering of
    these filtering operations isn't optimal. You might have noticed that there are
    a large number of items removed based on their `id` value. This is due to the
    nature of the filter and the dataset we're dealing with.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方法构建了一个由两个 `filter()` 调用组成的链。第一个 `filter()` 调用移除了任何禁用项。第二种方法移除了具有 `id` 属性且其值小于
    `75` 的任何项。然而，这些过滤操作的顺序并不最优。你可能已经注意到，根据 `id` 值移除的项目数量很多。这是由于过滤器的性质和我们正在处理的数据集的特性所导致的。
- en: Any calls made to `filter()` mean that a linear iteration takes place over the
    collection. With the first approach, there are two calls made to `filter()`, which
    means that we'll have to iterate linearly over the collection twice. Given what
    we now know about the collection data and what the filter is looking for, we can
    optimize the ordering of the filter calls. This is a simple change. We first filter
    by `id` and then by the `enabled` property. The result is a noticeable boost in
    performance because the second call to `filter()` has to iterate over far fewer
    items.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对 `filter()` 的任何调用都意味着在集合上发生线性迭代。在第一种方法中，调用了两次 `filter()`，这意味着我们将不得不对集合进行两次线性迭代。鉴于我们现在对集合数据和过滤器所寻找的内容的了解，我们可以优化过滤调用的顺序。这是一个简单的更改。我们首先按
    `id` 过滤，然后按 `enabled` 属性过滤。结果是性能有明显的提升，因为第二次调用 `filter()` 必须迭代的项目要少得多。
- en: The third approach takes things a step further and removes an iteration completely.
    Since both filter conditions are checked in the `filter()` callback function,
    there's no need to iterate over any collection item twice.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种方法更进一步，完全移除了一个迭代过程。由于两个过滤条件都在 `filter()` 回调函数中检查，因此没有必要对任何集合项进行两次迭代。
- en: Note
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Of course, the trade-off here is more complexity in the given callback function.
    Keep this in mind if your application does lots of filtering, because you'll want
    to avoid defining highly specialized callback functions that serve a single purpose.
    It's generally a better idea to keep your functions small and generic. The second
    approach strikes a good balance. These types of optimizations don't often happen
    upfront, so wait until the common case reveals itself before trying to optimize
    for it.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这里的权衡是在给定的回调函数中增加了更多的复杂性。如果你的应用程序进行大量的过滤，请记住这一点，因为你将想要避免定义高度专业化的、仅用于单一目的的回调函数。通常，保持函数小而通用是一个更好的主意。第二种方法达到了一个很好的平衡。这类优化通常不会一开始就发生，所以等到常见情况显现出来后再尝试对其进行优化。
- en: Sorting and indexing collections
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 排序和索引集合
- en: If the order of the collection is an important factor in the application you're
    developing, you can introduce tweaks that take advantage of its importance. These
    tweaks include maintaining the sort order. There's really no point in re-sorting
    collections every time you need to render it. Rather, it's better to sort the
    collection once and then maintain its order by inserting new items in the correct
    place. Lo-Dash has the `sortedIndex()` function, which helps find the proper insertion
    point for new items. In fact, it performs a binary search and is much faster than
    a linear search through the collection.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在开发的程序中，集合的顺序是一个重要因素，你可以引入一些调整，以利用其重要性。这些调整包括保持排序顺序。每次需要渲染时重新排序集合实际上并没有什么意义。相反，最好是一次性对集合进行排序，然后通过在正确的位置插入新项来维护其顺序。Lo-Dash
    有一个 `sortedIndex()` 函数，它有助于找到新项的正确插入点。实际上，它执行二分搜索，比在集合中进行线性搜索要快得多。
- en: 'For faster filtering operations, we can borrow the `sortedIndex()` function.
    If we have a sorted collection, there''s really no need to filter items using
    a linear search, which performs rather poorly in the worst case. Let''s introduce
    a new `mixin` function that performs the same job as the `filter()` function but
    is optimized for sorted collections:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更快的过滤操作，我们可以借用`sortedIndex()`函数。如果我们有一个已排序的集合，实际上根本不需要使用线性搜索来过滤项，这在最坏情况下表现相当差。让我们引入一个新的`mixin`函数，它执行与`filter()`函数相同的工作，但针对已排序的集合进行了优化：
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The new function we've introduced—`sortedFilter()`—is faster than the `filter()`
    function. Again, this is because we don't have to rely on a linear search, since
    the collection is sorted. Instead, the `sortedIndex()` function is used to find
    what we're looking for. It uses a binary search, which means that with larger
    collections, there are a large number of items that aren't checked. The end result
    is fewer CPU cycles and faster execution time.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们引入的新功能——`sortedFilter()`——比`filter()`函数更快。再次强调，这是因为我们不需要依赖线性搜索，因为集合已经排序。相反，我们使用`sortedIndex()`函数来找到我们想要的东西。它使用二分搜索，这意味着在更大的集合中，有很多项不会被检查。最终结果是更少的CPU周期和更快的执行时间。
- en: Our `sortedFilter()` implementation, thanks largely to `sortedIndex()`, isn't
    all that complicated. The binary search gets us the insertion point to insert
    the new item, but we're not actually inserting anything. We're just looking for
    it. There could be several items that match our criteria, or there could be none.
    This is where we iterate over the collection, using the insertion index as a starting
    point. We now have to explicitly check the values using `isEqual()` and build
    the result array. Since the collection is sorted, we know to stop and return when
    items stop matching the filter criteria.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`sortedFilter()`实现，很大程度上得益于`sortedIndex()`，并不复杂。二分搜索为我们提供了插入新项的位置，但我们实际上并没有插入任何东西。我们只是在寻找它。可能有几个项符合我们的标准，或者可能没有。这就是我们在集合上迭代，以插入索引作为起点的地方。现在我们必须使用`isEqual()`显式检查值并构建结果数组。由于集合已排序，我们知道当项不再符合过滤标准时停止并返回。
- en: Note
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Always take care to validate your code for correctness when improving Lo-Dash
    functions for performance purposes. The easiest way to do this is to set up a
    number of automated tests that compare the output of the Lo-Dash function with
    that of your faster variant. This allows you to throw all kinds of edge cases
    at your code before you get too excited about your newly found speed. Lo-Dash
    takes care of a lot of edge cases, so make sure you don't sidestep safety in favor
    of performance.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在提高Lo-Dash函数性能时，始终要注意验证代码的正确性。最简单的方法是设置一系列自动化测试，比较Lo-Dash函数的输出与你的更快变体的输出。这允许你在对新的发现速度过于兴奋之前，将所有各种边缘情况都抛给你的代码。Lo-Dash处理了很多边缘情况，所以请确保你不会为了性能而牺牲安全性。
- en: 'Another technique in speeding up filtering operations on collections is to
    index them. This means creating a new data structure that uses keys to look for
    common items in the collection. This is another way to avoid the costly linear
    search in large collections. Here''s an example that uses `groupBy()` to index
    a collection for a fast search of items using common filtering criteria:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在加快集合上的过滤操作速度的另一种技术是对其进行索引。这意味着创建一个新的数据结构，它使用键来查找集合中的常见项。这是避免在大集合中进行昂贵的线性搜索的另一种方法。以下是一个使用`groupBy()`对集合进行索引的示例，以便快速搜索使用常见过滤标准的项：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The indexed approach takes much less time than the `where()` approach to look
    for the same items. This approach is useful when there are several instances of
    the same filter throughout your application. The `indexed` variable holds the
    indexed version of the collection. The index is created using the `groupBy()`
    function. It takes an array as the input and produces an object. The index keys
    are the object keys, and the callback passed to `groupBy()` is responsible for
    generating these keys. The function returns the key value, and if the key already
    exists, the item is added to that key.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 索引方法查找相同项所需的时间比`where()`方法少得多。当你的应用程序中有多个相同的过滤器实例时，这种方法很有用。`indexed`变量持有集合的索引版本。索引是通过`groupBy()`函数创建的。它接受一个数组作为输入并生成一个对象。索引键是对象键，传递给`groupBy()`的回调函数负责生成这些键。该函数返回键值，如果键已存在，则该项将被添加到该键。
- en: The idea is that we want items indexed by their `age` property value, and by
    whether or not they're `enabled`. We use a neat little trick here to do that.
    The `enabled` property is converted to a positive integer and multiplied by the
    `age` value. So any disabled items will be indexed under `0`, where nobody looks.
    Now you can see that looking for the items in the `indexed` object yields the
    same results as the `where()` filter. With the latter approach, we're doing a
    simple object access operation rather than iterating over a collection and performing
    several operations.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是，我们希望根据`age`属性值和是否启用来索引项目。在这里，我们使用了一个巧妙的小技巧来实现这一点。`enabled`属性被转换成正整数，并乘以`age`值。因此，任何禁用的项目都将被索引在`0`下，那里没有人会去看。现在你可以看到，在`indexed`对象中查找项目会产生与`where()`过滤器相同的结果。在后一种方法中，我们执行的是一个简单的对象访问操作，而不是遍历一个集合并执行多个操作。
- en: Note
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: While the speedups here are quite impressive, be sure to consider the update
    frequency for items in this collection. If you think about it, the indexed version
    is really just a cache of common filter results. So if the collection is never
    updated, you're good to go assuming you're okay with the one-time payment of actually
    indexing the collection.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这里的速度提升相当令人印象深刻，但请务必考虑这个集合中项目的更新频率。如果你这么想，索引版本实际上只是一个常见过滤结果的缓存。所以如果集合从未更新，只要你对实际上索引集合的一次性付费没有问题，那么你就没问题。
- en: Bound and unbound callbacks
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 绑定与未绑定回调
- en: Lo-Dash embraces callback functions and does a really good job of optimizing
    the way they're called. For example, it avoids using `call()` and `apply()` when
    there's no `this` context necessary, and this is for a good reason—these calls
    are a lot slower than unbound function calls. So when we're writing our application
    that utilizes Lo-Dash callback functions, we have the option to provide context
    to each of these callbacks as they're applied to collections. Take the time to
    weigh the trade-offs before coding functions in this way.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Lo-Dash支持回调函数，并且在这方面做得非常好。例如，当不需要`this`上下文时，它避免了使用`call()`和`apply()`，这有一个很好的原因——这些调用比未绑定函数调用要慢得多。因此，当我们编写利用Lo-Dash回调函数的应用程序时，我们有选择在每个回调函数应用于集合时提供上下文的选项。在以这种方式编写函数之前，花时间权衡利弊。
- en: Binding our functions to a context is convenient when we want to use the same
    function in a different context. This isn't always necessary and it depends largely
    on the overall design of our code. If we have tons of objects that our callbacks
    need to access, the `this` context is pretty convenient. We might even have a
    single application object that is used to access other objects, and so on. If
    that's the case, we'll definitely need a way to pass this object to our callback
    functions. This could mean binding the `this` context, accessing the object through
    function closure, or creating a partial function for our callback.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想在不同的上下文中使用相同的函数时，将我们的函数绑定到上下文中是方便的。这并不总是必要的，这很大程度上取决于我们代码的整体设计。如果我们有很多对象需要回调函数访问，`this`上下文就非常方便。我们甚至可能有一个用于访问其他对象的单一应用程序对象，依此类推。如果是这样，我们肯定会需要一个方法将这个对象传递给我们的回调函数。这可能意味着绑定`this`上下文，通过函数闭包访问对象，或者为我们的回调创建一个部分函数。
- en: 'None of these options are particularly performance friendly. Therefore, if
    we find that our callbacks are in constant need of access to some object, it might
    make sense to define it in a callback function, instead of defining it as a variable.
    The following code illustrates this idea:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这些选项都不是特别适合性能。因此，如果我们发现我们的回调函数经常需要访问某些对象，那么在回调函数中定义它，而不是将其定义为变量，可能是有意义的。以下代码说明了这个想法：
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can see that the unbound callback function will generally outperform the
    bound callback function. What's important to note here is the approach. The `bound()`
    function is bound to a specific context with the call to `map()`. This is because
    it needs something from the application object. The `unbound()` function, instead
    of relying on some external instance, will declare the variable itself. So we
    will get what we need for the callback without the need to bind to a specific
    callback function.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，未绑定回调函数通常会比绑定回调函数表现更好。这里需要注意的是方法。`bound()`函数通过`map()`调用绑定到特定的上下文中，因为它需要从应用程序对象中获取一些东西。而`unbound()`函数，不依赖于外部实例，会自己声明变量。因此，我们可以在不需要绑定到特定回调函数的情况下，为回调函数获取所需的内容。
- en: At first, this may seem like a counterintuitive approach to defining application-level
    variables inside a callback function. Well, it boils down to the rest of your
    code. Do you have a lot of callback functions that require access to this data?
    If you put this callback function in an easy-to-locate place in your source tree,
    then it's really not all that different from modifying a variable.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，这可能会让人觉得在回调函数内定义应用级变量是一种反直觉的方法。好吧，这归结到你的代码的其他部分。你有很多需要访问这些数据的回调函数吗？如果你将这个回调函数放在源树中容易找到的位置，那么这实际上与修改一个变量并没有太大的区别。
- en: Note
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Switching from bound to unbound functions doesn't yield a huge performance gain
    when there are just a handful of callback functions. Even if there are lots of
    functions, it's fine to have several bound functions without impacting performance.
    The idea of this section is to keep you on the lookout for functions that are
    *needlessly* bound to a context. Fix them where you can if they don't have a noticeable
    impact on your design.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当只有少数回调函数时，从绑定函数切换到非绑定函数并不会带来巨大的性能提升。即使有很多函数，只要没有影响性能，拥有几个绑定函数也是可以的。本节的想法是让你留意那些无谓地绑定到上下文中的函数。如果它们对你的设计没有明显影响，你可以尝试修复它们。
- en: Lazy evaluation
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 惰性求值
- en: With the introduction of Lo-Dash 3.0, some functions use a **lazy evaluation**
    to compute their results. This simply means that the items in a given collection
    aren't iterated over until they're actually needed. It's figuring out when they're
    needed that is the tricky part. For example, just calling a single Lo-Dash function
    doesn't invoke any lazy evaluation mechanism. However, operations that are chained
    together could certainly benefit from this approach, in certain circumstances.
    For example, when we're only taking 10 items from the result, there's no need
    to iterate over the entire collection further up the chain.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 随着Lo-Dash 3.0的引入，一些函数使用**惰性求值**来计算它们的结果。这仅仅意味着给定集合中的项目在实际上需要之前不会迭代。确定它们何时需要才是棘手的部分。例如，仅仅调用单个Lo-Dash函数并不会触发任何惰性求值机制。然而，链式操作在某些情况下确实可能从这种方法中受益。例如，当我们只从结果中取10个项目时，就没有必要进一步迭代整个集合。
- en: 'To get an idea of what a lazy evaluation looks like, let''s write some code
    to utilize it. There''s nothing explicit to be done. The lazy mechanism happens
    transparently, behind the scenes, depending on which operations make up our chain
    and what order they''re called in:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解惰性求值的样子，让我们写一些代码来利用它。这里没有明确的事情要做。惰性机制在幕后透明地发生，取决于我们的链中包含哪些操作以及它们的调用顺序：
- en: '[PRE7]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here, our chain is composed of two functions—`reject()` and `map()`. Since `reject()`
    is called first, Lo-Dash makes it a lazy wrapper. This means that when `value()`
    is called, things are done a bit differently. Rather than running each function
    to completion, the lazy functions in the chain are asked for a value. For example,
    `reject()` doesn't run until `map()` asks it for a value. When it does, `reject()`
    will run till it produces a value. We can actually see this behavior in the output.
    The `reject()` function is checking item `1`, which gets rejected. It then moves
    on to item `2`, which passes the test. This is then passed to `map()`. Then item
    `3` is checked, and so on.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们的链由两个函数组成——`reject()`和`map()`。由于`reject()`首先被调用，Lo-Dash将其作为一个惰性包装器。这意味着当调用`value()`时，事情会有些不同。而不是运行每个函数直到完成，链中的惰性函数会被要求提供一个值。例如，`reject()`只有在`map()`请求值时才会运行。当它运行时，`reject()`会一直运行直到产生一个值。我们实际上可以在输出中看到这种行为。`reject()`函数正在检查项目`1`，该项目被拒绝。然后它继续到项目`2`，该项目通过了测试。然后这个项目被传递给`map()`。然后检查项目`3`，依此类推。
- en: 'The two function calls are interleaved and this property can extend upward
    through many functions in a more complicated chain. The advantage is that if these
    functions are too expensive to run through an entire collection, they generally
    don''t have to. They''ll execute only when asked to execute. Let''s see this concept
    in action:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个函数调用是交织在一起的，并且这种属性可以向上扩展到更复杂的链中的许多函数。优点是，如果这些函数在整个集合上运行成本太高，通常不需要运行。它们只会在被要求执行时执行。让我们看看这个概念的实际应用：
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You can see that the lazy approach takes much less time than the motivated approach,
    even though it is taking `100` results and the latter is taking only `10`. The
    reason is simple—the collection is large and the entire thing is filtered using
    the motivated approach. The lazy approach uses far fewer iterations.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，懒惰的方法比有动力的方法花费的时间少得多，尽管它处理了`100`个结果，而后者只处理了`10`个。原因很简单——集合很大，整个集合都是通过有动力的方法进行过滤的。懒惰的方法使用的迭代次数要少得多。
- en: Caching things
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缓存事物
- en: 'The best way to improve the performance of an operation is to not perform it—at
    least not twice, or worse, hundreds or thousands of times. Repeating costly computations
    is an unnecessary waste of CPU cycles and can be avoided by caching the results.
    The `memoize()` function helps us here, by caching the results of the called function
    for later use. However, caching has its own overheads and pitfalls to be aware
    of. Let''s start by taking a look at idempotent functions—these always produce
    the same output when given the same input arguments:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 提高操作性能的最佳方式是不要执行它——至少不要执行两次，或者更糟糕的是，数百或数千次。重复昂贵的计算是CPU周期的无谓浪费，可以通过缓存结果来避免。`memoize()`函数在这里帮助我们，通过缓存被调用函数的结果以供以后使用。然而，缓存有其自身的开销和需要注意的陷阱。让我们首先看看幂等函数——这些函数在给定相同的输入参数时总是产生相同的输出：
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `primeFactors()` function returns an array of prime factors of the given
    number. It has to do a fair amount of work to compute the returned array. There
    is nothing that hogs the CPU for any substantial amount of time, but nonetheless,
    it's work—work that yields the same result for a given input. Idempotent functions
    such as these are good candidates for memoization. This is easy to do with the
    `memoize()` function and we use this function to generate the `primes()` function.
    Also note that the cache key is the first argument, which is nice and easy here
    because it's the only input we're interested in caching.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`primeFactors()`函数返回给定数字的质因数数组。它必须进行相当多的工作来计算返回的数组。没有什么是占用CPU大量时间的，但无论如何，它的工作——对于给定的输入产生相同结果的工作。像这样的幂等函数是进行记忆化的良好候选者。使用`memoize()`函数来做这件事很容易，我们使用这个函数来生成`primes()`函数。此外，请注意，缓存键是第一个参数，在这里很好也很简单，因为它是我们唯一感兴趣要缓存输入。'
- en: Note
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: It's important to take into consideration the amount of overhead involved with
    looking up cached items. It's not a lot, but it's there. Often, this overhead
    outweighs the value of caching the results in the first place. The preceding code
    is a case of testing with a relatively large collection. As that collection size
    shrinks, so does the performance gain.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到查找缓存项所涉及的开销，这是很重要的。这并不是很多，但确实存在。通常，这种开销超过了最初缓存结果的价值。前面的代码是使用相对较大的集合进行测试的一个例子。随着集合大小的缩小，性能提升也随之减少。
- en: 'While it''s nice to cache the results of idempotent functions because you never
    have to worry about invalidating that cache, let''s look at a more common use
    case:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然缓存幂等函数的结果很方便，因为你永远不必担心缓存失效，但让我们看看一个更常见的用例：
- en: '[PRE10]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here we're caching the result of mapping a collection to a different representation.
    In other words, we're mapping the `age` property. This mapping operation can be
    costly if it's repeated throughout the application. So we use the `memoize()`
    function to cache the result of mapping the age values, resulting in the `ages()`
    function. However, there's still the issue of looking up the cached collection—we
    need a key resolution function. The one we've provided is quite simple. It assigns
    a unique identifier to the `mapAges` property of the collection. The next time
    `ages()` is called, this identifier is found and the cached copy is looked up.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们正在缓存将集合映射到不同表示形式的结果。换句话说，我们正在映射`age`属性。如果这个映射操作在整个应用程序中重复进行，可能会很昂贵。因此，我们使用`memoize()`函数来缓存映射年龄值的结果，从而生成`ages()`函数。然而，仍然存在查找缓存集合的问题——我们需要一个键解析函数。我们提供的这个函数相当简单。它为集合的`mapAges`属性分配一个唯一的标识符。下次调用`ages()`时，这个标识符会被找到，然后查找缓存的副本。
- en: We can see that not having to map the collection again and again saves CPU cycles.
    And this is a simple mapping; other mappings with callback functions can be costlier
    and much more elaborate than simply plucking a value.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，不必再次映射集合可以节省CPU周期。这是一个简单的映射；其他带有回调函数的映射可能更昂贵，比简单地提取一个值要复杂得多。
- en: Note
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Of course, this code assumes that this collection is constant and never changes.
    If you're building a large application with lots of moving parts, static collections
    like these are actually quite common. If the collection, or items in the collection
    for that matter, change frequently throughout its lifetime, you have to start
    thinking about invalidating the cache. It's probably not worth caching maps or
    other transformations for temperamental collections because, apart from naming
    things, cache invalidation is the toughest of all problems in programming.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这段代码假设这个集合是恒定的，永远不会改变。如果你正在构建一个包含许多动态部分的大型应用程序，像这样的静态集合实际上是非常常见的。如果集合，或者集合中的项目，在其生命周期内频繁改变，你必须开始考虑使缓存失效。对于这些易变的集合，缓存映射或其他转换可能并不值得，因为，除了命名之外，缓存失效是编程中所有问题中最难的一个。
- en: Summary
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we introduced some of the influences that guide the design
    and implementation of Lo-Dash. Earlier versions of the library opted for function
    compilation, building the functions on the fly to best handle performance and
    other variations from environment to environment. Recent versions have traded
    this approach for common base functions. Function compilation avoided some of
    the indirection associated with base functions. However, modern browsers have
    a JIT optimizer. It is better able to optimize base functions. Besides, the code
    is much more readable with base functions.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了一些指导 Lo-Dash 设计和实现的影響因素。库的早期版本选择了函数编译的方法，动态构建函数以最佳地处理性能和环境之间的变化。而最近的版本则选择了通用基础函数。函数编译避免了与基础函数相关的一些间接操作。然而，现代浏览器有一个
    JIT 优化器，它能够更好地优化基础函数。此外，使用基础函数的代码可读性也更高。
- en: The golden rule of the implementation of Lo-Dash is optimization for the common
    case. You'll see this rule in action all over Lo-Dash, and it is the key factor
    in its superior performance. In any given function, the most common case is heavily
    optimized first, pushing the uncommon cases towards the end of the function. Callbacks
    are used everywhere in Lo-Dash, so it's important that they're able to perform
    predictably. The base callback machinery takes care of this for us and serves
    as a great example of optimizing for the common case.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Lo-Dash 实现的金科玉律是对常见情况的优化。你将在 Lo-Dash 的各个地方看到这条规则在发挥作用，它是其卓越性能的关键因素。在任何给定的函数中，最常见的情况首先被高度优化，将不常见的情况推到函数的末尾。回调在
    Lo-Dash 中无处不在，因此它们能够可预测地执行非常重要。基础回调机制为我们处理这个问题，并作为一个优化常见情况的绝佳例子。
- en: We then looked at some techniques used to optimize our Lo-Dash code, following
    the design principles of Lo-Dash in most cases. Changing the order of chained
    operations in a Lo-Dash wrapper can eliminate needless iterations. Working with
    sorted collections can have a dramatic impact on filter performance. Lazy evaluation
    is a concept recently introduced to Lo-Dash, and it allows us to work with large
    collections without necessarily iterating over the entire collection. Lastly,
    we looked at some scenarios where caching could help boost performance, especially
    where the computations are expensive.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接着探讨了优化 Lo-Dash 代码的一些技术，大多数情况下遵循 Lo-Dash 的设计原则。改变 Lo-Dash 包装器中链式操作的顺序可以消除不必要的迭代。与排序集合一起工作可以对过滤性能产生重大影响。延迟评估是最近引入到
    Lo-Dash 中的一个概念，它允许我们在不必要遍历整个集合的情况下与大型集合一起工作。最后，我们探讨了缓存可以帮助提高性能的一些场景，特别是在计算成本高昂的地方。
- en: With that said, you're all set. Throughout this book, we learned and implemented
    concept after concept, starting with what you get out of the box in Lo-Dash, and
    wrapping up with how to go faster. Along the way, we looked at the most common
    usage patterns used to write solid Lo-Dash code. By now, it should be clear how
    everything in Lo-Dash relates to everything else, from the conceptual to the low-level
    function calls. As with any other library, there are a dozen or more ways of doing
    something in Lo-Dash. I hope you're now well-equipped to do it the best way.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，你们已经准备就绪了。在这本书中，我们学习并实现了许多概念，从 Lo-Dash 中开箱即用的内容开始，到如何提高速度结束。在这个过程中，我们探讨了编写稳健
    Lo-Dash 代码最常用的使用模式。到目前为止，Lo-Dash 中的每一部分如何与其它部分相关，从概念到低级函数调用，应该已经很清晰了。就像任何其他库一样，在
    Lo-Dash 中做某事有十几种或更多的方式。我希望你现在已经准备好以最佳方式完成它。
