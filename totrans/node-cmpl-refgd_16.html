<html><head></head><body><div><h1 class="header-title">Implementing a Full Fledged RESTful Service</h1>
                
            
            
                
<p>So far, we have created a second version of our RESTful service, and we had the two versions exposed by different URLs, ensuring backward compatibility. We implemented unit tests for its database layer and discussed how to use HTTP status codes appropriately. In this chapter, we will extend that implementation—by providing handling of non-document—binary data to the second version of the service and linking it accordingly to the documents it relates to.</p>
<p>We will look at a convenient way of presenting large result sets to consumers. For that purpose, we will introduce pagination as well as further filtering capabilities to our API.</p>
<p>There are cases when caching data responses should be considered as an option. We will look at its benefits and drawbacks and also decide to enable caching when necessary.</p>
<p>Finally, we will dive into the discovery and exploration of REST services.</p>
<p>To sum up, here's what should be further implemented to turn the catalog data service into a full-fledged RESTful service:</p>
<p class="mce-root"/>
<ul>
<li>Working with arbitrary data</li>
<li>Working with Linked data in the real world</li>
<li>Paging and filtering</li>
<li>Caching</li>
<li>Discovery and exploration</li>
</ul>


            

            
        
    </div>



  
<div><h1 class="header-title">Working with arbitrary data</h1>
                
            
            
                
<p>MongoDB utilizes BSON (Binary JSON) as the primary data format. It is a binary format that stores key/value pairs in a single entity called <strong>document.</strong> For example, a sample JSON, <kbd>{"hello":"world"}</kbd>, becomes <kbd>\x16\x00\x00\x00\x02hello\x00\x06\x00\x00\x00world\x00\x00</kbd> when encoded in BSON.</p>
<p>BSON stores data rather than literals. For instance, if an image is to be part of the document, it will not have to be converted to a base64-encoded string; instead, it will be directly stored as binary data, unlike plain JSON, which will usually represent such data as base64-encoded bytes, but that is obviously not the most efficient way.</p>
<p>Mongoose schemas enable storing binary content in the BSON format via the schema type—<strong>buffer</strong>. It stores binary content (image, ZIP archive, and so on) up to 16 MB. The reason behind the relatively small storage capacity is to prevent excessive usage of memory and bandwidth during transmission.</p>
<p>The <strong>GridFS</strong> specification addresses this limitation of BSON and enables you to work with data larger than 16 MB. GridFS divides data into chunks stored as separate document entries. Each chunk, by default, has a size of up to 255 KB. When data is requested from the data store, the GridFS driver retrieves all the required chunks and returns them in an assembled order, as if they had never been divided. Not only does this mechanism allow storage of data larger than 16 MB, it also enables consumers to retrieve data in portions so that it doesn't have to be loaded completely into the memory. Thus, the specification implicitly enables streaming support.</p>
<p>GridFS actually offers more—it supports storing metadata for the given binary data, for example, its format, a filename, size, and so on. The metadata is stored in a separate file and is available for more complex queries. There is a very usable Node.js module called <kbd>gridfs-stream</kbd>. It enables easy streaming of data in and out of MongoDB, as on all other modules it is installed as an <kbd>npm</kbd> package. So, let's install it globally and see how it is used; we will also use the <kbd>-s</kbd> option to ensure that the dependencies in the project's <kbd>package.json</kbd> are updated:</p>
<pre>    <strong>npm install -g -s gridfs-stream</strong></pre>
<p>To create a <kbd>Grid</kbd> instance, you are required to have a connection opened to the database:</p>
<pre>const mongoose = require('mongoose')
const Grid = require('gridfs-stream');

mongoose.connect('mongodb://localhost/catalog');
var connection = mongoose.connection;
var gfs = Grid(connection.db, mongoose.mongo);   </pre>
<p>Reading and writing into the stream is done through the <kbd>createReadStream()</kbd> and <kbd>createWriteStream()</kbd> functions. Each piece of data streamed into the database must have an <kbd>ObjectId</kbd> attribute set. The <kbd>ObjectId</kbd> identifies binary data entry uniquely, just as it would have identified any other document in MongoDB; using this <kbd>ObjectId</kbd>, we can find or delete it from the MongoDB collection by this identifier.</p>
<p>Let's extend the catalog service with functions for fetching, adding, and deleting an image assigned to an item. For simplicity, the service will support a single image per item, so there will be a single function responsible for adding an image. It will overwrite an existing image each time it is invoked, so an appropriate name for it is <kbd>saveImage</kbd>:</p>
<pre>exports.saveImage = function(gfs, request, response) {<br/><br/>    var writeStream = gfs.createWriteStream({<br/>            filename : request.params.itemId,<br/>            mode : 'w'<br/>        });<br/><br/>        writeStream.on('error', function(error) {<br/>            response.send('500', 'Internal Server Error');<br/>            console.log(error);<br/>            return;<br/>        })<br/><br/>        writeStream.on('close', function() {<br/>            readImage(gfs, request, response);<br/>        });<br/><br/>    request.pipe(writeStream);<br/>}</pre>
<p>As you can see, all we need to do to flush the data in MongoDB is to create a GridFS write stream instance. It requires some options that provide the <kbd>ObjectId</kbd> of the MongoDB entry and some additional metadata, such as a title as well as the writing mode. Then, we simply call the pipe function of the request. Piping will result in flushing the data from the request to the write stream, and, in this way, it will be safely stored in MongoDB. Once stored, the <kbd>close</kbd><strong> </strong>event associated with the <kbd>writeStream</kbd> will occur, and this is when our function reads back whatever it has stored in the database and returns that image in the HTTP response.</p>
<p>Retrieving an image is done the other way around—a <kbd>readStream</kbd> is created with options, and the value of the <kbd>_id</kbd> parameter should be the <kbd>ObjectId</kbd> of the arbitrary data, optional file name, and read mode:</p>
<pre>function readImage(gfs, request, response) {<br/><br/>  var imageStream = gfs.createReadStream({<br/>      filename : request.params.itemId,<br/>      mode : 'r'<br/>  });<br/><br/>  imageStream.on('error', function(error) {<br/>    console.log(error);<br/>    response.send('404', 'Not found');<br/>    return;<br/>  });<br/>   <br/>  response.setHeader('Content-Type', 'image/jpeg');<br/>  imageStream.pipe(response);<br/>}</pre>
<p>Before piping the read stream to the response, the appropriate <kbd>Content-Type</kbd> header has to be set so that the arbitrary data can be presented to the client  with an appropriate image media type, <kbd>image/jpeg</kbd>, in our case.</p>
<p>Finally, we export from our module a function for fetching the image back from MongoDB. We will use that function to bind it to the express route that reads the image from the database:</p>
<pre>exports.getImage = function(gfs, itemId, response) {<br/>     readImage(gfs, itemId, response);<br/>};</pre>
<p>Deleting arbitrary data from MongoDB is also straightforward. You have to delete the entry from two internal MongoDB collections, the <kbd>fs.files</kbd>, where all the files are kept, and from the <kbd>fs.files.chunks</kbd>:</p>
<pre>exports.deleteImage = function(gfs, mongodb, itemId, response) {<br/>  console.log('Deleting image for itemId:' + itemId);<br/><br/>    var options = {<br/>            filename : itemId,<br/>    };<br/><br/>    var chunks = mongodb.collection('fs.files.chunks');<br/>    chunks.remove(options, function (error, image) {<br/>        if (error) {<br/>            console.log(error);<br/>            response.send('500', 'Internal Server Error');<br/>            return;<br/>       } else {<br/>           console.log('Successfully deleted image for item: ' + itemId);<br/>       }<br/>    });<br/><br/>    var files = mongodb.collection('fs.files');<br/>    files.remove(options, function (error, image) {<br/>        if (error) {<br/>            console.log(error);<br/>            response.send('500', 'Internal Server Error');<br/>            return;<br/>        }<br/><br/>        if (image === null) {<br/>            response.send('404', 'Not found');<br/>            return;<br/>        } else {<br/>           console.log('Successfully deleted image for primary item: ' + itemId);<br/>           response.json({'deleted': true});<br/>        }<br/>    });<br/>}
 </pre>
<p>Let's bind the new functionality to the appropriate item route and test it:</p>
<pre>router.get('/v2/item/:itemId/image',<br/>  function(request, response){<br/>    var gfs = Grid(model.connection.db, mongoose.mongo);<br/>    catalogV2.getImage(gfs, request, response);<br/>});

router.get('/item/:itemId/image',<br/>  function(request, response){<br/>    var gfs = Grid(model.connection.db, mongoose.mongo);<br/>    catalogV2.getImage(gfs, request, response);<br/>});<br/><br/>router.post('/v2/item/:itemId/image',<br/>  function(request, response){<br/>    var gfs = Grid(model.connection.db, mongoose.mongo);<br/>    catalogV2.saveImage(gfs, request, response);<br/>});<br/><br/>router.post('/item/:itemId/image',<br/>  function(request, response){<br/>    var gfs = Grid(model.connection.db, mongoose.mongo);<br/>    catalogV2.saveImage(gfs, request.params.itemId, response);<br/>});<br/><br/>router.put('/v2/item/:itemId/image',<br/>  function(request, response){<br/>    var gfs = Grid(model.connection.db, mongoose.mongo);<br/>    catalogV2.saveImage (gfs, request.params.itemId, response);<br/>});<br/><br/>router.put('/item/:itemId/image',<br/>function(request, response){<br/>  var gfs = Grid(model.connection.db, mongoose.mongo);<br/>  catalogV2.saveImage(gfs, request.params.itemId, response);<br/>});<br/><br/>router.delete('/v2/item/:itemId/image',<br/>function(request, response){<br/>  var gfs = Grid(model.connection.db, mongoose.mongo);<br/>  catalogV2.deleteImage(gfs, model.connection,<br/>  request.params.itemId, response);<br/>});<br/><br/>router.delete('/item/:itemId/image',<br/>function(request, response){<br/>  var gfs = Grid(model.connection.db, mongoose.mongo);<br/>  catalogV2.deleteImage(gfs, model.connection,  request.params.itemId, response);<br/>});</pre>
<p>Since, at the time of writing, Version 2 is the latest version of our API, any new functionality exposed by it should be available at both locations: <kbd>/catalog</kbd> and <kbd>/v2/catalog</kbd>.</p>
<p>Let's start Postman and post an image to an existing item, assuming that we have an item with ID 14 <kbd>/catalog/v2/item/14/image</kbd>:</p>
<div><img src="img/2cc9c935-9db2-4a52-949b-f7c35b277648.png" width="1527" height="877"/></div>
<p>Post request assigning an image to an item using Postman. This is a screenshot for Postman. The individual settings are not important here. The purpose of the image is just to show how the window looks.</p>
<p>After the request is processed, the binary data is stored in the grid datastore and the image is returned in the response.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Linking</h1>
                
            
            
                
<p class="mce-root">In the Linked data section of the previous chapter, we defined that if an item in the catalog has an image assigned to it, this will be indicated with an HTTP header named Image-URL.</p>
<p class="mce-root">Let's modify the <kbd>findItemById</kbd> function in the V2 of the catalog. We will use the GridFS's existing function to check whether there is an image bound to the selected item; in case there is an image assigned to the item, its URL will be available to the response with the Image-Url header:</p>
<pre>exports.findItemById = function (gfs, request, response) {<br/>    CatalogItem.findOne({itemId: request.params.itemId}, function(error, result) {<br/>        if (error) {<br/>            console.error(error);<br/>            response.writeHead(500,    contentTypePlainText);<br/>            return;<br/>        } else {<br/>            if (!result) {<br/>                if (response != null) {<br/>                    response.writeHead(404, contentTypePlainText);<br/>                    response.end('Not Found');<br/>                }<br/>                return;<br/>            }<br/><br/>            var options = {<br/>                filename : result.itemId,<br/>            };<br/>            gfs.exist(options, function(error, found) {<br/>                if (found) {<br/>                    response.setHeader('Content-Type', 'application/json');<br/>                    var imageUrl = request.protocol + '://' + request.get('host') + request.baseUrl + request.path + '/image';<br/>                    response.setHeader('Image-Url', imageUrl);<br/>                    response.send(result);<br/>                } else {<br/>                    response.json(result);<br/>                }<br/>            });<br/>        }<br/>    });<br/>}</pre>
<p>So far, we linked an item to its image; however, that leaves our data partially linked, as there is a link from an item to its image but not the other way around. Let's change that and supply a header Item-Url to the image response by modifying the <kbd>readImage</kbd> function:</p>
<pre>function readImage(gfs, request, response) {<br/><br/>  var imageStream = gfs.createReadStream({<br/>      filename : request.params.itemId,<br/>      mode : 'r'<br/>  });<br/><br/>  imageStream.on('error', function(error) {<br/>    console.log(error);<br/>    response.send('404', 'Not found');<br/>    return;<br/>  });<br/><br/>  var itemImageUrl = request.protocol + '://' + request.get('host') + request.baseUrl+ request.path;<br/>  var itemUrl = itemImageUrl.substring(0, itemImageUrl.indexOf('/image'));<br/>  response.setHeader('Content-Type', 'image/jpeg');<br/>  response.setHeader('Item-Url', itemUrl);<br/><br/>  imageStream.pipe(response);<br/>}</pre>
<p>Now requesting the item at <kbd>http://localhost:3000/catalog/v2/item/3/</kbd> will return the item encoded in the JSON format:</p>
<pre>GET http://localhost:3000/catalog/v2/item/3/image HTTP/1.1 <br/>Accept-Encoding: gzip,deflate <br/>Host: localhost:3000 <br/><br/>HTTP/1.1 200 OK <br/>X-Powered-By: Express <br/>Content-Type: application/json; charset=utf-8 <br/>Image-Url: http://localhost:3000/catalog/v2/item/3/image <br/>Content-Length: 137 <br/>Date: Tue, 03 Apr 2018 19:47:41 GMT <br/>Connection: keep-alive <br/><br/>{<br/>   "_id": "5ab827f65d61450e40d7d984",<br/>   "itemId": "3",<br/>   "itemName": "Sports Watch 11",<br/>   "price": 99,<br/>   "currency": "USD",<br/>   "__v": 0,<br/>   "categories": ["Watches"]<br/>}</pre>
<p>Looking into the response headers, we find the <kbd>Image-Url</kbd> header its value, <kbd>http://localhost:3000/catalog/v2/item/3/image</kbd> provides the URL of the image linked to the item.</p>
<p>Requesting that image results in the following:</p>
<pre>GET http://localhost:3000/catalog/v2/item/3/image HTTP/1.1 <br/>Host: localhost:3000 <br/>Connection: Keep-Alive <br/><br/>HTTP/1.1 200 OK <br/>X-Powered-By: Express <br/>Content-Type: image/jpeg <br/>Item-Url: http://localhost:3000/catalog/v2/item/3 <br/>Connection: keep-alive <br/>Transfer-Encoding: chunked <br/><br/>&lt;BINARY DATA&gt;</pre>
<p>This time, the response provides the payload of the image linked to the item and a special header <strong>Item-Url</strong>. Its value—<kbd>http://localhost:3000/catalog/v2/item/3</kbd>—is the address where the item resource is available. Now if the item image appears, for instance, in image search results, the URL of the item linked with the image will also be part of the result. In this way, we linked the two data semantically without modifying or compromising their payload.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Implementing paging and filtering</h1>
                
            
            
                
<p>Once deployed to the web, each service becomes available to an enormous number of consumers. They will not only use it to get data but also to insert new data. At some point of time, this will inevitably lead to a large amount of data being available in the database. To keep the service user-friendly and maintain a reasonable response time, we need to take care of providing big data in reasonable portions, assuring that it does not need to return a few hundred thousand items when the <kbd>/catalog</kbd> URI is requested.</p>
<p>Web data consumers are used to having various pagination and filtering capabilities. Earlier in this chapter, we implemented the <kbd>findIfindItemsByAttribute()</kbd> function, which enabled filtering by any of the attributes of an item Now, it's time to introduce pagination capabilities to enable navigation within the <kbd>resultset</kbd> with the help of a URI parameter.</p>
<p>The <kbd>mongoose.js</kbd> models can make use of different plugin modules to provide additional functionality on top of them. Such a plugin module is <kbd>mongoose-paginate</kbd>. The Express framework also provides a piece of pagination middleware named <kbd>express-paginate</kbd>. It provides out-of-the-box linking and navigation with Mongoose's result pages:</p>
<ol>
<li>Before starting to develop the pagination mechanism, we should install these two useful modules:</li>
</ol>
<pre style="padding-left: 60px"><strong>npm install -g -s express-paginate</strong>
<strong>npm install -g -s mongoose-paginate</strong></pre>
<ol start="2">
<li>The next step will to be to create instances of the  <kbd>express-paginate</kbd> middleware in our application:</li>
</ol>
<pre style="padding-left: 60px">      
expressPaginate = require('express-paginate'); </pre>
<ol start="3">
<li>Initialize the pagination middleware in the application by calling its <kbd>middleware()</kbd> function. Its parameters specify a default limit and a maximum limit of results per page:</li>
</ol>
<pre style="padding-left: 60px">app.use(expressPaginate.middleware(limit, maxLimit); </pre>
<ol start="4">
<li>Then, provide the <kbd>mongoose-pagination</kbd> instance as a plugin to the <kbd>CatalogItem</kbd> schema before creating a model. Here's how the <kbd>item.js</kbd> module will export that along with the model:</li>
</ol>
<pre style="padding-left: 60px">var mongoose = require('mongoose');<br/>var mongoosePaginate = require('mongoose-paginate');<br/>var Schema = mongoose.Schema;<br/><br/>mongoose.connect('mongodb://localhost/catalog');<br/><br/>var itemSchema = new Schema ({<br/>    "itemId" : {type: String, index: {unique: true}},<br/>    "itemName": String,<br/>    "price": Number,<br/>    "currency" : String,<br/>    "categories": [String]<br/>});<br/>console.log('paginate');<br/>itemSchema.plugin(mongoosePaginate);<br/>var CatalogItem = mongoose.model('Item', itemSchema);<br/><br/>module.exports = {CatalogItem : CatalogItem, connection : mongoose.connection};</pre>
<ol start="5">
<li>Finally, call the <kbd>paginate()</kbd> function of the model to fetch the requested entries in a paginated manner:</li>
</ol>
<pre style="padding-left: 60px"><br/>CatalogItem.paginate({}, {page:request.query.page, limit:request.query.limit},<br/>    function (error, result){<br/>        if(error) {<br/>            console.log(error);<br/>            response.writeHead('500',<br/>               {'Content-Type' : 'text/plain'});<br/>            response.end('Internal Server Error');<br/>         } else {<br/>           response.json(result);<br/>         }<br/>});</pre>
<p class="mce-root">The first parameter is the filter that Mongoose should use for its query. The second parameter is an object specifying which page is requested and the entries per page. The third parameter is a callback-handler function, providing the result and any available error information via its parameters:</p>
<ul>
<li><kbd>error</kbd>: This specifies whether the query was executed successfully</li>
<li><kbd>result</kbd>: This is the retrieved data from the database</li>
</ul>
<p>The <kbd>express-paginate</kbd> middleware enables seamless integration of the <kbd>mongoose-paginate</kbd> module in the web environment by enriching the <kbd>request</kbd> and <kbd>response</kbd> objects of an Express handler function.</p>
<p>The <kbd>request</kbd> objects get two new attributes: <kbd>query.limit</kbd>, which tells the middleware the number of entries on the page, and <kbd>query.page</kbd>, which specifies the requested page. Note that the middleware will ignore values of <kbd>query.limit</kbd> that are larger than the <kbd>maxLimit</kbd> value specified at the middleware's initialization. This prevents the consumer from overriding the maximum limit and gives you total control over your application.</p>
<p>Here's the implementation of the <kbd>paginate</kbd> function in the second version of the catalog module:</p>
<pre>exports.paginate = function(model, request, response) {<br/>    var pageSize = request.query.limit;<br/>    var page = request.query.page;<br/>    if (pageSize === undefined) {<br/>        pageSize = 100;<br/>    }<br/>    if (page === undefined) {<br/>        page = 1;<br/>    }<br/><br/>    model.paginate({}, {page:page, limit:pageSize},<br/>            function (error, result){<br/>                if(error) {<br/>                    console.log(error);<br/>                    response.writeHead('500',<br/>                        {'Content-Type' : 'text/plain'});<br/>                    response.end('Internal Server Error');<br/>                }<br/>                else {<br/>                    response.json(result);<br/>                }<br/>            });<br/>}</pre>
<p>The following is the response from querying a dataset containing 11 items with a limit of five items per page:</p>
<pre>{<br/>  "docs": [<br/>    {<br/>      "_id": "5a4c004b0eed73835833cc9a",<br/>      "itemId": "1",<br/>      "itemName": "Sports Watch 1",<br/>      "price": 100,<br/>      "currency": "EUR",<br/>      "__v": 0,<br/>      "categories": [<br/>        "Watches",<br/>        "Sports Watches"<br/>      ]<br/>    },<br/>    {<br/>      "_id": "5a4c0b7aad0ebbce584593ee",<br/>      "itemId": "2",<br/>      "itemName": "Sports Watch 2",<br/>      "price": 100,<br/>      "currency": "USD",<br/>      "__v": 0,<br/>      "categories": [<br/>        "Sports Watches"<br/>      ]<br/>    },<br/>    {<br/>      "_id": "5a64d7ecfa1b585142008017",<br/>      "itemId": "3",<br/>      "itemName": "Sports Watch 3",<br/>      "price": 100,<br/>      "currency": "USD",<br/>      "__v": 0,<br/>      "categories": [<br/>        "Watches",<br/>        "Sports Watches"<br/>      ]<br/>    },<br/>    {<br/>      "_id": "5a64d9a59f4dc4e34329b80f",<br/>      "itemId": "8",<br/>      "itemName": "Sports Watch 4",<br/>      "price": 100,<br/>      "currency": "EUR",<br/>      "__v": 0,<br/>      "categories": [<br/>        "Watches",<br/>        "Sports Watches"<br/>      ]<br/>    },<br/>    {<br/>      "_id": "5a64da377d25d96e44c9c273",<br/>      "itemId": "9",<br/>      "itemName": "Sports Watch 5",<br/>      "price": 100,<br/>      "currency": "USD",<br/>      "__v": 0,<br/>      "categories": [<br/>        "Watches",<br/>        "Sports Watches"<br/>      ]<br/>    }<br/>  ],<br/>  "total": 11,<br/>  "limit": "5",<br/>  "page": "1",<br/>  "pages": 3<br/>}</pre>
<p>The <kbd>docs</kbd> attribute contains all the items that are part of the results. Its size is the same as the selected limit value. The <kbd>pages</kbd> attribute provides the total number of pages; in the example here, its value is 3, as 11 items are accommodated in three pages, each containing five items. The <kbd>Total</kbd> attribute gives us the total number of items.</p>
<p>The final step to enable pagination is to modify the <kbd>/v2/</kbd> route to start making use of the newly created function:</p>
<pre>  router.get('/v2/', function(request, response) {<br/>    var getParams = url.parse(request.url, true).query;<br/>    if (getParams['page'] !=null) {<br/>      catalogV2.paginate(model.CatalogItem, request, response);<br/>    } else {<br/>      var key = Object.keys(getParams)[0];<br/>      var value = getParams[key];<br/>      catalogV2.findItemsByAttribute(key, value, response);<br/>    }<br/>});</pre>
<p>We will use the HTTP <kbd>302 Found</kbd> status for the default route, <kbd>/catalog</kbd>. In this way, all incoming requests will be redirected to <kbd>/v2/</kbd>:</p>
<pre>router.get('/', function(request, response) {<br/>  console.log('Redirecting to v2');<br/>  response.writeHead(302, {'Location' : '/catalog/v2/'});<br/>  response.end('Version 2 is is available at /catalog/v2/: ');<br/>});</pre>
<p>Using an appropriate status code for redirection here is vital to the life cycle of any RESTful web service. Returning <kbd>302 Found</kbd>, followed by a redirection, ensures that the consumer of the API will always have its latest version available at that location. Furthermore, it is also a good practice from the development point of view to use redirection instead of code duplication here.</p>
<p>When you are between two versions, you should always consider using the HTTP <kbd>301 Moved Permanently</kbd> status to show where the previous version has been moved and the HTTP <kbd>302 Found</kbd> status to show the actual URI of the current version.</p>
<p>Now, getting back to pagination, as the requested page and the limit number are provided as <kbd>GET</kbd> parameters and we don't want to mix that up with the filtering capabilities, there is an explicit check for them. Pagination will be used only when either the page or the limit <kbd>GET</kbd> parameters, are available in the request. Otherwise, searching will be carried out.</p>
<p>Initially, we set the maximum limit of 100 results and a default limit of 10, so, before trying the new pagination functionality, ensure that you insert more items than the default limit into the database. This will make the test results more obvious.</p>
<p>Now, let's give it a try. Requesting <kbd>/catalog?limit=3</kbd> will result in returning a list containing only two items, as shown:</p>
<div><img src="img/3a92193f-e58d-4bfa-9f7f-f8378b41de4e.png" style="width:53.67em;height:30.33em;" width="1871" height="1056"/></div>
<p>Pagination enabled results. This is a screenshot for Postman. The individual settings are not important here. The purpose of the image is just to show how the window looks.</p>
<p>As you can see from the example, the total number of pages is four. The total number of items is stored in the database 11. Since we didn't specify a page parameter in the request, the pagination implicitly returned the first page. To navigate to the next page, simply add <kbd>&amp;page=2</kbd> to the URI.</p>
<p>Also, try changing the <kbd>limit</kbd> attribute, requesting <kbd>/catalog/v2?limit=4</kbd>. This will return the first four items, and the response will show that the total number of pages is three.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Caching</h1>
                
            
            
                
<p>When we discussed the REST principles defined by Roy Fielding, we mentioned that caching was a rather sensitive topic. In the end, our consumers will expect up-to-date results when executing a query. However, from a statistical point of view, data exposed in the web is more likely to be read rather than updated or deleted.</p>
<p>So, it is reasonable that some resources exposed by a public URL become a subject of millions of requests, considering taking off part of the load from the server to a cache. The HTTP protocol allows us to cache some responses for a given period of time. For instance, when multiple requests are received in a short period of time, querying for all items in the catalog of a given group, such as <kbd>/catalog/v2</kbd>, our service can utilize special HTTP headers that would force the HTTP server to cache the response for a defined time period. This would prevent redundant requests to the underlying database server.</p>
<p>Caching at the HTTP server level is achieved via special response headers. The HTTP server uses a <kbd>Cache-Control</kbd> header to specify how long a given response should be cached for. The period before the cache needs invalidation is set via its <kbd>max-age</kbd> attribute, and its value is provided in seconds. Of course, there is a nice Node.js module that provides a middleware function for caching, called <kbd>express-cache-control</kbd>.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Supplying the Cache-Control header in Express applications</h1>
                
            
            
                
<p>Let's install it with the NPM package manager; once again, we will install it globally and make use of the <kbd>-s</kbd> option, which will update the <kbd>package.json</kbd> file with the new <kbd>express-cache-control</kbd> dependency automatically:</p>
<pre>    <strong>npm install -g -s express-cache-control</strong></pre>
<p>Enabling caching with the <kbd>express-cache-control</kbd> middleware requires three straightforward steps:</p>
<ol>
<li>Get the module:</li>
</ol>
<pre>      CacheControl = require("express-cache-control") </pre>
<ol start="2">
<li>Create an instance of the <kbd>CacheControl</kbd> middleware:</li>
</ol>
<pre style="padding-left: 60px"> var cache = new CacheControl().middleware;</pre>
<ol start="3">
<li>To bind the middleware instance to the routes you want to enable caching for:</li>
</ol>
<pre style="padding-left: 60px">router.get('/v2/', cache('minutes', 1), function(request, response) {<br/>    var getParams = url.parse(request.url, true).query;<br/>    if (getParams['page'] !=null || getParams['limit'] != null) {<br/>      catalogV2.paginate(model.CatalogItem, request, response);<br/>    } else {<br/>      var key = Object.keys(getParams)[0];<br/>      var value = getParams[key];<br/>      catalogV2.findItemsByAttribute(key, value, response);<br/>    }<br/>});</pre>
<p>Usually, common URIs that provide many result entries should be the subject of caching, rather than URIs providing data for a concrete entry. In our application, only the <kbd>/catalog</kbd> URI will make use of caching. The <kbd>max-age</kbd> attribute must be selected according to the load of your application to minimize inaccurate responses.</p>
<p>Let's test our changes by requesting <kbd>/catalog/v2</kbd> in Postman:</p>
<div><img src="img/9a4c8d45-2367-4283-9aa8-47a2644b1af9.png" style="width:45.08em;height:25.92em;" width="1527" height="877"/></div>
<p>Cache-control header indicating that caching is enabled. This is a screenshot for Postman. The individual settings are not important here. The purpose of the image is just to show how the window looks.</p>
<p class="mce-root">As expected, the <kbd>express-cache-control</kbd> middleware has done its job—the <kbd>Cache-Control</kbd> header is now included in the response. The <kbd>must-revalidate</kbd> option ensures that the cache content is invalidated after the <kbd>max-age</kbd> interval expires. Now, if you make another request for a specific item, you will see that the response does not make use of the <kbd>express-cache-control</kbd> middleware, which is because it needs to be explicitly provided in each individual route. It will not be used in URIs deriving from one another.</p>
<p>Responses from <kbd>GET</kbd> requests against any route <kbd>/v1/</kbd> will not contain the <kbd>Cache-Control</kbd> header, as it is supported only in Version 2 of our API, and the <kbd>Cache-Control</kbd> middleware is used only in the main catalog routes: <kbd>/catalog/v2/</kbd> or <kbd>/catalog</kbd>.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Summary</h1>
                
            
            
                
<p>Congratulations! In this chapter, you succeeded in transforming a sample REST-enabled endpoint into a full-fledged RESTful web service that supports filtering for usability and paging for easy navigation. The service delivers both arbitrary and JSON data, and it is ready for high-load scenarios, as it enables caching in its critical parts. One thing that should draw your attention is the appropriate usage of the HTTP status codes when it comes to redirection between new and obsolete versions of any public API.</p>
<p>Implementing appropriate HTTP status is really important for the REST application, so we made use of rather exotic statuses, such as <kbd>301 Moved Permanently</kbd> and <kbd>302 Found</kbd>. </p>


            

            
        
    </div>



  </body></html>