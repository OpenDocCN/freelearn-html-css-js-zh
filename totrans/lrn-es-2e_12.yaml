- en: Shared Memory and Atomics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共享内存和原子操作
- en: Let's go to low-level memory stuff! This chapter is going to be a bit advanced,
    but interesting. I'll try to make it as simple and understandable as possible.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看低级内存内容！这一章将会有些高级，但很有趣。我会尽量让它尽可能简单易懂。
- en: With that out of the way, let's get to what we've FINALLY in JavaScript! Low-level
    memory access, multi-threading, atomics, shared memory, and all that cool and
    powerful stuff. But, as someone said, with great power comes great responsibility.
    Let's go!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些准备工作完成之后，让我们来看看JavaScript中最终能实现的功能！低级内存访问、多线程、原子操作、共享内存以及所有那些酷炫强大的功能。但正如有人所说，权力越大，责任越大。让我们开始吧！
- en: 'We''ll cover the following things in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下内容：
- en: Basics of memory management in computers
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算机内存管理基础
- en: What is shared memory?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是共享内存？
- en: Using `SharedArrayBuffer`
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`SharedArrayBuffer`
- en: Introduction to parallel programming
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍并行编程
- en: Problems when multiple threads access one memory location
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多线程访问同一内存位置时可能出现的问题
- en: What are atomics?
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是原子操作？
- en: Performing atomic operations
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行原子操作
- en: Atomic APIs in JavaScript
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JavaScript中的原子API
- en: Using parallel programming the right way
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正确使用并行编程
- en: Basics of memory
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存基础
- en: We have to understand a little about how memory works in order to appreciate
    the significance of `SharedArrayBuffer` in JavaScript.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须稍微了解内存是如何工作的，才能理解`SharedArrayBuffer`在JavaScript中的重要性。
- en: Think of memory as a collection of a lot of drawers in a big almirah kind of
    structure, where you can open a drawer and put something in it. Every drawer has
    its own maximum capacity.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 将内存想象成一个大衣柜里的一堆抽屉，你可以打开一个抽屉并放些东西进去。每个抽屉都有自己的最大容量。
- en: Every drawer also has a sticker associated with it, which has a unique number
    on it that helps you to note down which drawer has data and which doesn't. When
    the time comes to access that data, you are supplied with the numbered drawer
    and you can take out data accordingly.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 每个抽屉还贴有一个标签，上面有一个唯一的数字，这有助于你记录哪个抽屉有数据，哪个没有。当需要访问这些数据时，你会得到一个编号的抽屉，然后可以相应地取出数据。
- en: 'Now, let us start by understanding the basics of memory storage. Suppose I
    want to store a number, say, 100, in memory. First of all, we need to convert
    this number into binary, because that is what computers understand, and it is
    easy for them to store:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们先了解内存存储的基础。假设我想在内存中存储一个数字，比如100。首先，我们需要将这个数字转换为二进制，因为这是计算机理解的方式，对它们来说存储起来也很容易：
- en: '![](img/64948eed-49b0-4261-805f-6f030bb34c48.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/64948eed-49b0-4261-805f-6f030bb34c48.png)'
- en: The preceding figure is a binary representation of the number 100 and is how
    it is stored in memory.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图示是数字100的二进制表示，也是它在内存中的存储方式。
- en: Easy! In a similar manner, we can store more complicated data, such as letters,
    by converting them to numbers (called ASCII values), and then storing those numbers
    directly, instead of letters. Similarly, an image (assumed to be black and white)
    can be stored by, say, storing the brightness levels of each pixel floating point
    number.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 简单！以类似的方式，我们可以存储更复杂的数据，例如字母，通过将它们转换为数字（称为ASCII值），然后直接存储这些数字，而不是字母。同样，一个图像（假设是黑白图像）可以通过存储每个像素的亮度级别浮点数来存储。
- en: Abstraction of memory management
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存管理的抽象
- en: Memory management means that you're actually interacting directly with the hardware
    to store/update/free blocks of memory yourself from your code. Most higher level
    programming languages take away the memory management from the developers.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 内存管理意味着你实际上是在直接与硬件交互，从你的代码中自己存储/更新/释放内存块。大多数高级编程语言都从开发者那里拿走了内存管理。
- en: This is because managing memory is hard. It really is! In complicated programs,
    humans are bound to make mistakes and cause a ton of problems, not limited to
    memory leaks (which is the easiest mistake someone can make).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为管理内存很困难。真的！在复杂的程序中，人类难免会犯错误，造成大量问题，不仅限于内存泄漏（这是人们最容易犯的错误）。
- en: Of course, this abstraction comes at a performance cost. But compared with the
    security, readability, and convenience advantages, this is a fair deal.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这种抽象化会带来性能上的代价。但与安全性、可读性和便利性的优势相比，这是一个公平的交易。
- en: JavaScript also manages memory automatically. The JavaScript engine is responsible
    for registering memory whenever a new variable is created, freeing the memory
    when it is no longer needed, and so on. Imagine managing memory for a **closure**
    program yourself! Even if the program is a bit complicated, it is very easy to
    lose track of which variables to keep in memory and which ones to discard, even
    after function execution ends. JavaScript to the rescue!
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: JavaScript也会自动管理内存。JavaScript引擎负责在创建新变量时注册内存，在不再需要时释放内存，等等。想象一下自己管理一个**闭包**程序的内存！即使程序稍微复杂一些，也很容易在函数执行结束后弄不清楚哪些变量需要保留在内存中，哪些可以丢弃。JavaScript来拯救！
- en: Garbage collection
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 垃圾回收
- en: JavaScript is a garbage collected language. What that means is that a JavaScript
    engine will occasionally fire something called a garbage collector, which looks
    for unused and inaccessible references in memory for the program and clears them,
    making the memory available for storing other data.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: JavaScript是一种垃圾回收语言。这意味着JavaScript引擎会偶尔触发一个叫做垃圾回收器的东西，它会查找程序中内存中的未使用和不可访问的引用，并将它们清除，使内存可用于存储其他数据。
- en: Garbage collectors make life a lot easier, but add a bit of overhead in performance-critical
    applications. Say you are coding a 3D game where you want very high **Frames Per
    Second** (**FPS**) on not so good hardware.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 垃圾回收器让生活变得容易多了，但在性能关键的应用程序中会稍微增加一些开销。比如说你正在编写一个3D游戏，你希望在不太好的硬件上实现非常高的**每秒帧数**（**FPS**）。
- en: You might see that the results are extremely good for a game coded in C/C++,
    as compared to a garbage collected language like Java. This is because when you're
    playing the game, garbage collectors might fire off even when it is unnecessary,
    which wastes some resources that could've been used by the rendering thread.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会发现，与垃圾回收的语言如Java相比，用C/C++编写的游戏效果非常好。这是因为当你玩游戏时，垃圾回收器可能会在不必要的时候启动，这浪费了一些本可以由渲染线程使用的资源。
- en: Manually managing memory
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 手动管理内存
- en: Languages such as C/C++ are on their own in terms of memory management. In such
    languages, you have to allocate the memory and de-allocate it all by yourself.
    This is the reason why C/C++ are so fast--because they're very close to the hardware,
    and almost no abstraction is there. But that makes it painful to write complex
    applications because things can slip out of hand real quick.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在内存管理方面，像C/C++这样的语言是独立的。在这些语言中，你必须自己分配内存和释放内存。这也是为什么C/C++如此快的原因——因为它们非常接近硬件，几乎没有抽象。但这也使得编写复杂的应用程序变得痛苦，因为事情可能会迅速失控。
- en: There is something called as **WebAssembly**, which is the compiled form of
    a JavaScript alternative on the web. C/C++ code can be compiled down to WebAssembly,
    which is in some cases 100-200% faster than native JavaScript!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种叫做**WebAssembly**的东西，它是网络中JavaScript替代方案的编译形式。C/C++代码可以编译成WebAssembly，在某些情况下比原生JavaScript快100-200%！
- en: WebAssembly is going to be the future of the web because of its speed and multiple
    types of language support. However, it'll again require you to manage memory yourself,
    as, at the end of the day, C/C++ is what you'll need to write your code in.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: WebAssembly由于其速度和多种语言支持，将成为网络的未来。然而，它又要求你自行管理内存，因为最终，你需要用C/C++来编写代码。
- en: Manually managing memory is hard. It is hard to know when to clear off the part
    of memory you don't require in bigger programs. Do it early, and you break the
    application. Do it late, and you are out of memory. This is the reason abstraction
    is good in a lot of cases.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 手动管理内存很困难。在大型程序中，很难知道何时清除不再需要的内存部分。过早清除，应用程序会崩溃。过晚清除，你会耗尽内存。这就是为什么在很多情况下抽象是好的。
- en: What is shared memory?
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是共享内存？
- en: Let's suppose we are working on a real-time performance-critical application,
    which is the reason we're so concerned about this interesting topic. Suppose I
    have two web workers running in the background, and I want to share some data
    from one worker to another. Web workers run independently on separate OS-level
    threads and have no idea about each other.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在开发一个实时性能关键的应用程序，这就是我们为什么如此关注这个有趣话题的原因。假设我在后台运行了两个Web Workers，并且我想从一个Worker共享一些数据到另一个Worker。Web
    Workers在单独的操作系统级别线程上独立运行，彼此之间没有任何了解。
- en: One way is to make use of `postMessage` to transfer messages between web workers,
    as we saw in the last chapter. However, this is slow.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是通过`postMessage`在Web Workers之间传输消息，正如我们在上一章中看到的。然而，这很慢。
- en: Another way is to transfer the object to another worker completely; however,
    if you remember, that makes the object which is transferred inaccessible from
    the worker which sent it.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方式是将对象完全传输到另一个工作者；然而，如果你记得，那样会使传输的对象对发送它的工作者不可访问。
- en: The solution to this problem is `SharedArrayBuffer`.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的解决方案是 `SharedArrayBuffer`。
- en: Introduction to SharedArrayBuffer
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共享 `ArrayBuffer` 介绍
- en: The `SharedArrayBuffer` is the way to create a memory store which is accessible
    to all workers simultaneously. Now, if you've been reading keenly, you will have
    understood something mischievous that can happen once something like a shared
    memory store is allowed to exist.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`SharedArrayBuffer` 是创建一个所有工作者可以同时访问的内存存储的方式。现在，如果你一直在仔细阅读，你将已经理解到一旦允许存在类似共享内存存储的东西，可能会发生一些淘气的事情。'
- en: If you remember, the only reason workers didn't have direct access to `DOM`
    was because the DOM API is not thread-safe, and could cause problems like deadlocks
    and race conditions. And if you were able to judge that the same thing might happen
    here, you're right! But that's a topic for a later section (*The race condition*).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你记得，工作者没有直接访问 `DOM` 的唯一原因是因为 DOM API 不是线程安全的，可能会导致死锁和竞态条件等问题。如果你能判断出这里可能也会发生同样的事情，你是对的！但这将是后续章节（*竞态条件*）的主题。
- en: Let's get back to `SharedArrayBuffer`. So what's different from `ArrayBuffer`?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到 `SharedArrayBuffer`。那么它与 `ArrayBuffer` 有什么不同？
- en: Well, `SharedArrayBuffer` is pretty much the `ArrayBuffer` which is available
    to a lot of scripts. You just have to create `SharedArrayBuffer` in one place
    and use `postMessage` to post it to other workers (and not transfer it!).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，`SharedArrayBuffer` 几乎就是许多脚本可用的 `ArrayBuffer`。你只需要在一个地方创建 `SharedArrayBuffer`，然后使用
    `postMessage` 将其发送到其他工作者（而不是传输！）
- en: 'You should not transfer it because you''ll then lose ownership of the `SharedArrayBuffer`.
    When you post it, only the reference of the buffer is automatically passed and
    becomes available to all the other scripts:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你不应该传输它，因为那样你就会失去对 `SharedArrayBuffer` 的所有权。当你发送它时，只有缓冲区的引用会自动传递并可供所有其他脚本使用：
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once you do that, all the workers will be able to access, read, and write to
    `SharedArrayBuffer`. Take a look at the representation as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你这样做，所有的工作者都将能够访问、读取和写入 `SharedArrayBuffer`。请看以下表示：
- en: '![](img/b91c486c-0f13-4cc3-86c3-dc675edf6464.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b91c486c-0f13-4cc3-86c3-dc675edf6464.png)'
- en: This is a rough representation of how you might imagine `SharedArrayBuffer`
    is connected to the memory under the hood. Let's assume each thread is spawned
    on a different CPU, for now.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种粗略的表示，你可以想象 `SharedArrayBuffer` 如何与底下的内存连接。现在，让我们假设每个线程都在不同的 CPU 上生成。
- en: Understanding parallel programming
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解并行编程
- en: Parallel programming, as the name suggests, is just a program running in such
    a way that instances of that program are running simultaneously multiple times.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 并行编程，正如其名所示，就是以这种方式运行的一个程序，该程序的实例会同时多次运行。
- en: Concurrent programming, on the other hand, is very similar to parallel programming,
    but with the difference that tasks never happen together.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，并发编程与并行编程非常相似，但不同之处在于任务永远不会同时发生。
- en: Parallel versus concurrent programming
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行与并发编程的区别
- en: To understand the difference between parallel and concurrent programming, let
    us consider an example.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解并行编程和并发编程之间的区别，让我们考虑一个例子。
- en: Suppose there's a competition to eat candies put on two plates. Plates are at
    a distance of five meters from each other. Let's say you're the only player for
    now, and the constraint is that you have to keep the number of differences in
    candies on both plates to less than two.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有一个比赛，比赛内容是吃放在两个盘子上的糖果。盘子之间相距五米。现在，假设你是唯一的参赛者，约束条件是你必须保持两个盘子上的糖果数量差异小于两个。
- en: What will you do here? You have to eat from plate one, run five meters to plate
    two, eat from plate two, run five meters again to plate one, and so on.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 你在这里会做什么？你必须从第一个盘子开始吃，跑到五米外的第二个盘子，从第二个盘子吃，然后再跑五米回到第一个盘子，以此类推。
- en: Now, let's assume you have got a friend. Now, both of you can choose a plate
    and start eating your own candies.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设你有一个朋友。现在，你们两个人都可以选择一个盘子并开始吃自己的糖果。
- en: Try to relate it to concurrent programming and parallel programming, respectively.
    In the first example, you are the CPU's core, which is running here and there,
    again and again, between two threads (plates). You are running fast, but, no matter
    how hard you try, you cannot eat from both plates at the same time due to your
    physical limits. Similarly, the CPU in concurrent programming is doing both of
    the tasks, but instead of doing them simultaneously, it is doing both in chunks.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试将其与并发编程和并行编程分别联系起来。在第一个例子中，你是CPU的核心，在这里到处运行，一次又一次，在两个线程（盘子）之间。你跑得很快，但由于你的物理限制，无论你多么努力，你都无法同时从两个盘子中取食。同样，在并发编程中，CPU执行这两个任务，但它不是同时执行，而是分块执行。
- en: In the next example, for parallel programming, your friend acts like another
    CPU, which is handling the other thread completely. This way, each of you only
    have to execute your own thread. This is parallelism.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个例子中，对于并行编程，你的朋友就像另一个CPU，完全处理另一个线程。这样，你们每个人只需要执行自己的线程。这就是并行性。
- en: If that makes sense, then let us get into parallel programming, the thing which
    web workers give us, and how to make use of shared memory with parallel programming
    to actually make things faster and not slow them down (because that happens a
    lot of times, when you do it incorrectly).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这说得通，那么让我们进入并行编程，这是Web Workers给我们带来的东西，以及如何利用并行编程中的共享内存来真正加快速度而不是减慢速度（因为当你做错的时候，这种情况经常发生）。
- en: Myth-busting--Parallel computation is always faster
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 破除迷思——并行计算总是更快
- en: It seems so intuitive to say that parallel computation should always be faster
    than computing on a single thread. Like spawning two threads should, intuitively,
    almost halve the computation time. Not only is this numerically wrong, but parallel
    computing creates garbage results if not done properly.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 似乎很直观地说，并行计算应该总是比单线程计算更快。就像 spawning two threads 应该，直观上，几乎可以减半计算时间。这不仅从数字上是错误的，而且如果做得不正确，并行计算会产生垃圾结果。
- en: 'To understand this, consider a man who is given a task to transfer a pile of
    blocks from one place to another:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解这一点，可以考虑一个被分配任务将一堆积木从一个地方转移到另一个地方的人：
- en: '![](img/637443e1-2bc6-427d-a689-57b7177e6cd1.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/637443e1-2bc6-427d-a689-57b7177e6cd1.png)'
- en: He does this work at some speed. Putting another man with him might sound like
    doubling the speed of the work, but the two might actually crash into each other
    on their way and make things slower instead of faster.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 他以某种速度完成这项工作。带上另一个人可能听起来像是加倍工作的速度，但这两个人实际上可能在路上撞到一起，反而使事情变得更慢而不是更快。
- en: This actually happens a lot of times when parallelism is implemented incorrectly,
    as we shall see now.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 当并行性实现不正确时，这种情况实际上经常发生，我们现在就会看到。
- en: Let's count one billion!
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 让我们数到十亿！
- en: To verify that parallel computing, if set up wrongly, is actually garbage, let
    us count to one billion using a single-threaded and multi-threaded environment
    in JavaScript.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证如果设置不当，并行计算实际上就是垃圾，让我们用JavaScript的单线程和多线程环境数到十亿。
- en: 'Let us first try single-threaded counting:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先尝试单线程计数：
- en: '[PRE1]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'On my MacBook Air, it takes *∼2606* milliseconds for this program to run. That
    is roughly *2.6* seconds:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的MacBook Air上，这个程序运行需要 *∼2606* 毫秒。这大约是 *2.6* 秒：
- en: '![](img/8229befe-f419-425d-9598-42992ac49e2d.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8229befe-f419-425d-9598-42992ac49e2d.png)'
- en: 'Let us try to split the code among two workers now, and see what happens:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们尝试将代码分配给两个工人，看看会发生什么：
- en: '[PRE2]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Alright! So what the heck is going on here? The following is an explanation:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧！那么这里到底发生了什么？以下是一个解释：
- en: We created a `SharedArrayBuffer` in order to create a memory storage area which
    can be accessed simultaneously by both of the spawned web workers.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建了一个 `SharedArrayBuffer`，以便创建一个可以被两个生成的Web工人同时访问的内存存储区域。
- en: The size of `SharedArrayBuffer` is `4` because, to add numbers to the integer
    array, we'll cast it to `Uint32Array`, which has a size in multiples of `4`.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`SharedArrayBuffer` 的大小是 `4`，因为，为了将数字添加到整数数组中，我们将它转换为 `Uint32Array`，其大小是 `4`
    的倍数。'
- en: We started two web workers from the same file.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从同一个文件启动了两个Web工人。
- en: We gave them access to `SharedArrayBuffer`.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们给了他们访问 `SharedArrayBuffer` 的权限。
- en: We're listening in the main script when both workers say they're done.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在主脚本中监听，当两个工人都说他们完成了。
- en: We are sending 500 million iterations to each worker, thus splitting the work
    among these two threads.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们向每个工人发送了5亿次迭代，从而将这些工作分配给这两个线程。
- en: 'Let us now look at what `worker.js` looks like:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看 `worker.js` 的样子：
- en: '[PRE3]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In `worker.js`, we do the following:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `worker.js` 中，我们执行以下操作：
- en: Listen for messages from the main script.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监听来自主脚本的消息。
- en: Check if the message says to store `SharedArrayBuffer`; if it does, we store
    it.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查消息是否指示存储 `SharedArrayBuffer`；如果是，我们就存储它。
- en: If the message says to start the iterations, we start by first converting it
    to `Uint32Array`.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果消息指示开始迭代，我们首先将其转换为 `Uint32Array`。
- en: After iterations, we send a nice 'done' message to the main script to inform
    it that we're done.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在迭代之后，我们向主脚本发送一个友好的 'done' 消息，通知它我们已经完成。
- en: '**Expectation:** The program will have a speed-up of around 2x because each
    thread has to do half of the work. Also, we expect the final value to be one billion.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**预期结果：**程序的速度将提高约 2 倍，因为每个线程都必须完成一半的工作。我们还期望最终值为一亿。'
- en: '**Reality: **Test #1 is as follows.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**现实情况：**测试 #1 如下所示。'
- en: 'Running the preceding code for the first time produces the following result:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 首次运行前面的代码会产生以下结果：
- en: '![](img/002fe4d7-06af-4992-89b2-3165678b15ea.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/002fe4d7-06af-4992-89b2-3165678b15ea.png)'
- en: 'Test #2 is as follows.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '测试 #2 如下所示。'
- en: 'Running the preceding code for the second time produces the following result:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 第二次运行前面的代码会产生以下结果：
- en: '![](img/3015f7ac-dab7-487e-b41b-b7adb94db3b8.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/3015f7ac-dab7-487e-b41b-b7adb94db3b8.png)'
- en: 'Test #3 is as follows.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '测试 #3 如下所示。'
- en: 'Running the preceding code for the third time produces the following result:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 第三次运行前面的代码会产生以下结果：
- en: '![](img/01bf5e2b-11bc-4dd0-be61-c6e62a2fd17d.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/01bf5e2b-11bc-4dd0-be61-c6e62a2fd17d.png)'
- en: I've got garbage values! Every time I run the program, I get different values,
    near 500 million. Why is this so?
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我得到了垃圾值！每次我运行程序，我都会得到不同的值，接近 5 亿。为什么会这样？
- en: The race condition
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 竞态条件
- en: The garbage values which were there in the immediately previous two screenshots
    represent a classic race condition example. Do you remember the first image I
    showed you in the *Introduction to SharedArrayBuffer* section? Remember the `SharedArrayBuffer`
    linking to **CPU 1** and **CPU 2,** which links to **Worker 1** and **Worker 2**?
    Well, it turns out it's not completely correct.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两个截图中的垃圾值代表了一个经典的竞态条件示例。你还记得我在 *SharedArrayBuffer 简介* 部分中展示的第一个图像吗？记得链接到 **CPU
    1** 和 **CPU 2** 的 `SharedArrayBuffer`，它分别链接到 **Worker 1** 和 **Worker 2** 吗？好吧，结果证明这并不完全正确。
- en: 'Here''s how the actual setup is in your machine:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这是你在机器上的实际设置：
- en: '![](img/f2018f69-4963-4618-8ce8-7d02fdf9b183.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f2018f69-4963-4618-8ce8-7d02fdf9b183.png)'
- en: The problem arises here. Race condition means that **CPU 1** fetches the shared
    memory and sends it to **Worker 1**. Meanwhile, **CPU 2** also fetches it, but
    doesn't know that **CPU 1** is already working on it. So, by the time **Worker
    1** has changed the value from *0* to *1*, **CPU 2**, that is, **Worker 2**, is
    still fetching the value 0.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 问题就出现在这里。竞态条件意味着 **CPU 1** 从共享内存中获取数据并发送给 **Worker 1**。与此同时，**CPU 2** 也获取了它，但它不知道
    **CPU 1** 已经在处理它。所以，当 **Worker 1** 将值从 *0* 更改为 *1* 时，**CPU 2**，即 **Worker 2**，仍然在获取值
    0。
- en: '**Worker 1** then updates the shared memory to a value of 1, and then **Worker
    2** updates its own copy to a value of 1 (because it doesn''t know that **CPU
    1** has already updated it to 1), and then writes it again to the shared memory.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**Worker 1** 然后将共享内存更新为 1 的值，然后 **Worker 2** 将其自己的副本更新为 1（因为它不知道 **CPU 1**
    已经将其更新为 1），然后再次将其写入共享内存。'
- en: 'Here, we''ve successfully wasted two computations, which required only one.
    That was a quick example of how not to do parallelism:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们成功地浪费了两个计算，而只需要一个。这是一个如何不进行并行处理的快速示例：
- en: '![](img/7079a465-8da9-49d9-a90d-99abe42774cf.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/7079a465-8da9-49d9-a90d-99abe42774cf.png)'
- en: How do we fix this? Atomics (we will come back to this problem later in the
    chapter, in the section *Fixing one billion count with atomics*).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们该如何解决这个问题？原子操作（我们将在本章后面的部分，即 *使用原子操作修复十亿计数* 部分中回到这个问题）。
- en: What are atomics?
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原子操作是什么？
- en: What are atomics? Atomics, or, more precisely, an atomic operation, is an operation
    which happens in one go, not in steps. It is like an atom --indivisible (although
    an atom is technically divisible, let's not destroy the analogy).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 原子操作是什么？原子操作，或者更准确地说，一个原子操作，是一个一次性发生而不是分步骤发生的操作。它就像一个原子——不可分割的（尽管在技术上原子是可以分割的，但让我们不要破坏这个类比）。
- en: An atomic operation is a single operation as seen by all other working threads.
    It just happens immediately. It is like the execution of one machine code, which
    is either not done yet or is completed. There is no in-between.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 原子操作是一个对所有其他工作线程可见的单个操作。它立即发生。它就像一条机器代码的执行，要么尚未完成，要么已经完成。中间没有其他状态。
- en: In a nutshell, something being atomic means that only one operation can be done
    on it at a time. For example, updating a variable can be made atomic. This can
    be used to avoid a race condition.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，某物是原子的意味着一次只能对其执行一个操作。例如，更新一个变量可以使其成为原子的。这可以用来避免竞争条件。
- en: Information about lock and mutex
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 锁和互斥锁的信息
- en: When I said updating a variable can be made atomic, it means that during the
    time a thread is accessing that memory, no other thread should be allowed to access
    it. This is only possible when you introduce a lock or a mutex (mutual exclusion)
    on the variable being accessed. This way, the other thread knows that the variable
    is in use and it should wait for the lock to be released.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 当我说更新一个变量可以使其成为原子的，我的意思是，在某个线程访问该内存的期间，不应该允许其他线程访问它。这只有在你在访问的变量上引入锁或互斥锁（互斥排他）时才可能。这样，其他线程就知道该变量正在使用中，它应该等待锁被释放。
- en: This is how you make an operation atomic. But this sense of security also comes
    at a cost. Atomic locking is not an operation which will take negligible time,
    so it definitely involves some overhead.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这样就可以进行原子操作。但这种安全感也伴随着代价。原子锁定不是一个可以忽略不计时间的操作，所以它肯定涉及一些开销。
- en: Do it a billion times, and you're probably screwed (we'll see that soon in *Fixing
    one billion count with atomics*).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 做一亿次，你可能就完蛋了（我们很快将在 *使用原子操作修复一亿次计数* 中看到这一点）。
- en: Atomics in JavaScript
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: JavaScript 中的 Atomics
- en: JavaScript has an `Atomics` object, which provides us with exactly the functionality
    we discussed previously. However, it is quite limited, in the sense that you can
    only do addition, subtraction, bitwise AND, bitwise OR, bitwise XOR, and storing.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: JavaScript 有一个 `Atomics` 对象，它为我们提供了之前讨论过的确切功能。然而，它在某种程度上相当有限，因为你只能进行加法、减法、按位与、按位或、按位异或和存储。
- en: Other features can be built on top of these, and, in future, there will be libraries
    providing that. For now, let's learn about the natively available methods.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 其他功能可以建立在这些功能之上，未来将会有库提供这些功能。现在，让我们了解一下原生可用的方法。
- en: Using the Atomics.load(typedArray, index) method
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Atomics.load(typedArray, index) 方法
- en: 'The `Atomics.load` method returns the value inside a typed array at a particular
    index value. Here''s how to use it:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`Atomics.load` 方法返回一个特定索引值内类型数组的值。以下是使用方法：'
- en: '[PRE4]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The preceding code is just a thread-safe way to access `arr[0]`.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码只是线程安全地访问 `arr[0]` 的方式。
- en: 'This outputs:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这会输出：
- en: '[PRE5]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Using the Atomics.add(typedArray, index, value) method
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Atomics.add(typedArray, index, value) 方法
- en: '`Atomics.add` is a way to add a particular value to a particular index in a
    typed array. It is fairly simple to understand and write:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`Atomics.add` 是向类型数组中的特定索引添加特定值的方法。它很容易理解和编写：'
- en: '[PRE6]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '`Atomics.add` is, again, a thread-safe way of performing `arr[0] += 10`.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`Atomics.add` 又是执行 `arr[0] += 10` 的线程安全方式。'
- en: 'This outputs:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这会输出：
- en: '[PRE7]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`Atomics.add` returns the old value at that index. The value is updated at
    that index after the command is run.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`Atomics.add` 返回该索引处的旧值。在命令执行后，该索引处的值将被更新。'
- en: Using the Atomics.sub(typedArray, index, value) method
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Atomics.sub(typedArray, index, value) 方法
- en: '`Atomics.sub` is a way to subtract a particular value from a particular index
    in a typed array. It is also fairly simple to use:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`Atomics.sub` 是从类型数组中特定索引减去特定值的方法。它也很容易使用：'
- en: '[PRE8]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`Atomics.sub` is, again, a thread-safe way of doing `arr[0] -= 2`.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`Atomics.sub` 又是执行 `arr[0] -= 2` 的线程安全方式。'
- en: 'This outputs:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这会输出：
- en: '[PRE9]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`Atomics.sub` returns the old value at that index. The value is updated at
    that index after the command is run.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`Atomics.sub` 返回该索引处的旧值。在命令执行后，该索引处的值将被更新。'
- en: Using the Atomics.and(typedArray, index, value) method
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Atomics.and(typedArray, index, value) 方法
- en: '`Atomics.and` performs a bitwise AND between the value at that particular index
    in the typed array and the value you supplied:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`Atomics.and` 在类型数组中特定索引的值和您提供的值之间执行按位与运算：'
- en: '[PRE10]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`Atomics.and` here performs a bitwise AND between `arr[0]` and the number `12`.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`Atomics.and` 在这里执行 `arr[0]` 和数字 `12` 之间的按位与运算。'
- en: 'This outputs:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这会输出：
- en: '[PRE11]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: How bitwise AND works
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按位与运算的工作原理
- en: 'Suppose we want to take a bitwise AND of 5 and 12:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要对 5 和 12 进行按位与运算：
- en: Covert both numbers to binary; 5 is 0101 and 12 is 1100.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将两个数字转换为二进制；5 是 0101，12 是 1100。
- en: 'Bitwise AND performs the `AND` operation bit by bit, starting from the first
    bit:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按位与运算从第一个位开始逐位执行 `AND` 操作：
- en: '*5  &  12*'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*5 & 12*'
- en: '*0 && 1 = 0*'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*0 && 1 = 0*'
- en: '*1 && 1 = 1*'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*1 && 1 = 1*'
- en: '*0 && 0 = 0*'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*0 && 0 = 0*'
- en: '*1 && 0 = 0*'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*1 && 0 = 0*'
- en: Thus, *5 && 12 = 0100*, which is 4.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，*5 && 12 = 0100*，这是 4。
- en: Using the Atomics.or(typedArray, index, value) method
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Atomics.or(typedArray, index, value) 方法
- en: 'Similar to bitwise AND, `Atomics.or` method performs a bitwise OR:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 与按位与类似，`Atomics.or` 方法执行按位或操作：
- en: '[PRE12]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here, `Atomics.or` method performed a bitwise OR between `arr[0]` and the number
    `12`.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`Atomics.or` 方法在 `arr[0]` 和数字 `12` 之间执行了按位或操作。
- en: 'The output is:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE13]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: How bitwise OR works
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按位或的工作原理
- en: 'Suppose we want to take a bitwise OR of 5 and 12:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要对 5 和 12 进行按位或操作：
- en: Covert both numbers to binary; 5 is 0101 and 12 is 1100
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将两个数字都转换为二进制；5 是 0101，12 是 1100
- en: 'Bitwise OR performs an OR operation bit by bit, starting from the first bit:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按位或操作是逐位进行或操作的，从第一个位开始：
- en: '*5  |  12*'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*5 | 12*'
- en: '*0 || 1 = 1*'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*0 || 1 = 1*'
- en: '*1 || 1 = 1*'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*1 || 1 = 1*'
- en: '*0 || 0 = 0*'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*0 || 0 = 0*'
- en: '*1 || 0 = 1*'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*1 || 0 = 1*'
- en: Thus, *5 | 12 = 1101* which is 13.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，*5 | 12 = 1101*，即 13。
- en: Using the Atomics.xor(typedArray, index, value) method
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Atomics.xor(typedArray, index, value) 方法
- en: Again, `Atomics.xor` method performs a bitwise XOR operation, which is an exclusive
    OR (that is, it is an OR gate which gives `0` when both inputs are `1`)
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，`Atomics.xor` 方法执行按位异或操作，这是一种排他或操作（即，它是一个或门，当两个输入都是 `1` 时输出 `0`）
- en: '[PRE14]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '`Atomics.xor` here performed a XOR operation between `arr[0]` and the number
    `10`.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '`Atomics.xor` 这里在 `arr[0]` 和数字 `10` 之间执行了异或操作。'
- en: 'This outputs:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这会输出：
- en: '[PRE15]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: How bitwise XOR works
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按位异或的工作原理
- en: 'Suppose we want to take a bitwise XOR of 5 and 12:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要对 5 和 12 进行按位异或操作：
- en: Covert both numbers to binary; 5 is 0101 and 12 is 1100.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将两个数字都转换为二进制；5 是 0101，12 是 1100。
- en: 'Bitwise XOR performs an XOR operation bit by bit, starting from the first bit:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按位异或操作是逐位进行的，从第一个位开始：
- en: '*5  ^  12*'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*5 ^ 12*'
- en: '*0 ^ 1 = 1*'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*0 ^ 1 = 1*'
- en: '*1 ^ 1 = 0*'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*1 ^ 1 = 0*'
- en: '*0 ^ 0 = 0*'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*0 ^ 0 = 0*'
- en: '*1 ^ 0 = 1*'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*1 ^ 0 = 1*'
- en: Thus, *5 ^ 12 = 1001*, which is 9.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，*5 ^ 12 = 1001*，即 9。
- en: With all the knowledge we required about atomics, let's hop back to our one
    billion count problem and see a possible fix.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们所需的关于原子操作的所有知识的基础上，让我们回到我们的一千亿计数问题，看看一个可能的解决方案。
- en: Fixing one billion count with atomics
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用原子操作修复一亿计数问题
- en: Now we know the reason for our garbage value, and, with atomics, it should be
    easy to fix the problem. Right? Wrong.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了垃圾值的原因，并且，使用原子操作，应该很容易修复这个问题。对吗？不对。
- en: 'There is a massive performance penalty on using atomic locking a billion times.
    Let''s look at our updated `worker.js` code now:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 使用原子锁定一亿次会有巨大的性能损失。现在让我们看看我们的更新后的 `worker.js` 代码：
- en: '[PRE16]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This is similar to our previous implementation of the problem, with the change
    being that instead of adding it directly to the array, we are performing an atomic
    operation so that the value isn't changed by the other thread while one thread
    is adding value to it.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们的先前实现类似，只是变化在于我们不是直接将其添加到数组中，而是在执行原子操作，这样在另一个线程添加值时，值不会被其他线程更改。
- en: 'Sure, it is a beautiful fix. And it works, as well:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这是一个漂亮的解决方案。它也有效：
- en: '![](img/895b6207-da11-4939-bdb9-0af21a5604c8.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](img/895b6207-da11-4939-bdb9-0af21a5604c8.png)'
- en: 'But look at that time: 80 seconds! That is the penalty you get when you lock
    and unlock over a memory one billion times.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 但看看那个时间：80 秒！这就是当你在一亿次锁定和解锁内存时得到的惩罚。
- en: Single threaded is faster, because it can access the local variable values from
    the register really quickly and use them. Our performance is slow because we're
    getting the reference to shared memory down, locking it, incrementing it, putting
    it up, and unlocking it.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 单线程更快，因为它可以从寄存器中快速访问局部变量值并使用它们。我们的性能较慢，因为我们正在获取共享内存的引用，锁定它，增加它，然后释放它。
- en: Let's read that again. Single threaded is faster because it can access the local
    variable values from the register really quickly and use them. Can we do something
    about this? Let's see!
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再读一遍。单线程更快，因为它可以从寄存器中快速访问局部变量值并使用它们。我们能做些什么吗？让我们看看！
- en: The optimized fix
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化的解决方案
- en: 'Why not combine the good parts of atomics and the good parts of the speed of
    local variables sitting in the CPU register? Here we are:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么不结合原子操作和 CPU 寄存器中局部变量的速度优势呢？这里就是：
- en: '[PRE17]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Here, from our last implementation, we took `Atomics.add` out of the loop to
    avoid calling it a billion times. Instead, we performed the work assigned to this
    web worker inside a local variable, and updated the memory with atomics only when
    we were done. This ensures no overwrite by two threads, in case they finish at
    the same moment. It's time to see the output.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，从我们最后的实现中，我们将 `Atomics.add` 从循环中移除，以避免调用它一亿次。相反，我们在这个 web worker 内部的局部变量中执行分配给它的任务，并在完成后仅使用原子操作更新内存。这确保了在两个线程同时完成时不会发生覆盖。现在是时候查看输出结果了。
- en: 'Look at these awesome results:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 看看这些令人惊叹的结果：
- en: '![](img/5019587e-0546-40c9-89a0-a186e48262a3.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5019587e-0546-40c9-89a0-a186e48262a3.png)'
- en: It is less than a second! That is about a 2.5 times gain by using just two workers!
    When we implemented parallel programming correctly, we were able to defeat our
    projected speed-up of 2x and shoot it to about 2.5x!
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 不到一秒！仅仅使用两个工作者就实现了大约2.5倍的提升！当我们正确实现了并行编程，我们能够超越预期的2倍加速，达到大约2.5倍！
- en: 'Hang on. The story doesn''t end here. Let''s add `4` workers and see what happens:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 等一下。故事还没有结束。让我们增加4个工作者，看看会发生什么：
- en: '[PRE18]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Excited to see the results? So am I! Let''s see:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 对看到结果感到兴奋吗？我也是！让我们看看：
- en: '![](img/f31bc77f-259d-4c90-bcc6-0710118f5c42.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f31bc77f-259d-4c90-bcc6-0710118f5c42.png)'
- en: Uh oh. Hmm, that doesn't seem like a very impressive performance gain. Going
    from one thread to two threads was a huge boost. Why is going from two to four,
    not one?
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀。嗯，这看起来并不是一个非常令人印象深刻的性能提升。从单线程到双线程是一个巨大的提升。为什么从双线程到四线程，提升不是一倍呢？
- en: 'Let''s take a look at the Network tab:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看“网络”标签页：
- en: '![](img/8dcf2e50-e45e-4065-ae61-1bdb346507d7.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8dcf2e50-e45e-4065-ae61-1bdb346507d7.png)'
- en: Eureka moment! It looks like we're spending 462 ms out of 911 ms of total program
    execution on just downloading the `worker.js` file! This even excludes the time
    for compilation of every individual script to machine code, which the JavaScript
    engine performs once it downloads.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 哈哈，我们好像找到了一个突破！看起来我们在总共911毫秒的程序执行时间中，有462毫秒是在仅仅下载`worker.js`文件上！这甚至不包括JavaScript引擎在下载后对每个单独脚本编译成机器代码的时间。
- en: Unfortunately, that is the end of what we can do from our end. Now it's browser's
    task to optimize the thing that if a single file is called again and again in
    the web worker, it should pickup compiled file from cache so it can actually use
    an already compiled instance of one file instead of downloading it three more
    times and then compiling them again.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这就是我们能从我们这边做到的尽头。现在浏览器需要优化的是，如果单个文件在web worker中被反复调用，它应该从缓存中提取编译后的文件，这样它实际上可以使用一个已经编译的文件实例，而不是再次下载三次并重新编译。
- en: In future, if Chrome optimizes according to the preceding suggestion, we can
    say it takes around *~120* ms instead of 462 ms of downloading and compiling.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来，如果Chrome根据前面的建议进行优化，我们可以说它将花费大约*~120*毫秒而不是462毫秒来下载和编译。
- en: Therefore, our script, in the near future, will take around ~570 ms to count
    to one billion. That is a performance gain of 500% over a single thread. That
    is multi-threading in JavaScript for you, folks.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的脚本在不久的将来，将花费大约~570毫秒来计算到十亿。这是相对于单线程的500%的性能提升。这就是JavaScript中的多线程，朋友们。
- en: A peek into Spectre
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一瞥Spectre
- en: On January 3, 2018, there was a fundamental flaw discovered with the CPU architecture
    we've been using for the past 20 years. This has shaken modern security to its
    roots. While the workings of Spectre and Meltdown are highly complicated (and
    deeply interesting, if you like the security field), what you have to know right
    now is that because of Spectre, all major browser vendors have disabled `SharedArrayBuffer`
    in browsers by default.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 2018年1月3日，我们发现了一个与我们过去20年使用的CPU架构相关的根本性缺陷。这动摇了现代安全的根基。虽然Spectre和Meltdown的工作原理非常复杂（如果你对安全领域感兴趣，这非常有趣），你现在需要知道的是，由于Spectre，所有主要的浏览器供应商都默认禁用了`SharedArrayBuffer`。
- en: You can enable `SharedArrayBuffer` by going to `chrome://flags` and searching
    for `SharedArrayBuffer` and enabling it.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过访问`chrome://flags`并搜索`SharedArrayBuffer`来启用`SharedArrayBuffer`。
- en: The reason for disabling `SharedArrayBuffer` is to mitigate Spectre, which is
    a dangerous but beautifully crafted exploit which requires a very precise measurement
    of time to attack. `SharedArrayBuffer` provides a way for multiple threads to
    be accessible to every thread, and atomics add more precision over the data available.
    This can be used to create highly precise clocks using `SharedArrayBuffer`, which
    can be used to carry out a Spectre attack.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用`SharedArrayBuffer`的原因是为了减轻Spectre的影响，这是一个危险但精心设计的漏洞，需要非常精确的时间测量来攻击。`SharedArrayBuffer`为多个线程提供了一种方式，使得每个线程都可以访问到，原子操作则提供了对数据的更多精确控制。这可以通过`SharedArrayBuffer`创建高度精确的时钟，可以用来执行Spectre攻击。
- en: Spectre basically exploits the fact that modern CPUs precompute a lot of things
    and put them in the cache. So, if you get ACCESS DENIED for a part of memory your
    program is not supposed to access way quicker than it's supposed to be, chances
    are, that particular block of memory is in the cache. Using beautifully crafted
    scripts, it is even possible to know which value is in the cache because your
    program is the one which put it there!
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: Spectre 主要利用了现代 CPU 预计算大量事情并将它们放入缓存的事实。所以，如果你发现你的程序不应该访问的内存部分被拒绝访问的速度比预期快得多，那么很可能，那个特定的内存块就在缓存中。使用精心制作的脚本，甚至可以知道缓存中存储了哪个值，因为你的程序是将其放入那里的！
- en: Ahh! It'll take a long chapter to actually have a little fun with Spectre and
    Meltdown. But that is for some other day, some other book. The takeaway from here
    is that at the time of writing this chapter, `SharedArrayBuffer` is not enabled
    in browsers by default. It will be enabled in the future, when proper patches
    are put in place by all browser vendors.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 哎！要真正地玩转 Spectre 和 Meltdown，需要很长的一章。但这将是另一天，另一本书的内容。这里的要点是，在撰写本章时，`SharedArrayBuffer`
    在浏览器中默认未启用。当所有浏览器供应商都实施适当的补丁时，它将在未来启用。
- en: 'Here are some articles for people who find such stuff cool:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些文章，适合那些觉得这类东西很酷的人：
- en: How Spectre works: [http://www.i-programmer.info/news/149-security/11449-how-spectre-works.html](http://www.i-programmer.info/news/149-security/11449-how-spectre-works.html)
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何 Spectre 工作：[http://www.i-programmer.info/news/149-security/11449-how-spectre-works.html](http://www.i-programmer.info/news/149-security/11449-how-spectre-works.html)
- en: Spectre and Meltdown explained: [https://www.csoonline.com/article/3247868/vulnerabilities/spectre-and-meltdown-explained-what-they-are-how-they-work-whats-at-risk.html](https://www.csoonline.com/article/3247868/vulnerabilities/spectre-and-meltdown-explained-what-they-are-how-they-work-whats-at-risk.html)
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释 Spectre 和 Meltdown：[https://www.csoonline.com/article/3247868/vulnerabilities/spectre-and-meltdown-explained-what-they-are-how-they-work-whats-at-risk.html](https://www.csoonline.com/article/3247868/vulnerabilities/spectre-and-meltdown-explained-what-they-are-how-they-work-whats-at-risk.html)
- en: Till then, stay safe!
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 到那时，请保持安全！
- en: Summary
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: It wouldn't be wrong to say that this is now my favorite chapter, with *Chapter
    4, Asynchronous Programming,* sliding down to number two. This technology is raw,
    fresh, and waiting to be explored.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 不得不说，这现在是我的最爱章节，而**第4章，异步编程**则降至第二位。这项技术是原始的、新鲜的，等待被探索。
- en: We learned a lot of new stuff about ES2017 in this chapter, which, in the near
    future, will be the base of multi-threaded programs written in JavaScript. Well,
    that is it! You're now a good developer who knows a lot about ES2017 (that is,
    ES8) and a lot more about future tech, as well. Use your powers to make this world
    a good place!
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们关于 ES2017 学到了很多新知识，这些知识在不久的将来将成为用 JavaScript 编写的多线程程序的基础。好吧，就是这样！你现在已经成为一个了解
    ES2017（即 ES8）以及更多未来技术的优秀开发者了。运用你的力量，让这个世界变得更美好！
