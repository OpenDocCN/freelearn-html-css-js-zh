- en: Shared Memory and Atomics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's go to low-level memory stuff! This chapter is going to be a bit advanced,
    but interesting. I'll try to make it as simple and understandable as possible.
  prefs: []
  type: TYPE_NORMAL
- en: With that out of the way, let's get to what we've FINALLY in JavaScript! Low-level
    memory access, multi-threading, atomics, shared memory, and all that cool and
    powerful stuff. But, as someone said, with great power comes great responsibility.
    Let's go!
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll cover the following things in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Basics of memory management in computers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is shared memory?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `SharedArrayBuffer`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to parallel programming
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Problems when multiple threads access one memory location
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are atomics?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing atomic operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Atomic APIs in JavaScript
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using parallel programming the right way
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basics of memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have to understand a little about how memory works in order to appreciate
    the significance of `SharedArrayBuffer` in JavaScript.
  prefs: []
  type: TYPE_NORMAL
- en: Think of memory as a collection of a lot of drawers in a big almirah kind of
    structure, where you can open a drawer and put something in it. Every drawer has
    its own maximum capacity.
  prefs: []
  type: TYPE_NORMAL
- en: Every drawer also has a sticker associated with it, which has a unique number
    on it that helps you to note down which drawer has data and which doesn't. When
    the time comes to access that data, you are supplied with the numbered drawer
    and you can take out data accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let us start by understanding the basics of memory storage. Suppose I
    want to store a number, say, 100, in memory. First of all, we need to convert
    this number into binary, because that is what computers understand, and it is
    easy for them to store:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/64948eed-49b0-4261-805f-6f030bb34c48.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding figure is a binary representation of the number 100 and is how
    it is stored in memory.
  prefs: []
  type: TYPE_NORMAL
- en: Easy! In a similar manner, we can store more complicated data, such as letters,
    by converting them to numbers (called ASCII values), and then storing those numbers
    directly, instead of letters. Similarly, an image (assumed to be black and white)
    can be stored by, say, storing the brightness levels of each pixel floating point
    number.
  prefs: []
  type: TYPE_NORMAL
- en: Abstraction of memory management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Memory management means that you're actually interacting directly with the hardware
    to store/update/free blocks of memory yourself from your code. Most higher level
    programming languages take away the memory management from the developers.
  prefs: []
  type: TYPE_NORMAL
- en: This is because managing memory is hard. It really is! In complicated programs,
    humans are bound to make mistakes and cause a ton of problems, not limited to
    memory leaks (which is the easiest mistake someone can make).
  prefs: []
  type: TYPE_NORMAL
- en: Of course, this abstraction comes at a performance cost. But compared with the
    security, readability, and convenience advantages, this is a fair deal.
  prefs: []
  type: TYPE_NORMAL
- en: JavaScript also manages memory automatically. The JavaScript engine is responsible
    for registering memory whenever a new variable is created, freeing the memory
    when it is no longer needed, and so on. Imagine managing memory for a **closure**
    program yourself! Even if the program is a bit complicated, it is very easy to
    lose track of which variables to keep in memory and which ones to discard, even
    after function execution ends. JavaScript to the rescue!
  prefs: []
  type: TYPE_NORMAL
- en: Garbage collection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: JavaScript is a garbage collected language. What that means is that a JavaScript
    engine will occasionally fire something called a garbage collector, which looks
    for unused and inaccessible references in memory for the program and clears them,
    making the memory available for storing other data.
  prefs: []
  type: TYPE_NORMAL
- en: Garbage collectors make life a lot easier, but add a bit of overhead in performance-critical
    applications. Say you are coding a 3D game where you want very high **Frames Per
    Second** (**FPS**) on not so good hardware.
  prefs: []
  type: TYPE_NORMAL
- en: You might see that the results are extremely good for a game coded in C/C++,
    as compared to a garbage collected language like Java. This is because when you're
    playing the game, garbage collectors might fire off even when it is unnecessary,
    which wastes some resources that could've been used by the rendering thread.
  prefs: []
  type: TYPE_NORMAL
- en: Manually managing memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Languages such as C/C++ are on their own in terms of memory management. In such
    languages, you have to allocate the memory and de-allocate it all by yourself.
    This is the reason why C/C++ are so fast--because they're very close to the hardware,
    and almost no abstraction is there. But that makes it painful to write complex
    applications because things can slip out of hand real quick.
  prefs: []
  type: TYPE_NORMAL
- en: There is something called as **WebAssembly**, which is the compiled form of
    a JavaScript alternative on the web. C/C++ code can be compiled down to WebAssembly,
    which is in some cases 100-200% faster than native JavaScript!
  prefs: []
  type: TYPE_NORMAL
- en: WebAssembly is going to be the future of the web because of its speed and multiple
    types of language support. However, it'll again require you to manage memory yourself,
    as, at the end of the day, C/C++ is what you'll need to write your code in.
  prefs: []
  type: TYPE_NORMAL
- en: Manually managing memory is hard. It is hard to know when to clear off the part
    of memory you don't require in bigger programs. Do it early, and you break the
    application. Do it late, and you are out of memory. This is the reason abstraction
    is good in a lot of cases.
  prefs: []
  type: TYPE_NORMAL
- en: What is shared memory?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's suppose we are working on a real-time performance-critical application,
    which is the reason we're so concerned about this interesting topic. Suppose I
    have two web workers running in the background, and I want to share some data
    from one worker to another. Web workers run independently on separate OS-level
    threads and have no idea about each other.
  prefs: []
  type: TYPE_NORMAL
- en: One way is to make use of `postMessage` to transfer messages between web workers,
    as we saw in the last chapter. However, this is slow.
  prefs: []
  type: TYPE_NORMAL
- en: Another way is to transfer the object to another worker completely; however,
    if you remember, that makes the object which is transferred inaccessible from
    the worker which sent it.
  prefs: []
  type: TYPE_NORMAL
- en: The solution to this problem is `SharedArrayBuffer`.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to SharedArrayBuffer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `SharedArrayBuffer` is the way to create a memory store which is accessible
    to all workers simultaneously. Now, if you've been reading keenly, you will have
    understood something mischievous that can happen once something like a shared
    memory store is allowed to exist.
  prefs: []
  type: TYPE_NORMAL
- en: If you remember, the only reason workers didn't have direct access to `DOM`
    was because the DOM API is not thread-safe, and could cause problems like deadlocks
    and race conditions. And if you were able to judge that the same thing might happen
    here, you're right! But that's a topic for a later section (*The race condition*).
  prefs: []
  type: TYPE_NORMAL
- en: Let's get back to `SharedArrayBuffer`. So what's different from `ArrayBuffer`?
  prefs: []
  type: TYPE_NORMAL
- en: Well, `SharedArrayBuffer` is pretty much the `ArrayBuffer` which is available
    to a lot of scripts. You just have to create `SharedArrayBuffer` in one place
    and use `postMessage` to post it to other workers (and not transfer it!).
  prefs: []
  type: TYPE_NORMAL
- en: 'You should not transfer it because you''ll then lose ownership of the `SharedArrayBuffer`.
    When you post it, only the reference of the buffer is automatically passed and
    becomes available to all the other scripts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you do that, all the workers will be able to access, read, and write to
    `SharedArrayBuffer`. Take a look at the representation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b91c486c-0f13-4cc3-86c3-dc675edf6464.png)'
  prefs: []
  type: TYPE_IMG
- en: This is a rough representation of how you might imagine `SharedArrayBuffer`
    is connected to the memory under the hood. Let's assume each thread is spawned
    on a different CPU, for now.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding parallel programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Parallel programming, as the name suggests, is just a program running in such
    a way that instances of that program are running simultaneously multiple times.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrent programming, on the other hand, is very similar to parallel programming,
    but with the difference that tasks never happen together.
  prefs: []
  type: TYPE_NORMAL
- en: Parallel versus concurrent programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To understand the difference between parallel and concurrent programming, let
    us consider an example.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose there's a competition to eat candies put on two plates. Plates are at
    a distance of five meters from each other. Let's say you're the only player for
    now, and the constraint is that you have to keep the number of differences in
    candies on both plates to less than two.
  prefs: []
  type: TYPE_NORMAL
- en: What will you do here? You have to eat from plate one, run five meters to plate
    two, eat from plate two, run five meters again to plate one, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's assume you have got a friend. Now, both of you can choose a plate
    and start eating your own candies.
  prefs: []
  type: TYPE_NORMAL
- en: Try to relate it to concurrent programming and parallel programming, respectively.
    In the first example, you are the CPU's core, which is running here and there,
    again and again, between two threads (plates). You are running fast, but, no matter
    how hard you try, you cannot eat from both plates at the same time due to your
    physical limits. Similarly, the CPU in concurrent programming is doing both of
    the tasks, but instead of doing them simultaneously, it is doing both in chunks.
  prefs: []
  type: TYPE_NORMAL
- en: In the next example, for parallel programming, your friend acts like another
    CPU, which is handling the other thread completely. This way, each of you only
    have to execute your own thread. This is parallelism.
  prefs: []
  type: TYPE_NORMAL
- en: If that makes sense, then let us get into parallel programming, the thing which
    web workers give us, and how to make use of shared memory with parallel programming
    to actually make things faster and not slow them down (because that happens a
    lot of times, when you do it incorrectly).
  prefs: []
  type: TYPE_NORMAL
- en: Myth-busting--Parallel computation is always faster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It seems so intuitive to say that parallel computation should always be faster
    than computing on a single thread. Like spawning two threads should, intuitively,
    almost halve the computation time. Not only is this numerically wrong, but parallel
    computing creates garbage results if not done properly.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand this, consider a man who is given a task to transfer a pile of
    blocks from one place to another:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/637443e1-2bc6-427d-a689-57b7177e6cd1.png)'
  prefs: []
  type: TYPE_IMG
- en: He does this work at some speed. Putting another man with him might sound like
    doubling the speed of the work, but the two might actually crash into each other
    on their way and make things slower instead of faster.
  prefs: []
  type: TYPE_NORMAL
- en: This actually happens a lot of times when parallelism is implemented incorrectly,
    as we shall see now.
  prefs: []
  type: TYPE_NORMAL
- en: Let's count one billion!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To verify that parallel computing, if set up wrongly, is actually garbage, let
    us count to one billion using a single-threaded and multi-threaded environment
    in JavaScript.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us first try single-threaded counting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'On my MacBook Air, it takes *∼2606* milliseconds for this program to run. That
    is roughly *2.6* seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8229befe-f419-425d-9598-42992ac49e2d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let us try to split the code among two workers now, and see what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Alright! So what the heck is going on here? The following is an explanation:'
  prefs: []
  type: TYPE_NORMAL
- en: We created a `SharedArrayBuffer` in order to create a memory storage area which
    can be accessed simultaneously by both of the spawned web workers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The size of `SharedArrayBuffer` is `4` because, to add numbers to the integer
    array, we'll cast it to `Uint32Array`, which has a size in multiples of `4`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We started two web workers from the same file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We gave them access to `SharedArrayBuffer`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We're listening in the main script when both workers say they're done.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We are sending 500 million iterations to each worker, thus splitting the work
    among these two threads.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let us now look at what `worker.js` looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'In `worker.js`, we do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Listen for messages from the main script.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check if the message says to store `SharedArrayBuffer`; if it does, we store
    it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the message says to start the iterations, we start by first converting it
    to `Uint32Array`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After iterations, we send a nice 'done' message to the main script to inform
    it that we're done.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Expectation:** The program will have a speed-up of around 2x because each
    thread has to do half of the work. Also, we expect the final value to be one billion.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Reality: **Test #1 is as follows.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the preceding code for the first time produces the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/002fe4d7-06af-4992-89b2-3165678b15ea.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Test #2 is as follows.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the preceding code for the second time produces the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3015f7ac-dab7-487e-b41b-b7adb94db3b8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Test #3 is as follows.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the preceding code for the third time produces the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/01bf5e2b-11bc-4dd0-be61-c6e62a2fd17d.png)'
  prefs: []
  type: TYPE_IMG
- en: I've got garbage values! Every time I run the program, I get different values,
    near 500 million. Why is this so?
  prefs: []
  type: TYPE_NORMAL
- en: The race condition
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The garbage values which were there in the immediately previous two screenshots
    represent a classic race condition example. Do you remember the first image I
    showed you in the *Introduction to SharedArrayBuffer* section? Remember the `SharedArrayBuffer`
    linking to **CPU 1** and **CPU 2,** which links to **Worker 1** and **Worker 2**?
    Well, it turns out it's not completely correct.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s how the actual setup is in your machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f2018f69-4963-4618-8ce8-7d02fdf9b183.png)'
  prefs: []
  type: TYPE_IMG
- en: The problem arises here. Race condition means that **CPU 1** fetches the shared
    memory and sends it to **Worker 1**. Meanwhile, **CPU 2** also fetches it, but
    doesn't know that **CPU 1** is already working on it. So, by the time **Worker
    1** has changed the value from *0* to *1*, **CPU 2**, that is, **Worker 2**, is
    still fetching the value 0.
  prefs: []
  type: TYPE_NORMAL
- en: '**Worker 1** then updates the shared memory to a value of 1, and then **Worker
    2** updates its own copy to a value of 1 (because it doesn''t know that **CPU
    1** has already updated it to 1), and then writes it again to the shared memory.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we''ve successfully wasted two computations, which required only one.
    That was a quick example of how not to do parallelism:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7079a465-8da9-49d9-a90d-99abe42774cf.png)'
  prefs: []
  type: TYPE_IMG
- en: How do we fix this? Atomics (we will come back to this problem later in the
    chapter, in the section *Fixing one billion count with atomics*).
  prefs: []
  type: TYPE_NORMAL
- en: What are atomics?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are atomics? Atomics, or, more precisely, an atomic operation, is an operation
    which happens in one go, not in steps. It is like an atom --indivisible (although
    an atom is technically divisible, let's not destroy the analogy).
  prefs: []
  type: TYPE_NORMAL
- en: An atomic operation is a single operation as seen by all other working threads.
    It just happens immediately. It is like the execution of one machine code, which
    is either not done yet or is completed. There is no in-between.
  prefs: []
  type: TYPE_NORMAL
- en: In a nutshell, something being atomic means that only one operation can be done
    on it at a time. For example, updating a variable can be made atomic. This can
    be used to avoid a race condition.
  prefs: []
  type: TYPE_NORMAL
- en: Information about lock and mutex
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When I said updating a variable can be made atomic, it means that during the
    time a thread is accessing that memory, no other thread should be allowed to access
    it. This is only possible when you introduce a lock or a mutex (mutual exclusion)
    on the variable being accessed. This way, the other thread knows that the variable
    is in use and it should wait for the lock to be released.
  prefs: []
  type: TYPE_NORMAL
- en: This is how you make an operation atomic. But this sense of security also comes
    at a cost. Atomic locking is not an operation which will take negligible time,
    so it definitely involves some overhead.
  prefs: []
  type: TYPE_NORMAL
- en: Do it a billion times, and you're probably screwed (we'll see that soon in *Fixing
    one billion count with atomics*).
  prefs: []
  type: TYPE_NORMAL
- en: Atomics in JavaScript
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: JavaScript has an `Atomics` object, which provides us with exactly the functionality
    we discussed previously. However, it is quite limited, in the sense that you can
    only do addition, subtraction, bitwise AND, bitwise OR, bitwise XOR, and storing.
  prefs: []
  type: TYPE_NORMAL
- en: Other features can be built on top of these, and, in future, there will be libraries
    providing that. For now, let's learn about the natively available methods.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Atomics.load(typedArray, index) method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `Atomics.load` method returns the value inside a typed array at a particular
    index value. Here''s how to use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code is just a thread-safe way to access `arr[0]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Using the Atomics.add(typedArray, index, value) method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`Atomics.add` is a way to add a particular value to a particular index in a
    typed array. It is fairly simple to understand and write:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '`Atomics.add` is, again, a thread-safe way of performing `arr[0] += 10`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '`Atomics.add` returns the old value at that index. The value is updated at
    that index after the command is run.'
  prefs: []
  type: TYPE_NORMAL
- en: Using the Atomics.sub(typedArray, index, value) method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`Atomics.sub` is a way to subtract a particular value from a particular index
    in a typed array. It is also fairly simple to use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '`Atomics.sub` is, again, a thread-safe way of doing `arr[0] -= 2`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '`Atomics.sub` returns the old value at that index. The value is updated at
    that index after the command is run.'
  prefs: []
  type: TYPE_NORMAL
- en: Using the Atomics.and(typedArray, index, value) method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`Atomics.and` performs a bitwise AND between the value at that particular index
    in the typed array and the value you supplied:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '`Atomics.and` here performs a bitwise AND between `arr[0]` and the number `12`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: How bitwise AND works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Suppose we want to take a bitwise AND of 5 and 12:'
  prefs: []
  type: TYPE_NORMAL
- en: Covert both numbers to binary; 5 is 0101 and 12 is 1100.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Bitwise AND performs the `AND` operation bit by bit, starting from the first
    bit:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*5  &  12*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*0 && 1 = 0*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*1 && 1 = 1*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*0 && 0 = 0*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*1 && 0 = 0*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Thus, *5 && 12 = 0100*, which is 4.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the Atomics.or(typedArray, index, value) method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similar to bitwise AND, `Atomics.or` method performs a bitwise OR:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Here, `Atomics.or` method performed a bitwise OR between `arr[0]` and the number
    `12`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: How bitwise OR works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Suppose we want to take a bitwise OR of 5 and 12:'
  prefs: []
  type: TYPE_NORMAL
- en: Covert both numbers to binary; 5 is 0101 and 12 is 1100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Bitwise OR performs an OR operation bit by bit, starting from the first bit:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*5  |  12*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*0 || 1 = 1*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*1 || 1 = 1*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*0 || 0 = 0*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*1 || 0 = 1*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Thus, *5 | 12 = 1101* which is 13.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the Atomics.xor(typedArray, index, value) method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Again, `Atomics.xor` method performs a bitwise XOR operation, which is an exclusive
    OR (that is, it is an OR gate which gives `0` when both inputs are `1`)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '`Atomics.xor` here performed a XOR operation between `arr[0]` and the number
    `10`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This outputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: How bitwise XOR works
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Suppose we want to take a bitwise XOR of 5 and 12:'
  prefs: []
  type: TYPE_NORMAL
- en: Covert both numbers to binary; 5 is 0101 and 12 is 1100.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Bitwise XOR performs an XOR operation bit by bit, starting from the first bit:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*5  ^  12*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*0 ^ 1 = 1*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*1 ^ 1 = 0*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*0 ^ 0 = 0*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*1 ^ 0 = 1*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Thus, *5 ^ 12 = 1001*, which is 9.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With all the knowledge we required about atomics, let's hop back to our one
    billion count problem and see a possible fix.
  prefs: []
  type: TYPE_NORMAL
- en: Fixing one billion count with atomics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we know the reason for our garbage value, and, with atomics, it should be
    easy to fix the problem. Right? Wrong.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a massive performance penalty on using atomic locking a billion times.
    Let''s look at our updated `worker.js` code now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This is similar to our previous implementation of the problem, with the change
    being that instead of adding it directly to the array, we are performing an atomic
    operation so that the value isn't changed by the other thread while one thread
    is adding value to it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sure, it is a beautiful fix. And it works, as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/895b6207-da11-4939-bdb9-0af21a5604c8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'But look at that time: 80 seconds! That is the penalty you get when you lock
    and unlock over a memory one billion times.'
  prefs: []
  type: TYPE_NORMAL
- en: Single threaded is faster, because it can access the local variable values from
    the register really quickly and use them. Our performance is slow because we're
    getting the reference to shared memory down, locking it, incrementing it, putting
    it up, and unlocking it.
  prefs: []
  type: TYPE_NORMAL
- en: Let's read that again. Single threaded is faster because it can access the local
    variable values from the register really quickly and use them. Can we do something
    about this? Let's see!
  prefs: []
  type: TYPE_NORMAL
- en: The optimized fix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Why not combine the good parts of atomics and the good parts of the speed of
    local variables sitting in the CPU register? Here we are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Here, from our last implementation, we took `Atomics.add` out of the loop to
    avoid calling it a billion times. Instead, we performed the work assigned to this
    web worker inside a local variable, and updated the memory with atomics only when
    we were done. This ensures no overwrite by two threads, in case they finish at
    the same moment. It's time to see the output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Look at these awesome results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5019587e-0546-40c9-89a0-a186e48262a3.png)'
  prefs: []
  type: TYPE_IMG
- en: It is less than a second! That is about a 2.5 times gain by using just two workers!
    When we implemented parallel programming correctly, we were able to defeat our
    projected speed-up of 2x and shoot it to about 2.5x!
  prefs: []
  type: TYPE_NORMAL
- en: 'Hang on. The story doesn''t end here. Let''s add `4` workers and see what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Excited to see the results? So am I! Let''s see:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f31bc77f-259d-4c90-bcc6-0710118f5c42.png)'
  prefs: []
  type: TYPE_IMG
- en: Uh oh. Hmm, that doesn't seem like a very impressive performance gain. Going
    from one thread to two threads was a huge boost. Why is going from two to four,
    not one?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the Network tab:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8dcf2e50-e45e-4065-ae61-1bdb346507d7.png)'
  prefs: []
  type: TYPE_IMG
- en: Eureka moment! It looks like we're spending 462 ms out of 911 ms of total program
    execution on just downloading the `worker.js` file! This even excludes the time
    for compilation of every individual script to machine code, which the JavaScript
    engine performs once it downloads.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, that is the end of what we can do from our end. Now it's browser's
    task to optimize the thing that if a single file is called again and again in
    the web worker, it should pickup compiled file from cache so it can actually use
    an already compiled instance of one file instead of downloading it three more
    times and then compiling them again.
  prefs: []
  type: TYPE_NORMAL
- en: In future, if Chrome optimizes according to the preceding suggestion, we can
    say it takes around *~120* ms instead of 462 ms of downloading and compiling.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, our script, in the near future, will take around ~570 ms to count
    to one billion. That is a performance gain of 500% over a single thread. That
    is multi-threading in JavaScript for you, folks.
  prefs: []
  type: TYPE_NORMAL
- en: A peek into Spectre
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: On January 3, 2018, there was a fundamental flaw discovered with the CPU architecture
    we've been using for the past 20 years. This has shaken modern security to its
    roots. While the workings of Spectre and Meltdown are highly complicated (and
    deeply interesting, if you like the security field), what you have to know right
    now is that because of Spectre, all major browser vendors have disabled `SharedArrayBuffer`
    in browsers by default.
  prefs: []
  type: TYPE_NORMAL
- en: You can enable `SharedArrayBuffer` by going to `chrome://flags` and searching
    for `SharedArrayBuffer` and enabling it.
  prefs: []
  type: TYPE_NORMAL
- en: The reason for disabling `SharedArrayBuffer` is to mitigate Spectre, which is
    a dangerous but beautifully crafted exploit which requires a very precise measurement
    of time to attack. `SharedArrayBuffer` provides a way for multiple threads to
    be accessible to every thread, and atomics add more precision over the data available.
    This can be used to create highly precise clocks using `SharedArrayBuffer`, which
    can be used to carry out a Spectre attack.
  prefs: []
  type: TYPE_NORMAL
- en: Spectre basically exploits the fact that modern CPUs precompute a lot of things
    and put them in the cache. So, if you get ACCESS DENIED for a part of memory your
    program is not supposed to access way quicker than it's supposed to be, chances
    are, that particular block of memory is in the cache. Using beautifully crafted
    scripts, it is even possible to know which value is in the cache because your
    program is the one which put it there!
  prefs: []
  type: TYPE_NORMAL
- en: Ahh! It'll take a long chapter to actually have a little fun with Spectre and
    Meltdown. But that is for some other day, some other book. The takeaway from here
    is that at the time of writing this chapter, `SharedArrayBuffer` is not enabled
    in browsers by default. It will be enabled in the future, when proper patches
    are put in place by all browser vendors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some articles for people who find such stuff cool:'
  prefs: []
  type: TYPE_NORMAL
- en: How Spectre works: [http://www.i-programmer.info/news/149-security/11449-how-spectre-works.html](http://www.i-programmer.info/news/149-security/11449-how-spectre-works.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spectre and Meltdown explained: [https://www.csoonline.com/article/3247868/vulnerabilities/spectre-and-meltdown-explained-what-they-are-how-they-work-whats-at-risk.html](https://www.csoonline.com/article/3247868/vulnerabilities/spectre-and-meltdown-explained-what-they-are-how-they-work-whats-at-risk.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Till then, stay safe!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It wouldn't be wrong to say that this is now my favorite chapter, with *Chapter
    4, Asynchronous Programming,* sliding down to number two. This technology is raw,
    fresh, and waiting to be explored.
  prefs: []
  type: TYPE_NORMAL
- en: We learned a lot of new stuff about ES2017 in this chapter, which, in the near
    future, will be the base of multi-threaded programs written in JavaScript. Well,
    that is it! You're now a good developer who knows a lot about ES2017 (that is,
    ES8) and a lot more about future tech, as well. Use your powers to make this world
    a good place!
  prefs: []
  type: TYPE_NORMAL
