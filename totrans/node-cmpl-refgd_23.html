<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Testing</h1>
                </header>
            
            <article>
                
<p>When<span> y</span>ou're developing<span> an application, it will eventually form a structure and evolve into a stable product that you can use in production and sell to your customers. In the beginning, everything may seem simple and many tend to postpone the construction of a proper test suite.</span></p>
<div class="packt_quote">"Debugging is twice as hard as writing the code in the first place."</div>
<div class="packt_quote">              <em>—Brian W. Kernighan and P. J. Plauger in</em> The Elements of Programming Style</div>
<p>Later on, the application may become just sufficiently complex for you to hesitate to begin testing. You may eventually give up and never test your application. It may be frustrating, especially if you have never seen or used any test suite before.</p>
<p>Proper testing gives you more than a little bit of quality assurance. Proper testing gives you:</p>
<ul>
<li><strong>Predictability</strong>: This <span>means that your code execution, no matter if it's an application or just a module, will have an expected result. As you evolve the tests and introduce different test cases, you begin to fulfill all the uses for your code, and you ensure its results were as intended.</span></li>
<li><strong>Feature coverage</strong>: This <span>means that you can measure what parts of your code are tested or not. There are plenty of tools to inspect your code and tell you what parts of it haven't been used in your test suite, which helps you create specific tests for specific parts of the code that are not yet covered.</span></li>
<li><strong>Safe evolution</strong>: This <span>is a side effect. When your code gets complex, if your test suite has good code coverage, you can make changes and add features without compromising stability, as you can continuously run the test suite and see if it breaks anything.</span></li>
</ul>
<p class="mce-root"/>
<p>There's a developing methodology that involves first creating a test for a new feature and then making sure the test passes. This way, you can focus on how you think your code should be used (in the new test) and then evolve it (actually develop it) so the test stops failing and gives proper results.</p>
<p><span>Let's see how code coverage can help in the testing process. Finally, we'll look at how you can mock parts of your code.</span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Integrating tests</h1>
                </header>
            
            <article>
                
<p>We will create our first integration tests. Each of our tests will run separately, meaning they should not depend on any other test and should follow a predictable workflow. First, we need to change our <kbd>run.js</kbd> file to run all test files. For that, we'll use <kbd>mocha</kbd> and add all files found in the <kbd>integration</kbd> folder:</p>
<pre>const fs    = require("fs");<br/>const path  = require("path");<br/>const mocha = require("mocha");<br/>const suite = new mocha();<br/><br/>fs.readdir(path.join(__dirname, "integration"), (err, files) =&gt; {<br/>    if (err) throw err;<br/><br/>    files.filter((filename) =&gt; <br/>    (filename.match(/\.js$/))).map((filename) =&gt; {<br/>        suite.addFile(path.join(__dirname, "integration", filename));<br/>    });<br/><br/>    suite.run((failures) =&gt; {<br/>        process.exit(failures);<br/>    });<br/>});</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>Then, let's create the <kbd>integration</kbd> folder inside our <kbd>test</kbd> folder, and let's create our first test file, called <kbd>image-upload.js</kbd>. Add this content to the file:</p>
<pre>describe("Uploading image", () =&gt; {<br/>    it("should accept only images");<br/>});</pre>
<p>If we now run the tests again, we should see the default <kbd>mocha</kbd> response with no tests passing and no tests failing:</p>
<pre><strong>npm test</strong><br/><strong>&gt; imagini@1.0.0 test /Users/dresende/imagini</strong><br/><strong>&gt; node test/run</strong><br/><br/><strong>0 passing (2ms)</strong></pre>
<p>To avoid repeating code, let's create a <kbd>tools.js</kbd> file inside the <kbd>test</kbd> folder, so we can export common tasks that every test file can use. Out of the box, I'm thinking about our microservice location and a sample image:</p>
<pre>const fs   = require("fs");<br/>const path = require("path");<br/><br/>exports.service = require("../imagini.js");<br/>exports.sample  = fs.readFileSync(path.join(__dirname, "sample.png"));</pre>
<p>Create a <kbd>sample.png</kbd> image in the <kbd>test</kbd> folder. When a test needs to upload an image, it will use that sample. In the future, we could have different kinds of samples, such as huge images, to test performance and limitations.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using chai</h1>
                </header>
            
            <article>
                
<p>We also need to make a little change to our microservice. We need to export its app so that the HTTP plugin from <kbd>chai</kbd> can load it and were able to test it without the need to run in a separate console. Add this to the end of our microservice file:</p>
<pre>module.exports = app;</pre>
<p class="mce-root"/>
<p>You should have a folder hierarchy similar to the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/618c9422-7b6e-4442-80be-bcda48e204ec.png" width="1640" height="980"/></div>
<p>We should now change our <kbd>image-upload.js</kbd> test file to create our first real test:</p>
<pre>const chai  = require("chai");<br/>const http  = require("chai-http");<br/>const tools = require("../tools");<br/><br/>chai.use(http);<br/><br/>describe("Uploading image", () =&gt; {<br/>    beforeEach((done) =&gt; {<br/>        chai<br/>        .request(tools.service)<br/>        .delete("/uploads/test_image_upload.png")<br/>        .end(() =&gt; {<br/>            return done();<br/>        });<br/>    });<br/><br/>    it ("should accept a PNG image", function (done) {<br/>        chai<br/>        .request(tools.service)<br/>        .post("/uploads/test_image_upload.png")<br/>        .set("Content-Type", "image/png")<br/>        .send(tools.sample)<br/>        .end((err, res) =&gt; {<br/>            chai.expect(res).to.have.status(200);<br/>            chai.expect(res.body).to.have.status("ok");<br/><br/>            return done();<br/>        });<br/>    });<br/>});</pre>
<p>We start by first including the <kbd>chai</kbd> modules and our <kbd>tools</kbd> file:</p>
<pre>const chai  = require("chai");<br/>const http  = require("chai-http");<br/>const tools = require("../tools");<br/><br/>chai.use(http);</pre>
<p>Then, we describe our test file as <kbd>Uploading image</kbd>:</p>
<pre>describe("Uploading image", () =&gt; {</pre>
<p>We'll add the different use cases we can think of, related to the uploading of images.</p>
<p>Inside, we use <kbd>beforeEach</kbd>, which is a <kbd>mocha</kbd> method that will be called before every test in this file. Remember, we want our tests to be consistent, so we add this method to remove our image before running every test. We don't care whether the image exists:</p>
<pre>beforeEach((done) =&gt; {<br/>    chai<br/>    .request(tools.service)<br/>    .delete("/uploads/test_image_upload.png")<br/>    .end(() =&gt; {<br/>        return done();<br/>    });<br/>});</pre>
<p>Look how we use the <kbd>tools.service</kbd>, which points to our microservice. If, later on, we change the name or somehow make it more complex, we just need to change the <kbd>tools</kbd> file, and everything should work.</p>
<p>Then, we add our first <kbd>integration</kbd> file's test – a simple image upload:</p>
<pre>it("should accept a PNG image", (done) =&gt; {<br/>    chai<br/>    .request(tools.service)<br/>    .post("/uploads/test_image_upload.png")<br/>    .set("Content-Type", "image/png")<br/>    .send(tools.sample)<br/>    .end((err, res) =&gt; {<br/>        chai.expect(res).to.have.status(200);<br/>        chai.expect(res.body).to.have.status("ok");<br/><br/>        return done();<br/>    });<br/>});</pre>
<p>It checks whether the HTTP response code is <kbd>200</kbd> and if the response body, which is a JSON structure, has the status property set to <kbd>ok</kbd>. And we're done!</p>
<p>Let's run our test suite again and see how it goes.</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/c66ba039-aeab-40c5-b50d-244fbe83dd63.png" width="1934" height="460"/></div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Covering all code</h1>
                </header>
            
            <article>
                
<p>For now, let's focus on adding coverage to our code. It's important to have it covered as much as possible when it's still just a small service. If we start adding tests and coverage when it's already big, you'll be frustrated, and it will be hard to find the motivation to cover it all.</p>
<p>This way, you'll find it rewarding to cover it in the beginning and keep the coverage percentage as high as possible along with code evolution.</p>
<p>Let's get back to our image upload test, and add another test:</p>
<pre>it("should deny duplicated images", (done) =&gt; {<br/>    chai<br/>    .request(tools.service)<br/>    .post("/uploads/test_image_upload.png")<br/>    .set("Content-Type", "image/png")<br/>    .send(tools.sample)<br/>    .end((err, res) =&gt; {<br/>        chai.expect(res).to.have.status(200);<br/>        chai.expect(res.body).to.have.status("ok");<br/><br/>        chai<br/>        .request(tools.service)<br/>        .post("/uploads/test_image_upload.png")<br/>        .set("Content-Type", "image/png")<br/>        .send(tools.sample)<br/>        .end((err, res) =&gt; {<br/>            chai.expect(res).to.have.status(200);<br/>            chai.expect(res.body).to.have.status("error");<br/>            chai.expect(res.body).to.have.property("code", <br/>            "ER_DUP_ENTRY");<br/><br/>            return done();<br/>        });<br/>    });<br/>});</pre>
<p>This will upload the same image twice in a row and we should receive an error from the database saying there's a duplicate. Let's run the tests again:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/57c1f00d-fe1e-45eb-9108-2e0099655ebd.png" width="1999" height="806"/></div>
<p>Now, let's open the initial page  of the coverage report:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/0dea63b8-dc21-4397-8f1d-578c481602a3.png" width="1999" height="1155"/></div>
<p>Notice that our file is no longer in a red background. This means the statement coverage has reached <em>50%</em>. Let's click on our file and see how our image upload method is covered:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/cac710e1-c7a0-4606-baab-c61c84cce671.png" width="1999" height="1171"/></div>
<p>It's complete! We can now move on. Just a reminder before we move to another method: having full coverage does not mean there are no bugs. That's something you need to understand. You might have a use case that you're not expecting, and so, you have no code for it, so there's no obvious coverage.</p>
<p>For example, the <kbd>bodyparser</kbd> module will not limit the type of content. If we upload a text file with an image name on it, our code will accept it and store it in the database without noticing. Think of this use case as your homework, and try to create a test to cover that use case and then fix the code.</p>
<p>Let's move to the next method we see after our upload method: the image check on <em>line 67</em>. Let's create a new integration test file called <kbd>image-check.js</kbd>, and add a simple test:</p>
<pre>const chai = require("chai");<br/>const http = require("chai-http");<br/>const tools = require("../tools");<br/><br/>chai.use(http);<br/><br/>describe("Checking image", () =&gt; {<br/>    beforeEach((done) =&gt; {<br/>        chai<br/>        .request(tools.service)<br/>        .delete("/uploads/test_image_check.png")<br/>        .end(() =&gt; {<br/>            return done();<br/>        });<br/>    });<br/><br/>    it("should return 404 if it doesn't exist", (done) =&gt; {<br/>        chai<br/>        .request(tools.service)<br/>        .head("/uploads/test_image_check.png")<br/>        .end((err, res) =&gt; {<br/>            chai.expect(res).to.have.status(404);<br/><br/>            return done();<br/>        });<br/>    });<br/><br/>    it("should return 200 if it exists", (done) =&gt; {<br/>        chai<br/>        .request(tools.service)<br/>        .post("/uploads/test_image_check.png")<br/>        .set("Content-Type", "image/png")<br/>        .send(tools.sample)<br/>        .end((err, res) =&gt; {<br/>            chai.expect(res).to.have.status(200);<br/>            chai.expect(res.body).to.have.status("ok");<br/><br/>            chai<br/>            .request(tools.service)<br/>            .head("/uploads/test_image_check.png")<br/>            .end((err, res) =&gt; {<br/>                chai.expect(res).to.have.status(200);<br/><br/>                return done();<br/>            });<br/>        });<br/>    });<br/>});</pre>
<p>Let's run the test suite:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/4309bf36-5162-41b3-befb-d5c6f82a7ab7.png" width="1999" height="901"/></div>
<p>We can see our console report is getting bigger. As we're creating new integration test files and having a description for each one, <kbd>mocha</kbd> writes a nice tree view showing how the tests run. On the bottom, we can see the coverage report:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/bd63eccf-479c-4101-b6ce-333f96949c63.png" width="1674" height="1226"/></div>
<p>Looking at the check method, we see it's now fully covered. This one was very simple.</p>
<p>We're still in the middle of statement coverage as our top method; the image manipulation one is almost half of our code. This means that when we start covering it, the coverage will significantly rise.</p>
<p>Let's create an <kbd>integration</kbd> test for it:</p>
<pre>const chai = require("chai");<br/>const http = require("chai-http");<br/>const tools = require("../tools");<br/><br/>chai.use(http);<br/><br/>describe("Downloading image", () =&gt; {<br/>    beforeEach((done) =&gt; {<br/>        chai<br/>        .request(tools.service)<br/>        .delete("/uploads/test_image_download.png")<br/>        .end(() =&gt; {<br/>            chai<br/>            .request(tools.service)<br/>            .post("/uploads/test_image_download.png")<br/>            .set("Content-Type", "image/png")<br/>            .send(tools.sample)<br/>            .end((err, res) =&gt; {<br/>                chai.expect(res).to.have.status(200);<br/>                chai.expect(res.body).to.have.status("ok");<br/><br/>                return done();<br/>            });<br/>        });<br/>    });<br/><br/>    it("should return the original image size if no parameters given", <br/>    (done) =&gt; {<br/>        chai<br/>        .request(tools.service)<br/>        .get("/uploads/test_image_download.png")<br/>        .end((err, res) =&gt; {<br/>            chai.expect(res).to.have.status(200);<br/>            chai.expect(res.body).to.have.length(tools.sample.length);<br/><br/>            return done();<br/>        });<br/>    });<br/>});</pre>
<p>Before each test, we're deleting the image (if it exists) and then uploading a fresh sample one. Then, for each test, we'll download it and test the output according to what we asked for.</p>
<p>Let's try and run it:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/280f19a6-d82f-4a90-80d9-90ee36f3d1ab.png" width="1999" height="993"/></div>
<p>Well, that was unexpected. The test fails because our length check does not match. This is actually a good example of something we just notice when we start to execute testing.</p>
<p>What happens is that, when we request an image, we use the <kbd>sharp</kbd> module to make any manipulation on the image, according to query parameters. In this case, we're not asking for any manipulation, but when we output the image (through <kbd>sharp</kbd>), it actually returns the same image in size, but perhaps with a little bit less quality, or maybe it just knows how to better encode our image and remove data from the file that is not needed.</p>
<p>We don't know exactly, but let's assume we want the original image, untouched. We need to change our download method. Let's assume that if no query parameters are defined at all, we just return the original image. Let's add a condition to the top of our method:</p>
<pre>if (Object.keys(req.query).length === 0) {<br/>    db.query("UPDATE images " +<br/>             "SET date_used = UTC_TIMESTAMP " +<br/>             "WHERE id = ?",<br/>             [ req.image.id ]);<br/><br/>    res.setHeader("Content-Type", "image/" + <br/>    path.extname(req.image.name).substr(1));<br/><br/>    return res.end(req.image.data);<br/>}</pre>
<p>If we run  it now, we should have no failures:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/352b4409-20b4-4d2e-b195-03270611ab1e.png" width="1999" height="976"/></div>
<p>Our statement coverage did not rise much because we actually created a condition on top of the method and returned immediately, so our previous method is still untested:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/31f51911-414b-4152-b68a-182436f3abf6.png" width="1775" height="1243"/></div>
<p>Looking at <em>line 78,</em> you should see a new mark, an <kbd>E</kbd> that means that the condition in that line never executed the <kbd>else</kbd> statement, which is the rest of our code. Let's add a test to this integration and resize our image.</p>
<p>We will need <kbd>sharp</kbd> to help us check whether the results are correct. Let's include it on the top of our file:</p>
<pre>const sharp = require("sharp");</pre>
<p>Then, add a resize test:</p>
<pre>it("should be able to resize the image as we request", (done) =&gt; {<br/>    chai<br/>    .request(tools.service)<br/>    .get("/uploads/test_image_download.png?width=200&amp;height=100")<br/>    .end((err, res) =&gt; {<br/>        chai.expect(res).to.have.status(200);<br/><br/>        let image = sharp(res.body);<br/><br/>        image<br/>        .metadata()<br/>        .then((metadata) =&gt; {<br/>            chai.expect(metadata).to.have.property("width", 200);<br/>            chai.expect(metadata).to.have.property("height", 100);<br/><br/>            return done();<br/>        });<br/>    });<br/>});</pre>
<p>Let's run our test suite:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/d947fad9-1cc1-4db9-b3eb-482e75f78d37.png" width="1999" height="998"/></div>
<p>It now looks very good. From the console report, we can see some green. Let's look at the front page of the coverage report:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/6581e47d-6b3c-47b5-b3c3-9f70f6f8e583.png" width="1999" height="1154"/></div>
<p>We see green here as well. Having more than <em>80%</em> coverage is good, but we can still go further. Let's see the file:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/e3ff1101-6b82-4765-86ab-f6f784086d7b.png" width="1999" height="1167"/></div>
<p>It's more or less covered. We still need to cover all the effects. We can actually run them all at once. The first two conditions also have an <kbd>E</kbd> marker, but that should disappear after adding a test without resizing. Let's add it:</p>
<pre>it("should be able to add image effects as we request", (done) =&gt; {<br/>    chai<br/>    .request(tools.service)<br/>    .get("/uploads/test_image_download.png?<br/>    flip=y&amp;flop=y&amp;greyscale=y&amp;blur=10&amp;sharpen=10")<br/>    .end((err, res) =&gt; {<br/>        chai.expect(res).to.have.status(200);<br/><br/>        return done();<br/>    });<br/>});</pre>
<p>Looking at our report now, we see the coverage is almost complete:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/58b6d4de-05c0-40e3-8df5-50e38d241898.png" width="1999" height="1168"/></div>
<p>To cover those yellow nulls there, we need to resize the image with only <kbd>width</kbd> or <kbd>height</kbd>. We can add two tests for those:</p>
<pre>it("should be able to resize the image width as we request", (done) =&gt; {<br/>    chai<br/>    .request(tools.service)<br/>    .get("/uploads/test_image_download.png?width=200")<br/>    .end((err, res) =&gt; {<br/>        chai.expect(res).to.have.status(200);<br/><br/>        let image = sharp(res.body);<br/><br/>        image<br/>        .metadata()<br/>        .then((metadata) =&gt; {<br/>            chai.expect(metadata).to.have.property("width", 200);<br/><br/>            return done();<br/>        });<br/>    });<br/>});</pre>
<p>Add a similar one for the <kbd>height</kbd>, and run the test suite. You should not see the statement coverage go up, only the branch coverage:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/4f13bae9-3dae-49e6-8f9d-0f27711e67e3.png" width="1999" height="1145"/></div>
<p>The only method missing is the statistics method. This one is simple. We could eventually run a more specific test, by asking statistics, making a change such as an upload, and asking for statistics again to compare. I'll leave that to you. Let's just add a simple request test:</p>
<pre>const chai = require("chai");<br/>const http = require("chai-http");<br/>const tools = require("../tools");<br/><br/>chai.use(http);<br/><br/>describe("Statistics", () =&gt; {<br/>    it("should return an object with total, size, last_used and <br/>    uptime", (done) =&gt; {<br/>        chai<br/>        .request(tools.service)<br/>        .get("/stats")<br/>        .end((err, res) =&gt; {<br/>            chai.expect(res).to.have.status(200);<br/>            chai.expect(res.body).to.have.property("total");<br/>            chai.expect(res.body).to.have.property("size");<br/>            chai.expect(res.body).to.have.property("last_used");<br/>            chai.expect(res.body).to.have.property("uptime");<br/><br/>            return done();<br/>        });<br/>    });<br/>});</pre>
<p>Now, running our test suite should give all green:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/d7410c16-009c-45b0-b94e-7630e2685d0d.png" width="1999" height="1156"/></div>
<p>We see there are only two lines uncovered: <kbd>29.121</kbd>. The first one is our timer and the second one is on the statistics method. Let's refresh our HTML report:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/63b758d2-a4e9-422c-bb9e-815b5e3bb32e.png" width="1999" height="1156"/></div>
<p>This is rewarding; we have almost <em>100%</em> coverage. There's only one function not covered, which is our timer. And, there are only tree statements, which also represent the three branches, that aren't covered, but those aren't actually that important.</p>
<p>What is important is to keep this high coverage mark during the course of our development.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Mocking our services</h1>
                </header>
            
            <article>
                
<p>It's not at all uncommon to have parts of your service that are harder to test. Some, or most, of those parts are error-related conditions, where it's hard to make an external service such as a database engine return an error that will rarely occur during normal execution.</p>
<p>To be able to test, or at least simulate these kinds of events, we need to mock our services. There are a couple of options around, and Sinon is the most commonly used one in the Node.js ecosystem. This framework provides more than mocking; it also provides the following:</p>
<ul>
<li><strong>Spies</strong>: Which monitor function calls and record arguments passed, the returned value and other properties</li>
<li><strong>Stubs</strong>: Which are enhanced spies with a pre-programmed behavior, helping us drive the execution into a pre-determined path (allowing us to mock a behavior)</li>
</ul>
<p>Sinon also allows us to bend time, by virtually changing the service perception of time, and to be able to test timed interval calls (remember our interval timer?). With this in mind, let's see if we can make our microservice reach <em>100%</em> test coverage.</p>
<p>Let's start by installing the framework, as we did with <kbd>chai</kbd>:</p>
<pre><strong>npm install --save-dev sinon</strong></pre>
<p>Now, let's add a test for the image deletion. This method is tested through the other tests and that's why we didn't need to add it before, but now that we want to fully test it, let's add a basic test file called <kbd>image-delete.js</kbd>, with the following content:</p>
<pre>const chai = require("chai");<br/>const sinon = require("sinon");<br/>const http = require("chai-http");<br/>const tools = require("../tools");<br/><br/>chai.use(http);<br/><br/>describe.only("Deleting image", () =&gt; {<br/>    beforeEach((done) =&gt; {<br/>        chai<br/>        .request(tools.service)<br/>        .delete("/uploads/test_image_delete.png")<br/>        .end(() =&gt; {<br/>            return done();<br/>        });<br/>    });<br/><br/>    it("should return 200 if it exists", (done) =&gt; {<br/>        chai<br/>        .request(tools.service)<br/>        .post("/uploads/test_image_delete.png")<br/>        .set("Content-Type", "image/png")<br/>        .send(tools.sample)<br/>        .end((err, res) =&gt; {<br/>            chai.expect(res).to.have.status(200);<br/>            chai.expect(res.body).to.have.status("ok");<br/><br/>            chai<br/>            .request(tools.service)<br/>            .delete("/uploads/test_image_delete.png")<br/>            .end((err, res) =&gt; {<br/>                chai.expect(res).to.have.status(200);<br/><br/>                return done();<br/>            });<br/>        });<br/>    });<br/>});</pre>
<p>Notice that I added the Sinon dependency on top, although I'm not using it just yet. You may run the tests again, but you shouldn't notice any difference.</p>
<p>We'll need to change the database behavior, so let's export a reference to it, so as to be able to access it from the tests. Add the following line in our microservice file before connecting to the database:</p>
<pre>app.db = db;</pre>
<p>Now, add another test to that file:</p>
<pre>it("should return 500 if a database error happens", (done) =&gt; {<br/>    chai<br/>    .request(tools.service)<br/>    .post("/uploads/test_image_delete.png")<br/>    .set("Content-Type", "image/png")<br/>    .send(tools.sample)<br/>    .end((err, res) =&gt; {<br/>        chai.expect(res).to.have.status(200);<br/>        chai.expect(res.body).to.have.status("ok");<br/><br/>        let query = sinon.stub(tools.service.db, "query");<br/><br/>        query<br/>        .withArgs("DELETE FROM images WHERE id = ?")<br/>        .callsArgWithAsync(2, new Error("Fake"));<br/><br/>        query<br/>        .callThrough();<br/><br/>        chai<br/>        .request(tools.service)<br/>        .delete("/uploads/test_image_delete.png")<br/>        .end((err, res) =&gt; {<br/>            chai.expect(res).to.have.status(500);<br/><br/>            query.restore();<br/><br/>            return done();<br/>        });<br/>    });<br/>});</pre>
<p>What we're doing is uploading an image, but, before requesting to delete it, we create a <kbd>stub</kbd> on the <kbd>db.query</kbd> method. We then inform Sinon that when the <kbd>stub</kbd> is called with the first argument with <kbd>DELETE</kbd>, we want it to asynchronously call the third argument (counting starts at 0) with a fake error. For any other call, we want it to just pass through.</p>
<p>Then, after deleting the image, we check that we received an HTTP <kbd>500</kbd> error code and restore the <kbd>stub</kbd> to the original function, ensuring that the other tests pass.</p>
<p>We're able to test this because <kbd>mocha</kbd> runs tests in serial; otherwise, we would need to do some gymnastics to ensure that we wouldn't interfere with the other tests.</p>
<p>Now, open the previously created test file, <kbd>image-stats.js</kbd>, include Sinon on the top, and add the following test:</p>
<pre>it("should return 500 if a database error happens", (done) =&gt; {<br/>    let query = sinon.stub(tools.service.db, "query");<br/><br/>    query<br/>    .withArgs("SELECT COUNT(*) total, SUM(size) size, MAX(date_used) <br/>    last_used FROM images")<br/>    .callsArgWithAsync(1, new Error("Fake"));<br/><br/>    query<br/>    .callThrough();<br/><br/>    chai<br/>    .request(tools.service)<br/>    .get("/stats")<br/>    .end((err, res) =&gt; {<br/>        chai.expect(res).to.have.status(500);<br/><br/>        query.restore();<br/><br/>        return done();<br/>    });<br/>});</pre>
<p>We're now over 97% coverage. Let's bend time and test our timer. Create a new test file called <kbd>image-delete-old.js</kbd>, and add the following content:</p>
<pre>const chai = require("chai");<br/>const sinon = require("sinon");<br/>const http = require("chai-http");<br/>const tools = require("../tools");<br/><br/>chai.use(http);<br/><br/>describe("Deleting older images", () =&gt; {<br/>    let clock = sinon.useFakeTimers({ shouldAdvanceTime : true });<br/><br/>    it("should run every hour", (done) =&gt; {<br/>        chai<br/>        .request(tools.service)<br/>        .get("/stats")<br/>        .end((err, res) =&gt; {<br/>            chai.expect(res).to.have.status(200);<br/><br/>            clock.tick(3600 * 1000);<br/>            clock.restore();<br/><br/>            return done();<br/>        });<br/>    });<br/>});</pre>
<p>In this test, we're replacing the global timer functions (<kbd>setTimeout</kbd>and <kbd>setInterval</kbd>) with fake timers. We then make a simple call to statistics, and then advance time by one hour (the tick call), and then finish.</p>
<p>Now, run the tests and see the results:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/b344f959-c4d5-4473-97e7-f295bc1f4cce.png" width="1926" height="1179"/></div>
<p>We now reach <em>100% coverage</em> on functions and lines. There's only one branch, with one statement missing. It's the possibility of a connection error:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/87727f4f-fbfb-42a5-b895-b80a691133ac.png" width="1920" height="1204"/></div>
<p>I'll leave it to you to figure it out how to mock that.</p>
<div class="packt_infobox">Remember that if you successfully mock the <kbd>connect</kbd> method, you'll also need to handle the throw.</div>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Tests allow us to ensure a certain code quality level. It's very important to include tests from the very beginning, while the code is simple, to ensure that we keep tests updated and avoid regressions to the expected behavior.</p>
<p>It's very rewarding when we see that our code has a very high test coverage. This feeling forces you to keep that high mark and indirectly maintains good code quality.</p>


            </article>

            
        </section>
    </div>



  </body></html>