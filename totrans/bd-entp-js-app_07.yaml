- en: Modularizing Our Code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we followed a TDD workflow and implemented the first
    endpoint of our API—the Create User endpoint. We wrote our End-to-End (E2E) tests
    in Gherkin, ran them using the *Cucumber* test runner, and used them to drive
    development. Everything works, but all the code is contained within a single, monolithic
    file (`src/index.js`); this is not modular and makes our project hard to maintain,
    especially as we add more endpoints. Therefore, in this chapter, we will be separating
    our application code into smaller modules. This will allow us to write **unit** and **integration
    tests** for them in [Chapter 8](38b85b06-d091-4751-a2ac-32ca0f98f26b.xhtml), *Writing
    Unit/Integration Tests*.
  prefs: []
  type: TYPE_NORMAL
- en: 'By following this chapter, you will be able to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Break down large blocks of code into smaller modules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define and validate JavaScript objects with **JSON Schema** and Ajv
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modularizing our code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you take a look inside the `src/index.js` file, you'll see that there are
    three top-level middleware functions—`checkEmptyPayload`, `checkContentTypeIsSet`,
    and `checkContentTypeIsJson`—as well as an anonymous error handler function. These
    are prime candidates that we can extract into their own modules. So, let's get
    started!
  prefs: []
  type: TYPE_NORMAL
- en: Modularizing our middleware
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s carry out this refactoring process in a new branch called `create-user/refactor-modules`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, create a directory at `src/middlewares`; this is where we will store
    all of our middleware modules. Inside it, create four files—one for each middleware
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, move the middleware functions from `src/index.js` into their corresponding
    file. For example, the `checkEmptyPayload` function should be moved to `src/middlewares/check-empty-payload.js`.
    Then, at the end of each module, export the function as the default export. For
    example, the `error-handler.js` file would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, go back to `src/index.js` and import these modules to restore the previous
    behavior:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now, run our E2E tests again to make sure that we haven't broken anything. Also,
    don't forget to commit your code!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: By pulling out the middleware functions, we've improved the readability of our `src/index.js` file.
    The intention and flow of our code is apparent because we've named our functions
    properly—you understand what the functions do from their names. Next, let's do
    the same with our request handler.
  prefs: []
  type: TYPE_NORMAL
- en: Modularizing our request handlers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At the moment, we only have one request handler for our `POST /users` endpoint,
    but by the end of this chapter, we will have implemented many more. Defining them
    all inside the `src/index.js` file would lead to a huge, unreadable mess. Therefore,
    let''s define each request handler as its own module. Let''s begin by creating
    a file at `src/handlers/users/create.js` and extract the Create User request handler
    into it. Previously, the request handler was an anonymous arrow function; now
    that it''s in its own module, let''s give it a name of `createUser`. Lastly, `export` the
    function in the same manner as we did with the middleware. You should end up with
    something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, import the `createUser` handler back into `src/index.js` and use it inside `app.post`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'However, our request handler requires an Elasticsearch client to work. One
    way to resolve this would be to move the following lines to the top of the `src/handlers/users/create.js` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: However, thinking ahead, since we will have many request handlers, we shouldn't
    instantiate a separate instance of the client for each handler. Instead, we should
    create one Elasticsearch client instance and pass it by reference into each request
    handler.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, let''s create a utility function at `src/utils/inject-handler-dependencies.js` that
    takes in a request handler function and the Elasticsearch client, and returns
    a new function that will call the request handler, passing in the client as one
    of the parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This is an example of a **higher-order function**, which is a function that
    operates on, or returns, other functions. This is possible because functions are
    a type of object in JavaScript, and thus are treated as **first-class citizens**.
    This means you can pass a function around just like any other object, even as
    function parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use it, import it into our `src/index.js` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, instead of using the `createUser` request handler directly, pass in the
    handler returned from `injectHandlerDependencies`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, update the request handler itself to make use of the client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Once again, run the E2E tests to make sure we have not introduced a bug, and
    then commit our changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The single responsibility principle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have pulled out the request handler and migrated it into its own module.
    However, it is not as modular as it could be; at the moment, the handler serves
    three functions:'
  prefs: []
  type: TYPE_NORMAL
- en: Validates the request
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writes to the database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generates the response
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have studied object-orientated design principles, you will undoubtedly
    have come across the **SOLID** principle, which is a mnemonic acronym for **single
    responsibility**, **open/closed**, **Liskov substitution**, **interface segregation**,
    and **dependency inversion**.
  prefs: []
  type: TYPE_NORMAL
- en: The single responsibility principle states that a module should perform one,
    and only one, function. Therefore, we should pull out the validation and database
    logic into their own dedicated modules.
  prefs: []
  type: TYPE_NORMAL
- en: Decoupling our validation logic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: However, we cannot directly copy our existing validation code from `src/handlers/users/create.js` without
    modification. This is because the validation code directly modifies the response
    object, `res`, which means that the validation logic and response logic are **tightly
    coupled** to each other.
  prefs: []
  type: TYPE_NORMAL
- en: To resolve this, we must define a common **interface** between our validation
    logic and our response handler. Instead of modifying the response directly, the
    validation logic will produce an object that conforms to this interface, and the
    response handler will consume this object to produce an appropriate response.
  prefs: []
  type: TYPE_NORMAL
- en: When a request fails validation, we can consider it as a type of error, because
    the client provided an incorrect payload. Therefore, we can extend the native `Error` object
    to create a new `ValidationError` object, which will act as the interface. We
    don't have to provide the status or set the headers, as that's the job of our
    request handlers. We just need to make sure an instance of `ValidationError` will
    contain the `message` property. Since this is the default behavior of `Error`,
    we don't need to do much else.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the ValidationError interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create a new file at `src/validators/errors/validation-error.js` and add a
    class definition for `ValidationError`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code extends the `Error` class to create its own class. We need
    to do this in order to distinguish between validation errors (which should return
    a `400` response) and errors in our code (which should return a `500` response).
  prefs: []
  type: TYPE_NORMAL
- en: Modularizing our validation logic
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, create a new file at `src/validators/users/create.js` and copy the validation
    blocks from our request handlers into the file, wrapping it inside its own function
    and exporting that function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, import the `ValidationError` class from `src/validators/errors/validation-error.js`.
    Then, instead of modifying the `res` object (which is not in scope), return instances
    of `ValidationError` instead. The final `src/validators/users/create.js` file may
    look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to import this function into our request handler and use it to
    validate our Create User request payload. If the validation result is an instance
    of `ValidationError`, then generate the `400` response; otherwise, carry on with
    indexing the user document:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: By providing a common interface, we have successfully decoupled our validation
    logic from the rest of the code. Now, run the E2E tests, and if they're green,
    commit our changes!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Creating engines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although the bulk of the validation logic has been abstracted into a separate
    module, the request handler is still processing the results of the validator,
    interacting with the database, and sending back the response; it still does not
    comply with the single responsibility principle.
  prefs: []
  type: TYPE_NORMAL
- en: The request handler's only job should be to pass the request to an *engine*,
    which will process the request, and respond with the result of the operation.
    Based on the result of the operation, the request handler should then issue an
    appropriate response to the client.
  prefs: []
  type: TYPE_NORMAL
- en: So, let's create a new directory at `src/engines/users` and add a `create.js` file;
    inside, define a `create` function and `export` it. This `create` function will
    validate our request and write to the database, returning the result of the operation
    back to the request handler. Since writing to the database is an asynchronous
    operation, our `create` function should return a promise.
  prefs: []
  type: TYPE_NORMAL
- en: 'Try implementing the `create` function yourself, and check back here for our
    implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, in `src/handlers/users/create.js`, import the engine module and use the
    result to generate the response. The final file should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the tests to make sure that they all still pass, and then commit these
    changes to Git:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Fantastic! We have now refactored our code to be more modular and ensured that
    each module is decoupled from the others!
  prefs: []
  type: TYPE_NORMAL
- en: Adding a user profile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If we look back at our requirements for creating a user, there's one that is
    still unfinished – "The user may optionally provide a profile; otherwise, an empty
    profile will be created for them". So, let's implement this requirement!
  prefs: []
  type: TYPE_NORMAL
- en: Writing a specification as a test
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will begin development by first writing E2E tests. In the previous chapter,
    we already tested a scenario where the profile is not supplied. In these new E2E
    tests, we will add two more scenarios where the client provides a profile object—one
    using an invalid profile, the other a valid one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we must first decide what constitutes a valid profile; in other
    words, what should the structure of our profile object be? There are no right
    or wrong answers, but for this book, we will use the following structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: All of the fields are optional, but if they are provided, they must be of the
    correct type.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with testing for the invalid profile scenario. In `spec/cucumber/features/users/create/main.feature`,
    add the following scenario outline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: These examples cover the cases where properties have the incorrect type, and/or
    unsupported properties were provided.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we run these tests, the `And attaches <payload> as the payload` shows
    up as undefined. This step definition should allow us to attach any arbitrary
    payload to the request. Try implementing this inside `spec/cucumber/steps/index.js`,
    and check your solution against the following one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Run the E2E tests again, and this time, the newly defined tests should fail. Red.
    Green. Refactor. We have now written a failing test; the next step is to implement
    the feature so that it passes the tests.
  prefs: []
  type: TYPE_NORMAL
- en: Schema-based validation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our tests are failing because our API is actually writing the (invalid) profile
    objects into the database; conversely, we expect our API to respond with a `400` error.
    Therefore, we must implement additional validation steps for the `profile` subdocument.
  prefs: []
  type: TYPE_NORMAL
- en: Currently, we are using `if` conditional blocks to validate the email and password
    fields. If we use the same approach for our new user object, we'd have to write
    a very long list of `if` statements, which is bad for readability. One may also
    argue that our current implementation of the `validation` function is already
    quite unreadable, because it's not immediately obvious what the user object should
    look like. Therefore, we need to find a better approach.
  prefs: []
  type: TYPE_NORMAL
- en: A more declarative way of validating is to use a **schema**, which is just a
    formal way of describing a data structure. After a schema is defined, we can use
    validation libraries to test the request payload against the schema, and respond
    with an appropriate error message if it does not pass.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, in this section, we are going to use a schema to validate our profile
    object, and then refactor all of our existing validation code to use schema-based
    validation as well.
  prefs: []
  type: TYPE_NORMAL
- en: Types of schema
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most common schema used in JavaScript is **JSON Schema** ([json-schema.org](http://json-schema.org/)).
    To use it, you first define a schema written in JSON, and then use a schema validation
    library to compare the object of interest with the schema to see if they match.
  prefs: []
  type: TYPE_NORMAL
- en: 'But before we explain the syntax of JSON Schema, let''s take a look at two
    major JavaScript libraries that support schema validation while not using JSON
    Schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '`joi` ([https://github.com/hapijs/joi](https://github.com/hapijs/joi)) allows
    you to define requirements in a composable, chainable manner, which means that
    the code is very readable. It has over 9,000 stars on GitHub and is depended on
    by over 94,000 repositories and 3,300 packages:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '`validate.js` ([https://validatejs.org/](https://validatejs.org/)) is another
    very expressive validation library, and allows you to define your own custom validation
    function. It has 1,700 stars on GitHub, and is depended on by over 2,700 repositories
    and 290 packages:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Picking an object schema and validation library
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So out of the three options, which one should we use? To answer this question,
    we should first consider their **interoperability** and **expressiveness**.
  prefs: []
  type: TYPE_NORMAL
- en: Interoperability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Interoperability has to do with how easy is it for different frameworks, libraries,
    and languages to consume the schema. In this criterion, JSON Schema wins hands
    down.
  prefs: []
  type: TYPE_NORMAL
- en: The benefits of using a standardized schema such as JSON Schema is that the
    same schema file may be used by multiple code bases. For example, as our platform
    grows, we may have multiple internal services that each need to validate user
    data; some may even be written in another language (for example, Python).
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of having multiple definitions of the user schema in different languages,
    we can use the same schema file, as there are JSON Schema validators for all major
    languages:'
  prefs: []
  type: TYPE_NORMAL
- en: Swift: `JSONSchema.swift` ([https://github.com/kylef-archive/JSONSchema.swift](https://github.com/kylef-archive/JSONSchema.swift))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Java: `json-schema-validator` ([github.com/java-json-tools/json-schema-validator](https://github.com/java-json-tools/json-schema-validator))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python: `jsonschema` ([pypi.python.org/pypi/jsonschema](https://pypi.python.org/pypi/jsonschema))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Go: `gojsonschema` ([github.com/xeipuuv/gojsonschema](https://github.com/xeipuuv/gojsonschema))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can view the full list of validators at [json-schema.org/implementations.html](http://json-schema.org/implementations.html).
  prefs: []
  type: TYPE_NORMAL
- en: Expressiveness
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'JSON Schema supports many validation keywords and data formats, as defined
    in the IETF memo *JSON Schema Validation: A Vocabulary for Structu**ral Validation
    of JSON* ([json-schema.org/latest/json-schema-validation.html](http://json-schema.org/latest/json-schema-validation.html));
    however, due to the restrictions of JSON itself, JSON Schema lacks the ability
    to define custom validation logic in the form of functions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, JSON Schema does not provide a way to express the following logic:
    "if the `age` property is below `18`, then the `hasParentalConsent` property must
    be set to `true`." Thus, if you want to perform more complicated checks, these
    must be done as a separate function in JavaScript. Alternatively, some JSON Schema-based
    validation libraries extend the JSON Schema syntax and allow developers to implement
    custom validation logic. For instance, the `ajv` validation library supports defining
    custom keywords.'
  prefs: []
  type: TYPE_NORMAL
- en: For non-JSON Schema validation libraries, both `joi` and `validate.js` allow
    you to define custom validation functions.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, although JSON Schema is less expressive in theory, in practice, all
    solutions have the same level of expressiveness and flexibility. Because JSON
    Schema is a well-established standard and also more interoperable, that's the
    solution we will use to validate our payloads.
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing this book, the JSON Schema specification is still in
    draft (specifically draft-07, which can be found at [tools.ietf.org/html/draft-handrews-json-schema-00](https://tools.ietf.org/html/draft-handrews-json-schema-00)).
    It is likely that the final specification will be slightly different to the one
    described here. Please refer to the latest version at [json-schema.org](http://json-schema.org/).
  prefs: []
  type: TYPE_NORMAL
- en: Creating our profile schema
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So, let's construct the schema for our user profile object using JSON Schema.
    To do that, we must first understand its syntax.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing to note is that a JSON Schema is itself a JSON object. Therefore,
    the simplest JSON Schema is simply an empty object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This empty object schema will allow any type of data, so it is pretty much useless.
    For it to be useful, we must describe the type of data we expect. This can be
    done through the `type` keyword. The `type` keyword expects its value to be either
    a string, where only one type is allowed, or an array, where any types specified
    in the array are allowed.
  prefs: []
  type: TYPE_NORMAL
- en: 'We expect our input for the user profile object to only be objects, and so
    we can specify a `type` of `"object"`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '`type` is the most basic keyword. There are many other common keywords that
    are applicable to all types, such as `title`; there are also type-specific keywords,
    such as `maximum`, which only applies to data of type `number`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For object types, we can use the type-specific keyword `properties` to describe
    what properties we expect our object to contain. The value of `properties` must
    be an object, with property names as the key and another valid JSON Schema, called
    a **sub-schema**, as the value. In our case, we expect the `bio` and `summary` properties
    to be of type `string`, and the `name` property to have an `object` type, so our
    schema would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Rejecting additional properties
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Lastly, we will set the object-specific `additionalProperties` keyword to `false`.
    This will reject objects that contain keys not already defined under `properties` (for
    example, `isAdmin`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Having `additionalProperties` set to `false` is really important, especially
    for Elasticsearch. This is because Elasticsearch uses a technique called **dynamic
    mapping** to infer the data types of its documents, and uses it to generate its
    indexes.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic mapping in Elasticsearch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To create a table inside a relational database, you must specify a **model**,
    which stores information about the name and data type of each column. This information
    must be supplied before any data is inserted.
  prefs: []
  type: TYPE_NORMAL
- en: Elasticsearch has a similar concept called **type mapping**, which stores information
    about the name and data type of each property in the document. The difference
    is that we don't have to supply the type mapping before we insert any data; in
    fact, we don't have to supply it *at all*! This is because when Elasticsearch
    tries to infer the data type from the documents being indexed, it will add it
    to the type mapping. This automatic detection of data types and addition to type
    mapping is what we refer to as dynamic mapping.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic mapping is a convenience provided by Elasticsearch, but it also means
    we must sanitize and validate our data before indexing it into Elasticsearch.
    If we allow users to add arbitrary fields to their documents, the type mapping
    may infer the wrong data type, or become littered with irrelevant fields. Moreover,
    since Elasticsearch indexes every field by default, this can lead to many irrelevant
    indices.
  prefs: []
  type: TYPE_NORMAL
- en: You can read more about dynamic mapping at [https://www.elastic.co/guide/en/elasticsearch/guide/current/dynamic-mapping.html](https://www.elastic.co/guide/en/elasticsearch/guide/current/dynamic-mapping.html).
  prefs: []
  type: TYPE_NORMAL
- en: Adding specificity to a sub-schema
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At the moment, the only constraint we placed on the `name` property is that
    it must be an object. This is not specific enough. Because the value of each property
    is just another valid JSON Schema, we can define a more specific schema for the `name` property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: This JSON Schema satisfies every constraint we want to impose on our Create
    User request payload. However, it looks just like an arbitrary JSON object; someone
    looking at it won't immediately understand that it is a schema. Therefore, to
    make our intentions more clear, we should add a title, description, and some metadata
    to it.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a title and description
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we should provide the `title` and `description` keywords for the schema
    and for each property that may require clarification. These keywords are not used
    in validation and exist only to provide context for the users of your schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Specifying a meta-schema
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, we should include the `$schema` keyword, which declares that the JSON
    object is a JSON Schema. It points to a URL that defines the meta-schema that
    the current JSON Schema must conform to. We chose [http://json-schema.org/schema#](http://json-schema.org/schema#), which
    points to the latest draft of the JSON Schema specification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Specifying a unique ID
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Lastly, we should include the `$id` keyword, which defines a unique URI for
    our schema. This URI can be used by other schemas to reference our schema, for
    example, when using our schema as a sub-schema. For now, just set it to a valid
    URL, preferably using a domain that you control:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: If you don't know how to purchase a domain, we will show you in [Chapter 10](673a49d6-f4c5-47b4-afec-af3ff031f150.xhtml), *Deploying
    Your Application on a VPS*. For now, just use a dummy domain like `example.com`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our finished JSON Schema should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Save this file to `/src/schema/users/profile.json`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a schema for the Create User request payload
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the moment, our existing code still uses custom-defined `if` statements to
    validate the email and password fields of the Create User request payload object.
    Since we will be using a JSON Schema validation library for our profile object,
    we should also migrate our existing validation logic to a JSON Schema to remain
    consistent. Therefore, let's create a schema for the entire Create User request
    payload object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new file at `src/schema/users/create.json`, and insert the following
    schema:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'There are a few things to note here:'
  prefs: []
  type: TYPE_NORMAL
- en: We are using the `format` property to ensure that the email property is a valid
    email, as defined by RFC 5322, section 3.4.1 ([https://tools.ietf.org/html/rfc5322#section-3.4.1](https://tools.ietf.org/html/rfc5322#section-3.4.1)). However,
    we also want to exclude certain syntactically-valid emails like `daniel@127.0.0.1`,
    which are likely to be spam. Later in this chapter, we will show you how to override
    this default format.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have used a JSON reference (`$ref`) to reference the profile schema we defined
    earlier. The `$ref` syntax was specified in [https://tools.ietf.org/html/draft-pbryan-zyp-json-ref-03](https://tools.ietf.org/html/draft-pbryan-zyp-json-ref-03) and
    allows us to compose more complex schema from existing ones, removing the need
    for duplication.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have marked the `email` and `password` properties as required.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Picking a JSON Schema validation library
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The next step is to pick a JSON Schema validation library. The json-schema.org
    ([https://json-schema.org/](https://json-schema.org/)) provides a list of validators
    which you can read at [json-schema.org/implementations.html](http://json-schema.org/implementations.html). When
    choosing a schema validation library, we are looking for two things: performance
    (how quick it is) and conformity (how closely it conforms to the specification).'
  prefs: []
  type: TYPE_NORMAL
- en: 'An open-source developer from Denmark, Allan Ebdrup, has created a set of benchmarks
    that compare these libraries. You can find it at [github.com/ebdrup/json-schema-benchmark](https://github.com/ebdrup/json-schema-benchmark).
    The benchmark shows that the *Dynamic JSON Schema Validator* (djv, [github.com/korzio/djv](https://github.com/korzio/djv))
    is the fastest and also has fewest failing tests (only 1). The second fastest
    library is *Another JSON Schema Validator* (ajv, [github.com/epoberezkin/ajv](https://github.com/epoberezkin/ajv)),
    which also only has a single failing test:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Library | Relative Speed | Number of failing tests |'
  prefs: []
  type: TYPE_TB
- en: '| `djv v2.0.0` (fastest) | 100% | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| `ajv v5.5.1` | 98% | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| `is-my-json-valid v2.16.1` | 50.1% | 14 |'
  prefs: []
  type: TYPE_TB
- en: '| `tv4 v1.3.0` | 0.2% | 33 |'
  prefs: []
  type: TYPE_TB
- en: 'Therefore, djv seems like an obvious choice. However, developer and community
    support are also important factors to consider. So, let''s take some of the most
    popular libraries and examine their number of GitHub stars, the number of weekly
    downloads from [npmjs.com](https://www.npmjs.com), and the number of dependent
    repositories and packages*:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Library** | **GitHub Repository** | **Version** | **GitHub stars** | **Weekly
    downloads** | **Number of Contributors** | **Dependent** |'
  prefs: []
  type: TYPE_TB
- en: '| **Repositories** | **Packages** |'
  prefs: []
  type: TYPE_TB
- en: '| `ajv` | [epoberezkin/ajv](https://github.com/epoberezkin/ajv) | 6.5.3 | 4,117
    | 12,324,991 | 74 | 1,256,690 | 2,117 |'
  prefs: []
  type: TYPE_TB
- en: '| `tv4` | [geraintluff/tv4](https://github.com/geraintluff/tv4) | 1.3.0 | 1,001
    | 342,094 | 22 | 8,276 | 486 |'
  prefs: []
  type: TYPE_TB
- en: '| `jsonschema` | [tdegrunt/jsonschema](https://github.com/tdegrunt/jsonschema)
    | 1.2.4 | 889 | 214,902 | 39 | 18,636 | 727 |'
  prefs: []
  type: TYPE_TB
- en: '| `is-my-json-valid` | [mafintosh/is-my-json-valid](https://github.com/mafintosh/is-my-json-valid)
    | 2.19.0 | 837 | 2,497,926 | 23 | 463,005 | 267 |'
  prefs: []
  type: TYPE_TB
- en: '| `JSV` | [garycourt/JSV](https://github.com/garycourt/JSV) | 4.0.2 | 597 |
    211,573 | 6 | 9,475 | 71 |'
  prefs: []
  type: TYPE_TB
- en: '| `djv` | [korzio/djv](https://github.com/korzio/djv) | 2.1.1 | 134 | 1,036
    | 6 | 36 | 10 |'
  prefs: []
  type: TYPE_TB
- en: '* These figures are correct as of 6 September, 2018.'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, although djv is the best solution technically, Ajv has the most
    downloads and number of contributors—signs that the project is well-supported
    by the community.
  prefs: []
  type: TYPE_NORMAL
- en: 'Apart from these metrics, you may also want to examine the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The date of its last meaningful commit to the `master` branch (this excludes
    version bump and formatting changes)—for instance, the last commit to the `JSV` library
    was on 11 Jul 2012; therefore, although it may still have a lot of active users,
    we should not use a library that's no longer maintained
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of open issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The frequency of releases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these factors will give you an indication of whether the tool is being
    actively developed.
  prefs: []
  type: TYPE_NORMAL
- en: Taking everything into account, it seems like Ajv is the obvious choice, as
    it has the right balance between performance, conformity, and community support.
  prefs: []
  type: TYPE_NORMAL
- en: Validating against JSON Schema with Ajv
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So, let''s start by adding Ajv to our project''s dependencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, in `src/validators/users/create.js`, import the `ajv` library as well
    as our two JSON Schemas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: We need to import both schemas because our Create User schema is referencing
    the Profile schema, and Ajv requires both schemas in order to resolve this reference.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, gut out the entire `validate` function, and replace it with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will create an instance of Ajv and run the `addFormat` method to override
    the default validation function for the `email` format; the `validate` function
    will now use the regular expression we provided to validate any properties with
    the `email` format.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we use the `addSchema` method to supply Ajv with any referenced sub-schemas.
    This allows Ajv to follow the references and produce a dereferenced, flattened
    schema, which will be used for the validation operation. Lastly, we run the `compile` method
    to return the actual validation function.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we run the validate function, it will return either `true` (if it is valid)
    or `false` (if it is invalid). If invalid, `ajvValidate.errors` will be populated with
    an array of errors, which looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'By default, Ajv works in a short-circuit manner and will return `false` as
    soon as it encounters the first error. Therefore, the `ajvValidate.errors` array
    is, by default, a single-item array containing the details of the first error.
    To instruct Ajv to return all errors, you must set the `allErrors` option in the Ajv constructor,
    for example, `new Ajv({allErrors: true})`.'
  prefs: []
  type: TYPE_NORMAL
- en: Generating validation error messages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When our object fails validation, we should generate the same human-readable
    error messages as we did before. To do this, we must process the errors stored
    at `ajvValidate.errors`, and use them to generate human-readable messages. Thus,
    create a new module at `src/validators/errors/messages.js`, and copy the following
    message generator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The `generateValidationErrorMessage` function extracts the first error object
    from the `ajvValidate.errors` array, and use it to generate the appropriate error
    message. There's also a generic, default error message in case none of the conditionals
    apply.
  prefs: []
  type: TYPE_NORMAL
- en: Generalizing functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the moment, the `generateValidationErrorMessage` function produces messages
    that are specific to the Create User operations. This means that although the
    code is separated, the logic is still highly coupled to the Create User endpoint.
    This coupling defeats the purpose of modules; it is a code smell that should be
    eliminated.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, we should program the `generateValidationErrorMessage` function to
    be able to generate error messages for all validation errors. Doing so also provides local
    consistency, because all validators will now have a consistent structure/format
    for their error messages.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let''s make the change by replacing our `generateValidationErrorMessage` function with
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Because this change will break our current implementation and tests, we must
    obtain approval from the product manager. If they approve, we must then update
    the E2E tests to reflect this change:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, import the `generateValidationErrorMessage` function into our `src/validators/users/create.js` file and
    update the `validateRequest` function so that we can use it to return an object
    containing an error message if validation fails:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Updating the npm build script
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Everything looks good, but if we run the tests, they will return with the following
    error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'This is because Babel, by default, only processes `.js` files. Therefore, our `.json` schema
    files were not processed or copied over to the `dist/` directory, which leads
    to the preceding error. To fix this, we can update our `build` npm script to use
    Babel''s `--copy-files` flag, which will copy over any non-compilable files to
    the `dist/` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Now, if we run our tests again, they should all pass.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the success scenario
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Since we added the validation steps, we now need to ensure that requests carrying
    valid user payloads will get added to the database, just like before. Therefore,
    at the end of `spec/cucumber/features/users/create/main.feature`, add the following
    scenario outline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Run your tests again to make sure that they pass.
  prefs: []
  type: TYPE_NORMAL
- en: Resetting our test index
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the moment, our test index on Elasticsearch is filled with dummy users. Although
    this is not an issue right now, it may become an issue in the future (for example,
    if we decide to change the schema). In any case, it's always a good practice to
    clean up side effects after the tests have finished in order to leave a blank
    slate for subsequent test runs. Therefore, at the end of each test, we should
    delete the Elasticsearch index. This is not a problem because the index will be
    recreated automatically by the test code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, add the following lines below into our `e2e.test.sh` script; this
    will clean up the test index (you should place it after Elasticsearch is responsive,
    but before you run the API server):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the tests again and they should still pass. Now, we can commit our changes
    to Git:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have broken up our monolithic application into many smaller
    modules, and implemented all the requirements for our Create User feature. We
    integrated JSON Schema and Ajv into our validation modules, which forced us to
    be more consistent with the structure of our error messages. This, in turn, improves
    the experience of our end users.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will use Mocha and Sinon to write unit and integration
    tests, which will strengthen the confidence we have in our code.
  prefs: []
  type: TYPE_NORMAL
