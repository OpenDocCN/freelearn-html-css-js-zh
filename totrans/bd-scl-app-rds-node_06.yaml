- en: '[CHAPTER 7](toc.xhtml#c07)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[API Caching](toc.xhtml#c07)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Introduction](toc.xhtml#s196a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A user opens the browser and tries to access different parts of the application.
    This causes many API calls to the backend. Normally, with a low count of users,
    the response would be quick. However, when the data grows in the application and
    a significant number of users are accessing the data simultaneously, the response
    time increases. This may lead to poor user experience.
  prefs: []
  type: TYPE_NORMAL
- en: Usually, for a system, when the state of the data does not change frequently,
    for a given input, the output will mostly be the same unless something changes
    in data. Till the time, data does not change, the database query is not necessary
    to fetch the same data repetitively if you can keep a copy of the outcome somewhere.
    The process of storing this outcome and accessing it when needed is a fundamental
    concept of caching.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to cache the data and use the cached data
    to serve APIs or save data of the queries so that we do not have to query the
    database for a certain time or till the time data is unchanged.
  prefs: []
  type: TYPE_NORMAL
- en: '[Structure](toc.xhtml#s197a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will discuss the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Caching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to Redis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting Up Redis server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pros and Cons of Redis/Caching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Redis for Caching Data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Understanding Caching](toc.xhtml#s198a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Consider yourself trying to log in to the application. After entering a username
    and password, the application takes a couple of seconds to validate and then navigate
    to the homepage. At the homepage, there are many things: project list you are
    part of, team activities on the project tasks, your high-priority tasks list,
    and many more. Bringing data for each of them is going to take a good amount of
    time if the system is busy serving too many requests already.'
  prefs: []
  type: TYPE_NORMAL
- en: All of these things on the homepage would require some data to be fetched from
    the database. The database queries are going to take time every single time you
    or other users open the application. These database query results can be *cached*.
    If cached, whenever the homepage is requested, the database queries would be avoided,
    and data will be read from the cache and sent in response. This process of caching-retrieving
    data would make responses faster and improve the user experience.
  prefs: []
  type: TYPE_NORMAL
- en: By definition, caching is a technique to store fetched data, or calculated results
    in *cache* so that any future request asking for that data can be served faster.
    When we need to access the data, the cache will be checked first to see if the
    desired data is cached or not. If yes, then serve the data from cache. Otherwise,
    fetch the data, process it if needed, and then store it in cache so that the next
    request can be served quicker.
  prefs: []
  type: TYPE_NORMAL
- en: 'Caching is a critical component when it comes to optimization of system performance.
    It helps to lower the response time or latency, and makes the system highly scalable.
    Cache can be considered a high-speed data storage system. There are many types
    of caching: memory cache, disk cache, browser cache, database cache, and so on.
    For our use-case, we will cache the data needed for API response, and database
    query results. For the caching, we will use a software called Redis.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Introduction to Redis](toc.xhtml#s199a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Quoting the content from Redis.io website:'
  prefs: []
  type: TYPE_NORMAL
- en: '*“The open source, in-memory data store used by millions of developers as a
    database, cache, streaming engine, and message broker.”*'
  prefs: []
  type: TYPE_NORMAL
- en: In simple words, Redis can store various types of data. Most of them are simple
    Key-Value pairs. It supports various data structures such as strings, hashes,
    lists, sets, sorted sets, bitmaps, and more. We can store these kinds of data
    in Redis and access via a key.
  prefs: []
  type: TYPE_NORMAL
- en: Being in-memory by nature makes Redis blazingly fast for read and write operations,
    thus, making it a popular choice for caching.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from the core data structures which help us store various types of data,
    Redis also offers features including data replication, persistence, sharding,
    and transaction capabilities. Redis is adopted by developers for a variety of
    applications. Redis is used by GitHub, Twitter, snapchat, stackoverflow, and many
    more. Techstacks.io maintains a list of popular websites which utilize Redis for
    their use cases.
  prefs: []
  type: TYPE_NORMAL
- en: More on Redis can be learned at - [https://redis.io](https://redis.io).
  prefs: []
  type: TYPE_NORMAL
- en: '[Setting Up Redis Server](toc.xhtml#s200a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let us start by setting up the Redis server. This section will cover the installation
    for MacOS, Ubuntu(debian), and Rocky Linux.
  prefs: []
  type: TYPE_NORMAL
- en: '[Installing Redis Server on Mac OS](toc.xhtml#s201a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The easiest way to install most of the softwares on a Mac is to use `**homebrew**`.
    If `**homebrew**` is not installed, it can be installed by running:'
  prefs: []
  type: TYPE_NORMAL
- en: '`/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"`'
  prefs: []
  type: TYPE_NORMAL
- en: This will make available a command named `**brew**` which we can use to install
    Redis server.
  prefs: []
  type: TYPE_NORMAL
- en: '`brew install redis`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once this completes, the server can be started with:'
  prefs: []
  type: TYPE_NORMAL
- en: '`brew services start redis`'
  prefs: []
  type: TYPE_NORMAL
- en: To verify if Redis is installed or not, we can try running `**redis-cli**` which
    is a command line interface for accessing Redis.
  prefs: []
  type: TYPE_NORMAL
- en: '`redis-cli`'
  prefs: []
  type: TYPE_NORMAL
- en: 'If Redis was successfully installed, it will open a Redis prompt as:'
  prefs: []
  type: TYPE_NORMAL
- en: '`127.0.0.1:6379>`'
  prefs: []
  type: TYPE_NORMAL
- en: If the prompt is visible, Redis is correctly installed and ready for use.
  prefs: []
  type: TYPE_NORMAL
- en: Further, we can do a command `**ping**` which should respond as `**PONG**`.
    If it does, then everything is working fine.
  prefs: []
  type: TYPE_NORMAL
- en: '`127.0.0.1:6379> ping`'
  prefs: []
  type: TYPE_NORMAL
- en: '`PONG`'
  prefs: []
  type: TYPE_NORMAL
- en: '[Installing Redis Server on Ubuntu / Linux](toc.xhtml#s202a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To install the Redis on Ubuntu, we need `**lsb-release**`, `**curl**`, and `**gpg**`.
    If these are not available already, it can be installed using `**apt**`.
  prefs: []
  type: TYPE_NORMAL
- en: '`sudo apt install lsb-release curl gpg`'
  prefs: []
  type: TYPE_NORMAL
- en: Now, we need to add the repository where the `**redis**` binaries are available.
  prefs: []
  type: TYPE_NORMAL
- en: '`curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg`'
  prefs: []
  type: TYPE_NORMAL
- en: '`echo "deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb
    $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/redis.list`'
  prefs: []
  type: TYPE_NORMAL
- en: '`Once the repositories are added, we can install Redis:`'
  prefs: []
  type: TYPE_NORMAL
- en: '`sudo apt-get update`'
  prefs: []
  type: TYPE_NORMAL
- en: '`sudo apt-get install redis`'
  prefs: []
  type: TYPE_NORMAL
- en: 'After this, server can be started using:'
  prefs: []
  type: TYPE_NORMAL
- en: '`sudo systemctl start redis`'
  prefs: []
  type: TYPE_NORMAL
- en: Once the server is started, similar to Mac OS, we can verify using `**redis-cli**`.
  prefs: []
  type: TYPE_NORMAL
- en: '[Installing Redis Server on Rocky (RHEL-based)](toc.xhtml#s203a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can simply use the `**dnf**` package manager to install Redis.
  prefs: []
  type: TYPE_NORMAL
- en: '`sudo dnf update -y`'
  prefs: []
  type: TYPE_NORMAL
- en: '`sudo dnf install -y redis`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once installed, the service can be started as:'
  prefs: []
  type: TYPE_NORMAL
- en: '`sudo systemctl status redis`'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we can verify using `**redis-cli**`.
  prefs: []
  type: TYPE_NORMAL
- en: '[Pros and Cons of Caching](toc.xhtml#s204a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we proceed to use Redis for our purpose, it is important to know about
    pros and cons that caching brings in. Caching is a crucial technique but it comes
    with certain advantages and disadvantages, which we should keep in mind while
    implementing it in the application.
  prefs: []
  type: TYPE_NORMAL
- en: '[Pros of Caching](toc.xhtml#s205a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some of the major benefits of caching are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Performance improvement**: Caching significantly reduces the time needed
    to access data, which makes the responses to the end user faster. Thus, it provides
    better and faster application performance and an improved user experience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reduced load**: If implemented properly, most of the data is now served from
    cache which reduces the load on the application. This way, the application can
    serve more requests and operate more efficiently.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost effectiveness**: With caching in place, a single server can handle a
    larger number of requests efficiently. Consider if a server without caching was
    able to handle 100 requests per minute, and with caching, it can serve 1000 requests
    per minute. We do not need to put in more servers when the user load increases.
    Not only server costs, but the operational costs are also lowered due to decreased
    load and reduced bandwidth consumption.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reduced network traffic**: The caching server can be installed locally to
    the application or on another server. If done locally, it can reduce the network
    traffic. However, it must be seen if both application and caching server can stay
    on the same machine, without making the resource consumption high, such as memory
    and CPU.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Cons of Caching](toc.xhtml#s206a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some cons to be kept in mind and to be careful while doing development are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stale data**: It is important to ensure cache consistency. If the data is
    old, there should be effective cache invalidation strategies in place to remove
    old and invalid data from cache. Consider an example where you update your profile
    by updating your phone number. The application had already cached the user entity,
    which keeps your profile data in cache. When there is an update for the cached
    entity, the old data must be removed from cache and the new data must be placed
    in it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is very important to be careful while storing data in cache. At all points
    where the data might not be valid anymore, it should either be removed or replaced
    with the updated data. Sometimes, when data update is not always possible, the
    TTL kind of feature can be utilized. TTL stands for time to live. Usually, all
    caching systems provide this feature. This allows us to set a time for which the
    data should be in cache. Once the time expires, the data will be invalidated automatically.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Resource consumption**: If there is a lot of data in the application, it
    is important to decide what we are caching. Only the data which is needed most
    frequently should be cached. Otherwise, memory, disk space, and other resources
    can be a concern in a resource-constrained environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cache Miss**: When we try to access some data and it is not found in cache,
    then it is called a Cache Miss. It is important to know how it is handled. If
    data is not found in cache, the application must revert to the original data source.
    Also, when the data is fetched from the original source, it should be placed in
    cache to serve future requests faster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling a situation like Cache Miss is critical, as it may be expensive in
    terms of both time and resources. If there are too many requests in place and
    if there are too many Cache Miss, it will lead to an inefficient application.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Data synchronization issues**: For distributed environments, keeping the
    cached data and original data source as synchronous can be a challenge. It gets
    bigger if there are multiple caches.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Complexity**: Overall, implementing caching can add more complexity to the
    system. It may also lead to additional development efforts as well as testing
    and maintenance efforts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using Redis for Caching](toc.xhtml#s207a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In our project management system, so far, we have implemented several modules:
    users, roles, projects, and tasks. Consider this application being in use by an
    organization of 100,000 users. At the start of the office, typically 9 am, people
    are going to login and access their projects to learn about their tasks and make
    progress. If we cache a few things, the response time would improve and the user
    experience would be better.'
  prefs: []
  type: TYPE_NORMAL
- en: There are many strategies to caching such as on demand caching, and proactive
    caching. Proactive caching would be when we cache something at the application
    start without any user requests. This caching is done anticipating future requests.
    On the other hand, whenever something is accessed and it is a cache miss situation,
    caching at this moment would be on-demand. In case of on-demand caching, initially
    there would not be any records, and an object would be cached only after a cache
    miss.
  prefs: []
  type: TYPE_NORMAL
- en: In our application, we could do a mix of both strategies. When the application
    starts, we can cache all users, roles, projects, and their tasks. There could
    be some specific cases when the data we want to cache is not a straightforward
    database query result, for example, if you want a count of projects and similarly
    counts of tasks in all projects, respectively. These values would be results of
    some function which we can cache. In this section, we will see how we can cache
    both types of data we are interested in caching.
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall, we want to store the data as:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Objects**: essentially JSON objects of projects, tasks, users, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Numbers**: counts of projects, tasks, users, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There can be more.
  prefs: []
  type: TYPE_NORMAL
- en: '[Updating Project Dependencies](toc.xhtml#s208a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First of all, we need to update the project dependencies, that is, node modules
    in our case. The only package that we need is Redis. Let us install Redis using
    `**npm**` `**install**`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`npm install redis`'
  prefs: []
  type: TYPE_NORMAL
- en: It is better to install type definitions for Redis as well so that while doing
    development we get proper code hints.
  prefs: []
  type: TYPE_NORMAL
- en: '`npm install --save-dev @types/redis`'
  prefs: []
  type: TYPE_NORMAL
- en: 'After Redis package is available, we can use it as following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '`import { createClient, RedisClient } from ''redis'';`'
  prefs: []
  type: TYPE_NORMAL
- en: '`const client: RedisClient = createClient();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`client.on(''connect'', () => {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`console.log(''Connected to Redis'');`'
  prefs: []
  type: TYPE_NORMAL
- en: '`});`'
  prefs: []
  type: TYPE_NORMAL
- en: '`client.set(''key''`, `''value'', (err, reply) => {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`if (err) throw err;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`console.log(reply); // OK`'
  prefs: []
  type: TYPE_NORMAL
- en: '`});`'
  prefs: []
  type: TYPE_NORMAL
- en: '`client.get(''key'', (err, reply) => {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`if (err) throw err;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`console.log(reply); // value`'
  prefs: []
  type: TYPE_NORMAL
- en: '`});`'
  prefs: []
  type: TYPE_NORMAL
- en: '`client.quit();`'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding example, we are importing the `**createClient**` function and
    `**RedisClient**` for type. Next, a client is created using `**createClient()**`
    function call and using `**client.on()**` function we try to connect to the Redis
    server.
  prefs: []
  type: TYPE_NORMAL
- en: In the example discussed, we used callbacks, but we could also use async-await.
  prefs: []
  type: TYPE_NORMAL
- en: Using `**client.set()**`, we can set a key-value pair. This will store the key-value
    to the Redis server acting as a caching server here. When needed, we can get the
    value of the key using `**client.get()**`.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we are storing a simple string `**'value'**`, and if we want to store
    an object, we will have to convert the object to string using `**JSON.stringify()**`
    and store it as string. All of this is because Redis does not support JSON objects
    as values straightforwardly. To make Redis store JSON objects, we need to set
    up a Redis Module named `**RedisJSON**`. This module provides native JSON capabilities
    to Redis.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `**RedisJSON**` module is available at GitHub: `**https://github.com/RedisJSON/RedisJSON**`.'
  prefs: []
  type: TYPE_NORMAL
- en: We need to either clone this repository or download the repository zip file.
    Before continuing further, ensure that Rust is installed.
  prefs: []
  type: TYPE_NORMAL
- en: 'If not available, rust can be installed using:'
  prefs: []
  type: TYPE_NORMAL
- en: '`curl --proto ''=https'' --tlsv1.2 -sSf https://sh.rustup.rs | sh`'
  prefs: []
  type: TYPE_NORMAL
- en: After this step completes, we can verify the installation by checking the rust
    version.
  prefs: []
  type: TYPE_NORMAL
- en: '`rustc --version`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once installed, we can begin building the `**RedisJSON**`. Navigate to the
    downloaded repository and run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '`cargo build –release`'
  prefs: []
  type: TYPE_NORMAL
- en: This will create the module in `**target/release/librejson.so**`. If the file
    is missing, then something went wrong and try building again.
  prefs: []
  type: TYPE_NORMAL
- en: We need to modify the Redis configuration typically located at `**/etc/redis/redis.conf**`
    or `**/usr/local/etc/redis.conf**` and add enable to the `**redisjson.so**` module.
  prefs: []
  type: TYPE_NORMAL
- en: '**On linux**'
  prefs: []
  type: TYPE_NORMAL
- en: '`loadmodule /path/to/redisjson.so`'
  prefs: []
  type: TYPE_NORMAL
- en: '**On Mac**'
  prefs: []
  type: TYPE_NORMAL
- en: '`loadmodule /path/to/rejson.dylib`'
  prefs: []
  type: TYPE_NORMAL
- en: Once the module is loaded, restart Redis to enable it.
  prefs: []
  type: TYPE_NORMAL
- en: '[Cache Utility](toc.xhtml#s209a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since we’re dealing with a large number of entities to cache, using a cache
    utility class can be beneficial. This class would ideally provide functions for
    both setting and retrieving cached values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have the cache utility class, we can simply import it where we need
    and use the functions directly. Let us create a file `**cache_util.ts**` which
    would have the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`// cache_util.ts`'
  prefs: []
  type: TYPE_NORMAL
- en: '`import * as redis from ''redis'';`'
  prefs: []
  type: TYPE_NORMAL
- en: '`export class CacheUtil {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// redis client instance`'
  prefs: []
  type: TYPE_NORMAL
- en: '`private static client = redis.createClient();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`constructor() {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`CacheUtil.client.connect();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`public static async get(cacheName: string, key: string) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`try {`'
  prefs: []
  type: TYPE_NORMAL
- en: '``const data = await CacheUtil.client.json.get(`${cacheName}:${key}`);``'
  prefs: []
  type: TYPE_NORMAL
- en: '`return data;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`} catch (err) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '``console.error(`Error getting cache: ${err}`);``'
  prefs: []
  type: TYPE_NORMAL
- en: '`return null;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`public static async set(cacheName: string, key: string, value) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`try {`'
  prefs: []
  type: TYPE_NORMAL
- en: '``await CacheUtil.client.json.set(`${cacheName}:${key}`, ''.'', value);``'
  prefs: []
  type: TYPE_NORMAL
- en: '`} catch (err) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '``console.error(`Error setting cache: ${err}`);``'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`public static async remove(cacheName: string, key: string) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`try {`'
  prefs: []
  type: TYPE_NORMAL
- en: '``await CacheUtil.client.del(`${cacheName}:${key}`);``'
  prefs: []
  type: TYPE_NORMAL
- en: '`} catch (err) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '``console.error(`Error deleting cache: ${err}`);``'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: The function `**set()**` can be used to set a key-value in cache and the `**get()**`
    function can be used to retrieve the values. Notice how we are using `**client.json.get()**`
    and `**client.json.set()**` to actually get and set the values. Both set and get
    functions are made static so that we can simply use those without initializing
    the class every time.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now initialize the class once and use it everywhere. We need to do so
    in order to connect the Redis client to the server. Without making a call to `**CacheUtil.client.connect()**`
    the application will throw an error as: The client is closed.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, when the cache utility is ready, let us initialize it in `**main.ts**`.
  prefs: []
  type: TYPE_NORMAL
- en: '`// main.ts`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// initialise the cache utility`'
  prefs: []
  type: TYPE_NORMAL
- en: '`new CacheUtil();`'
  prefs: []
  type: TYPE_NORMAL
- en: This will make a call to the constructor and connect the client to the Redis
    server.
  prefs: []
  type: TYPE_NORMAL
- en: '[Caching Entities](toc.xhtml#s210a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We previously discussed two entity caching approaches: on-demand and proactive.
    For on demand caching, we can update all of our controllers’ functions to first
    check if the data needed is in the cache or not. The following example shows how
    the `**getOneHandler**` of `**users_controller**` which is responsible for returning
    a user for a given user id:'
  prefs: []
  type: TYPE_NORMAL
- en: '`// users_controller.ts`'
  prefs: []
  type: TYPE_NORMAL
- en: '`public async getOneHandler(req: Request, res: Response): Promise<void> {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`if (!hasPermission(req.user.rights, ''get_details_user'')) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`res.status(403).json({ statusCode: 403, status: ''error'', message: ''Unauthorised''
    });`'
  prefs: []
  type: TYPE_NORMAL
- en: '`return;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// check user is in cache`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**const userFromCache = await CacheUtil.get(**''**User**''**, req.params.id);**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`if (userFromCache) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`res.status(200).json({ statusCode: 200, status: ''success'', data: userFromCache
    });`'
  prefs: []
  type: TYPE_NORMAL
- en: '`return;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`} else {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// get user from db`'
  prefs: []
  type: TYPE_NORMAL
- en: '`const service = new UsersService();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`const result = await service.findOne(req.params.id);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`if (result.statusCode === 200) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`delete result.data.password;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// set user in cache`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**CacheUtil.set(**''**User**''**, req.params.id, result.data);**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`res.status(result.statusCode).json(result);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`return;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the function, we are making a call to `**CacheUtil.get()**` for cacheName
    `**''User''**` and the key is the `**user_id**` which is supplied in the request
    parameters. There is a chance that the requested user is not present in the cache
    so it must be checked if the returned value `**userFromCache**` is null or not.
    If it is null, then we should take the regular course and fetch the user from
    the database. If a user is present in the database, then we should also save that
    to the cache. The following line making a call to `**CacheUtil.set()**` is doing
    that for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '`**CacheUtil.set(''User'', req.params.id, result.data);**`'
  prefs: []
  type: TYPE_NORMAL
- en: This way, all of the functions can be updated to check cache before making an
    actual database query. For cases when delete api is called, the value in cache
    must also be removed. If the value is not removed, future API calls to get the
    user by `**user_id**` will return a value which does not exist in the database
    anymore.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `**delete**` function can be updated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '`public async deleteHandler(req: Request, res: Response): Promise<void> {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`if (!hasPermission(req.user.rights, ''delete_user'')) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`res.status(403).json({ statusCode: 403, status: ''error'', message: ''Unauthorised''
    });`'
  prefs: []
  type: TYPE_NORMAL
- en: '`return;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`const service = new UsersService();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`const result = await service.delete(req.params.id);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`// remove user from cache`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**CacheUtil.remove(**''**User**''**, req.params.id);**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`res.status(result.statusCode).json(result);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`return;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: A call to `**CacheUtil.remove()**` will remove the user from cache.
  prefs: []
  type: TYPE_NORMAL
- en: Caching using this on-demand approach ensures the frequently used data stays
    in cache and the data which is not used does not fill up the cache. However, in
    this case, there will always be a cache miss when the data is requested for the
    first time.
  prefs: []
  type: TYPE_NORMAL
- en: '[Building Cache at Startup](toc.xhtml#s211a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, it is good to fill the cache when the application starts. This may
    help in preventing some cache miss since the data requested will be there in the
    cache. Let us update `**UsersUtil**` to add a function `**putAllUsersInCache()**`
    which will fetch all of the users from the database and put them in the cache.
  prefs: []
  type: TYPE_NORMAL
- en: '`// function to put all users in cache`'
  prefs: []
  type: TYPE_NORMAL
- en: '`public static async putAllUsersInCache() {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`const userService = new UsersService();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`const result = await userService.findAll({});`'
  prefs: []
  type: TYPE_NORMAL
- en: '`if (result.statusCode === 200) {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`const users = result.data;`'
  prefs: []
  type: TYPE_NORMAL
- en: '`users.forEach(i => {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`CacheUtil.set(''User'', i.user_id, i);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`});`'
  prefs: []
  type: TYPE_NORMAL
- en: '``console.log(`All users are put in cache`);``'
  prefs: []
  type: TYPE_NORMAL
- en: '`}else{`'
  prefs: []
  type: TYPE_NORMAL
- en: '``console.log(`Error while putAllUsersInCache() => ${result.message}`);``'
  prefs: []
  type: TYPE_NORMAL
- en: '`console.log(result);`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}`'
  prefs: []
  type: TYPE_NORMAL
- en: This function is making a call to `**findAll()**` using `**userService**` to
    get all of the users from the database and if the result of the query is a success,
    putting the users in the cache using `**forEach**`.
  prefs: []
  type: TYPE_NORMAL
- en: We can call this function from `**main.ts**`.
  prefs: []
  type: TYPE_NORMAL
- en: '`// Proactive cache update`'
  prefs: []
  type: TYPE_NORMAL
- en: '`setTimeout(() => {`'
  prefs: []
  type: TYPE_NORMAL
- en: '`UsersUtil.putAllUsersInCache();`'
  prefs: []
  type: TYPE_NORMAL
- en: '`}, 1000 * 10 );`'
  prefs: []
  type: TYPE_NORMAL
- en: When an application starts, it may require time to establish connections to
    databases, caching servers, and perform other initializations. It is wise to allow
    sufficient time for these connections and initializations to complete before commencing
    other operations to ensure smooth functioning of the application. Hence, we have
    put some delay (10 seconds here) using `**setTimeout**`.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to `**UsersUtil**`, other entity utils can be modified to add a function
    and then we can make a call to those functions from `**main.ts**`. It is not necessary
    that those functions be called from the `**main.ts**` file. We can put those elsewhere,
    for example, `**CacheUtil**` and call `**CacheUtil**` from `**main.ts**` to `**init**`
    the caching. Likewise, it can be another function than `**putAllXXToCache**`.
  prefs: []
  type: TYPE_NORMAL
- en: '[Consideration when Using Redis](toc.xhtml#s212a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Despite being a powerful in-memory data store, there are some challenges when
    it comes to using Redis. The following points discusses some of the challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Memory Limitation**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since it is an in-memory data store, it offers faster access but is limited
    by the system capacity. If you have a large dataset and the target is to minimize
    the cost then it could be a drawback.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Data Security**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Redis, by default, is not encrypted. Although, it supports a simple password
    based authentication but does not have built-in support for SSL/TLS encryption.
    Securing data for REST APIs requires additional tools.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Limited ways to Query data**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Redis querying capabilities are limited compared to a traditional database system.
    However, by implementing some additional logic at application level, complex queries
    can be performed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Single-threaded nature**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Redis servers are single-threaded in nature. Most of the machines these days
    are multi-core and Redis cannot utilize more than one core. However, newer Redis
    versions put slow queries to separate threads but the requests to Redis servers
    are still handled by a single thread only.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Hosting Cost on Cloud**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All major cloud platforms offer Redis as a service. AWS `**Elasticache**`, Azure
    Cache for Redis are some examples. These offerings can be expensive for large
    datasets.
  prefs: []
  type: TYPE_NORMAL
- en: If Redis does not perform well for your use case, other options such as Memcached,
    Apache Kafka, and others can also be explored.
  prefs: []
  type: TYPE_NORMAL
- en: '[Conclusion](toc.xhtml#s213a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Caching can improve the user experience and greatly enhance the performance
    of an application while also making it more stable and scalable. In this chapter,
    we got familiar with the concepts of caching along with setting up Redis, a popular
    choice for caching for any size of the application. We learned and implemented
    the two caching strategies: on demand and proactive caching.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next chapter, we will implement the notification module while learning
    another aspect of Redis: Message Queue.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Multiple Choice Questions](toc.xhtml#s214a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the primary goal of implementing caching in an application?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To increase data processing time.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To store user passwords securely.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To reduce the time needed to access data.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To increase network traffic.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a significant benefit of caching for handling database queries?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It increases the load on the application server.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It helps in avoiding database queries by fetching data from the cache.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It decreases the application’s performance.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It consumes more bandwidth.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following is not a pro of caching?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Performance improvement.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Reduced load on the application.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Increased network traffic.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Cost effectiveness.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What does TTL stand for in the context of caching?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Time To Launch
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Time To Live
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Total Time Limit
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Time To Load
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a ‘*cache miss*’?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When data is successfully retrieved from the cache.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: When data is not found in the cache.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: When the cache is fully utilized.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: When the cache fails to save data.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a key challenge in caching for distributed environments?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Simplifying user interfaces.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Reducing the number of users.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Keeping cached data and original data source synchronized.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Decreasing the server costs.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is an advantage of building cache at startup?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It increases the cache size unnecessarily.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It ensures frequently requested data is immediately available.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It slows down the application startup.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It requires less development effort.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which software is used for caching in the described scenario?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: MySQL
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Redis
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: MongoDB
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Oracle
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Answers](toc.xhtml#s215a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: c
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: b
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: c
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: b
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: b
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: c
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: b
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: b
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Further Readings](toc.xhtml#s216a)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[https://www.geeksforgeeks.org/caching-system-design-concept-for-beginners/](https://www.geeksforgeeks.org/caching-system-design-concept-for-beginners/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://redis.io](https://redis.io)'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://redis.io/docs/data-types/json/](https://redis.io/docs/data-types/json/)'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.npmjs.com/package/redis](https://www.npmjs.com/package/redis)'
  prefs: []
  type: TYPE_NORMAL
