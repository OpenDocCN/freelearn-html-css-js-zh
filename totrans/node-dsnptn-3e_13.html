<html><head></head><body>
  <div id="_idContainer310">
    <h1 class="chapterNumber">13</h1>
    <h1 id="_idParaDest-362" class="chapterTitle">Messaging and Integration Patterns</h1>
    <p class="normal">If scalability is about distributing systems, integration is about connecting them. In the previous chapter, we learned how to distribute an application, fragmenting it across several processes and machines. For this to work properly, all those pieces have to communicate in some way and, hence, they have to be integrated.</p>
    <p class="normal">There are two main techniques to integrate a distributed application: one is to use shared storage as a central coordinator and keeper of all the information, the other one is to use messages to disseminate data, events, and commands across the nodes of the system. This last option is what really makes the difference when scaling distributed systems, and it's also what makes this topic so fascinating and sometimes complex.</p>
    <p class="normal">Messages are used in every layer of a software system. We exchange messages to communicate on the Internet; we can use messages to send information to other processes using pipes; we can use messages within an application as an alternative to direct function invocation (the Command pattern), and also device drivers use messages to communicate with the hardware. Any discrete and structured data that is used as a way to exchange information between components and systems can be seen as a <em class="italic">message</em>. However, when dealing with distributed architectures, the term <strong class="keyword">messaging system</strong> is used to describe a specific class of solutions, patterns, and architectures that are meant to facilitate the exchange of information over the network.</p>
    <p class="normal">As we will see, several traits characterize these types of systems. We might choose to use a broker versus a peer-to-peer structure, we might use a request/reply message exchange or one-way type of communication, or we might use queues to deliver our messages more reliably; the scope of the topic is really broad. The book <em class="italic">Enterprise Integration Patterns</em> by Gregor Hohpe and Bobby Woolf gives us an idea about the vastness of the topic. Historically, it is considered the <em class="italic">Bible</em> of messaging and integration patterns and has more than 700 pages describing 65 different integration patterns. In this final chapter, we will explore the most important of those well-known patterns—plus some more modern alternatives—considering them from the perspective of Node.js and its ecosystem.</p>
    <p class="normal">To sum up, in this chapter, we will learn about the following topics:</p>
    <ul>
      <li class="Bullet--PACKT-">The fundamentals of a messaging system</li>
      <li class="Bullet--PACKT-">The Publish/Subscribe pattern</li>
      <li class="Bullet--PACKT-">Task distribution patterns and pipelines</li>
      <li class="Bullet-End--PACKT-">Request/reply patterns</li>
    </ul>
    <p class="normal">Let's begin with the fundamentals.</p>
    <h1 id="_idParaDest-363" class="title">Fundamentals of a messaging system</h1>
    <p class="normal">When talking about messages and<a id="_idIndexMarker1338"/> messaging systems, there are four fundamental elements to take into consideration:</p>
    <ul>
      <li class="Bullet--PACKT-">The direction of the communication, which can be one-way only or a request/reply exchange</li>
      <li class="Bullet--PACKT-">The purpose of the message, which also determines its content</li>
      <li class="Bullet--PACKT-">The timing of the message, which can be sent and received in-context (synchronously) or out-of-context (asynchronously)</li>
      <li class="Bullet-End--PACKT-">The delivery of the message, which can happen directly or via a broker</li>
    </ul>
    <p class="normal">In the sections that follow, we are going to formalize these aspects to provide a base for our later discussions.</p>
    <h2 id="_idParaDest-364" class="title">One way versus request/reply patterns</h2>
    <p class="normal">The most fundamental <a id="_idIndexMarker1339"/>aspect in a messaging system is the <a id="_idIndexMarker1340"/>direction of the communication, which often also determines its semantics.</p>
    <p class="normal">The simplest communication pattern is when the message is pushed <em class="italic">one way</em> from a source to a destination; this is a trivial situation, and it doesn't need much explanation:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_01.png" alt=""/></figure>
    <p class="packt_figref">Figure 13.1: One-way communication</p>
    <p class="normal">A typical example of one-way communication is an email or a web server that sends a message to a connected browser using WebSockets, or a system that distributes tasks to a set of workers.</p>
    <p class="normal">On the other side, we have the<a id="_idIndexMarker1341"/> Request/Reply exchange pattern, where <a id="_idIndexMarker1342"/>the message in one direction is always matched (excluding error conditions) by a message in the opposite direction. A typical example of this exchange pattern is the invocation of a web service or sending a query to a database. The following diagram shows this simple and well-known scenario:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_02.png" alt=""/></figure>
    <p class="packt_figref">Figure 13.2: Request/Reply message exchange pattern</p>
    <p class="normal">The Request/Reply pattern might seem a trivial pattern to implement, however, as we will see later, it becomes more complicated when the communication channel is asynchronous or involves multiple nodes. Take a look at the example represented in the next diagram:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_03.png" alt="A close up of a womans face  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 13.3: Multi-node request/reply communication</p>
    <p class="normal">With the setup shown in <em class="italic">Figure 13.3</em>, we can better appreciate the complexity of some request/reply patterns. If we consider the direction of the communication between any two nodes, we can surely say that it is one way. However, from a global point of view, the initiator sends a request and in turn receives an associated response, even if from a different node. In these situations, what really differentiates a Request/Reply pattern from a bare one-way loop is the relationship between the request and the reply, which is kept in the initiator. The reply is usually handled in the same context as the request.</p>
    <h2 id="_idParaDest-365" class="title">Message types</h2>
    <p class="normal">A <strong class="keyword">message</strong> is essentially<a id="_idIndexMarker1343"/> a means to connect different software components and there are different reasons for doing so: it might be because we want to obtain some information held by another system or component, to execute operations remotely, or to notify some peers that something has just happened.</p>
    <p class="normal">The message content will also vary depending on the reason for the communication. In general, we can identify three types of messages, depending on their purpose:</p>
    <ul>
      <li class="Bullet--PACKT-">Command Messages</li>
      <li class="Bullet--PACKT-">Event Messages</li>
      <li class="Bullet-End--PACKT-">Document Messages</li>
    </ul>
    <h3 id="_idParaDest-366" class="title">Command Messages</h3>
    <p class="normal">You should already be <a id="_idIndexMarker1344"/>familiar with the <strong class="keyword">Command Message</strong> as it's essentially a <a id="_idIndexMarker1345"/>serialized Command object (we learned about this in the <em class="italic">Command</em> section in <em class="chapterRef">Chapter 9</em>, <em class="italic">Behavioral Design Patterns</em>)</p>
    <p class="normal">The purpose of this type of message is to trigger the execution of an action or a task on the receiver. For this to be possible, the Command Message has to contain the essential information to run the task, which usually includes the name of the operation and a list of arguments. The Command Message can be<a id="_idIndexMarker1346"/> used to implement <strong class="keyword">remote procedure call</strong> (<strong class="keyword">RPC</strong>) systems, distributed computations, or can be more simply used to request some data. RESTful HTTP calls are simple examples of commands; each HTTP verb has a specific meaning and is associated with a precise operation: <code class="Code-In-Text--PACKT-">GET</code>, to retrieve the resource; <code class="Code-In-Text--PACKT-">POST</code>, to create a new one; <code class="Code-In-Text--PACKT-">PUT</code>/<code class="Code-In-Text--PACKT-">PATCH</code>, to update it; and <code class="Code-In-Text--PACKT-">DELETE</code>, to destroy it.</p>
    <h3 id="_idParaDest-367" class="title">Event Messages</h3>
    <p class="normal">An <strong class="keyword">Event Message</strong> is used to <a id="_idIndexMarker1347"/>notify another component that something has occurred. It <a id="_idIndexMarker1348"/>usually contains the <em class="italic">type</em> of the event and sometimes also some details such as the context, the subject, or the actor involved.</p>
    <p class="normal">In web development, we are using an Event Message when, for example, we leverage WebSockets to send notifications from the server to the client to communicate changes to some data or mutations in the state of the system.</p>
    <p class="normal">Events are a very important integration mechanism in distributed applications, as they enable us to keep all the nodes of the system on the same page.</p>
    <h3 id="_idParaDest-368" class="title">Document Messages</h3>
    <p class="normal">The <strong class="keyword">Document Message</strong> is primarily <a id="_idIndexMarker1349"/>meant to transfer data between components and machines. A<a id="_idIndexMarker1350"/> typical example is a message used to transfer the results of a database query.</p>
    <p class="normal">The main characteristic that differentiates a Document Message from a Command Message (which might also contain data) is that the message does not contain any information that tells the receiver what to do with the data. On the other hand, the main difference between a Document Message and an Event Message is the absence of an association with a particular occurrence with something that happened. Often, the replies to Command Messages are Document Messages, as they usually contain only the data that was requested or the result of an operation.</p>
    <p class="normal">Now that we know how to categorize the semantics of a message, let's learn about the semantic of the communication channel used to move our messages around.</p>
    <h2 id="_idParaDest-369" class="title">Asynchronous messaging, queues, and streams</h2>
    <p class="normal">At this point in the book, you should already be familiar with the characteristics of an asynchronous operation. Well, it turns out that the same principles can be applied to messaging and communications.</p>
    <p class="normal">We can compare synchronous communications to a phone call: the two peers must be connected to the same channel at the same time and they should exchange messages in real time. Normally, if we want to call someone else, we either need another phone or terminate the ongoing communication to start a new one.</p>
    <p class="normal">Asynchronous communication <a id="_idIndexMarker1351"/>is similar to an SMS: it doesn't require the recipient to be connected to the network the moment we send it; we might receive a response immediately or after an unknown delay, or we might not receive a response at all. We might send multiple SMSes to multiple recipients one after the other and receive their responses (if any) in any order. In short, we have better parallelism with the use of fewer resources.</p>
    <p class="normal">Another important characteristic of <a id="_idIndexMarker1352"/>asynchronous communications is that the messages can be stored and then delivered as soon as possible or at a later time. This can be useful when the receiver is too busy to handle new messages or when we want to guarantee delivery. In messaging systems, this is made possible using a <strong class="keyword">message queue</strong>, a component<a id="_idIndexMarker1353"/> that mediates the communication between the producer of the messages and the consumer, storing any message before it gets delivered to its destination, as shown in the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_04.png" alt="A picture containing clock  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 13.4: A message queue</p>
    <p class="normal">If for any reason the consumer crashes, disconnects from the network, or experiences a slowdown, the messages are accumulated in the queue and dispatched as soon as the consumer comes back online. The queue can be located in the producer, or be split between the producer and the consumer (in peer-to-peer architectures), or live in a dedicated external system acting as middleware for the communication (<strong class="keyword">broker</strong>).</p>
    <p class="normal">Another data structure that has a similar (but not the same!) goal as a message queue is the <strong class="keyword">log</strong>. A log<a id="_idIndexMarker1354"/> is an append-only data structure, which is durable and whose messages can be read as they arrive or by accessing its history. In the context of messaging and integration systems, this is also known as a data <strong class="keyword">stream.</strong></p>
    <p class="normal">Compared to a queue, in a stream, messages are not <a id="_idIndexMarker1355"/>removed when they are retrieved or processed. This way, consumers can retrieve the messages as they arrive or can query the stream at any time to retrieve past messages. This means that a stream provides more freedom when it comes to accessing the messages, while queues usually expose only one message at a time to their consumers. Most importantly, a stream can be shared by more than one consumer, which can access the messages (even the same messages) using different approaches. </p>
    <p class="normal"><em class="italic">Figure 13.5</em> gives you an idea of the structure of a stream compared to that of a message queue:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_05.png" alt="A close up of a logo  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 13.5: A stream</p>
    <p class="normal">You will be able to better <a id="_idIndexMarker1356"/>appreciate the difference between a queue and a stream later in the chapter when we implement a sample application using both approaches.</p>
    <p class="normal">The final fundamental element to consider in a messaging system is the way the nodes of the system are connected together, which can be directly or through an intermediary.</p>
    <h2 id="_idParaDest-370" class="title">Peer-to-peer or broker-based messaging</h2>
    <p class="normal">Messages can be delivered directly to the receiver in a <strong class="keyword">peer-to-peer</strong> fashion, or through a centralized intermediary system<a id="_idIndexMarker1357"/> called a <strong class="keyword">message broker</strong>. The main role of the broker is to decouple the receiver of the message from the sender. The following diagram shows the architectural difference between the two approaches:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_06.png" alt="A close up of a device  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 13.6: Peer-to-peer communication versus message brokering</p>
    <p class="normal">In a peer-to-peer architecture, every <a id="_idIndexMarker1358"/>node is directly responsible for the delivery of the message to the receiver. This implies that the nodes have to know the address and port of the receiver and they have to agree on a protocol and message format. The broker eliminates these complexities from the equation: each node can be totally independent and can communicate with an unspecified number of peers without directly knowing their details.</p>
    <p class="normal">A broker can also act as a<a id="_idIndexMarker1359"/> bridge between <a id="_idIndexMarker1360"/>different communication protocols. For example, the<a id="_idIndexMarker1361"/> popular RabbitMQ broker (<a href="http://nodejsdp.link/rabbitmq"><span class="url">nodejsdp.link/rabbitmq</span></a>) supports <strong class="keyword">Advanced Message Queuing Protocol</strong> (<strong class="keyword">AMQP</strong>), <strong class="keyword">Message Queue Telemetry Transport</strong> (<strong class="keyword">MQTT</strong>), and <strong class="keyword">Simple/Streaming Text Orientated Messaging Protocol</strong> (<strong class="keyword">STOMP</strong>), enabling multiple applications supporting <a id="_idIndexMarker1362"/>different messaging protocols to interact.</p>
    <div class="packt_tip">
      <p class="Tip--PACKT-">MQTT (<a href="http://nodejsdp.link/mqtt"><span class="url">nodejsdp.link/mqtt</span></a>) is a <a id="_idIndexMarker1363"/>lightweight messaging protocol, specifically designed for machine-to-machine <a id="_idIndexMarker1364"/>communications (such as the Internet of things). AMQP (<a href="http://nodejsdp.link/amqp"><span class="url">nodejsdp.link/amqp</span></a>) is a more complex messaging protocol, designed to be an open source alternative to proprietary messaging middleware. STOMP (<a href="http://nodejsdp.link/stomp"><span class="url">nodejsdp.link/stomp</span></a>) is a <a id="_idIndexMarker1365"/>lightweight text-based protocol, which comes from "the HTTP school of design". All three are application layer protocols and are based on TCP/IP.</p>
    </div>
    <p class="normal">Besides the advantages in terms of decoupling and interoperability, a broker can offer additional features such as persistent queues, routing, message transformations, and monitoring, without mentioning the broad range of messaging patterns that many brokers support out of the box.</p>
    <p class="normal">Of course, nothing prevents us from implementing all these features using a peer-to-peer architecture, but unfortunately, there is much more effort involved. Nonetheless, there might be different <a id="_idIndexMarker1366"/>reasons for choosing a peer-to-peer approach instead of a broker:</p>
    <ul>
      <li class="Bullet--PACKT-">By removing the broker, we are removing a single point of failure from the system</li>
      <li class="Bullet--PACKT-">A broker has to be scaled, while in a peer-to-peer architecture we only need to scale the single nodes of the application</li>
      <li class="Bullet-End--PACKT-">Exchanging messages without intermediaries can greatly reduce the latency of the communication</li>
    </ul>
    <p class="normal">By using a peer-to-peer messaging system we can have much more flexibility and power because we are not bound to any particular technology, protocol, or architecture.</p>
    <p class="normal">Now that we know the basics of a messaging system, let's explore some of the most important messaging patterns. Let's start with the Publish/Subscribe pattern.</p>
    <h1 id="_idParaDest-371" class="title">Publish/Subscribe pattern</h1>
    <p class="normal"><strong class="keyword">Publish/Subscribe</strong> (often abbreviated to Pub/Sub) is probably the best-known one-way messaging pattern. We <a id="_idIndexMarker1367"/>should already be familiar with it, as it's nothing more than a distributed Observer pattern. As in the case of Observer, we have a set of <em class="italic">subscribers</em> registering their interest in receiving a specific category of messages. On the other side, the <em class="italic">publisher</em> produces messages that are distributed across all the relevant subscribers. <em class="italic">Figure 13.7</em> shows the two main variants of the Pub/Sub pattern; the first is based on a peer-to-peer architecture, and the second uses a broker to mediate the communication:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_07.png" alt=""/></figure>
    <p class="packt_figref">Figure 13.7: Publish/Subscribe messaging pattern</p>
    <p class="normal">What makes Pub/Sub so special is the fact that the publisher doesn't know in advance who the recipients of the messages are. As we said, it's the subscriber that has to register its interest to receive a particular message, allowing the publisher to work with an unspecified number of receivers. In other words, the two sides of the Pub/Sub pattern are <em class="italic">loosely coupled</em>, which makes this an ideal pattern to integrate the nodes of an evolving distributed system.</p>
    <p class="normal">The presence of a broker further<a id="_idIndexMarker1368"/> improves the decoupling between the nodes of the system because the subscribers interact only with the broker, not knowing which node is the publisher of a message. As we will see later, a broker can also provide a message queuing system, allowing reliable delivery even in the presence of connectivity problems between the nodes.</p>
    <p class="normal">Now, let's work on an example to demonstrate this pattern.</p>
    <h2 id="_idParaDest-372" class="title">Building a minimalist real-time chat application</h2>
    <p class="normal">To show a real-life example<a id="_idIndexMarker1369"/> of how the Pub/Sub pattern can help <a id="_idIndexMarker1370"/>us integrate a distributed architecture, we are now going to build a very basic real-time chat application using pure WebSockets. Then, we will scale it by running multiple instances, and finally, using a messaging system, we will build a communication channel between all the server instances.</p>
    <h3 id="_idParaDest-373" class="title">Implementing the server side</h3>
    <p class="normal">Now, let's take one step at a<a id="_idIndexMarker1371"/> time. Let's first build a basic chat application, then we'll scale it to multiple instances.</p>
    <p class="normal">To implement the real-time capabilities of a typical chat application, we will rely on the <code class="Code-In-Text--PACKT-">ws</code> package (<a href="http://nodejsdp.link/ws"><span class="url">nodejsdp.link/ws</span></a>), which is a pure WebSocket implementation for Node.js. Implementing real-time applications in Node.js is pretty simple, and the code we are going to write will confirm this assumption. So, let's create the server side of our chat application in a file called <code class="Code-In-Text--PACKT-">index.js</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> { createServer } <span class="hljs-keyword">from</span> <span class="hljs-string">'http'</span>
<span class="hljs-keyword">import</span> staticHandler <span class="hljs-keyword">from</span> <span class="hljs-string">'serve-handler'</span>
<span class="hljs-keyword">import</span> ws <span class="hljs-keyword">from</span> <span class="hljs-string">'ws'</span>
<span class="hljs-comment">// serve static files</span>
<span class="hljs-keyword">const</span> server = createServer(<span class="hljs-function">(</span><span class="hljs-params">req, res</span><span class="hljs-function">) =&gt;</span> {                <span class="hljs-comment">// (1)</span>
  <span class="hljs-keyword">return</span> staticHandler(req, res, { <span class="hljs-attr">public</span>: <span class="hljs-string">'www'</span> })
})
<span class="hljs-keyword">const</span> wss = <span class="hljs-keyword">new</span> ws.Server({ server })                      <span class="hljs-comment">// (2)</span>
wss.on(<span class="hljs-string">'connection'</span>, <span class="hljs-params">client</span><span class="hljs-function"> =&gt;</span> {
  <span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Client connected'</span>)
  client.on(<span class="hljs-string">'message'</span>, <span class="hljs-params">msg</span><span class="hljs-function"> =&gt;</span> {                            <span class="hljs-comment">// (3)</span>
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Message: </span><span class="hljs-subst">${msg}</span><span class="hljs-string">`</span>)
    broadcast(msg)
  })
})
<span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">broadcast</span><span class="hljs-function"> (</span><span class="hljs-params">msg</span><span class="hljs-function">) </span>{                                 <span class="hljs-comment">// (4)</span>
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> client <span class="hljs-keyword">of</span> wss.clients) {
    <span class="hljs-keyword">if</span> (client.readyState === ws.OPEN) {
      client.send(msg)
    }
  }
}
server.listen(process.argv[<span class="hljs-number">2</span>] || <span class="hljs-number">8080</span>)
</code></pre>
    <p class="normal">That's it! That's all we need to implement the server-side component of our chat application. This is how it works:</p>
    <ol>
      <li class="numbered">We first create an HTTP <a id="_idIndexMarker1372"/>server and forward every request to a special handler (<a href="http://nodejsdp.link/serve-handler"><span class="url">nodejsdp.link/serve-handler</span></a>), which will take care to serve all the static files from the <code class="Code-In-Text--PACKT-">www</code> directory. This is needed to access the client-side resources of our application (for example, HTML, JavaScript, and CSS files).</li>
      <li class="numbered">We then create a new instance of the WebSocket server, and we attach it to our existing HTTP server. Next, we start listening for incoming WebSocket client connections by attaching an event listener for the <code class="Code-In-Text--PACKT-">connection</code> event.</li>
      <li class="numbered">Each time a new client connects to our server, we start listening for incoming messages. When a new message arrives, we broadcast it to all the connected clients.</li>
      <li class="numbered">The <code class="Code-In-Text--PACKT-">broadcast()</code> function is a simple iteration over all the known clients, where the <code class="Code-In-Text--PACKT-">send()</code> function is invoked on each connected client.</li>
    </ol>
    <p class="normal">This is the magic of Node.js! Of course, the server that we just implemented is very minimal and basic, but as we will see, it does its job.</p>
    <h3 id="_idParaDest-374" class="title">Implementing the client side</h3>
    <p class="normal">Next, it's time to implement the<a id="_idIndexMarker1373"/> client side of our chat application. This can be done with another compact and simple fragment of code, essentially a minimal HTML page with some basic JavaScript code. Let's create this page in a file named <code class="Code-In-Text--PACKT-">www/index.html</code> as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-meta">&lt;!DOCTYPE </span><span class="hljs-meta-keyword">html</span><span class="hljs-meta">&gt;</span>
<span class="hljs-tag">&lt;</span><span class="hljs-name">html</span><span class="hljs-tag">&gt;</span>
  <span class="hljs-tag">&lt;</span><span class="hljs-name">body</span><span class="hljs-tag">&gt;</span>
    Messages:
    <span class="hljs-tag">&lt;</span><span class="hljs-name">div</span><span class="hljs-tag"> </span><span class="hljs-attr">id</span><span class="hljs-tag">=</span><span class="hljs-string">"messages"</span><span class="hljs-tag">&gt;&lt;/</span><span class="hljs-name">div</span><span class="hljs-tag">&gt;</span>
    <span class="hljs-tag">&lt;</span><span class="hljs-name">form</span><span class="hljs-tag"> </span><span class="hljs-attr">id</span><span class="hljs-tag">=</span><span class="hljs-string">"msgForm"</span><span class="hljs-tag">&gt;</span>
      <span class="hljs-tag">&lt;</span><span class="hljs-name">input</span><span class="hljs-tag"> </span><span class="hljs-attr">type</span><span class="hljs-tag">=</span><span class="hljs-string">"text"</span><span class="hljs-tag"> </span><span class="hljs-attr">placeholder</span><span class="hljs-tag">=</span><span class="hljs-string">"Send a message"</span><span class="hljs-tag"> </span><span class="hljs-attr">id</span><span class="hljs-tag">=</span><span class="hljs-string">"msgBox"</span><span class="hljs-tag">/&gt;</span>
      <span class="hljs-tag">&lt;</span><span class="hljs-name">input</span><span class="hljs-tag"> </span><span class="hljs-attr">type</span><span class="hljs-tag">=</span><span class="hljs-string">"submit"</span><span class="hljs-tag"> </span><span class="hljs-attr">value</span><span class="hljs-tag">=</span><span class="hljs-string">"Send"</span><span class="hljs-tag">/&gt;</span>
    <span class="hljs-tag">&lt;/</span><span class="hljs-name">form</span><span class="hljs-tag">&gt;</span>
    <span class="hljs-tag">&lt;</span><span class="hljs-name">script</span><span class="hljs-tag">&gt;</span>
      <span class="hljs-keyword">const</span> ws = <span class="hljs-keyword">new</span> WebSocket(
        <span class="hljs-string">`ws://</span><span class="hljs-subst">${</span><span class="hljs-built_in">window</span>.<span class="hljs-built_in">document</span>.<span class="hljs-subst">location</span>.<span class="hljs-subst">host}</span><span class="hljs-string">`</span>
      )
      ws.onmessage = <span class="hljs-keyword">function</span><span class="hljs-function"> (</span><span class="hljs-params">message</span><span class="hljs-function">) </span>{
        <span class="hljs-keyword">const</span> msgDiv = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">'div'</span>)
        msgDiv.innerHTML = message.data
        <span class="hljs-built_in">document</span>.getElementById(<span class="hljs-string">'messages'</span>).appendChild(msgDiv)
      }
      <span class="hljs-keyword">const</span> form = <span class="hljs-built_in">document</span>.getElementById(<span class="hljs-string">'msgForm'</span>)
      form.addEventListener(<span class="hljs-string">'submit'</span>, <span class="hljs-function">(</span><span class="hljs-params">event</span><span class="hljs-function">) =&gt;</span> {
        event.preventDefault()
        <span class="hljs-keyword">const</span> message = <span class="hljs-built_in">document</span>.getElementById(<span class="hljs-string">'msgBox'</span>).value
        ws.send(message)
        <span class="hljs-built_in">document</span>.getElementById(<span class="hljs-string">'msgBox'</span>).value = <span class="hljs-string">''</span>
      })
    <span class="hljs-tag">&lt;/</span><span class="hljs-name">script</span><span class="hljs-tag">&gt;</span>
  <span class="hljs-tag">&lt;/</span><span class="hljs-name">body</span><span class="hljs-tag">&gt;</span>
<span class="hljs-tag">&lt;/</span><span class="hljs-name">html</span><span class="hljs-tag">&gt;</span>
</code></pre>
    <p class="normal">The HTML page we just created doesn't really need many comments, it's just a piece of straightforward web development. We use the native WebSocket object to initialize a connection to our Node.js server, and then start listening for messages from the server, displaying them in new <code class="Code-In-Text--PACKT-">div</code> elements as they arrive. For sending messages, instead, we use a simple textbox and a <a id="_idIndexMarker1374"/>button within a form.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">Please note that when stopping or restarting the chat server, the WebSocket connection is closed and the client will not try to reconnect automatically (as we might expect from a production-grade application). This means that it is necessary to refresh the browser after a server restart to reestablish the connection (or implement a reconnection mechanism, which we will not cover here for brevity). Also, in this initial version of our app, the clients will not receive any message sent while they were not connected to the server.</p>
    </div>
    <h3 id="_idParaDest-375" class="title">Running and scaling the chat application</h3>
    <p class="normal">We can try to run our application<a id="_idIndexMarker1375"/> immediately. Just launch the server with the<a id="_idIndexMarker1376"/> following command:</p>
    <pre class="programlisting con"><code class="hljs-con">node index.js 8080
</code></pre>
    <p class="normal">Then, open a couple of browser tabs or even two different browsers, point them at <code class="Code-In-Text--PACKT-">http://localhost:8080</code>, and start chatting:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_08.png" alt=""/></figure>
    <p class="packt_figref">Figure 13.8: Our new chat application in action</p>
    <p class="normal">Now, we want to see what happens when we try to scale our application by launching multiple instances. Let's try to do that. Let's start another server on another port:</p>
    <pre class="programlisting con"><code class="hljs-con">node index.js 8081
</code></pre>
    <p class="normal">The desired outcome should be that<a id="_idIndexMarker1377"/> two different clients, connected to two different servers, should be able to exchange chat messages. Unfortunately, this is not what happens with our current implementation. We can test this by opening another browser tab to <code class="Code-In-Text--PACKT-">http://localhost:8081</code>.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">In a real-world application, we would use a load balancer to distribute the load across our instances, but for this demo we will not use one. This allows us to access each server instance in a deterministic way to verify how it interacts with the other instances.</p>
    </div>
    <p class="normal">When sending a chat message on one instance, we only broadcast the message locally, distributing it only to the clients connected to that particular server. In practice, the two servers are not talking to each other. We need to integrate them, and that's exactly what we are going to see next.</p>
    <h2 id="_idParaDest-376" class="title">Using Redis as a simple message broker</h2>
    <p class="normal">We start our analysis of<a id="_idIndexMarker1378"/> the most common Pub/Sub <a id="_idIndexMarker1379"/>implementations<a id="_idIndexMarker1380"/> by introducing <strong class="keyword">Redis</strong> (<a href="http://nodejsdp.link/redis"><span class="url">nodejsdp.link/redis</span></a>), which is a very fast and flexible in-memory data structure store. Redis is often used as a database or a cache server, however, among its many features there is a pair of commands specifically designed to implement a centralized Pub/Sub message exchange pattern.</p>
    <p class="normal">Redis' message brokering capabilities are (intentionally) very simple and basic, especially if we compare them to those of more advanced message-oriented middleware. However, this is one of the main reasons for its popularity. Often, Redis is already available in an existing infrastructure, for example, used as a cache server or as a session data store. Its speed and flexibility make it a very popular choice for sharing data in a distributed system. So, as soon as the need for a publish/subscribe broker arises in a project, the most simple and immediate choice is to reuse Redis itself, avoiding the need to install and maintain a dedicated message broker.</p>
    <p class="normal">Let's now work on an example<a id="_idIndexMarker1381"/> to demonstrate the simplicity and power of using Redis <a id="_idIndexMarker1382"/>as a message broker.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">This example requires a working installation of Redis, listening on its default port. You can find more details at <a href="http://nodejsdp.link/redis-quickstart"><span class="url">nodejsdp.link/redis-quickstart</span></a>.</p>
    </div>
    <p class="normal">Our plan of action is to integrate our chat servers using Redis as a message broker. Each instance publishes any message received from its clients to the broker, and at the same time, it subscribes for any message coming from other server instances. As we can see, each server in our architecture is both a subscriber and a publisher. The following diagram shows a representation of the architecture that we want to obtain:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_09.png" alt=""/></figure>
    <p class="packt_figref">Figure 13.9: Using Redis as a message broker for our chat application</p>
    <p class="normal">Based on the architecture described in <em class="italic">Figure 13.9</em>, we can sum up the journey of a message as follows:</p>
    <ol>
      <li class="numbered">The message is typed into the textbox of the web page and sent to the connected instance of our chat server.</li>
      <li class="numbered">The message is then published to the broker.</li>
      <li class="numbered">The broker dispatches the message to all the subscribers, which in our architecture are all the instances of the chat server.</li>
      <li class="numbered">In each instance, the message is<a id="_idIndexMarker1383"/> distributed to all the connected clients.</li>
    </ol>
    <p class="normal">Let's see in practice how this <a id="_idIndexMarker1384"/>works. Let's modify the server code by adding the publish/subscribe logic:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> { createServer } <span class="hljs-keyword">from</span> <span class="hljs-string">'http'</span>
<span class="hljs-keyword">import</span> staticHandler <span class="hljs-keyword">from</span> <span class="hljs-string">'serve-handler'</span>
<span class="hljs-keyword">import</span> ws <span class="hljs-keyword">from</span> <span class="hljs-string">'ws'</span>
<strong class="hljs-keyword-slc">import</strong><strong class="hljs-slc"> Redis </strong><strong class="hljs-keyword-slc">from</strong><strong class="hljs-slc"> </strong><strong class="hljs-string-slc">'ioredis'</strong>                                <span class="hljs-comment">// (1)</span>
<strong class="hljs-keyword-slc">const</strong><strong class="hljs-slc"> redisSub = </strong><strong class="hljs-keyword-slc">new</strong><strong class="hljs-slc"> Redis()</strong>
<strong class="hljs-keyword-slc">const</strong><strong class="hljs-slc"> redisPub = </strong><strong class="hljs-keyword-slc">new</strong><strong class="hljs-slc"> Redis()</strong>
<span class="hljs-comment">// serve static files</span>
<span class="hljs-keyword">const</span> server = createServer(<span class="hljs-function">(</span><span class="hljs-params">req, res</span><span class="hljs-function">) =&gt;</span> {
  <span class="hljs-keyword">return</span> staticHandler(req, res, { <span class="hljs-attr">public</span>: <span class="hljs-string">'www'</span> })
})
<span class="hljs-keyword">const</span> wss = <span class="hljs-keyword">new</span> ws.Server({ server })
wss.on(<span class="hljs-string">'connection'</span>, <span class="hljs-params">client</span><span class="hljs-function"> =&gt;</span> {
  <span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Client connected'</span>)
  client.on(<span class="hljs-string">'message'</span>, <span class="hljs-params">msg</span><span class="hljs-function"> =&gt;</span> {
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Message: </span><span class="hljs-subst">${msg}</span><span class="hljs-string">`</span>)
    <strong class="hljs-slc">redisPub.publish(</strong><strong class="hljs-string-slc">'chat_messages'</strong><strong class="hljs-slc">, msg)</strong>                 <span class="hljs-comment">// (2)</span>
  })
})
<strong class="hljs-slc">redisSub.subscribe(</strong><strong class="hljs-string-slc">'chat_messages'</strong><strong class="hljs-slc">)</strong>                        <span class="hljs-comment">// (3)</span>
<strong class="hljs-slc">redisSub.on(</strong><strong class="hljs-string-slc">'message'</strong><strong class="hljs-slc">, </strong><strong class="hljs-function-slc">(</strong><strong class="hljs-params-slc">channel, msg</strong><strong class="hljs-function-slc">) =&gt;</strong><strong class="hljs-slc"> {</strong>
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> client <span class="hljs-keyword">of</span> wss.clients) {
    <span class="hljs-keyword">if</span> (client.readyState === ws.OPEN) {
      client.send(msg)
    }
  }
})
server.listen(process.argv[<span class="hljs-number">2</span>] || <span class="hljs-number">8080</span>)
</code></pre>
    <p class="normal">The changes that we made to our original chat server are highlighted in the preceding code. This how the new implementation works:</p>
    <ol>
      <li class="numbered">To connect our Node.js application to the Redis server, we use the <code class="Code-In-Text--PACKT-">ioredis</code> package (<a href="http://nodejsdp.link/ioredis"><span class="url">nodejsdp.link/ioredis</span></a>), which is a complete Node.js client supporting all the available Redis commands. Next, we instantiate two different connections, one used to subscribe to a channel, the other to publish messages. This is necessary in Redis, because once a connection is put in subscriber mode, only commands related to the subscription can be used. This means that we need a second connection for publishing messages.</li>
      <li class="numbered">When a new message is<a id="_idIndexMarker1385"/> received from a connected client, we publish the<a id="_idIndexMarker1386"/> message in the <code class="Code-In-Text--PACKT-">chat_messages</code> channel. We don't directly broadcast the message to our clients because our server is subscribed to the same channel (as we will see in a moment), so it will come back to us through Redis. For the scope of this example, this is a simple and effective mechanism. However, depending on the requirements of your application, you may instead want to broadcast the message immediately and ignore any message arriving from Redis and originating from the current server instance. We leave this to you as an exercise.</li>
      <li class="numbered">As we said, our server also has to subscribe to the <code class="Code-In-Text--PACKT-">chat_messages</code> channel, so we register a listener to receive all the messages published into that channel (either by the current server instance or any other chat server instance). When a message is received, we simply broadcast it to all the clients connected to the current WebSocket server.</li>
    </ol>
    <p class="normal">These few changes are enough to integrate all the chat server instances that we might decide to start. To prove this, you can try starting multiple instances of our application:</p>
    <pre class="programlisting con"><code class="hljs-con">node index.js 8080
node index.js 8081
node index.js 8082
</code></pre>
    <p class="normal">You can then connect multiple browser tabs to each instance and verify that the messages you send to one instance are successfully received by all the other clients connected to the other instances.</p>
    <p class="normal">Congratulations! We just integrated multiple nodes of a distributed real-time application using the Publish/Subscribe pattern.</p>
    <div class="packt_tip">
      <p class="Tip--PACKT-">Redis allows us to publish and subscribe to channels identified by a string, for example, <code class="Code-In-Text--PACKT-">chat.nodejs</code>. But it also allows us to use glob-style patterns to define subscriptions that can potentially match multiple channels, for example, <code class="Code-In-Text--PACKT-">chat.*</code>.</p>
    </div>
    <h2 id="_idParaDest-377" class="title">Peer-to-peer Publish/Subscribe with ZeroMQ</h2>
    <p class="normal">The presence of a broker<a id="_idIndexMarker1387"/> can considerably simplify the architecture of a messaging system. However, in some circumstances, this may not be the best solution. This includes all the situations where a low latency is critically important, or when scaling complex distributed systems, or when the presence of a single point of failure is not an option. The alternative to using a broker is, of course, implementing a peer-to-peer messaging system.</p>
    <h3 id="_idParaDest-378" class="title">Introducing ZeroMQ</h3>
    <p class="normal">If our<a id="_idIndexMarker1388"/> project is a good candidate for a peer-to-peer architecture, one of the best solutions to <a id="_idIndexMarker1389"/>evaluate is certainly <strong class="keyword">ZeroMQ</strong> (<a href="http://nodejsdp.link/zeromq"><span class="url">nodejsdp.link/zeromq</span></a>, also known as zmq or ØMQ). ZeroMQ is a networking library that provides the basic tools to build a large variety of messaging patterns. It is low-level, extremely fast, and has a minimalistic API, but it offers all the basic building blocks to create a solid messaging system, such as atomic messages, load balancing, queues, and many more. It supports many types of transport, such as in-process channels (<code class="Code-In-Text--PACKT-">inproc://</code>), inter-process communication (<code class="Code-In-Text--PACKT-">ipc://</code>), multicast using the PGM protocol (<code class="Code-In-Text--PACKT-">pgm://</code> or <code class="Code-In-Text--PACKT-">epgm://</code>), and, of course, the classic TCP (<code class="Code-In-Text--PACKT-">tcp://</code>).</p>
    <p class="normal">Among the features of ZeroMQ, we can also find tools to implement a Publish/Subscribe pattern, which is exactly what we need for our example. So, what we are going to do now is remove the broker (Redis) from the architecture of our chat application and let the various nodes communicate in a peer-to-peer fashion, leveraging the publish/subscribe sockets of ZeroMQ.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">A ZeroMQ socket can be considered as a network socket on steroids, which provides additional abstractions to help implement the most common messaging patterns. For example, we can find sockets designed to implement publish/subscribe, request/reply, or one-way push communications.</p>
    </div>
    <h3 id="_idParaDest-379" class="title">Designing a peer-to-peer architecture for the chat server</h3>
    <p class="normal">When we <a id="_idIndexMarker1390"/>remove the broker from<a id="_idIndexMarker1391"/> our architecture, each instance of the chat server has to directly connect to the other available instances in order to receive the messages they publish. In ZeroMQ, we have two types of sockets specifically designed for this purpose: <code class="Code-In-Text--PACKT-">PUB</code> and <code class="Code-In-Text--PACKT-">SUB</code>. The typical pattern is to bind a <code class="Code-In-Text--PACKT-">PUB</code> socket to a local port where it will start listening for incoming subscription requests from sockets of type <code class="Code-In-Text--PACKT-">SUB</code>.</p>
    <p class="normal">A subscription can have a <em class="italic">filter</em> that specifies what messages are delivered to the connected <code class="Code-In-Text--PACKT-">SUB</code> sockets. The filter is a <a id="_idIndexMarker1392"/>simple <strong class="keyword">binary buffer</strong> (so it can also be a string), which will be matched against the beginning of the message (which is also a binary buffer). When a message is sent through the <code class="Code-In-Text--PACKT-">PUB</code> socket it is broadcast to all the connected <code class="Code-In-Text--PACKT-">SUB</code> sockets, but only after their subscription filters are applied. The filters will be applied to the publisher side only if a <em class="italic">connected</em> protocol is used, such as, for example, TCP.</p>
    <p class="normal">The following diagram shows<a id="_idIndexMarker1393"/> the pattern applied to our <a id="_idIndexMarker1394"/>distributed chat server architecture (with only two instances, for simplicity):</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_10.png" alt="A close up of a logo  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 13.10: Chat server messaging architecture using ZeroMQ PUB/SUB sockets</p>
    <p class="normal"><em class="italic">Figure 13.10</em> shows us the flow of information when we have two instances of the chat application, but the same concept can be applied to <em class="italic">N</em> instances. This architecture tells us that each node must be aware of the other nodes in the system to be able to establish all the necessary connections. It also shows us how the subscriptions go from a <code class="Code-In-Text--PACKT-">SUB</code> socket to a <code class="Code-In-Text--PACKT-">PUB</code> socket, while messages travel in the opposite direction.</p>
    <h3 id="_idParaDest-380" class="title">Using the ZeroMQ PUB/SUB sockets</h3>
    <p class="normal">Let's see how the<a id="_idIndexMarker1395"/> ZeroMQ <code class="Code-In-Text--PACKT-">PUB</code>/<code class="Code-In-Text--PACKT-">SUB</code> sockets work in practice by modifying our chat server:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> { createServer } <span class="hljs-keyword">from</span> <span class="hljs-string">'http'</span>
<span class="hljs-keyword">import</span> staticHandler <span class="hljs-keyword">from</span> <span class="hljs-string">'serve-handler'</span>
<span class="hljs-keyword">import</span> ws <span class="hljs-keyword">from</span> <span class="hljs-string">'ws'</span>
<span class="hljs-keyword">import</span> yargs <span class="hljs-keyword">from</span> <span class="hljs-string">'yargs'</span>                                    <span class="hljs-comment">// (1)</span>
<span class="hljs-keyword">import</span> zmq <span class="hljs-keyword">from</span> <span class="hljs-string">'zeromq'</span>
<span class="hljs-comment">// serve static files</span>
<span class="hljs-keyword">const</span> server = createServer(<span class="hljs-function">(</span><span class="hljs-params">req, res</span><span class="hljs-function">) =&gt;</span> {
  <span class="hljs-keyword">return</span> staticHandler(req, res, { <span class="hljs-attr">public</span>: <span class="hljs-string">'www'</span> })
})
<span class="hljs-keyword">let</span> pubSocket
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">initializeSockets</span><span class="hljs-function"> () </span>{
  pubSocket = <span class="hljs-keyword">new</span> zmq.Publisher()                            <span class="hljs-comment">// (2)</span>
  <span class="hljs-keyword">await</span> pubSocket.bind(<span class="hljs-string">`tcp://127.0.0.1:</span><span class="hljs-subst">${</span>yargs.<span class="hljs-subst">argv</span>.<span class="hljs-subst">pub}</span><span class="hljs-string">`</span>)
  <span class="hljs-keyword">const</span> subSocket = <span class="hljs-keyword">new</span> zmq.Subscriber()                     <span class="hljs-comment">// (3)</span>
  <span class="hljs-keyword">const</span> subPorts = [].concat(yargs.argv.sub)
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> port <span class="hljs-keyword">of</span> subPorts) {
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Subscribing to </span><span class="hljs-subst">${port}</span><span class="hljs-string">`</span>)
    subSocket.connect(<span class="hljs-string">`tcp://127.0.0.1:</span><span class="hljs-subst">${port}</span><span class="hljs-string">`</span>)
  }
  subSocket.subscribe(<span class="hljs-string">'chat'</span>)
  <span class="hljs-keyword">for</span> <span class="hljs-keyword">await</span> (<span class="hljs-keyword">const</span> [msg] <span class="hljs-keyword">of</span> subSocket) {                     <span class="hljs-comment">// (4)</span>
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Message from another server: </span><span class="hljs-subst">${msg}</span><span class="hljs-string">`</span>)
    broadcast(msg.toString().split(<span class="hljs-string">' '</span>)[<span class="hljs-number">1</span>])
  }
}
initializeSockets()
<span class="hljs-keyword">const</span> wss = <span class="hljs-keyword">new</span> ws.Server({ server })
wss.on(<span class="hljs-string">'connection'</span>, <span class="hljs-params">client</span><span class="hljs-function"> =&gt;</span> {
  <span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Client connected'</span>)
  client.on(<span class="hljs-string">'message'</span>, <span class="hljs-params">msg</span><span class="hljs-function"> =&gt;</span> {
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Message: </span><span class="hljs-subst">${msg}</span><span class="hljs-string">`</span>)
    broadcast(msg)
    pubSocket.send(<span class="hljs-string">`chat </span><span class="hljs-subst">${msg}</span><span class="hljs-string">`</span>)                            <span class="hljs-comment">// (5)</span>
  })
})
<span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">broadcast</span><span class="hljs-function"> (</span><span class="hljs-params">msg</span><span class="hljs-function">) </span>{
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> client <span class="hljs-keyword">of</span> wss.clients) {
    <span class="hljs-keyword">if</span> (client.readyState === ws.OPEN) {
      client.send(msg)
    }
  }
}
server.listen(yargs.argv.http || <span class="hljs-number">8080</span>)
</code></pre>
    <p class="normal">The preceding code clearly shows that the logic of our application became slightly more complicated, however, it's still straightforward considering that we are implementing a peer-to-peer Publish/Subscribe pattern. Let's see how all the pieces come together:</p>
    <ol>
      <li class="numbered">We import two new packages. First, we import <code class="Code-In-Text--PACKT-">yargs</code> (<a href="http://nodejsdp.link/yargs"><span class="url">nodejsdp.link/yargs</span></a>), which is a command-line argument parser; we need this to easily accept named arguments. Secondly, we<a id="_idIndexMarker1396"/> import the <code class="Code-In-Text--PACKT-">zeromq</code> package (<a href="http://nodejsdp.link/zeromq"><span class="url">nodejsdp.link/zeromq</span></a>), which is a Node.js client for ZeroMQ.</li>
      <li class="numbered">In the <code class="Code-In-Text--PACKT-">initializeSockets()</code> function, we immediately create our <code class="Code-In-Text--PACKT-">Publisher</code> socket and bind it to the port provided in the <code class="Code-In-Text--PACKT-">--pub</code> command-line argument.</li>
      <li class="numbered">We create the <code class="Code-In-Text--PACKT-">Subscriber</code> socket and we connect it to the <code class="Code-In-Text--PACKT-">Publisher</code> sockets of the other instances of our application. The ports of the target <code class="Code-In-Text--PACKT-">Publisher</code> sockets are provided in the <code class="Code-In-Text--PACKT-">--sub</code> command-line arguments (there might be more than one). We then create the actual subscription, by providing <code class="Code-In-Text--PACKT-">chat</code> as a filter, which means that we will receive only the messages beginning with <code class="Code-In-Text--PACKT-">chat</code>.</li>
      <li class="numbered">We start listening for messages arriving at our <code class="Code-In-Text--PACKT-">Subscriber</code> socket using a <code class="Code-In-Text--PACKT-">for await...of</code> loop, since <code class="Code-In-Text--PACKT-">subSocket</code> is an async iterable. With each message we receive, we do some simple parsing to remove the <code class="Code-In-Text--PACKT-">chat</code> prefix, and then we <code class="Code-In-Text--PACKT-">broadcast()</code> the actual payload to all the clients connected to the current WebSocket server.</li>
      <li class="numbered">When a new message is received by the WebSocket server of the current instance, we broadcast it to all the connected clients but we also publish it through our <code class="Code-In-Text--PACKT-">Publisher</code> socket. We use <code class="Code-In-Text--PACKT-">chat</code> as a prefix followed by a space, so that the message will be published to all the subscriptions using <code class="Code-In-Text--PACKT-">chat</code> as a filter.</li>
    </ol>
    <p class="normal">We have now built a simple distributed system, integrated using a peer-to-peer Publish/Subscribe pattern!</p>
    <p class="normal">Let's fire it up, let's start three instances of our application by making sure to connect their <code class="Code-In-Text--PACKT-">Publisher</code> and <code class="Code-In-Text--PACKT-">Subscriber</code> sockets properly:</p>
    <pre class="programlisting con"><code class="hljs-con">node index.js --http 8080 --pub 5000 --sub 5001 --sub 5002
node index.js --http 8081 --pub 5001 --sub 5000 --sub 5002
node index.js --http 8082 --pub 5002 --sub 5000 --sub 5001
</code></pre>
    <p class="normal">The first command will start an instance with an HTTP server listening on port <code class="Code-In-Text--PACKT-">8080</code>, while binding its <code class="Code-In-Text--PACKT-">Publisher</code> socket on port <code class="Code-In-Text--PACKT-">5000</code> and connecting the <code class="Code-In-Text--PACKT-">Subscriber</code> socket to ports <code class="Code-In-Text--PACKT-">5001</code> and <code class="Code-In-Text--PACKT-">5002</code>, which is where the <code class="Code-In-Text--PACKT-">Publisher</code> sockets of the other two instances should be listening at. The<a id="_idIndexMarker1397"/> other two commands work in a similar way.</p>
    <p class="normal">Now, the first thing you will see is that ZeroMQ will not complain if a <code class="Code-In-Text--PACKT-">Subscriber</code> socket can't establish a connection to a <code class="Code-In-Text--PACKT-">Publisher</code> socket. For example, at the time of the first command, there are no <code class="Code-In-Text--PACKT-">Publisher</code> sockets listening on ports <code class="Code-In-Text--PACKT-">5001</code> and <code class="Code-In-Text--PACKT-">5002</code>, however, ZeroMQ is not throwing any error. This is because ZeroMQ is built to be resilient to faults and it implements a built-in connection retry mechanism. This feature also comes in particularly handy if any node goes down or is restarted. The same <em class="italic">forgiving</em> logic applies to the <code class="Code-In-Text--PACKT-">Publisher</code> socket: if there are no subscriptions, it will simply drop all the messages, but it will continue working.</p>
    <p class="normal">At this point, we can try to navigate with a browser to any of the server instances that we started and verify that the messages are properly propagated to all the chat servers.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">In the previous example, we assumed a static architecture where the number of instances and their addresses are known in advance. We can introduce a service registry, as explained in <em class="chapterRef">Chapter 12</em>, <em class="italic">Scalability and Architectural Patterns</em>, to connect our instances dynamically. It is also important to point out that ZeroMQ can be used to implement a broker using the same primitives we demonstrated here.</p>
    </div>
    <h2 id="_idParaDest-381" class="title">Reliable message delivery with queues</h2>
    <p class="normal">An important abstraction <a id="_idIndexMarker1398"/>in a messaging system is the <strong class="keyword">message queue</strong> (<strong class="keyword">MQ</strong>). With a message queue, the sender and the receiver(s) of the <a id="_idIndexMarker1399"/>message don't necessarily need to be active and connected at the same time to establish a communication, because the queuing system takes care of storing the messages until the destination is able to receive them. This behavior is opposed to the <em class="italic">fire-and-forget</em> paradigm, where a subscriber can receive messages only during the time it is connected to the messaging system.</p>
    <p class="normal">A subscriber that is able to always <a id="_idIndexMarker1400"/>reliably receive all the messages, even those sent when it's not listening for them, is called a <strong class="keyword">durable subscriber</strong>.</p>
    <p class="normal">We can summarize the <strong class="keyword">delivery semantic</strong> of a messaging system in three categories:</p>
    <ul>
      <li class="Bullet--PACKT-"><strong class="keyword">At most once</strong>: Also known as <em class="italic">fire-and-forget</em>, the message is not persisted, and the delivery is not acknowledged. This means that the message can be lost in cases of crashes or disconnections of the receiver.</li>
      <li class="Bullet--PACKT-"><strong class="keyword">At least once</strong>: The message is guaranteed to be received at least once, but duplicates might occur if, for example, the receiver crashes before notifying the sender of the reception. This implies that the message has to be persisted in the eventuality it has to be sent again.</li>
      <li class="Bullet-End--PACKT-"><strong class="keyword">Exactly once</strong>: This is the most reliable delivery semantic. It guarantees that the message is received once and only once. This comes at the expense of a slower and more data-intensive mechanism for acknowledging the delivery of messages.</li>
    </ul>
    <p class="normal">We have a durable subscriber when our messaging system can achieve an "at least once" or an "exactly once" delivery semantic and to do that, the system has to use a message queue to accumulate the messages while the subscriber is disconnected. The queue can be stored in memory or persisted on disk to allow the recovery of its messages even if the queuing system restarts or crashes.</p>
    <p class="normal">The following diagram shows a graphical representation of a durable subscriber backed by a message queue:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_11.png" alt="A close up of text on a white background  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 13.11: Example behavior of a messaging system backed by a queue</p>
    <p class="normal"><em class="italic">Figure 13.11</em> shows us <a id="_idIndexMarker1401"/>how a message queue can help us implement the Durable Subscriber pattern. As we can see, during normal operations (1) messages travel from the publisher to the subscriber through the message queue. When the subscriber goes offline (2) because of a crash, a malfunction, or simply a planned maintenance period, any message sent by the publisher is stored and accumulated safely in the message queue. Afterward, when the subscriber comes back online (3), all messaged accumulated in the queue are sent to the subscriber, so no message is lost.</p>
    <p class="normal">The durable subscriber is probably the most important pattern enabled by a message queue, but it's certainly not the only one, as we will see later in the chapter.</p>
    <p class="normal">Next, we are going to learn about AMQP, which is the protocol we are going to use throughout the rest of the chapter to implement our message queue examples.</p>
    <h3 id="_idParaDest-382" class="title">Introducing AMQP</h3>
    <p class="normal">A message queue is normally <a id="_idIndexMarker1402"/>used in situations where messages must not be lost, which includes mission-critical applications such as banking systems, air traffic management and control systems, medical applications, and so on. This usually means that the typical enterprise-grade message queue is a very complex piece of software, which utilizes bulletproof protocols and persistent storage to guarantee the delivery of the message even in the presence of malfunctions. For this reason, enterprise messaging middleware has been, for many years, a prerogative of tech giants such as Oracle and IBM, each one of them usually implementing their own proprietary protocol, resulting in a strong customer lock-in. Fortunately, it's been a few years now since messaging systems entered the mainstream, thanks to the growth of open protocols such as AMQP, STOMP, and MQTT. Throughout the rest of the chapter we are going to use AMQP as the messaging protocol for our queuing system, so let's give it a proper introduction.</p>
    <p class="normal"><strong class="keyword">AMQP</strong> is an open <a id="_idIndexMarker1403"/>standard protocol supported by many message-queuing systems. Besides defining a common communication protocol, it also provides a model to describe routing, filtering, queuing, reliability, and security.</p>
    <p class="normal">The following diagram shows us all the AMQP components at a glance:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_12.png" alt="A screenshot of a map  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 13.12: Example of an AMQP-based messaging system</p>
    <p class="normal">As shown in <em class="italic">Figure 13.12</em>, in AMQP there are three essential components:</p>
    <ul>
      <li class="Bullet--PACKT-"><strong class="keyword">Queue</strong>: The data <a id="_idIndexMarker1404"/>structure responsible for storing the messages consumed by the clients. The messages from a queue are pushed (or pulled) to one or more consumers. If multiple consumers are attached to the same queue, the messages are load balanced across them. A queue can be any of the following:<ul>
          <li class="Bullet-Within-Bullet--PACKT-"><strong class="keyword">Durable</strong>: This means that the queue is automatically recreated if the broker restarts. A durable queue does not imply that its contents are preserved as well; in fact, only messages that are marked as persistent are saved to the disk and restored in case of a restart.</li>
          <li class="Bullet-Within-Bullet--PACKT-"><strong class="keyword">Exclusive</strong>: This means that the queue is bound to only one particular subscriber connection. When the connection is closed, the queue is destroyed.</li>
          <li class="Bullet-Within-Bullet--PACKT-"><strong class="keyword">Auto-delete</strong>: This will cause the queue to be deleted when the last subscriber disconnects.</li>
        </ul>
      </li>
      <li class="Bullet--PACKT-"><strong class="keyword">Exchange</strong>: This is where a message is published. An exchange<a id="_idIndexMarker1405"/> routes the messages to one or more queues depending on the algorithm it implements:<ul>
          <li class="Bullet-Within-Bullet--PACKT-"><strong class="keyword">Direct exchange</strong>: It routes the messages by matching an entire routing key (for example, <code class="Code-In-Text--PACKT-">chat.msg</code>)</li>
          <li class="Bullet-Within-Bullet--PACKT-"><strong class="keyword">Topic exchange</strong>: It distributes the messages using a glob-like pattern matched against the routing key (for example, <code class="Code-In-Text--PACKT-">chat.#</code> matches all the routing keys starting with <code class="Code-In-Text--PACKT-">chat.</code>)</li>
          <li class="Bullet-Within-Bullet--PACKT-"><strong class="keyword">Fanout exchange</strong>: It broadcasts a message to all the connected queues, ignoring any routing key provided</li>
        </ul>
      </li>
      <li class="Bullet-End--PACKT-"><strong class="keyword">Binding</strong>: This is the <a id="_idIndexMarker1406"/>link between exchanges and queues. It also defines the routing key or the pattern used to filter the messages that arrive from the exchange.</li>
    </ul>
    <p class="normal">These components are managed by a broker, which exposes an API for creating and manipulating them. When connecting to a broker, a client creates a <strong class="keyword">channel</strong>—an abstraction of a connection—which is responsible for maintaining the state of the communication with the broker.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">In AMQP, we can obtain the Durable Subscriber pattern by creating any type of queue that is not exclusive or auto-delete.</p>
    </div>
    <p class="normal">The AMQP model is way more complex than the messaging systems we have used so far (Redis and ZeroMQ). However, it offers a set of features and a level of reliability that would be very hard to obtain using only primitive publish/subscribe mechanisms.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">You can find a detailed introduction to the AMQP model<a id="_idIndexMarker1407"/> on the RabbitMQ website at <a href="http://nodejsdp.link/amqp-components"><span class="url">nodejsdp.link/amqp-components</span></a>.</p>
    </div>
    <h3 id="_idParaDest-383" class="title">Durable subscribers with AMQP and RabbitMQ</h3>
    <p class="normal">Let's now practice what<a id="_idIndexMarker1408"/> we learned about durable subscribers and AMQP and work on a small <a id="_idIndexMarker1409"/>example. A typical scenario where it's <a id="_idIndexMarker1410"/>important to not lose any message is when we want to keep the different services of a microservice architecture in sync (we already described this integration pattern in the previous chapter). If we want to use a broker to keep all our services on the same page, it's important that we don't lose any information, otherwise we might end up in an inconsistent state.</p>
    <h4 class="title">Designing a history service for the chat application</h4>
    <p class="normal">Let's now extend our<a id="_idIndexMarker1411"/> small chat application using a<a id="_idIndexMarker1412"/> microservice approach. Let's add a history service that persists our chat messages inside a database, so that when a client connects, we can query the service and retrieve the entire chat history. We are going to integrate the history service with the chat server using the RabbitMQ broker (<a href="http://nodejsdp.link/rabbitmq"><span class="url">nodejsdp.link/rabbitmq</span></a>) and AMQP.</p>
    <p class="normal">The following diagram shows our planned architecture:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_13.png" alt="A close up of a piece of paper  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 13.13: Architecture of our chat application with AMQP and history service</p>
    <p class="normal">As shown in <em class="italic">Figure 13.13</em>, we are going to use a single fanout exchange; we don't need any complicated routing logic, so our scenario does not require any exchange more complex than that. Next, we will create one queue for each instance of the chat server. </p>
    <p class="normal">These queues are exclusive since we are not interested in receiving any messages missed while a chat server is offline; that's the job of our history service, which can eventually also implement more complicated queries against the stored messages. In practice, this means that our chat servers are not durable subscribers and their queues will be destroyed as soon as the connection is closed. The history service instead cannot afford to lose any messages, otherwise it would not fulfill its very purpose. Therefore, the queue we are going to create for it has to be durable, so that any message that is published while the history<a id="_idIndexMarker1413"/> service is disconnected will be kept in <a id="_idIndexMarker1414"/>the queue and delivered when it comes back online.</p>
    <p class="normal">We are going to use the familiar LevelUP as the storage engine for the history service, while we will use the <code class="Code-In-Text--PACKT-">amqplib</code> package (<a href="http://nodejsdp.link/amqplib"><span class="url">nodejsdp.link/amqplib</span></a>) to connect to RabbitMQ using the AMQP protocol.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">The example that follows requires a working RabbitMQ server, listening on its default port. For more information, please refer to its official installation guide at <a href="http://nodejsdp.link/rabbitmq-getstarted"><span class="url">nodejsdp.link/rabbitmq-getstarted</span></a>.</p>
    </div>
    <h4 class="title">Implementing a history service using AMQP</h4>
    <p class="normal">Let's now <a id="_idIndexMarker1415"/>implement our history service! We are going to<a id="_idIndexMarker1416"/> create a standalone application (a typical microservice), which is implemented in the <code class="Code-In-Text--PACKT-">historySvc.js</code> module. The module is made up of two parts: an HTTP server to expose the chat history to clients, and an AMQP consumer responsible for capturing the chat messages and storing them in a local database.</p>
    <p class="normal">Let's see what this looks like in the code that follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> { createServer } <span class="hljs-keyword">from</span> <span class="hljs-string">'http'</span>
<span class="hljs-keyword">import</span> level <span class="hljs-keyword">from</span> <span class="hljs-string">'level'</span>
<span class="hljs-keyword">import</span> timestamp <span class="hljs-keyword">from</span> <span class="hljs-string">'monotonic-timestamp'</span>
<span class="hljs-keyword">import</span> JSONStream <span class="hljs-keyword">from</span> <span class="hljs-string">'JSONStream'</span>
<span class="hljs-keyword">import</span> amqp <span class="hljs-keyword">from</span> <span class="hljs-string">'amqplib'</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">main</span><span class="hljs-function"> () </span>{
  <span class="hljs-keyword">const</span> db = level(<span class="hljs-string">'./msgHistory'</span>)
  <span class="hljs-keyword">const</span> connection = <span class="hljs-keyword">await</span> amqp.connect(<span class="hljs-string">'amqp://localhost'</span>)  <span class="hljs-comment">// (1)</span>
  <span class="hljs-keyword">const</span> channel = <span class="hljs-keyword">await</span> connection.createChannel()
  <span class="hljs-keyword">await</span> channel.assertExchange(<span class="hljs-string">'chat'</span>, <span class="hljs-string">'fanout'</span>)             <span class="hljs-comment">// (2)</span>
  <span class="hljs-keyword">const</span> { queue } = channel.assertQueue(<span class="hljs-string">'chat_history'</span>)      <span class="hljs-comment">// (3)</span>
  <span class="hljs-keyword">await</span> channel.bindQueue(queue, <span class="hljs-string">'chat'</span>)                     <span class="hljs-comment">// (4)</span>
  channel.consume(queue, <span class="hljs-keyword">async</span> msg =&gt; {                      <span class="hljs-comment">// (5)</span>
    <span class="hljs-keyword">const</span> content = msg.content.toString()
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Saving message: </span><span class="hljs-subst">${content}</span><span class="hljs-string">`</span>)
    <span class="hljs-keyword">await</span> db.put(timestamp(), content)
    channel.ack(msg)
  })
  createServer(<span class="hljs-function">(</span><span class="hljs-params">req, res</span><span class="hljs-function">) =&gt;</span> {
    res.writeHead(<span class="hljs-number">200</span>)
    db.createValueStream()
      .pipe(JSONStream.stringify())
      .pipe(res)
  }).listen(<span class="hljs-number">8090</span>)
}
main().catch(<span class="hljs-params">err</span><span class="hljs-function"> =&gt;</span> <span class="hljs-built_in">console</span>.error(err))
</code></pre>
    <p class="normal">We can immediately see that AMQP requires a little bit of setting up, which is necessary to create and connect all the components of the model. Let's see in detail how it works:</p>
    <ol>
      <li class="numbered">We first establish a<a id="_idIndexMarker1417"/> connection with the AMQP broker, which <a id="_idIndexMarker1418"/>in our case is RabbitMQ. Then, we create a channel, which is similar to a session that will maintain the state of our communications.</li>
      <li class="numbered">Next, we set up an exchange, named <code class="Code-In-Text--PACKT-">chat</code>. As we already mentioned, it is a fanout exchange. The <code class="Code-In-Text--PACKT-">assertExchange()</code> command will make sure that the exchange exists on the broker, otherwise it will create it.</li>
      <li class="numbered">We also create a queue called <code class="Code-In-Text--PACKT-">chat_history</code>. By default, the queue is durable (not exclusive and not auto-delete), so we don't need to pass any extra options to support durable subscribers.</li>
      <li class="numbered">Next, we bind the queue to the exchange we previously created. Here, we don't need any other particular option (such as a routing key or pattern), as the exchange is of the type fanout, so it doesn't perform any filtering.</li>
      <li class="numbered">Finally, we can begin to listen for messages coming from the queue we just created. We save every message that we receive in a LevelDB database using a monotonic timestamp as the key (see <a href="http://nodejsdp.link/monotonic-timestamp"><span class="url">nodejsdp.link/monotonic-timestamp</span></a>) to keep the messages sorted by date. It's also interesting to see that we are acknowledging every message using <code class="Code-In-Text--PACKT-">channel.ack(msg)</code>, but only after the message is successfully saved into the database. If the ACK (acknowledgment) is not received by the broker, the message is kept in the queue to be processed again.</li>
    </ol>
    <div class="packt_tip">
      <p class="Tip--PACKT-">If we are not interested in sending explicit acknowledgments, we can pass the <code class="Code-In-Text--PACKT-">{ noAck: true }</code> option  to the <code class="Code-In-Text--PACKT-">channel.consume()</code> API.</p>
    </div>
    <h4 class="title">Integrating the chat application with AMQP</h4>
    <p class="normal">To integrate the chat <a id="_idIndexMarker1419"/>servers using AMQP, we have to<a id="_idIndexMarker1420"/> use a setup very similar to the one we implemented in the history service, but with some small variations. So, let's see how the new <code class="Code-In-Text--PACKT-">index.js</code> module looks with the introduction of AMQP:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> { createServer } <span class="hljs-keyword">from</span> <span class="hljs-string">'http'</span>
<span class="hljs-keyword">import</span> staticHandler <span class="hljs-keyword">from</span> <span class="hljs-string">'serve-handler'</span>
<span class="hljs-keyword">import</span> ws <span class="hljs-keyword">from</span> <span class="hljs-string">'ws'</span>
<span class="hljs-keyword">import</span> amqp <span class="hljs-keyword">from</span> <span class="hljs-string">'amqplib'</span>
<span class="hljs-keyword">import</span> JSONStream <span class="hljs-keyword">from</span> <span class="hljs-string">'JSONStream'</span>
<span class="hljs-keyword">import</span> superagent <span class="hljs-keyword">from</span> <span class="hljs-string">'superagent'</span>
<span class="hljs-keyword">const</span> httpPort = process.argv[<span class="hljs-number">2</span>] || <span class="hljs-number">8080</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">main</span><span class="hljs-function"> () </span>{
  <span class="hljs-keyword">const</span> connection = <span class="hljs-keyword">await</span> amqp.connect(<span class="hljs-string">'amqp://localhost'</span>)
  <span class="hljs-keyword">const</span> channel = <span class="hljs-keyword">await</span> connection.createChannel()
  <span class="hljs-keyword">await</span> channel.assertExchange(<span class="hljs-string">'chat'</span>, <span class="hljs-string">'fanout'</span>)
  <span class="hljs-keyword">const</span> { queue } = <span class="hljs-keyword">await</span> channel.assertQueue(               <span class="hljs-comment">// (1)</span>
    <span class="hljs-string">`chat_srv_</span><span class="hljs-subst">${httpPort}</span><span class="hljs-string">`</span>,
    { <span class="hljs-attr">exclusive</span>: <span class="hljs-literal">true</span> }
  )
  <span class="hljs-keyword">await</span> channel.bindQueue(queue, <span class="hljs-string">'chat'</span>)
  channel.consume(queue, <span class="hljs-params">msg</span><span class="hljs-function"> =&gt;</span> {                            <span class="hljs-comment">// (2)</span>
    msg = msg.content.toString()
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`From queue: </span><span class="hljs-subst">${msg}</span><span class="hljs-string">`</span>)
    broadcast(msg)
  }, { <span class="hljs-attr">noAck</span>: <span class="hljs-literal">true</span> })
  <span class="hljs-comment">// serve static files</span>
  <span class="hljs-keyword">const</span> server = createServer(<span class="hljs-function">(</span><span class="hljs-params">req, res</span><span class="hljs-function">) =&gt;</span> {
    <span class="hljs-keyword">return</span> staticHandler(req, res, { <span class="hljs-attr">public</span>: <span class="hljs-string">'www'</span> })
  })
  <span class="hljs-keyword">const</span> wss = <span class="hljs-keyword">new</span> ws.Server({ server })
  wss.on(<span class="hljs-string">'connection'</span>, <span class="hljs-params">client</span><span class="hljs-function"> =&gt;</span> {
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Client connected'</span>)
    client.on(<span class="hljs-string">'message'</span>, <span class="hljs-params">msg</span><span class="hljs-function"> =&gt;</span> {
      <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Message: </span><span class="hljs-subst">${msg}</span><span class="hljs-string">`</span>)
      channel.publish(<span class="hljs-string">'chat'</span>, <span class="hljs-string">''</span>, Buffer.from(msg))          <span class="hljs-comment">// (3)</span>
    })
    <span class="hljs-comment">// query the history service</span>
    superagent                                               <span class="hljs-comment">// (4)</span>
      .get(<span class="hljs-string">'http://localhost:8090'</span>)
      .on(<span class="hljs-string">'error'</span>, <span class="hljs-params">err</span><span class="hljs-function"> =&gt;</span> <span class="hljs-built_in">console</span>.error(err))
      .pipe(JSONStream.parse(<span class="hljs-string">'*'</span>))
      .on(<span class="hljs-string">'data'</span>, <span class="hljs-params">msg</span><span class="hljs-function"> =&gt;</span> client.send(msg))
  })
  <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">broadcast</span><span class="hljs-function"> (</span><span class="hljs-params">msg</span><span class="hljs-function">) </span>{
    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> client <span class="hljs-keyword">of</span> wss.clients) {
      <span class="hljs-keyword">if</span> (client.readyState === ws.OPEN) {
        client.send(msg)
      }
    }
  }
  server.listen(httpPort)
}
main().catch(<span class="hljs-params">err</span><span class="hljs-function"> =&gt;</span> <span class="hljs-built_in">console</span>.error(err))
</code></pre>
    <p class="normal">As we can see, AMQP made the code a little bit more verbose on this occasion too, but at this point we should already be familiar with most of it. There are just a few aspects to be aware of:</p>
    <ol>
      <li class="numbered">As we mentioned, our <a id="_idIndexMarker1421"/>chat server doesn't need to be a durable subscriber: a fire-and-forget paradigm is enough. So when we create <a id="_idIndexMarker1422"/>our queue, we pass the <code class="Code-In-Text--PACKT-">{ exclusive: true }</code> option, indicating that the queue is scoped to the current connection and therefore it will be destroyed as soon as the chat server shuts down.</li>
      <li class="numbered">For the same reason as in the previous point, we don't need to send back any acknowledgement when we read a message from the queue. So, to make things easier, we pass the <code class="Code-In-Text--PACKT-">{ noAck: true }</code> option when starting to consume the messages from the queue.</li>
      <li class="numbered">Publishing a new message is also very easy. We simply have to specify the target exchange (<code class="Code-In-Text--PACKT-">chat</code>) and a routing key, which in our case is empty (<code class="Code-In-Text--PACKT-">''</code>) because we are using a fanout exchange, so there is no routing to perform.</li>
      <li class="numbered">The other peculiarity of this version of our chat server is that we can now present to the user the full history of the chat, thanks to our history microservice. We do that by querying the history microservice and sending every past message to the client as soon as a new connection is established.</li>
    </ol>
    <p class="normal">We can now run our new improved chat application. To do that, first make sure to have RabbitMQ running locally on your machine, then let's start two chat servers and the history service in three different terminals:</p>
    <pre class="programlisting con"><code class="hljs-con">node index.js 8080
node index.js 8081
node historySvc.js
</code></pre>
    <p class="normal">We should now focus our attention on how our system, and in particular the history service, behaves in case of downtime. If we stop the history server and continue to send messages using the web UI of the chat application, we will see that when the history server is restarted, it will immediately receive all the messages it missed. This is a perfect demonstration of how the Durable Subscriber pattern works!</p>
    <div class="note">
      <p class="Information-Box--PACKT-">It is interesting to see how the microservice approach allows our system to survive even without one of its components—the history service. There would be a temporary reduction of functionality (no chat history available) but people would still be able to exchange chat messages in real time. Awesome!</p>
    </div>
    <h2 id="_idParaDest-384" class="title">Reliable messaging with streams</h2>
    <p class="normal">At the beginning of this chapter, we<a id="_idIndexMarker1423"/> mentioned that a possible alternative to message<a id="_idIndexMarker1424"/> queues are <strong class="keyword">streams</strong>. The two paradigms are similar in scope, but fundamentally different in their approach to messaging. In this section, we are going to unveil the power of streams by leveraging Redis Streams to implement our chat application.</p>
    <h3 id="_idParaDest-385" class="title">Characteristics of a streaming platform</h3>
    <p class="normal">In the context of <a id="_idIndexMarker1425"/>system integration, a <strong class="keyword">stream</strong> (or <strong class="keyword">log</strong>) is an <a id="_idIndexMarker1426"/>ordered, append-only, durable data structure. Messages—which in the <a id="_idIndexMarker1427"/>context of streams would be more appropriately called <strong class="keyword">records</strong>—are<a id="_idIndexMarker1428"/> always added at the end of the stream and, unlike queues, they are not automatically deleted when they are consumed. Essentially, this characteristic makes a stream more similar to a data store than to a message broker. And like a data store, a stream can be queried to retrieve a batch of past records or replayed starting from a specific record.</p>
    <p class="normal">Another important characteristic of streams is that records are pulled by the consumer from the stream. This intrinsically allows the consumer to process the records at its own pace without risking being overwhelmed.</p>
    <p class="normal">Based on these features, a stream allows us to implement reliable message delivery out of the box, since no data is ever <em class="italic">lost</em> from the stream (even though data can still be removed explicitly or can be deleted after an optional retention period). In fact, as <em class="italic">Figure 13.14</em> shows, if a consumer crashes, all it has to do is start reading the stream from where it left off:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_14.png" alt="A close up of text on a white background  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 13.14: Reliable message delivery with streams</p>
    <p class="normal">As <em class="italic">Figure 13.14</em> shows, during normal operations (1) the consumer processes the records in the stream as soon as they are added by the producer. When the consumer becomes unavailable (2) because of a problem or a scheduled maintenance, the producer simply continues to add records to the stream as normal. When the consumer comes back online (3), it starts processing the records from the point where it left. The main aspect of this mechanism<a id="_idIndexMarker1429"/> is that it's very simple and barebone, but it's quite effective at making sure that no message is lost even when the consumer is not available.</p>
    <h3 id="_idParaDest-386" class="title">Streams versus message queues</h3>
    <p class="normal">As we have seen so far, there are a <a id="_idIndexMarker1430"/>lot of differences, but also a lot of<a id="_idIndexMarker1431"/> similarities between a message queue and a stream. So, when should you use one in place of the other?</p>
    <p class="normal">Well, the obvious use case for streams is when we have to process sequential data (streaming data) that may also require the consumer to process messages in batch or to look for correlations in past messages. Also, modern streaming platforms allow the ingestion of gigabytes of data per second and the distribution of both the data and the processing of the data across multiple nodes.</p>
    <p class="normal">Both message queues and streams are well suited to implement simple Publish/Subscribe patterns, even with reliable message delivery. However, message queues are better suited for <a id="_idIndexMarker1432"/>complex system integration tasks, since they <a id="_idIndexMarker1433"/>provide advanced routing of messages and allow us to have different priorities for different messages (in streams, the order of the records is always preserved).</p>
    <p class="normal">As we will see later, both can also be used to implement task distribution patterns, even though, in a standard architecture, message queues could be more suitable thanks to message priorities and more advanced routing mechanisms.</p>
    <h3 id="_idParaDest-387" class="title">Implementing the chat application using Redis Streams</h3>
    <p class="normal">At the moment of writing, the <a id="_idIndexMarker1434"/>most popular streaming<a id="_idIndexMarker1435"/> platforms out there <a id="_idIndexMarker1436"/>are Apache Kafka (<a href="http://nodejsdp.link/kafka"><span class="url">nodejsdp.link/kafka</span></a>) and<a id="_idIndexMarker1437"/> Amazon Kinesis (<a href="http://nodejsdp.link/kinesis"><span class="url">nodejsdp.link/kinesis</span></a>). However, for simpler tasks, we can rely again on Redis, which implements a log data structure called <strong class="keyword">Redis Streams</strong>.</p>
    <p class="normal">In the next code sample, we are going to see Redis Streams in action by adapting our chat application. The immediate advantage of using a stream over a message queue is that we don't need to rely on a dedicated component to store and retrieve the history of the messages exchanged in a chat room, but we can simply query the stream every time we need to access older messages. As we will see, this simplifies a lot the architecture of our application and certainly makes streams a better choice than message queues, at least for our very simple use case.</p>
    <p class="normal">So, let's dive into some code. Let's update the <code class="Code-In-Text--PACKT-">index.js</code> of our chat application to use Redis Streams:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> { createServer } <span class="hljs-keyword">from</span> <span class="hljs-string">'http'</span>
<span class="hljs-keyword">import</span> staticHandler <span class="hljs-keyword">from</span> <span class="hljs-string">'serve-handler'</span>
<span class="hljs-keyword">import</span> ws <span class="hljs-keyword">from</span> <span class="hljs-string">'ws'</span>
<span class="hljs-keyword">import</span> Redis <span class="hljs-keyword">from</span> <span class="hljs-string">'ioredis'</span>
<span class="hljs-keyword">const</span> redisClient = <span class="hljs-keyword">new</span> Redis()
<span class="hljs-keyword">const</span> redisClientXRead = <span class="hljs-keyword">new</span> Redis()
<span class="hljs-comment">// serve static files</span>
<span class="hljs-keyword">const</span> server = createServer(<span class="hljs-function">(</span><span class="hljs-params">req, res</span><span class="hljs-function">) =&gt;</span> {
  <span class="hljs-keyword">return</span> staticHandler(req, res, { <span class="hljs-attr">public</span>: <span class="hljs-string">'www'</span> })
})
<span class="hljs-keyword">const</span> wss = <span class="hljs-keyword">new</span> ws.Server({ server })
wss.on(<span class="hljs-string">'connection'</span>, <span class="hljs-keyword">async</span> client =&gt; {
  <span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Client connected'</span>)
  client.on(<span class="hljs-string">'message'</span>, <span class="hljs-params">msg</span><span class="hljs-function"> =&gt;</span> {
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Message: </span><span class="hljs-subst">${msg}</span><span class="hljs-string">`</span>)
    redisClient.xadd(<span class="hljs-string">'chat_stream'</span>, <span class="hljs-string">'*'</span>, <span class="hljs-string">'message'</span>, msg)     <span class="hljs-comment">// (1)</span>
  })
  <span class="hljs-comment">// Load message history</span>
  <span class="hljs-keyword">const</span> logs = <span class="hljs-keyword">await</span> redisClient.xrange(                     <span class="hljs-comment">// (2)</span>
    <span class="hljs-string">'chat_stream'</span>, <span class="hljs-string">'-'</span>, <span class="hljs-string">'+'</span>)
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> [, [, message]] <span class="hljs-keyword">of</span> logs) {
    client.send(message)
  }
})
<span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">broadcast</span><span class="hljs-function"> (</span><span class="hljs-params">msg</span><span class="hljs-function">) </span>{
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> client <span class="hljs-keyword">of</span> wss.clients) {
    <span class="hljs-keyword">if</span> (client.readyState === ws.OPEN) {
      client.send(msg)
    }
  }
}
<span class="hljs-keyword">let</span> lastRecordId = <span class="hljs-string">'$'</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">processStreamMessages</span><span class="hljs-function"> () </span>{                    <span class="hljs-comment">// (3)</span>
  <span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) {
    <span class="hljs-keyword">const</span> [[, records]] = <span class="hljs-keyword">await</span> redisClientXRead.xread(
      <span class="hljs-string">'BLOCK'</span>, <span class="hljs-string">'0'</span>, <span class="hljs-string">'STREAMS'</span>, <span class="hljs-string">'chat_stream'</span>, lastRecordId)
    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> [recordId, [, message]] <span class="hljs-keyword">of</span> records) {
      <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Message from stream: </span><span class="hljs-subst">${message}</span><span class="hljs-string">`</span>)
      broadcast(message)
      lastRecordId = recordId
    }
  }
}
processStreamMessages().catch(<span class="hljs-params">err</span><span class="hljs-function"> =&gt;</span> <span class="hljs-built_in">console</span>.error(err))
server.listen(process.argv[<span class="hljs-number">2</span>] || <span class="hljs-number">8080</span>)
</code></pre>
    <p class="normal">As always, the overall structure of the application has remained the same; what changed is the API we used to exchange messages with the other instances of the application.</p>
    <p class="normal">Let's take a look at those APIs more closely:</p>
    <ol>
      <li class="numbered">The first command we want to analyze is <code class="Code-In-Text--PACKT-">xadd</code>. This command appends a new record to a stream, and we are using it to add a new chat message as it arrives from a connected client. We pass to <code class="Code-In-Text--PACKT-">xadd</code> the following arguments:<ol style="list-style-type: lower-alpha">
          <li class="alphabetic-l2">The name of the stream, which in our case is <code class="Code-In-Text--PACKT-">chat_stream</code>.</li>
          <li class="alphabetic-l2">The ID of the record. In our case, we provide an asterisk (<code class="Code-In-Text--PACKT-">*</code>), which is a special ID that<a id="_idIndexMarker1438"/> asks Redis to generate<a id="_idIndexMarker1439"/> an ID for us. This is usually what we want, as IDs have to be monotonic to preserve the lexicographic order of the records and Redis takes care of that for us.</li>
          <li class="alphabetic-l2">It follows a list of key-value pairs. In our case, we specify only a <code class="Code-In-Text--PACKT-">'message'</code> key of the value <code class="Code-In-Text--PACKT-">msg</code> (which is the message we receive from the client).</li>
        </ol>
      </li>
      <li class="numbered">This is one of the most interesting aspects of using streams: we query the past records of the stream to retrieve the chat history. We do this every time a client connects. We use the <code class="Code-In-Text--PACKT-">xrange</code> command for that, which, as the name implies, allows us to retrieve all the records in the stream within the two specified IDs. In our case we are using the special IDs <code class="Code-In-Text--PACKT-">'-'</code> (minus) and <code class="Code-In-Text--PACKT-">'+'</code> (plus) which indicate the lowest possible ID and the highest possible ID. This essentially means that we want to retrieve all the records currently in the stream.</li>
      <li class="numbered">The last interesting part of our new chat application is where we wait for new records to be added to the stream. This allows each application instance to read new chat messages as they are added into the queue, and it's an essential part for the integration to work. We use an infinite loop and the <code class="Code-In-Text--PACKT-">xread</code> command for the task, providing the following arguments:<ol style="list-style-type: lower-alpha">
          <li class="alphabetic-l2"><code class="Code-In-Text--PACKT-">BLOCK</code> means that we want the call to block until new messages arrive.</li>
          <li class="alphabetic-l2">Next, we specify the timeout after which the command will simply return with a <code class="Code-In-Text--PACKT-">null</code> result. In our case, <code class="Code-In-Text--PACKT-">0</code> means that we want to wait forever.</li>
          <li class="alphabetic-l2"><code class="Code-In-Text--PACKT-">STREAMS</code> is a keyword that tells Redis that we are now going to specify the details of the streams we want to read.</li>
          <li class="alphabetic-l2"><code class="Code-In-Text--PACKT-">chat_stream</code> is the name of the stream we want to read.</li>
          <li class="alphabetic-l2">Finally, we supply the record ID (<code class="Code-In-Text--PACKT-">lastRecordId</code>) after which we want to start reading the new messages. Initially, this is set to <code class="Code-In-Text--PACKT-">$</code> (dollar sign), which is a special ID indicating the highest ID currently in the stream, which should essentially start to read the stream after the last record currently in the stream. After we read the first record, we update the <code class="Code-In-Text--PACKT-">lastRecordId</code> variable with the ID of the last record read.</li>
        </ol>
      </li>
    </ol>
    <p class="normal">Within the previous example, we also made use of some clever destructuring instructions. Consider for example the following code:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> [, [, message]] <span class="hljs-keyword">of</span> logs) {...}
</code></pre>
    <p class="normal">This instruction could be expanded to something like the following:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> [recordId, [propertyId, message]] <span class="hljs-keyword">of</span> logs) {...}
</code></pre>
    <p class="normal">But since we are not interested in <a id="_idIndexMarker1440"/>getting the <code class="Code-In-Text--PACKT-">recordId</code> and the <code class="Code-In-Text--PACKT-">propertyId</code>, we are simply keeping them out of the destructuring instruction. This <a id="_idIndexMarker1441"/>particular destructuring, in combination with the <code class="Code-In-Text--PACKT-">for...of loop</code>, is necessary to parse the data returned from the <code class="Code-In-Text--PACKT-">xrange</code> command, which in our case is in the following form:</p>
    <pre class="programlisting code"><code class="hljs-code">[
  [<span class="hljs-string">"1588590110918-0"</span>, [<span class="hljs-string">"message"</span>, <span class="hljs-string">"This is a message"</span>]],
  [<span class="hljs-string">"1588590130852-0"</span>, [<span class="hljs-string">"message"</span>, <span class="hljs-string">"This is another message"</span>]]
]
</code></pre>
    <p class="normal">We applied a similar principle to parse the return value of <code class="Code-In-Text--PACKT-">xread</code>. Please refer to the API documentation of those instructions for a detailed explanation of their return value.</p>
    <div class="packt_tip">
      <p class="Tip--PACKT-">You can read more about the <code class="Code-In-Text--PACKT-">xadd</code> command and the format of record IDs in the official Redis documentation at <a href="http://nodejsdp.link/xadd"><span class="url">nodejsdp.link/xadd</span></a>.</p>
      <p class="Tip--PACKT-">The <code class="Code-In-Text--PACKT-">xread</code> command has also a fairly complicated arguments list and return value that you can read more about at <a href="http://nodejsdp.link/xread"><span class="url">nodejsdp.link/xread</span></a>.</p>
      <p class="Tip--PACKT-">Also, check out the documentation for <code class="Code-In-Text--PACKT-">xrange</code> at <a href="http://nodejsdp.link/xrange"><span class="url">nodejsdp.link/xrange</span></a>.</p>
    </div>
    <p class="normal">Now, you can start a couple of server instances again and test the application to see how the new implementation works.</p>
    <p class="normal">It's interesting to highlight again <a id="_idIndexMarker1442"/>the fact that we didn't need<a id="_idIndexMarker1443"/> to rely on a dedicated component to manage our chat history, but instead, all we needed to do was to retrieve the past records from the stream with <code class="Code-In-Text--PACKT-">xrange</code>. This aspect of streams makes them intrinsically reliable as no message is <em class="italic">lost</em> unless explicitly deleted.</p>
    <div class="packt_tip">
      <p class="Tip--PACKT-">Records can be removed from the stream with the <code class="Code-In-Text--PACKT-">xdel</code> (<a href="http://nodejsdp.link/xdel"><span class="url">nodejsdp.link/xdel</span></a>) or <code class="Code-In-Text--PACKT-">xtrim</code> commands (<a href="http://nodejsdp.link/xtrim"><span class="url">nodejsdp.link/xtrim</span></a>) or with the <code class="Code-In-Text--PACKT-">MAXLEN</code> option of <code class="Code-In-Text--PACKT-">xadd</code> (<a href="http://nodejsdp.link/xadd-maxlen"><span class="url">nodejsdp.link/xadd-maxlen</span></a>).</p>
    </div>
    <p class="normal">This concludes our exploration of the Publish/Subscribe pattern. Now, it's time to discover another important category of messaging patterns: task distribution patterns.</p>
    <h1 id="_idParaDest-388" class="title">Task distribution patterns</h1>
    <p class="normal">In <em class="chapterRef">Chapter 11</em>, <em class="italic">Advanced Recipes</em>, you<a id="_idIndexMarker1444"/> learned how to delegate costly tasks to multiple local processes. Even though this was an effective approach, it cannot be scaled beyond the boundaries of a single machine, so in this section, we are going to see how it's possible to use a similar pattern in a distributed architecture, using remote workers located anywhere in a network.</p>
    <p class="normal">The idea is to have a messaging pattern that allows us to spread tasks across multiple machines. These tasks might be individual chunks of work or pieces of a bigger task split using a <em class="italic">divide and conquer</em> approach.</p>
    <p class="normal">If we look at the logical architecture represented in the following diagram, we should be able to recognize a familiar pattern:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_15.png" alt=""/></figure>
    <p class="packt_figref">Figure 13.15: Distributing tasks to a set of consumers</p>
    <p class="normal">As we can see from the diagram of <em class="italic">Figure 13.15</em>, the Publish/Subscribe pattern is not suitable for this type of application, as we absolutely don't want a task to be received by multiple workers. What we need instead, is a message distribution pattern similar to a load balancer that dispatches each message to a different consumer (also called a <strong class="keyword">worker</strong>, in this case). In messaging systems terminology, this pattern is also known as <strong class="keyword">competing consumers</strong>, fanout distribution, or <strong class="keyword">ventilator</strong>.</p>
    <p class="normal">One important difference to<a id="_idIndexMarker1445"/> the HTTP load balancers that we saw in the previous chapter is that, here, the consumers have a more active role. In fact, as we will see later, most of the time it's not the producer that connects to the consumers, but the consumers themselves that connect to the task producer or to the task queue in order to receive new jobs. This is a great advantage in a scalable system as it allows us to seamlessly increase the number of workers without modifying the producer or adopting a service registry.</p>
    <p class="normal">Also, in a generic messaging system, we don't necessarily have request/reply communication between the producer and the workers. Instead, most of the time, the preferred approach is to use one-way asynchronous communication, which enables better parallelism and scalability. In such an architecture, messages can potentially always travel in one direction, creating <strong class="keyword">pipelines</strong>, as shown in the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_16.png" alt=""/></figure>
    <p class="packt_figref">Figure 13.16: A messaging pipeline</p>
    <p class="normal">Pipelines allow us to build very complex processing architectures without the overhead of a synchronous request/reply communication, often resulting in lower latency and higher throughput. In <em class="italic">Figure 13.16</em>, we can see how messages can be distributed across a set of workers (fanout), forwarded<a id="_idIndexMarker1446"/> to other processing units, and then aggregated into a single node (fanin), usually called the <strong class="keyword">sink</strong>.</p>
    <p class="normal">In this section, we are going to focus on the building blocks of these kinds of architectures, by analyzing the two most important variations: peer-to-peer and broker-based.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">The combination of a pipeline<a id="_idIndexMarker1447"/> with a task distribution pattern is also called a <strong class="keyword">parallel pipeline</strong>.</p>
    </div>
    <h2 id="_idParaDest-389" class="title">The ZeroMQ Fanout/Fanin pattern</h2>
    <p class="normal">We have already discovered some of the <a id="_idIndexMarker1448"/>capabilities of ZeroMQ for building peer-to-peer distributed architectures. In the previous section, in fact, we used <code class="Code-In-Text--PACKT-">PUB</code> and <code class="Code-In-Text--PACKT-">SUB</code> sockets to disseminate a single message to multiple consumers, and now, we are going to see how it's possible to build parallel pipelines using another pair of sockets called <code class="Code-In-Text--PACKT-">PUSH</code> and <code class="Code-In-Text--PACKT-">PULL</code>.</p>
    <h3 id="_idParaDest-390" class="title">PUSH/PULL sockets</h3>
    <p class="normal">Intuitively, we can say that <a id="_idIndexMarker1449"/>the <code class="Code-In-Text--PACKT-">PUSH</code> sockets are made for <em class="italic">sending</em> messages, while the <code class="Code-In-Text--PACKT-">PULL</code> sockets are meant for <em class="italic">receiving</em>. It might seem a trivial combination, however, they have some extra features that make them perfect for building one-way communication systems:</p>
    <ul>
      <li class="Bullet--PACKT-">Both can work in <em class="italic">connect</em> mode or <em class="italic">bind</em> mode. In other words, we can create a <code class="Code-In-Text--PACKT-">PUSH</code> socket and bind it to a local port listening for the incoming connections from a <code class="Code-In-Text--PACKT-">PULL</code> socket, or vice versa, a <code class="Code-In-Text--PACKT-">PULL</code> socket might listen for connections from a <code class="Code-In-Text--PACKT-">PUSH</code> socket. The messages always travel in the same direction, from <code class="Code-In-Text--PACKT-">PUSH</code> to <code class="Code-In-Text--PACKT-">PULL</code>, it's only the initiator of the connection that can be different. The bind mode is the best solution for <em class="italic">durable</em> nodes, such as, for example, the task producer and the sink, while the connect mode is perfect for <em class="italic">transient</em> nodes, such as the task workers. This allows the number of transient nodes to vary arbitrarily without affecting the more stable, durable nodes.</li>
      <li class="Bullet--PACKT-">If there are multiple <code class="Code-In-Text--PACKT-">PULL</code> sockets connected to a single <code class="Code-In-Text--PACKT-">PUSH</code> socket, the messages are evenly distributed across all the <code class="Code-In-Text--PACKT-">PULL</code> sockets. In practice, they are load balanced (peer-to-peer load balancing!). On the other hand, a <code class="Code-In-Text--PACKT-">PULL</code> socket that receives messages from multiple <code class="Code-In-Text--PACKT-">PUSH</code> sockets will process the messages using a fair queuing system, which means that they are consumed evenly from all the sources—a round-robin applied to inbound messages.</li>
      <li class="Bullet-End--PACKT-">The messages sent over <a id="_idIndexMarker1450"/>a <code class="Code-In-Text--PACKT-">PUSH</code> socket that doesn't have any connected <code class="Code-In-Text--PACKT-">PULL</code> sockets do not get lost. They are instead queued until a node comes online and starts pulling the messages.</li>
    </ul>
    <p class="normal">We are now starting to understand how ZeroMQ is different from traditional web services and why it's a perfect tool for building a distributed messaging system.</p>
    <h3 id="_idParaDest-391" class="title">Building a distributed hashsum cracker with ZeroMQ</h3>
    <p class="normal">Now it's time to <a id="_idIndexMarker1451"/>build a sample application to <a id="_idIndexMarker1452"/>see the properties of the <code class="Code-In-Text--PACKT-">PUSH</code>/<code class="Code-In-Text--PACKT-">PULL</code> sockets we just described in action.</p>
    <p class="normal">A simple and fascinating application to work with would be a <em class="italic">hashsum cracker</em>: A system that uses a brute-force approach to try to match a given hashsum (such as MD5 or SHA1) to the hashsum of every possible variation of characters of a given alphabet, thus discovering the original string the given hashsum was created from. </p>
    <p class="normal">This is an <em class="italic">embarrassingly parallel</em> workload (<a href="http://nodejsdp.link/embarrassingly-parallel"><span class="url">nodejsdp.link/embarrassingly-parallel</span></a>), which is perfect for building an example demonstrating the power of parallel pipelines.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">Never use plain hashsums to encrypt passwords as they are very easy to crack. Use instead a purpose-built algorithm such as <strong class="keyword">bcrypt</strong> (<a href="http://nodejsdp.link/bcrypt"><span class="url">nodejsdp.link/bcrypt</span></a>), <strong class="keyword">scrypt</strong> (<a href="http://nodejsdp.link/scrypt"><span class="url">nodejsdp.link/scrypt</span></a>), <strong class="keyword">PBKDF2</strong> (<a href="http://nodejsdp.link/pbkdf2"><span class="url">nodejsdp.link/pbkdf2</span></a>), or <strong class="keyword">Argon2</strong> (<a href="http://nodejsdp.link/argon2"><span class="url">nodejsdp.link/argon2</span></a>).</p>
    </div>
    <p class="normal">For our application, we want to implement a typical parallel pipeline where we have the following:</p>
    <ul>
      <li class="Bullet--PACKT-">A node to create and distribute tasks across multiple workers</li>
      <li class="Bullet--PACKT-">Multiple worker nodes (where the actual computation happens)</li>
      <li class="Bullet-End--PACKT-">A node to collect all the results</li>
    </ul>
    <p class="normal">The system we just described <a id="_idIndexMarker1453"/>can be implemented in ZeroMQ <a id="_idIndexMarker1454"/>using the following architecture:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_17.png" alt=""/></figure>
    <p class="packt_figref">Figure 13.17: The architecture of a typical pipeline with ZeroMQ</p>
    <p class="normal">In our architecture, we have a <em class="italic">ventilator</em> generating intervals of variations of characters in the given alphabet (for example, the interval 'aa' to 'bb' includes the variations 'aa', 'ab', 'ba', 'bb') and distributing those intervals to the workers as tasks. Each worker, then, calculates the hashsum of every variation in the given interval, trying to match each resulting hashsum against the control hashsum given as input. If a match is found, the result is sent to a results collector node (sink).</p>
    <p class="normal">The durable nodes of our architecture are the ventilator and the sink, while the transient nodes are the workers. This means that each worker connects its <code class="Code-In-Text--PACKT-">PULL</code> socket to the ventilator and its <code class="Code-In-Text--PACKT-">PUSH</code> socket to the sink, this way we can start and stop as many workers as we want without changing any parameter in the ventilator or the sink.</p>
    <h4 class="title">Implementing the producer</h4>
    <p class="normal">To<a id="_idIndexMarker1455"/> represent intervals of variations, we are going to use indexed n-ary trees. If we imagine having a tree in which each node has exactly <em class="italic">n</em> children, where each child is one of the <em class="italic">n</em> elements of the given alphabet and we assign an index to each node in breadth-first order, then, given the alphabet <code class="Code-In-Text--PACKT-">[a, b]</code> we should obtain a tree such as the following:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_18.png" alt="A close up of a clock  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 13.18: Indexed n-ary tree for alphabet [a, b]</p>
    <p class="normal">It's then possible to obtain the variation corresponding to an index by traversing the tree from the root to the given index, appending the element of the nodes found along the way to the variation being calculated. For example, given the tree in <em class="italic">Figure 13.18</em>, the variation corresponding to the index 13 will be 'bba'.</p>
    <p class="normal">We'll leverage the <code class="Code-In-Text--PACKT-">indexed-string-variation</code> package (<a href="http://nodejsdp.link/indexed-string-variation"><span class="url">nodejsdp.link/indexed-string-variation</span></a>) to aid us in calculating the corresponding variation given its index in the n-ary tree. This operation is done in the workers, so all we have to do in the ventilator is to produce intervals of indexes to give to the workers, which in turn will calculate all the variations of characters represented by those intervals.</p>
    <p class="normal">Now, after the necessary theory, let's start to build our system by implementing the component responsible to generate the tasks to distribute (<code class="Code-In-Text--PACKT-">generateTasks.js</code>):</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">export</span> <span class="hljs-keyword">function</span><span class="hljs-function"> * </span><span class="hljs-title">generateTasks</span><span class="hljs-function"> (</span><span class="hljs-params">searchHash, alphabet,</span>
<span class="hljs-params">  maxWordLength, batchSize</span><span class="hljs-function">) </span>{
  <span class="hljs-keyword">let</span> nVariations = <span class="hljs-number">0</span>
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">let</span> n = <span class="hljs-number">1</span>; n &lt;= maxWordLength; n++) {
    nVariations += <span class="hljs-built_in">Math</span>.pow(alphabet.length, n)
  }
  <span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Finding the hashsum source string over '</span> +
    <span class="hljs-string">`</span><span class="hljs-subst">${nVariations}</span><span class="hljs-string"> possible variations`</span>)
  <span class="hljs-keyword">let</span> batchStart = <span class="hljs-number">1</span>
  <span class="hljs-keyword">while</span> (batchStart &lt;= nVariations) {
    <span class="hljs-keyword">const</span> batchEnd = <span class="hljs-built_in">Math</span>.min(
      batchStart + batchSize - <span class="hljs-number">1</span>, nVariations)
    <span class="hljs-keyword">yield</span> {
      searchHash,
      <span class="hljs-attr">alphabet</span>: alphabet,
      batchStart,
      batchEnd
    }
    batchStart = batchEnd + <span class="hljs-number">1</span>
  }
}
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">generateTasks()</code> generator<a id="_idIndexMarker1456"/> creates intervals of integers of <code class="Code-In-Text--PACKT-">batchSize</code> size, starting from <code class="Code-In-Text--PACKT-">1</code> (we exclude <code class="Code-In-Text--PACKT-">0</code>, which is the root of the tree, corresponding to the empty variation) and ending at the largest possible index (<code class="Code-In-Text--PACKT-">nVariations</code>) for the given <code class="Code-In-Text--PACKT-">alphabet</code> and the maximum word length provided (<code class="Code-In-Text--PACKT-">maxLength</code>). Then, we pack all the data about the task into an object and <code class="Code-In-Text--PACKT-">yield</code> it to the caller.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">Please consider that to generate longer strings it may be necessary to switch to <code class="Code-In-Text--PACKT-">BigInt</code> (<a href="http://nodejsdp.link/bigint"><span class="url">nodejsdp.link/bigint</span></a>) to represent their indexes, since the maximum safe integer manageable by JavaScript is currently 2<sup class="Superscript--PACKT-">53</sup> – 1, which is the value of <code class="Code-In-Text--PACKT-">Number.MAX_SAFE_INTEGER</code>. Note that using very large integers may have a negative impact on the performances of the variations generator.</p>
    </div>
    <p class="normal">Now, we need to implement the logic of our producer, which is responsible for distributing the tasks across all workers (in the <code class="Code-In-Text--PACKT-">producer.js</code> file):</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> zmq <span class="hljs-keyword">from</span> <span class="hljs-string">'zeromq'</span>
<span class="hljs-keyword">import</span> delay <span class="hljs-keyword">from</span> <span class="hljs-string">'delay'</span>
<span class="hljs-keyword">import</span> { generateTasks } <span class="hljs-keyword">from</span> <span class="hljs-string">'./generateTasks.js'</span>
<span class="hljs-keyword">const</span> ALPHABET = <span class="hljs-string">'abcdefghijklmnopqrstuvwxyz'</span>
<span class="hljs-keyword">const</span> BATCH_SIZE = <span class="hljs-number">10000</span>
<span class="hljs-keyword">const</span> [, , maxLength, searchHash] = process.argv
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">main</span><span class="hljs-function"> () </span>{
  <span class="hljs-keyword">const</span> ventilator = <span class="hljs-keyword">new</span> zmq.Push()                          <span class="hljs-comment">// (1)</span>
  <span class="hljs-keyword">await</span> ventilator.bind(<span class="hljs-string">'tcp://*:5016'</span>)
  <span class="hljs-keyword">await</span> delay(<span class="hljs-number">1000</span>) <span class="hljs-comment">// wait for all the workers to connect</span>
  <span class="hljs-keyword">const</span> generatorObj = generateTasks(searchHash, ALPHABET,
    maxLength, BATCH_SIZE)
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> task <span class="hljs-keyword">of</span> generatorObj) {
    <span class="hljs-keyword">await</span> ventilator.send(<span class="hljs-built_in">JSON</span>.stringify(task))              <span class="hljs-comment">// (2)</span>
  }
}
main().catch(<span class="hljs-params">err</span><span class="hljs-function"> =&gt;</span> <span class="hljs-built_in">console</span>.error(err))
</code></pre>
    <p class="normal">To avoid generating too<a id="_idIndexMarker1457"/> many variations, our generator uses only the lowercase letters of the English alphabet and sets a limit on the size of the words generated. This limit is provided as an input in the command-line arguments (<code class="Code-In-Text--PACKT-">maxLength</code>) together with the hashsum to match (<code class="Code-In-Text--PACKT-">searchHash</code>).</p>
    <p class="normal">But the part that we are most interested in analyzing is how we distribute the tasks across the workers:</p>
    <ol>
      <li class="numbered">We first create a <code class="Code-In-Text--PACKT-">PUSH</code> socket and we bind it to the local port <code class="Code-In-Text--PACKT-">5016</code>, which is where the <code class="Code-In-Text--PACKT-">PULL</code> socket of the workers will connect to receive their tasks. We then wait 1 second for all the workers to connect: we do this because if the producer starts while the workers are already running, the workers may connect at different times (because of their timer-based reconnection algorithm) and that may cause the first connecting worker to receive most of the tasks.</li>
      <li class="numbered">For each generated task, we stringify it and send it to a worker using the <code class="Code-In-Text--PACKT-">send()</code> function of the <code class="Code-In-Text--PACKT-">ventilator</code> socket. Each connected worker will receive a different task following a round-robin approach.</li>
    </ol>
    <h4 class="title">Implementing the worker</h4>
    <p class="normal">Now it's time <a id="_idIndexMarker1458"/>to implement the worker, but first, let's create a component to process the incoming tasks (in the <code class="Code-In-Text--PACKT-">processTask.js</code> file):</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> isv <span class="hljs-keyword">from</span> <span class="hljs-string">'indexed-string-variation'</span>
<span class="hljs-keyword">import</span> { createHash } <span class="hljs-keyword">from</span> <span class="hljs-string">'crypto'</span>
<span class="hljs-keyword">export</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">processTask</span><span class="hljs-function"> (</span><span class="hljs-params">task</span><span class="hljs-function">) </span>{
  <span class="hljs-keyword">const</span> variationGen = isv.generator(task.alphabet)
  <span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Processing from '</span> +
    <span class="hljs-string">`</span><span class="hljs-subst">${</span>variationGen(task.<span class="hljs-subst">batchStart</span>)<span class="hljs-subst">}</span><span class="hljs-string"> (</span><span class="hljs-subst">${</span>task.<span class="hljs-subst">batchStart}</span><span class="hljs-string">) `</span> +
    <span class="hljs-string">`to </span><span class="hljs-subst">${</span>variationGen(task.<span class="hljs-subst">batchEnd</span>)<span class="hljs-subst">}</span><span class="hljs-string"> (</span><span class="hljs-subst">${</span>task.<span class="hljs-subst">batchEnd}</span><span class="hljs-string">)`</span>)
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">let</span> idx = task.batchStart; idx &lt;= task.batchEnd; idx++) {
    <span class="hljs-keyword">const</span> word = variationGen(idx)
    <span class="hljs-keyword">const</span> shasum = createHash(<span class="hljs-string">'sha1'</span>)
    shasum.update(word)
    <span class="hljs-keyword">const</span> digest = shasum.digest(<span class="hljs-string">'hex'</span>)
    <span class="hljs-keyword">if</span> (digest === task.searchHash) {
      <span class="hljs-keyword">return</span> word
    }
  }
}
</code></pre>
    <p class="normal">The logic of the <code class="Code-In-Text--PACKT-">processTask()</code> function is quite simple: it iterates over the indexes within the given interval, then for each index it generates the corresponding variation of characters (<code class="Code-In-Text--PACKT-">word</code>). Next, it calculates the SHA1 checksum for the <code class="Code-In-Text--PACKT-">word</code> and it tries to match it against the <code class="Code-In-Text--PACKT-">searchHash</code> passed within the <code class="Code-In-Text--PACKT-">task</code> object. If the two digests match, then it returns the source <code class="Code-In-Text--PACKT-">word</code> to the caller.</p>
    <p class="normal">Now we are ready to implement the main logic of our worker (<code class="Code-In-Text--PACKT-">worker.js</code>):</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> zmq <span class="hljs-keyword">from</span> <span class="hljs-string">'zeromq'</span>
<span class="hljs-keyword">import</span> { processTask } <span class="hljs-keyword">from</span> <span class="hljs-string">'./processTask.js'</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">main</span><span class="hljs-function"> () </span>{
  <span class="hljs-keyword">const</span> fromVentilator = <span class="hljs-keyword">new</span> zmq.Pull()
  <span class="hljs-keyword">const</span> toSink = <span class="hljs-keyword">new</span> zmq.Push()
  fromVentilator.connect(<span class="hljs-string">'tcp://localhost:5016'</span>)
  toSink.connect(<span class="hljs-string">'tcp://localhost:5017'</span>)
  <span class="hljs-keyword">for</span> <span class="hljs-keyword">await</span> (<span class="hljs-keyword">const</span> rawMessage <span class="hljs-keyword">of</span> fromVentilator) {
    <span class="hljs-keyword">const</span> found = processTask(<span class="hljs-built_in">JSON</span>.parse(rawMessage.toString()))
    <span class="hljs-keyword">if</span> (found) {
      <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Found! =&gt; </span><span class="hljs-subst">${found}</span><span class="hljs-string">`</span>)
      <span class="hljs-keyword">await</span> toSink.send(<span class="hljs-string">`Found: </span><span class="hljs-subst">${found}</span><span class="hljs-string">`</span>)
    }
  }
}
main().catch(<span class="hljs-params">err</span><span class="hljs-function"> =&gt;</span> <span class="hljs-built_in">console</span>.error(err))
</code></pre>
    <p class="normal">As we said, our worker represents a transient node in our architecture, therefore, its sockets should connect to a remote node instead of listening for the incoming connections. That's exactly what we do in our worker, we create two sockets:</p>
    <ul>
      <li class="Bullet--PACKT-">A <code class="Code-In-Text--PACKT-">PULL</code> socket that connects to the ventilator, for receiving the tasks</li>
      <li class="Bullet-End--PACKT-">A <code class="Code-In-Text--PACKT-">PUSH</code> socket that connects to the sink, for propagating the results</li>
    </ul>
    <p class="normal">Besides this, the<a id="_idIndexMarker1459"/> job done by our worker is very simple: it processes every task received, and if a match is found, we send a message to the results collector through the <code class="Code-In-Text--PACKT-">toSink</code> socket.</p>
    <h4 class="title">Implementing the results collector</h4>
    <p class="normal">For our example, the<a id="_idIndexMarker1460"/> results collector (sink) is a very basic program that simply prints the messages received by the workers to the console. The contents of the <code class="Code-In-Text--PACKT-">collector.js</code> file are as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> zmq <span class="hljs-keyword">from</span> <span class="hljs-string">'zeromq'</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">main</span><span class="hljs-function"> () </span>{
  <span class="hljs-keyword">const</span> sink = <span class="hljs-keyword">new</span> zmq.Pull()
  <span class="hljs-keyword">await</span> sink.bind(<span class="hljs-string">'tcp://*:5017'</span>)
  <span class="hljs-keyword">for</span> <span class="hljs-keyword">await</span> (<span class="hljs-keyword">const</span> rawMessage <span class="hljs-keyword">of</span> sink) {
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Message from worker: '</span>, rawMessage.toString())
  }
}
main().catch(<span class="hljs-params">err</span><span class="hljs-function"> =&gt;</span> <span class="hljs-built_in">console</span>.error(err))
</code></pre>
    <p class="normal">It's interesting to see that the results collector (as the producer) is also a durable node of our architecture and therefore we bind its <code class="Code-In-Text--PACKT-">PULL</code> socket instead of connecting it explicitly to the <code class="Code-In-Text--PACKT-">PUSH</code> socket of the workers.</p>
    <h4 class="title">Running the application</h4>
    <p class="normal">We are now ready<a id="_idIndexMarker1461"/> to launch our application; let's start a couple of workers and the results collector (each one in a different terminal):</p>
    <pre class="programlisting con"><code class="hljs-con">node worker.js
node worker.js
node collector.js
</code></pre>
    <p class="normal">Then it's time to start the producer, specifying the maximum length of the words to generate and the SHA1 checksum that we want to match. The following is a sample command line:</p>
    <pre class="programlisting con"><code class="hljs-con">node producer.js 4 f8e966d1e207d02c44511a58dccff2f5429e9a3b
</code></pre>
    <p class="normal">When the preceding command is run, the producer will start generating tasks and distributing them to the set of workers we started. We are telling the producer to generate all possible words with 4 lowercase letters (because our alphabet comprises only lowercase letters) and we also provide a sample SHA1 checksum that corresponds to a secret 4-letter word.</p>
    <p class="normal">The results of the computation, if any, will appear in the terminal of the results collector application.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">Please note that given the low-level nature of <code class="Code-In-Text--PACKT-">PUSH</code>/<code class="Code-In-Text--PACKT-">PULL</code> sockets in ZeroMQ and in particular the lack of message acknowledgments, if a node crashes, then all the tasks it was processing will be lost. It's possible to implement a custom acknowledgment mechanism on top of ZeroMQ but we'll leave that as an exercise for the reader.</p>
      <p class="Information-Box--PACKT-">Another known limitation of this implementation is the fact that the workers won't stop processing tasks if a match is found. This feature was intentionally left out to make the examples as focused as possible on the pattern being discussed. You can try adding this "stopping" mechanism as an exercise.</p>
    </div>
    <h2 id="_idParaDest-392" class="title">Pipelines and competing consumers in AMQP</h2>
    <p class="normal">In the previous section, we saw how a parallel pipeline can be implemented in a peer-to-peer context. Now, we are going to explore this pattern when applied in a broker-based architecture using RabbitMQ.</p>
    <h3 id="_idParaDest-393" class="title">Point-to-point communications and competing consumers</h3>
    <p class="normal">In a peer-to-peer configuration, a pipeline is a very straightforward concept to imagine. With a message broker in the middle, though, the relationships between the various nodes of the system are a <a id="_idIndexMarker1462"/>little bit harder to understand: the broker itself acts as an intermediary for our communications <a id="_idIndexMarker1463"/>and, often, we don't really know who is on the other side listening for messages. For example, when we send a message using AMQP, we don't deliver it directly to its destination, but instead to an exchange and then to a queue. Finally, it will be for the broker to decide where to route the message, based on the rules defined in the exchange, the bindings, and the destination queues.</p>
    <p class="normal">If we want to implement<a id="_idIndexMarker1464"/> a pipeline and a task distribution pattern using a system like AMQP, we have to make sure that each message is received by only one consumer, but this is impossible to guarantee if an exchange can potentially be bound to more than one queue. The solution, then, is to send a message directly to the destination queue, bypassing the exchange altogether. This way, we can make sure that only one queue will ever receive the message. This communication pattern is called <strong class="keyword">point-to-point</strong>.</p>
    <p class="normal">Once we are able to send a set of messages directly to a single queue, we are already half-way to implementing our task distribution pattern. In fact, the next step comes naturally: when multiple consumers are listening on the same queue, the messages will be distributed evenly across them, following a fanout distribution pattern. As we already mentioned, in the context of message brokers this is better known as the <strong class="keyword">Competing Consumers</strong> pattern.</p>
    <p class="normal">Next, we are going to reimplement our simple hashsum cracker using AMQP, so we can appreciate the differences to the peer-to-peer approach we have discussed in the previous section.</p>
    <h3 id="_idParaDest-394" class="title">Implementing the hashsum cracker using AMQP</h3>
    <p class="normal">We just <a id="_idIndexMarker1465"/>learned that exchanges are the point in a broker where a message is multicast to a set of consumers, while queues are the place where messages are load balanced. With this knowledge in mind, let's now implement our brute-force hashsum cracker on top of an AMQP broker (which in our case is RabbitMQ). The following figure gives you an overview of the system we want to implement:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_19.png" alt="A screenshot of a cell phone  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 13.19: Task distribution architecture using a message queue broker</p>
    <p class="normal">As we discussed, to <a id="_idIndexMarker1466"/>distribute a set of tasks across multiple workers, we need to use a single queue. In <em class="italic">Figure 13.19</em>, we called this the <em class="italic">tasks queue</em>. On the other side of the tasks queue, we have a set of workers, which are <em class="italic">competing consumers</em>: in other words, each one will receive a different message from the queue. The effect is that multiple tasks will execute in parallel on different workers.</p>
    <p class="normal">The results generated by the workers are published into another queue, which we called the <em class="italic">results queue</em>, and then consumed by the results collector, which is actually equivalent to a sink. In the entire architecture, we don't make use of any exchange, we only send messages directly to their destination queue, implementing a point-to-point type of communication.</p>
    <h4 class="title">Implementing the producer</h4>
    <p class="normal">Let's see how to <a id="_idIndexMarker1467"/>implement such a system, starting from the producer (in the <code class="Code-In-Text--PACKT-">producer.js</code> file):</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> amqp <span class="hljs-keyword">from</span> <span class="hljs-string">'amqplib'</span>
<span class="hljs-keyword">import</span> { generateTasks } <span class="hljs-keyword">from</span> <span class="hljs-string">'./generateTasks.js'</span>
<span class="hljs-keyword">const</span> ALPHABET = <span class="hljs-string">'abcdefghijklmnopqrstuvwxyz'</span>
<span class="hljs-keyword">const</span> BATCH_SIZE = <span class="hljs-number">10000</span>
<span class="hljs-keyword">const</span> [, , maxLength, searchHash] = process.argv
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">main</span><span class="hljs-function"> () </span>{
  <span class="hljs-keyword">const</span> connection = <span class="hljs-keyword">await</span> amqp.connect(<span class="hljs-string">'amqp://localhost'</span>)
  <span class="hljs-keyword">const</span> channel = <span class="hljs-keyword">await</span> connection.createConfirmChannel()    <span class="hljs-comment">// (1)</span>
  <span class="hljs-keyword">await</span> channel.assertQueue(<span class="hljs-string">'tasks_queue'</span>)
  <span class="hljs-keyword">const</span> generatorObj = generateTasks(searchHash, ALPHABET,
    maxLength, BATCH_SIZE)
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> task <span class="hljs-keyword">of</span> generatorObj) {
    channel.sendToQueue(<span class="hljs-string">'tasks_queue'</span>,                       <span class="hljs-comment">// (2)</span>
      Buffer.from(<span class="hljs-built_in">JSON</span>.stringify(task)))
  }
  <span class="hljs-keyword">await</span> channel.waitForConfirms()
  channel.close()
  connection.close()
}
main().catch(<span class="hljs-params">err</span><span class="hljs-function"> =&gt;</span> <span class="hljs-built_in">console</span>.error(err))
</code></pre>
    <p class="normal">As we can see, the <a id="_idIndexMarker1468"/>absence of any exchange or binding makes the setup of an AMQP-based application much simpler. There are however a few details to note:</p>
    <ol>
      <li class="numbered">Instead of creating a standard channel, we are creating a <code class="Code-In-Text--PACKT-">confirmChannel</code>. This is necessary as it creates a channel with some extra functionality, in particular, it provides the <code class="Code-In-Text--PACKT-">waitForConfirms()</code> function that we use later in the code to wait until the broker confirms the reception of all the messages. This is necessary to prevent the application from closing the connection to the broker too soon, before all the messages have been dispatched from the local queue.</li>
      <li class="numbered">The core of the producer is the <code class="Code-In-Text--PACKT-">channel.sendToQueue()</code> API, which is actually new to us. As its <a id="_idIndexMarker1469"/>name says, that's the API responsible for delivering a message straight to a queue—the <code class="Code-In-Text--PACKT-">tasks_queue</code> in our example—bypassing any exchange or routing.</li>
    </ol>
    <h4 class="title">Implementing the worker</h4>
    <p class="normal">On the other <a id="_idIndexMarker1470"/>side of the <code class="Code-In-Text--PACKT-">tasks_queue</code>, we have the workers listening for the incoming tasks. Let's update the code of our existing <code class="Code-In-Text--PACKT-">worker.js</code> module to use AMQP:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> amqp <span class="hljs-keyword">from</span> <span class="hljs-string">'amqplib'</span>
<span class="hljs-keyword">import</span> { processTask } <span class="hljs-keyword">from</span> <span class="hljs-string">'./processTask.js'</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">main</span><span class="hljs-function"> () </span>{
  <span class="hljs-keyword">const</span> connection = <span class="hljs-keyword">await</span> amqp.connect(<span class="hljs-string">'amqp://localhost'</span>)
  <span class="hljs-keyword">const</span> channel = <span class="hljs-keyword">await</span> connection.createChannel()
  <span class="hljs-keyword">const</span> { queue } = <span class="hljs-keyword">await</span> channel.assertQueue(<span class="hljs-string">'tasks_queue'</span>)
  channel.consume(queue, <span class="hljs-keyword">async</span> (rawMessage) =&gt; {
    <span class="hljs-keyword">const</span> found = processTask(
      <span class="hljs-built_in">JSON</span>.parse(rawMessage.content.toString()))
    <span class="hljs-keyword">if</span> (found) {
      <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Found! =&gt; </span><span class="hljs-subst">${found}</span><span class="hljs-string">`</span>)
      <span class="hljs-keyword">await</span> channel.sendToQueue(<span class="hljs-string">'results_queue'</span>,
        Buffer.from(<span class="hljs-string">`Found: </span><span class="hljs-subst">${found}</span><span class="hljs-string">`</span>))
    }
    <span class="hljs-keyword">await</span> channel.ack(rawMessage)
  })
}
main().catch(<span class="hljs-params">err</span><span class="hljs-function"> =&gt;</span> <span class="hljs-built_in">console</span>.error(err))
</code></pre>
    <p class="normal">Our new worker is also very similar to the one we implemented in the previous section using ZeroMQ, except for the parts related to the exchange of messages. In the preceding code, we can see how we first get a reference to the queue called <code class="Code-In-Text--PACKT-">tasks_queue</code> and then we start listening for incoming tasks using <code class="Code-In-Text--PACKT-">channel.consume()</code>. Then, every time a match is found, we send the result to the collector via the <code class="Code-In-Text--PACKT-">results_queue</code>, again <a id="_idIndexMarker1471"/>using point-to-point communication. It's also important to note how we are acknowledging every message with <code class="Code-In-Text--PACKT-">channel.ack()</code> after the message has been completely processed.</p>
    <p class="normal">If multiple workers are started, they will all listen on the same queue, resulting in the messages being load balanced between them (they become <em class="italic">competing consumers</em>).</p>
    <h4 class="title">Implementing the result collector</h4>
    <p class="normal">The results collector is again a<a id="_idIndexMarker1472"/> trivial module, simply printing any message received to the console. This is implemented in the <code class="Code-In-Text--PACKT-">collector.js</code> file, as follows:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> amqp <span class="hljs-keyword">from</span> <span class="hljs-string">'amqplib'</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">main</span><span class="hljs-function"> () </span>{
  <span class="hljs-keyword">const</span> connection = <span class="hljs-keyword">await</span> amqp.connect(<span class="hljs-string">'amqp://localhost'</span>)
  <span class="hljs-keyword">const</span> channel = <span class="hljs-keyword">await</span> connection.createChannel()
  <span class="hljs-keyword">const</span> { queue } = <span class="hljs-keyword">await</span> channel.assertQueue(<span class="hljs-string">'results_queue'</span>)
  channel.consume(queue, <span class="hljs-params">msg</span><span class="hljs-function"> =&gt;</span> {
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Message from worker: </span><span class="hljs-subst">${</span>msg.<span class="hljs-subst">content</span>.<span class="hljs-subst">toString()}</span><span class="hljs-string">`</span>)
  })
}
main().catch(<span class="hljs-params">err</span><span class="hljs-function"> =&gt;</span> <span class="hljs-built_in">console</span>.error(err))
</code></pre>
    <h4 class="title">Running the application</h4>
    <p class="normal">Now everything is ready<a id="_idIndexMarker1473"/> to give our new system a try. First, make sure that the RabbitMQ server is running, then you can launch a couple of workers (in two separate terminals), which will both connect to the same queue (<code class="Code-In-Text--PACKT-">tasks_queue</code>) so that every message will be load balanced between them:</p>
    <pre class="programlisting con"><code class="hljs-con">node worker.js
node worker.js
</code></pre>
    <p class="normal">Then, you can run the <code class="Code-In-Text--PACKT-">collector</code> module and then the <code class="Code-In-Text--PACKT-">producer</code> (by providing the maximum word length and the hash to crack):</p>
    <pre class="programlisting con"><code class="hljs-con">node collector.js
node producer.js 4 f8e966d1e207d02c44511a58dccff2f5429e9a3b
</code></pre>
    <p class="normal">With this, we implemented a<a id="_idIndexMarker1474"/> message pipeline and the Competing Consumers pattern using AMQP.</p>
    <div class="packt_tip">
      <p class="Tip--PACKT-">It's interesting to note that our new version of the hashsum cracker based on AMQP takes slightly longer (compared to the ZeroMQ-based version) to execute all the tasks and find a match. This is a practical demonstration of how a broker can actually introduce a negative performance impact, compared to a more low-level peer-to-peer approach. However, let's not forget that with AMQP we are getting much more out of the box compared to our ZeroMQ implementation. For example, with the AMQP implementation, if a worker crashes, the messages it was processing won't be lost and will eventually be passed to another worker. So, remember to always look at the bigger picture when choosing the right approach to use for your application: a small delay may mean nothing compared to a massive increase in the overall complexity of the system or to a lack of some important features.</p>
    </div>
    <p class="normal">Now, let's consider another broker-based approach for implementing task distribution patterns, this time built on top of Redis Streams.</p>
    <h2 id="_idParaDest-395" class="title">Distributing tasks with Redis Streams</h2>
    <p class="normal">After seeing how the Task Distribution pattern can be<a id="_idIndexMarker1475"/> implemented using <a id="_idIndexMarker1476"/>ZeroMQ and AMQP, we are now going to see how we can implement this pattern leveraging Redis Streams.</p>
    <h3 id="_idParaDest-396" class="title">Redis consumer groups</h3>
    <p class="normal">Before diving into some <a id="_idIndexMarker1477"/>code, we need to learn about a critical feature of Redis that allows us to implement a Task Distribution pattern using Redis Streams. This feature is called <strong class="keyword">consumer groups</strong> and is an <a id="_idIndexMarker1478"/>implementation of the Competing Consumer pattern (with the addition of some useful accessories) on top of Redis Streams.</p>
    <p class="normal">A consumer group is a stateful entity, identified by a name, which comprises a set of consumers identified by a name. When the consumers in the group try to read the stream, they will receive the records in a round-robin configuration.</p>
    <p class="normal">Each record has to be explicitly acknowledged, otherwise, the record will be kept in a <em class="italic">pending</em> state. Each consumer can only access its own history of pending records unless it explicitly <em class="italic">claims</em> the records of another consumer. This is useful if a consumer crashes while processing a record. When the consumer comes back online, the first thing it should do is retrieve its list of pending records and process those before requesting new records from the stream. <em class="italic">Figure 13.20</em> provides a visual representation of how consumer groups work in <a id="_idIndexMarker1479"/>Redis.</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_20.png" alt="A picture containing screenshot  Description automatically generated"/></figure>
    <p class="packt_figref">Figure 13.20: A Redis Stream consumer group</p>
    <p class="normal">We can note how the two<a id="_idIndexMarker1480"/> consumers in the group receive two different records (B for Consumer 1 and C for Consumer 2) when they try to read from the stream. The consumer group also stores the ID of the last retrieved record (record C), so that at the successive read operation the consumer group knows what's the next record to read. We can also note how Consumer 1 has a pending record (A), which is a record that it's still processing or couldn't process. Consumer 1 can implement a retry algorithm to make sure to process all the pending records assigned to itself.</p>
    <div class="packt_tip">
      <p class="Tip--PACKT-">A Redis Stream can have multiple consumer groups. This way it's possible to simultaneously apply different types of processing to the same data.</p>
    </div>
    <p class="normal">Now let's put into practice what we just learned about Redis consumer groups to implement our hashsum cracker.</p>
    <h3 id="_idParaDest-397" class="title">Implementing the hashsum cracker using Redis Streams</h3>
    <p class="normal">The architecture of our <a id="_idIndexMarker1481"/>hashsum cracker with Redis Streams is going to resemble closely that of the previous AMQP example. In fact, we are going to have two different streams (in the AMQP examples they were queues): one stream to hold the tasks to be processed (<code class="Code-In-Text--PACKT-">tasks_stream</code>) and another stream to hold the results coming from the workers (<code class="Code-In-Text--PACKT-">results_stream</code>).</p>
    <p class="normal">Then, we are going to use a consumer group to distribute the tasks from the <code class="Code-In-Text--PACKT-">tasks_stream</code> to the workers of our application (our workers are the consumers).</p>
    <h4 class="title">Implementing the producer</h4>
    <p class="normal">Let's start by <a id="_idIndexMarker1482"/>implementing the producer (in the <code class="Code-In-Text--PACKT-">producer.js</code> file):</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> Redis <span class="hljs-keyword">from</span> <span class="hljs-string">'ioredis'</span>
<span class="hljs-keyword">import</span> { generateTasks } <span class="hljs-keyword">from</span> <span class="hljs-string">'./generateTasks.js'</span>
<span class="hljs-keyword">const</span> ALPHABET = <span class="hljs-string">'abcdefghijklmnopqrstuvwxyz'</span>
<span class="hljs-keyword">const</span> BATCH_SIZE = <span class="hljs-number">10000</span>
<span class="hljs-keyword">const</span> redisClient = <span class="hljs-keyword">new</span> Redis()
<span class="hljs-keyword">const</span> [, , maxLength, searchHash] = process.argv
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">main</span><span class="hljs-function"> () </span>{
  <span class="hljs-keyword">const</span> generatorObj = generateTasks(searchHash, ALPHABET,
    maxLength, BATCH_SIZE)
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> task <span class="hljs-keyword">of</span> generatorObj) {
    <span class="hljs-keyword">await</span> redisClient.xadd(<span class="hljs-string">'tasks_stream'</span>, <span class="hljs-string">'*'</span>,
      <span class="hljs-string">'task'</span>, <span class="hljs-built_in">JSON</span>.stringify(task))
  }
  redisClient.disconnect()
}
main().catch(<span class="hljs-params">err</span><span class="hljs-function"> =&gt;</span> <span class="hljs-built_in">console</span>.error(err))
</code></pre>
    <p class="normal">As we can see, there is nothing new to us in the implementation of the new <code class="Code-In-Text--PACKT-">producer.js</code> module. In fact, we already know very well how to add records to a stream; all we have to do is invoke <code class="Code-In-Text--PACKT-">xadd()</code> as discussed in the <em class="italic">Reliable messaging with streams</em> section.</p>
    <h4 class="title">Implementing the worker</h4>
    <p class="normal">Next, we need to<a id="_idIndexMarker1483"/> adapt our worker so it can interface with a Redis Stream using a consumer group. This is the core of all the architecture, as in here, in the worker, we leverage consumer groups and their features. So, let's implement the new <code class="Code-In-Text--PACKT-">worker.js</code> module:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> Redis <span class="hljs-keyword">from</span> <span class="hljs-string">'ioredis'</span>
<span class="hljs-keyword">import</span> { processTask } <span class="hljs-keyword">from</span> <span class="hljs-string">'./processTask.js'</span>
<span class="hljs-keyword">const</span> redisClient = <span class="hljs-keyword">new</span> Redis()
<span class="hljs-keyword">const</span> [, , consumerName] = process.argv
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">main</span><span class="hljs-function"> () </span>{
  <span class="hljs-keyword">await</span> redisClient.xgroup(<span class="hljs-string">'CREATE'</span>, <span class="hljs-string">'tasks_stream'</span>,         <span class="hljs-comment">// (1)</span>
    <span class="hljs-string">'workers_group'</span>, <span class="hljs-string">'$'</span>, <span class="hljs-string">'MKSTREAM'</span>)
    .catch(<span class="hljs-function">() =&gt;</span> <span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Consumer group already exists'</span>))
  <span class="hljs-keyword">const</span> [[, records]] = <span class="hljs-keyword">await</span> redisClient.xreadgroup(        <span class="hljs-comment">// (2)</span>
    <span class="hljs-string">'GROUP'</span>, <span class="hljs-string">'workers_group'</span>, consumerName, <span class="hljs-string">'STREAMS'</span>,
    <span class="hljs-string">'tasks_stream'</span>, <span class="hljs-string">'0'</span>)
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> [recordId, [, rawTask]] <span class="hljs-keyword">of</span> records) {
    <span class="hljs-keyword">await</span> processAndAck(recordId, rawTask)
  }
  <span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) {
    <span class="hljs-keyword">const</span> [[, records]] = <span class="hljs-keyword">await</span> redisClient.xreadgroup(      <span class="hljs-comment">// (3)</span>
      <span class="hljs-string">'GROUP'</span>, <span class="hljs-string">'workers_group'</span>, consumerName, <span class="hljs-string">'BLOCK'</span>, <span class="hljs-string">'0'</span>,
      <span class="hljs-string">'COUNT'</span>, <span class="hljs-string">'1'</span>, <span class="hljs-string">'STREAMS'</span>, <span class="hljs-string">'tasks_stream'</span>, <span class="hljs-string">'&gt;'</span>)
    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> [recordId, [, rawTask]] <span class="hljs-keyword">of</span> records) {
      <span class="hljs-keyword">await</span> processAndAck(recordId, rawTask)
    }
  }
}
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">processAndAck</span><span class="hljs-function"> (</span><span class="hljs-params">recordId, rawTask</span><span class="hljs-function">) </span>{           <span class="hljs-comment">// (4)</span>
  <span class="hljs-keyword">const</span> found = processTask(<span class="hljs-built_in">JSON</span>.parse(rawTask))
  <span class="hljs-keyword">if</span> (found) {
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Found! =&gt; </span><span class="hljs-subst">${found}</span><span class="hljs-string">`</span>)
    <span class="hljs-keyword">await</span> redisClient.xadd(<span class="hljs-string">'results_stream'</span>, <span class="hljs-string">'*'</span>, <span class="hljs-string">'result'</span>,
      <span class="hljs-string">`Found: </span><span class="hljs-subst">${found}</span><span class="hljs-string">`</span>)
  }
  <span class="hljs-keyword">await</span> redisClient.xack(<span class="hljs-string">'tasks_stream'</span>, <span class="hljs-string">'workers_group'</span>, recordId)
}
main().catch(<span class="hljs-params">err</span><span class="hljs-function"> =&gt;</span> <span class="hljs-built_in">console</span>.error(err))
</code></pre>
    <p class="normal">OK, there are a lot of moving parts in the new worker code. So, let's analyze it one step at a time:</p>
    <ol>
      <li class="numbered">First, we need to make sure that the consumer group exists before we can use it. We can do that with the <code class="Code-In-Text--PACKT-">xgroup</code> command, which we invoke with the following parameters:<ol style="list-style-type: lower-alpha">
          <li class="alphabetic-l2"><code class="Code-In-Text--PACKT-">'CREATE'</code> is the keyword to use when we want to create a consumer group. In fact, with the <code class="Code-In-Text--PACKT-">xgroup</code> command, we can also destroy the consumer group, remove a consumer, or update the last read record ID, using different subcommands.</li>
          <li class="alphabetic-l2"><code class="Code-In-Text--PACKT-">'tasks_stream'</code> is the name of the stream we want to read from.</li>
          <li class="alphabetic-l2"><code class="Code-In-Text--PACKT-">'workers_group'</code> is the name of the consumer group.</li>
          <li class="alphabetic-l2">The <a id="_idIndexMarker1484"/>fourth argument represents the record ID from where the consumer group should start consuming records from the stream. Using <code class="Code-In-Text--PACKT-">'$'</code> (dollar sign) means that the consumer group should start reading the stream from the ID of the last record currently in the stream.</li>
          <li class="alphabetic-l2"><code class="Code-In-Text--PACKT-">'MKSTREAM'</code> is an extra parameter that instructs Redis to create the stream if it doesn't exist already.</li>
        </ol>
      </li>
      <li class="numbered">Next, we read all the pending records belonging to the current consumer. Those are the leftover records from a previous run of the consumer that weren't processed because of an abrupt interruption of the application (such as a crash). If the same consumer (with the same name) terminated properly during the last run, without errors, then this list would most likely be empty. As we already mentioned, each consumer has access only to its own pending records. We retrieve this list with a <code class="Code-In-Text--PACKT-">xreadgroup</code> command and the following arguments:<ol style="list-style-type: lower-alpha">
          <li class="alphabetic-l2"><code class="Code-In-Text--PACKT-">'GROUP', 'workers_group', consumerName</code> is a mandatory trio where we specify the name of the consumer group (<code class="Code-In-Text--PACKT-">'workers_group'</code>) and the name of the consumer (<code class="Code-In-Text--PACKT-">consumerName</code>) that we read from the command-line inputs.</li>
          <li class="alphabetic-l2">Then we specify the stream we would like to read with <code class="Code-In-Text--PACKT-">'STREAMS', 'tasks_stream'</code>.</li>
          <li class="alphabetic-l2">Finally, we specify <code class="Code-In-Text--PACKT-">'0'</code> as the last argument, which is the ID from which we should start reading. Essentially, we are saying that we want to read all pending messages belonging to the current consumer starting from the first message.</li>
        </ol>
      </li>
      <li class="numbered">Then, we have another call to <code class="Code-In-Text--PACKT-">xreadgroup()</code>, but this time it has a completely different semantic. In this case, in fact, we want to start reading new records from the stream (and not access the consumer's own history). This is possible with the following list of arguments:<ol style="list-style-type: lower-alpha">
          <li class="alphabetic-l2">As in the previous call of <code class="Code-In-Text--PACKT-">xreadgroup()</code>, we specify the consumer group that we want to use for the read operation with the three arguments: <code class="Code-In-Text--PACKT-">'GROUP', 'workers_group', consumerName</code>.</li>
          <li class="alphabetic-l2">Then we<a id="_idIndexMarker1485"/> indicate that the call should block if there are no new records currently available instead of returning an empty list. We do that with the following two arguments: <code class="Code-In-Text--PACKT-">'BLOCK', '0'</code>. The last argument is the timeout after which the function returns anyway, even without results. <code class="Code-In-Text--PACKT-">'0'</code> means that we want to wait indefinitely.</li>
          <li class="alphabetic-l2">The next two arguments, <code class="Code-In-Text--PACKT-">'COUNT'</code> and <code class="Code-In-Text--PACKT-">'1'</code>, tell Redis that we are interested in getting one record per call.</li>
          <li class="alphabetic-l2">Next, we specify the stream we want to read from with <code class="Code-In-Text--PACKT-">'STREAMS', 'tasks_stream'</code>.</li>
          <li class="alphabetic-l2">Finally, with the special ID <code class="Code-In-Text--PACKT-">'&gt;'</code>(greater than symbol), we indicate that we are interested in any record not yet retrieved by this consumer group.</li>
        </ol>
      </li>
      <li class="numbered">Finally, in the <code class="Code-In-Text--PACKT-">processAndAck()</code> function, we check if we have a match and if that's the case, we append a new record to the <code class="Code-In-Text--PACKT-">results_stream</code>. At last, when all the processing for the record returned by <code class="Code-In-Text--PACKT-">xreadgroup()</code> completes, we invoke the Redis <code class="Code-In-Text--PACKT-">xack</code> command to acknowledge that the record has been successfully consumed, which results in the record being removed from the pending list for the current consumer.</li>
    </ol>
    <p class="normal">Phew! There was a lot going on in the <code class="Code-In-Text--PACKT-">worker.js</code> module. It's interesting to note that most of the complexity comes from the large amount of arguments required by the various Redis commands.</p>
    <div class="note">
      <p class="Information-Box--PACKT-">You may be surprised to know that this example just scratches the surface, as there is a lot more to know about Redis Streams, and in particular, consumer groups. Check out the official Redis introduction to Streams for more details at <a href="http://nodejsdp.link/redis-streams"><span class="url">nodejsdp.link/redis-streams</span></a>.</p>
    </div>
    <p class="normal">Now, everything should be ready for us to try out this new version of the hashsum cracker. Let's start a couple of workers, but this time remember to assign them a name, which will be used to<a id="_idIndexMarker1486"/> identify them in the consumer group:</p>
    <pre class="programlisting con"><code class="hljs-con">node worker.js workerA
node worker.js workerB
</code></pre>
    <p class="normal">Then, you can run the collector and the producer as we did in the previous examples:</p>
    <pre class="programlisting con"><code class="hljs-con">node collector.js
node producer.js 4 f8e966d1e207d02c44511a58dccff2f5429e9a3b
</code></pre>
    <p class="normal">This concludes our exploration of the task distribution patterns, so now, we'll take a closer look at the request/reply patterns.</p>
    <h1 id="_idParaDest-398" class="title">Request/Reply patterns</h1>
    <p class="normal">One-way communications<a id="_idIndexMarker1487"/> can give us great advantages in terms of parallelism and efficiency, but alone they are not able to solve all our integration and communication problems. Sometimes, a good old request/reply pattern might just be the perfect tool for the job. But, there are situations in which all we have is an asynchronous one-way channel. It's therefore important to know the various patterns and approaches required to build an abstraction that would allow us to exchange messages in a request/reply fashion on top of a one-way channel. That's exactly what we are going to learn next.</p>
    <h2 id="_idParaDest-399" class="title">Correlation Identifier</h2>
    <p class="normal">The first Request/Reply pattern that we are going to learn is <a id="_idIndexMarker1488"/>called the <strong class="keyword">Correlation Identifier</strong> and it represents the basic block for building a request/reply abstraction on top of a one-way channel.</p>
    <p class="normal">The pattern involves marking each request with an identifier, which is then attached to the response by the receiver: this way, the sender of the request can correlate the two messages and return the response to the right handler. This elegantly solves the problem in the context of a one-way asynchronous channel, where messages can travel in any direction at any time. Let's take a look at the example in the following diagram:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_21.png" alt=""/></figure>
    <p class="packt_figref">Figure 13.21: Request/reply message exchange using correlation identifiers</p>
    <p class="normal">The scenario depicted in <em class="italic">Figure 13.21</em> shows how using a correlation ID allows us to match each response with the right request, even if those are sent and then received in a different order. The way this works will be much clearer once we start working on our next example.</p>
    <h3 id="_idParaDest-400" class="title">Implementing a request/reply abstraction using correlation identifiers</h3>
    <p class="normal">Let's now start <a id="_idIndexMarker1489"/>working on an example by choosing the simplest type of one-way channel; one that is point-to-point (which directly connects two nodes of the system) and fully duplex (messages can travel in both directions).</p>
    <p class="normal">In this <em class="italic">simple channel</em> category, we can find, for example, WebSockets: they establish a point-to-point connection between the server and browser, and the messages can travel in any direction. Another example is the communication channel that is created when a child process is spawned using <code class="Code-In-Text--PACKT-">child_process.fork()</code> (we already met this API in <em class="chapterRef">Chapter 11</em>, <em class="italic">Advanced Recipes</em>). This channel too is asynchronous, point-to-point, and duplex since it connects the parent only with the child process and it allows messages to travel in any direction. This is probably the most basic channel of this category, so that's what we are going to use in the next example.</p>
    <p class="normal">The plan for the next application is to build an abstraction in order to wrap the channel created between the parent process and the child process. This abstraction should provide a request/reply communication <a id="_idIndexMarker1490"/>channel by automatically marking each request with a correlation identifier and then matching the ID of any incoming reply against the list of request handlers awaiting a response.</p>
    <p class="normal">From <em class="chapterRef">Chapter 11</em>, <em class="italic">Advanced Recipes</em>, we should remember that the parent process can send a message to a child with <code class="Code-In-Text--PACKT-">child.send(message)</code>, while receiving messages is possible with the <code class="Code-In-Text--PACKT-">child.on('message', callback)</code> event handler.</p>
    <p class="normal">In a similar way, the child process can send a message to the parent process using <code class="Code-In-Text--PACKT-">process.send(message)</code> and receive messages with <code class="Code-In-Text--PACKT-">process.on('message', callback)</code>.</p>
    <p class="normal">This means that the interface of the channel available in the parent process is identical to the one available in the child. This will allow us to build a common abstraction that can be used from both ends of the channel.</p>
    <h4 class="title">Abstracting the request</h4>
    <p class="normal">Let's start <a id="_idIndexMarker1491"/>building this abstraction by considering the part responsible for sending new requests. Let's create a new file called <code class="Code-In-Text--PACKT-">createRequestChannel.js</code> with the following content:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> { nanoid } <span class="hljs-keyword">from</span> <span class="hljs-string">'nanoid'</span>
<span class="hljs-keyword">export</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">createRequestChannel</span><span class="hljs-function"> (</span><span class="hljs-params">channel</span><span class="hljs-function">) </span>{             <span class="hljs-comment">// (1)</span>
  <span class="hljs-keyword">const</span> correlationMap = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Map</span>()
  <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">sendRequest</span><span class="hljs-function"> (</span><span class="hljs-params">data</span><span class="hljs-function">) </span>{                              <span class="hljs-comment">// (2)</span>
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Sending request'</span>, data)
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function">(</span><span class="hljs-params">resolve, reject</span><span class="hljs-function">) =&gt;</span> {
      <span class="hljs-keyword">const</span> correlationId = nanoid()
      <span class="hljs-keyword">const</span> replyTimeout = <span class="hljs-built_in">setTimeout</span>(<span class="hljs-function">() =&gt;</span> {
        correlationMap.delete(correlationId)
        reject(<span class="hljs-keyword">new</span> <span class="hljs-built_in">Error</span>(<span class="hljs-string">'Request timeout'</span>))
      }, <span class="hljs-number">10000</span>)
      correlationMap.set(correlationId, <span class="hljs-function">(</span><span class="hljs-params">replyData</span><span class="hljs-function">) =&gt;</span> {
        correlationMap.delete(correlationId)
        <span class="hljs-built_in">clearTimeout</span>(replyTimeout)
        resolve(replyData)
      })
      channel.send({
        <span class="hljs-attr">type</span>: <span class="hljs-string">'request'</span>,
        data,
        <span class="hljs-attr">id</span>: correlationId
      })
    })
  }
  channel.on(<span class="hljs-string">'message'</span>, <span class="hljs-params">message</span><span class="hljs-function"> =&gt;</span> {                         <span class="hljs-comment">// (3)</span>
    <span class="hljs-keyword">const</span> callback = correlationMap.get(message.inReplyTo)
    <span class="hljs-keyword">if</span> (callback) {
      callback(message.data)
    }
  })
  <span class="hljs-keyword">return</span> sendRequest
}
</code></pre>
    <p class="normal">This is how our <a id="_idIndexMarker1492"/>request abstraction works:</p>
    <ol>
      <li class="numbered">The <code class="Code-In-Text--PACKT-">createRequestChannel()</code> is a factory that wraps the input channel and returns a <code class="Code-In-Text--PACKT-">sendRequest()</code> function used to send a request and receive a reply. The magic of the pattern lies in the <code class="Code-In-Text--PACKT-">correlationMap</code> variable, which stores the association between the outgoing requests and their reply handlers.</li>
      <li class="numbered">The <code class="Code-In-Text--PACKT-">sendRequest()</code> function is used to send new requests. Its job is to generate a correlation ID using the <code class="Code-In-Text--PACKT-">nanoid</code> package (<a href="http://nodejsdp.link/nanoid"><span class="url">nodejsdp.link/nanoid</span></a>) and then wrap the request data in an envelope that allows us to specify the correlation ID and the type of the message. The correlation ID and the handler responsible for returning the reply data to the caller (which uses <code class="Code-In-Text--PACKT-">resolve()</code> under the hood) are then added to the <code class="Code-In-Text--PACKT-">correlationMap</code> so that the handler can be retrieved later using the correlation ID. We also implemented a very simple request timeout logic.</li>
      <li class="numbered">When the factory is invoked, we also start listening for incoming messages. If the correlation ID of the message (contained in the <code class="Code-In-Text--PACKT-">inReplyTo</code> property) matches any of the IDs<a id="_idIndexMarker1493"/> contained in the <code class="Code-In-Text--PACKT-">correlationMap</code> map, we know that we just received a reply, so we obtain the reference to the associated response handler and we invoke it with the data contained in the message.</li>
    </ol>
    <p class="normal">That's it for the <code class="Code-In-Text--PACKT-">createRequestChannel.js</code> module. Let's move on to the next part.</p>
    <h4 class="title">Abstracting the reply</h4>
    <p class="normal">We are just a<a id="_idIndexMarker1494"/> step away from implementing the full pattern, so let's see how the counterpart of the request channel, which is the reply channel, works. Let's create another file called <code class="Code-In-Text--PACKT-">createReplyChannel.js</code>, which will contain the abstraction for wrapping the reply handler:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">export</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">createReplyChannel</span><span class="hljs-function"> (</span><span class="hljs-params">channel</span><span class="hljs-function">) </span>{
  <span class="hljs-keyword">return</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">registerHandler</span><span class="hljs-function"> (</span><span class="hljs-params">handler</span><span class="hljs-function">) </span>{
    channel.on(<span class="hljs-string">'message'</span>, <span class="hljs-keyword">async</span> <span class="hljs-params">message</span><span class="hljs-function"> =&gt;</span> {
      <span class="hljs-keyword">if</span> (message.type !== <span class="hljs-string">'request'</span>) {
        <span class="hljs-keyword">return</span>
      }
      <span class="hljs-keyword">const</span> replyData = <span class="hljs-keyword">await</span> handler(message.data)      <span class="hljs-comment">// (1)</span>
      channel.send({                                     <span class="hljs-comment">// (2)</span>
        type: <span class="hljs-string">'response'</span>,
        <span class="hljs-attr">data</span>: replyData,
        <span class="hljs-attr">inReplyTo</span>: message.id
      })
    })
  }
}
</code></pre>
    <p class="normal">Our <code class="Code-In-Text--PACKT-">createReplyChannel()</code> function is again a factory that returns another function used to register new reply handlers. This is what happens when a new handler is registered:</p>
    <ol>
      <li class="numbered">When we receive a new request, we immediately invoke the handler by passing the data contained in the message.</li>
      <li class="numbered">Once the handler has done its work and returned its reply, we build an envelope around the data and include the type of the message and the correlation ID of the request (the <code class="Code-In-Text--PACKT-">inReplyTo</code> property), then we put everything back into the channel.</li>
    </ol>
    <p class="normal">The amazing thing about this pattern is that in Node.js it comes very easily: everything for us is already asynchronous, so an asynchronous request/reply communication built on top of a one-way channel is not very different from any other asynchronous operation, especially<a id="_idIndexMarker1495"/> if we build an abstraction to hide its implementation details.</p>
    <h4 class="title">Trying the full request/reply cycle</h4>
    <p class="normal">Now we are ready to try our <a id="_idIndexMarker1496"/>new asynchronous request/reply abstraction. Let's create a sample <em class="italic">replier</em> in a file named <code class="Code-In-Text--PACKT-">replier.js</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> { createReplyChannel } <span class="hljs-keyword">from</span> <span class="hljs-string">'./createReplyChannel.js'</span>
<span class="hljs-keyword">const</span> registerReplyHandler = createReplyChannel(process)
registerReplyHandler(<span class="hljs-params">req</span><span class="hljs-function"> =&gt;</span> {
  <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(resolve =&gt; {
    <span class="hljs-built_in">setTimeout</span>(<span class="hljs-function">() =&gt;</span> {
      resolve({ <span class="hljs-attr">sum</span>: req.a + req.b })
    }, req.delay)
  })
})
process.send(<span class="hljs-string">'ready'</span>)
</code></pre>
    <p class="normal">Our replier simply calculates the sum between the two numbers received in the request and returns the result after a certain delay (which is also specified in the request). This will allow us to verify that the order of the responses can be different from the order in which we sent the requests, to confirm that our pattern is working. With the last instruction of the module, we send a message back to the parent process to indicate that the child is ready to accept requests.</p>
    <p class="normal">The final step to complete the example is to create the requestor in a file named <code class="Code-In-Text--PACKT-">requestor.js</code>, which also has the task of starting the replier using <code class="Code-In-Text--PACKT-">child_process.fork()</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> { fork } <span class="hljs-keyword">from</span> <span class="hljs-string">'child_process'</span>
<span class="hljs-keyword">import</span> { dirname, join } <span class="hljs-keyword">from</span> <span class="hljs-string">'path'</span>
<span class="hljs-keyword">import</span> { fileURLToPath } <span class="hljs-keyword">from</span> <span class="hljs-string">'url'</span>
<span class="hljs-keyword">import</span> { once } <span class="hljs-keyword">from</span> <span class="hljs-string">'events'</span>
<span class="hljs-keyword">import</span> { createRequestChannel } <span class="hljs-keyword">from</span> <span class="hljs-string">'./createRequestChannel.js'</span>
<span class="hljs-keyword">const</span> __dirname = dirname(fileURLToPath(<span class="hljs-keyword">import</span>.meta.url))
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">main</span><span class="hljs-function"> () </span>{
  <span class="hljs-keyword">const</span> channel = fork(join(__dirname, <span class="hljs-string">'replier.js'</span>))          <span class="hljs-comment">// (1)</span>
  <span class="hljs-keyword">const</span> request = createRequestChannel(channel)
  <span class="hljs-keyword">try</span> {
    <span class="hljs-keyword">const</span> [message] = <span class="hljs-keyword">await</span> once(channel, <span class="hljs-string">'message'</span>)       <span class="hljs-comment">// (2)</span>
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Child process initialized: </span><span class="hljs-subst">${message}</span><span class="hljs-string">`</span>)
    <span class="hljs-keyword">const</span> p1 = request({ <span class="hljs-attr">a</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">b</span>: <span class="hljs-number">2</span>, <span class="hljs-attr">delay</span>: <span class="hljs-number">500</span> })         <span class="hljs-comment">// (3)</span>
      .then(<span class="hljs-params">res</span><span class="hljs-function"> =&gt;</span> {
        <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Reply: 1 + 2 = </span><span class="hljs-subst">${</span>res.<span class="hljs-subst">sum}</span><span class="hljs-string">`</span>)
      })
    <span class="hljs-keyword">const</span> p2 = request({ <span class="hljs-attr">a</span>: <span class="hljs-number">6</span>, <span class="hljs-attr">b</span>: <span class="hljs-number">1</span>, <span class="hljs-attr">delay</span>: <span class="hljs-number">100</span> })         <span class="hljs-comment">// (4)</span>
      .then(<span class="hljs-params">res</span><span class="hljs-function"> =&gt;</span> {
        <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`Reply: 6 + 1 = </span><span class="hljs-subst">${</span>res.<span class="hljs-subst">sum}</span><span class="hljs-string">`</span>)
      })
    <span class="hljs-keyword">await</span> <span class="hljs-built_in">Promise</span>.all([p1, p2])                            <span class="hljs-comment">// (5)</span>
  } <span class="hljs-keyword">finally</span> {
    channel.disconnect()                                   <span class="hljs-comment">// (6)</span>
  }
}
main().catch(<span class="hljs-params">err</span><span class="hljs-function"> =&gt;</span> <span class="hljs-built_in">console</span>.error(err))
</code></pre>
    <p class="normal">The requestor starts the <a id="_idIndexMarker1497"/>replier (1) and then passes its reference to our <code class="Code-In-Text--PACKT-">createRequestChannel()</code> abstraction. We then wait for the child process to be available (2) and run a couple of sample requests (3, 4). Finally, we wait for both requests to complete (5) and we disconnect the channel (6) to allow the child process (and therefore the parent process) to exit gracefully.</p>
    <p class="normal">To try out the sample, simply launch the <code class="Code-In-Text--PACKT-">requestor.js</code> module. The output should be something similar to the following:</p>
    <pre class="programlisting con"><code class="hljs-con">Child process initialized: ready
Sending request { a: 1, b: 2, delay: 500 }
Sending request { a: 6, b: 1, delay: 100 }
Reply: 6 + 1 = 7
Reply: 1 + 2 = 3
</code></pre>
    <p class="normal">This confirms that our implementation of the Request/Reply messaging pattern works perfectly and that the replies are correctly associated with their respective requests, no matter in what order they are sent or received.</p>
    <p class="normal">The technique we've discussed in this section works great when we have a single point-to-point channel. But what happens if we have a more complex architecture with multiple channels or queues? That's what we are going to see next.</p>
    <h2 id="_idParaDest-401" class="title">Return address</h2>
    <p class="normal">The Correlation Identifier is the fundamental pattern for creating a request/reply communication on top of a one-way channel. However, it's not enough when our messaging architecture has <a id="_idIndexMarker1498"/>more than one channel or queue, or when there can be potentially more than one requestor. In these situations, in addition to a correlation ID, we also need to know the <strong class="keyword">return address</strong>, a piece of information that allows the replier to send the response back to the original sender of the request.</p>
    <h3 id="_idParaDest-402" class="title">Implementing the Return Address pattern in AMQP</h3>
    <p class="normal">In the context of an <a id="_idIndexMarker1499"/>AMQP-based architecture, the return address <a id="_idIndexMarker1500"/>is the queue where the requestor is listening for incoming replies. Because the response is meant to be received by only one requestor, it's important that the queue is private and not shared across different consumers. From these properties, we can infer that we are going to need a transient queue scoped to the connection of the requestor, and that the replier has to establish a point-to-point communication with the return queue to be able to deliver its responses.</p>
    <p class="normal">The following diagram gives us an example of this scenario:</p>
    <figure class="mediaobject"><img src="../Images/B15729_13_22.png" alt=""/></figure>
    <p class="packt_figref">Figure 13.22: Request/reply messaging architecture using AMQP</p>
    <p class="normal"><em class="italic">Figure 13.22</em> shows us how each requestor has its own private queue, specifically intended to handle the replies to their requests. All requests are sent instead to a single queue, which is then consumed by the replier. The replier will route the replies to the correct response queue <a id="_idIndexMarker1501"/>thanks to the <em class="italic">return address</em> information specified in the request.</p>
    <p class="normal">In fact, to create a Request/Reply <a id="_idIndexMarker1502"/>pattern on top of AMQP, all we need to do is to specify the name of the response queue in the message properties, so that the replier knows where the response message has to be delivered.</p>
    <p class="normal">The theory seems very straightforward, so let's see how to implement this in a real application.</p>
    <h4 class="title">Implementing the request abstraction</h4>
    <p class="normal">Let's now build a<a id="_idIndexMarker1503"/> request/reply abstraction on top of AMQP. We will use RabbitMQ as a broker, but any compatible AMQP broker should do the job. Let's start with the request abstraction, implemented in the <code class="Code-In-Text--PACKT-">amqpRequest.js</code> module. We will show the code here one piece at a time to make the explanation easier. Let's start from the constructor of the <code class="Code-In-Text--PACKT-">AMQPRequest</code> class:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">export</span> <span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">AMQPRequest</span><span class="hljs-class"> </span>{
  <span class="hljs-keyword">constructor</span> () {
    <span class="hljs-built_in">this</span>.correlationMap = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Map</span>()
  }
  <span class="hljs-comment">//...</span>
</code></pre>
    <p class="normal">As we can see from the preceding code, we will again be using the Correlation Identifier pattern, so we are going to <a id="_idIndexMarker1504"/>need a map to hold the association between the message ID and the relative handler.</p>
    <p class="normal">Then, we need a method to initialize the AMQP connection and its objects:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">async</span> initialize () {
  <span class="hljs-built_in">this</span>.connection = <span class="hljs-keyword">await</span> amqp.connect(<span class="hljs-string">'amqp://localhost'</span>)
  <span class="hljs-built_in">this</span>.channel = <span class="hljs-keyword">await</span> <span class="hljs-built_in">this</span>.connection.createChannel()
  <span class="hljs-keyword">const</span> { queue } = <span class="hljs-keyword">await</span> <span class="hljs-built_in">this</span>.channel.assertQueue(<span class="hljs-string">''</span>,       <span class="hljs-comment">// (1)</span>
    { <span class="hljs-attr">exclusive</span>: <span class="hljs-literal">true</span> })
  <span class="hljs-built_in">this</span>.replyQueue = queue
  <span class="hljs-built_in">this</span>.channel.consume(<span class="hljs-built_in">this</span>.replyQueue, <span class="hljs-params">msg</span><span class="hljs-function"> =&gt;</span> {             <span class="hljs-comment">// (2)</span>
    <span class="hljs-keyword">const</span> correlationId = msg.properties.correlationId
    <span class="hljs-keyword">const</span> handler = <span class="hljs-built_in">this</span>.correlationMap.get(correlationId)
    <span class="hljs-keyword">if</span> (handler) {
      handler(<span class="hljs-built_in">JSON</span>.parse(msg.content.toString()))
    }
  }, { <span class="hljs-attr">noAck</span>: <span class="hljs-literal">true</span> })
}
</code></pre>
    <p class="normal">The interesting thing to observe here is how we create the queue to hold the replies (1). The peculiarity is that we don't specify any name, which means that a random one will be chosen for us. In addition to this, the queue is <em class="italic">exclusive</em>, which means that it's bound to the currently active AMQP connection and it will be destroyed when the connection closes. There is no need to bind the queue to an exchange as we don't need any routing or distribution to multiple queues, which means that the messages have to be delivered straight into our response queue. In the second part of the function (2), we start to consume the messages from the <code class="Code-In-Text--PACKT-">replyQueue</code>. Here we match the ID of the incoming message with the one we have in our <code class="Code-In-Text--PACKT-">correlationMap</code> and invoke the associated handler.</p>
    <p class="normal">Next, let's see how it's possible to send new requests:</p>
    <pre class="programlisting code"><code class="hljs-code">send (queue, message) {
  <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-built_in">Promise</span>(<span class="hljs-function">(</span><span class="hljs-params">resolve, reject</span><span class="hljs-function">) =&gt;</span> {
    <span class="hljs-keyword">const</span> id = nanoid()                                    <span class="hljs-comment">// (1)</span>
    <span class="hljs-keyword">const</span> replyTimeout = <span class="hljs-built_in">setTimeout</span>(<span class="hljs-function">() =&gt;</span> {
      <span class="hljs-built_in">this</span>.correlationMap.delete(id)
      reject(<span class="hljs-keyword">new</span> <span class="hljs-built_in">Error</span>(<span class="hljs-string">'Request timeout'</span>))
    }, <span class="hljs-number">10000</span>)
    <span class="hljs-built_in">this</span>.correlationMap.set(id, <span class="hljs-function">(</span><span class="hljs-params">replyData</span><span class="hljs-function">) =&gt;</span> {           <span class="hljs-comment">// (2)</span>
      <span class="hljs-built_in">this</span>.correlationMap.delete(id)
      <span class="hljs-built_in">clearTimeout</span>(replyTimeout)
      resolve(replyData)
    })
    <span class="hljs-built_in">this</span>.channel.sendToQueue(queue,                        <span class="hljs-comment">// (3)</span>
      Buffer.from(<span class="hljs-built_in">JSON</span>.stringify(message)),
      { <span class="hljs-attr">correlationId</span>: id, <span class="hljs-attr">replyTo</span>: <span class="hljs-built_in">this</span>.replyQueue }
    )
  })
}
</code></pre>
    <p class="normal">The <code class="Code-In-Text--PACKT-">send()</code> method accepts as<a id="_idIndexMarker1505"/> input the name of the requests <code class="Code-In-Text--PACKT-">queue</code> and the <code class="Code-In-Text--PACKT-">message</code> to send. As we learned in the previous section, we need to generate a correlation ID (1) and associate it to a handler responsible for returning the reply to the caller (2). Finally, we send the message (3), specifying the <code class="Code-In-Text--PACKT-">correlationId</code> and the <code class="Code-In-Text--PACKT-">replyTo</code> property as metadata. In AMQP, in fact, we can specify a set of properties (or metadata) to be passed to the consumer, together with the main message. The metadata object is passed as the third argument of the <code class="Code-In-Text--PACKT-">sendToQueue()</code> method.</p>
    <p class="normal">It's important to note that we are using the <code class="Code-In-Text--PACKT-">channel.sentToQueue()</code> API instead of <code class="Code-In-Text--PACKT-">channel.publish()</code> to send the message. This is because we are not interested in implementing a publish/subscribe distribution pattern using exchanges, but a more basic point-to-point delivery straight into the destination queue.</p>
    <p class="normal">The last piece of our <code class="Code-In-Text--PACKT-">AMQPRequest</code> class is where we implement the <code class="Code-In-Text--PACKT-">destroy()</code> method, which is used to close the connection and the channel:</p>
    <pre class="programlisting code"><code class="hljs-code">  destroy () {
    <span class="hljs-built_in">this</span>.channel.close()
    <span class="hljs-built_in">this</span>.connection.close()
  }
}
</code></pre>
    <p class="normal">That's it for the <code class="Code-In-Text--PACKT-">amqpRequest.js</code> module.</p>
    <h4 class="title">Implementing the reply abstraction</h4>
    <p class="normal">Now it's time to implement the<a id="_idIndexMarker1506"/> reply abstraction in a new module named <code class="Code-In-Text--PACKT-">amqpReply.js</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> amqp <span class="hljs-keyword">from</span> <span class="hljs-string">'amqplib'</span>
<span class="hljs-keyword">export</span> <span class="hljs-keyword">class</span><span class="hljs-class"> </span><span class="hljs-title">AMQPReply</span><span class="hljs-class"> </span>{
  <span class="hljs-keyword">constructor</span> (requestsQueueName) {
    <span class="hljs-built_in">this</span>.requestsQueueName = requestsQueueName
  }
  <span class="hljs-keyword">async</span> initialize () {
    <span class="hljs-keyword">const</span> connection = <span class="hljs-keyword">await</span> amqp.connect(<span class="hljs-string">'amqp://localhost'</span>)
    <span class="hljs-built_in">this</span>.channel = <span class="hljs-keyword">await</span> connection.createChannel()
    <span class="hljs-keyword">const</span> { queue } = <span class="hljs-keyword">await</span> <span class="hljs-built_in">this</span>.channel.assertQueue(        <span class="hljs-comment">// (1)</span>
      <span class="hljs-built_in">this</span>.requestsQueueName)
    <span class="hljs-built_in">this</span>.queue = queue
  }
  handleRequests (handler) {                                 <span class="hljs-comment">// (2)</span>
    <span class="hljs-built_in">this</span>.channel.consume(<span class="hljs-built_in">this</span>.queue, <span class="hljs-keyword">async</span> <span class="hljs-params">msg</span><span class="hljs-function"> =&gt;</span> {
      <span class="hljs-keyword">const</span> content = <span class="hljs-built_in">JSON</span>.parse(msg.content.toString())
      <span class="hljs-keyword">const</span> replyData = <span class="hljs-keyword">await</span> handler(content)
      <span class="hljs-built_in">this</span>.channel.sendToQueue(                              <span class="hljs-comment">// (3)</span>
        msg.properties.replyTo,
        Buffer.from(<span class="hljs-built_in">JSON</span>.stringify(replyData)),
        { <span class="hljs-attr">correlationId</span>: msg.properties.correlationId }
      )
      <span class="hljs-built_in">this</span>.channel.ack(msg)
    })
  }
}
</code></pre>
    <p class="normal">In the <code class="Code-In-Text--PACKT-">initialize()</code> method of the <code class="Code-In-Text--PACKT-">AMQPReply</code> class, we create the queue that will receive the incoming requests (1): we can use a simple durable queue for this purpose. The <code class="Code-In-Text--PACKT-">handleRequests()</code> method (2) is used to register new request handlers from where new replies can be sent. When sending back a reply (3), we use <code class="Code-In-Text--PACKT-">channel.sendToQueue()</code> to publish the message straight into the queue specified in the <code class="Code-In-Text--PACKT-">replyTo</code> property of the message (our return address). We also set the <code class="Code-In-Text--PACKT-">correlationId</code> in the reply, so that <a id="_idIndexMarker1507"/>the receiver can match the message with the list of pending requests.</p>
    <h4 class="title">Implementing the requestor and the replier</h4>
    <p class="normal">Everything is <a id="_idIndexMarker1508"/>now ready to give<a id="_idIndexMarker1509"/> our system a try, but first, let's build a pair sample requestor and replier to see how to use our new abstraction.</p>
    <p class="normal">Let's start with the <code class="Code-In-Text--PACKT-">replier.js</code> module:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> { AMQPReply } <span class="hljs-keyword">from</span> <span class="hljs-string">'./amqpReply.js'</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">main</span><span class="hljs-function"> () </span>{
  <span class="hljs-keyword">const</span> reply = <span class="hljs-keyword">new</span> AMQPReply(<span class="hljs-string">'requests_queue'</span>)
  <span class="hljs-keyword">await</span> reply.initialize()
  reply.handleRequests(<span class="hljs-params">req</span><span class="hljs-function"> =&gt;</span> {
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">'Request received'</span>, req)
    <span class="hljs-keyword">return</span> { <span class="hljs-attr">sum</span>: req.a + req.b }
  })
}
main().catch(<span class="hljs-params">err</span><span class="hljs-function"> =&gt;</span> <span class="hljs-built_in">console</span>.error(err))
</code></pre>
    <p class="normal">It's nice to see how the abstraction we built allows us to hide all the mechanisms to handle the correlation ID and the return address. All we need to do is initialize a new <code class="Code-In-Text--PACKT-">reply</code> object, specifying the name of the queue where we want to receive our requests (<code class="Code-In-Text--PACKT-">'requests_queue'</code>). The rest of the code is just trivial; in practice, our sample replier simply calculates the sum of the two numbers received as the input and sends back the result in an object.</p>
    <p class="normal">On the other side, we have a sample requestor implemented in the <code class="Code-In-Text--PACKT-">requestor.js</code> file:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-keyword">import</span> { AMQPRequest } <span class="hljs-keyword">from</span> <span class="hljs-string">'./amqpRequest.js'</span>
<span class="hljs-keyword">import</span> delay <span class="hljs-keyword">from</span> <span class="hljs-string">'delay'</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">main</span><span class="hljs-function"> () </span>{
  <span class="hljs-keyword">const</span> request = <span class="hljs-keyword">new</span> AMQPRequest()
  <span class="hljs-keyword">await</span> request.initialize()
  <span class="hljs-keyword">async</span> <span class="hljs-keyword">function</span><span class="hljs-function"> </span><span class="hljs-title">sendRandomRequest</span><span class="hljs-function"> () </span>{
    <span class="hljs-keyword">const</span> a = <span class="hljs-built_in">Math</span>.round(<span class="hljs-built_in">Math</span>.random() * <span class="hljs-number">100</span>)
    <span class="hljs-keyword">const</span> b = <span class="hljs-built_in">Math</span>.round(<span class="hljs-built_in">Math</span>.random() * <span class="hljs-number">100</span>)
    <span class="hljs-keyword">const</span> reply = <span class="hljs-keyword">await</span> request.send(<span class="hljs-string">'requests_queue'</span>, { a, b })
    <span class="hljs-built_in">console</span>.log(<span class="hljs-string">`</span><span class="hljs-subst">${a}</span><span class="hljs-string"> + </span><span class="hljs-subst">${b}</span><span class="hljs-string"> = </span><span class="hljs-subst">${</span>reply.<span class="hljs-subst">sum}</span><span class="hljs-string">`</span>)
  }
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">let</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">20</span>; i++) {
    <span class="hljs-keyword">await</span> sendRandomRequest()
    <span class="hljs-keyword">await</span> delay(<span class="hljs-number">1000</span>)
  }
  request.destroy()
}
main().catch(<span class="hljs-params">err</span><span class="hljs-function"> =&gt;</span> <span class="hljs-built_in">console</span>.error(err))
</code></pre>
    <p class="normal">Our sample requestor sends 20 random requests at one-second intervals to the <code class="Code-In-Text--PACKT-">requests_queue</code> queue. In this case, also, it's interesting to see that our abstraction is doing its job perfectly, hiding all the details behind the implementation of the asynchronous Request/Reply pattern.</p>
    <p class="normal">Now, to try out the system, simply run the <code class="Code-In-Text--PACKT-">replier</code> module followed by a couple of <code class="Code-In-Text--PACKT-">requestor</code> instances:</p>
    <pre class="programlisting con"><code class="hljs-con">node replier.js
node requestor.js
node requestor.js
</code></pre>
    <p class="normal">You will see a set of operations <a id="_idIndexMarker1510"/>published by the requestors <a id="_idIndexMarker1511"/>and then received by the replier, which in turn will send back the responses to the right requestor.</p>
    <p class="normal">Now we can try other experiments. Once the replier is started for the first time, it creates a durable queue and this means that if we now stop it and then run the replier again, no request will be lost. All the messages will be stored in the queue until the replier is started again!</p>
    <div class="note">
      <p class="Information-Box--PACKT-">Note that based on how we implemented the application, a request will time out after 10 seconds. So, in order for a reply to reach the requestor in time, the replier can afford to have only a limited downtime (certainly less than 10 seconds).</p>
    </div>
    <p class="normal">Another nice feature that we get for free by using AMQP is the fact that our replier is scalable out of the box. To test this assumption, we can try to start two or more instances of the replier, and watch the requests being load balanced between them. This works because, every time a requestor starts, it attaches itself as a listener to the same durable queue, and as a <a id="_idIndexMarker1512"/>result, the broker will <a id="_idIndexMarker1513"/>load balance the messages across all the consumers of the queue (remember the Competing Consumers pattern?). Sweet!</p>
    <div class="note">
      <p class="Information-Box--PACKT-">ZeroMQ has a pair of sockets specifically meant for implementing request/reply patterns, called <code class="Code-In-Text--PACKT-">REQ</code>/<code class="Code-In-Text--PACKT-">REP</code>, however, they are synchronous (only one request/response at a time). More complex request/reply patterns are possible with more sophisticated techniques. For more information, you can read the official guide at <a href="http://nodejsdp.link/zeromq-reqrep"><span class="url">nodejsdp.link/zeromq-reqrep</span></a>.</p>
      <p class="Information-Box--PACKT-">A Request/Reply pattern with a return address is also possible on top of Redis Streams and resembles very closely the system we implemented with AMQP. We'll leave this to you to implement as an exercise.</p>
    </div>
    <h1 id="_idParaDest-403" class="title">Summary</h1>
    <p class="normal">You have reached the end of this chapter. Here, you learned the most important messaging and integration patterns and the role they play in the design of distributed systems. You should now have mastered the three most important types of message exchange patterns: Publish/Subscribe, Task Distribution, and Request/Reply, implemented either on top of a peer-to-peer architecture or using a broker. We analyzed the pros and cons of each pattern and architecture, and we saw that by using a broker (implementing either a message queue or data stream), it's possible to implement reliable and scalable applications with little effort, but at the cost of having one more system to maintain and scale.</p>
    <p class="normal">You have also learned how ZeroMQ allows you to build distributed systems where you can have total control over every aspect of the architecture, fine tuning its properties around your very own requirements.</p>
    <p class="normal">Ultimately, both approaches will give you all the tools that you need to build any type of distributed systems, from basic chat applications to web-scale platforms used by millions of people.</p>
    <p class="normal">This chapter also closes the book. By now, you should have a toolbelt full of patterns and techniques that you can go and apply in your projects. You should also have a deeper understanding of how Node.js development works and what its strengths and weaknesses are. Throughout the book, you also had the chance to work with a myriad of packages and solutions developed by many extraordinary developers. In the end, this is the most beautiful aspect of Node.js: its people, a community where everybody plays their part in giving something back.</p>
    <p class="normal">We hope you enjoyed our small contribution and we look forward to seeing yours.</p>
    <p class="normal">Sincerely, Mario Casciaro and Luciano Mammino.</p>
    <h1 id="_idParaDest-404" class="title">Exercises</h1>
    <ul>
      <li class="Bullet--PACKT-"><strong class="keyword">13.1 History service with streams</strong>: In our publish/subscribe example with Redis Stream, we didn't need a history service (as we did instead in the related AMQP example) because all the message history was saved in the stream anyway. Now, implement such a history service, storing all the incoming messages in a separate database and use this service to retrieve the chat history when a new client connects. Hint: the history service will need to remember the ID of the last message retrieved across restarts.</li>
      <li class="Bullet--PACKT-"><strong class="keyword">13.2 Multiroom chat</strong>: Update the chat application example we created in this chapter to be able to support multiple chat rooms. The application should also support displaying the message history when the client connects. You can choose the messaging system you prefer, and even mix different ones.</li>
      <li class="Bullet--PACKT-"><strong class="keyword">13.3 Tasks that stop</strong>: Update the hashsum cracker examples we implemented in this chapter and add the necessary logic to stop the computation on all nodes once a match has been found.</li>
      <li class="Bullet--PACKT-"><strong class="keyword">13.4 Reliable task processing with ZeroMQ</strong>: Implement a mechanism to make our hashsum cracker example with ZeroMQ more reliable. As we already mentioned, with the implementation we saw in this chapter, if a worker crashes, all the tasks it was processing are lost. Implement a peer-to-peer queuing system and an acknowledgment mechanism to make sure that the message is always processed at least once (excluding errors due to hypothetical unprocessable tasks).</li>
      <li class="Bullet--PACKT-"><strong class="keyword">13.5 Data aggregator</strong>: Create an abstraction that can be used to send a request to all the nodes connected to the system and then returns an aggregation of all the replies received by those nodes. Hint: you can use publish/reply to send the request, and any one-way channel to send back the replies. Use any combination of the technologies we have learned.</li>
      <li class="Bullet--PACKT-"><strong class="keyword">13.6 Worker status CLI</strong>: Use the data aggregator component defined in <em class="italic">Exercise 13.5</em> to implement a command-line application that, when invoked, displays the current status of all the workers of the hashsum cracker application (for example, which chunk they are processing, whether they found a match, and so on).</li>
      <li class="Bullet--PACKT-"><strong class="keyword">13.7 Worker status UI</strong>: Implement a web application (from client to server) to expose the status of the workers of the hashsum cracker application through a web UI that can report in real time when a match is found.</li>
      <li class="Bullet--PACKT-"><strong class="keyword">13.8 Pre-initialization queues are back</strong>: In the AMQP request/reply example, we implemented a <em class="italic">Delayed Startup</em> pattern to deal with the fact that the <code class="Code-In-Text--PACKT-">initialize()</code> method is asynchronous. Now, refactor that example by adding pre-initialization queues as we learned in <em class="chapterRef">Chapter 11</em>, <em class="italic">Advanced Recipes</em>.</li>
      <li class="Bullet--PACKT-"><strong class="keyword">13.9 Request/reply with Redis Streams</strong>: Build a request/reply abstraction on top of Redis Streams.</li>
      <li class="Bullet--PACKT-"><strong class="keyword">13.10 Kafka</strong>: If you are brave enough, try to reimplement all relevant examples in this chapter using Apache Kafka (<a href="http://nodejsdp.link/kafka"><span class="url">nodejsdp.link/kafka</span></a>) instead of Redis Streams.</li>
    </ul>
  </div>
</body></html>