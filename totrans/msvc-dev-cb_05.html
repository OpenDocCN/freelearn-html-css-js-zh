<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Reliability Patterns</h1>
                </header>
            
            <article>
                
<p class="mce-root">In this chapter, we will cover the following recipes:</p>
<ul>
<li class="mce-root">Using circuit breakers to implement backpressure</li>
<li class="mce-root">Retrying requests with exponential backoff</li>
<li class="mce-root">Improving performance with caching</li>
<li class="mce-root">Fronting your services with a CDN</li>
<li class="mce-root">Gracefully degrading the user experience</li>
<li class="mce-root">Testing your failure scenarios with controlled game days</li>
<li class="mce-root">Introducing automated chaos</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p>Reliability is becoming an increasingly popular topic in the world of distributed systems. Job postings for <strong>Site Reliability Engineers</strong> (<strong>SRE</strong>) or <strong>chaos engineers</strong> are becoming common, and as more and more organizations move toward cloud-native technologies, it's becoming impossible to ignore that system failure is always a reality. Networks will experience congestion, switches, other hardware components will fail, and a whole host of potential failure modes in systems will surprise us in production. It is impossible to completely prevent failures, so we should try to design our systems to be as tolerant of failure as possible.  </p>
<p>Microservices provide interesting and useful opportunities to design for reliability. Because microservices encourage us to break our systems into services encapsulating single responsibilities, we can use a number of useful reliability patterns to isolate failures when they do occur. Microservice architectures also present a number of challenges when planning for reliability. Increased reliance on network requests, heterogeneous configurations, multiple data stores and connection pools, and different technical stacks all contribute to an inherently more complex environment where different styles of failure modes can surface.</p>
<p>Whether dealing with a microservice architecture or a monolith code base, we all find ourselves fundamentally surprised [1] (you can check this link for more information: <a href="https://www.youtube.com/watch?v=tZ2wj2pxO6Q">https://www.youtube.com/watch?v=tZ2wj2pxO6Q</a>) by the behavior of a system under some kind of failure state at one point or another. Building resiliency into our systems from the start allows us to optimize how we react in these situations. In this chapter, we'll discuss a number of useful reliability patterns that can be used when designing and building microservices to prepare for and reduce the impact of system failures, both expected and unexpected.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using circuit breakers</h1>
                </header>
            
            <article>
                
<p>Failures in distributed systems can be difficult to debug. A symptom (spikes in latency or a high error rate) can appear far away from the underlying cause (slow database query, garbage collection cycles causing a service to slow down the processing of requests). Sometimes a complete outage can be the result of a failure in a small part of the system, especially when components of the system are having difficulty handling increases in load.</p>
<p>Whenever possible, we want to prevent failures in one part of a system from cascading to other parts, causing widespread and hard-to-debug production issues. Furthermore, if a failure is temporary, we'd like our system to be able to self-repair when the failure is over. If a specific service is experiencing problems because of a temporary spike in load, we should design our system in such a way that it prevents requests to the unhealthy service, allowing it time to recover before beginning to send it traffic again. </p>
<p>Circuit breakers are used in houses to prevent the overuse of electricity from heating up the internal wiring and burning the house down. A circuit is tripped if the breaker detects that it is being overused and cannot handle the amount of current being drawn from it. After some time passes, the circuit can be closed again, allowing the system to function normally.</p>
<p>This same approach can be translated to software and applied to microservice architectures. When a service invokes another service, we should wrap the RPC call in a circuit breaker. If the request fails repeatedly, indicating that the service is unhealthy, the circuit breaker is opened, preventing any further requests from being attempted. The invoking service can then "fail fast" and decide how to handle the failure mode. After a configurable period of time, we can allow another request through, and if it succeeds, close the circuit again, allowing the system to resume normal operation. You can a look at the following related flowchart:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/e1b37656-3fa1-43e4-9872-321809e991ed.png" style="width:29.42em;height:12.25em;"/></div>
<p>Libraries that implement circuit breakers are available for most popular programming languages. The Hystrix fault-tolerance library, built by Netflix and used in previous recipes is one such library. Some frameworks, such as Twitter's Finagle, automatically wrap RPCs in circuit breakers, keeping track of failures and automatically managing the state of the breaker. Open source service-mesh software, such as <strong>Conduit</strong> and <strong>Linkerd</strong>, automatically add circuit breakers to RPCs as well. In this recipe, we'll introduce a library called <kbd>resilience4j</kbd> and use its circuit breaker implementation to allow calls from one service to another to fail fast in the event of a failure threshold being reached. To make the example more concrete, we'll modify a message service, which calls a socialgraph service to determine whether two users follow each other, and wrap RPC calls in a circuit breaker.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>To demonstrate wrapping service invocations in circuit breakers, we're going to create a version of the <kbd>pichat</kbd> message service that exposes endpoints for sending and retrieving messages. To send a message from a sender to a recipient, those two users must have a friendship. Friendships are handled by a social-graph-service. For the sake of simplicity, we'll code up a simple mock social-graph-service in Ruby, as we have done in previous recipes. The mock service will expose a single endpoint that lists friendships for a specified user. Here is the source code for the mock social-graph-service in Ruby:</p>
<pre>require 'sinatra'<br/>require 'json'<br/><br/>get '/friendships/:username' do<br/>  content_type :json<br/>  {<br/>    'username': params[:username],<br/>    'friendships': [<br/>      'pichat:users:johndoe',<br/>      'pichat:users:janesmith',<br/>      'pichat:users:anotheruser'<br/>    ]<br/>  }.to_json<br/>end</pre>
<div class="packt_infobox">In our mock service, we're using strings in the <kbd>pichat:users:username</kbd> format to identify users in our system. These are pseudo-URIs, which uniquely identify users in our system. For now, just know that these are unique strings used to identify users in our system.</div>
<p>Our mock social-graph-service exposes the following single endpoint:</p>
<pre>GET /friendships/paulosman</pre>
<p>The preceding endpoint returns a JSON response body representing the friendships that the requested user has:</p>
<pre>{<br/>  "username": "fdsa",<br/>  "friendships": [<br/>    "pichat:users:foobar",<br/>    "pichat:users:asomefdsa"<br/>  ]<br/>}</pre>
<p>With our mock social-graph-service running on the localhost, port <kbd>4567</kbd> (the default port for Ruby Sinatra applications), we're ready to start writing our message service. As in previous recipes, we'll use Java and the Spring Boot framework. We'll also use the <kbd>resilience4j</kbd> circuit-breaker library to wrap calls from the message service to the social-graph-service. First, we'll develop our message-service code, then we'll add in the <kbd>resilience4j</kbd> circuit-breaker library to add a level of resilience to our service, as shown in the following steps:</p>
<ol>
<li>Create a new Gradle Java project and add the following code to <kbd>build.gradle</kbd>:</li>
</ol>
<pre style="color: black;padding-left: 60px">group 'com.packtpub.microservices'<br/>version '1.0-SNAPSHOT'<br/><br/>buildscript {<br/>    repositories {<br/>        mavenCentral()<br/>    }<br/>    dependencies {<br/>        classpath group: 'org.springframework.boot', name: 'spring-boot-gradle-plugin', version: '1.5.9.RELEASE'<br/>    }<br/>}<br/><br/>apply plugin: 'java'<br/>apply plugin: 'org.springframework.boot'<br/><br/>sourceCompatibility = 1.8<br/><br/>repositories {<br/>    mavenCentral()<br/>}<br/><br/>dependencies {<br/>    testCompile group: 'junit', name: 'junit', version: '4.12'<br/>    compile group: 'org.springframework.boot', name: 'spring-boot-starter-web'<br/>}</pre>
<ol start="2">
<li>Our message-service code will have two beans that get autowired into our controller. The first is an in-memory message repository (in a real-world example, this would be replaced with a more durable persistence layer), and the second is a client for the social-graph-service. Before we create those, let's create some supporting objects. Create a new package called <kbd>com.packtpub.microservices.ch05.message.exceptions</kbd> and a new class called <kbd>MessageNotFoundException</kbd>. This will be used to indicate that a message cannot be found, which will result in a <kbd>404</kbd> response from our service, as shown here:</li>
</ol>
<pre style="color: black;padding-left: 60px">package com.packtpub.microservices.ch05.exceptions;<br/><br/>import org.springframework.http.HttpStatus;<br/>import org.springframework.web.bind.annotation.ResponseStatus;<br/><br/>@ResponseStatus(HttpStatus.NOT_FOUND)<br/>public class MessageNotFoundException extends Exception {<br/>    public MessageNotFoundException(String message) { super(message); }<br/>}</pre>
<ol start="3">
<li>Create another class in the exceptions package called <kbd>MessageSendForbiddenException</kbd>. This will be used to indicate that a message cannot be sent because the sender and the recipient are not friends. The response code from our service will be <kbd>403</kbd> forbidden, as shown here:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">package com.packtpub.microservices.ch05.message.exceptions;<br/><br/>import org.springframework.http.HttpStatus;<br/>import org.springframework.web.bind.annotation.ResponseStatus;<br/><br/>@ResponseStatus(HttpStatus.FORBIDDEN)<br/>public class MessageSendForbiddenException extends Exception {<br/>    public MessageSendForbiddenException(String message) { super(message); }<br/>}</pre>
<ol start="4">
<li>Create the <kbd>SocialGraphClient</kbd> class. Create a new package called <kbd>com.packtpub.microservices.ch05.message.clients</kbd> and a new class called <kbd>SocialGraphClient</kbd>, as shown here:</li>
</ol>
<pre style="color: black;padding-left: 60px">package com.packtpub.microservices.ch05.message.clients;<br/><br/>import com.packtpub.microservices.ch05.models.Friendships;<br/>import org.springframework.web.client.RestTemplate;<br/><br/>import java.util.List;<br/><br/>public class SocialGraphClient {<br/>    private String baseUrl;<br/><br/>    public SocialGraphClient(String baseUrl) {<br/>        this.baseUrl = baseUrl;<br/>    }<br/><br/>    public List&lt;String&gt; getFriendships(String username) {<br/>        String requestUrl = baseUrl + "/friendships/" + username;<br/>        RestTemplate template = new RestTemplate();<br/>        UserFriendships friendships = template.getForObject(requestUrl, UserFriendships.class);<br/>        return friendships.getFriendships();<br/>    }<br/>}</pre>
<ol start="5">
<li>Let's create our models. We'll need a model to represent <kbd>UserFriendships</kbd> that a specific user has as well as a model to represent <kbd>Messages</kbd>. Create a new package called <kbd>com.packtpub.microservices.ch05.models</kbd> and a new class called <kbd>Friendships</kbd> as shown here:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">package com.packtpub.microservices.ch05.models;<br/><br/>import java.util.List;<br/><br/>public class Friendships {<br/>    private String username;<br/>    private List&lt;String&gt; friendships;<br/><br/>    public Friendships() {<br/>        this.friendships = new ArrayList&lt;&gt;();<br/>    }<br/><br/>    public Friendships(String username) {<br/>        this.username = username;<br/>        this.friendships = new ArrayList&lt;&gt;();<br/>    }<br/><br/>    public Friendships(String username, List&lt;String&gt; friendships) {<br/>        this.username = username;<br/>        this.friendships = friendships;<br/>    }<br/><br/>    public String getUsername() {<br/>        return username;<br/>    }<br/><br/>    public void setUsername(String username) {<br/>        this.username = username;<br/>    }<br/><br/>    public List&lt;String&gt; getFriendships() {<br/>        return friendships;<br/>    }<br/><br/>    public void setFriendships(List&lt;String&gt; friendships) {<br/>        this.friendships = friendships;<br/>    }<br/>}</pre>
<ol start="6">
<li>Create a new class, in the same package, called <kbd>Message</kbd> as shown here:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">package com.packtpub.microservices.ch05.message.models;<br/><br/>import com.fasterxml.jackson.annotation.JsonProperty;<br/><br/>public class Message {<br/>    private String id;<br/>    private String sender;<br/>    private String recipient;<br/>    private String body;<br/>    @JsonProperty("attachment_uri")<br/>    private String attachmentUri;<br/><br/>    public Message() {}<br/><br/>    public Message(String sender, String recipient, String body, String attachmentUri) {<br/>        this.sender = sender;<br/>        this.recipient = recipient;<br/>        this.body = body;<br/>        this.attachmentUri = attachmentUri;<br/>    }<br/><br/>    public Message(String id, String sender, String recipient, String body, String attachmentUri) {<br/>        this.id = id;<br/>        this.sender = sender;<br/>        this.recipient = recipient;<br/>        this.body = body;<br/>        this.attachmentUri = attachmentUri;<br/>    }<br/><br/>    public String getId() {<br/>        return id;<br/>    }<br/><br/>    public String getSender() {<br/>        return sender;<br/>    }<br/><br/>    public void setSender(String sender) {<br/>        this.sender = sender;<br/>    }<br/><br/>    public String getRecipient() {<br/>        return recipient;<br/>    }<br/><br/>    public void setRecipient(String recipient) {<br/>        this.recipient = recipient;<br/>    }<br/><br/>    public String getBody() {<br/>        return body;<br/>    }<br/><br/>    public void setBody(String body) {<br/>        this.body = body;<br/>    }<br/><br/>    public String getAttachmentUri() {<br/>        return attachmentUri;<br/>    }<br/><br/>    public void setAttachmentUri(String attachmentUri) {<br/>        this.attachmentUri = attachmentUri;<br/>    }<br/>}</pre>
<ol start="7">
<li>With our models created, we can now move on to our in-memory message repository. This class simply uses <kbd>HashMap</kbd> to store messages keyed by <kbd>UUID</kbd>. These messages are not durable and will not survive a restart of the service, so this is not a recommended technique for a production service. The class has two methods: <kbd>saved</kbd>, which generates UUID and stores a message in the map, and <kbd>get</kbd>, which attempts to retrieve a message from the map. If no message is found, an exception is thrown, as shown here:</li>
</ol>
<pre style="color: black;padding-left: 60px">package com.packtpub.microservices.ch05.message;<br/><br/>import com.packtpub.microservices.ch05.message.exceptions.MessageNotFoundException;<br/>import com.packtpub.microservices.ch05.message.models.Message;<br/><br/>import java.util.HashMap;<br/>import java.util.Map;<br/>import java.util.UUID;<br/><br/>public class MessageRepository {<br/><br/>    private Map&lt;String, Message&gt; messages;<br/><br/>    public MessageRepository() {<br/>        messages = new HashMap&lt;&gt;();<br/>    }<br/><br/>    public Message save(Message message) {<br/>        UUID uuid = UUID.randomUUID();<br/>        Message saved = new Message(uuid.toString(), message.getSender(), message.getRecipient(),<br/>                message.getBody(), message.getAttachmentUri());<br/>        messages.put(uuid.toString(), saved);<br/>        return saved;<br/>    }<br/><br/>    public Message get(String id) throws MessageNotFoundException {<br/>        if (messages.containsKey(id)) {<br/>            Message message = messages.get(id);<br/>            return message;<br/>        } else {<br/>            throw new MessageNotFoundException("Message " + id + " could not be found");<br/>        }<br/>    }<br/>}</pre>
<ol start="8">
<li>Our service has a single controller for messages. The controller has two endpoints, one that allows a caller to retrieve a message by ID (or a <kbd>404</kbd> response if the message is not found) and another that attempts to send a message (or a <kbd>403</kbd> response if the sender and recipient of the message are not friends):</li>
</ol>
<pre style="color: black;padding-left: 60px">package com.packtpub.microservices.ch05.message;<br/><br/>import com.packtpub.microservices.ch05.message.clients.SocialGraphClient;<br/>import com.packtpub.microservices.ch05.message.exceptions.MessageNotFoundException;<br/>import com.packtpub.microservices.ch05.message.exceptions.MessageSendForbiddenException;<br/>import com.packtpub.microservices.ch05.message.models.Message;<br/>import org.springframework.beans.factory.annotation.Autowired;<br/>import org.springframework.http.ResponseEntity;<br/>import org.springframework.web.bind.annotation.*;<br/>import org.springframework.web.servlet.support.ServletUriComponentsBuilder;<br/><br/>import java.net.URI;<br/>import java.util.List;<br/><br/>@RestController<br/>public class MessageController {<br/><br/>    @Autowired<br/>    private MessageRepository messagesStore;<br/><br/>    @Autowired<br/>    private SocialGraphClient socialGraphClient;<br/><br/>    @RequestMapping(path = "/messages/{id}", method = RequestMethod.GET, produces = "application/json")<br/>    public Message get(@PathVariable("id") String id) throws MessageNotFoundException {<br/>        return messagesStore.get(id);<br/>    }<br/><br/>    @RequestMapping(path = "/messages", method = RequestMethod.POST, produces = "application/json")<br/>    public ResponseEntity&lt;Message&gt; send(@RequestBody Message message) throws MessageSendForbiddenException {<br/><br/>        List&lt;String&gt; friendships = socialGraphClient.getFriendships(message.getSender());<br/>        if (!friendships.contains(message.getRecipient())) {<br/>            throw new MessageSendForbiddenException("Must be friends to send message");<br/>        }<br/><br/>        Message saved = messagesStore.save(message);<br/>        URI location = ServletUriComponentsBuilder<br/>                .fromCurrentRequest().path("/{id}")<br/>                .buildAndExpand(saved.getId()).toUri();<br/>        return ResponseEntity.created(location).build();<br/>    }<br/>}</pre>
<ol start="9">
<li>Create a <kbd>Application</kbd> class that simply runs our application and creates the necessary beans that get wired into our controller, as shown here:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px">package com.packtpub.microservices.ch05.message;<br/><br/>import com.packtpub.microservices.ch05.message.clients.SocialGraphClient;<br/>import org.springframework.boot.SpringApplication;<br/>import org.springframework.boot.autoconfigure.SpringBootApplication;<br/>import org.springframework.context.annotation.Bean;<br/><br/>@SpringBootApplication<br/>public class Application {<br/>    @Bean<br/>    public MessageRepository messageRepository() {<br/>        return new MessageRepository();<br/>    }<br/><br/>    @Bean<br/>    public SocialGraphClient socialGraphClient() {<br/>        return new SocialGraphClient("http://localhost:4567");<br/>    }<br/><br/></pre>
<pre class="mce-root" style="padding-left: 60px">    public static void main(String[] args) {<br/>        SpringApplication.run(Main.class, args);<br/>    }<br/>}</pre>
<p>This service works, and meets our primary requirement that a message cannot be sent if the sender and recipient are not friends, but it is susceptible to all the problems we described. If the social-graph-service is experiencing problems, the message service will be dependent on timeouts in the <kbd>RestTemplate</kbd> client, which will impact the number of requests the message service is able to serve. Furthermore, if the social-graph-service is overwhelmed and starts returning <kbd>503</kbd> (an HTTP status code meant to indicate that a service is temporarily unavailable) the message service has no mechanism to allow the social-graph-service to recover. Let's now introduce the <kbd>resilience4j</kbd> circuit-breaker library and wrap calls to the social-graph-service: </p>
<ol>
<li>Open <kbd>build.gradle</kbd> and add the <kbd>resilience4j</kbd> circuit-breaker library to the list of dependencies, as shown here:</li>
</ol>
<pre style="color: black;padding-left: 60px">...<br/>dependencies {<br/>    testCompile group: 'junit', name: 'junit', version: '4.12'<br/><strong>    compile group: 'io.github.resilience4j', name: 'resilience4j-circuitbreaker', version: </strong><strong>'0.11.0'</strong><br/>    compile group: 'org.springframework.boot', name: 'spring-boot-starter-web'<br/>}<br/>...</pre>
<ol start="2">
<li>Modify <kbd>SocialGraphClient</kbd> to use <kbd>CircuitBreaker</kbd> when invoking the social-graph-client. In the event that the <kbd>SocialGraphClient</kbd> returns a failure, we'll return an empty <kbd>Friendships</kbd> instance, which will cause our service to respond to the user request with a <kbd>403</kbd> forbidden (default closed). We'll use the default configuration for circuit breakers here, but you should consult the documentation for <kbd>resilience4j</kbd>, which contains plenty of information about configuring circuit breakers to suit the specific needs of your service. Take a look at this code:</li>
</ol>
<pre style="color: black;padding-left: 60px">package com.packtpub.microservices.ch05.clients;<br/><br/>import com.packtpub.microservices.ch05.models.Friendships;<br/>import <strong>io.github.resilience4j.circuitbreaker.CircuitBreaker;<br/>import io.github.resilience4j.circuitbreaker.CircuitBreakerRegistry</strong><strong>;</strong><br/><strong>import io.vavr.CheckedFunction0;<br/>import io.vavr.control.Try</strong><strong>;</strong><br/>import org.springframework.web.client.RestTemplate;<br/><br/>import java.util.List;<br/><br/>public class SocialGraphClient {<br/>    private String baseUrl;<br/><br/><strong>    private CircuitBreaker circuitBreaker</strong><strong>;</strong><br/><br/>    public SocialGraphClient(String baseUrl) {<br/>        this.baseUrl = baseUrl;<br/>        this.<strong>circuitBreaker = CircuitBreaker.ofDefaults("socialGraphClient");<br/></strong>    }<br/><br/>    public List&lt;String&gt; getFriendships(String username) {<br/><br/>        <strong>CheckedFunction0&lt;Friendships&gt; decoratedSupplier = CircuitBreaker.decorateCheckedSupplier(circuitBreaker, () -&gt; {</strong><br/>            String requestUrl = baseUrl + "/friendships/" + username;<br/>            RestTemplate template = new RestTemplate();<br/>            return template.getForObject(requestUrl, Friendships.class);<br/>        <strong>})</strong><strong>;</strong><br/><br/>        <strong>Try&lt;Friendships&gt; result = Try.of(decoratedSupplier);<br/></strong><br/><strong>        return result.getOrElse(new Friendships(username)).getFriendships();<br/></strong>    }<br/>}</pre>
<p>Now our service wraps dangerous network calls in a circuit breaker, preventing failures in the social-graph-service from cascading to the message service. In the event of a temporary failure in the social-graph-service, the message service will eventually fail fast and allow the social-graph-service time to recover. You can test this by forcing the mock-social-graph service to return an error code—that's left as a fun exercise for the reader! </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Retrying requests with exponential backoff</h1>
                </header>
            
            <article>
                
<p>Failure in distributed systems is inevitable. Instead of trying to prevent failure entirely, we want to design systems that are capable of self-repair. To accomplish this, it is essential to have a good strategy for clients to follow when initiating retries. A service may become temporarily unavailable or experience a problem that requires manual response from an on-call engineer. In either scenario, clients should be able to queue and then retry requests to be given the best chance of success. </p>
<p>Retrying endlessly in the event of an error is not an effective tactic. Imagine a service starts to experience a higher-than-normal failure rate, perhaps even failing 100% of requests. If clients all continuously enqueue retries without ever giving up, you'll end up with a thundering-herd problem—clients continuously retrying requests without limit. As the timeline of the failure progresses, more clients will experience failures, resulting in more retries. You'll end up with a traffic pattern, illustrated by the following diagram, which is a similar graph to the one you'll see during a denial-of-service attack. The end result will be the same—cascading failures due to overwhelmed services and a shedding of legitimate traffic. Your application will become unusable and the failing service will be harder to isolate and repair:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/9ab2b33d-c4c1-4421-bd88-deaecaf2d6c1.png" style="width:40.08em;height:24.17em;"/></div>
<p>The solution to prevent thundering herds is to add a backoff algorithm that exponentially increases the wait period between retries and gives up after a certain number of failures. This approach is referred to as capped exponential backoff. Adding an exponentially-increasing sleep function between retries accomplishes half of what we're after—clients will slow down their retry attempts, distributing load over time. Unfortunately, client retries will still be clustered, resulting in periods of time where your service is being hammered by many concurrent requests. The second half of our strategy addresses this problem by adding a randomized value or jitter to our sleep function to distribute the retries over time. To summarize, our retry strategy has the following three requirements:</p>
<ul>
<li>Retries must be spaced out using an exponential backoff</li>
<li>Retries must be randomized by adding jitter</li>
<li>Retries must terminate after a specific amount of time</li>
</ul>
<p>Most HTTP libraries will have support for a retry strategy that meets these requirements. In this recipe, we'll look at the HTTP <kbd>client</kbd> library for Java written by Google.  </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>To demonstrate using exponential backoff and jitter, we're going to create a sample service in Ruby that has one simple job: to return an HTTP status that indicates a failure. In previous recipes, we've used the <kbd>sinatra</kbd> Ruby library to do this, so we'll continue with this, a service that simply returns a <kbd>503</kbd> HTTP status code for every request, as shown here:</li>
</ol>
<pre style="color: black;padding-left: 60px">require 'sinatra'<br/><br/>get '/' do<br/>  halt 503<br/>end</pre>
<ol start="2">
<li>Create an HTTP client using the Google HTTP <kbd>client</kbd> Library. First, create a new Gradle Java project with the following <kbd>build.gradle</kbd> file that imports the necessary libraries and plugins, as shown here:</li>
</ol>
<pre style="color: black;padding-left: 60px">group 'com.packtpub.microservices'<br/>version '1.0-SNAPSHOT'<br/><br/>apply plugin: 'java'<br/>apply plugin: 'application'<br/><br/>mainClassName = 'com.packtpub.microservices.ch05.retryclient.Main'<br/><br/>sourceCompatibility = 1.8<br/><br/>repositories {<br/>    mavenCentral()<br/>}<br/><br/>dependencies {<br/>    compile group: 'com.google.http-client', name: 'google-http-client', version: '1.23.0'<br/>    testCompile group: 'junit', name: 'junit', version: '4.12'<br/>}</pre>
<ol start="3">
<li>Create a new package called <kbd>com.packtpub.microservices.ch05.retryclient</kbd>. Create a new class called <kbd>Main</kbd>. In the <kbd>Main</kbd> class, we're just going to create an HTTP request and execute it. If the request was successful, we'll just print its status code with a nice message. If the success fails, we'll still print its status code, but with a message indicating that something went wrong. The first version of our HTTP client will not attempt any retries. The purpose of this code is to write the simplest client possible, not to show off the features of the Google HTTP <kbd>client</kbd> library, but I encourage you to consult the documentation for the project to learn more about it. Let's take a look at the following code:</li>
</ol>
<pre style="color: black;padding-left: 60px">package com.packtpub.microservices.ch05.retryclient;<br/><br/>import com.google.api.client.http.*;<br/>import com.google.api.client.http.javanet.NetHttpTransport;<br/>import com.google.api.client.util.ExponentialBackOff;<br/><br/>import java.io.IOException;<br/><br/>public class Main {<br/><br/>    static final HttpTransport transport = new NetHttpTransport();<br/><br/>    public static void main(String[] args) {<br/>        HttpRequestFactory factory = transport.createRequestFactory();<br/>        GenericUrl url = new GenericUrl("http://localhost:4567/");<br/><br/>        try {<br/>            HttpRequest request = factory.buildGetRequest(url);<br/>            HttpResponse response = request.execute();<br/>            System.out.println("Got a successful response: " + response.getStatusCode());<br/>        } catch (HttpResponseException e) {<br/>            System.out.println("Got an unsuccessful response: " + e.getStatusCode());<br/>        } catch (IOException e) {<br/>            e.printStackTrace();<br/>        }<br/>    }<br/>}</pre>
<ol start="4">
<li>If you run the preceding code either with your IDE or by running <kbd>./gradlew run</kbd> from your command line, you'll see that the code tries to make a single HTTP request, receives <kbd>503</kbd> from our Ruby service, and then gives up. Let's now instrument it with a configurable backoff that has a randomization factor for adding jitter, as shown here:</li>
</ol>
<pre style="color: black;padding-left: 60px">package com.packtpub.microservices.ch05.retryclient;<br/><br/>import com.google.api.client.http.*;<br/>import com.google.api.client.http.javanet.NetHttpTransport;<br/>import com.google.api.client.util.ExponentialBackOff;<br/><br/>import java.io.IOException;<br/><br/>public class Main {<br/><br/>    static final HttpTransport transport = new NetHttpTransport();<br/><br/>    public static void main(String[] args) {<br/>        HttpRequestFactory factory = transport.createRequestFactory();<br/>        GenericUrl url = new GenericUrl("http://localhost:4567/");<br/><br/>        try {<br/>            HttpRequest request = factory.buildGetRequest(url);<br/>            <strong>ExponentialBackOff backoff = new ExponentialBackOff.Builder()</strong><br/><strong>                    .setInitialIntervalMillis(500)</strong><br/><strong>                    .setMaxElapsedTimeMillis(10000)</strong><br/><strong>                    .setMaxIntervalMillis(6000)</strong><br/><strong>                    .setMultiplier(1.5)</strong><br/><strong>                    .setRandomizationFactor(0.5)</strong><br/><strong>                    .build();<br/></strong><br/><strong>            request.setUnsuccessfulResponseHandler(</strong><br/><strong>              new HttpBackOffUnsuccessfulResponseHandler(backoff))</strong><strong>;</strong><br/>            HttpResponse response = request.execute();<br/>            System.out.println("Got a successful response: " + response.getStatusCode());<br/>        } catch (HttpResponseException e) {<br/>            System.out.println("Got an unsuccessful response: " + e.getStatusCode());<br/>        } catch (IOException e) {<br/>            e.printStackTrace();<br/>        }<br/>    }<br/>}</pre>
<ol start="5">
<li>If you run the program now and watch the logs of your Ruby service, you'll see that the code makes multiple attempts to make the request, increasing the amount of time it sleeps between retries, before eventually giving up after about 10 seconds. In a real-world setting, this could give the service enough time to possibly recover while not creating a thundering herd that would eliminate any possibility of repair. </li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Improving performance with caching</h1>
                </header>
            
            <article>
                
<p>Microservices should be designed in such a way that a single service is usually the only thing that reads or writes to a particular data store. In this model, services have full ownership over the domain models involved in the business capability they provide. Having clean boundaries makes it easier to think about the life cycle of data in a system. Some <span>models</span> in our system will change frequently, but many will be read much more often than they are written. In these cases, we can use a cache to store infrequently changed data, saving us from having to make a request to the database every time the object is requested. Database queries are typically more expensive than cache lookups, so it's ideal to use a cache whenever possible. </p>
<p>In addition to help improve performance, having an effective caching layer can help improve the reliability of a service. It's impossible to guarantee 100% availability for a database, so in the event of a database failure, a service can revert to serving cached data. In most cases, it's preferable for a user to receive some data, even if it's old and potentially out of date, than to receive no data at all. Having a cache layer allows you to configure your service to use it as another source of available data to serve to users of your service.</p>
<p>In this recipe, we'll create a simple example service that serves information about users of your application. It will have two endpoints, the first will accept POST requests and will persist a properly formed user to a database. The second will retrieve a user representation by the ID specified. IDs are stored as UUIDs, which is preferable to autoincrementing IDs for many reasons, which we'll go into in later chapters. We'll start with the basic service, then add caching so we can see specifically what steps are required. In this recipe, we'll use Redis, a popular open source in-memory data-structure store that is particular useful for storing key-value pairs. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Create a Gradle Java project called caching-user-service with the following <kbd>build.gradle</kbd> file. Note that we're adding dependencies for <strong>Java Persistence API</strong> (<strong>JPA</strong>) and a Java MySQL <kbd>client</kbd> library:</li>
</ol>
<pre style="color: black;padding-left: 60px">group 'com.packtpub.microservices.ch05'<br/>version '1.0-SNAPSHOT'<br/><br/>buildscript {<br/>    repositories {<br/>        mavenCentral()<br/>    }<br/>    dependencies {<br/>        classpath("org.springframework.boot:spring-boot-gradle-plugin:2.0.0.RELEASE")<br/>    }<br/>}<br/><br/>apply plugin: 'java'<br/>apply plugin: 'org.springframework.boot'<br/><br/>sourceCompatibility = 1.8<br/><br/>repositories {<br/>    mavenCentral()<br/>}<br/><br/>dependencies {<br/>    compile group: 'org.springframework.boot', name: 'spring-boot-starter-web', version: '2.0.0.RELEASE'</pre>
<pre style="color: black;padding-left: 60px">    compile group: 'org.springframework.boot', name: 'spring-boot-starter-data-jpa', version: '2.0.0.RELEASE'<br/>    compile group: 'mysql', name: 'mysql-connector-java', version: '6.0.6'<br/>    testCompile group: 'junit', name: 'junit', version: '4.12'<br/>}</pre>
<ol start="2">
<li>Create the <kbd>Main</kbd> class. As usual, this is the main entry point to our application and is pretty simple:</li>
</ol>
<pre style="color: black;padding-left: 60px">package com.packtpub.microservices.ch05.userservice;<br/><br/>import org.springframework.boot.SpringApplication;<br/>import org.springframework.boot.autoconfigure.SpringBootApplication;<br/><br/>@SpringBootApplication<br/>public class Main {<br/>    public static void main(String[] args) {<br/>        SpringApplication.run(Main.class, args);<br/>    }<br/>}</pre>
<ol start="3">
<li>Create a <kbd>User</kbd> class in the <kbd>com.packtpub.microservices.ch05.userservice.models</kbd> package. This will serve as our entity representation and contains the fields that will be stored in the database and eventually in our Redis cache:</li>
</ol>
<pre style="color: black;padding-left: 60px">package com.packtpub.microservices.ch05.userservice.models;<br/><br/>import com.fasterxml.jackson.annotation.JsonProperty;<br/>import org.hibernate.annotations.GenericGenerator;<br/><br/>import javax.persistence.Column;<br/>import javax.persistence.Entity;<br/>import javax.persistence.GeneratedValue;<br/>import javax.persistence.Id;<br/><br/>@Entity<br/>public class User {<br/><br/>    @Id<br/>    @GeneratedValue(generator = "uuid")<br/>    @GenericGenerator(name = "uuid", strategy = "uuid2")<br/>    private String id;<br/><br/>    private String username;<br/><br/>    @JsonProperty("full_name")<br/>    private String fullName;<br/><br/>    private String email;<br/><br/>    public User() {}<br/><br/>    public String getId() {<br/>        return id;<br/>    }<br/><br/>    public void setId(String id) {<br/>        this.id = id;<br/>    }<br/><br/>    public String getUsername() {<br/>        return username;<br/>    }<br/><br/>    public void setUsername(String username) {<br/>        this.username = username;<br/>    }<br/><br/>    public String getFullName() {<br/>        return fullName;<br/>    }<br/><br/>    public void setFullName(String fullName) {<br/>        this.fullName = fullName;<br/>    }<br/><br/>    public String getEmail() {<br/>        return email;<br/>    }<br/><br/>    public void setEmail(String email) {<br/>        this.email = email;<br/>    }<br/>}</pre>
<ol start="4">
<li>To wire up our <kbd>User</kbd> entity to our MySQL database, create a <kbd>UserRepository</kbd> interface that extends the <kbd>CrudRepository</kbd> interface defined by the <kbd>springframework</kbd> data package, as shown here:</li>
</ol>
<pre style="color: black;padding-left: 60px">package com.packtpub.microservices.ch05.userservice.db;<br/><br/>import com.packtpub.microservices.ch05.userservice.models.User;<br/>import org.springframework.data.repository.CrudRepository;<br/><br/>public interface UserRepository extends CrudRepository&lt;User, String&gt; {}</pre>
<ol start="5">
<li>Create the <kbd>UserController</kbd> class. This is <kbd>RestController</kbd>, which maps certain endpoints to the functionality discussed previously, namely creating and retrieving user records. Everything here should look familiar. Of note is that the <kbd>findById</kbd> method returns <kbd>Optional&lt;T&gt;</kbd>, so we use <kbd>map</kbd> and <kbd>orElseGet</kbd> to return either a <kbd>200 OK HTTP</kbd> response with the user in the response body or a <kbd>404</kbd> status, as shown in the following code:</li>
</ol>
<pre style="color: black;padding-left: 60px">package com.packtpub.microservices.ch05.userservice.controllers;<br/><br/>import com.packtpub.microservices.ch05.userservice.db.UserRepository;<br/>import com.packtpub.microservices.ch05.userservice.models.User;<br/>import org.springframework.beans.factory.annotation.Autowired;<br/>import org.springframework.http.HttpStatus;<br/>import org.springframework.http.ResponseEntity;<br/>import org.springframework.web.bind.annotation.*;<br/><br/>import java.util.Optional;<br/><br/>@RestController<br/>public class UserController {<br/><br/>    @Autowired<br/>    private UserRepository userRepository;<br/><br/>    @RequestMapping(path = "/users", method = RequestMethod.POST, produces = "application/json")<br/>    public User create(@RequestBody User user) {<br/>        User savedUser = userRepository.save(user);<br/>        return savedUser;<br/>    }<br/><br/>    @RequestMapping(path = "/users/{id}", method = RequestMethod.GET, produces = "application/json")<br/>    public ResponseEntity&lt;User&gt; getById(@PathVariable("id") String id) {<br/>        Optional&lt;User&gt; user = userRepository.findById(id);<br/><br/>        return user.map(u -&gt; new ResponseEntity&lt;&gt;(u, HttpStatus.OK)).orElseGet(<br/>                () -&gt; new ResponseEntity&lt;&gt;(HttpStatus.NOT_FOUND));<br/>    }<br/>}</pre>
<ol start="6">
<li>Add the following <kbd>application.properties</kbd> file to the <kbd>src/main/resources</kbd> directory. It contains the necessary configuration to connect to a local MySQL instance. It's assumed that you have installed MySQL and have it running locally. You should have also created a database called <kbd>users</kbd>, a user with the username <kbd>userservice</kbd>, and a password: <kbd>password</kbd>. Note that we're setting <kbd>ddl-auto</kbd> to <kbd>create</kbd>, which is a good practice for development, but should not be used for production:</li>
</ol>
<pre style="color: black;padding-left: 60px">spring.jpa.hibernate.ddl-auto=create<br/>spring.datasource.url=jdbc:mysql://localhost:3306/users?serverTimezone=UTC&amp;&amp;&amp;useSSL=false<br/>spring.datasource.username=userservice<br/>spring.datasource.password=password</pre>
<ol start="7">
<li>Let's add some caching! The first thing we'll do is open the <kbd>application.properties</kbd> file again and add some configuration for a <kbd>redis</kbd> instance running locally on port <kbd>6379</kbd> (the default), as shown here:</li>
</ol>
<pre style="color: black;padding-left: 60px">spring.jpa.hibernate.ddl-auto=create<br/>spring.datasource.url=jdbc:mysql://localhost:3306/users?serverTimezone=UTC&amp;&amp;&amp;useSSL=false<br/>spring.datasource.username=userservice<br/>spring.datasource.password=password<br/><strong>spring.cache.type=redis<br/>spring.redis.host=localhost<br/>spring.redis.port=6379</strong></pre>
<ol start="8">
<li>With our application configured to use MySQL as a primary datasource and Redis as a cache, we can now override methods in the <kbd>CrudRepository&lt;T, ID&gt;</kbd> interface and add annotations instructing it to cache. We want to write to our cache every time we call the <kbd>save</kbd> method with a <kbd>User</kbd> object, and read from the cache every time we call <kbd>findById</kbd> with a valid user ID string:</li>
</ol>
<pre style="color: black;padding-left: 60px">package com.packtpub.microservices.ch05.userservice.db;<br/><br/>import com.packtpub.microservices.ch05.userservice.models.User;<br/>import org.springframework.cache.annotation.CachePut;<br/>import org.springframework.cache.annotation.Cacheable;<br/>import org.springframework.data.repository.CrudRepository;<br/>import org.springframework.stereotype.Repository;<br/><br/>import java.util.Optional;<br/><br/>@Repository<br/>public interface UserRepository extends CrudRepository&lt;User, String&gt; {<br/>    <strong>@Override<br/>    @Cacheable(value = "users", key = "#id")</strong><br/><strong>    Optional&lt;User&gt; findById(String id);<br/><br/>    @Override<br/>    @CachePut(value = "users", key = "#user.id")</strong><br/><strong>    User save(User user)</strong><strong>;</strong><br/>}</pre>
<ol start="9">
<li>That's it! You can test this by running the service, creating a user, verifying that the user is in both the MySQL database and Redis cache, and then deleting the user from the database. Requests to the <kbd>users/ID</kbd> endpoint will still return the user record. Before finishing this service, you'll want to make sure that the cache is invalidated if a user is ever deleted. Any other endpoints that mutate users should invalidate and/or rewrite the cache. This is left as an exercise for the reader!</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fronting your services with a CDN</h1>
                </header>
            
            <article>
                
<p>The <strong>Content Delivery Network</strong> (<strong>CDN</strong>) improves performance and availability by delivering content through a globally distributed network of proxy servers. When a user (usually through their mobile device) makes a request to your API through a CDN, they will create a network connection with one of many <strong>points of presence</strong> (<strong>PoPs</strong>), based on their geographic location. Instead of having to make roundtrips to the origin data center for every single request, content can be cached at the edge of a CDN, greatly reducing the response time for the user and reducing unnecessary, costly traffic to the origin. </p>
<p>CDNs are a requirement if you plan to have a global user base. If every request to your application's API has to perform a full roundtrip to a single origin, you'll create a subpar experience for users in parts of the world physically distant from the data center that you host your applications in. Even if you host your applications in multiple data centers, you'll never be able to create as high-performing an experience for as many users as you can using a CDN. </p>
<p>In addition to performance, CDNs can improve the availability of your application. As we discussed in the previous recipe, many entities in your system are read much more frequently than they are written. In these cases, you can configure your CDN to cache payloads from a service for a specific amount of time (commonly specified by a TTL or time-to-live). Caching responses from your service reduces the amount of traffic to your origin, making it harder to run out of capacity (compute, storage, or network). Additionally, if your service starts to experience high latency, or total or partial failure, the CDN can be configured to serve cached responses instead of continuing to send traffic to a failing service. This allows you to at least be able to serve content to users in the event of service downtime.</p>
<p>Some CDN providers have APIs that allow you to automatically invalidate a resource. In these cases, you can instrument your microservice to invalidate a resource just as you would using a Redis- or Memcached-based cache, as discussed in the previous recipe. </p>
<p>There are many different CDN providers out there. Some of the large ones include <strong>Akamai</strong> and <strong>Edgecast</strong>. Amazon Web Services provides a CDN offering, called CloudFront, that can be configured to serve requests to origin servers in AWS or static resources hosted in S3 buckets. One of the more developer-friendly offerings in the CDN market is from a company called <strong>Fastly</strong>. Fastly is built using <strong>Varnish</strong>, an<span> open source web-application accelerator</span><span>.</span></p>
<p><span>As a provider, Fastly allows you to upload your own</span> <strong>Varnish Configuration Language</strong> <span>(</span><strong>VCL</strong><span>) files, effectively allowing you to create caching rules based on any aspect of the request (incoming headers, path segments, query string parameters, and so on). Additionally, Fastly provide a</span> <strong>Fast Purge API</strong> <span>that allows you to invalidate resources based on a URI. </span></p>
<p>In this recipe, we'll go through the basic steps required to create an account with a CDN provider and start serving traffic through a CDN. We'll do this with a hypothetical service made accessible to the public internet with the hostname <kbd>api.pichat.me</kbd>. The service authenticates requests by inspecting the value of the Authorization header of the incoming request for a valid OAuth2 bearer token.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Create an account with Fastly, the CDN provider we'll be using in this example. As of this writing, the signup URL is <kbd>https://www.fastly.com/signup</kbd>. </li>
<li>Fastly will ask you to create a service. Enter a name for your service, along with the domain (<kbd>api.pichat.me</kbd>) and the hostname of the origin server the application is running on.</li>
<li>Using your DNS provider for the domain, create a CNAME for <kbd>api.pichat.me</kbd>, pointing your domain to Fastly's servers. Read the updated documentation to find out what hostnames to use. </li>
<li>Once that is set up and your service is created, requests to your hostname will now go through the Fastly CDN. Read the Fastly documentation (<a href="https://docs.fastly.com/guides/basic-setup/">https://docs.fastly.com/guides/basic-setup/</a>) to discover how to customize VCLs and other settings for your service.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Gracefully degrading the user experience</h1>
                </header>
            
            <article>
                
<p>We understand by now that a certain amount of failure is inevitable. In a sufficiently complex system, some amount of failure will occur some of the time. By using the techniques in this chapter, we can try and reduce the likelihood that one of these failures will impact customers. Regardless of how much we try to prevent it from happening, some kind of failure will probably impact the customer experience at some point in your applications lifespan. Users, however, can be surprisingly compassionate in the face of system outages, provided the user experience degrades gracefully. </p>
<p>Consider this scenario: you are using an application that allows you to browse a catalog of products and look for local stores that carry that product, along with important information such as its address, phone number, and store hours. Let's say the service that provides information about local stores becomes unavailable. This clearly impacts the user experience in a less-than-ideal way, but the application can handle the failure in more than one way. The worst way, which would probably result in the worst user experience, would be to allow the failure to cascade and take down the product catalog. A slightly better way would be to allow the user to continue searching for products, but when they go to find a local store that carries the product, they're informed via some kind of information box that the local store information is currently unavailable. This is frustrating, but at least they can still look at product information, such as price, models, and colors. It would be better still to recognize that the service was not operating and have some kind of informational banner informing the user that local store information is temporarily unavailable. With this information, we can inform the user of the situation, allowing them to decide whether they'd still like to go ahead and search for products. The experience is suboptimal, but we would avoid unnecessarily frustrating the user.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Verifying fault tolerance with Gameday exercises</h1>
                </header>
            
            <article>
                
<p>This chapter contains recipes that should help you create more reliable, resilient microservice architectures. Each recipe documents a pattern or technique for anticipating and dealing with some kind of failure scenario. Our aim when building resilient systems is to tolerate failure with as little impact to our users as possible. Anticipating and designing for failure is essential when building distributed systems, but without verifying that our systems handle failure in the ways we expect, we aren't doing much more than hoping, and hope is definitely not a strategy! </p>
<p>When building systems, unit and functional tests are necessary parts of our confidence-building toolkit. However, these tools alone are not enough. Unit and functional tests work by isolating dependencies, good unit tests, for instance, don't rely on network conditions, and functional tests don't involve testing under production-level traffic conditions, instead focusing on various software components working together properly under ideal conditions. To gain more confidence in the fault tolerance of a system, it's necessary to observe it responding to failure in production. </p>
<p>Gameday exercises are another useful tool for building confidence in the resiliency of a system. These exercises involve forcing certain failure scenarios in production to verify that our assumptions about fault tolerance match reality. John Allspaw describes this practice in detail in his paper, <em>Fault Injection in Production</em>. If we accept that failure is impossible to avoid completely, it becomes sensible to force failure and observe how our system responds to it as a planned exercise. It’s better to have a system fail for the first time while an entire team is watching and ready to take action, than at 3 a.m. when a system alert wakes up an on-call engineer.</p>
<p>Planning a Gameday exercise provides a large amount of value. Engineers should get together and brainstorm the various failure scenarios their service is likely to experience. Work should then be scheduled to try to reduce or eliminate the impact of those scenarios (that is, in the event of database failure, revert to a cache). Each Gameday exercise should have a planning document that describes the system being tested, the various failure scenarios, including steps that will be taken to simulate the failures, expectations surrounding how the system should respond to the failures, and the expected impact on users (if any). As the Gameday exercise proceeds, the team should work through each of the scenarios, documenting observations—it’s important to ensure that metrics we expect to see emitted are being emitted, alerts that we expect to fire do indeed fire, and the failure is handled in the way we expect. As observations are made, document any differences between expectations and reality. These observations should become planned work to bridge the gap between our ideal world and the real world.</p>
<p class="mce-root">Instead of walking through code, this recipe will demonstrate a process and template that can be used to run Gameday exercises. The following is not the only way to conduct Gameday exercises, but one that should serve as a good starting point for your organization.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Prerequisites</h1>
                </header>
            
            <article>
                
<p>As always, there are some prerequisites you should ensure you meet before attempting to run a Gameday exercise. Specifically, your teams should be used to instrumenting code with the necessary metrics and alerts to provide a good degree of observability into your production environment. Your teams should have experience working within a well-understood and practiced incident-response process that includes having regular retrospectives to continuously improve in light of production incidents.</p>
<p>Finally, your organization should be accustomed to talking openly about failure and unexpected production incidents, and be committed to processes that encourage continuous improvement. These prerequisites should suggest that your teams have the necessary organizational support and psychological safety to conduct these kinds of resiliency exercises.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>The first step in a Gameday exercise is selecting a system that will be tested. When you're just getting started with Gamedays, it's wise to select a system that is well understood, has failed before, and has a limited blast radius in terms of the impact on users. </li>
<li>Once the service is selected, gather the team responsible for its development and operation, and start brainstorming different failure scenarios. If there is a data store, consider what could happen if it were suddenly unavailable due to a hardware failure. Perhaps the database could be shut down manually. What happens if the database is terminated in an unsafe way? The service runs in some kind of clustered configuration, so what happens if one node is removed from the load balancer? What happens when all nodes fail and are removed from the load-balancing pool? Another area to test is unexpected latency. In a distributed system, sufficiently high latency is impossible to distinguish from lack of service availability, so there are a number of interesting bugs that can lurk here. Getting the team together to discuss all of these scenarios (as well as others) can be a great way to learn more about a system. Document all of the scenarios that you plan to test. </li>
<li>Schedule a time and a room for the Gameday experiment (if you're a remote team, arrange for everyone to be on a video call together). Invite the team responsible for the service being tested, a representative from your customer support team, and any other stakeholders who are interested in seeing the experiment. </li>
<li>Using a template, such as the one included here, plan out in detail how the experiment is going to be conducted. On the day at the scheduled time, start with an overview of the system being tested. This is a good opportunity to ensure that everyone has a consistent view of how the system works. Then go through each scenario, assigning the actual action to someone on the team. </li>
</ol>
<p> </p>
<ol start="5">
<li>Document observations during the experiment, detailing how the system reacted to the failure injection. </li>
<li>In the event that observations made during the experiment are different than expectations, schedule follow-up tasks, in the form of tickets, for the team to correct the discrepancy. </li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">A template for Gameday exercises</h1>
                </header>
            
            <article>
                
<p class="mce-root">The following template can be used for planning and executing a Gameday exercise.<br/>
<br/>
<strong>System: </strong>Message Service<br/>
<br/>
<strong><strong>System Overview: </strong></strong></p>
<p class="mce-root">A detailed description (possibly including diagrams) of the system under test. It’s a good idea to document how requests are routed to the system, some of the major systems that interact with it, data stores it uses and their general configuration, and any downstream services it depends on.</p>
<p class="mce-root"><strong>Dashboards:</strong></p>
<p class="mce-root">Links to important dashboards to watch while the Gameday exercise is underway.</p>
<p class="mce-root"><strong>Test Scenarios:</strong></p>
<p class="mce-root"><strong>Scenario:</strong> Database becomes unavailable due to nodes being terminated.</p>
<p class="mce-root"><strong>Method:</strong></p>
<p class="mce-root">Shut down database EC2 nodes manually using AWS CLI tools (include actual command).</p>
<p class="mce-root"><strong>Expectations:</strong></p>
<p class="mce-root">List how you expect the service to react. Include details about expected changes in metrics, alerts that should be fired, system behavior, and user impact.</p>
<p class="mce-root"><strong>Observations:</strong></p>
<p class="mce-root">Document observations during the actual test.</p>
<p class="mce-root"><strong>Follow-up Action Items:</strong></p>
<p class="mce-root">Create tickets for any follow-up work that should be done as a result of the experiment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introducing automated chaos</h1>
                </header>
            
            <article>
                
<p>Running manual Gameday exercises is a great way to introduce the practice of failure injection. Forcing failures in production helps build confidence in the resilience of systems and identifies opportunities for improvement. Gameday helps teams gain a better overall understanding of how their systems behave when confronted with a number of failure scenarios. As a team conducts more exercises, it will start to accumulate tools for performing common tasks, such as introducing latency in the network or spiking CPU usage. Tooling helps automate mundane tasks, improving the efficiency of Gameday exercises. There are a variety of open source and commercial tools designed to automate chaos engineering that teams can take advantage of right away. </p>
<p>Gameday exercises are planned and scheduled. Some organizations go one step further and introduce continuous failure injection as a way of ensuring that systems are handling common failure scenarios smoothly. In early 2011, Netflix announced the creation of the Simian Army—a suite of tools designed to inject common failures into a production environment. Arguably the most famous member of the Simian Army, Chaos Monkey, randomly shuts down nodes in a production environment. The Simian Army tools have been open sourced and are available to use in your own organization. They can be scheduled to run as part of a Gameday exercise, or set up to run on specific schedules (that is, Monday to Friday, 9 a.m. to 5 p.m., when on-call engineers are usually in the office).</p>
<p>Pioneers in this space, PagerDuty, have conducted "failure Fridays" since 2013. Every Friday, engineers get together to attack a specific service. Over time, engineers started building commands into their Chat Bot to perform common functions such as isolating a node from other network traffic, even adding a "roulette" command that would randomly select hosts for rebooting. </p>
<p>Hosted commercial services have been developed to help automate chaos engineering. Gremlin is a hosted product designed to help teams run Gameday exercises by providing access to a library of "attacks" executed through agents installed on nodes in your environment. Gremlin provides an API and a web interface that allows users to configure attacks designed to spike resource usage (CPU, memory, disk), simulate random failures by killing processes or rebooting hosts, and simulate common network conditions, such as latency and <strong>Network Time Protocol</strong> (<strong>NTP</strong>) drift. Having a product like Gremlin lowers the amount of upfront effort needed to start doing failure injection.</p>
<p>Another open source tool is the Chaos toolkit, a CLI tool designed to make it easier to design and run experiments. In this recipe, we'll install the Chaos toolkit and use it to execute a simple experiment against a hypothetical user service. The user service will be the same one we wrote in the <em>Improving performance with caching</em> recipe earlier in this chapter. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>The Chaos toolkit is written in Python and can be installed using <kbd>pip</kbd>. We'll need a working Python3 environment. This recipe will assume you are installing it on macOS X using Homebrew. First, install <kbd>pyen</kbd><span>—</span>a utility that supports managing multiple Python development environments, as shown here:</li>
</ol>
<pre style="color: black;padding-left: 60px"><strong>$ brew install pyenv</strong></pre>
<ol start="2">
<li>Install Python3 by executing the following command line:</li>
</ol>
<pre style="color: black;padding-left: 60px"><strong>$ pyenv install 3.4.2</strong><br/><strong>$ pyenv global 3.4.2</strong></pre>
<ol start="3">
<li>With a newly-installed Python3 environment, go ahead and install the Chaos toolkit by executing the following command line:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><span> </span><strong>$ pip install -U chaostoolkit</strong></pre>
<ol start="4">
<li>The Chaos toolkit uses the JSON files to describe experiments. Each experiment should have a title, description, and optionally some tags used to categorize experiments. The <kbd>steady-state-hypothesis</kbd> section describes how the service is expected to behave under normal conditions. In our situation, we assume that the service will return either <kbd>200</kbd> in the event that a user is found, or <kbd>404</kbd> in the event that a user has not been found:</li>
</ol>
<pre style="color: black;padding-left: 60px">{<br/>  "title": "Kill MySQL process",<br/>  "description": "The user service uses a MySQL database to store user information. This experiment will test how the service behaves when the database is unavailable.",<br/>  "tags": [<br/>    "database", "mysql"<br/>  ],<br/>  "steady-state-hypothesis": {<br/>    "title": "Service responds when MySQL is running",<br/>    "probes": [<br/>      {<br/>        "type": "probe",<br/>        "name": "service-is-running",<br/>        "tolerance": [200, 404],<br/>        "provider": {<br/>          "type": "http",<br/>          "url": "http://localhost:8080/users/12345"<br/>        }<br/>      }<br/>    ]<br/>  },<br/>  "method": [<br/>    {<br/>      "name": "kill-mysql-process",<br/>      "type": "action",<br/>      "provider": {<br/>        "type": "process",<br/>        "path": "/usr/local/bin/mysql.server",<br/>        "arguments": ["stop"],<br/>        "timeout": 10<br/>      }<br/>    }<br/>  ]<br/>}</pre>
<ol start="5">
<li>Run this experiment:</li>
</ol>
<pre style="color: black;padding-left: 60px"><strong>$ chaos run</strong></pre>
<ol start="6">
<li>If successful, the output should indicate that the service responds well when MySQL is unavailable. However, in its current state, the experiment will leave MySQL stopped, which isn't ideal. Now you have something to fix, which is left as an exercise to the reader, and you can rerun your experiment. Congratulations! You just ran your first automated chaos experiment.</li>
</ol>


            </article>

            
        </section>
    </body></html>