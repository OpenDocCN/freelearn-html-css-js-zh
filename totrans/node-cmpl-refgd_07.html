<html><head></head><body><div><h1 class="header-title">Data Storage and Retrieval</h1>
                
            
            
                
<p>In the previous two chapters, we built a small and somewhat useful application for storing notes, and then made it work on mobile devices. While the application works reasonably well, it doesn't store those notes anywhere on a long-term basis, meaning the notes are lost when you stop the server and, if you run multiple instances of Notes, each instance has its own set of notes. The typical next step is to introduce a database tier. </p>
<p>In this chapter, we will look at database support in Node.js, so the user sees the same set of notes for any Notes instance accessed, and to reliably store notes for long-term retrieval.</p>
<p>We'll start with the <em>Notes</em> application code used in the previous chapter. We started with a simple, in-memory data model using an array to store the notes, and then made it mobile friendly. In this chapter, we will:</p>
<ul>
<li>Discover logging operational and debugging information</li>
<li>Begin using the ES6 module format</li>
<li>Implement data persistence for Notes objects using several database engines</li>
</ul>
<p>Let's get started!</p>
<p class="mce-root"/>
<p>The first step is to duplicate the code from the previous chapter. For instance, if you were working in <kbd>chap06/notes</kbd>, duplicate that to be <kbd>chap07/notes</kbd>.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Data storage and asynchronous code</h1>
                
            
            
                
<p>By definition, external data storage systems require asynchronous code in the Node.js architecture. The access time to retrieve data from disk, from another process, or from a database, always takes sufficient time to require deferred execution. </p>
<p>The existing <kbd>Notes</kbd> data model is an in-memory data store. In theory, in-memory data access does not require asynchronous code and therefore, the existing model module could have used regular functions rather than <kbd>async</kbd> functions.</p>
<p>We knew that Notes must move to using databases, and would require an asynchronous API to access Notes data. For that reason, the existing Notes model API uses <kbd>async</kbd> functions so that in this chapter, we can persist Note data to databases.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Logging</h1>
                
            
            
                
<p>Before we get into databases, we have to address one of the attributes of a high-quality software system: managing logged information, including normal system activity, system errors, and debugging information. Logs give us an insight into the behavior of the system. How much traffic is it getting? If it's a website, which pages are people hitting the most? How many errors occur and of what kind? Do attacks occur? Are malformed requests being sent?</p>
<p>Log management is also an issue. Log rotation means regularly moving the log file out of the way, to start with a fresh log file. You should process logged data to produce reports. A high priority on screening for security vulnerabilities is a must.</p>
<p>The Twelve Factor application model suggests simply sending logging information to the console, and then some other software system captures that output and directs it to a logging service. Following their advice can reduce system complexity by having fewer things that can break. In a later chapter, we'll use PM2 for that purpose.</p>
<p>Let's first complete a tour of information logging as it stands right now in Notes.</p>
<p>When we used the Express Generator to initially create the <em>Notes</em> application, it configured an activity logging system using <kbd>morgan</kbd>:</p>
<pre>const logger = require('morgan'); 
.. 
app.use(logger('dev')); </pre>
<p>This is what prints the requests on the Terminal window. Visit <a href="https://github.com/expressjs/morgan">https://github.com/expressjs/morgan</a> for more information.</p>
<p>Internally, Express uses the <strong>Debug</strong> package for debugging traces. You can turn these on using the <kbd>DEBUG</kbd> environment variable. We should try to use this package in our application code. For more information, visit <a href="https://www.npmjs.com/package/debug">https://www.npmjs.com/package/debug</a>.</p>
<p>Finally, the application might generate uncaught exceptions. The <kbd>uncaughtException</kbd> error needs to be captured, logged, and dealt with appropriately.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Request logging with Morgan</h1>
                
            
            
                
<p>The Morgan package has two general areas for configuration:</p>
<ul>
<li>Log format</li>
<li>Log location</li>
</ul>
<p>As it stands, Notes uses the <kbd>dev</kbd> format, which is described as a concise status output meant for developers. This can be used to log web requests as a way to measure website activity and popularity. The Apache log format already has a large ecosystem of reporting tools and, sure enough, Morgan can produce log files in this format. </p>
<p>To change the format, simply change this line in <kbd>app.js</kbd>:</p>
<pre>app.use(logger(process.env.REQUEST_LOG_FORMAT || 'dev')); </pre>
<p>Then run <em>Notes</em> as follows:</p>
<pre><strong>$ REQUEST_LOG_FORMAT=common npm start
    
&gt; notes@0.0.0 start /Users/david/chap07/notes
&gt; node ./bin/www
::1 - - [12/Feb/2016:05:51:21 +0000] "GET / HTTP/1.1" 304 -
::1 - - [12/Feb/2016:05:51:21 +0000] "GET /vendor/bootstrap/css/bootstrap.min.css HTTP/1.1" 304 -
::1 - - [12/Feb/2016:05:51:21 +0000] "GET /stylesheets/style.css HTTP/1.1" 304 -
::1 - - [12/Feb/2016:05:51:21 +0000] "GET /vendor/bootstrap/js/bootstrap.min.js HTTP/1.1" 304 - </strong> </pre>
<p>To revert to the previous logging output, simply do not set this environment variable. If you've looked at Apache access logs, this logging format will look familiar. The <kbd>::1</kbd> notation at the beginning of the line is IPV6 notation for the <kbd>localhost</kbd>, which you may be more familiar with as <kbd>127.0.0.1</kbd>.</p>
<p>We can declare victory on request logging and move on to debugging messages. However, let's look at logging this to a file directly. While it's possible to capture <kbd>stdout</kbd> through a separate process, Morgan is already installed in Notes and it does provide the capability to direct its output to a file.</p>
<p>The Morgan documentation suggests this:</p>
<pre>// create a write stream (in append mode) 
var accessLogStream = fs.createWriteStream(__dirname + '/access.log', {flags: 'a'}) 
 
// setup the logger 
app.use(morgan('combined', {stream: accessLogStream})); </pre>
<p>But this has a problem; it's impossible to perform log rotation without killing and restarting the server. Instead, we'll use their <kbd>rotating-file-stream</kbd> package.</p>
<p>First, install the package:</p>
<pre><strong>$ npm install rotating-file-stream --save </strong> </pre>
<p>Then we add this code to <kbd>app.js</kbd>:</p>
<pre>const fs = require('fs-extra');<br/>...<br/>const rfs = require('rotating-file-stream');<br/>var logStream;<br/>// Log to a file if requested<br/>if (process.env.REQUEST_LOG_FILE) {<br/>  (async () =&gt; {<br/>    let logDirectory = path.dirname(process.env.REQUEST_LOG_FILE); <br/>    await fs.ensureDir(logDirectory);<br/>    logStream = rfs(process.env.REQUEST_LOG_FILE, {<br/>        size: '10M',     // rotate every 10 MegaBytes written<br/>        interval: '1d',  // rotate daily<br/>        compress: 'gzip' // compress rotated files<br/>    });<br/>  })().catch(err =&gt; { console.error(err); });<br/>}
.. 
app.use(logger(process.env.REQUEST_LOG_FORMAT || 'dev', { 
    stream: logStream ? logStream : process.stdout 
})); </pre>
<p>Here, we're using an environment variable, <kbd>REQUEST_LOG_FILE</kbd>, to control whether to send the log to <kbd>stdout</kbd> or to a file. The log can go into a directory, and the code will automatically create that directory if it doesn't exist. By using <kbd>rotating-file-stream</kbd> (<a href="https://www.npmjs.com/package/rotating-file-stream">https://www.npmjs.com/package/rotating-file-stream</a>), we're guaranteed to have log file rotation with no extra systems required.</p>
<p>The <kbd>fs-extra</kbd> module is being used because it adds Promise-based functions to the <kbd>fs</kbd> module (<a href="https://www.npmjs.com/package/fs-extra">https://www.npmjs.com/package/fs-extra</a>). In this case, <kbd>fs.ensureDir</kbd> checks if the named directory structure exists and, if not, the directory path is created. </p>


            

            
        
    </div>



  
<div><h1 class="header-title">Debugging messages</h1>
                
            
            
                
<p>You can generate quite a detailed trace of what Express does by running <em>Notes</em> this way:</p>
<pre><strong>$ DEBUG=express:* npm start </strong> </pre>
<p>This is pretty useful if you want to debug Express. But, we can use this in our own code as well. It is similar to inserting <kbd>console.log</kbd> statements, but without having to remember to comment out the debugging code.</p>
<p>It is very simple to enable debugging in a module:</p>
<pre>const debug = require('debug')('module-name'); 
.. 
debug('some message'); 
.. 
debug(`got file ${fileName}`); </pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Capturing stdout and stderr</h1>
                
            
            
                
<p>Important messages can be printed to <kbd>process.stdout</kbd> or <kbd>process.stderr</kbd>, which can be lost if you don't capture that output. The Twelve Factor model suggests using a system facility to capture these output streams. With Notes, we'll use PM2 for that purpose, which we'll cover in <a href="7542f45a-6bd9-432e-875a-c110c0d84c61.xhtml">Chapter 10</a>, <em>Deploying Node.js Applications</em>.</p>
<p>The <kbd>logbook</kbd> module (<a href="https://github.com/jpillora/node-logbook">https://github.com/jpillora/node-logbook</a>) offers some useful capabilities in term of not only capturing <kbd>process.stdout</kbd> and <kbd>process.stderr</kbd>, but sending that output to useful places.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Uncaught exceptions</h1>
                
            
            
                
<p>Uncaught exceptions is another area where important information can be lost. This is easy to fix in the <em>Notes</em> application:</p>
<pre>const error = require('debug')('notes:error'); 
 
process.on('uncaughtException', function(err) { 
  error("I've crashed!!! - "+ (err.stack || err)); 
}); 
.. 
if (app.get('env') === 'development') { 
  app.use(function(err, req, res, next) { 
    // util.log(err.message); 
    res.status(err.status || 500); 
    error((err.status || 500) +' '+ error.message); 
    res.render('error', { 
      message: err.message, 
      error: err 
    }); 
  }); 
} 
.. 
app.use(function(err, req, res, next) { 
  // util.log(err.message); 
  res.status(err.status || 500); 
  error((err.status || 500) +' '+ error.message); 
  res.render('error', { 
    message: err.message, 
    error: {} 
  }); 
}); </pre>
<p>The <kbd>debug</kbd> package has a convention we're following. For an application with several modules, all debugger objects should use the naming pattern <kbd>app-name:module-name</kbd>. In this case, we used <kbd>notes:error</kbd> that will be used for all error messages. We could also use <kbd>notes:memory-model</kbd> or <kbd>notes:mysql-model</kbd> for debugging different models.</p>
<p>While we were setting up the handler for uncaught exceptions, it is also a good idea to add error logging into the error handlers.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Unhandled Promise rejections</h1>
                
            
            
                
<p>Using Promise and <kbd>async</kbd> functions automatically channels errors in a useful direction.  Errors will cause a Promise to flip into a <em>rejected</em> state, which must eventually be handled in a <kbd>.catch</kbd> method.  Since we're all human, we're bound to forget to ensure that all code paths handle their rejected Promise's.</p>
<p>Currently, Node.js prints the following warning if it detects an unhandled Promise rejection:</p>
<pre>(node:4796) UnhandledPromiseRejectionWarning: Unhandled promise rejection </pre>
<p>The warning goes on to say that the default handler for unhandled Promise rejection has been deprecated and that such Promise rejections will crash the Node process rather than print this message. The built-in <kbd>process</kbd> module does emit an event in this case, so it's easy enough to add a handler:</p>
<pre>import util from 'util';<br/>...<br/>process.on('unhandledRejection', (reason, p) =&gt; {<br/>  error(`Unhandled Rejection at: ${util.inspect(p)} reason: ${reason}`);<br/>});</pre>
<p>At the minimum, we can print an error message such as the following:</p>
<pre>notes:error Unhandled Rejection at: Promise {<br/>  notes:error &lt;rejected&gt; TypeError: model(...).keylist is not a function<br/>  ... full stack trace<br/>} reason: TypeError: model(...).keylist is not a function +3s</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Using the ES6 module format</h1>
                
            
            
                
<p>We wrote the <em>Notes</em> application using CommonJS modules, the traditional Node.js module format. While the application could continue using that format, the JavaScript community has chosen to switch to ES6 modules in both browser and Node.js code, and therefore it's important to switch ES6 modules so we can all get on board with a common module format. Let's rewrite the application using ES6 modules, and then write ES6 modules for anything new we add.</p>
<p class="mce-root"/>
<p>The changes required are large to replace <kbd>require</kbd> statements with <kbd>import</kbd> statements, and renaming files from <kbd>foo.js</kbd> to <kbd>foo.mjs</kbd>. Let's get started.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Rewriting app.js as an ES6 module</h1>
                
            
            
                
<p>Let's start with <kbd>app.js</kbd>, changing its name to <kbd>app.mjs</kbd>:</p>
<pre><strong>$ mv app.js app.mjs</strong></pre>
<p>Change the block of <kbd>require</kbd> statements at the top to the following:</p>
<div><pre>import fs from 'fs-extra';<br/>import url from 'url';<br/>import express from 'express';<br/>import hbs from 'hbs';<br/>import path from 'path';<br/>import util from 'util';<br/>import favicon from 'serve-favicon';<br/>import logger from 'morgan';<br/>import cookieParser from 'cookie-parser';<br/>import bodyParser from 'body-parser';<br/>import DBG from 'debug';<br/>const debug = DBG('notes:debug'); <br/>const error = DBG('notes:error'); <br/>import { router as index } from './routes/index';<br/>// const users = require('./routes/users');<br/>import { router as notes } from './routes/notes'; <br/><br/>// Workaround for lack of __dirname in ES6 modules<br/>const __dirname = path.dirname(new URL(import.meta.url).pathname);<br/><br/>const app = express();<br/><br/>import rfs from 'rotating-file-stream';</pre></div>
<p>Then, at the bottom of the script, make this change:</p>
<div><pre>export default app;</pre></div>
<p>Let's talk a little about the workaround mentioned here. There were several global variables automatically injected by Node.js into CommonJS modules. Those variables are not supported by ES6 modules. The critical variable for <em>Notes</em> is <kbd>__dirname</kbd>, which is used in <kbd>app.mjs</kbd> in several places. The code change shown here includes a workaround based on a brand new JavaScript feature that is available starting in Node.js 10.x, the <kbd>import.meta.url</kbd> variable.</p>
<p>The <kbd>import.meta</kbd> object is meant to inject useful information into an ES6 module. As the name implies, the <kbd>import.meta.url</kbd> variable contains the URL describing where the module was loaded from.  For Node.js, at this time, ES6 modules can only be loaded from a <kbd>file://</kbd> URL on the local filesystem. That means, if we extract the <kbd>pathname</kbd> of that URL, we can easily calculate the directory containing the module, as shown here.</p>
<p>Why this solution? Why not use a pathname beginning with <kbd>./</kbd>?  The answer is that a <kbd>./</kbd> filename is evaluated relative to the process's current working directory. That directory is usually different from the directory containing the Node.js module being executed.  Therefore it is more than convenient that the Node.js team has added the <kbd>import.meta.url</kbd> feature.</p>
<p>The pattern followed in most cases is this change:</p>
<pre>const moduleName = require('moduleName');  // in CommonJS modules<br/>import moduleName from 'moduleName';       // in ES6 modules</pre>
<p>Remember that Node.js uses the same module lookup algorithm in both ES6 and CommonJS modules. A Node.js <kbd>require</kbd> statement is synchronous, meaning that by the time <kbd>require</kbd> finishes, it has executed the module and is returning its <kbd>module.exports</kbd>. By contrast, an ES6 module is asynchronous, meaning the module may not have finished loading, and you can import just the required bits of the module.</p>
<p>Most of the module imports shown here are for regular Node.js modules installed in the <kbd>node_modules</kbd> directory, most of which are CommonJS modules. The rule for using <kbd>import</kbd> with a CommonJS module is that the <kbd>module.exports</kbd> object is treated as if it were the default export. The <kbd>import</kbd> statement shown earlier name the default export (or the <kbd>module.exports</kbd> object) as shown in the <kbd>import</kbd> statement. For a CommonJS module imported this way, you then use it as you would in a CommonJS context, <kbd>moduleName.functionName()</kbd>.</p>
<p class="mce-root"/>
<p>The usage of the <kbd>debug</kbd> module is effectively the same, but is coded differently. In the CommonJS context, we're told to use that module as follows:</p>
<div><pre>const debug = require('debug')('notes:debug'); <br/>const error = require('debug')('notes:error'); </pre></div>
<p>In other words, the <kbd>module.exports</kbd> of this module is a function, which we immediately invoke. There isn't a syntax for ES6 modules to use the <kbd>debug</kbd> module in that fashion. Therefore, we had to break it apart as shown, and explicitly call that function.</p>
<p>The final point of discussion is the <kbd>import</kbd> of the two router modules. It was first attempted to have those modules export the <kbd>router</kbd> as the default value, but Express threw an error in that case. Instead, we'll rewrite these modules to export <kbd>router</kbd> as a named export and then use that named export as shown here.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Rewriting bin/www as an ES6 module</h1>
                
            
            
                
<p>Remember that <kbd>bin/www</kbd> is a script used to launch the application. It is written as a CommonJS script, but because <kbd>app.mjs</kbd> is now an ES6 module, <kbd>bin/www</kbd> also must be rewritten as an ES6 module. A CommonJS module cannot, at the time of writing, import an ES6 module.</p>
<p>Change the filename:</p>
<pre><strong>$ mv bin/www bin/www.mjs</strong></pre>
<p>Then, at the top, change the <kbd>require</kbd> statements to <kbd>import</kbd> statements:</p>
<div><pre>import app from '../app.mjs';<br/>import DBG from 'debug';<br/>const debug = DBG('notes:server-debug'); <br/>const error = DBG('notes:server-error'); <br/>import http from 'http';</pre></div>
<p>We've already discussed everything here except that <kbd>app.mjs</kbd> exports its <kbd>app</kbd> object as the default export. Therefore, we use it as shown here.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Rewriting models code as ES6 modules</h1>
                
            
            
                
<p>The models directory contains two modules: <kbd>Note.js</kbd> defines the <kbd>Note</kbd> class, and <kbd>notes-memory.js</kbd> contains an in-memory data model. Both are easy to convert to ES6 modules.</p>
<p>Change the filenames:</p>
<pre><strong>$ cd models</strong><br/><strong>$ mv Note.js Note.mjs</strong><br/><strong>$ mv notes-memory.js notes-memory.mjs</strong></pre>
<p>In <kbd>Note.mjs</kbd>, simply make the following change:</p>
<div><pre>export default class Note {<br/>  ...<br/>}</pre></div>
<p>This makes the <kbd>Note</kbd> class the default export. </p>
<p>Then, in <kbd>notes-memory.mjs</kbd>, make the following change:</p>
<div><pre>import Note from './Note';<br/><br/>var notes = [];<br/><br/>async function crupdate(key, title, body) {<br/>  notes[key] = new Note(key, title, body);<br/>  return notes[key];<br/>}<br/><br/>export function create(key, title, body) { return crupdate(key, title, body); }<br/>export function update(key, title, body) { return crupdate(key, title, body); }<br/><br/>export async function read(key) {<br/>  if (notes[key]) return notes[key];<br/>  else throw new Error(`Note ${key} does not exist`);<br/>}<br/><br/>export async function destroy(key) {<br/>  if (notes[key]) {<br/>    delete notes[key];<br/>  } else throw new Error(`Note ${key} does not exist`);<br/>}<br/><br/>export async function keylist() { return Object.keys(notes); }<br/>export async function count() { return notes.length; }<br/>export async function close() { }<br/></pre></div>
<p>This is a straightforward transliteration of assigning functions to <kbd>module.exports</kbd> to using named exports.</p>
<p>By defining the <kbd>Note</kbd> class as the default export of the <kbd>Note.mjs</kbd> module, it <kbd>import</kbd>s nicely  into any module using that class.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Rewriting router modules as ES6 modules</h1>
                
            
            
                
<p>The <kbd>routes</kbd> directory contains two router modules. As it stands, each router module creates a <kbd>router</kbd> object, adds route functions to that object, and then assigns it to the <kbd>module.exports</kbd> field. That suggests we should export the <kbd>router</kbd> as the default export, but as we said earlier, that didn't work out right. Instead, we'll export <kbd>router</kbd> as a named export.</p>
<p>Change the filenames:</p>
<pre><strong>$ cd routes</strong><br/><strong>$ mv index.js index.mjs</strong><br/><strong>$ mv notes.js notes.mjs</strong></pre>
<p>Then, at the top of each, change the <kbd>require</kbd> statement block to the following:</p>
<div><pre>import util from 'util';<br/>import express from 'express';<br/>import * as notes from '../models/notes-memory';<br/><br/>export const router = express.Router();</pre></div>
<p>It will be the same in both files. Then, at the bottom of each file, delete the line assigning <kbd>router</kbd> to <kbd>module.exports</kbd>.</p>
<p>Let's turn to <kbd>app.mjs</kbd> and change how the router modules are imported.</p>
<p>Because <kbd>router</kbd> is a named export, by default you'd import the <kbd>router</kbd> object, in <kbd>app.mjs</kbd>, as follows:</p>
<pre>import { router } from './routes/index';</pre>
<p>But then we'd have a conflict since both modules define a <kbd>router</kbd> object. Instead, we changed the name of this object using an <kbd>as</kbd> clause:</p>
<div><pre>import { router as index } from './routes/index';<br/>import { router as notes } from './routes/notes'; </pre></div>
<p>The <kbd>router</kbd> object from each module is hence given a suitable name.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Storing notes in the filesystem</h1>
                
            
            
                
<p>The filesystem is an often overlooked database engine. While filesystems don't have the sort of query features supported by database engines, they are a reliable place to store files. The notes schema is simple enough that the filesystem can easily serve as its data storage layer.</p>
<p>Let's start by adding a function to <kbd>Note.mjs</kbd>:</p>
<pre>export default class Note {<br/>   ...<br/>   get JSON() { <br/>      return JSON.stringify({ 
        key: this.key, title: this.title, body: this.body 
      }); 
   }<br/><br/>   static fromJSON(json) { 
       var data = JSON.parse(json); 
       var note = new Note(data.key, data.title, data.body); 
       return note; 
   } <br/>}</pre>
<p><kbd>JSON</kbd> is a getter, which means it gets the value of the object. In this case, the <kbd>note.JSON</kbd> attribute/getter, no parentheses, will simply give us the JSON representation of the Note. We'll use this later for writing to JSON files.</p>
<p><kbd>fromJSON</kbd> is a static function, or factory method, to aid in constructing <kbd>Note</kbd> objects if we have a JSON string. The difference is that <kbd>JSON</kbd> is associated with an instance of the <kbd>Note</kbd> class, while <kbd>fromJSON</kbd> is associated with the class itself. The two can be used as follows:</p>
<pre>const note = new Note("key", "title", "body"); 
const json = note.JSON;    // produces JSON text<br/>const newnote = Note.fromJSON(json); // produces new Note instance</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>Now, let's create a new module, <kbd>models/notes-fs.mjs</kbd>, to hold the filesystem model:</p>
<pre>import fs from 'fs-extra';<br/>import path from 'path';<br/>import util from 'util';<br/>import Note from './Note';<br/>import DBG from 'debug';<br/>const debug = DBG('notes:notes-fs');<br/>const error = DBG('notes:error-fs');<br/><br/>async function notesDir() { <br/>    const dir = process.env.NOTES_FS_DIR || "notes-fs-data"; <br/>    await fs.ensureDir(dir);<br/>    return dir;<br/>} <br/><br/>function filePath(notesdir, key) { return path.join(notesdir, `${key}.json`); } <br/><br/>async function readJSON(notesdir, key) { <br/>    const readFrom = filePath(notesdir, key); <br/>    var data = await fs.readFile(readFrom, 'utf8');<br/>    return Note.fromJSON(data);<br/>}</pre>
<p>The <kbd>notesDir</kbd> function will be used throughout <kbd>notes-fs</kbd> to ensure that the directory exists. To make this simple, we're using the <kbd>fs-extra</kbd> module because it adds Promise-based functions to the <kbd>fs</kbd> module (<a href="https://www.npmjs.com/package/fs-extra">https://www.npmjs.com/package/fs-extra</a>). In this case, <kbd>fs.ensureDir</kbd> verifies whether the named directory structure exists, and, if not, the directory path is created. </p>
<p>The environment variable, <kbd>NOTES_FS_DIR</kbd>, configures a directory within which to store notes. We'll have one file per note and store the note as JSON. If no environment variable is specified, we'll fall back on using <kbd>notes-fs-data</kbd> as the directory name.</p>
<p>Because we're adding another dependency:</p>
<pre><strong>$ npm install fs-extra --save</strong> </pre>
<p>The filename for each data file is the <kbd>key</kbd> with <kbd>.json</kbd> appended. That gives one limitation that filenames cannot contain the <kbd>/</kbd> character, so we test for that using the following code:</p>
<pre>async function crupdate(key, title, body) { <br/>    var notesdir = await notesDir();<br/>    if (key.indexOf('/') &gt;= 0) <br/>        throw new Error(`key ${key} cannot contain '/'`); <br/>    var note = new Note(key, title, body); <br/>    const writeTo = filePath(notesdir, key); <br/>    const writeJSON = note.JSON; <br/>    await fs.writeFile(writeTo, writeJSON, 'utf8');<br/>    return note;<br/>}<br/><br/>export function create(key, title, body) { return crupdate(key, title, body); }<br/>export function update(key, title, body) { return crupdate(key, title, body); }</pre>
<p>As is the case with the <kbd>notes-memory</kbd> module, the <kbd>create</kbd> and <kbd>update</kbd> functions use the exact same code. The <kbd>notesDir</kbd> function is used to ensure that the directory exists, then we create a <kbd>Note</kbd> object, and then write the data to a file. </p>
<p>Notice how the code is very straightforward because of the <kbd>async</kbd> function. We aren't checking for errors because they'll be automatically caught by the <kbd>async</kbd> function and bubble out to our caller:</p>
<pre>export async function read(key) { <br/>    var notesdir = await notesDir();<br/>    var thenote = await readJSON(notesdir, key);<br/>    return thenote; <br/>}</pre>
<p>Using <kbd>readJSON</kbd>, read the file from the disk. It already generates the <kbd>Note</kbd> object, so all we have to do is return that object:</p>
<pre>export async function destroy(key) { <br/>    var notesdir = await notesDir();<br/>    await fs.unlink(filePath(notesdir, key)); <br/>}</pre>
<p>The <kbd>fs.unlink</kbd> function deletes our file. Because this module uses the filesystem, deleting the file is all that's necessary to delete the <kbd>note</kbd> object:</p>
<pre>export async function keylist() { <br/>    var notesdir = await notesDir();<br/>    var filez = await fs.readdir(notesdir);<br/>    if (!filez || typeof filez === 'undefined') filez = []; <br/>    var thenotes = filez.map(async fname =&gt; { <br/>        var key = path.basename(fname, '.json');<br/>        var thenote = await readJSON(notesdir, key);<br/>        return thenote.key; <br/>    }); <br/>    return Promise.all(thenotes); <br/>}</pre>
<p>The contract for <kbd>keylist</kbd> is to return a Promise that will resolve to an array of keys for existing note objects. Since they're stored as individual files in the <kbd>notesdir</kbd>, we have to read every file in that directory to retrieve its key.</p>
<p><kbd>Array.map</kbd> constructs a new array from an existing array, namely the array of filenames returned by <kbd>fs.readdir</kbd>. Each entry in the constructed array is the <kbd>async</kbd> function, which reads the Note, returning the <kbd>key</kbd>:</p>
<pre>export async function count() { <br/>    var notesdir = await notesDir();<br/>    var filez = await fs.readdir(notesdir); <br/>    return filez.length;<br/>}<br/><br/>export async function close() { }</pre>
<p>Counting the number of notes is simply a matter of counting the number of files in <kbd>notesdir</kbd>.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Dynamic import of ES6 modules</h1>
                
            
            
                
<p>Before we start modifying the router functions, we have to consider how to account for multiple models. We currently have two modules for our data model, <kbd>notes-memory</kbd> and <kbd>notes-fs</kbd>, and we'll be implementing several more by the end of this chapter. We will need a simple method to select between the model being used.</p>
<p>There are several possible ways to do this. For example, in a CommonJS module, it's possible to do the following:</p>
<pre>const path  = require('path'); 
const notes = require(process.env.NOTES_MODEL  
                  ? path.join('..', process.env.NOTES_MODEL)  
                  : '../models/notes-memory'); </pre>
<p>This lets us set an environment variable, <kbd>NOTES_MODEL</kbd>, to select the module to use for the data model.</p>
<p>This approach does not work with the regular <kbd>import</kbd> statement, because the module name in an <kbd>import</kbd> statement cannot be such an expression.  The Dynamic Import feature now in Node.js does offer a mechanism similar to the snippet just shown. </p>
<p>Dynamic import is an <kbd>import()</kbd> function that returns a Promise that will resolve to the imported module. As a function-returning-a-Promise, <kbd>import()</kbd> won't be useful as top-level code in the module. But, consider this:</p>
<pre>var NotesModule;<br/><br/>async function model() {<br/>  if (NotesModule) return NotesModule;<br/>  NotesModule = await import(`../models/notes-${process.env.NOTES_MODEL}`);<br/>  return NotesModule;<br/>}<br/><br/>export async function create(key, title, body) { <br/>    return (await model()).create(key, title, body); <br/>}<br/>export async function update(key, title, body) { <br/>    return (await model()).update(key, title, body); <br/>}<br/>export async function read(key) { return (await model()).read(key); }<br/>export async function destroy(key) { return (await model()).destroy(key); }<br/>export async function keylist() { return (await model()).keylist(); }<br/>export async function count() { return (await model()).count(); }<br/>export async function close() { return (await model()).close(); }</pre>
<p>Save that module in a file, <kbd>models/notes.mjs</kbd>. This module implements the same API as we'll use for all Notes model modules. The <kbd>model()</kbd> function is the key to dynamically selecting a notes model implementation based on an environment variable.</p>
<p>This is an <kbd>async</kbd> function and therefore its return value is a Promise. The value of that Promise is the selected module, as loaded by <kbd>import()</kbd>. Because <kbd>import()</kbd> returns a Promise, we use <kbd>await</kbd> to know whether it loaded correctly.</p>
<p>Every API method follows this pattern:</p>
<pre>export async function methodName(args) { <br/>    return (await model()).methodName(args); <br/>}</pre>
<p>Because <kbd>model()</kbd> returns a Promise, it's most succinct to use an <kbd>async</kbd> function and use <kbd>await</kbd> to resolve the Promise. Once the Promise is resolved, we simply call the <kbd>methodName</kbd> function and go about our business. Otherwise, those API method functions would be as follows:</p>
<pre>export function methodName(args) {<br/>    return model().then(notes =&gt; { return notes.<em>methodName</em>(args); });<br/>}</pre>
<p>The two implementations are equivalent, and it's clear which is the more succinct.</p>
<p>With all this <kbd>await</kbd>ing on Promise's returned from <kbd>async</kbd> functions, it's worth discussing the overhead. The worst case is on the first call to <kbd>model()</kbd>, because the selected notes model has not been loaded. The first time around, the call flow goes as follows:</p>
<ul>
<li>The API method calls <kbd>model()</kbd>, which calls <kbd>import()</kbd>, then <kbd>await</kbd>'s the module to finish loading</li>
<li>The API method <kbd>await</kbd>'s the Promise returned from <kbd>model()</kbd>, getting the module object, and it then calls the API function</li>
<li>The caller is also using <kbd>await</kbd> to receive the final result</li>
</ul>
<p>The first time around, the time is dominated by waiting on <kbd>import()</kbd> to finish loading the module. On subsequent calls, the module has already been loaded and the first step is to simply form a resolved Promise containing the module. The API method can then quickly get on with delegating to the actual API method.</p>
<p>To use this, in <kbd>routes/index.mjs</kbd>, and in <kbd>routes/notes.mjs</kbd>, we make this change:</p>
<pre>import util from 'util';<br/>import express from 'express';<br/>import * as notes from '../models/notes';<br/><br/>export const router = express.Router();</pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Running the Notes application with filesystem storage</h1>
                
            
            
                
<p>In <kbd>package.json</kbd>, add this to the <kbd>scripts</kbd> section:</p>
<pre>"start-fs": "DEBUG=notes:* NOTES_MODEL=fs node --experimental-modules ./bin/www.mjs", </pre>
<p>When you put these entries in <kbd>package.json</kbd>, make sure that you use correct JSON syntax. In particular, if you leave a comma at the end of the <kbd>scripts</kbd> section, it will fail to parse and npm will throw up an error message.</p>
<p>With this code in place, we can now run the <em>Notes</em> application as follows:</p>
<pre><strong>$ DEBUG=notes:* npm run start-fs
    
&gt; notes@0.0.0 start-fs /Users/david/chap07/notes
&gt; NOTES_MODEL=models/notes-fs node --experimental-modules./bin/www.mjs
    
  notes:server Listening on port 3000 +0ms
  notes:fs-model keylist dir=notes-fs-data files=[  ] +4s </strong> </pre>
<p>Then we can use the application at <kbd>http://localhost:3000</kbd> as before. Because we did not change any template or CSS files, the application will look exactly as you left it at the end of <a href="">Chapter 6</a>, <em>Implementing the Mobile-First Paradigm</em>.</p>
<p>Because debugging is turned on for <kbd>notes:*</kbd>, we'll see a log of whatever the <em>Notes</em> application is doing. It's easy to turn this off simply by not setting the <kbd>DEBUG</kbd> variable.</p>
<p>You can now kill and restart the <em>Notes</em> application and see the exact same notes. You can also edit the notes at the command line using regular text editors such as <kbd>vi</kbd>. You can now start multiple servers on different ports and see exactly the same notes:</p>
<pre>"server1": "NOTES_MODEL=fs PORT=3001 node --experimental-modules./bin/www.mjs", 
"server2": "NOTES_MODEL=fs PORT=3002 node --experimental-modules./bin/www.mjs", </pre>
<p>Then you start <kbd>server1</kbd> and <kbd>server2</kbd> in separate command windows as we did in <a href="e4322e55-673b-45c5-b64e-fc107d57ef03.xhtml">Chapter 5</a>, <em>Your First Express Application</em>. Then, visit the two servers in separate browser windows, and you will see that both browser windows show the same notes.</p>
<p>The final check is to create a note where the key has a <kbd>/</kbd> character. Remember that the key is used to generate the filename where we store the note, and therefore the key cannot contain a <kbd>/</kbd> character. With the browser open, click on ADD Note and enter a note, ensuring that you use a <kbd>/</kbd> character in the <kbd>key</kbd> field. On clicking the Submit button, you'll see an error saying that this isn't allowed.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Storing notes with the LevelUP data store</h1>
                
            
            
                
<p>To get started with actual databases, let's look at an extremely lightweight, small-footprint database engine: <strong>LevelUP</strong>. This is a Node.js-friendly wrapper around the LevelDB engine developed by Google, which is normally used in web browsers for local data persistence. It is a non-indexed, NoSQL data store designed originally for use in browsers. The Node.js module, Level, uses the LevelDB API, and supports multiple backends, including <kbd>LevelDOWN</kbd>, which integrates the C++ LevelDB database into Node.js.</p>
<p>Visit <a href="https://www.npmjs.com/package/level">https://www.npmjs.com/package/level</a> for information on the module. The <kbd>level</kbd> package automatically sets up the <kbd>levelup</kbd> and <kbd>leveldown</kbd> packages. </p>
<p>To install the database engine, run this command:</p>
<pre><strong>$ npm install level@2.1.x --save</strong></pre>
<p>Then, start creating the <kbd>models/notes-level.mjs</kbd> module:</p>
<pre>import fs from 'fs-extra';<br/>import path from 'path';<br/>import util from 'util';<br/>import Note from './Note';<br/>import level from 'level';<br/>import DBG from 'debug';<br/>const debug = DBG('notes:notes-level'); <br/>const error = DBG('notes:error-level'); <br/><br/>var db;<br/><br/>async function connectDB() { <br/>    if (typeof db !== 'undefined' || db) return db;<br/>    db = await level(<br/>        process.env.LEVELDB_LOCATION || 'notes.level', { <br/>            createIfMissing: true, <br/>            valueEncoding: "json" <br/>    }); <br/>    return db;<br/>} </pre>
<p>The <kbd>level</kbd> module gives us a <kbd>db</kbd> object through which to interact with the database. We're storing that object as a global within the module for ease of use. If the <kbd>db</kbd> object is set, we can just return it immediately. Otherwise, we open the database using <kbd>createIfMissing</kbd> to go ahead and create the database if needed.</p>
<p>The location of the database defaults to <kbd>notes.level</kbd> in the current directory. The environment variable <kbd>LEVELDB_LOCATION</kbd> can be set, as the name implies, to specify the database location:</p>
<pre>async function crupdate(key, title, body) { <br/>    const db = await connectDB();<br/>    var note = new Note(key, title, body); <br/>    await db.put(key, note.JSON);<br/>    return note;<br/>}<br/><br/>export function create(key, title, body) {<br/>    return crupdate(key, title, body);<br/>}<br/><br/>export function update(key, title, body) {<br/>    return crupdate(key, title, body);<br/>}</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>Calling <kbd>db.put</kbd> either creates a new database entry, or replaces an existing one. Therefore, both <kbd>update</kbd> and <kbd>create</kbd> are set to be the same function. We convert the Note to JSON so it can be easily stored in the database:</p>
<pre>export async function read(key) {<br/>    const db = await connectDB();<br/>    var note = Note.fromJSON(await db.get(key));<br/>    return new Note(note.key, note.title, note.body);<br/>}</pre>
<p>Reading a Note is easy: just call <kbd>db.get</kbd> and it retrieves the data, which must be decoded from the JSON representation. </p>
<p>Notice that <kbd>db.get</kbd> and <kbd>db.put</kbd> did not take a callback function, and that we use <kbd>await</kbd> to get the results value. The functions exported by <kbd>level</kbd> can take a callback function, in which the callback will be invoked. Alternatively, if no callback function is provided, the <kbd>level</kbd> function will instead return a Promise for compatibility with <kbd>async</kbd> functions:</p>
<pre>export async function destroy(key) { <br/>    const db = await connectDB();<br/>    await db.del(key);<br/>}</pre>
<p>The <kbd>db.destroy</kbd> function deletes a record from the database:</p>
<pre>export async function keylist() { <br/>    const db = await connectDB();<br/>    var keyz = [];<br/>    await new Promise((resolve, reject) =&gt; { <br/>        db.createKeyStream()<br/>        .on('data', data =&gt; keyz.push(data)) <br/>        .on('error', err =&gt; reject(err)) <br/>        .on('end', () =&gt; resolve(keyz));<br/>    }); <br/>    return keyz;<br/>}<br/> <br/>export async function count() { <br/>    const db = await connectDB();<br/>    var total = 0;<br/>    await new Promise((resolve, reject) =&gt; { <br/>        db.createKeyStream()<br/>        .on('data', data =&gt; total++) <br/>        .on('error', err =&gt; reject(err)) <br/>        .on('end', () =&gt; resolve(total));<br/>    }); <br/>    return total;<br/>}<br/><br/>export async function close() {<br/>    var _db = db;<br/>    db = undefined;<br/>    return _db ? _db.close() : undefined;<br/>}</pre>
<p>The <kbd>createKeyStream</kbd> function uses an event-oriented interface similar to the Streams API. It will stream through every database entry, emitting events as it goes. A <kbd>data</kbd> event is emitted for every key in the database, while the <kbd>end</kbd> event is emitted at the end of the database, and the <kbd>error</kbd> event is emitted on errors. The effect is that there's no simple way to present this as a simple Promise. Instead, we invoke <kbd>createKeyStream</kbd>, let it run its course, collecting data as it goes. We have to wrap it inside a Promise object, and call resolve on the <kbd>end</kbd> event.</p>
<p>Then we add this to <kbd>package.json</kbd> in the <kbd>scripts</kbd> section:</p>
<pre>"start-level": "DEBUG=notes:* NOTES_MODEL=level node --experimental-modules ./bin/www.mjs",</pre>
<p>Finally, you can run the <em>Notes</em> application:</p>
<pre><strong>$ DEBUG=notes:* npm run start-level
&gt; notes@0.0.0 start /Users/david/chap07/notes
&gt; node ./bin/www
  
  notes:server Listening on port 3000 +0ms</strong> </pre>
<p>The printout in the console will be the same, and the application will also look the same. You can put it through its paces and see that everything works correctly.</p>
<p>Since <kbd>level</kbd> does not support simultaneous access to a database from multiple instances, you won't be able to use the multiple <em>Notes</em> application scenario. You will, however, be able to stop and restart the application at will without losing any notes.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Storing notes in SQL with SQLite3</h1>
                
            
            
                
<p>To get started with more normal databases, let's see how to use SQL from Node.js. First, we'll use SQLite3, a lightweight, simple-to-set-up database engine eminently suitable for many applications.</p>
<p>To learn about that database engine, visit <a href="http://www.sqlite.org/">http://www.sqlite.org/</a>.
<p> </p>
<p>To learn about the Node.js module, visit <a href="https://github.com/mapbox/node-sqlite3/wiki/API">https://github.com/mapbox/node-sqlite3/wiki/API</a> or <a href="https://www.npmjs.com/package/sqlite3">https://www.npmjs.com/package/sqlite3</a>.</p>
</p>
<p>The primary advantage of SQLite3 is that it doesn't require a server; it is a self-contained, no-set-up-required SQL database.</p>
<p>The first step is to install the module:</p>
<pre><strong>$ npm install sqlite3@3.x --save</strong></pre>


            

            
        
    </div>



  
<div><h1 class="header-title">SQLite3 database schema</h1>
                
            
            
                
<p>Next, we need to make sure that our database is configured. We're using this SQL table definition for the schema (save this as <kbd>models/schema-sqlite3.sql</kbd>):</p>
<pre>CREATE TABLE IF NOT EXISTS notes (<br/>    notekey VARCHAR(255),<br/>    title VARCHAR(255),<br/>    body TEXT<br/>);</pre>
<p>How do we initialize this schema before writing some code? One way is to ensure that the <kbd>sqlite3</kbd> package is installed through your operating system package management system, such as using <kbd>apt-get</kbd> on Ubuntu/Debian, and MacPorts on macOS. Once it's installed, you can run the following command:</p>
<pre><strong>$ sqlite3 chap07.sqlite3 </strong><br/><strong>SQLite version 3.21.0 2017-10-24 18:55:49</strong><br/><strong>Enter ".help" for usage hints.</strong><br/><strong>sqlite&gt; CREATE TABLE IF NOT EXISTS notes (</strong><br/><strong>   ...&gt; notekey VARCHAR(255),</strong><br/><strong>   ...&gt; title VARCHAR(255),</strong><br/><strong>   ...&gt; body TEXT</strong><br/><strong>   ...&gt; );</strong><br/><strong>sqlite&gt; .schema notes</strong><br/><strong>CREATE TABLE notes (</strong><br/><strong>    notekey VARCHAR(255),</strong><br/><strong>    title VARCHAR(255),</strong><br/><strong>    body TEXT</strong><br/><strong>);</strong><br/><strong>sqlite&gt; ^D</strong><br/><strong>$ ls -l chap07.sqlite3 </strong><br/><strong>-rwx------ 1 david staff 8192 Jan 14 20:40 chap07.sqlite3 </strong> </pre>
<p>While we can do that, the Twelve Factor application model says we must automate any administrative processes in this way. To that end, we should instead write a little script to run an SQL operation on SQLite3 and use that to initialize the database.</p>
<p>Fortunately, the <kbd>sqlite3</kbd> command offers us a way to do this. Add the following to the <kbd>scripts</kbd> section of <kbd>package.json</kbd>:</p>
<pre>"sqlite3-setup": "sqlite3 chap07.sqlite3 --init models/schema-sqlite3.sql", </pre>
<p>Run the setup script:</p>
<pre><strong>$ npm run sqlite3-setup
    
&gt; notes@0.0.0 sqlite3-setup /Users/david/chap07/notes
&gt; sqlite3 chap07.sqlite3 --init models/schema-sqlite3.sql 
    
-- Loading resources from models/schema-sqlite3.sql
    
SQLite version 3.10.2 2016-01-20 15:27:19
Enter ".help" for usage hints.
sqlite&gt; .schema notes
CREATE TABLE notes (
    notekey VARCHAR(255),
    title   VARCHAR(255),
    body    TEXT
);
sqlite&gt; ^D</strong></pre>
<p>We could have written a small Node.js script to do this, and it's easy to do so. However, by using the tools provided by the package, we have less code to maintain in our own project.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">SQLite3 model code</h1>
                
            
            
                
<p>Now, we can write code to use this database in the <em>Notes</em> application.</p>
<p class="mce-root"/>
<p>Create <kbd>models/notes-sqlite3.mjs</kbd> file:</p>
<pre>import util from 'util';<br/>import Note from './Note';<br/>import sqlite3 from 'sqlite3';<br/>import DBG from 'debug';<br/>const debug = DBG('notes:notes-sqlite3'); <br/>const error = DBG('notes:error-sqlite3'); <br/><br/>var db; // store the database connection here <br/> <br/>async function connectDB() { <br/>    if (db) return db; <br/>    var dbfile = process.env.SQLITE_FILE || "notes.sqlite3"; <br/>    await new Promise((resolve, reject) =&gt; {<br/>        db = new sqlite3.Database(dbfile, <br/>            sqlite3.OPEN_READWRITE | sqlite3.OPEN_CREATE, <br/>            err =&gt; { <br/>                if (err) return reject(err); <br/>                resolve(db);<br/>        });<br/>    });<br/>    return db;<br/>}</pre>
<p>This serves the same purpose as the <kbd>connectDB</kbd> function in <kbd>notes-level.mjs</kbd>: to manage the database connection. If the database is not open, it'll go ahead and do so, and even make sure that the database file is created (if it doesn't exist). But if it is already open, it is immediately returned:</p>
<pre>export async function create(key, title, body) { <br/>    var db = await connectDB();<br/>    var note = new Note(key, title, body); <br/>    await new Promise((resolve, reject) =&gt; { <br/>        db.run("INSERT INTO notes ( notekey, title, body) "+ <br/>            "VALUES ( ?, ? , ? );", [ key, title, body ], err =&gt; { <br/>                if (err) return reject(err); <br/>                resolve(note); <br/>        }); <br/>    });<br/>    return note;<br/>}<br/> <br/>export async function update(key, title, body) { <br/>    var db = await connectDB();<br/>    var note = new Note(key, title, body); <br/>    await new Promise((resolve, reject) =&gt; { <br/>        db.run("UPDATE notes "+ <br/>            "SET title = ?, body = ? WHERE notekey = ?", <br/>            [ title, body, key ], err =&gt; { <br/>                if (err) return reject(err); <br/>                resolve(note); <br/>        }); <br/>    });<br/>    return note;<br/>}</pre>
<p>These are our <kbd>create</kbd> and <kbd>update</kbd> functions. As promised, we are now justified in defining the Notes model to have separate functions for <kbd>create</kbd> and <kbd>update</kbd> operations, because the SQL statement for each is different.</p>
<p>Calling <kbd>db.run</kbd> executes an SQL query, giving us the opportunity to insert parameters into the query string.</p>
<p>The <kbd>sqlite3</kbd> module uses a parameter substitution paradigm that's common in SQL programming interfaces. The programmer puts the SQL query into a string, and then places a question mark in each place where the aim is to insert a value into the query string. Each question mark in the query string has to match a value in the array provided by the programmer. The module takes care of encoding the values correctly so that the query string is properly formatted, while preventing SQL injection attacks.</p>
<p>The <kbd>db.run</kbd> function simply runs the SQL query it is given, and does not retrieve any data. Because the <kbd>sqlite3</kbd> module doesn't produce any kind of Promise, we have to wrap function calls in a <kbd>Promise</kbd> object:</p>
<pre>export async function read(key) {<br/>  var db = await connectDB();<br/>  var note = await new Promise((resolve, reject) =&gt; {<br/>    db.get("SELECT * FROM notes WHERE notekey = ?", [key], (err,row) =&gt; {<br/>        if (err) return reject(err);<br/>        const note = new Note(row.notekey, row.title, row.body);<br/>        resolve(note);<br/>     });<br/>  });<br/>  return note;<br/>}</pre>
<p>To retrieve data using the <kbd>sqlite3</kbd> module, you use the <kbd>db.get</kbd>, <kbd>db.all</kbd>, or <kbd>db.each</kbd> functions. The <kbd>db.get</kbd> function used here returns only the first row of the result set. The <kbd>db.all</kbd> function returns all rows of the result set at once, which can be a problem for available memory if the result set is large. The <kbd>db.each</kbd> function retrieves one row at a time, while still allowing processing of the entire result set.</p>
<p>For the <em>Notes</em> application, using <kbd>db.get</kbd> to retrieve a note is sufficient because there is only one note per <kbd>notekey</kbd>. Therefore, our <kbd>SELECT</kbd> query will return at most one row anyway. But what if your application will see multiple rows in the result set? We'll see what to do about that in a minute.</p>
<p>By the way, this <kbd>read</kbd> function has a bug in it. See if you can spot the error. We'll read more about this in <a href="">Chapter 11</a>, <em>Unit Testing and Functional Testing</em>, when our testing efforts uncover the bug:</p>
<pre>export async function destroy(key) {<br/>  var db = await connectDB();<br/>  return await new Promise((resolve, reject) =&gt; {<br/>    db.run("DELETE FROM notes WHERE notekey = ?;", [key], err =&gt; {<br/>        if (err) return reject(err);<br/>        resolve();<br/>    });<br/>  });<br/>}</pre>
<p>To destroy a note, we simply execute the <kbd>DELETE FROM</kbd> statement:</p>
<pre>export async function keylist() {<br/>    var db = await connectDB();<br/>    var keyz = await new Promise((resolve, reject) =&gt; {<br/>        var keyz = [];<br/>        db.all("SELECT notekey FROM notes", (err, rows) =&gt; {<br/>                if (err) return reject(err);<br/>                resolve(rows.map(row =&gt; row.notekey ));<br/>            });<br/>    });<br/>    return keyz;<br/>}</pre>
<p>The <kbd>db.all</kbd> function retrieves all rows of the result set. </p>
<p>The contract for this function is to return an array of note keys. The <kbd>rows</kbd> object is an array of results from the database that contains the data we are to return, but in a different format. Therefore, we use the <kbd>map</kbd> function to convert the array into the format required to fulfill the contract:</p>
<pre>export async function count() {<br/>    var db = await connectDB();<br/>    var count = await new Promise((resolve, reject) =&gt; {<br/>        db.get("select count(notekey) as count from notes",(err, row) <br/>        =&gt; {<br/>                if (err) return reject(err);<br/>                resolve(row.count);<br/>            });<br/>    });<br/>    return count;<br/>}<br/><br/>export async function close() {<br/>    var _db = db;<br/>    db = undefined;<br/>    return _db ? new Promise((resolve, reject) =&gt; {<br/>            _db.close(err =&gt; {<br/>                if (err) reject(err);<br/>                else resolve();<br/>            });<br/>        }) : undefined;<br/>}</pre>
<p>We can simply use SQL to count the number of notes for us. In this case, <kbd>db.get</kbd> returns a row with a single column, <kbd>count</kbd>, which is the value we want to return.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Running Notes with SQLite3</h1>
                
            
            
                
<p>Finally, we're ready to run the <em>Notes</em> application with SQLite3. Add the following code to the <kbd>scripts</kbd> section of <kbd>package.json</kbd>:</p>
<pre>"start-sqlite3": "SQLITE_FILE=chap07.sqlite3 NOTES_MODEL=sqlite3 node --experimental-modules ./bin/www.mjs",</pre>
<p>Run the <em>Notes</em> application:</p>
<pre><strong>$ DEBUG=notes:* npm run start-sqlite3
    
&gt; notes@0.0.0 start-sqlite3 /Users/david/chap07/notes
&gt; SQLITE_FILE=chap07.sqlite3 NOTES_MODEL=models/notes-sqlite3 node ./bin/www.mjs
    
  notes:server Listening on port 3000 +0ms
  notes:sqlite3-model Opened SQLite3 database chap07.sqlite3 +5s </strong> </pre>
<p>You can now browse the application at <kbd>http://localhost:3000</kbd>, and run it through its paces as before.</p>
<p>Because SQLite3 supports simultaneous access from multiple instances, you can run the multiserver example by adding this to the <kbd>scripts</kbd> section of <kbd>package.json</kbd>:</p>
<pre>"server1-sqlite3": "SQLITE_FILE=chap07.sqlite3 NOTES_MODEL=sqlite3 PORT=3001 node ./bin/www.mjs", 
"server2-sqlite3": "SQLITE_FILE=chap07.sqlite3 NOTES_MODEL=sqlite3 PORT=3002 node ./bin/www.mjs", </pre>
<p>Then, run each of these in separate command Windows, as before.</p>
<p>Because we still haven't made any changes to the View templates or CSS files, the application will look the same as before.</p>
<p>Of course, you can use the <kbd>sqlite</kbd> command, or other SQLite3 client applications, to inspect the database:</p>
<pre><strong>$ sqlite3 chap07.sqlite3 
SQLite version 3.10.2 2016-01-20 15:27:19
Enter ".help" for usage hints.
sqlite&gt; select * from notes;
hithere|Hi There||ho there what there
himom|Hi Mom||This is where we say thanks </strong> </pre>


            

            
        
    </div>



  
<div><h1 class="header-title">Storing notes the ORM way with Sequelize</h1>
                
            
            
                
<p>There are several popular SQL database engines, such as PostgreSQL, MySQL (<a href="https://www.npmjs.com/package/mysql">https://www.npmjs.com/package/mysql</a>), and MariaDB (<a href="https://www.npmjs.com/package/mariasql">https://www.npmjs.com/package/mariasql</a>). Corresponding to each are Node.js client modules similar in nature to the <kbd>sqlite3</kbd> module that we just used. The programmer is close to the SQL, which can be good in the same way that driving a stick shift car is fun. But what if we want a higher-level view of the database so that we can think in terms of objects rather than rows of a database table? <strong>Object Relation Mapping</strong> (<strong>ORM</strong>) systems provide such a higher-level interface and even offer the ability to use the same data model with several databases.</p>
<p>The <strong>Sequelize</strong> module (<a href="http://www.sequelizejs.com/">http://www.sequelizejs.com/</a>) is Promise-based, offers strong, well-developed ORM features, and can connect with SQLite3, MySQL, PostgreSQL, MariaDB, and MSSQL. Because Sequelize is Promise-based, it will fit naturally with the Promise-based application code we're writing.</p>
<p>A prerequisite to most SQL database engines is having access to a database server. In the previous section, we skirted around that issue by using SQLite3, which requires no database server setup. While it's possible to install a database server on your laptop, we want to avoid the complexity of doing so, and will use Sequelize to manage an SQLite3 database. We'll also see that it's simply a matter of a configuration file to run the same Sequelize code against a hosted database such as MySQL. In <a href="7542f45a-6bd9-432e-875a-c110c0d84c61.xhtml">Chapter 10</a>, <em>Deploying Node.js Applications</em>, we'll learn how to use Docker to easily set up any service, including database servers, on our laptop and deploy the exact same configuration to a live server. Most web hosting providers offer MySQL or PostgreSQL as part of the service.</p>
<p>Before we start on the code, let's install two modules:</p>
<pre><strong>$ npm install sequelize@4.31.x --save
$ npm install js-yaml@3.10.x --save</strong></pre>
<p>The first obviously installs the Sequelize package. The second, <kbd>js-yaml</kbd>, is installed so that we can implement a YAML-formatted file to store the Sequelize connection configuration. YAML is a human-readable <em>data serialization language</em>, which simply means YAML is an easy-to-use text file format to describe data objects. Perhaps the best place to learn about YAML is its Wikipedia page at <a href="https://en.wikipedia.org/wiki/YAML">https://en.wikipedia.org/wiki/YAML</a>.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Sequelize model for the Notes application</h1>
                
            
            
                
<p>Let's create a new file, <kbd>models/notes-sequelize.mjs</kbd>:</p>
<pre>import fs from 'fs-extra';<br/>import util from 'util';<br/>import jsyaml from 'js-yaml';<br/>import Note from './Note';<br/>import Sequelize from 'sequelize';<br/>import DBG from 'debug';<br/>const debug = DBG('notes:notes-sequelize'); <br/>const error = DBG('notes:error-sequelize'); <br/><br/>var SQNote; <br/>var sequlz;<br/><br/>async function connectDB() { <br/>  if (typeof sequlz === 'undefined') {<br/>    const YAML = await fs.readFile(process.env.SEQUELIZE_CONNECT,'utf8');<br/>    const params = jsyaml.safeLoad(YAML, 'utf8'); <br/>    sequlz = new Sequelize(params.dbname, params.username,<br/>                           params.password, params.params); <br/>  }<br/>  if (SQNote) return SQNote.sync(); <br/>  SQNote = sequlz.define('Note', { <br/>        notekey: { type: Sequelize.STRING, primaryKey: true, unique: <br/>        true }, <br/>        title: Sequelize.STRING, <br/>        body: Sequelize.TEXT <br/>  }); <br/>  return SQNote.sync();<br/>}</pre>
<p>The database connection is stored in the <kbd>sequlz</kbd> object, and is established by reading a configuration file (we'll go over this file later), and instantiating a Sequelize instance. The data model, <kbd>SQNote</kbd>, describes our object structure to Sequelize so that it can define corresponding database table(s). If <kbd>SQNote</kbd> is already defined, we simply return it, otherwise we define and return <kbd>SQNote</kbd>. </p>
<p>The Sequelize connection parameters are stored in a YAML file we specify in the <kbd>SEQUELIZE_CONNECT</kbd> environment variable. The line <kbd>new Sequelize(..)</kbd> opens the database connection. The parameters obviously contain any needed database name, username, password, and other options required to connect with the database.</p>
<p>The line <kbd>sequlz.define</kbd> is where we define the database schema. Instead of defining the schema as the SQL command to create the database table, we're giving a high-level description of the fields and their characteristics. Sequelize maps the object attributes into columns in tables. </p>
<p>We're telling Sequelize to call this schema Note, but we're using a <kbd>SQNote</kbd> variable to refer to that schema. That's because we already defined Note as a class to represent notes. To avoid a clash of names, we'll keep using the <kbd>Note</kbd> class, and use SQNote to interact with Sequelize about the notes stored in the database.</p>
<p>Online documentation can be found at the following locations:<br/>
Sequelize class: <a href="http://docs.sequelizejs.com/en/latest/api/sequelize/">http://docs.sequelizejs.com/en/latest/api/sequelize/</a>.<a href="http://docs.sequelizejs.com/en/latest/api/sequelize/"><br/></a>Defining models: <a href="http://docs.sequelizejs.com/en/latest/api/model/">http://docs.sequelizejs.com/en/latest/api/model/</a>.<a href="http://docs.sequelizejs.com/en/latest/api/model/"/></p>
<p>Add these functions to <kbd>models/notes-sequelize.mjs</kbd>:</p>
<pre>export async function create(key, title, body) { <br/>    const SQNote = await connectDB();<br/>    const note = new Note(key, title, body); <br/>    await SQNote.create({ notekey: key, title: title, body: body });<br/>    return note;<br/>}<br/> <br/>export async function update(key, title, body) { <br/>    const SQNote = await connectDB();<br/>    const note = await SQNote.find({ where: { notekey: key } }) <br/>    if (!note) { throw new Error(`No note found for ${key}`); } else { <br/>        await note.updateAttributes({ title: title, body: body });<br/>        return new Note(key, title, body);<br/>    } <br/>}</pre>
<p>There are several ways to create a new object instance in Sequelize. The simplest is to call an object's <kbd>create</kbd> function (in this case, <kbd>SQNote.create</kbd>). That function collapses together two other functions, <kbd>build</kbd> (to create the object), and <kbd>save</kbd> (to write it to the database).</p>
<p>Updating an object instance is a little different. First, we must retrieve its entry from the database using the <kbd>find</kbd> operation. The <kbd>find</kbd> operation is given an object specifying the query. Using <kbd>find</kbd>, we retrieve one instance, whereas the <kbd>findAll</kbd> operation retrieves all matching instances.</p>
<p class="mce-root">For documentation on Sequelize queries, visit <a href="http://docs.sequelizejs.com/en/latest/docs/querying/">http://docs.sequelizejs.com/en/latest/docs/querying/</a>.</p>
<p>Like most or all other Sequelize functions, <kbd>SQNote.find</kbd> returns a Promise. Therefore, inside an <kbd>async</kbd> function, we <kbd>await</kbd> the result of the operation. </p>
<p>The update operation requires two steps, the first being to <kbd>find</kbd> the corresponding object to read it in from the database. Once the instance is found, we can update its values simply with the <kbd>updateAttributes</kbd> function:</p>
<pre>export async function read(key) { <br/>    const SQNote = await connectDB();<br/>    const note = await SQNote.find({ where: { notekey: key } }) <br/>    if (!note) { throw new Error(`No note found for ${key}`); } else { <br/>        return new Note(note.notekey, note.title, note.body); <br/>    } <br/>}</pre>
<p>To read a note, we use the <kbd>find</kbd> operation again. There is the possibility of an empty result, and we have to throw an error to match.</p>
<p>The contract for this function is to return a <kbd>Note</kbd> object. That means taking the fields retrieved using Sequelize and using that to create a <kbd>Note</kbd> object:</p>
<pre>export async function destroy(key) { <br/>    const SQNote = await connectDB();<br/>    const note = await SQNote.find({ where: { notekey: key } }) <br/>    return note.destroy(); <br/>}</pre>
<p>To destroy a note, we use the <kbd>find</kbd> operation to retrieve its instance, and then call its <kbd>destroy()</kbd> method:</p>
<pre>export async function keylist() { <br/>    const SQNote = await connectDB();<br/>    const notes = await SQNote.findAll({ attributes: [ 'notekey' ] });<br/>    return notes.map(note =&gt; note.notekey); <br/>}</pre>
<p>Because the <kbd>keylist</kbd> function acts on all <kbd>Note</kbd> objects, we use the <kbd>findAll</kbd> operation. We query for the <kbd>notekey</kbd> attribute on all notes. We're given an array of objects with a field named <kbd>notekey</kbd>, and we use the <kbd>.map</kbd> function to convert this into an array of the note keys:</p>
<pre>export async function count() { <br/>    const SQNote = await connectDB();<br/>    const count = await SQNote.count();<br/>    return count; <br/>}<br/><br/>export async function close() {<br/>    if (sequlz) sequlz.close();<br/>    sequlz = undefined;<br/>    SQNote = undefined;<br/>}</pre>
<p>For the <kbd>count</kbd> function, we can just use the <kbd>count()</kbd> method to calculate the needed result.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Configuring a Sequelize database connection</h1>
                
            
            
                
<p>Sequelize supports the same API on several SQL database engines. The database connection is initialized using parameters on the Sequelize constructor. The Twelve Factor Application model suggests that configuration data such as this should be kept outside the code and injected using environment variables or a similar mechanism. What we'll do is use a YAML-formatted file to store the connection parameters, specifying the filename with an environment variable.</p>
<p>The Sequelize library does not define any such file for storing connection parameters. But it's simple enough to develop such a file. Let's do so.</p>
<p>The API for the Sequelize constructor is: <kbd>constructor(database: String, username: String, password: String, options: Object)</kbd>.</p>
<p>In the <kbd>connectDB</kbd> function, we wrote the constructor as follows:</p>
<pre>sequlz = new Sequelize(params.dbname, params.username, params.password, params.params); </pre>
<p>This file, named <kbd>models/sequelize-sqlite.yaml</kbd>, provides with us a simple mapping that looks like this for an SQLite3 database:</p>
<pre>dbname: notes 
username: 
password: 
params: 
    dialect: sqlite 
    storage: notes-sequelize.sqlite3 </pre>
<p>The YAML file is a direct mapping to the Sequelize constructor parameters. The <kbd>dbname</kbd>, <kbd>username</kbd>, and <kbd>password</kbd> fields in this file correspond directly to the connection credentials, and the <kbd>params</kbd> object gives additional parameters. There are many, many, possible attributes to use in the <kbd>params</kbd> field, and you can read about them in the Sequelize documentation at <a href="http://docs.sequelizejs.com/manual/installation/usage.html">http://docs.sequelizejs.com/manual/installation/usage.html</a>.</p>
<p>The <kbd>dialect</kbd> field tells Sequelize what kind of database to use. For an SQLite database, the database filename is given in the <kbd>storage</kbd> field. </p>
<p>Let's first use SQLite3, because no further setup is required. After that, we'll get adventurous and reconfigure our Sequelize module to use MySQL. </p>
<p>If you already have a different database server available, it's simple to create a corresponding configuration file. For a plausible MySQL database on your laptop, create a new file, such as <kbd>models/sequelize-mysql.yaml</kbd>, containing something like the following code:</p>
<pre>dbname: notes 
username: .. user name 
password: .. password 
params: 
    host: localhost 
    port: 3306 
    dialect: mysql </pre>
<p>This is straightforward. The <kbd>username</kbd> and <kbd>password</kbd> must correspond to the database credentials, while <kbd>host</kbd> and <kbd>port</kbd> will specify where the database is hosted.  Set the database <kbd>dialect</kbd> and other connection information, and you're good to go.</p>
<p>To use MySQL, you will need to install the base MySQL driver so that Sequelize can use MySQL:</p>
<pre><strong>$ npm install mysql@2.x --save</strong></pre>
<p>Running with Sequelize against other databases it supports, such as PostgreSQL, is just as simple. Just create a configuration file, install the Node.js driver, and install/configure the database engine.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Running the Notes application with Sequelize</h1>
                
            
            
                
<p>Now we can get ready to run the <em>Notes</em> application using Sequelize. We can run this against both SQLite3 and MySQL, but let's start with SQLite. Add this entry to the <kbd>scripts</kbd> entry in <kbd>package.json</kbd>:</p>
<pre>"start-sequelize": "SEQUELIZE_CONNECT=models/sequelize-sqlite.yaml NOTES_MODEL=sequelize node  --experimental-modules ./bin/www.mjs" </pre>
<p>Then run it as follows:</p>
<pre><strong>$ DEBUG=notes:* npm run start-sequelize
    
&gt; notes@0.0.0 start-sequelize /Users/david/chap07/notes
&gt; SEQUELIZE_CONNECT=models/sequelize-sqlite.yaml NOTES_MODEL=sequelize node --experimental-modules./bin/www.mjs
    
  notes:server Listening on port 3000 +0ms </strong></pre>
<p>As before, the application looks exactly the same because we've not changed the View templates or CSS files. Put it through its paces and everything should work.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>With Sequelize, multiple <em>Notes</em> application instances is as simple as adding these lines to the <kbd>scripts</kbd> section of <kbd>package.json</kbd>, and then starting both instances as before:</p>
<pre><strong>"server1-sequelize": "SEQUELIZE_CONNECT=models/sequelize-sqlite.yaml NOTES_MODEL=sequelize PORT=3001 node --experimental-modules ./bin/www.mjs", </strong><br/><strong>"server2-sequelize": "SEQUELIZE_CONNECT=models/sequelize-sqlite.yaml NOTES_MODEL=sequelize PORT=3002 node --experimental-modules ./bin/www.mjs",</strong></pre>
<p>You will be able to start both instances, use separate browser windows to visit both instances, and see that they show the same set of notes.</p>
<p>To reiterate using the Sequelize-based model on a given database server:</p>
<ol>
<li>Install and provision the database server instance, or else get the connection parameters for an already-provisioned database server.</li>
<li>Install the corresponding Node.js driver.</li>
<li>Write a YAML configuration file corresponding to the connection parameters.</li>
<li>Create new <kbd>scripts</kbd> entries in <kbd>package.json</kbd> to automate starting Notes against that database.</li>
</ol>


            

            
        
    </div>



  
<div><h1 class="header-title">Storing notes in MongoDB</h1>
                
            
            
                
<p>MongoDB is widely used with Node.js applications, a sign of which is the popular MEAN acronym: MongoDB (or MySQL), Express, Angular, and Node.js. MongoDB is one of the leading NoSQL databases. It is described as a <em>scalable, high-performance, open source, document-oriented database</em>. It uses JSON-style documents with no predefined, rigid schema and a large number of advanced features. You can visit their website for more information and documentation at <a href="http://www.mongodb.org">http://www.mongodb.org</a>.</p>
<p>Documentation on the Node.js driver for MongoDB can be found at <a href="https://www.npmjs.com/package/mongodb">https://www.npmjs.com/package/mongodb</a> and <a href="http://mongodb.github.io/node-mongodb-native/">http://mongodb.github.io/node-mongodb-native/</a>.</p>
<p>Mongoose is a popular ORM for MongoDB (<a href="http://mongoosejs.com/">http://mongoosejs.com/</a>). In this section, we'll use the native MongoDB driver instead, but Mongoose is a worthy alternative.</p>
<p>You will need a running MongoDB instance. The <kbd>compose.io</kbd> (<a href="https://www.compose.io/">https://www.compose.io/</a>) and <kbd>ScaleGrid.io</kbd> (<a href="https://scalegrid.io/">https://scalegrid.io/</a>) hosted service providers offer hosted MongoDB services. Nowadays, it is straightforward to host MongoDB as a Docker container as part of a system built of other Docker containers. We'll do this in <a href="">Chapter 11</a>, <em>Unit Testing and Functional Testing</em>.</p>
<p>It's possible to set up a temporary MongoDB instance for testing on, say, your laptop. It is available in all the operating system package management systems, and the MongoDB website has instructions (<a href="https://docs.mongodb.org/manual/installation/">https://docs.mongodb.org/manual/installation/</a>).</p>
<p>Once installed, it's not necessary to set up MongoDB as a background service. Instead, you can run a couple of simple commands to get a MongoDB instance running in the foreground of a command window, which you can kill and restart any time you like.</p>
<p>In one command window, run the following:</p>
<pre><strong>$ mkdir data
$ mongod --dbpath data</strong></pre>
<p>In another command window, you can test it as follows:</p>
<pre><strong>$ mongo
MongoDB shell version: 3.0.8
connecting to: test
Welcome to the MongoDB shell.
For interactive help, type "help".
For more comprehensive documentation, see
  http://docs.mongodb.org/
Questions? Try the support group
  http://groups.google.com/group/mongodb-user
&gt; db.foo.save({ a: 1});
WriteResult({ "nInserted" : 1 })
&gt; db.foo.find();
{ "_id" : ObjectId("56c0c98673f65b7988a96a77"), "a" : 1 }
&gt; 
bye</strong></pre>
<p>This saves a <em>document</em> in the collection named <kbd>foo</kbd>. The second command finds all documents in <kbd>foo</kbd>, printing them out for you. The <kbd>_id</kbd> field is added by MongoDB and serves as a document identifier. This is useful for testing and debugging. For a real deployment, your MongoDB server must be properly installed on a server. See the MongoDB documentation for these instructions.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">MongoDB model for the Notes application</h1>
                
            
            
                
<p>Now that you've proved you have a working MongoDB server, let's get to work.</p>
<p>Installing the Node.js driver is as simple as running the following command:</p>
<pre><strong>$ npm install mongodb@3.x --save</strong></pre>
<p>Now create a new file, <kbd>models/notes-mongodb.mjs</kbd>:</p>
<pre>import util from 'util';<br/>import Note from './Note';<br/>import mongodb from 'mongodb'; <br/>const MongoClient = mongodb.MongoClient;<br/>import DBG from 'debug';<br/>const debug = DBG('notes:notes-mongodb'); <br/>const error = DBG('notes:error-mongodb'); <br/><br/>var client;<br/><br/>async function connectDB() { <br/>    if (!client) client = await MongoClient.connect(process.env.MONGO_URL);<br/>    return { <br/>        db: client.db(process.env.MONGO_DBNAME), <br/>        client: client<br/>    };<br/>}</pre>
<p>The <kbd>MongoClient</kbd> class is used to connect with a MongoDB instance. The required URL, which will be specified through an environment variable, uses a straightforward format: <kbd>mongodb://localhost/</kbd>. The database name is specified via another environment variable.</p>
<p>Documentation for the corresponding objects can be found at<br/>
<a href="http://mongodb.github.io/node-mongodb-native/2.2/api/MongoClient.html">http://mongodb.github.io/node-mongodb-native/2.2/api/MongoClient.html<br/></a>for MongoClient and <a href="http://mongodb.github.io/node-mongodb-native/2.2/api/Db.html">http://mongodb.github.io/node-mongodb-native/2.2/api/Db.html</a> for Db</p>
<p>This creates the database client, and then opens the database connection. Both objects are returned from <kbd>connectDB</kbd> in an anonymous object. The general pattern for MongoDB operations is as follows:</p>
<pre>(async () =&gt; {<br/>  const client = await MongoClient.connect(process.env.MONGO_URL);<br/>  const db = client.db(process.env.MONGO_DBNAME);<br/>  // perform database operations using db object<br/>  client.close();<br/>})();</pre>
<p>Therefore, our model methods require both <kbd>client</kbd> and <kbd>db</kbd> objects, because they will use both. Let's see how that's done:</p>
<pre>export async function create(key, title, body) { <br/>    const { db, client } = await connectDB();<br/>    const note = new Note(key, title, body); <br/>    const collection = db.collection('notes'); <br/>    await collection.insertOne({ notekey: key, title, body });<br/>    return note;<br/>}<br/> <br/>export async function update(key, title, body) { <br/>    const { db, client } = await connectDB();<br/>    const note = new Note(key, title, body); <br/>    const collection = db.collection('notes'); <br/>    await collection.updateOne({ notekey: key }, { $set: { title, body } });<br/>    return note;<br/>}</pre>
<p>We retrieve <kbd>db</kbd> and <kbd>client</kbd> into individual variables using a destructuring assignment. </p>
<p>MongoDB stores all documents in collections. A <em>collection</em> is a group of related documents, and a collection is analogous to a table in a relational database. This means creating a new document or updating an existing one starts by constructing it as a JavaScript object, and then asking MongoDB to save that object to the database. MongoDB automatically encodes the object into its internal representation.</p>
<p>The <kbd>db.collection</kbd> method gives us a <kbd>Collection</kbd> object with which we can manipulate the named collection. See its documentation at <a href="http://mongodb.github.io/node-mongodb-native/2.2/api/Collection.html">http://mongodb.github.io/node-mongodb-native/2.2/api/Collection.html</a>.</p>
<p>As the method name implies, <kbd>insertOne</kbd> inserts one document into the collection. Likewise, the <kbd>updateOne</kbd> method first finds a document (in this case, by looking up the document with the matching <kbd>notekey</kbd> field), and then changes fields in the document as specified.</p>
<p>You'll see that these methods return a Promise. The <kbd>mongodb</kbd> driver supports both callbacks and Promises. Many methods will invoke the callback function if one is provided, otherwise it returns a Promise that will deliver the results or errors. And, of course, since we're using <kbd>async</kbd> functions, the <kbd>await</kbd> keyword makes this so clean.</p>
<p>Further documentation can be found at the following links:<br/>
Insert: <a href="https://docs.mongodb.org/getting-started/node/insert/">https://docs.mongodb.org/getting-started/node/insert/</a>.<a href="https://docs.mongodb.org/getting-started/node/insert/"><br/></a>Update: <a href="https://docs.mongodb.org/getting-started/node/update/">https://docs.mongodb.org/getting-started/node/update/</a>.</p>
<p>Next, let's look at reading a note from MongoDB:</p>
<pre>export async function read(key) { <br/>    const { db, client } = await connectDB();<br/>    const collection = db.collection('notes');<br/>    const doc = await collection.findOne({ notekey: key });<br/>    const note = new Note(doc.notekey, doc.title, doc.body);<br/>    return note; <br/>}</pre>
<p>The <kbd>mongodb</kbd> driver supports several variants of <kbd>find</kbd> operations. In this case, the <em>Notes</em> application ensures that there is exactly one document matching a given key. Therefore, we can use the <kbd>findOne</kbd> method. As the name implies, <kbd>findOne</kbd> will return the first matching document.</p>
<p>The argument to <kbd>findOne</kbd> is a query descriptor. This simple query looks for documents whose <kbd>notekey</kbd> field matches the requested <kbd>key</kbd>. An empty query will, of course, match all documents in the collection. You can match against other fields in a similar way, and the query descriptor can do much more. For documentation on queries, visit <a href="https://docs.mongodb.org/getting-started/node/query/">https://docs.mongodb.org/getting-started/node/query/</a>.</p>
<p>The <kbd>insertOne</kbd> method we used earlier also took the same kind of query descriptor.</p>
<p>In order to satisfy the contract for this function, we create a <kbd>Note</kbd> object and then return it to the caller. Hence, we create a Note using the data retrieved from the database:</p>
<pre>export async function destroy(key) { <br/>    const { db, client } = await connectDB();<br/>    const collection = db.collection('notes'); <br/>    await collection.findOneAndDelete({ notekey: key });<br/>}</pre>
<p>One of the <kbd>find</kbd> variants is <kbd>findOneAndDelete</kbd>. As the name implies, it finds one document matching the query descriptor, and then deletes that document:</p>
<pre>export async function keylist() { <br/>    const { db, client } = await connectDB();<br/>    const collection = db.collection('notes'); <br/>    const keyz = await new Promise((resolve, reject) =&gt; { <br/>        var keyz = []; <br/>        collection.find({}).forEach( <br/>            note =&gt; { keyz.push(note.notekey); }, <br/>            err =&gt; { <br/>                if (err) reject(err); <br/>                else resolve(keyz); <br/>            } <br/>        ); <br/>    }); <br/>    return keyz;<br/>}</pre>
<p>Here, we're using the base <kbd>find</kbd> operation and giving it an empty query so that it matches every document. What we're to return is an array containing the <kbd>notekey</kbd> for every document.</p>
<p>All of the <kbd>find</kbd> operations return a <kbd>Cursor</kbd> object. The documentation can be found at <a href="http://mongodb.github.io/node-mongodb-native/2.1/api/Cursor.html">http://mongodb.github.io/node-mongodb-native/2.1/api/Cursor.html</a>.</p>
<p>The Cursor object is, as the name implies, a pointer into a result set from a query. It has a number of useful functions related to operating on a result set. For example, you can skip the first few items in the results, or limit the size of the result set, or perform the <kbd>filter</kbd> and <kbd>map</kbd> operations.</p>
<p>The <kbd>Cursor.forEach</kbd> method takes two callback functions. The first is called on every element in the result set. In this case, we can use that to record just the <kbd>notekey</kbd> in an array. The second callback is called after all elements in the result set have been processed. We use this to indicate success or failure, and to return the <kbd>keyz</kbd> array.</p>
<p>Because <kbd>forEach</kbd> uses this pattern, it does not have an option for supplying a Promise, and we have to create the Promise ourselves, as shown here:</p>
<pre>export async function count() { <br/>    const { db, client } = await connectDB();<br/>    const collection = db.collection('notes');<br/>    const count = await collection.count({});<br/>    return count;<br/>}<br/><br/>export async function close() {<br/>    if (client) client.close();<br/>    client = undefined;<br/>}</pre>
<p>The <kbd>count</kbd> method takes a query descriptor and, as the name implies, counts the number of matching documents.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Running the Notes application with MongoDB</h1>
                
            
            
                
<p>Now that we have our MongoDB model, we can get ready to run <em>Notes</em> with it.</p>
<p>By now you know the drill; add this to the <kbd>scripts</kbd> section of <kbd>package.json</kbd>:</p>
<pre>"start-mongodb": "MONGO_URL=mongodb://localhost/ MONGO_DBNAME=chap07 NOTES_MODEL=mongodb node --experimental-modules ./bin/www.mjs", </pre>
<p>The <kbd>MONGO_URL</kbd> environment variable is the URL to connect with your MongoDB database.</p>
<p>You can start the <em>Notes</em> application as follows:</p>
<pre><strong>$ DEBUG=notes:* npm run start-mongodb
&gt; notes@0.0.0 start-mongodb /Users/david/chap07/notes
&gt; MONGO_URL=mongodb://localhost/ MONGO_DBNAME=chap07 NOTES_MODEL=mongodb node --experimental-modules ./bin/www
    
  notes:server Listening on port 3000 +0ms  </strong></pre>
<p>You can browse the application at <kbd>http://localhost:3000</kbd> and put it through its paces. You can kill and restart the application, and your notes will still be there.</p>
<p>Add this to the <kbd>scripts</kbd> section of <kbd>package.json</kbd>:</p>
<pre>"server1-mongodb": "MONGO_URL=mongodb://localhost/ MONGO_DBNAME=chap07 NOTES_MODEL=mongodb PORT=3001 node --experimental-modules ./bin/www.mjs", <br/>"server2-mongodb": "MONGO_URL=mongodb://localhost/ MONGO_DBNAME=chap07 NOTES_MODEL=mongodb PORT=3002 node --experimental-modules ./bin/www.mjs",</pre>
<p>You will be able to start two instances of the <em>Notes</em> application, and see that both share the same set of notes.</p>


            

            
        
    </div>



  
<div><h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we went through a real whirlwind of different database technologies. While we looked at the same seven functions over and over, it's useful to be exposed to the various data storage models and ways of getting things done. Even so, we only touched the surface of options for accessing databases and data storage engines from Node.js.</p>
<p>By abstracting the model implementations correctly, we were able to easily switch data storage engines while not changing the rest of the application. We did skip around the issue of setting up database servers. As promised, we'll get to that in <a href="7542f45a-6bd9-432e-875a-c110c0d84c61.xhtml">Chapter 10,</a> <em>Deploying Node.js Applications</em>, when we explore production deployment of Node.js applications.</p>
<p>By focusing the model code on the purpose of storing data, both the models and the application should be easier to test. The application can be tested with a mock data module that provides known predictable notes that can be checked predictably. We'll look at this in more depth in <a href="">Chapter 11</a>, <em>Unit Testing and Functional Testing</em>.</p>
<p>In the next chapter, we'll focus on authenticating our users using OAuth2.</p>


            

            
        
    </div>



  </body></html>