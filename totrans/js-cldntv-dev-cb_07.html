<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Optimizing Observability</h1>
                </header>
            
            <article>
                
<p> In this chapter, the following recipes will be covered:</p>
<ul>
<li class="mce-root">Monitoring a cloud-native system</li>
<li class="mce-root">Implementing custom metrics</li>
<li class="mce-root">Monitoring domain events</li>
<li class="mce-root">Creating alerts</li>
<li class="mce-root">Creating continuous synthetic transaction tests</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p>Confidence is crucial to maximize the potential of our lean and autonomous cloud-native services, because a crisis of confidence will stifle progress. Leveraging fully managed cloud services and following cloud-native design patterns to create autonomous services significantly increases team confidence. Decoupling deployment from release and shifting testing to the left, to create a streamlined continuous deployment pipeline, further increases team confidence. Yet, this is not enough. We need to shift testing to the right as well, all the way into production, so that we can monitor and alert the team about the status of the system. This gives teams confidence that they will have timely information so that they can minimize the mean time to recovery when errors do happen. The recipes in this chapter demonstrate how to optimize the observability of cloud-native services, alert about what matters, and continuously test in production to increase team confidence.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monitoring a cloud-native system</h1>
                </header>
            
            <article>
                
<p>Leveraging fully managed cloud services is key to creating lean, cloud-native services, because embracing this disposable architecture empowers self-sufficient, full-stack teams to rapidly deliver with confidence based on the foundation provided by those cloud services. Team confidence is further increased because this foundation comes with good observability. This recipe demonstrates how to tap into cloud-provider metrics using a cloud-provider-agnostic, third-party monitoring service.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Before starting this recipe you will need a Datadog account (<a href="https://www.datadoghq.com">https://www.datadoghq.com</a>).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Create the project from the following template:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch7/datadog-account --path cncb-datadog-account</pre>
<ol start="2">
<li>Navigate to the <kbd>cncb-datadog-account</kbd> directory with <kbd>cd cncb-datadog-account</kbd>.</li>
<li>Review the file named <kbd>serverless.yml</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">service: cncb-datadog-account<br/>...<br/>resources:<br/>  Resources:<br/>    DatadogAWSIntegrationPolicy: <br/>      Type: AWS::IAM::ManagedPolicy<br/>      Properties:<br/>        PolicyDocument: ${file(includes.yml):PolicyDocument}<br/>    DatadogAWSIntegrationRole:<br/>      Type: AWS::IAM::Role<br/>      Properties: <br/>        RoleName: DatadogAWSIntegrationRole<br/>        AssumeRolePolicyDocument:<br/>          Statement:<br/>            Effect: Allow<br/>            Principal:<br/>              AWS: arn:aws:iam::464622532012:root<br/>            Action: sts:AssumeRole<br/>            Condition:<br/>              StringEquals:<br/>                sts:ExternalId: &lt;copy value from datadog aws integration dialog&gt;<br/>        ManagedPolicyArns:<br/>          - Ref: DatadogAWSIntegrationPolicy </pre>
<ol start="4">
<li>Install the dependencies<span> with </span><kbd>npm install</kbd>.</li>
<li>Run the tests<span> with </span><kbd>npm test</kbd>.</li>
<li>Review the contents generated in the <kbd>.serverless</kbd> directory.</li>
<li>Deploy the stack<span> with </span><kbd>npm run dp:lcl -- -s $MY_STAGE</kbd>.</li>
<li>Log in to <strong>Datadog</strong> and go to the <strong>Integrations</strong> page and select the AWS integration tile.</li>
<li>Select <span class="packt_screen">Role Delegation</span>, enter your AWS account ID and set the AWS role name to <kbd>DatadogAWSIntegrationRole</kbd>.</li>
<li>Copy the AWS external ID value and use it to update <kbd>sts:ExternalId</kbd> in  <kbd>serverless.yml</kbd>.</li>
<li>Set tags to <kbd>account:cncb</kbd> and press <span class="packt_screen">Install Integration.</span></li>
<li>Update the stack<span> with </span><kbd>npm run dp:lcl -- -s $MY_STAGE</kbd>.</li>
<li>Review the stack and resources in the AWS Console.</li>
<li>Invoke the sample function multiple times with the following command:</li>
</ol>
<pre style="padding-left: 30px">$ sls invoke -f hello -r us-east-1 -s $MY_STAGE</pre>
<ol start="15">
<li>Review the preset Datadog Lambda dashboard<span> with </span><span class="packt_screen">Dashboards</span> | <span class="packt_screen">Dashboard List</span> | <span class="packt_screen">All Integrations</span> | <span class="packt_screen">AWS Lambda.</span></li>
<li>Remove the stack once you are finished with this chapter<span> with </span><kbd>npm run rm:lcl -- -s $MY_STAGE</kbd>.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Cloud providers collect valuable metrics for their cloud services. However, they do not necessarily retain this data for extended periods, and the ability to slice and dice this data can be limited. Therefore, it is recommended to employ a third-party monitoring service to fill in the gaps and provide more comprehensive monitoring capabilities. Furthermore, in the eventuality of utilizing a polyglot cloud, a cloud-provider-agnostic monitoring service offers a unified monitoring experience. My monitoring service of choice is Datadog. This recipe shows how easily and quickly we can connect Datadog to an AWS account and start aggregating metrics to increase the observability of our cloud-native systems.</p>
<p>To allow Datadog to start collecting metrics from an AWS account, we must grant it permission to do so. As the <em>How to do it</em> section shows, this requires steps on the AWS side and the Datadog side. First, we deploy a stack to create <kbd>DatadogAWSIntegrationPolicy</kbd> with all the necessary permissions, and <kbd>DatadogAWSIntegrationRole</kbd> connects the AWS account with Datadog's AWS account. This last bit is important. Datadog runs in AWS as well. This means that we can use <em>Role Delegation</em> to connect the accounts instead of sharing access keys. Once <kbd>DatadogAWSIntegrationRole</kbd> is created, we can configure the AWS integration on the Datadog side, which has a prerequisite for the existence of the role. Datadog generates <kbd>ExternalId</kbd>, which we need to add to <kbd>DatadogAWSIntegrationRole</kbd> as a condition for assuming the role. With the integration in place, Datadog consumes the requested metrics from CloudWatch in your AWS account, so that they can be aggregated into meaningful dashboards, retained for historical analysis, and monitored to alert about conditions of interest.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing custom metrics</h1>
                </header>
            
            <article>
                
<p>The metrics provided by value-added cloud services, such as <em>Function-as-a-service</em>, are a great starting point. Teams can put their cloud-native services into production with just these metrics with a reasonable level of confidence. However, more observability is almost always better. We need fine-grained details about the inner workings of our functions. This recipe demonstrates how to collect additional metrics, such as cold starts, memory, CPU utilization, and the latency of HTTP resources.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Create the project from the following template:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch7/custom-metrics --path cncb-custom-metrics</pre>
<ol start="2">
<li>Navigate to the <kbd>cncb-custom-metrics</kbd> directory<span> with </span><kbd>cd cncb-custom-metrics</kbd>.</li>
<li>Review the file named <kbd>serverless.yml</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">service: cncb-custom-metrics<br/>...<br/>functions:<br/>  hello:<br/>    ...<br/>    environment:<br/>      <strong>ACCOUNT_NAME</strong>: ${opt:account}<br/>      <strong>SERVERLESS_STAGE</strong>: ${opt:stage}<br/>      <strong>SERVERLESS_PROJECT</strong>: ${self:service}<br/>      <strong>MONITOR_ADVANCED</strong>: false<br/>      DEBUG: '*'</pre>
<ol start="4">
<li>Review the file named <kbd>handler.js</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">const { monitor, count } = require('<strong>serverless-datadog-metrics</strong>');<br/>const debug = require('debug')('handler');<br/><br/>module.exports.hello = <strong>monitor</strong>((request, context, callback) =&gt; {<br/>  debug('request: %j', request);<br/>  <strong>count</strong>('hello.count', 1);<br/>  const response = { ... };<br/>  callback(null, response);<br/>});</pre>
<ol start="5">
<li>Install the dependencies<span> with </span><kbd>npm install</kbd>.</li>
<li>Run the tests<span> with </span><kbd>npm test</kbd>.</li>
<li>Review the contents generated in the <kbd>.serverless</kbd> directory.</li>
<li>Deploy the stack:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ npm run dp:lcl -- -s $MY_STAGE</strong><br/><br/>&gt; cncb-custom-metrics@1.0.0 dp:lcl &lt;path-to-your-workspace&gt;/cncb-custom-metrics<br/>&gt; sls deploy -r us-east-1 --account cncb "-s" "john"<br/>...<br/>endpoints:<br/>  GET - <strong>https://h865txqjqj.execute-api.us-east-1.amazonaws.com/john/hello</strong><br/><br/></pre>
<ol start="9">
<li>Review the stack and resources in the AWS Console.</li>
<li>Invoke the endpoint shown in the stack output in the  following commands:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ curl https://&lt;APP-ID&gt;.execute-api.us-east-1.amazonaws.com/$MY_STAGE/hello | json_pp</strong><br/>{<br/>   "message" : "JavaScript Cloud Native Development Cookbook! ..."<br/>}</pre>
<ol start="11">
<li>Take a look at the logs:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ sls logs -f hello -r us-east-1 -s $MY_STAGE</strong><br/><br/>MONITORING|1530339912|1|<strong>count</strong>|aws.lambda.<strong>coldstart</strong>.count|#account:cncb,...<br/>MONITORING|1530339912|0.259|<strong>gauge</strong>|node.process.<strong>uptime</strong>|#account:cncb,...<br/>MONITORING|1530339912|1|count|<strong>hello.count</strong>|#account:cncb,...<br/>MONITORING|1530339912|0|check|aws.lambda.<strong>check</strong>|#account:cncb,...<br/>MONITORING|1530339912|0.498...|gauge|node.mem.heap.<strong>utilization</strong>|#account:cncb,...<br/>MONITORING|1530339912|1.740238|<strong>histogram</strong>|aws.lambda.<strong>handler</strong>|#account:cncb,...  </pre>
<ol start="12">
<li>Execute the service several more times and then review the Lambda dashboard in Datadog under <span class="packt_screen">Dashboards</span> | <span class="packt_screen">Dashboard List</span> | <span class="packt_screen">All Integrations</span> | <span class="packt_screen">AWS Lambda</span>.</li>
<li>Explore the custom metrics in Datadog under <span class="packt_screen">Metrics</span> <em>|</em> <span class="packt_screen">Explore with Graph</span>: <kbd>hello.count</kbd> and <kbd>aws.lambda.handler.avg</kbd>.</li>
<li>Remove the stack once you are finished<span> with </span><kbd>npm run rm:lcl -- -s $MY_STAGE</kbd>.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Adding custom metrics to a function works differently than traditional monitoring. The traditional approach involves adding an agent to each machine that collects metrics and periodically sends the data to the monitoring system. But with <em>Function-as-a-service,</em> there is no machine for us to deploy an agent on. An alternative is simply <span>to</span><span> </span><span>send the collected metrics at the end of each function invocation. However, this adds significant latency to each function invocation. Datadog offers a unique alternative based on structured log statements. Counts, gauges, histograms, and checks are simply logged as they are collected and Datadog automatically consumes these statements from CloudWatch Logs.</span></p>
<p>The <kbd>serverless-datadog-metrics</kbd> <span>library </span>(<a href="https://www.npmjs.com/package/serverless-datadog-metrics">https://www.npmjs.com/package/serverless-datadog-metrics</a>)  facilitates using this approach. We simply wrap the handler function with the <kbd>monitor</kbd> function and it will collect useful metrics, such as cold starts, errors, execution time, memory, and CPU utilization as well as the latency of HTTP resources. The HTTP metrics are very valuable. All HTTP calls to resources, such as DynamoDB, S3, and Kinesis, are automatically recorded so that we can see how much time a function spends waiting on its external resources.</p>
<p>This library also exports low-level functions, such as <kbd>count</kbd>, <kbd>gauge</kbd>, and <kbd>histogram</kbd>, to support additional custom metrics. The environment valuables, such as <kbd>ACCOUNT_NAME</kbd> and <kbd>SERVERLESS_PROJECT</kbd>, are used as tags for filtering metrics in dashboards and alerts.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monitoring domain events</h1>
                </header>
            
            <article>
                
<p>In traditional systems, we typically focus on observing the behavior of synchronous requests. However, our cloud-native systems are highly asynchronous and event-driven. Therefore, we need to place equal or greater attention on the flow of domain events through the system so that we can determine when these flows deviate from the norm. This recipe demonstrates how to collect domain event metrics.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Before starting this recipe, you will need an AWS Kinesis Stream, such as the one created in the <em>Creating an event stream</em> recipe.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Create the project from the following template:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch7/event-metrics --path cncb-event-metrics</pre>
<ol start="2">
<li>Navigate to the <kbd>cncb-event-metrics</kbd> directory<span> with </span><kbd>cd cncb-event-metrics</kbd>.</li>
<li>Review the file named <kbd>serverless.yml</kbd>.</li>
<li>Review the file named <kbd>handler.js</kbd> with the following content:</li>
</ol>
<pre style="padding-left: 30px">module.exports.<strong>listener</strong> = (event, context, cb) =&gt; {<br/>  _(event.Records)<br/>    .map(recordToUow)<br/>    .tap(<strong>count</strong>)<br/>    ...<br/>    .collect().toCallback(cb);<br/>};<br/><br/>const <strong>count</strong> = (uow) =&gt; {<br/>  const tags = [<br/>    `account:${process.env.ACCOUNT_NAME}`,<br/>    `region:${uow.record.awsRegion}`,<br/>    `stream:${uow.record.eventSourceARN.split('/')[1]}`,<br/>    `shard:${uow.record.eventID.split('-')[1].split(':')[0]}`,<br/>    `source:${uow.event.tags &amp;&amp; uow.event.tags.source || 'not-specified'}`,<br/>    `type:${uow.event.type}`,<br/>  ];<br/><br/>  console.log(`<strong>MONITORING</strong>|${uow.event.timestamp}|1|<strong>count</strong>|domain.event|#${tags.join()}`);<br/>};<br/><br/>...</pre>
<ol start="5">
<li>Install the dependencies<span> with </span><kbd>npm install</kbd>.</li>
<li>Run the tests<span> with </span><kbd>npm test -- -s $MY_STAGE</kbd>.</li>
<li>Review the contents generated in the <kbd>.serverless</kbd> directory.</li>
<li>Deploy the stack: <kbd>npm run dp:lcl -- -s $MY_STAGE</kbd>.</li>
<li>Review the stack and resources in the AWS Console.</li>
<li>Invoke the <kbd>simulate</kbd> function with the following command:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ sls invoke -f simulate -r us-east-1 -s $MY_STAGE<br/></strong><br/>[<br/>    {<br/>        "total": 4500,<br/>        "purple": 1151,<br/>        "green": 1132,<br/>        "blue": 1069,<br/>        "orange": 1148<br/>    }<br/>]</pre>
<ol start="11">
<li>Take a look at the logs:</li>
</ol>
<pre style="padding-left: 30px"><strong>$ sls logs -f listener -r us-east-1 -s $MY_STAGE</strong><br/>...<br/>... <strong>MONITORING</strong>|1531020609200|1|<strong>count</strong>|domain.event|#account:cncb,...,type:purple</pre>
<ol start="12">
<li>Explore the event metrics in Datadog under <span class="packt_screen">Metrics</span> <em>|</em> <span class="packt_screen">Explore with Graph</span>: <kbd>domain.event</kbd> and one graph per <kbd>type</kbd>.</li>
<li>Remove the stack once you are finished: <kbd>npm run rm:lcl -- -s $MY_STAGE</kbd>.</li>
</ol>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Monitoring events works similarly to collecting events in the data lake. A single stream processor observes all events from all streams and simply counts the domain events by event <kbd>type</kbd>, along with additional tags, such as <kbd>region</kbd>, <kbd>stream</kbd>, and <kbd>source</kbd>. Again, these counts are recorded as structured log statements and Datadog consumes these statements from CloudWatch Logs. Graphing the domain event metrics in a dashboard can provide great insight into the behavior of a system. We will see how to alert about the flow of domain events in the <em>Creating alerts</em> recipe. We also perform special handling for <kbd>fault</kbd> events. For these events, we invoke the Datadog Event API, which provides for sending additional contextual information, such as a stack trace. We will discuss <kbd>fault</kbd> events in <a href="5c400ff6-91da-4782-9369-549622d4a0d1.xhtml">Chapter 8</a>, <em>Designing for Failure</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating alerts</h1>
                </header>
            
            <article>
                
<p>To maximize our confidence in our cloud-native services, we need to be alerted about issues ahead of the end users so that we can respond quickly and minimize the mean time to recovery. This also means that we need to eliminate alert fatigue and only alert on what really matters, otherwise important alerts will be lost in the noise. This recipe demonstrates how to create alerts on key metrics.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Log in to your Datadog account.</li>
<li>Create an IAM alert with the following settings:
<ul>
<li>Select <span class="packt_screen">Monitors</span> | <span class="packt_screen">New Monitor</span> | <span class="packt_screen">Event</span></li>
<li>Match events from <kbd>Amazon Cloudtrail</kbd> over <kbd>aws-service:iam</kbd></li>
<li><span class="packt_screen">Multi Alert</span><span>—</span><kbd>aws_account</kbd></li>
<li><span class="packt_screen">Alert threshold</span><span>—</span><kbd>above 0</kbd></li>
<li><span class="packt_screen">Title</span><span>—</span><kbd>aws.iam</kbd></li>
<li><span class="packt_screen">Include trigger tags</span><span>—</span><kbd>true</kbd></li>
<li><span class="packt_screen">Notify</span><span>—</span><kbd>yourself</kbd></li>
</ul>
</li>
</ol>
<ol start="3">
<li>Create an iterator age alert with the following settings:
<ul>
<li>Select <span class="packt_screen">Monitors</span> | <span class="packt_screen">New Monitor</span> | <span class="packt_screen">Integration</span> | <span class="packt_screen">AWS Lambda</span></li>
<li><span class="packt_screen">Metric</span><span>—</span><kbd>aws.lambda.iterator_age</kbd></li>
<li><span class="packt_screen">Max by</span><span>—</span><kbd>functionname</kbd>, <kbd>region</kbd> and <kbd>account</kbd></li>
<li><span class="packt_screen">Multi Alert</span><span>—</span><kbd>functionname</kbd>, <kbd>region</kbd> and <kbd>account</kbd></li>
<li><span class="packt_screen">Alert threshold</span><span>—</span><kbd>7200000</kbd> (2 hrs)</li>
<li><span class="packt_screen">Warning threshold</span><span>—</span><kbd>1800000</kbd>  (0.5 hrs)</li>
<li><span class="packt_screen">Title</span><span>—</span><kbd>aws.lambda.iterator_age</kbd></li>
<li><span class="packt_screen">Include trigger tags</span><span>—</span><kbd>true</kbd></li>
<li><span class="packt_screen">Notify</span><span>—</span><kbd>yourself</kbd></li>
</ul>
</li>
<li>Create a request rate alert with the following settings:
<ul>
<li>Select <span class="packt_screen">Monitors</span> | <span class="packt_screen">New Monitor</span> | <span class="packt_screen">Anomaly</span></li>
<li><span class="packt_screen">Metric</span><span>—</span><kbd>aws.apigateway.count</kbd></li>
<li><span class="packt_screen">Average by</span><span>—</span><kbd>apiname</kbd>, <kbd>region</kbd>, and <kbd>account</kbd> as <kbd>rate</kbd></li>
<li><span class="packt_screen">Multi Alert</span><span>—</span><kbd>apiname</kbd>, <kbd>region</kbd>, and <kbd>account</kbd></li>
<li><span class="packt_screen">Alert conditions</span><span>—</span>start with the defaults and tune to your data</li>
<li><span class="packt_screen">Title</span><span>—</span><kbd>aws.apigateway.rate</kbd></li>
<li><span class="packt_screen">Include trigger tags</span><span>—</span><kbd>true</kbd></li>
<li><span class="packt_screen">Notify</span><span>—</span><kbd>yourself</kbd></li>
</ul>
</li>
<li>Create a domain event rate alert with the following settings:
<ul>
<li>Select <span class="packt_screen">Monitors</span> | <span class="packt_screen">New Monitor</span> | <span class="packt_screen">Anomaly</span></li>
<li><span class="packt_screen">Metric</span><span>—</span><kbd>domain.event</kbd></li>
<li><span class="packt_screen">Average by</span><span>—</span><kbd>type</kbd>, <kbd>region</kbd>, and <kbd>account</kbd> as <kbd>rate</kbd></li>
<li><span class="packt_screen">Multi Alert</span><span>—</span><kbd>type</kbd>, <kbd>region</kbd>, and <kbd>account</kbd></li>
<li><span class="packt_screen">Alert conditions</span><span>—</span>Start with the defaults and tune to your data</li>
<li><span class="packt_screen">Title</span><span>—</span><kbd>domain.event.rate</kbd></li>
<li><span class="packt_screen">Include trigger tags</span><span>—</span><kbd>true</kbd></li>
<li><span class="packt_screen">Notify</span><span>—</span><kbd>yourself</kbd></li>
</ul>
</li>
<li>Create a Fault Event alert with the following settings:
<ul>
<li>Select <span class="packt_screen">Monitors</span> | <span class="packt_screen">New Monitor</span> | <span class="packt_screen">Event</span></li>
<li><span class="packt_screen">Match events containing</span><span>—</span><kbd>Fault Event</kbd> with status <kbd>error</kbd> from: <kbd>My Apps</kbd></li>
<li><span class="packt_screen">Multi Alert</span><span>—</span><kbd>functionname</kbd>, <kbd>region</kbd>, and <kbd>account</kbd></li>
<li><span class="packt_screen">Alert threshold</span><span>—</span><kbd>above 0</kbd></li>
<li><span class="packt_screen">Title</span><span>—</span><kbd>fault.event</kbd></li>
<li><span class="packt_screen">Include trigger tags</span><span>—</span><kbd>true</kbd></li>
<li><span class="packt_screen">Notify</span><span>—</span><kbd>yourself</kbd></li>
</ul>
</li>
</ol>
<div class="packt_infobox">Datadog autocomplete menus are populated based on the metrics that have been recently collected.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Now that our system is observable, we need to do something proactive and useful with all this data. There is simply too much data to process manually and our confidence will only be increased if we can turn this data into valuable, timely information. We will certainly use this data for root-cause and post-mortem analysis, but our confidence is increased by our focus on mean time to recovery. Therefore, we need to create monitors that are constantly <em>testing</em> the data, turning it into information and alerting on what matters. However, we must be careful to avoid alert fatigue. The best practice is to alert liberally, but page judiciously on symptoms rather than causes. For example, we should create many monitors that only record that a threshold was crossed so that this additional information can be used in the root-cause analysis. Other monitors will email the team to warn of a potential problem, but a few select monitors will page the team to jump into immediate action.</p>
<p>To know the difference between a symptom and a cause, we categorize our metrics into work metrics and resource metrics. Work metrics represent the user-visible output of the system. Resource metrics represent the internal workings of the system. Our resource monitors will usually record and send warnings, and our work monitors will page the team. The RED method (<a href="https://dzone.com/articles/red-method-for-prometheus-3-key-metrics-for-micros">https://dzone.com/articles/red-method-for-prometheus-3-key-metrics-for-micros</a>) and the USE method (<a href="https://dzone.com/articles/red-method-for-prometheus-3-key-metrics-for-micros">https://dzone.com/articles/red-method-for-prometheus-3-key-metrics-for-micros</a>) break these categories down further. <strong>RED</strong> stands for <strong>Rate, Error, and Duration</strong>. When a critical service has a significant decrease in the rate of requests or events or a significant increase in errors, or latency significantly increases, then these may warrant paging the team. <strong>USE</strong> stands for <strong>Utilization</strong>, <strong>Saturation</strong>, and <strong>Errors</strong>. When the utilization of a resource, such as DynamoDB or Kinesis, reaches a certain level then it is probably good to warn the team. However, saturation and/or errors, such as throttling, may just warrant recording, because they may quickly subside or, if prolonged, they will trigger the work monitors.</p>
<p>This recipe demonstrated a few possible monitors. The <kbd>fault</kbd> monitor represents work that is failing and must be addressed. The stream <kbd>iterator age</kbd> monitor straddles the line, because it could represent temporary resource saturation, or it could represent an error that is causing work to back up. Therefore, it has both a warning and an alert at different thresholds. The <kbd>anomaly detection</kbd> monitors should focus on work metrics, such as the rate of critical requests or domain events. It is also a good idea to monitor CloudTrail for any IAM changes, such as to roles and permissions.</p>
<p>The <kbd>notification</kbd> step is optional if you only need to record the condition. To warn the team, send the notification to chat and/or group email. To page the team, send the notification to an SNS topic. It is best to use the <span class="packt_screen">Multi Alert</span> feature, triggered on pertinent tags, and include these in the notification title so that this information is available at a glance.</p>
<p>Ultimately, to be valuable and to avoid fatigue, these monitors need care and feeding. These monitors are your tests in production. As your team's understanding of your system increases, then you will uncover better tests/monitors. When your monitors produce false positives, they will need to be tuned or eliminated. Your level of confidence is the true measure of successful monitoring.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating synthetic transaction tests</h1>
                </header>
            
            <article>
                
<p>If a tree falls in a forest and no one is around to hear it, does it make a sound? Or more on topic, if a deployment is broken in a region and no one is awake to use it, does it make a difference? Of course, the answer is yes. We want to be alerted about the broken deployment so that it can be fixed before normal traffic begins. To enable this, we need to continuously pump synthetic traffic through the system so that there is a continuous signal to test. This recipe demonstrates how to generate synthetic traffic using cloud-provider-agnostic, third-party services.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Before starting this recipe, you will need a Pingdom account (<a href="https://www.pingdom.com">https://www.pingdom.com</a>). You will also need an AWS Cognito user pool, such as the one created in the <em>Creating a federated identity pool</em> recipe.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<ol>
<li>Create the project from the following template:</li>
</ol>
<pre style="padding-left: 30px">$ sls create --template-url https://github.com/danteinc/js-cloud-native-cookbook/tree/master/ch7/synthetics --path cncb-synthetics</pre>
<ol start="2">
<li>Navigate to the <kbd>cncb-synthetics</kbd> directory <kbd>cd cncb-synthetics</kbd>.</li>
<li>Install the dependencies with <kbd>npm install</kbd>.</li>
<li>Review the file named <kbd>src/App.js</kbd> and update the <kbd>clientId</kbd> and <kbd>domain</kbd> fields with the values for the user pool stack.</li>
<li>Build the app<span> with </span><kbd>npm run build</kbd>.</li>
<li>Deploy the stack:</li>
</ol>
<div style="padding-left: 120px" class="packt_infobox">Deploying a CloudFront distribution can take upward of 20 minutes.</div>
<pre style="padding-left: 30px"><strong>$ </strong><strong>npm run dp:lcl -- -s $MY_STAGE</strong><br/><br/>&gt; cncb-synthetics@1.0.0 dp:lcl &lt;path-to-your-workspace&gt;/cncb-synthetics<br/>&gt; sls deploy -r us-east-1 --account cncb "-s" "john"<br/>...<br/><strong>WebsiteDistributionURL</strong>: https://dqvo8ga8z7ao3.cloudfront.net</pre>
<ol start="7">
<li>Update the <kbd>callbackURLs</kbd> and <kbd>logoutURLs</kbd> of the user pool stack to include <kbd>WebsiteDistributionURL</kbd> and then redeploy it.</li>
<li>Browse to <kbd>WebsiteDistributionURL</kbd> provided in the stack output to test the site configuration.</li>
<li>Log in to your Pingdom account.</li>
<li>Create an uptime check with the following settings:
<ul>
<li>Select <span class="packt_screen">Experience Monitoring</span> | <span class="packt_screen">Uptime</span> | <span class="packt_screen">Add check</span>.</li>
<li>Name<span>—</span><kbd>cncb-synthetics</kbd>.</li>
<li>Check interval<span>—</span><kbd>1 minute</kbd></li>
<li>URL<span>—</span><kbd>WebsiteDistributionURL from your deploy output</kbd></li>
</ul>
</li>
</ol>
<ol start="11">
<li>Review the <span class="packt_screen">Experience Monitoring</span> <em>|</em> <span class="packt_screen">Uptime</span> dashboard periodically.</li>
<li>Create a real user monitor with the following settings:<br/>
<ul>
<li>Select <span class="packt_screen">Experience Monitoring</span> | <span class="packt_screen">Visitor Insights (RUM)</span> | <span class="packt_screen">Add site</span>.</li>
<li>Name<span>—</span><kbd>cncb-synthetics</kbd></li>
<li>URL<span>—</span><kbd>WebsiteDistributionURL from your deploy output</kbd></li>
</ul>
</li>
<li>Review the file named <kbd>public/index.html</kbd>, uncomment the following code, and replace the ID with the value from the generated code snippet:</li>
</ol>
<pre style="padding-left: 30px">    &lt;!--<br/>    &lt;script src="//rum-static.pingdom.net/<strong>ID</strong>.js" async&gt;&lt;/script&gt;<br/>    --&gt;</pre>
<ol start="14">
<li>Build and redeploy the app:</li>
</ol>
<pre style="padding-left: 30px">$ npm run build<br/>$ npm run dp:lcl -- -s $MY_STAGE</pre>
<ol start="15">
<li>Review the <span class="packt_screen">Experience Monitoring</span> | <span class="packt_screen">Visitor Insights (RUM)</span> dashboard periodically.</li>
<li>Create a Synthetic Transaction test with the following settings:<br/>
<ul>
<li>Select <span class="packt_screen">Experience Monitoring</span> | <span class="packt_screen">Transactions</span> | <span class="packt_screen">Add check</span><em><br/></em></li>
<li>Name<span>—</span><kbd>cncb-synthetics</kbd></li>
<li>Test interval<span>—</span><kbd>10 minutes</kbd></li>
<li>Go to the URL <kbd>WebsiteDistributionURL from deploy output</kbd></li>
<li>Fill in the <kbd>username</kbd> <span>field </span><span>with</span> <kbd>your-username</kbd></li>
<li>Fill in the <kbd>password</kbd> <span>field </span><span>with</span> <kbd>your-password</kbd></li>
<li>Click <span class="packt_screen">Sign In</span></li>
<li>Wait for the element <kbd>.App-title</kbd> <span>to contain</span> <kbd>Welcome to React</kbd></li>
</ul>
</li>
</ol>
<ol start="17">
<li>Review the <span class="packt_screen">Experience Monitoring</span> <em>|</em> <span class="packt_screen">Transactions</span> dashboard periodically.</li>
<li>Remove the stack once you are finished<span> with </span><kbd>npm run rm:lcl -- -s $MY_STAGE</kbd>.</li>
<li>Cancel your Pingdom free trial, under <span class="packt_screen">Account</span> | <span class="packt_screen">Subscriptions</span> | <span class="packt_screen">Manage Plan</span>, before the 14 days expire, to avoid costs.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Testing in production is different than traditional preproduction testing. As demonstrated in the <em>Creating alerts</em> recipe, our production tests are implemented as monitors that are constantly testing the signals emitted by the system. However, if there is no traffic, then there is no signal, and so no tests to alert us to problems in any deployments that happen during these periods. This, in turn, decreases our confidence in these deployments. The solution is to generate steady synthetic traffic to fill in the gaps when there is no natural traffic.</p>
<p>Uptime checks are the simplest to put in place because they only make a single request. These should be included at a minimum, because they can be put in place quickly with little effort and because they have the highest frequency. <strong>Real User Monitoring</strong> (<strong>RUM</strong>) should be included because it only requires a simple code modification and because a significant amount of the user performance experience in cloud-native systems is executed in the browser by single-page applications. Finally, a small but strategic set of synthetic transaction scripts needs to be implemented to smoke test crucial features<span> </span><span>continuously</span><span>. These scripts resemble traditional test scripts, but their focus is on continuously exercising these critical happy paths to ensure that the crucial features are unaffected by the continuous deployment of new features.</span></p>


            </article>

            
        </section>
    </body></html>