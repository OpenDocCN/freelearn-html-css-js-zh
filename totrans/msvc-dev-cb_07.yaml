- en: Monitoring and Observability
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控和可观察性
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍以下配方：
- en: Structured JSON logging
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结构化 JSON 记录
- en: Collecting metrics with StatsD and Graphite
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 StatsD 和 Graphite 收集指标
- en: Collecting metrics with Prometheus
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Prometheus 收集指标
- en: Making debugging easier with tracing
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用跟踪简化调试
- en: Alerting when something goes wrong
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当出现问题时发出警报
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: Microservices add complexity to an architecture. With more moving parts in a
    system, monitoring and observing the behavior of the system becomes more important
    and more challenging. In a microservice architecture, failure conditions impacting
    one service can cascade in unexpected ways, impacting the system as a whole. A
    faulty switch somewhere in a datacenter may be causing unusually high latency
    for a service, perhaps resulting in intermittent timeouts in requests originating
    from the API Gateway, which may result in unexpected user impact, which results
    in an alert being fired. This kind of scenario is not uncommon in a microservice
    architecture and requires forethought so that engineers can easily determine the
    nature of customer-impacting incidents. Distributed systems are bound to experience
    certain failures and special consideration must be taken to build observability
    into systems.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务增加了架构的复杂性。随着系统中移动部件的增加，监控和观察系统的行为变得更加重要和更具挑战性。在微服务架构中，影响一个服务的故障条件可能会以意想不到的方式级联，影响整个系统。数据中心某个地方的故障交换机可能正在导致某个服务的异常高延迟，这可能导致来自
    API 网关的请求间歇性超时，这可能导致意外的用户影响，从而触发警报。这种场景在微服务架构中并不罕见，需要提前考虑，以便工程师可以轻松确定影响客户的故障的性质。分布式系统注定会经历某些故障，必须特别考虑将可观察性构建到系统中。
- en: Another shift that microservices have necessitated is the move to DevOps. Many
    traditional monitoring solutions were developed at a time when operations were
    the sole responsibility of a special and distinct group of system administrators
    or operations engineers. System administrators and operations engineers are often
    interested in system-level or host-level metrics, such as CPU, memory disk, and
    network usage. These metrics are important but only make up a small part of observability.
    **Observability** must also be considered by engineers writing microservices. It's
    equally important to use metrics to be able to observe events unique to a system,
    such as certain types of exceptions being thrown or the number of events emitted
    to a queue.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务还迫使我们需要转向 DevOps。许多传统的监控解决方案是在操作是系统管理员或操作工程师特殊且独立群体唯一责任的时代开发的。系统管理员和操作工程师通常对系统级或主机级指标感兴趣，例如
    CPU、内存、磁盘和网络使用情况。这些指标很重要，但只是可观察性的一小部分。**可观察性**也必须由编写微服务的工程师考虑。使用指标来观察系统特有的事件同样重要，例如抛出某些类型的异常或发送到队列的事件数量。
- en: Planning for observability also gives us the information we need to effectively
    test systems in production. Ephemeral environments for staging and integration
    testing can be useful, but there are entire classes of failure states that they
    are unable to test for. As discussed in [Chapter 5](b569ef24-285f-40bf-97b0-0ac9c1a79494.xhtml),
    *Reliability Patterns*, Gamedays and other forms of failure injection are critical
    for improving the resilience of systems. Observable systems lend themselves to
    this kind of testing, allowing engineers to gain confidence in our understanding
    of the system.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 规划可观察性也为我们提供了在生产环境中有效测试系统所需的信息。用于预演和集成测试的临时环境可能很有用，但它们无法测试整个类别的故障状态。如第 5 章[可靠性模式](b569ef24-285f-40bf-97b0-0ac9c1a79494.xhtml)中所述，Gamedays
    和其他形式的故障注入对于提高系统的弹性至关重要。可观察的系统适合这种测试，使工程师能够对我们的系统理解充满信心。
- en: In this chapter, we'll introduce several tenants of monitoring and observability.
    We'll demonstrate how to modify our services to emit structured logs. We'll also
    take a look at metrics, using a number of different systems for collecting, aggregating,
    and visualizing metrics. Finally we'll look at tracing, a way to look at requests
    as they travel through various components of a system and alert us when user-impacting
    error conditions are detected.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍监控和可观察性的几个原则。我们将演示如何修改我们的服务以生成结构化日志。我们还将查看指标，使用多个不同的系统来收集、聚合和可视化指标。最后，我们将探讨跟踪，这是一种查看请求如何穿越系统的各个组件的方法，并在检测到影响用户的错误条件时发出警报。
- en: Structured JSON logging
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结构化 JSON 记录
- en: Outputting useful logs is a key part of building an observable service. What
    constitutes a useful log is subjective, but a good set of guidelines is that logs
    should contain timestamped information about key events in a system. A good logging
    system supports the notion of configurable log levels, so the amount of information
    sent to logs can be dialed up or down for a specific amount of time depending
    on the needs of engineers working with the system. For example, when testing a
    service against failure scenarios in production, it may be useful to turn up the
    log level and get more detail about events in the system.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 输出有用的日志是构建可观察服务的关键部分。有用的日志构成是主观的，但一个好的指导原则是日志应包含关于系统关键事件的带时间戳的信息。一个好的日志系统支持可配置的日志级别概念，因此可以根据工程师的需求在特定时间内调整发送到日志的信息量。例如，当在生产环境中测试服务的故障场景时，提高日志级别并获取系统事件的更多详细信息可能是有用的。
- en: The two most popular logging libraries for Java applications are **Log4j** ([https://logging.apache.org/log4j/2.x/](https://logging.apache.org/log4j/2.x/))
    and **Logback** ([https://logback.qos.ch/](https://logback.qos.ch/)). By default,
    both of these libraries will emit log entries in an unstructured format, usually
    space-separated fields including information such as a timestamp, log level, and
    message. This is useful, but especially so in a microservices architecture, where
    multiple services are emitting event logs possibly to a centralized log store;
    it's extremely useful to emit structured logs with some consistency.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Java 应用程序中最受欢迎的两个日志库是 **Log4j** ([https://logging.apache.org/log4j/2.x/](https://logging.apache.org/log4j/2.x/))
    和 **Logback** ([https://logback.qos.ch/](https://logback.qos.ch/))。默认情况下，这两个库将以非结构化格式输出日志条目，通常是空格分隔的字段，包括时间戳、日志级别和消息等信息。这很有用，但在微服务架构中尤其有用，其中多个服务可能向集中日志存储输出事件日志；输出具有一致性的结构化日志非常有用。
- en: JSON has become a common standard for passing messages between systems. Nearly
    every popular language has libraries for parsing and generating JSON. It's lightweight,
    yet structured, making it a good choice for data, such as event logs. Emitting
    event logs in JSON makes it easier to feed your service's logs into a centralized
    store and have log data analyzed and queried.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 已经成为在系统间传递消息的通用标准。几乎每种流行的语言都有解析和生成 JSON 的库。它轻量级，但结构化，使其成为事件日志等数据的好选择。以
    JSON 格式输出事件日志使得将服务日志输入集中存储并分析查询日志数据变得更加容易。
- en: In this recipe, we'll modify our message-service to emit logs using the popular
    `logback` library for Java applications.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将修改我们的消息服务以使用流行的 `logback` 库来生成 Java 应用程序的日志。
- en: How to do it...
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Let''s have a look at the following steps:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下步骤：
- en: 'Open the message-service project from [Chapter 6](5c67f295-78fb-4ae9-a596-39f384f6e9f2.xhtml),
    *Security*. The first change we''ll make is to add the `logback` library to the
    `build.gradle` file:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 [第 6 章](5c67f295-78fb-4ae9-a596-39f384f6e9f2.xhtml)，*安全*，打开消息服务项目。我们将做的第一个更改是向
    `build.gradle` 文件中添加 `logback` 库：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Create a `logback.xml` configuration file. In the configuration file, we''ll
    create a single logger, called `jsonLogger`, that references a single appender,
    called `consoleAppender`:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 `logback.xml` 配置文件。在配置文件中，我们将创建一个名为 `jsonLogger` 的单个记录器，它引用一个名为 `consoleAppender`
    的单个追加器：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Add a single sample log message to `Application.java` to test our new logging
    configuration:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将单个示例日志消息添加到 `Application.java` 以测试我们新的日志配置：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Run the application and see that log messages are now emitted in JSON:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行应用程序并查看日志消息现在以 JSON 格式输出：
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Collecting metrics with StatsD and Graphite
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 StatsD 和 Graphite 收集指标
- en: Metrics are numeric measurements over time. The most common types of metrics
    collected in our systems are counters, timers, and gauges. A counter is exactly
    what it sounds like, a value that is incremented a number of times over some time
    period. A timer can be used to measure recurring events in a system, such as the
    amount of time it takes to serve a request or perform a database query. Gauges
    are just arbitrary numeric values that can be recorded.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 指标是随时间变化的数值测量。我们系统中收集的最常见的指标类型是计数器、计时器和仪表。计数器正是其名称的含义，在一定时间内增加一定次数的值。计时器可以用来测量系统中的重复事件，例如处理请求或执行数据库查询所需的时间。仪表只是可以记录的任意数值。
- en: '**StatsD** is an open source network daemon invented in 2011 at Etsy. Metrics
    data is pushed to a `statsd` server, often on the same server, which aggregates
    data before sending it on to a durable backend. One of the most common backends
    used with `statsd` is **Graphite**, an open source time-series storage engine
    and graphing tool. Together, Graphite and StatsD make up a very popular metrics
    stack. They''re easy to get started with and enjoy large communities and a large
    selection of tools and libraries.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**StatsD** 是一个开源的网络守护进程，于 2011 年在 Etsy 发明。指标数据被推送到一个 `statsd` 服务器，通常在同一服务器上，在发送到持久后端之前聚合数据。与
    `statsd` 一起使用最常用的后端之一是 **Graphite**，一个开源的时间序列存储引擎和绘图工具。Graphite 和 StatsD 一起构成了一个非常流行的指标栈。它们易于入门，拥有庞大的社区和大量的工具和库。'
- en: Spring Boot has a sub-project called **Actuator** that adds a number of production
    readiness features to a service. Actuator gives us our services certain metrics
    for free, together with a project called micrometer, Actuator enables a vendor-neutral
    API to various metric's backends. We'll use Actuator and micrometer in this recipe
    and the next one.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot 有一个名为 **Actuator** 的子项目，它为服务添加了多个生产就绪功能。Actuator 为我们的服务免费提供了一些指标，与名为
    micrometer 的项目一起，Actuator 实现了一个对各种指标后端的供应商中立 API。我们将在这个菜谱和下一个菜谱中使用 Actuator 和
    micrometer。
- en: In this recipe, we'll add Actuator to the message-service we've worked with
    in previous recipes. We'll create a few custom metrics and demonstrate using `statsd`
    and `graphite` to graph metrics from our application. We'll run `statsd` and `graphite`
    locally in docker containers.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将向之前菜谱中使用的 message-service 添加 Actuator。我们将创建一些自定义指标，并演示如何使用 `statsd`
    和 `graphite` 绘制应用程序的指标。我们将在本地 docker 容器中运行 `statsd` 和 `graphite`。
- en: How to do it...
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点……
- en: 'Let''s look at the following steps:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下步骤：
- en: 'Open the message-service project from previous recipes. We''re going to upgrade
    the version of Spring Boot and add `actuator` and `micrometer` to our list of
    dependencies. Modify the `build.gradle` file to look like the following:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开之前菜谱中的 message-service 项目。我们将升级 Spring Boot 的版本，并将 `actuator` 和 `micrometer`
    添加到我们的依赖列表中。修改 `build.gradle` 文件，使其看起来如下所示：
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Open `application.yml` in the `src/main/resources` directory and add the following:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `src/main/resources` 目录下打开 `application.yml` 文件，并添加以下内容：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Our application now supports emitting metrics to a locally-running instance
    of `statsd`. Open `MessageController.java` and add the `Timed` annotation to the
    class as well as the `get` method:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的应用程序现在支持向本地运行的 `statsd` 实例发出指标。打开 `MessageController.java` 文件，并将 `Timed`
    注解添加到类以及 `get` 方法中：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In order to demonstrate that metrics are actually being emitted, we''ll run
    `statsd` and graphite locally in a docker container. Having installed `docker`,
    run the following command, which will pull down an image from `dockerhub` and
    run a container locally:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了证明指标实际上正在发出，我们将在本地 docker 容器中运行 `statsd` 和 graphite。安装了 `docker` 后，运行以下命令，它将从
    `dockerhub` 拉取一个镜像并在本地运行一个容器：
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now, visit `http://localhost` to see your metrics!
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，访问 `http://localhost` 来查看你的指标！
- en: Collecting metrics with Prometheus
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Prometheus 收集指标
- en: '**Prometheus** is an open source monitoring and alerting toolkit originally
    developed in 2012 at **SoundCloud**. It was inspired by Borgmon at Google. In
    contrast to the push model employed by systems such as `statsd`, Prometheus uses
    a pull model for collecting metrics. Instead of each service being responsible
    for pushing metrics to a `statsd` server, Prometheus is responsible for scraping
    an endpoint exposed by services that have metrics. This inversion of responsibilities
    provides some benefits when operating metrics at scale. Targets in Prometheus
    can be configured manually or via service discovery.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**Prometheus** 是一个开源的监控和警报工具包，最初于 2012 年在 **SoundCloud** 开发。它受到了谷歌的 Borgmon
    的启发。与 `statsd` 等系统采用的推送模型不同，Prometheus 使用拉模型来收集指标。不是每个服务都负责将指标推送到 `statsd` 服务器，而是
    Prometheus 负责抓取具有指标的服务公开的端点。这种责任反转在按比例操作指标时提供了一些好处。Prometheus 中的目标可以手动配置或通过服务发现配置。'
- en: In contrast to the hierarchical format that systems such as Graphite use to
    store metrics data, Prometheus employs a multidimensional data model. Time-series
    data in Prometheus is identified by a metric name (such as `http_request_duration_seconds`)
    and one or more labels (such as `service=message-service` and `method=POST`).
    This format can make it easier to standardize metrics across a number of different
    applications, which is particularly valuable in a microservices architecture.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 与使用分层格式存储指标数据的系统（如 Graphite）相比，Prometheus 采用多维数据模型。Prometheus 中的时间序列数据由一个指标名称（例如
    `http_request_duration_seconds`）和一个或多个标签（例如 `service=message-service` 和 `method=POST`）标识。这种格式可以更容易地在多个不同的应用程序之间标准化指标，这在微服务架构中尤其有价值。
- en: In this recipe, we'll continue to use message-service and the Actuator and micrometer
    libraries. We'll configure micrometer to use the Prometheus metrics registry and
    we'll expose an endpoint that Prometheus can scrape in order to collect metrics
    from our service. We'll then configure Prometheus to scrape the message-service
    (running locally) and run Prometheus locally to verify that we can query our metrics.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将继续使用 message-service 以及 Actuator 和 micrometer 库。我们将配置 micrometer 以使用
    Prometheus 指标注册表，并公开 Prometheus 可以抓取以收集我们服务指标的端点。然后我们将配置 Prometheus 以抓取运行在本地的
    message-service，并在本地运行 Prometheus 以验证我们是否可以查询我们的指标。
- en: How to do it...
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Open the message-service and edit `build.gradle` to include actuator and the
    micrometer-prometheus dependencies:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开消息服务并编辑 `build.gradle` 文件，以包含 actuator 和 micrometer-prometheus 依赖项：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Add the following to `application.yml`. This will enable an endpoint that exposes
    metrics collected in the Prometheus metrics registry. Notice that we''re opening
    another port for the management endpoints added by `actuator`:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下内容添加到 `application.yml` 中。这将启用一个端点，该端点公开 Prometheus 指标注册表中收集的指标。请注意，我们正在为
    `actuator` 添加的管理端点打开另一个端口：
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can now test that our service is exposing metrics on the `/manage/prometheus`
    endpoint. Run the service and make the following `curl` request:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以测试我们的服务是否在 `/manage/prometheus` 端点公开指标。运行服务并执行以下 `curl` 请求：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Configure and run Prometheus in a docker container. Create a new file in the
    `/tmp` directory, called `prometheus.yml`, with information about our target:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `/tmp` 目录中创建一个名为 `prometheus.yml` 的新文件，其中包含有关我们的目标信息，并配置和运行 Prometheus 在 Docker
    容器中：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Download and extract the version of Prometheus for your platform. Instructions
    are on the Prometheus website ([https://prometheus.io/docs/introduction/first_steps/](https://prometheus.io/docs/introduction/first_steps/)).
    Run Prometheus with the configuration file we created in the previous step:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并解压适用于您平台的 Prometheus 版本。说明在 Prometheus 网站上（[https://prometheus.io/docs/introduction/first_steps/](https://prometheus.io/docs/introduction/first_steps/)）。使用我们在上一步创建的配置文件运行
    Prometheus：
- en: '[PRE12]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Open `http://localhost:9090` in your browser to issue Prometheus queries and
    see your metrics! Until you start making requests to your service, the only metrics
    you'll see will be the JVM and system metrics, but this should give you an idea
    of the kind of querying you can do with Prometheus and demonstrate how the scraper
    works.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的浏览器中打开 `http://localhost:9090` 以执行 Prometheus 查询并查看您的指标！在您开始向服务发送请求之前，您将看到的唯一指标将是
    JVM 和系统指标，但这应该能给您一个关于您可以使用 Prometheus 进行何种查询以及演示抓取器如何工作的概念。
- en: Making debugging easier with tracing
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用跟踪简化调试
- en: In a microservices architecture, a single request can go through several different
    services and result in writes to several different data stores and event queues.
    When debugging a production incident, it isn't always clear whether a problem
    exists in one system or another. This lack of specificity means metrics and logs
    only form a small part of the picture. Sometimes we need to zoom out and look
    at the complete life cycle of a request from the user agent to a terminal service
    and back again.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在微服务架构中，单个请求可以经过几个不同的服务，并导致写入几个不同的数据存储和事件队列。在生产事件调试时，并不总是清楚问题是否存在于一个系统或另一个系统中。这种缺乏具体性意味着指标和日志只是整个画面的一小部分。有时我们需要放大并查看从用户代理到终端服务再到用户代理的整个请求生命周期。
- en: In 2010, engineers at Google published a paper describing **Dapper** ([https://research.google.com/archive/papers/dapper-2010-1.pdf](https://research.google.com/archive/papers/dapper-2010-1.pdf)),
    a large-scale distributed systems tracing infrastructure. The paper described
    how Google had been using an internally developed tracing system to aid in observing
    system behavior and debugging performance issues. This work inspired others, including
    engineers at Twitter who, in 2012, introduced an open source distributed tracing
    system called **Zipkin** ([https://blog.twitter.com/engineering/en_us/a/2012/distributed-systems-tracing-with-zipkin.html](https://blog.twitter.com/engineering/en_us/a/2012/distributed-systems-tracing-with-zipkin.html)).
    Zipkin started out as an implementation of the Dapper paper but evolved into a
    full set of tools for analyzing performance and inspecting requests to Twitter
    infrastructure.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在2010年，谷歌的工程师发表了一篇论文，描述了**Dapper** ([https://research.google.com/archive/papers/dapper-2010-1.pdf](https://research.google.com/archive/papers/dapper-2010-1.pdf))，这是一个大规模分布式系统跟踪基础设施。论文中描述了谷歌如何使用内部开发的跟踪系统来帮助观察系统行为和调试性能问题。这项工作启发了其他人，包括Twitter的工程师，他们在2012年引入了一个名为**Zipkin**
    ([https://blog.twitter.com/engineering/en_us/a/2012/distributed-systems-tracing-with-zipkin.html](https://blog.twitter.com/engineering/en_us/a/2012/distributed-systems-tracing-with-zipkin.html))的开源分布式跟踪系统。Zipkin最初是Dapper论文的一个实现，但后来发展成了一套完整的性能分析和检查Twitter基础设施请求的工具。
- en: All of the work going on in the tracing space made apparent a need for some
    kind of standardized API. The **OpenTracing** ([http://opentracing.io/](http://opentracing.io/))
    framework is an attempt to do just that. OpenTracing defines a specification detailing
    a pan-language standard for traces. Many engineers from different companies have
    contributed to this effort, including the engineers at Uber who originally created
    Jaeger ([https://eng.uber.com/distributed-tracing/](https://eng.uber.com/distributed-tracing/)),
    an open source, end-to-end distributed tracing system that conforms to the OpenTracing
    specification.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在跟踪领域进行的所有工作都明显表明需要某种标准化的API。**OpenTracing** ([http://opentracing.io/](http://opentracing.io/))框架正是为此而做的尝试。OpenTracing定义了一个规范，详细说明了跟踪的跨语言标准。许多不同公司的工程师都为此做出了贡献，包括最初创建Jaeger
    ([https://eng.uber.com/distributed-tracing/](https://eng.uber.com/distributed-tracing/))的Uber工程师，Jaeger是一个符合OpenTracing规范的开放源代码、端到端分布式跟踪系统。
- en: In this recipe, we'll modify our message-service to add support for tracing.
    We'll then run Jaeger in a docker container so that we can see a few traces in
    practice.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将修改我们的message-service以添加跟踪支持。然后，我们将在docker容器中运行Jaeger，这样我们就可以在实践中看到一些跟踪信息。
- en: How to do it...
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'Open the message-service project and replace the contents of `build.gradle`
    with the following:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开message-service项目，并用以下内容替换`build.gradle`的内容：
- en: '[PRE13]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Open `application.yml` in the `src/main/resources` directory and add a section
    for `opentracing` configuration. Here we''re configuring our `opentracing` implementation
    to connect to an instance of Jaeger running locally on port `6831`:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`src/main/resources`目录中打开`application.yml`文件，并添加一个`opentracing`配置部分。在这里，我们正在配置我们的`opentracing`实现以连接到本地运行的端口`6831`上的Jaeger实例：
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In order to collect traces, we''ll run an instance of Jaeger locally. Docker
    makes this easy with the following command:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了收集跟踪信息，我们将在本地运行一个Jaeger实例。Docker使用以下命令使这变得简单：
- en: '[PRE15]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Run message-service and make a few example requests (even if they result in
    a 404). Open `http://localhost:16686` in your browser and you'll see Jaeger's
    web UI. Hit search and explore the trace data collected so far!
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行message-service并发出一些示例请求（即使它们导致404）。在浏览器中打开`http://localhost:16686`，你会看到Jaeger的Web界面。点击搜索并探索迄今为止收集到的跟踪数据！
- en: Alerting us when something goes wrong
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当出现问题时提醒我们
- en: If you're seriously looking at microservices, you're probably running a 24/7
    service. Customers demand that your service is available to use at any time. Contrast
    this increase in the need for availability with the reality that distributed systems
    are constantly experiencing some kind of failure. No system is ever completely
    healthy.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在认真考虑微服务，你可能正在运行一个24/7的服务。客户要求你的服务在任何时候都可以使用。将这种对可用性的需求增加与分布式系统不断经历某种故障的现实进行对比。没有系统是完全健康的。
- en: Whether you have a monolith or microservices architecture, it is pointless to
    try to avoid production incidents altogether. Instead, you should try to optimize
    how you are able to respond to failures, limiting their impact on customers by
    reducing the time it takes to resolve them.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你是采用单体架构还是微服务架构，试图完全避免生产事故都是没有意义的。相反，你应该尝试优化你应对故障的方式，通过减少解决故障所需的时间来限制其对客户的影响。
- en: Reducing the time it takes to resolve incidents (often measured as mean time
    to resolve or MTTR) involves first reducing the **Mean Time To Detect** (**MTTD**).
    Being able to accurately alert the right on-call engineer when a service is in
    a customer-impacting failure state is paramount to being able to maintain uptime.
    Good alerts should be actionable and urgent; if your system notifies on-call engineers
    when failures are either unactionable or non-urgent (not customer-impacting),
    you risk burning out on-call engineers and creating what is commonly referred
    to as alert fatigue. Alert fatigue is very real and can have a more catastrophic
    impact on uptime than any amount of software bugs or failing hardware. It is essential
    to continuously improve your system's alerting to get thresholds and other factors
    just right, to prevent false positives while maintaining alerting for truly customer-impacting
    incidents.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 减少解决事故所需的时间（通常以平均解决时间或MTTR衡量）首先需要减少**平均检测时间**（**MTTD**）。在服务处于影响客户的故障状态时，能够准确地向值班工程师发出警报对于保持正常运行至关重要。好的警报应该是可操作的且紧急的；如果你的系统在故障不可操作或非紧急（不影响客户）时通知值班工程师，你可能会让值班工程师疲惫不堪，并造成通常所说的告警疲劳。告警疲劳是真实存在的，并且可能对正常运行时间产生比任何数量的软件错误或故障硬件更灾难性的影响。持续改进你的系统告警，以获得阈值和其他因素的恰到好处，防止误报，同时保持对真正影响客户的故障的告警。
- en: Alerting infrastructure is not something you want to build yourself. **PagerDuty**
    is an SaaS tool that allows you to create escalation policies and schedules for
    teams of engineers who are on-call for specific services. Using PagerDuty, you
    can set up a rotating schedule so that an engineer on a team of five, for example,
    can expect to be on-call one week in every five. Escalation policies allow you
    to configure a set of steps in case the on-call engineer is unavailable (perhaps
    they're driving their car on the freeway). Escalation policies are often configured
    to page a secondary on-call schedule, a manager, or even the entire team in the
    event that an incident goes unacknowledged for a certain amount of time. Using
    a system such as PagerDuty allows engineers on a team to enjoy much-needed off-call
    time while knowing that customer-impacting incidents will be responded to promptly.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 告警基础设施不是你想自己构建的东西。**PagerDuty**是一个SaaS工具，允许你为特定服务的值班工程师团队创建升级策略和日程安排。使用PagerDuty，你可以设置一个轮换日程，例如，一个五人团队的工程师可以预期每五周值班一周。升级策略允许你在值班工程师不可用的情况下（例如，他们可能在高速公路上开车）配置一系列步骤。升级策略通常配置为在事故未被确认一定时间后，向二级值班日程、经理甚至整个团队发送警报。使用像PagerDuty这样的系统，可以让团队中的工程师在享受必要的非值班时间的同时，知道影响客户的故障将会得到及时响应。
- en: Alerts can be configured manually using any number of supporting integrations,
    but this is time-consuming and error-prone. Instead, it's desirable to have a
    system that allows you to automate the creation and maintenance of alerts for
    your services. The Prometheus monitoring and alerting toolkit covered in this
    chapter includes a tool called Alertmanager which allows you to do just that.
    In this recipe, we'll modify our message-service to add alerts using Alertmanager.
    Specifically, we'll configure a single alert that fires when the average response
    time exceeds 500 ms for at least 5 minutes. We'll work from the version of message-service
    that already includes Prometheus metrics. We won't add any PagerDuty integration
    in this recipe, since that would require a PagerDuty account in order to follow
    along. PagerDuty has an excellent integration guide on its website. We'll configure
    `alertmanager` to send a simple WebHook-based alert.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用任何数量的支持集成手动配置警报，但这既耗时又容易出错。相反，我们希望有一个系统，允许您自动化创建和维护服务的警报。本章中涵盖的 Prometheus
    监控和警报工具包包括一个名为 Alertmanager 的工具，它允许您做到这一点。在这个配方中，我们将修改我们的消息服务以使用 Alertmanager
    添加警报。具体来说，我们将配置一个警报，当平均响应时间超过 500 毫秒且至少持续 5 分钟时触发。我们将从已经包含 Prometheus 指标的消息服务版本开始工作。在这个配方中，我们不会添加任何
    PagerDuty 集成，因为这需要 PagerDuty 账户才能继续。PagerDuty 在其网站上有一个优秀的集成指南。我们将配置 `alertmanager`
    以发送基于简单 WebHook 的警报。
- en: How to do it...
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Now, let''s have a look at the following steps:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看以下步骤：
- en: 'In a previous recipe, we configured Prometheus with a file called `prometheus.yml`.
    We''ll need to add the `alertmanager` configuration to this file, so open it again
    and add the following:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在之前的配方中，我们使用名为 `prometheus.yml` 的文件配置了 Prometheus。我们需要将 `alertmanager` 配置添加到该文件中，所以请再次打开它并添加以下内容：
- en: '[PRE16]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Create a new file called `/tmp/rules.yml`. This file defines the rules we want
    Prometheus to be able to creates alerts for:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `/tmp/rules.yml` 的新文件。该文件定义了我们希望 Prometheus 能够创建警报的规则：
- en: '[PRE17]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Create a new file called `/tmp/alertmanager.yml`. This is the file that will
    describe our alerting configuration. It is broken into a few different sections, global
    sets of certain configuration options that impact how `alertmanager` works. The
    section called receivers is where we configure our alert notification systems. In
    this case, it''s a WebHook to a service running locally. This is just for demo
    purposes; we''ll write a small ruby script that listens for HTTP requests and
    prints the payload to the standard output:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `/tmp/alertmanager.yml` 的新文件。这是描述我们的警报配置的文件。它被分成几个不同的部分，这些部分是某些配置选项的全局集合，这些选项会影响
    `alertmanager` 的工作方式。名为 receivers 的部分是我们配置警报通知系统的位置。在这种情况下，它是一个运行在本地的服务的 WebHook。这只是为了演示目的；我们将编写一个小的
    Ruby 脚本，该脚本监听 HTTP 请求并将有效负载打印到标准输出：
- en: '[PRE18]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Here''s the source code for the small ruby service that will print out our
    alerts:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是将打印出我们的警报的小型 Ruby 服务的源代码：
- en: '[PRE19]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Run the ruby script, restart `prometheus`, and start `alertmanager`. With these
    three systems running, we''ll be ready to test our alert:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 Ruby 脚本，重启 `prometheus` 和 `alertmanager`。这三个系统运行后，我们将准备好测试我们的警报：
- en: '[PRE20]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In order to get our alert to fire, open message-service and add the following
    line to `MessageController.java`. It''s a single line that will force the controller
    to sleep for 600 milliseconds before returning a response. Note that this is above
    our threshold described in our rules configuration:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使我们的警报触发，打开消息服务并添加以下行到 `MessageController.java`。这是一行代码，它将迫使控制器在返回响应之前暂停600毫秒。请注意，这超出了我们在规则配置中描述的阈值：
- en: '[PRE21]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: With that in place, run your updated message service and make a number of requests
    to it. After one minute, Prometheus should notify Alertmanager, which should then
    notify your local debug ruby service. Your alert is working!
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在设置完成后，运行您更新的消息服务并向其发送多个请求。一分钟过后，Prometheus 应该会通知 Alertmanager，然后 Alertmanager
    应该会通知您本地的调试 Ruby 服务。您的警报正在工作！
