<html><head></head><body>
        

                            
                    <h1 class="header-title">Modularizing Our Code</h1>
                
            
            
                
<p>In the previous chapter, we followed a TDD workflow and implemented the first endpoint of our API—the Create User endpoint. We wrote our End-to-End (E2E) tests in Gherkin, ran them using the <em>Cucumber</em> test runner, and used them to drive development. Everything works, but all the code is contained within a single, monolithic file (<kbd>src/index.js</kbd>); this is not modular and makes our project hard to maintain, especially as we add more endpoints. Therefore, in this chapter, we will be separating our application code into smaller modules. This will allow us to write <strong>unit</strong> and <strong>integration tests</strong> for them in <a href="38b85b06-d091-4751-a2ac-32ca0f98f26b.xhtml" target="_blank">Chapter 8</a>, <em>Writing Unit/Integration Tests</em>.</p>
<p>By following this chapter, you will be able to do the following:</p>
<ul>
<li>Break down large blocks of code into smaller modules</li>
<li>Define and validate JavaScript objects with <strong>JSON Schema</strong> and Ajv</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Modularizing our code</h1>
                
            
            
                
<p>If you take a look inside the <kbd>src/index.js</kbd> file, you'll see that there are three top-level middleware functions—<kbd>checkEmptyPayload</kbd>, <kbd>checkContentTypeIsSet</kbd>, and <kbd>checkContentTypeIsJson</kbd>—as well as an anonymous error handler function. These are prime candidates that we can extract into their own modules. So, let's get started!</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Modularizing our middleware</h1>
                
            
            
                
<p>Let's carry out this refactoring process in a new branch called <kbd>create-user/refactor-modules</kbd>:</p>
<pre><strong>$ git checkout -b create-user/refactor-modules</strong></pre>
<p class="mce-root"/>
<p>Then, create a directory at <kbd>src/middlewares</kbd>; this is where we will store all of our middleware modules. Inside it, create four files—one for each middleware function:</p>
<pre><strong>$ mkdir -p src/middlewares &amp;&amp; cd src/middlewares</strong><br/><strong>$ touch check-empty-payload.js \</strong><br/><strong>  check-content-type-is-set.js \</strong><br/><strong>  check-content-type-is-json.js \</strong><br/><strong>  error-handler.js</strong></pre>
<p>Then, move the middleware functions from <kbd>src/index.js</kbd> into their corresponding file. For example, the <kbd>checkEmptyPayload</kbd> function should be moved to <kbd>src/middlewares/check-empty-payload.js</kbd>. Then, at the end of each module, export the function as the default export. For example, the <kbd>error-handler.js</kbd> file would look like this:</p>
<pre>function errorHandler(err, req, res, next) {<br/>  ...<br/>}<br/><br/>export default errorHandler;</pre>
<p>Now, go back to <kbd>src/index.js</kbd> and import these modules to restore the previous behavior:</p>
<pre>import checkEmptyPayload from './middlewares/check-empty-payload';<br/>import checkContentTypeIsSet from './middlewares/check-content-type-is-set';<br/>import checkContentTypeIsJson from './middlewares/check-content-type-is-json';<br/>import errorHandler from './middlewares/error-handler';<br/>...<br/>app.use(errorHandler);</pre>
<p>Now, run our E2E tests again to make sure that we haven't broken anything. Also, don't forget to commit your code!</p>
<pre><strong>$ git add -A &amp;&amp; git commit -m "Extract middlewares into modules"</strong></pre>
<p>By pulling out the middleware functions, we've improved the readability of our <kbd>src/index.js</kbd> file. The intention and flow of our code is apparent because we've named our functions properly—you understand what the functions do from their names. Next, let's do the same with our request handler.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Modularizing our request handlers</h1>
                
            
            
                
<p>At the moment, we only have one request handler for our <kbd>POST /users</kbd> endpoint, but by the end of this chapter, we will have implemented many more. Defining them all inside the <kbd>src/index.js</kbd> file would lead to a huge, unreadable mess. Therefore, let's define each request handler as its own module. Let's begin by creating a file at <kbd>src/handlers/users/create.js</kbd> and extract the Create User request handler into it. Previously, the request handler was an anonymous arrow function; now that it's in its own module, let's give it a name of <kbd>createUser</kbd>. Lastly, <kbd>export</kbd> the function in the same manner as we did with the middleware. You should end up with something like this:</p>
<pre>function createUser(req, res) {<br/>  if (<br/>    !Object.prototype.hasOwnProperty.call(req.body, 'email')<br/>    || !Object.prototype.hasOwnProperty.call(req.body, 'password')<br/>  ) {<br/>    res.status(400);<br/>    res.set('Content-Type', 'application/json');<br/>    return res.json({ message: 'Payload must contain at least the email and password fields' });<br/>  }<br/>  ...<br/>}<br/><br/>export default createUser;</pre>
<p>Then, import the <kbd>createUser</kbd> handler back into <kbd>src/index.js</kbd> and use it inside <kbd>app.post</kbd>:</p>
<pre>...<br/>import createUser from './handlers/users/create';<br/>...<br/>app.post('/users', createUser);<br/>...</pre>
<p>However, our request handler requires an Elasticsearch client to work. One way to resolve this would be to move the following lines to the top of the <kbd>src/handlers/users/create.js</kbd> module:</p>
<pre>import elasticsearch from 'elasticsearch';<br/>const client = new elasticsearch.Client({ host: ... });</pre>
<p>However, thinking ahead, since we will have many request handlers, we shouldn't instantiate a separate instance of the client for each handler. Instead, we should create one Elasticsearch client instance and pass it by reference into each request handler.</p>
<p class="mce-root"/>
<p>To do this, let's create a utility function at <kbd>src/utils/inject-handler-dependencies.js</kbd> that takes in a request handler function and the Elasticsearch client, and returns a new function that will call the request handler, passing in the client as one of the parameters:</p>
<pre>function injectHandlerDependencies(handler, db) {<br/>  return (req, res) =&gt; { handler(req, res, db); };<br/>}<br/><br/>export default injectHandlerDependencies;</pre>
<p>This is an example of a <strong>higher-order function</strong>, which is a function that operates on, or returns, other functions. This is possible because functions are a type of object in JavaScript, and thus are treated as <strong>first-class citizens</strong>. This means you can pass a function around just like any other object, even as function parameters.</p>
<p>To use it, import it into our <kbd>src/index.js</kbd> file:</p>
<pre>import injectHandlerDependencies from './utils/inject-handler-dependencies';</pre>
<p>Then, instead of using the <kbd>createUser</kbd> request handler directly, pass in the handler returned from <kbd>injectHandlerDependencies</kbd>:</p>
<pre># Change this<br/>app.post('/users', <strong>createUser</strong>);<br/><br/># To this<br/>app.post('/users', <strong>injectHandlerDependencies(createUser, client)</strong>);</pre>
<p>Lastly, update the request handler itself to make use of the client:</p>
<pre>function createUser(req, res, <strong>db</strong>) {<br/>  ...<br/>  <strong>db</strong>.index({ ... });<br/>}</pre>
<p>Once again, run the E2E tests to make sure we have not introduced a bug, and then commit our changes:</p>
<pre><strong>$ git add -A &amp;&amp; git commit -m "Extract request handlers into modules"</strong></pre>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">The single responsibility principle</h1>
                
            
            
                
<p>We have pulled out the request handler and migrated it into its own module. However, it is not as modular as it could be; at the moment, the handler serves three functions:</p>
<ul>
<li>Validates the request</li>
<li>Writes to the database</li>
<li>Generates the response</li>
</ul>
<p>If you have studied object-orientated design principles, you will undoubtedly have come across the <strong>SOLID</strong> principle, which is a mnemonic acronym for <strong>single responsibility</strong>, <strong>open/closed</strong>, <strong>Liskov substitution</strong>, <strong>interface segregation</strong>, and <strong>dependency inversion</strong>.</p>
<p>The single responsibility principle states that a module should perform one, and only one, function. Therefore, we should pull out the validation and database logic into their own dedicated modules.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Decoupling our validation logic</h1>
                
            
            
                
<p>However, we cannot directly copy our existing validation code from <kbd>src/handlers/users/create.js</kbd> without modification. This is because the validation code directly modifies the response object, <kbd>res</kbd>, which means that the validation logic and response logic are <strong>tightly coupled</strong> to each other.</p>
<p>To resolve this, we must define a common <strong>interface</strong> between our validation logic and our response handler. Instead of modifying the response directly, the validation logic will produce an object that conforms to this interface, and the response handler will consume this object to produce an appropriate response.</p>
<p>When a request fails validation, we can consider it as a type of error, because the client provided an incorrect payload. Therefore, we can extend the native <kbd>Error</kbd> object to create a new <kbd>ValidationError</kbd> object, which will act as the interface. We don't have to provide the status or set the headers, as that's the job of our request handlers. We just need to make sure an instance of <kbd>ValidationError</kbd> will contain the <kbd>message</kbd> property. Since this is the default behavior of <kbd>Error</kbd>, we don't need to do much else.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating the ValidationError interface</h1>
                
            
            
                
<p>Create a new file at <kbd>src/validators/errors/validation-error.js</kbd> and add a class definition for <kbd>ValidationError</kbd>:</p>
<pre>class ValidationError extends Error {<br/>  constructor(...params) {<br/>    super(...params);<br/><br/>    if (Error.captureStackTrace) {<br/>      Error.captureStackTrace(this, ValidationError);<br/>    }<br/>  }<br/>}<br/><br/>export default ValidationError;</pre>
<p>The preceding code extends the <kbd>Error</kbd> class to create its own class. We need to do this in order to distinguish between validation errors (which should return a <kbd>400</kbd> response) and errors in our code (which should return a <kbd>500</kbd> response).</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Modularizing our validation logic</h1>
                
            
            
                
<p>Next, create a new file at <kbd>src/validators/users/create.js</kbd> and copy the validation blocks from our request handlers into the file, wrapping it inside its own function and exporting that function:</p>
<pre>function validate (req) {<br/>  if (<br/>    !Object.prototype.hasOwnProperty.call(req.body, 'email')<br/>    || !Object.prototype.hasOwnProperty.call(req.body, 'password')<br/>  ) {<br/>    res.status(400);<br/>    res.set('Content-Type', 'application/json');<br/>    return res.json({ message: 'Payload must contain at least the email and password fields' });<br/>  }<br/>  ...<br/>}<br/><br/>export default validate;</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Next, import the <kbd>ValidationError</kbd> class from <kbd>src/validators/errors/validation-error.js</kbd>. Then, instead of modifying the <kbd>res</kbd> object (which is not in scope), return instances of <kbd>ValidationError</kbd> instead. The final <kbd>src/validators/users/create.js</kbd> file may look like this:</p>
<pre>import ValidationError from '../errors/validation-error';<br/><br/>function validate(req) {<br/>  if (<br/>    !Object.prototype.hasOwnProperty.call(req.body, 'email')<br/>    || !Object.prototype.hasOwnProperty.call(req.body, 'password')<br/>  ) {<br/>    return new ValidationError('Payload must contain at least the email and password fields');<br/>  }<br/>  if (<br/>    typeof req.body.email !== 'string'<br/>    || typeof req.body.password !== 'string'<br/>  ) {<br/>    return new ValidationError('The email and password fields must be of type string');<br/>  }<br/>  if (!/^[\w.+]+@\w+\.\w+$/.test(req.body.email)) {<br/>    return new ValidationError('The email field must be a valid email.');<br/>  }<br/>  return undefined;<br/>}<br/><br/>export default validate;</pre>
<p>Next, we need to import this function into our request handler and use it to validate our Create User request payload. If the validation result is an instance of <kbd>ValidationError</kbd>, then generate the <kbd>400</kbd> response; otherwise, carry on with indexing the user document:</p>
<pre>import ValidationError from '../../validators/errors/validation-error';<br/>import validate from '../../validators/users/create';<br/>function createUser(req, res, db) {<br/>  const validationResults = validate(req);<br/>  if (validationResults instanceof ValidationError) {<br/>    res.status(400);<br/>    res.set('Content-Type', 'application/json');
    return res.json({ message: validationResults.message });<br/>  }<br/>  db.index({ ... })<br/>}<br/><br/>export default createUser;</pre>
<p>By providing a common interface, we have successfully decoupled our validation logic from the rest of the code. Now, run the E2E tests, and if they're green, commit our changes!</p>
<pre><strong>$ git add -A &amp;&amp; git commit -m "Decouple validation and response logic"</strong></pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating engines</h1>
                
            
            
                
<p>Although the bulk of the validation logic has been abstracted into a separate module, the request handler is still processing the results of the validator, interacting with the database, and sending back the response; it still does not comply with the single responsibility principle.</p>
<p>The request handler's only job should be to pass the request to an <em>engine</em>, which will process the request, and respond with the result of the operation. Based on the result of the operation, the request handler should then issue an appropriate response to the client.</p>
<p>So, let's create a new directory at <kbd>src/engines/users</kbd> and add a <kbd>create.js</kbd> file; inside, define a <kbd>create</kbd> function and <kbd>export</kbd> it. This <kbd>create</kbd> function will validate our request and write to the database, returning the result of the operation back to the request handler. Since writing to the database is an asynchronous operation, our <kbd>create</kbd> function should return a promise.</p>
<p>Try implementing the <kbd>create</kbd> function yourself, and check back here for our implementation:</p>
<pre>import ValidationError from '../../validators/errors/validation-error';<br/>import validate from '../../validators/users/create';<br/><br/>function create(req, db) {<br/>  const validationResults = validate(req);<br/>  if (validationResults instanceof ValidationError) {<br/>    return Promise.reject(validationResults);<br/>  }<br/>  return db.index({<br/>    index: process.env.ELASTICSEARCH_INDEX,<br/>    type: 'user',<br/>    body: req.body,<br/>  });<br/>}<br/><br/>export default create;</pre>
<p>Then, in <kbd>src/handlers/users/create.js</kbd>, import the engine module and use the result to generate the response. The final file should look like this:</p>
<pre>import ValidationError from '../../validators/errors/validation-error';<br/>import create from '../../engines/users/create';<br/><br/>function createUser(req, res, db) {<br/>  create(req, db).then((result) =&gt; {<br/>    res.status(201);<br/>    res.set('Content-Type', 'text/plain');<br/>    return res.send(result._id);<br/>  }, (err) =&gt; {<br/>    if (err instanceof ValidationError) {<br/>      res.status(400);<br/>      res.set('Content-Type', 'application/json');<br/>      return res.json({ message: err.message });<br/>    }<br/>    return undefined;<br/>  }).catch(() =&gt; {<br/>    res.status(500);<br/>    res.set('Content-Type', 'application/json');<br/>    return res.json({ message: 'Internal Server Error' });<br/>  });<br/>}<br/><br/>export default createUser;</pre>
<p>Run the tests to make sure that they all still pass, and then commit these changes to Git:</p>
<pre><strong>$ git add -A &amp;&amp; git commit -m "Ensure Single-Responsibility Principle for handler"</strong></pre>
<p>Fantastic! We have now refactored our code to be more modular and ensured that each module is decoupled from the others!</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Adding a user profile</h1>
                
            
            
                
<p>If we look back at our requirements for creating a user, there's one that is still unfinished – "The user may optionally provide a profile; otherwise, an empty profile will be created for them". So, let's implement this requirement!</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Writing a specification as a test</h1>
                
            
            
                
<p>We will begin development by first writing E2E tests. In the previous chapter, we already tested a scenario where the profile is not supplied. In these new E2E tests, we will add two more scenarios where the client provides a profile object—one using an invalid profile, the other a valid one.</p>
<p>Therefore, we must first decide what constitutes a valid profile; in other words, what should the structure of our profile object be? There are no right or wrong answers, but for this book, we will use the following structure:</p>
<pre>{<br/>  "name": {<br/>    "first": &lt;string&gt;,<br/>    "last": &lt;string&gt;,<br/>    "middle": &lt;string&gt;<br/>  },<br/>  "summary": &lt;string&gt;,<br/>  "bio": &lt;string&gt;<br/>}</pre>
<p>All of the fields are optional, but if they are provided, they must be of the correct type.</p>
<p>Let's start with testing for the invalid profile scenario. In <kbd>spec/cucumber/features/users/create/main.feature</kbd>, add the following scenario outline:</p>
<pre>Scenario Outline: Invalid Profile<br/><br/>  When the client creates a POST request to /users/<br/>  And attaches &lt;payload&gt; as the payload<br/>  And sends the request<br/>  Then our API should respond with a 400 HTTP status code<br/>  And the payload of the response should be a JSON object<br/>  And contains a message property which says "The profile provided is invalid."<br/><br/>  Examples:<br/><br/>  | payload                                                                          |<br/>  | {"email":"e@ma.il","password":"abc","profile":{"foo":"bar"}}                     |<br/>  | {"email":"e@ma.il","password":"abc","profile":{"name":{"first":"Jane","a":"b"}}} |<br/>  | {"email":"e@ma.il","password":"abc","profile":{"summary":0}}                     |<br/>  | {"email":"e@ma.il","password":"abc","profile":{"bio":0}}                         |</pre>
<p>These examples cover the cases where properties have the incorrect type, and/or unsupported properties were provided.</p>
<p>When we run these tests, the <kbd>And attaches &lt;payload&gt; as the payload</kbd> shows up as undefined. This step definition should allow us to attach any arbitrary payload to the request. Try implementing this inside <kbd>spec/cucumber/steps/index.js</kbd>, and check your solution against the following one:</p>
<pre>When(/^attaches (.+) as the payload$/, function (payload) {<br/>  this.requestPayload = JSON.parse(payload);<br/>  this.request<br/>    .send(payload)<br/>    .set('Content-Type', 'application/json');<br/>});</pre>
<p>Run the E2E tests again, and this time, the newly defined tests should fail. Red. Green. Refactor. We have now written a failing test; the next step is to implement the feature so that it passes the tests.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Schema-based validation</h1>
                
            
            
                
<p>Our tests are failing because our API is actually writing the (invalid) profile objects into the database; conversely, we expect our API to respond with a <kbd>400</kbd> error. Therefore, we must implement additional validation steps for the <kbd>profile</kbd> subdocument.</p>
<p>Currently, we are using <kbd>if</kbd> conditional blocks to validate the email and password fields. If we use the same approach for our new user object, we'd have to write a very long list of <kbd>if</kbd> statements, which is bad for readability. One may also argue that our current implementation of the <kbd>validation</kbd> function is already quite unreadable, because it's not immediately obvious what the user object should look like. Therefore, we need to find a better approach.</p>
<p>A more declarative way of validating is to use a <strong>schema</strong>, which is just a formal way of describing a data structure. After a schema is defined, we can use validation libraries to test the request payload against the schema, and respond with an appropriate error message if it does not pass.</p>
<p>Therefore, in this section, we are going to use a schema to validate our profile object, and then refactor all of our existing validation code to use schema-based validation as well.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Types of schema</h1>
                
            
            
                
<p>The most common schema used in JavaScript is <strong>JSON Schema</strong> (<a href="http://json-schema.org/">json-schema.org</a>). To use it, you first define a schema written in JSON, and then use a schema validation library to compare the object of interest with the schema to see if they match.</p>
<p>But before we explain the syntax of JSON Schema, let's take a look at two major JavaScript libraries that support schema validation while not using JSON Schema:</p>
<ul>
<li class="mce-root"><kbd>joi</kbd> (<a href="https://github.com/hapijs/joi" target="_blank">https://github.com/hapijs/joi</a>) allows you to define requirements in a composable, chainable manner, which means that the code is very readable. It has over 9,000 stars on GitHub and is depended on by over 94,000 repositories and 3,300 packages:</li>
</ul>
<pre style="color: black">const schema = Joi.object().keys({<br/>    username: Joi.string().alphanum().min(3).max(30).required(),<br/>    password: Joi.string().regex(/^[a-zA-Z0-9]{3,30}$/),<br/>    access_token: [Joi.string(), Joi.number()],<br/>    birthyear: Joi.number().integer().min(1900).max(2013),<br/>    email: Joi.string().email()<br/>}).with('username', 'birthyear').without('password', 'access_token');<br/><br/>const result = Joi.validate({ username: 'abc', birthyear: 1994 }, schema);</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ul>
<li class="mce-root"><kbd>validate.js</kbd> (<a href="https://validatejs.org/" target="_blank">https://validatejs.org/</a>) is another very expressive validation library, and allows you to define your own custom validation function. It has 1,700 stars on GitHub, and is depended on by over 2,700 repositories and 290 packages:</li>
</ul>
<pre style="color: black">var constraints = {<br/>  username: {<br/>    presence: true,<br/>    exclusion: {<br/>      within: ["nicklas"],<br/>      message: "'%{value}' is not allowed"<br/>    }<br/>  },<br/>  password: {<br/>    presence: true,<br/>    length: {<br/>      minimum: 6,<br/>      message: "must be at least 6 characters"<br/>    }<br/>  }<br/>};<br/><br/>validate({password: "bad"}, constraints);</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Picking an object schema and validation library</h1>
                
            
            
                
<p>So out of the three options, which one should we use? To answer this question, we should first consider their <strong>interoperability</strong> and <strong>expressiveness</strong>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Interoperability</h1>
                
            
            
                
<p>Interoperability has to do with how easy is it for different frameworks, libraries, and languages to consume the schema. In this criterion, JSON Schema wins hands down.</p>
<p class="mce-root">The benefits of using a standardized schema such as JSON Schema is that the same schema file may be used by multiple code bases. For example, as our platform grows, we may have multiple internal services that each need to validate user data; some may even be written in another language (for example, Python).</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root">Instead of having multiple definitions of the user schema in different languages, we can use the same schema file, as there are JSON Schema validators for all major languages:</p>
<ul>
<li class="mce-root">Swift: <kbd>JSONSchema.swift</kbd> (<a href="https://github.com/kylef-archive/JSONSchema.swift" target="_blank">https://github.com/kylef-archive/JSONSchema.swift</a>)</li>
<li class="mce-root">Java: <kbd>json-schema-validator</kbd> (<a href="https://github.com/java-json-tools/json-schema-validator">github.com/java-json-tools/json-schema-validator</a>)</li>
<li class="mce-root">Python: <kbd>jsonschema</kbd> (<a href="https://pypi.python.org/pypi/jsonschema">pypi.python.org/pypi/jsonschema</a>)</li>
<li class="mce-root">Go: <kbd>gojsonschema</kbd> (<a href="https://github.com/xeipuuv/gojsonschema">github.com/xeipuuv/gojsonschema</a>)</li>
</ul>
<p class="mce-root">You can view the full list of validators at <a href="http://json-schema.org/implementations.html">json-schema.org/implementations.html</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Expressiveness</h1>
                
            
            
                
<p class="mce-root">JSON Schema supports many validation keywords and data formats, as defined in the IETF memo <em>JSON Schema Validation: A Vocabulary for Structu</em><em>ral Validation of JSON</em> (<a href="http://json-schema.org/latest/json-schema-validation.html">json-schema.org/latest/json-schema-validation.html</a>); however, due to the restrictions of JSON itself, JSON Schema lacks the ability to define custom validation logic in the form of functions.</p>
<p>For example, JSON Schema does not provide a way to express the following logic: "if the <kbd>age</kbd> property is below <kbd>18</kbd>, then the <kbd>hasParentalConsent</kbd> property must be set to <kbd>true</kbd>." Thus, if you want to perform more complicated checks, these must be done as a separate function in JavaScript. Alternatively, some JSON Schema-based validation libraries extend the JSON Schema syntax and allow developers to implement custom validation logic. For instance, the <kbd>ajv</kbd> validation library supports defining custom keywords.</p>
<p class="mce-root">For non-JSON Schema validation libraries, both <kbd>joi</kbd> and <kbd>validate.js</kbd> allow you to define custom validation functions.</p>
<p>Therefore, although JSON Schema is less expressive in theory, in practice, all solutions have the same level of expressiveness and flexibility. Because JSON Schema is a well-established standard and also more interoperable, that's the solution we will use to validate our payloads.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p>At the time of writing this book, the JSON Schema specification is still in draft (specifically draft-07, which can be found at <a href="https://tools.ietf.org/html/draft-handrews-json-schema-00">tools.ietf.org/html/draft-handrews-json-schema-00</a>). It is likely that the final specification will be slightly different to the one described here. Please refer to the latest version at <a href="http://json-schema.org/">json-schema.org</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating our profile schema</h1>
                
            
            
                
<p>So, let's construct the schema for our user profile object using JSON Schema. To do that, we must first understand its syntax.</p>
<p>The first thing to note is that a JSON Schema is itself a JSON object. Therefore, the simplest JSON Schema is simply an empty object:</p>
<pre>{}</pre>
<p>This empty object schema will allow any type of data, so it is pretty much useless. For it to be useful, we must describe the type of data we expect. This can be done through the <kbd>type</kbd> keyword. The <kbd>type</kbd> keyword expects its value to be either a string, where only one type is allowed, or an array, where any types specified in the array are allowed.</p>
<p>We expect our input for the user profile object to only be objects, and so we can specify a <kbd>type</kbd> of <kbd>"object"</kbd>:</p>
<pre>{ "type": "object" }</pre>
<p><kbd>type</kbd> is the most basic keyword. There are many other common keywords that are applicable to all types, such as <kbd>title</kbd>; there are also type-specific keywords, such as <kbd>maximum</kbd>, which only applies to data of type <kbd>number</kbd>.</p>
<p>For object types, we can use the type-specific keyword <kbd>properties</kbd> to describe what properties we expect our object to contain. The value of <kbd>properties</kbd> must be an object, with property names as the key and another valid JSON Schema, called a <strong>sub-schema</strong>, as the value. In our case, we expect the <kbd>bio</kbd> and <kbd>summary</kbd> properties to be of type <kbd>string</kbd>, and the <kbd>name</kbd> property to have an <kbd>object</kbd> type, so our schema would look like this:</p>
<pre>{<br/>  "type": "object",<br/>  "properties": {<br/>    "bio": { "type": "string" },
    "summary": { "type": "string" },<br/>    "name": { "type": "object" }<br/>  }<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Rejecting additional properties</h1>
                
            
            
                
<p>Lastly, we will set the object-specific <kbd>additionalProperties</kbd> keyword to <kbd>false</kbd>. This will reject objects that contain keys not already defined under <kbd>properties</kbd> (for example, <kbd>isAdmin</kbd>):</p>
<pre>{<br/>  "type": "object",<br/>  "properties": {<br/>    "bio": { "type": "string" },<br/>    "summary": { "type": "string" },<br/>    "name": { "type": "object" }<br/>  },<br/>  "additionalProperties": false<br/>}</pre>
<p class="mce-root">Having <kbd>additionalProperties</kbd> set to <kbd>false</kbd> is really important, especially for Elasticsearch. This is because Elasticsearch uses a technique called <strong>dynamic mapping</strong> to infer the data types of its documents, and uses it to generate its indexes.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Dynamic mapping in Elasticsearch</h1>
                
            
            
                
<p class="mce-root">To create a table inside a relational database, you must specify a <strong>model</strong>, which stores information about the name and data type of each column. This information must be supplied before any data is inserted.</p>
<p class="mce-root">Elasticsearch has a similar concept called <strong>type mapping</strong>, which stores information about the name and data type of each property in the document. The difference is that we don't have to supply the type mapping before we insert any data; in fact, we don't have to supply it <em>at all</em>! This is because when Elasticsearch tries to infer the data type from the documents being indexed, it will add it to the type mapping. This automatic detection of data types and addition to type mapping is what we refer to as dynamic mapping.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root">Dynamic mapping is a convenience provided by Elasticsearch, but it also means we must sanitize and validate our data before indexing it into Elasticsearch. If we allow users to add arbitrary fields to their documents, the type mapping may infer the wrong data type, or become littered with irrelevant fields. Moreover, since Elasticsearch indexes every field by default, this can lead to many irrelevant indices.</p>
<p>You can read more about dynamic mapping at <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/dynamic-mapping.html" target="_blank">https://www.elastic.co/guide/en/elasticsearch/guide/current/dynamic-mapping.html</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Adding specificity to a sub-schema</h1>
                
            
            
                
<p>At the moment, the only constraint we placed on the <kbd>name</kbd> property is that it must be an object. This is not specific enough. Because the value of each property is just another valid JSON Schema, we can define a more specific schema for the <kbd>name</kbd> property:</p>
<pre>{<br/>  "type": "object",<br/>  "properties": {<br/>    "bio": { "type": "string" },<br/>    "summary": { "type": "string" },<br/>    "name": {<br/>      "type": "object",<br/>      "properties": {<br/>        "first": { "type": "string" },<br/>        "last": { "type": "string" },<br/>        "middle": { "type": "string" }<br/>      },<br/>      "additionalProperties": false<br/>    }<br/>  },<br/>  "additionalProperties": false<br/>}</pre>
<p>This JSON Schema satisfies every constraint we want to impose on our Create User request payload. However, it looks just like an arbitrary JSON object; someone looking at it won't immediately understand that it is a schema. Therefore, to make our intentions more clear, we should add a title, description, and some metadata to it.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Adding a title and description</h1>
                
            
            
                
<p>First, we should provide the <kbd>title</kbd> and <kbd>description</kbd> keywords for the schema and for each property that may require clarification. These keywords are not used in validation and exist only to provide context for the users of your schema:</p>
<pre>"title": "User Profile Schema",<br/>"description": "For validating client-provided user profile object when creating and/or updating an user",</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Specifying a meta-schema</h1>
                
            
            
                
<p>Next, we should include the <kbd>$schema</kbd> keyword, which declares that the JSON object is a JSON Schema. It points to a URL that defines the meta-schema that the current JSON Schema must conform to. We chose <a href="http://json-schema.org/schema#">http://json-schema.org/schema#</a>, which points to the latest draft of the JSON Schema specification:</p>
<pre>{ "$schema": "http://json-schema.org/schema#" }</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Specifying a unique ID</h1>
                
            
            
                
<p>Lastly, we should include the <kbd>$id</kbd> keyword, which defines a unique URI for our schema. This URI can be used by other schemas to reference our schema, for example, when using our schema as a sub-schema. For now, just set it to a valid URL, preferably using a domain that you control:</p>
<pre>"$id": "http://api.hobnob.social/schemas/users/profile.json"</pre>
<p>If you don't know how to purchase a domain, we will show you in <a href="673a49d6-f4c5-47b4-afec-af3ff031f150.xhtml" target="_blank">Chapter 10</a>, <em>Deploying Your Application on a VPS</em>. For now, just use a dummy domain like <kbd>example.com</kbd>.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Our finished JSON Schema should look like this:</p>
<pre>{<br/>  "$schema": "http://json-schema.org/schema#",<br/>  "$id": "http://api.hobnob.social/schemas/users/profile.json",<br/>  "title": "User Profile Schema",<br/>  "description": "For validating client-provided user profile object <br/>   when creating and/or updating an user",<br/>  "type": "object",<br/>  "properties": {<br/>    "bio": { "type": "string" },<br/>    "summary": { "type": "string" },<br/>    "name": {<br/>      "type": "object",<br/>      "properties": {<br/>        "first": { "type": "string" },<br/>        "last": { "type": "string" },<br/>        "middle": { "type": "string" }<br/>      },<br/>      "additionalProperties": false<br/>    }<br/>  },<br/>  "additionalProperties": false<br/>}</pre>
<p>Save this file to <kbd>/src/schema/users/profile.json</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a schema for the Create User request payload</h1>
                
            
            
                
<p>At the moment, our existing code still uses custom-defined <kbd>if</kbd> statements to validate the email and password fields of the Create User request payload object. Since we will be using a JSON Schema validation library for our profile object, we should also migrate our existing validation logic to a JSON Schema to remain consistent. Therefore, let's create a schema for the entire Create User request payload object.</p>
<p>Create a new file at <kbd>src/schema/users/create.json</kbd>, and insert the following schema:</p>
<pre>{<br/>  "$schema": "http://json-schema.org/schema#",<br/>  "$id": "http://api.hobnob.social/schemas/users/create.json",<br/>  "title": "Create User Schema",<br/>  "description": "For validating client-provided create user object",<br/>  "type": "object",<br/>  "properties": {<br/>    "email": {<br/>      "type": "string",<br/>      "format": "email"<br/>    },<br/>    "password": { "type": "string" },<br/>    "profile": { "$ref": "profile.json#"}<br/>  },<br/>  "required": ["email", "password"],<br/>  "additionalProperties": false<br/>}</pre>
<p>There are a few things to note here:</p>
<ul>
<li>We are using the <kbd>format</kbd> property to ensure that the email property is a valid email, as defined by RFC 5322, section 3.4.1 (<a href="https://tools.ietf.org/html/rfc5322#section-3.4.1" target="_blank">https://tools.ietf.org/html/rfc5322#section-3.4.1</a>). However, we also want to exclude certain syntactically-valid emails like <kbd>daniel@127.0.0.1</kbd>, which are likely to be spam. Later in this chapter, we will show you how to override this default format.</li>
<li>We have used a JSON reference (<kbd>$ref</kbd>) to reference the profile schema we defined earlier. The <kbd>$ref</kbd> syntax was specified in <a href="https://tools.ietf.org/html/draft-pbryan-zyp-json-ref-03" target="_blank">https://tools.ietf.org/html/draft-pbryan-zyp-json-ref-03</a> and allows us to compose more complex schema from existing ones, removing the need for duplication.</li>
<li>We have marked the <kbd>email</kbd> and <kbd>password</kbd> properties as required.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Picking a JSON Schema validation library</h1>
                
            
            
                
<p>The next step is to pick a JSON Schema validation library. The json-schema.org (<a href="https://json-schema.org/" target="_blank">https://json-schema.org/</a>) provides a list of validators which you can read at <a href="http://json-schema.org/implementations.html">json-schema.org/implementations.html</a>. When choosing a schema validation library, we are looking for two things: performance (how quick it is) and conformity (how closely it conforms to the specification).</p>
<p>An open-source developer from Denmark, Allan Ebdrup, has created a set of benchmarks that compare these libraries. You can find it at <a href="https://github.com/ebdrup/json-schema-benchmark">github.com/ebdrup/json-schema-benchmark</a>. The benchmark shows that the <em>Dynamic JSON Schema Validator</em> (djv, <a href="https://github.com/korzio/djv">github.com/korzio/djv</a>) is the fastest and also has fewest failing tests (only 1). The second fastest library is <em>Another JSON Schema Validator</em> (ajv, <a href="https://github.com/epoberezkin/ajv">github.com/epoberezkin/ajv</a>), which also only has a single failing test:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>Library</td>
<td>Relative Speed</td>
<td>Number of failing tests</td>
</tr>
<tr>
<td><kbd>djv v2.0.0</kbd> (fastest)</td>
<td>100%</td>
<td>1</td>
</tr>
<tr>
<td><kbd>ajv v5.5.1</kbd></td>
<td>98%</td>
<td>1</td>
</tr>
<tr>
<td><kbd>is-my-json-valid v2.16.1</kbd></td>
<td>50.1%</td>
<td>14</td>
</tr>
<tr>
<td><kbd>tv4 v1.3.0</kbd></td>
<td>0.2%</td>
<td>33</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Therefore, djv seems like an obvious choice. However, developer and community support are also important factors to consider. So, let's take some of the most popular libraries and examine their number of GitHub stars, the number of weekly downloads from <a href="https://www.npmjs.com">npmjs.com</a>, and the number of dependent repositories and packages*:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td rowspan="2"><strong>Library</strong></td>
<td rowspan="2"><strong>GitHub Repository</strong></td>
<td rowspan="2"><strong>Version</strong></td>
<td rowspan="2"><strong>GitHub stars</strong></td>
<td rowspan="2"><strong>Weekly downloads</strong></td>
<td rowspan="2"><strong>Number of Contributors</strong></td>
<td colspan="2"><strong>Dependent</strong></td>
</tr>
<tr>
<td><strong>Repositories</strong></td>
<td><strong>Packages</strong></td>
</tr>
<tr>
<td><kbd>ajv</kbd></td>
<td><a href="https://github.com/epoberezkin/ajv">epoberezkin/ajv</a></td>
<td>6.5.3</td>
<td>4,117</td>
<td>12,324,991</td>
<td>74</td>
<td>1,256,690</td>
<td>2,117</td>
</tr>
<tr>
<td><kbd>tv4</kbd></td>
<td><a href="https://github.com/geraintluff/tv4">geraintluff/tv4</a></td>
<td>1.3.0</td>
<td>1,001</td>
<td>342,094</td>
<td>22</td>
<td>8,276</td>
<td>486</td>
</tr>
<tr>
<td><kbd>jsonschema</kbd></td>
<td><a href="https://github.com/tdegrunt/jsonschema">tdegrunt/jsonschema</a></td>
<td>1.2.4</td>
<td>889</td>
<td>214,902</td>
<td>39</td>
<td>18,636</td>
<td>727</td>
</tr>
<tr>
<td><kbd>is-my-json-valid</kbd></td>
<td><a href="https://github.com/mafintosh/is-my-json-valid">mafintosh/is-my-json-valid</a></td>
<td>2.19.0</td>
<td>837</td>
<td>2,497,926</td>
<td>23</td>
<td>463,005</td>
<td>267</td>
</tr>
<tr>
<td><kbd>JSV</kbd></td>
<td><a href="https://github.com/garycourt/JSV">garycourt/JSV</a></td>
<td>4.0.2</td>
<td>597</td>
<td>211,573</td>
<td>6</td>
<td>9,475</td>
<td>71</td>
</tr>
<tr>
<td><kbd>djv</kbd></td>
<td><a href="https://github.com/korzio/djv">korzio/djv</a></td>
<td>2.1.1</td>
<td>134</td>
<td>1,036</td>
<td>6</td>
<td>36</td>
<td>10</td>
</tr>
</tbody>
</table>
<p>* These figures are correct as of 6 September, 2018.</p>
<p>As you can see, although djv is the best solution technically, Ajv has the most downloads and number of contributors—signs that the project is well-supported by the community.</p>
<p>Apart from these metrics, you may also want to examine the following:</p>
<ul>
<li class="mce-root">The date of its last meaningful commit to the <kbd>master</kbd> branch (this excludes version bump and formatting changes)—for instance, the last commit to the <kbd>JSV</kbd> library was on 11 Jul 2012; therefore, although it may still have a lot of active users, we should not use a library that's no longer maintained</li>
<li class="mce-root">The number of open issues</li>
<li class="mce-root">The frequency of releases</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p>All of these factors will give you an indication of whether the tool is being actively developed.</p>
<p>Taking everything into account, it seems like Ajv is the obvious choice, as it has the right balance between performance, conformity, and community support.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Validating against JSON Schema with Ajv</h1>
                
            
            
                
<p>So, let's start by adding Ajv to our project's dependencies:</p>
<pre><strong>$ yarn add ajv</strong></pre>
<p>Then, in <kbd>src/validators/users/create.js</kbd>, import the <kbd>ajv</kbd> library as well as our two JSON Schemas:</p>
<pre><strong>import Ajv from 'ajv';</strong><br/><strong>import profileSchema from '../../schema/users/profile.json';</strong><br/><strong>import createUserSchema from '../../schema/users/create.json';</strong><br/>import ValidationError from '../errors/validation-error';<br/>...</pre>
<p>We need to import both schemas because our Create User schema is referencing the Profile schema, and Ajv requires both schemas in order to resolve this reference.</p>
<p>Then, gut out the entire <kbd>validate</kbd> function, and replace it with the following:</p>
<pre>function validate(req) {<br/>  const ajvValidate = new Ajv()<br/>    .addFormat('email', /^[\w.+]+@\w+\.\w+$/)<br/>    .addSchema([profileSchema, createUserSchema])<br/>    .compile(createUserSchema);<br/><br/>  const valid = ajvValidate(req.body);<br/>  if (!valid) {<br/>    // Return ValidationError<br/>  }<br/>  return true;<br/>}</pre>
<p>Next, we will create an instance of Ajv and run the <kbd>addFormat</kbd> method to override the default validation function for the <kbd>email</kbd> format; the <kbd>validate</kbd> function will now use the regular expression we provided to validate any properties with the <kbd>email</kbd> format.</p>
<p>Next, we use the <kbd>addSchema</kbd> method to supply Ajv with any referenced sub-schemas. This allows Ajv to follow the references and produce a dereferenced, flattened schema, which will be used for the validation operation. Lastly, we run the <kbd>compile</kbd> method to return the actual validation function.</p>
<p>When we run the validate function, it will return either <kbd>true</kbd> (if it is valid) or <kbd>false</kbd> (if it is invalid). If invalid, <kbd>ajvValidate.errors</kbd> will be populated with an array of errors, which looks something like this:</p>
<pre>[<br/>  {<br/>    "keyword": "type",<br/>    "dataPath": ".bio",<br/>    "schemaPath": "#/properties/bio/type",<br/>    "params": {<br/>      "type": "string"<br/>    },<br/>    "message": "should be string"<br/>  }<br/>]</pre>
<p>By default, Ajv works in a short-circuit manner and will return <kbd>false</kbd> as soon as it encounters the first error. Therefore, the <kbd>ajvValidate.errors</kbd> array is, by default, a single-item array containing the details of the first error. To instruct Ajv to return all errors, you must set the <kbd>allErrors</kbd> option in the Ajv constructor, for example, <kbd>new Ajv({allErrors: true})</kbd>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Generating validation error messages</h1>
                
            
            
                
<p>When our object fails validation, we should generate the same human-readable error messages as we did before. To do this, we must process the errors stored at <kbd>ajvValidate.errors</kbd>, and use them to generate human-readable messages. Thus, create a new module at <kbd>src/validators/errors/messages.js</kbd>, and copy the following message generator:</p>
<pre>function generateValidationErrorMessage(errors) {<br/>  const error = errors[0];<br/><br/>  if (error.dataPath.indexOf('.profile') === 0) {<br/>    return 'The profile provided is invalid.';<br/>  }<br/>  if (error.keyword === 'required') {<br/>    return 'Payload must contain at least the email and password fields';<br/>  }<br/>  if (error.keyword === 'type') {<br/>    return 'The email and password fields must be of type string';<br/>  }<br/>  if (error.keyword === 'format') {<br/>    return 'The email field must be a valid email.';<br/>  }<br/>  return 'The object is invalid';<br/>}<br/><br/>export default generateValidationErrorMessage;</pre>
<p>The <kbd>generateValidationErrorMessage</kbd> function extracts the first error object from the <kbd>ajvValidate.errors</kbd> array, and use it to generate the appropriate error message. There's also a generic, default error message in case none of the conditionals apply.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Generalizing functions</h1>
                
            
            
                
<p>At the moment, the <kbd>generateValidationErrorMessage</kbd> function produces messages that are specific to the Create User operations. This means that although the code is separated, the logic is still highly coupled to the Create User endpoint. This coupling defeats the purpose of modules; it is a code smell that should be eliminated.</p>
<p>Instead, we should program the <kbd>generateValidationErrorMessage</kbd> function to be able to generate error messages for all validation errors. Doing so also provides local consistency, because all validators will now have a consistent structure/format for their error messages.</p>
<p>So, let's make the change by replacing our <kbd>generateValidationErrorMessage</kbd> function with the following:</p>
<pre>function generateValidationErrorMessage(errors) {<br/>  const error = errors[0];<br/>  if (error.keyword === 'required') {<br/>    return `The '${error.dataPath}.${error.params.missingProperty}' field is missing`;<br/>  }<br/>  if (error.keyword === 'type') {<br/>    return `The '${error.dataPath}' field must be of type ${error.params.type}`;<br/>  }<br/>  if (error.keyword === 'format') {<br/>    return `The '${error.dataPath}' field must be a valid ${error.params.format}`;<br/>  }<br/>  if (error.keyword === 'additionalProperties') {<br/>    return `The '${error.dataPath}' object does not support the field '${error.params.additionalProperty}'`;<br/>  }<br/>  return 'The object is not valid';<br/>}</pre>
<p>Because this change will break our current implementation and tests, we must obtain approval from the product manager. If they approve, we must then update the E2E tests to reflect this change:</p>
<pre>Scenario Outline: Bad Request Payload<br/>  ...<br/>  <strong>And contains a message property which says "&lt;message&gt;"</strong><br/>  <br/>  Examples:<br/>  <br/>  <strong>| missingFields | message                          |</strong><br/><strong>  | email         | The '.email' field is missing    |</strong><br/><strong>  | password      | The '.password' field is missing |</strong><br/><br/>Scenario Outline: Request Payload with Properties of Unsupported Type<br/>  ...<br/><strong>  And contains a message property which says "The '.&lt;field&gt;' field must be of type &lt;type&gt;"</strong><br/>  ...<br/><br/>Scenario Outline: Request Payload with invalid email format<br/>  ...<br/>  <strong>And contains a message property which says "The '.email' field must be a valid email"</strong><br/>  ...<br/><br/>Scenario Outline: Invalid Profile<br/>  ...<br/>  <strong>And contains a message property which says "&lt;message&gt;"</strong><br/><br/>  Examples:<br/><br/>  | payload | <strong>message                                                   |</strong><br/>  | ...     | <strong>The '.profile' object does not support the field 'foo'    |</strong><br/>  | ...     | <strong>The '.profile.name' object does not support the field 'a' |</strong><br/>  | ...     | <strong>The '.profile.summary' field must be of type string       |</strong><br/>  | ...     | <strong>The '.profile.bio' field must be of type string           |</strong></pre>
<p>Next, import the <kbd>generateValidationErrorMessage</kbd> function into our <kbd>src/validators/users/create.js</kbd> file and update the <kbd>validateRequest</kbd> function so that we can use it to return an object containing an error message if validation fails:</p>
<pre><strong>import generateValidationErrorMessage from '../errors/messages';</strong><br/><br/>function validate(req) {<br/>  ...<br/>  const valid = ajvValidate(req.body);<br/>  if (!valid) {<br/>    <strong>return new ValidationError(generateValidationErrorMessage(ajvValidate.errors));</strong><br/>  }<br/>  return true;<br/>}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Updating the npm build script</h1>
                
            
            
                
<p>Everything looks good, but if we run the tests, they will return with the following error:</p>
<pre>Error: Cannot find module '../../schema/users/profile.json'</pre>
<p>This is because Babel, by default, only processes <kbd>.js</kbd> files. Therefore, our <kbd>.json</kbd> schema files were not processed or copied over to the <kbd>dist/</kbd> directory, which leads to the preceding error. To fix this, we can update our <kbd>build</kbd> npm script to use Babel's <kbd>--copy-files</kbd> flag, which will copy over any non-compilable files to the <kbd>dist/</kbd> directory:</p>
<pre>"build": "rimraf dist &amp;&amp; babel src -d dist --copy-files",</pre>
<p>Now, if we run our tests again, they should all pass.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Testing the success scenario</h1>
                
            
            
                
<p>Since we added the validation steps, we now need to ensure that requests carrying valid user payloads will get added to the database, just like before. Therefore, at the end of <kbd>spec/cucumber/features/users/create/main.feature</kbd>, add the following scenario outline:</p>
<pre>Scenario Outline: Valid Profile<br/><br/>  When the client creates a POST request to /users/<br/>  And attaches &lt;payload&gt; as the payload<br/>  And sends the request<br/>  Then our API should respond with a 201 HTTP status code<br/>  And the payload of the response should be a string<br/>  And the payload object should be added to the database, grouped under the "user" type<br/>  And the newly-created user should be deleted<br/><br/>  Examples:<br/><br/>  | payload                                                                         |<br/>  | {"email":"e@ma.il","password":"password","profile":{}}                          |<br/>  | {"email":"e@ma.il","password":"password","profile":{"name":{}}}                 |<br/>  | {"email":"e@ma.il","password":"password","profile":{"name":{"first":"Daniel"}}} |<br/>  | {"email":"e@ma.il","password":"password","profile":{"bio":"bio"}}               |<br/>  | {"email":"e@ma.il","password":"password","profile":{"summary":"summary"}}       |</pre>
<p>Run your tests again to make sure that they pass.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Resetting our test index</h1>
                
            
            
                
<p>At the moment, our test index on Elasticsearch is filled with dummy users. Although this is not an issue right now, it may become an issue in the future (for example, if we decide to change the schema). In any case, it's always a good practice to clean up side effects after the tests have finished in order to leave a blank slate for subsequent test runs. Therefore, at the end of each test, we should delete the Elasticsearch index. This is not a problem because the index will be recreated automatically by the test code.</p>
<p>Therefore, add the following lines below into our <kbd>e2e.test.sh</kbd> script; this will clean up the test index (you should place it after Elasticsearch is responsive, but before you run the API server):</p>
<pre># Clean the test index (if it exists)<br/><strong>curl --silent -o /dev/null -X DELETE "$ELASTICSEARCH_HOSTNAME:$ELASTICSEARCH_PORT/$ELASTICSEARCH_INDEX"</strong></pre>
<p>Run the tests again and they should still pass. Now, we can commit our changes to Git:</p>
<pre><strong>$ git add -A &amp;&amp; git commit -m "Fully validate Create User request payload"</strong></pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we have broken up our monolithic application into many smaller modules, and implemented all the requirements for our Create User feature. We integrated JSON Schema and Ajv into our validation modules, which forced us to be more consistent with the structure of our error messages. This, in turn, improves the experience of our end users.</p>
<p>In the next chapter, we will use Mocha and Sinon to write unit and integration tests, which will strengthen the confidence we have in our code.</p>


            

            
        
    </body></html>