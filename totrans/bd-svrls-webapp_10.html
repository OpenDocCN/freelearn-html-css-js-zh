<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Testing, Deploying, and Monitoring</h1>
                </header>
            
            <article>
                
<p>We are approaching the end of this book, but we can't finish without discussing some aspects that are beyond coding a solution. We need to understand how you can test functions that run in an environment that you don't own, what is a good development workflow to deploy and deliver new versions of your solution, and, although we don't need to worry about servers when building a serverless project, we need to understand what is the minimal monitoring that we need to configure to provide a cost-efficient and reliable solution.<br/>
In this chapter, we will cover the following topics:</p>
<ul>
<li>Testing a serverless solution</li>
<li>Defining how to handle the deployment and delivery of new versions</li>
<li>Monitoring errors, performance, and costs</li>
</ul>
<p>After this chapter, you'll have completed the book and will be prepared to build your next solution with serverless components or enhance an existing one benefiting from the serverless concept.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Testing your solution</h1>
                </header>
            
            <article>
                
<p>Testing a serverless project can be a challenging experience, since we rely on many different cloud services that are hard to emulate locally and, besides testing individual services, we need to test how they work together.</p>
<p>However, the practices that you have already used in traditional projects can all be used for serverless applications. To improve the quality of your software, you may use <strong>Test-Driven Development</strong> (<strong>TDD</strong>), <strong>Behavior-Driven Development</strong> (<strong>BDD</strong>), or any other development process that fundamentally relies on automating tests. Although we don't have access to the machines that will execute the code, we can simulate many things locally and we can run integrations tests from time to time to assert that everything works as expected.</p>
<p>In the following sections, we are going to see how to create tests for the backend and frontend. To make this topic simpler, we are going to create tests for trivial functions. If you want more extensive examples, you can browse the code files of this chapter to see how the serverless store was tested.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Unit testing Lambda functions</h1>
                </header>
            
            <article>
                
<p>Since a Lambda function is defined in a common JavaScript file, you just need to set your testing tool to load this file and test the function locally. To simulate the input data that is set by the API Gateway or another trigger, you need to set the <kbd>event</kbd> variable of your test according to the expected input.</p>
<p>Let's perform the following steps to see how to unit test a Lambda function:</p>
<ol>
<li>First, let's create a new serverless project by running the following command:</li>
</ol>
<pre>
<strong><span class="s1">      serverless create --template aws-nodejs --name testing</span></strong>
</pre>
<ol start="2">
<li>Now, let's modify the <kbd>serverless.yml</kbd> file to the following:</li>
</ol>
<pre>
       service: testing-service<br/><br/>       provider:<br/>         name: aws<br/>         runtime: nodejs6.10<br/><br/>       functions:<br/>         hello:<br/>           handler: functions/greetings.hello
</pre>
<p> </p>
<ol start="3">
<li>In this project, we have only one Lambda function, and this <kbd>hello</kbd> function is defined by a <kbd>greetings.js</kbd> file inside a folder named <kbd>functions</kbd>. Consider the following simple implementation:</li>
</ol>
<pre>
        module.exports.hello = (event, context, callback) =&gt; {<br/>          const message = `Hello, ${event.name}!`<br/>          callback(null, message);<br/>        };
</pre>
<ol start="4">
<li>This <kbd>hello</kbd> function is the function that we want to test. Now, let's create our testing code. In the following screenshot, we show the project tree, where a folder named <kbd>test</kbd> was created and it contains a <kbd>mocha.opts</kbd> file, along with two other folders, <kbd>unit</kbd> and <kbd>integration</kbd>. Since this sample code doesn't interact with any other service, we can call it a <kbd>unit</kbd> test and the file <kbd>test-greetings.js</kbd> is where it will be implemented:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" height="208" src="assets/292f8892-ccf8-47e1-b638-6efa46ddc8e2.png" width="248"/></div>
<ol start="5">
<li>We can exclude this <kbd>test</kbd> folder and all of its contents from the deployment package by adding an exclude rule at the end of the <kbd>serverless.yml</kbd> file:</li>
</ol>
<pre>
        package:<br/>          exclude:<br/>            - test/**
</pre>
<ol start="6">
<li>Regarding the <kbd>mocha.opts</kbd> file, it was included to configure the options for the Mocha test framework (<a href="https://mochajs.org/">https://mochajs.org/</a>), but you can use any other testing tool.</li>
</ol>
<p> </p>
<ol start="7">
<li>In this <kbd>mocha.opts</kbd> file, I've added only one line of code to specify which folder must be used to run tests:</li>
</ol>
<pre>
<span>        test/unit</span>
</pre>
<p style="padding-left: 90px">The <kbd>unit</kbd> folder will hold unit tests, which are tests that must execute in milliseconds so that the developer can immediately assert the state of the code with each modification. The <kbd>integration</kbd> folder holds tests that access external services and are allowed to complete in seconds/minutes. These are designed to execute occasionally, usually once a day, and not as frequently as unit tests. So, they were not included in the options.</p>
<ol start="8">
<li>Mocha is installed through npm, so we need to add a <kbd>package.json</kbd> file and execute the following command:</li>
</ol>
<pre>
<strong>        npm install mocha --save-dev</strong>
</pre>
<ol start="9">
<li>In the <kbd>package.json</kbd> file, add a <kbd>test</kbd> command with the <kbd>mocha</kbd> value in the <kbd>scripts</kbd> field. It will be helpful later, since you can run the <kbd>npm test</kbd> command to execute the unit tests:</li>
</ol>
<pre>
        {<br/>            "name": "testing",<br/>            "version": "1.0.0",<br/><strong>            "scripts": {</strong><br/><strong>                "test": "mocha"</strong><br/><strong>            },</strong><br/>            "devDependencies": {<br/>                "mocha": "^3.2.0"<br/>            }<br/>        }
</pre>
<ol start="10">
<li>Now that we have properly set up the test environment, we can implement the test file named <kbd>test-greetings.js</kbd>. To use Mocha, we need to use the <kbd>describe</kbd> function to list the test cases and the <kbd>it</kbd> function to implement a test case:</li>
</ol>
<pre>
        const assert = require('assert');<br/><br/>        // list the unit tests of the greetings function<br/>        describe('Greetings', () =&gt; {<br/><br/>          // this is the only test that we have for this file<br/>          describe('#hello()', () =&gt; {<br/><br/>            // the `done` argument must be used only for <br/>            // async tests, like this one<br/>            it('should return hello + name', (done) =&gt; {<br/><br/>              // the test code will be defined here<br/><br/>            }); <br/>          });<br/>        });
</pre>
<ol start="11">
<li>For this Lambda function, we can implement the following test:</li>
</ol>
<pre>
        // load the Lambda function<br/>        const greetings = require('../../lib/greetings');<br/><br/>        // set the event variable as expected by the function<br/>        const event = { <br/>          name: 'John'<br/>        };<br/><br/>        // context can be null in this test<br/>        const context = null;<br/> <br/>        // invoke the function locally<br/>        greetings.hello(event, context, (err, response) =&gt; {<br/>            <br/>          const expected = 'Hello, John!';<br/>          const actual = response;<br/>    <br/>          // testing if the result is the expected<br/><strong>          assert.equal(expected, actual);</strong><br/><br/>          // exiting successfully if `err` variable is null<br/>          done(err);<br/>        });
</pre>
<p> </p>
<ol start="12">
<li>To execute the tests, run <kbd>npm test</kbd>. You should receive the following output:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" height="271" src="assets/389eeef3-3b6f-443d-b14d-61c686f7bee0.png" width="433"/></div>
<ol start="13">
<li>As a good practice, you should always <em>test</em> the test. You can do this by changing the expected result from <kbd>Hello, John!</kbd> to <kbd>Bye, John!</kbd>, which will obviously make the assert fail, resulting in the following output:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" height="270" src="assets/a49fc326-18c0-4f40-9688-3e49dbba583a.png" width="432"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Mocking external services</h1>
                </header>
            
            <article>
                
<p>Sometimes, you can't unit test a Lambda function directly simply because, sometimes, you can't consider the function as a <em>unit</em>. If the function interacts with external services, like sending a notification or persisting some data in a database, you can't consider it as a unit of logic. In this case, you can only unit test the function if you remove such dependencies from the test, and you do so by <em>mocking</em> them.</p>
<p>Mocking is the act of building an object to simulate the behavior of another object. When we need to test a complex service, there are many underlying behaviors that we may not be interested in testing. For example, if I use an external service to process credit card payments and I want to test whether it processes correctly for a given input, I don't want to handle unexpected events such as connectivity issues. In this case, I could create a fake object that would imitate the expected behavior and my test case would return success or failure if a specific condition is met.</p>
<p>To be able to mock services, we need to separate the business logic from external services. With this approach, we can write unit tests and keep the solution less dependent of cloud services, which helps if one day you need to migrate from one cloud provider to another.</p>
<p>The following code shows an example where there <strong>isn't</strong> a clear separation of the business logic and services. Therefore, it is harder to test:</p>
<pre class="mce-root">
    const db = require('db');<br/>    const notifier = require('notifier');<br/><br/>    module.exports.saveOrder = (event, context, callback) =&gt; {<br/><br/><strong>      db.saveOrder(event.order, (err) =&gt; {</strong><br/>        if (err) {<br/>          callback(err);<br/>        } else {<br/><strong>          notifier.sendEmail(event.email, callback);</strong><br/>        }<br/>      });<br/>    };
</pre>
<p>This example receives an order information, saves it in a database, and sends an e-mail notification. There are two main problems here such as the code is bound to the input (how it handles the <kbd>event</kbd> object) and you can't unit test the inner contents of the Lambda function without triggering requests to the database and the notification service.</p>
<p>A better implementation is to create a separated module that will control the business logic, and to build this module allowing you to inject the dependencies:</p>
<pre class="mce-root">
    class Order {<br/><br/><strong>      // Dependency Injection</strong><br/>      constructor(db, notifier) {<br/>        this.db = db;<br/>        this.notifier = notifier;<br/>      }<br/><br/><strong>      save(order, email, callback) { </strong><br/><strong>        this.db.saveOrder(order, (err) =&gt; {</strong><br/>          if (err) {<br/>            callback(err);<br/>          } else {<br/><strong>            this.notifier.sendEmail(email, callback);</strong>          <br/>          }<br/>        });<br/>      }<br/>    }<br/><br/>    module.exports = Order;
</pre>
<p>Now, this code can be unit tested since the database and notifier services are passed as input values, so they can be mocked.</p>
<p>Regarding the Lambda code, it becomes much simpler:</p>
<pre class="mce-root">
    const db = require('db');<br/>    const notifier = require('notifier');<br/>    const Order = require('order');<br/><br/>    const order = new Order(db, notifier);<br/><br/>    module.exports.saveOrder = (event, context, callback) =&gt; {<br/>      order.save(event.order, event.email, callback);<br/>    };
</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using Sinon.JS for mocking</h1>
                </header>
            
            <article>
                
<p>In the previous example, we improved the Lambda function by creating an external module, named <kbd>Order</kbd>, to handle all actions related to orders. This was necessary because we can only mock the objects that we have access to. We won't be able to test the Lambda function directly because we don't have access to the services that it uses (database and notifications), but at least we will be able to test the <kbd>Order</kbd> class, since it allows the services to be injected.</p>
<p>For our mocking example, we are going to use Sinon.JS. It can be installed with the following command:</p>
<pre>
<strong>    npm install sinon --save-dev</strong>
</pre>
<p>Sinon will be used along with Mocha. So, we will need to create a test case like the following one:</p>
<pre class="mce-root">
    const assert = require('assert');<br/><strong>    const sinon = require('sinon');</strong><br/>    const Order = require('./order');<br/><br/>    describe('Order', () =&gt; {<br/>      describe('#saveOrder()', () =&gt; {<br/>        it('should call db and notifier', (done) =&gt; {<br/>        <br/>          // the test code will be defined here<br/><br/>        });<br/>      }); <br/>    });
</pre>
<p>We can implement this test as the following:</p>
<pre class="mce-root">
<strong>    // define the behavior of the fake functions</strong><br/>    const dbMock = {<br/>      saveOrder: (order, callback) =&gt; {<br/>        callback(null);<br/>      }<br/>    }  <br/><br/>    const notifierMock = {<br/>      sendEmail: (email, callback) =&gt; {<br/>        callback(null);<br/>      }<br/>    }<br/><br/><strong>    // spy the objects to identify when and how they are executed<br/>    sinon.spy(dbMock, 'saveOrder');</strong><br/><strong>    sinon.spy(notifierMock, 'sendEmail');</strong><br/><br/>    // define the input event <br/>    const event = { <br/>      order: { id: 1 },<br/>      email: 'example@example.com'<br/>    };<br/><br/><strong>    // inject the mocked objects</strong><br/><strong>    const order = new Order(dbMock, notifierMock);</strong><br/><br/>    // execute the function<br/>    order.save(event.order, event.email, (err, res) =&gt; {<br/><br/><strong>      // assert if the mocked functions were used as expected</strong><br/>      assert(dbMock.saveOrder.calledOnce, true);<br/>      assert(notifierMock.sendEmail.calledOnce, true);<br/>      assert(dbMock.saveOrder.calledWith(event.order), true);<br/>      assert(notifierMock.sendEmail.calledWith(event.email), true);<br/><br/>      done(err);<br/>    });
</pre>
<p>This example shows that you can use Sinon.JS to check whether your dependencies are being called as expected and with the correct parameters. You can improve this example, adding fake responses and testing different behaviors, but we won't go deeper into this subject because those features are not strictly related to serverless. The objective here is to show that common testing frameworks can be used with serverless without needing anything special to configure them.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Testing the frontend</h1>
                </header>
            
            <article>
                
<p>We have developed the frontend using React, so we will build a simple example to show how you can test it. The objective is to see if a simple component renders correctly and if it displays a text as expected.</p>
<p>Let's take a look at the following steps to create this example:</p>
<ol>
<li>We will start by creating a new React project executing the following command:</li>
</ol>
<pre>
<strong>        create-react-app frontend-test</strong>
</pre>
<ol start="2">
<li>Create React App uses Jest as its test runner. As a convention, it will always looks for files that end with <kbd>.test.js</kbd> to execute the tests. In the default template, we have the <kbd>App.js</kbd> and <kbd>App.test.js</kbd> files. If you run <kbd>npm test</kbd>, Jest will execute the sample test that was created in <kbd>App.test.js</kbd> and it will output the following result:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" src="assets/cbdf4bfd-3d05-4442-8927-ae6063c0af4e.png"/></div>
<div class="packt_infobox">After running <kbd>npm test</kbd>, Jest will be watching for changes, so you can continue developing your frontend and Jest will execute all test cases whenever you save a file.</div>
<p> </p>
<ol start="3">
<li>Inside <kbd>App.js</kbd>, we have an <kbd>App</kbd> component defined by the following code:</li>
</ol>
<pre>
        render() {<br/>          return (<br/>            &lt;div className="App"&gt;<br/>              &lt;div className="App-header"&gt;<br/>                &lt;img src={logo} alt="logo"/&gt;<br/><strong>                &lt;h2&gt;Welcome to React&lt;/h2&gt;</strong><br/>              &lt;/div&gt;<br/>            &lt;/div&gt;<br/>          );<br/>        }
</pre>
<ol start="4">
<li>And <kbd>App.test.js</kbd> is defined by the following code, which is just a smoke test to see if the component can be rendered without crashing:</li>
</ol>
<pre class="mce-root">
        import React from 'react';<br/>        import ReactDOM from 'react-dom';<br/>        import App from './App';<br/><br/>        it('renders without crashing', () =&gt; {<br/><strong>          const div = document.createElement('div');</strong><br/><strong>          ReactDOM.render(&lt;App/&gt;, div);</strong><br/>        });
</pre>
<ol start="5">
<li>Now we are going to improve this test case and we will need to install two helper tools such as Enzyme and react-test-renderer:</li>
</ol>
<pre>
<strong>        npm install enzyme react-test-renderer --save-dev</strong>
</pre>
<ol start="6">
<li>With Enzyme, we can simplify the previous example by using the <kbd>mount</kbd> function instead of <kbd>ReactDOM.render</kbd>:</li>
</ol>
<pre class="mce-root">
        import React from 'react';<br/>        import ReactDOM from 'react-dom';<br/>        import App from './App';<br/><strong>        import { mount } from 'enzyme';</strong><br/><br/>        it('renders without crashing', () =&gt; {<br/><strong>          mount(&lt;App/&gt;);</strong><br/>        });
</pre>
<p> </p>
<ol start="7">
<li>To finish this example, we are going to add another test case to see if a given element, <kbd>&lt;h2&gt;Welcome to React&lt;/h2&gt;</kbd>, was rendered within this component as we are expecting:</li>
</ol>
<pre>
        it('renders with "Welcome to React"', () =&gt; {<br/>          const wrapper = mount(&lt;App/&gt;);<br/>          const welcome = &lt;h2&gt;Welcome to React&lt;/h2&gt;;<br/>          expect(<strong>wrapper.contains(welcome)</strong>).toEqual(true);<br/>        });
</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Simulating AWS services locally</h1>
                </header>
            
            <article>
                
<p>One of the drawbacks of using cloud services is that they offer products that you can't install on your own machine. If you could install them, your development speed would increase because testing locally is faster them connecting to them through the Internet.</p>
<p>To solve this limitation, there are many tools that have been created by the community to help you to simulate AWS services by running them locally. You can find some of them in the following links:</p>
<ul>
<li><strong>Lambda functions</strong>: <a href="https://github.com/lambci/docker-lambda">https://github.com/lambci/docker-lambda</a></li>
<li><strong>API Gateway and Lambda</strong>: <a href="https://github.com/dherault/serverless-offline">https://github.com/dherault/serverless-offline</a></li>
<li><strong>Scheduled Lambda functions</strong>: <a href="https://github.com/ajmath/serverless-offline-scheduler">https://github.com/ajmath/serverless-offline-scheduler</a></li>
<li><strong>DynamoDB</strong>: <a href="https://github.com/mhart/dynalite">https://github.com/mhart/dynalite</a><a href="https://github.com/sdd/serverless-dynalite"/></li>
</ul>
<p>There are some benefits and drawbacks with this strategy. Particularly, I don't buy this idea and I don't use them. You can find my view of the pros and cons as follows and decide for yourself if those tools may improve your development workflow:</p>
<p><strong>Pros:</strong></p>
<ul>
<li><strong>Speed</strong>: It is faster to run locally than using the Internet.</li>
<li><strong>Tests</strong>: Some tools are just mocks that simulate the behavior of a real service without making any I/O operations, which means that you can test your services without changing your code. Others are similar implementations that allows you to debug your code.</li>
<li><strong>Costs</strong><span><span>: You can run them for free using your own machine.</span></span></li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li><strong>Speed</strong>: Most services need extra configuration steps. For a small project, you may take more time configuring and troubleshooting issues with the fake services than you will benefit from faster tests.</li>
<li><strong>Tests</strong>: It is hard to feel confident in your tests if you are using only simulated services. You need to run integration tests with real services from time to time. Also, you may not be able to do some tests. For example, simulating IAM permissions is really hard.</li>
<li><strong>Costs</strong>: You may spend more developer-hours configuring those tools than you will save on cloud costs. Most cloud providers have adopted a pricing schema where they offer a free tier that allows developers to build and test their products for free and the providers just start to charge money when the service is used intensively.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deploying your application</h1>
                </header>
            
            <article>
                
<p>In this section, we will discuss the deployment of a serverless application. I'm not referring to just running the <kbd>serverless deploy</kbd> command, what I mean is that you need to know and define how to handle and manage new versions of your application in the production environment.</p>
<p>Can you hit the deploy button at any time of the day? What are the implications? How can you create a replica of the production environment just for testing? Those are the kind of things that will be discussed in this section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Development workflow</h1>
                </header>
            
            <article>
                
<p>Deploying a new version of a Lambda function is a simple task. We run a command and the framework is responsible for packaging the contents and uploading them to AWS. However, running the <kbd>serverless deploy</kbd> command usually takes a couple of minutes. The problem is not the time to upload the ZIP file, but what the framework needs to update using CloudFormation. A new CloudFormation template needs to be issued asking AWS to update all related resources of a specific zone, which takes time. As our codebase grows, we may need to create dozens of API Gateway endpoints, many different IAM roles, or other kinds of AWS resources. Managing them can be troublesome, as they increase the deployment time to an unpleasant duration.</p>
<p>Reducing this time can be achieved using selective deployment. If you have modified just a specific function, you can make a fast deploy by referencing it using the following command:</p>
<pre>
<strong>    serverless deploy function -f myFunction</strong>
</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Blue-green deployment</h1>
                </header>
            
            <article>
                
<p>Blue-green deployment is a common technique to deploy a new version of software without generating unavailability. Consider that you're running an application of the 3.0 version and you want to deploy the new 3.1 version. Before you start updating your machines, all of them are using the 3.0 version and we say that they are in a <em>blue</em> state. We start by creating new machines with the updated code, version 3.1, and these machines are in a <em>green</em> state. The next step is to modify the load balancer to redirect all new connections to the new machines (green) while it keeps on running requests to the old machines (blue). After the previous calls finish running, the <em>blue</em> machines won't receive any new requests, and they can be shutdown.</p>
<p>Blue-green is important because, in the past, as we usually had just one web server machine to handle an application, the common practice was to stop the web server, update the code, and start it again. Those few seconds of unavailability were acceptable in the past, but today, with automation and the possibility of distributing the load among multiple servers, it is not necessary anymore to disrupt the service for an update or maintenance routine.</p>
<p>This concept is equivalent in the serverless world. When you update the code of a Lambda function, AWS will use it to handle new incoming requests while the previous one will keep running with the previous code. The API Gateway will also handle modifications in the endpoints behaviors without causing unavailability:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" src="assets/72c5f8ca-50f5-46d6-a1d2-335823f3dde2.png"/></div>
<p>So, answering the previous question: can you hit the deploy button at any time of the day? Yes, you can deploy new versions of your application without worrying about availability. However, during the deployment of a new version, we can have different versions running simultaneously. You should pay attention to this case, especially regarding versions that require changes to the database model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deploying new versions with a different database model</h1>
                </header>
            
            <article>
                
<p>In serverless, we usually run code that executes in fractions of a second. So, running two different versions simultaneously may take less than a second, but how do we apply databases changes in a model? Renaming a column may break the execution of a previous version.</p>
<p>Ideally, we would all be using NoSQL databases with flexible schemas, but that's not true. Some business cases are better handled by relational databases or NoSQL databases with a restrict schema.</p>
<p>When modifying a schema, there are three operations that require our attention such as create, rename, and drop.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a new table or column</h1>
                </header>
            
            <article>
                
<p>Adding a table or a column in a pre-existing table shouldn't break any kind of application. However, there are some ORM tools, such as the Entity Framework (for .NET), that associates each schema version with a migration ID. In this case, when you run a migrate command to upgrade a database schema, it adds a new migration ID that will be checked by the application code. If you run the previous version of the code, the ID will not match and it will return an error.</p>
<p>This kind of restriction was created as a safety measure to avoid a deprecated code from running in production and causing inconsistencies when the expected model is different. Though, if you have proper control over your deployments, you can disable this restriction to avoid unavailabilities while upgrading versions.</p>
<p>Also, we need to pay attention when we add constraints or foreign keys. If you modify a table with thousands of rows to add a new foreign key, the alter table command may need some significant time to process. While processing, the table will be locked for selects and this can lead to some query timeouts.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Renaming a table or column</h1>
                </header>
            
            <article>
                
<p>Suppose you need to rename a column from name <kbd>A</kbd> to <kbd>B</kbd>. If you make this change, the previous code may not work properly, since it won't find the column with name <kbd>A</kbd> and the newest code may not work if deployed before the rename happens.</p>
<p>The proposed solution here is to make this change by performing the following steps:</p>
<ol>
<li>Run a script to create a new column named <kbd>B</kbd>.</li>
<li>Add a temporary trigger that will execute every time that you modify some data in the <kbd>A</kbd> column to apply the same modifications to the <kbd>B</kbd> column.</li>
<li>Duplicate all contents from <kbd>A</kbd> to <kbd>B</kbd>.</li>
<li>Deploy a new code version that is exactly like the previous one, but read/write using the column <kbd>B</kbd> and not <kbd>A</kbd>.</li>
</ol>
<p> </p>
<ol start="5">
<li>Wait a bit to ensure that all requests are using the new Lambda code and not the previous one. You may need to wait for the maximum timeout of your Lambda functions.</li>
<li>Run another script that will remove column <kbd>A</kbd> and the temporary trigger.</li>
<li>Deploy your up-to-date code that uses column <kbd>B</kbd> and adds new features to your application.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Dropping a table or column</h1>
                </header>
            
            <article>
                
<p>Dropping a table or column is a little bit easier. You just need to deploy a new application code that doesn't use the table or field that you want to remove. After waiting a little bit to ensure that the previous code has finished being executed, you can safely execute a script that will delete the table or remove the field.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Rollback a deployment</h1>
                </header>
            
            <article>
                
<p>Sometimes, we deploy a new version of an application that may introduce a buggy feature. Depending on the error severity, you may need to rollback the application before starting to fix the error for a new deployment. You have two options for this rollback:</p>
<ol>
<li>Version control all deployments in tags. When you need to rollback, select the code from the previous tag and run <kbd>serverless deploy</kbd> again.</li>
<li>Use the <kbd>serverless rollback</kbd> command to change your functions to a previous version.</li>
</ol>
<p>AWS has a versioning system for our deployments, so using the <kbd>serverless rollback</kbd> command is safe and fast. This command should be used passing a <kbd>timestamp</kbd> parameter, like the following:</p>
<pre>
<strong>    serverless rollback --timestamp &lt;timestamp&gt;</strong>
</pre>
<p>To find the timestamp information of our last deploy, we need to run the following command:</p>
<pre>
<strong>    serverless deploy list</strong>
</pre>
<p>It will give you the following output:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" height="287" src="assets/4d947e54-8d26-4d11-8dd3-42d6b1edabf9.png" width="458"/></div>
<p>In the previous screenshot, we would use the value <kbd>1499216616127</kbd> for the <kbd>timestamp</kbd> parameter. Note that we need to select the penultimate version and not the last one.</p>
<div class="packt_infobox">The command <kbd>serverless rollback</kbd> will rollback all functions for a previous deployment that was done with the command <kbd>serverless deploy</kbd>. If you used <kbd>serverless deploy function</kbd>, this change won't be versioned.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating staging environments</h1>
                </header>
            
            <article>
                
<p>Best practice says that we must have different environments for development and production. You can also add a third environment, usually named <em>staging</em>, for testing:</p>
<ul>
<li><strong>Development</strong>: This is where you deploy code as a work in progress, testing that it works together with other services</li>
<li><strong>Staging</strong>: This is usually necessary to validate the build by customers or a quality assurance team</li>
<li><strong>Production</strong>: This is where your application is visible by end users</li>
</ul>
<p>All software that we develop is highly dependent on the environment, such as the operating system, runtime version, installed modules and dlls, external services, configuration files, and others. Therefore, it was a pretty common excuse, at least some years ago, for a developer to explain production errors saying that "it works on my machine". Mirroring the development environment with the production setting was a very difficult task. Sometimes, changes applied to one were not reflected to the other, causing strange errors.</p>
<p>With virtual machines, and more recently with Docker containers, this issue has greatly diminished, since we can now trust that we can perfectly reproduce production errors in our development machines and that what we build will work exactly as expected, regardless of the machine that executes it.</p>
<p>With cloud providers, all of our infrastructure can be scripted. So, we can automate how an environment can be created through code. In this case, you just need to change a variable value and deploy it again to mirror your development code with the production code. In your <kbd>serverless.yml</kbd> file, there is an option under <kbd>provider</kbd> that allows you to name your current environment and easily mirror it to others simply by choosing a new name for the <kbd>stage</kbd> property:</p>
<pre>
    service: serverless-app<br/><br/>    provider:<br/>      name: aws<br/>      runtime: nodejs6.10<br/><strong>      stage: dev</strong><br/>      region: us-east-1
</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Being careful with the production environment</h1>
                </header>
            
            <article>
                
<p>Being able to easily mirror the development environment to production is a very powerful feature that needs to be used wisely. In my earlier days as a developer, I had the unfortunate habit of having the staging and production virtual machines open simultaneously. Which, of course, I stopped doing the day I messed with a production service thinking that I was changing the staging version.</p>
<p>What I recommend is to use the staging option to mirror the <em>development</em> environment with the <em>testing</em> environment. You can easily deploy a new version for your customer or for your quality assurance team, but you should <em>never</em> use your development machine to apply updates in production to avoid the associated risks.</p>
<div class="packt_tip">Creating a new environment is as simple as choosing a new name for the <kbd>stage</kbd>. So, you can name it with things like <kbd>test-2017-08-02</kbd> or <kbd>test-feature-x</kbd> to create new endpoints with a specific test environment.</div>
<p>You can designate someone in the team who will be the only person responsible for deploying a new production version. Restricting the responsibility to just one person will reduce the chance of accidents. Another option is to have one machine with the sole purpose of production deployments. Needing an extra step, which is to connect with the machine, helps because it forces you to be focused on the task and you won't accidentally select the wrong environment.</p>
<p>Furthermore, I also recommend that you have two different AWS accounts, one for development and testing, and another one exclusively for production. Although it is possible to configure the IAM roles to protect your environment and prevent the same user from modifying both environments, it is still risky. The IAM restrictions may be incorrectly configured, or you could add a new resource and forget to set the proper access, allowing undesired changes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Test data</h1>
                </header>
            
            <article>
                
<p>When you have your entire infrastructure scripted, the only difference between the development and production environments is the associated data. The test environment usually has its own fabricated data, but sometimes we can't reproduce errors, for example, performance issues or inconsistencies, because the underlying data is different.</p>
<p>However, making a backup of the production data and directly restoring a copy into the testing environment can be a bad practice for the following reasons:</p>
<ul>
<li>Production data contains real e-mails. Running test code may send accidental e-mails to real people.</li>
<li>Production data contains sensitive data such as real names, e-mails, phone numbers, and addresses. Sharing this data with all developers is unnecessary and risky. The developer machine is much more unsafe and susceptible to being hacked than the production environment.</li>
</ul>
<p>In this case, I recommend using fabricated data for most of the tests, and when you need to make performance tests or analyze a specific issue, you use a production backup but you need to have a procedure in place to modify the content, removing sensitive data before sharing the data with all developers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Keeping your functions warm</h1>
                </header>
            
            <article>
                
<p>As we have discussed in past chapters, one of the problems with serverless functions is the cold starts. When your Lambda function is triggered, AWS will find its package, unzip, and install it in a container to be executed. These steps takes some time (usually 5 seconds) and they delay the execution of your function.</p>
<p>After executing a function, AWS will keep it in a suspended state for a while. If a new request is done a few minutes later, it won't suffer from the cold start delay because the package will be readily available. After 15 minutes of inactivity, it will <em>freeze</em> again.</p>
<p>If your application needs to ensure low response times, you can deploy them with a configuration to keep them <em>warm</em>. There is a plugin for the Serverless Framework called <strong>WarmUP</strong> (<a href="https://github.com/FidelLimited/serverless-plugin-warmup">https://github.com/FidelLimited/serverless-plugin-warmup</a>) that will create a scheduled Lambda function that will be responsible by invoking the other functions from time to time (default it to 5 minutes).</p>
<p>Let's follow the following steps to see how to use it:</p>
<ol>
<li>Create a new serverless project by executing the following command:</li>
</ol>
<pre>
<strong><span class="s1">        serverless create --template aws-nodejs --name warmup</span></strong>
</pre>
<ol start="2">
<li>Create a <kbd>package.json</kbd> file.</li>
<li>Install the WarmUP plugin by executing the following command:</li>
</ol>
<pre>
<strong>      npm install serverless-plugin-warmup --save-dev</strong>
</pre>
<ol start="4">
<li>Add the following reference to the end of the <kbd>serverless.yml</kbd> file:</li>
</ol>
<pre>
<strong>        plugins:</strong><br/><strong>          - serverless-plugin-warmup</strong>
</pre>
<ol start="5">
<li>For each function that you want to keep warm, add the <kbd>warm: true</kbd> pair:</li>
</ol>
<pre>
        functions:<br/>          hello:<br/>            handler: handler.hello<br/><strong>            warmup: true</strong>
</pre>
<ol start="6">
<li>This plugin will invoke other functions, so we need to give it the necessary permission:</li>
</ol>
<pre>
        iamRoleStatements:<br/>          - Effect: 'Allow'<br/>            Action:<br/>              - 'lambda:InvokeFunction'<br/>            Resource: "*"
</pre>
<ol start="7">
<li>The last step is to modify the Lambda function to ignore requests created by this plugin:</li>
</ol>
<pre>
        module.exports.hello = (event, context, callback) =&gt; {<br/> <br/><strong>          if (event.source === 'serverless-plugin-warmup') {</strong><br/><strong>            console.log('WarmUP - Lambda is warm!')</strong><br/><strong>            return callback(null, 'Lambda is warm!')</strong><br/><strong>          }</strong><br/> <br/>          callback(null, { message: 'Hello!' });<br/>        };
</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monitoring the operation</h1>
                </header>
            
            <article>
                
<p>The serverless concept is defined as running your code without worrying about the infrastructure that will be responsible for supporting it. This still holds true, but there are some DevOps tasks that may improve your application's efficiency and stability. Therefore, you should not confuse serverless with NoOps. You just don't need to worry <em>that</em> much about the infrastructure.</p>
<p>Since we are using AWS, we are going to use its monitoring tool: Amazon CloudWatch. There are some other paid and free tools that can also be used for this task, so feel free to compare them before selecting your own tool.</p>
<p>To use CloudWatch, open the Management Console at <a href="https://console.aws.amazon.com/cloudwatch">https://console.aws.amazon.com/cloudwatch</a>, and let's see in the following subsections how we can monitor our Lambda functions:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" src="assets/d0d1718b-80e4-409a-840d-da3bd62dc665.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monitoring costs</h1>
                </header>
            
            <article>
                
<p>Estimating costs in serverless is a difficult task, since it depends highly on usage. Also, deploying a new function may result in unexpected costs due to programming errors. For example, consider that you set a function with a timeout of 5 minutes and 1 GB of RAM. Maybe it is supposed to execute in a few milliseconds 95% of the time, but due to an error, it may freeze every time and run indefinitely, just stopping after the timeout is reached.</p>
<p>Another scenario is when you use a Lambda function to call another Lambda function, but a programming error may create an endless loop causing your Lambda functions to execute constantly. In fact, AWS has some limits and measures to prevent these kind of errors, but that's something that we should pay attention to avoiding.</p>
<p>You can always open your AWS Billing dashboard to track your monthly expenses, but when these kind of issues occur, you want to be at least warned as soon as possible. In this case, you can set a billing alert to send an e-mail if the monthly cost reaches an unexpected level.</p>
<p>Let's monitor the costs by performing the following steps:</p>
<ol>
<li>Open your <span class="packt_screen">CloudWatch</span> console and browse the <span class="packt_screen">Billing</span> link in the left-hand side menu, followed by <span class="packt_screen">Create Alarm:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" height="178" src="assets/04986da6-29f8-48dc-80d5-24dd225f4392.png" width="114"/></div>
<ol start="2">
<li>On the next screen, select <span class="packt_screen">Billing Metrics:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" height="363" src="assets/087d4c19-bcd6-49e3-94ac-840b177937d2.png" width="480"/></div>
<ol start="3">
<li>CloudWatch allows you to create a billing alert for the entire account or to filter the alert by service. In this case, you can select the <span class="packt_screen">AWSLambda</span> service and click on <span class="packt_screen">Next:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" src="assets/74d52908-9f99-4ad0-b034-a8abf94b97f2.png"/></div>
<ol start="4">
<li>On the last screen, you can set a threshold for the alarm and define which persons it should notify if it goes beyond an acceptable value:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" src="assets/b500d879-faea-4a3e-b93c-deb69078cbb0.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monitoring errors</h1>
                </header>
            
            <article>
                
<p>Going back to the <span class="packt_screen">CloudWatch</span> console home screen, click on the <span class="packt_screen">Browse Metrics</span> button located at the center. It will redirect you to another page where you can select all the metrics available to your Lambda functions. You can choose to monitor by function name, resource, or across all functions. The available metrics are as follows:</p>
<ul>
<li><strong>Errors</strong>: This is the metric of the number of times that the Lambda function stopped prematurely due to an error, or it has stopped after reaching the timeout limit. This is an important metric because, ideally, you expect to see zero errors in production and will want to be warned when an error is detected.</li>
<li><strong>Invocations</strong>: This is the metric of the number of times that your Lambda function was invoked. If this function is executed by a schedule, you may want to be notified if it executes more times than expected. Also, using this metric, you may track when executions go out of control if the function is executed more times than a reasonable value.</li>
<li><strong>Duration</strong>: With this metric, you can track if your function is taking longer than expected to execute.</li>
<li><strong>Throttles</strong>: This metric is counted every time the function is not executed because the limit of concurrent Lambda functions is reached. This value can be increased if you open a support ticket to AWS, but the default value is 1,000 and it can be very low for some use cases.</li>
</ul>
<p>As you can see, these metrics are automatically monitored and you can build some graphs with historical data. If you want to set alarms, go back to the <span class="packt_screen">Console Home</span> page and click on <span class="packt_screen">Alarms</span> in the left-hand side menu, followed by <span class="packt_screen">Create Alarms</span>, and configure the recipients as you wish.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Retrieving metrics with the Serverless Framework</h1>
                </header>
            
            <article>
                
<p>You can use the Serverless Framework to retrieve CloudWatch metrics. It can be a useful feature to take a quick look at the application's operation without browsing the <span class="packt_screen">CloudWatch</span> console.</p>
<p>The following screenshot shows the output of the <kbd>serverless metrics</kbd> command:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" src="assets/f8d5f14a-037d-4baa-aec9-69adc9cb745d.png"/></div>
<p>This command can be used to see the combined operation of all functions (<kbd>serverless metrics</kbd>) or the stats of just one function (<kbd>serverless metrics --function &lt;your-function&gt;</kbd>).</p>
<p>Also, you can filter by a date range using the arguments <kbd>--startTime</kbd> and <kbd>--endTime</kbd>. The following command will include only stats related to events that happened in the last 30 minutes:</p>
<pre>
<strong>    serverless metrics --startTime 30m</strong>
</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Streaming Lambda logs</h1>
                </header>
            
            <article>
                
<p>When an error occurs in a Lambda execution, the error message is usually insufficient. For example, consider the following error message:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" src="assets/b78b9183-cac1-472a-8997-04f807e15abf.png"/></div>
<p>You can retrieve more details about the error message by streaming logs to the terminal. You can hook to a specific function and receive the history of error messages and live errors. For this, run the following command:</p>
<pre>
<strong>    serverless logs -f myFunction --tail</strong>
</pre>
<p>The <kbd>--tail</kbd> argument indicates that you want to listen to new error messages. You can also use <kbd>--filter word</kbd> to show only messages that match the filter or <kbd>--startTime</kbd> to specify the range of logs that you want to see. For example, <kbd>--startTime 2h</kbd> shows logs from the last two hours.</p>
<p>The log messages show the stack trace of the errors, which is much more useful to understand the root cause of an issue:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" height="310" src="assets/cf8b7e30-4d5f-46fa-bfef-c425b09b59cc.png" width="472"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Handling errors</h1>
                </header>
            
            <article>
                
<p>When a function executes with errors, Lambda offers two handlers such as SNS and SQS. You can use them to handle events that have failed, so you may try them again later or retrieve additional information to understand what caused the issue.</p>
<p>SNS is used to notify on errors and SQS is used to create a queue of failed Lambda tasks that can be processed by another service:</p>
<pre>
    functions:<br/>      hello:<br/>        handler: handler.hello<br/><strong>        onError: &lt;ARN&gt;</strong>
</pre>
<p>You should set the ARN of the SNS topic as SQS queue.</p>
<div class="packt_infobox">SQS is currently not supported due to a bug in the Serverless Framework v.1.18, but this error is already a known issue and should be fixed soon.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monitoring performance</h1>
                </header>
            
            <article>
                
<p>As we already discussed, you can find how long it takes for a function to execute through the duration metric in the CloudWatch option or by running the <kbd>serverless logs</kbd> command of the framework. Ideally, there is no difference if the code is executed during work hours, at midnight, or on weekends. AWS strives to always provide a constant experience at any time of the day.</p>
<p>In practice, this is not always true. There is no known pattern for this behavior, but you can expect large differences in the execution time. Without considering cold start delays, your function can take 50 milliseconds to execute, and 1 minute later, it can take 400 milliseconds to execute the same code with the same input. It is much more difficult to provide a constant experience in serverless sites than when using a traditional infrastructure. This is because your infrastructure is always shared between other customers.</p>
<p>Though you can see discrepancies, it is a good practice to monitor the duration. Instead of setting an alarm considering the <em>maximum</em> duration, you can set the <em>average</em> or <em>percentile</em>, where a percentile is a statistic unit, which means the percentage of observations that fall in a category. For example, a p90 of 100 milliseconds means that you expect that 90% of the requests will take less than 100 milliseconds to execute and you should receive an alarm message if this is not true for a given period of time.</p>
<p>Setting alarms is especially important when our Lambda function relies on external services. If the function reads data from a database table, it may take 200 milliseconds if the table has 10 records and 1 minute if it has 1,000,000 records. In this case, an alarm may be useful to alert you that it's time to clean some old data or improve the query.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Monitoring efficiency</h1>
                </header>
            
            <article>
                
<p>Monitoring the efficiency means that you want to certify that you are using your resources in the best way possible. When you create a new Lambda function, there are two important options to configure such as the timeout value and the RAM memory to allocate.</p>
<p>Having a long timeout value will not impact the efficiency, but setting the wrong RAM memory will really affect the function performance and costs.</p>
<p>For example, consider the logs of the function executed in the following screenshot:</p>
<div class="CDPAlignCenter CDPAlign"><img class="image-border" height="286" src="assets/86c851be-c6af-4a61-9fac-b45127998a62.png" width="435"/></div>
<p>It has an allocated memory size of 1,024 MB (default) while <kbd>Max Memory Used</kbd> was only <kbd>19 MB</kbd>. In this case, it clearly shows that you can reduce the allocated memory to minimize costs.</p>
<p>I recommend that you always test your code with different memory sizes and track the duration time. Running with less memory than needed results in much higher times to process. If your Lambda function is used to answer user requests, you may think of paying for a little more memory to process the requests faster while, if it is a background task, you may use the minimum necessary to save money.</p>
<p>Also, when benchmarking your own code to see how fast it is for different memory sizes, pay attention to which scenario it is running. If your project architecture is a Monolith, it may be very fast to retrieve some user data using just a few megabytes of memory, but it may have trouble processing the sales report of a given period.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, you learned how you can test serverless code in the frontend and backend. Also, we have discussed some key concepts that you must consider in your deployment workflow, and showed how you can monitor serverless applications using Amazon CloudWatch.</p>
<p>Now the book has finished. I hope that you have enjoyed reading through the chapters and have learned enough to build your next awesome application using serverless. You can use the serverless store demo as a reference for your future projects, but don't feel limited to it. Use your own preferred tools to test, to develop the frontend, and to access the database. My objective with this book is not to define a strict pattern of how you should build a serverless application, but to give you an example to prove that the concept is valid and may be a good one for many applications.</p>
<p>Finally, I encourage you to try other cloud providers. This book focuses on AWS due to my own positive experiences, but there are other excellent services out there. When evaluating a provider, don't just pay attention to the price tag. Look at the tools that are offered that will make it easier for you to build your application. Mixing services from different providers is also viable. Good luck!</p>


            </article>

            
        </section>
    </body></html>