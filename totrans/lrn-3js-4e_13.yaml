- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working with Blender and Three.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll dive a bit deeper into how you can use Blender and Three.js
    together. We’ll explain the following concepts in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Exporting from Three.js and importing into Blender*: We’ll create a simple
    scene, export it from Three.js, and load and render it in Blender.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Exporting a static scene from Blender and importing it into Three.js*: Here,
    we will create a scene in Blender, export it into Three.js, and render it in Three.js.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Exporting an animation from Blender and importing it into Three.js*: Blender
    allows us to create animations, we’ll create a simple animation, and load and
    show it in Three.js.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Baking lightmaps and ambient occlusion maps in Blender*: Blender allows us
    to bake different types of maps that we can use in Three.js.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Custom UV modeling in Blender*: With UV modeling, we determine how a texture
    is applied to a geometry. Blender provides a lot of tools to make that easy. We’ll
    explore how you can use the UV modeling capabilities of Blender and use the results
    in Three.js.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Before we get started with this chapter, make sure to install Blender so that
    you can follow along. You can install Blender by downloading the installer for
    your OS from here: [https://www.blender.org/download/](https://www.blender.org/download/).
    The screenshots shown of Blender in this chapter were taken using the macOS version
    of Blender, but the versions for Windows and Linux look the same.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started with our first topic, where we create a scene in Three.js,
    export it to an intermediate format, and finally import it into Blender.
  prefs: []
  type: TYPE_NORMAL
- en: Exporting from Three.js and importing into Blender
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this example, we’ll just take a simple sample reusing the parametric geometry
    we saw in [*Chapter 6*](B18726_06.xhtml#_idTextAnchor101), *Exploring Advanced
    Geometries*. If you open `export-to-blender.html` in the browser, you can create
    some parametric geometries. At the bottom of the menu on the right, we’ve added
    an **exportScene** button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.1 – A simple scene that we’ll export](img/Figure_13.1_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.1 – A simple scene that we’ll export
  prefs: []
  type: TYPE_NORMAL
- en: 'When you click on that button, the model will be saved in the GLTF format and
    downloaded onto your computer. To export a model with Three.js, we can use `GLTFexporter`
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Here, you can see that we have created a `GLTFExporter` that we can use to export
    a `THREE.Scene`. We can export a scene in the glTF binary format or the JSON format.
    For this example, we export in JSON. The glTF format is a complex format, and
    while `GLTFExporter` supports many of the objects that make up a Three.js scene,
    you can still run into issues where the export fails. Updating to the latest version
    of Three.js is often the best solution since work is being constantly done on
    this component.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we’ve got our `output`, we can trigger the browser’s `download` functionality,
    which will save it to your local machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is a glTF file, and its first couple of lines look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now that we’ve got a glTF file containing our scene, we can import this into
    Blender. So, open up Blender and you’ll be presented with the default scene with
    a single cube. Remove the cube by selecting it and pressing **x**. Once removed,
    we have an empty scene in which we’ll load our exported scene.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the **File** menu at the top, select **Import | glTF 2.0**, and you’ll
    be presented with a file browser. Navigate to where you’ve downloaded the model,
    select the file, and click on **Import glTF 2.0**. This will open the file, and
    show you something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.2 – Three.js scene imported in Blender](img/Figure_13.2_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.2 – Three.js scene imported in Blender
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, Blender has imported our complete scene, and the `THREE.Mesh`
    we defined in Three.js is now available in Blender. In Blender, we can now use
    this just like any other mesh. For this example, however, let’s keep it simple
    and just render this scene with the **Cycles** Blender renderer. To do this, click
    on **Render Properties** in the menu on the right (the icon that looks like a
    camera) and for **Render Engine**, select **Cycles**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.3 – Rendering with the Cycles render engine in Blender](img/Figure_13.03_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.3 – Rendering with the Cycles render engine in Blender
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to position the camera correctly, so use the mouse to move around
    the scene until you’ve got a view you’re happy with, and then press *Ctrl* + *Alt*
    + *numpad 0* to align the camera. At this point, you’ll have something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.4 – Showing the area the camera sees and what will be rendered](img/Figure_13.2_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.4 – Showing the area the camera sees and what will be rendered
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can render the scene by hitting *F12*. This will start the **Cycles**
    render engine, and you’ll see the model being rendered in Blender:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.5 – Final image being rendered in Blender from our exported Three.js
    model](img/Figure_13.5_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.5 – Final image being rendered in Blender from our exported Three.js
    model
  prefs: []
  type: TYPE_NORMAL
- en: As you’ve seen, using the glTF as a format for exchanging models and scenes
    between Three.js and Blender is very straightforward. Just use `GLTFExporter`,
    import the model in Blender, and you can use everything Blender has to offer on
    your model.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, the other way around works just as easily, as we’ll show you in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: Exporting a static scene from Blender and importing it into Three.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Exporting models from Blender is just as easy as importing them. In the older
    version of Three.js, there was a specific Blender plugin you could use to export
    in a Three.js-specific JSON format. In later versions though, glTF in Three.js
    has become the standard for exchanging models with other tools. So, to get this
    working with Blender, all we have to do is this:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a model in Blender.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Export the model to a glTF file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Import the glTF file in Blender and add it to the scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s create a simple model in Blender first. We’ll use the default model Blender
    uses, which can be added in **Object Mode** by selecting **Add** | **Mesh** |
    **Monkey** from the menu. Click on **monkey** to select it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.6 – Creating the model in Blender that you want to export](img/Figure_13.6_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.6 – Creating the model in Blender that you want to export
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the model is selected, in the top menu, select `File->Export->glTF 2.0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.7 – Selecting the glTF export](img/Figure_13.07_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.7 – Selecting the glTF export
  prefs: []
  type: TYPE_NORMAL
- en: For this example, we only export the mesh. Note that when you’re exporting from
    Blender, always check the **Apply Modifiers** checkbox. This will make sure any
    advanced generators or modifiers used in Blender are applied before exporting
    the mesh.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.8 – Exporting the model as a glTF file](img/Figure_13.08_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.8 – Exporting the model as a glTF file
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the file is exported, we can load it in Three.js using `GLTFImporter`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The final result is the exact model from Blender, but visualized in Three.js
    (see the `import-from-blender.html` example):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.9 – The Blender model visualized in Three.js](img/Figure_13.9_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.9 – The Blender model visualized in Three.js
  prefs: []
  type: TYPE_NORMAL
- en: Note that this isn’t just limited to the meshes – with glTF, we can also export
    lights, cameras, and textures in the same manner.
  prefs: []
  type: TYPE_NORMAL
- en: Exporting an animation from Blender and importing it into Three.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Exporting an animation from Blender works in pretty much the same way as exporting
    a static scene. Therefore, for this example, we’ll create a simple animation,
    export it in the glTF format again, and load it into a Three.js scene. For this,
    we’re going to create a simple scene where we render a cube falling and breaking
    into parts. The first thing we need for this is a floor and a cube. Therefore,
    create a plane and a cube that hangs a little bit above this plane:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.10 – An empty Blender project](img/Figure_13.10_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.10 – An empty Blender project
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we just moved the cube up a little bit (press *G* to grab the cube) and
    added a plane (**Add** | **Mesh** | **Plane**), and then we scaled this plane
    to make it bigger. Now, we can add physics to the scene. In [*Chapter 12*](B18726_12.xhtml#_idTextAnchor212),
    *Adding Physics and Sounds to Your Scene*, we introduced the concept of rigid
    bodies. Blender uses this same approach. Select the cube and use **Object** |
    **Rigid Body** | **Add Active**, and select the plane and add its rigid body like
    this: **Object** | **Rigid Body** | **Add Passive**. At this point, when we play
    (by using the *spacebar*) the animation in Blender, you’ll see that the cube falls:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.11 – A halfway animation of a cube falling](img/Figure_13.11_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.11 – A halfway animation of a cube falling
  prefs: []
  type: TYPE_NORMAL
- en: 'To create the breaking block effect, we need to enable the `Cell Fracture`
    plugin, and check the checkbox to enable the plugin:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.12 – Enabling the Cell Fracture plugin](img/Figure_13.12_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.12 – Enabling the Cell Fracture plugin
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we split up the cube into smaller parts, let’s add some vertices to
    the model so that Blender has a good number of vertices, which it can use to split
    up the model. For this, select the cube in **Edit Mode** (by using the *Tab* key)
    and from the menu at the top, select **Edge** | **Subdivide**. Do this twice,
    and you’ll have something looking like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.13 – Showing the cube with a number of sub-divisions](img/Figure_13.13_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.13 – Showing the cube with a number of sub-divisions
  prefs: []
  type: TYPE_NORMAL
- en: 'Hit *Tab* to go back to **Object Mode** and with the cube selected, open the
    **Cell Fracture** window, and go to **Object** | **Quick Effects** | **Cell Fracture**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.14 – Configuring fractures](img/Figure_13.14_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.14 – Configuring fractures
  prefs: []
  type: TYPE_NORMAL
- en: 'You can play around with these settings to get different kinds of fractures.
    With the settings configured in *Figure 13**.3*, you’ll get something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.15 – Cube showing fractures](img/Figure_13.15_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.15 – Cube showing fractures
  prefs: []
  type: TYPE_NORMAL
- en: Next, select the original cube and hit **x** to delete it. This will only leave
    the fractured parts, which we’ll animate. To do this, select all the cells from
    the cube and use **Object** | **Rigid Body** | **Add Active** again. Once done,
    hit the *spacebar* and you’ll see the cube falling and breaking down on impact.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.16 – The cube after being dropped](img/Figure_13.16_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.16 – The cube after being dropped
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we’ve pretty much got our animation ready. Now, we need to export
    this animation so that we can load it into Three.js and replay it from there.
    Before we do this, make sure to set the end of the animation (the lower-right
    corner of the screen) at frame 80, since it isn’t that useful to export the full
    250 frames. Besides this, we need to tell Blender to convert the information from
    the physics engine into a set of keyframes. This needs to be done since we can’t
    export the physics engine itself, so we have to bake the position and rotation
    of all the meshes so that we can export them. To do this, select all the cells
    again, and use **Object** | **Rigid Body** | **Bake to Keyframes**. You can select
    the defaults and click on the **Export glTF2.0** button to get the following screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.17 – Animation export settings](img/Figure_13.17_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.17 – Animation export settings
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we’ll have an animation for each of the cells, which keeps track
    of the rotation and position of the individual meshes. With this information,
    we can load the scene in Three.js and set up the animation mixer for playback:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In the render loop, we need to update the mixer for each animation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The result looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.18 – An exploded cube in Three.js](img/Figure_13.18_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.18 – An exploded cube in Three.js
  prefs: []
  type: TYPE_NORMAL
- en: The same principle we’ve shown you here can be applied to different kinds of
    animations supported by Blender. The main thing to keep in mind is that Three.js
    won’t understand physics engines used by Blender, or other advanced animation
    models. Therefore, when you export an animation, make sure you bake the animation
    so that you can use the standard Three.js tools to play back these keyframe-based
    animations.
  prefs: []
  type: TYPE_NORMAL
- en: For the next section, we’re going to look a bit closer at how you can use Blender
    to bake different kinds of textures (maps) that you can then load into Three.js.
    We’ve already seen the results in action in [*Chapter 10*](B18726_10.xhtml#_idTextAnchor171),
    *Loading and Working with Textures*, but in this section, we’ll show you how to
    use Blender to bake these maps.
  prefs: []
  type: TYPE_NORMAL
- en: Baking lightmaps and ambient occlusion maps in Blender
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this scenario, we’re going to revisit the example from [*Chapter 10*](B18726_10.xhtml#_idTextAnchor171),
    where we used a lightmap from Blender. This lightmap provides good-looking lighting
    without having to calculate it in real time in Three.js. To do this with Blender,
    we’re going to take the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Set up a simple scene in Blender with a couple of models.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set up the lighting and the models in Blender.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bake the lighting to textures in Blender.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Export the scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Render everything in Three.js.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the following sections, we will discuss each step in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a scene in Blender
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For this example, we’ll create a simple scene in which we’ll bake in some lighting.
    Start a new project, delete the default cube by selecting it and hitting `e` and
    then `z` to extrude along the *z*-axis to get a simple shape like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.19 – Creating a simple room structure](img/Figure_13.19_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.19 – Creating a simple room structure
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you’ve got this model, go back to **Object Mode** (using *Tab*), and place
    a couple of meshes in the room to get something looking similar to what is shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.20 – A full room with some meshes](img/Figure_13.20_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.20 – A full room with some meshes
  prefs: []
  type: TYPE_NORMAL
- en: 'Nothing special at this point – just a simple room without any lighting. Before
    we move on to adding some lighting, change the colors of the objects a bit. Therefore,
    in Blender, go to **Material Properties**, create a new material for each mesh,
    and set a color. The result will look something similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.21 – Adding colors to the different objects in the scene](img/Figure_13.21_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.21 – Adding colors to the different objects in the scene
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll add some nice lighting.
  prefs: []
  type: TYPE_NORMAL
- en: Adding lighting to the scene
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the lighting in this scene, we’ll add nice HDRI-based lighting. With HDRI
    lighting, we don’t have a single source of light but provide an image that’ll
    be used as the source of light for the scene. For this example, we’ve downloaded
    an HDRI image from here: [https://polyhaven.com/a/thatch_chapel](https://polyhaven.com/a/thatch_chapel).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.22 – Downloading an HDRI from Poly Haven](img/Figure_13.22_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.22 – Downloading an HDRI from Poly Haven
  prefs: []
  type: TYPE_NORMAL
- en: 'After downloading, we have a large image file that we can use in Blender. For
    this, open up the **World** tab from the **Properties Editor** panel, select the
    **Surface** dropdown, and select **Background**. Below this, you’ll find the **Color**
    option, click this, and select **Environment Texture**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.23 – Adding an environment texture to the world](img/Figure_13.23_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.23 – Adding an environment texture to the world
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, click on **Open**, browse to where you downloaded the image, and select
    that location. At this point, we can just render the scene and see what the HDRI
    map provides as lighting:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.24 – Rendering the scene to check out the HDRI lighting](img/Figure_13.24_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.24 – Rendering the scene to check out the HDRI lighting
  prefs: []
  type: TYPE_NORMAL
- en: As you can see here, the scene already looks quite nice without us having to
    position separate lights. We now have some nice soft shadows on the walls, the
    objects seem to be lit from multiple angles, and the objects look nice. To use
    the information from the lights as a static lightmap, we need to bake the lighting
    onto a texture and map that texture to the objects in Three.js.
  prefs: []
  type: TYPE_NORMAL
- en: Baking the light textures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To bake the lights, first, we have to create a texture to hold this information.
    Select the cube (or any of the other objects you want to bake the lighting for).
    Go to the **Shading** view, and in **Node Editor** at the bottom of the screen,
    add a new **Image Texture** item: **Add** | **Texture** | **Image Texture**. The
    default values should be good to use:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.25 – Adding a texture image to hold the baked lightmap](img/Figure_13.25_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.25 – Adding a texture image to hold the baked lightmap
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, click on the **New** button of the node you just added, and select the
    size and name of the texture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.26 – Adding a new image to be used with the texture image](img/Figure_13.26_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.26 – Adding a new image to be used with the texture image
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, go to the **Render** tab of the **Properties Editor** panel and set the
    following properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Render** **Engine**: **Cycles**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`512` or rendering the lightmap will take a very long time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the **Bake** menu, select **Diffuse** from the **Bake Type** menu, and in
    the **Influence** section, select **Direct** and **Indirect**. This will just
    render the influence of our environment lighting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, you can click **Bake** and Blender will render the lightmap for the selected
    object to the texture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.27 – Rendered lightmap for the cube](img/Figure_13.27_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.27 – Rendered lightmap for the cube
  prefs: []
  type: TYPE_NORMAL
- en: 'And that’s it. As you can see in the image viewer on the bottom left, we’ve
    now got a nice-looking rendered lightmap for our cube. You can export this image
    as a standalone texture by clicking on the hamburger menu in the image viewer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.28 – Exporting the lightmap to an external file](img/Figure_13.28_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.28 – Exporting the lightmap to an external file
  prefs: []
  type: TYPE_NORMAL
- en: 'You can now repeat this for the other meshes. Before doing this for the box
    though, we quickly need to fix the UV mapping. We need to do this since we extruded
    a couple of vertices to make the room-like structure, and Blender needs to know
    how to map them correctly. Without going into too much detail here, we can have
    Blender make a proposal on how to create the UV mapping. Click on the **UV Editing**
    menu at the top, select **Plane**, go to **Edit Mode**, and from the **UV** menu,
    select **UV** | **Unwrap** | **Smart Unwrap**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.29 – Fixing the UVs for the room mesh](img/Figure_13.29_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.29 – Fixing the UVs for the room mesh
  prefs: []
  type: TYPE_NORMAL
- en: 'This will make sure that a lightmap will be generated for all sides of the
    room. Now, repeat this for all the meshes, and you will have the lightmaps for
    this specific scene. Once you’ve exported all the lightmaps, we can export the
    scene itself and after that, render it using these created lightmaps in Three.js:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.30 – All the created lightmaps](img/Figure_13.30_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.30 – All the created lightmaps
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve baked all our maps, the next step is exporting everything from
    Blender and importing the scene and maps in Three.js.
  prefs: []
  type: TYPE_NORMAL
- en: Exporting the scene and importing it into Blender
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ve already seen in the *Exporting a static scene from Blender and importing
    it into Three.js* section how to export a scene from Blender to be used in Three.js,
    so we’ll repeat these same steps. Click on **File** | **Export** | **glTF 2.0**.
    We can use the defaults and since we don’t have an animation, we can disable the
    animation checkbox. After exporting it, we can import the scene into Three.js.
    If we don’t apply the texture (and use our own default lights), the scene will
    look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.31 – The Three.js scene rendered with default lights without the
    lightmaps](img/Figure_13.31_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.31 – The Three.js scene rendered with default lights without the lightmaps
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ve already seen how to load and apply a lightmap in [*Chapter 10*](B18726_10.xhtml#_idTextAnchor171).
    The following code fragment shows how to load the lightmap textures for all the
    lightmaps we’ve exported from Blender:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, when we look at the same scene (`import-from-blender-lightmap.html`),
    we have a scene with very nice lighting, even though we didn’t provide any light
    sources ourselves and used the baked lights from Blender instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.32 – The same scene but with the baked lightmaps applied from Blender](img/Figure_13.31_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.32 – The same scene but with the baked lightmaps applied from Blender
  prefs: []
  type: TYPE_NORMAL
- en: If we export the lightmaps, we already implicitly get information about the
    shadows as well since, at those locations, there is, of course, less light. We
    can also get more detailed shadow maps from Blender. For instance, we can generate
    ambient occlusion maps so we don’t have to create those at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Baking an ambient occlusion map in Blender
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If we go back to the scene we already have, we can also bake an ambient occlusion
    map. The approach for this is the same as that used for baking a lightmap:'
  prefs: []
  type: TYPE_NORMAL
- en: Set up a scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add all the lights and objects that cast shadows.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Make sure you’ve got an empty **Image Texture** in **Shader Editor**, to which
    we can bake the shadows.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the relevant baking options and render the shadows to the image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Since the first three steps are the same as those for lightmaps, we’ll skip
    those and look at the render settings needed to render the shadow maps:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.33 – Render settings to bake an ambient occlusion map](img/Figure_13.33_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.33 – Render settings to bake an ambient occlusion map
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, you only have to change the dropdown for **Bake Type** to **Ambient
    Occlusion**. Now, you can select the mesh for which you want to bake these shadows
    and click on the **Bake** button. For the room mesh, the result looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.34 – An ambient occlusion map as a texture](img/Figure_13.34_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.34 – An ambient occlusion map as a texture
  prefs: []
  type: TYPE_NORMAL
- en: Blender provides a number of other bake types that you can use to get good-looking
    textures (especially for the static parts of your scene), which can greatly improve
    the rendering performance.
  prefs: []
  type: TYPE_NORMAL
- en: There is one more subject we’re going to look at for this section on Blender,
    and that is how to use Blender to change the UV mapping of a texture.
  prefs: []
  type: TYPE_NORMAL
- en: Custom UV modeling in Blender
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we’re going to start with a new empty Blender scene, and we’ll
    use the default cube to experiment with. To get a good overview of how UV mapping
    works, you can use something called a UV grid, which looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.35 – A sample UV texture](img/Figure_13.35_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.35 – A sample UV texture
  prefs: []
  type: TYPE_NORMAL
- en: 'When you apply this as the texture of the default cube, you’ll see how the
    various vertices of a mesh map to a specific location on the texture. To use this,
    the first thing we need to do is define this texture. You can easily do this from
    **Material Properties** in the **Properties** view on the right of the screen.
    Click on the yellow dot before the **Base Color** property and select **Image
    Texture**. This allows you to browse for an image to use as texture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.36 – Adding a texture to a mesh in Blender](img/Figure_13.36_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.36 – Adding a texture to a mesh in Blender
  prefs: []
  type: TYPE_NORMAL
- en: 'You can already see in the main viewport how this texture is applied to the
    cube. If we export this mesh including the material into Three.js and render it,
    we will see exactly the same mapping because Three.js will use the UV mapping
    defined by Blender (`import-from-blender-uv-map-1.html`):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.37 – A box with a UV grid rendered in Three.js](img/Figure_13.37_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.37 – A box with a UV grid rendered in Three.js
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s switch back to Blender, and open up the **UV Editing** tab. Go to
    **Edit Mode** (using the *Tab* key) on the right-hand side of the screen and select
    the four front-facing vertices. When you’ve selected these, you’ll see the position
    of these four vertices on the left-hand side of the screen as well.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.38 – The UV editor showing the mapping of the four pixels that
    make up the front face of the cube](img/Figure_13.38_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.38 – The UV editor showing the mapping of the four pixels that make
    up the front face of the cube
  prefs: []
  type: TYPE_NORMAL
- en: 'In the UV editor, you can now grab (*g*) the vertices and move them to a different
    position on the texture. For instance, you can move them to the edges of the texture
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.39 – One side mapped to the complete texture](img/Figure_13.39_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.39 – One side mapped to the complete texture
  prefs: []
  type: TYPE_NORMAL
- en: 'Moving the vertices will result in a cube that looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.40 – The Blender render of the cube with custom UV mapping](img/Figure_13.40_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.40 – The Blender render of the cube with custom UV mapping
  prefs: []
  type: TYPE_NORMAL
- en: 'And, of course, this is also directly shown in Three.js as well when we export
    and import this minimal model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.41 – The Three.js view of the cube with custom UV mapping](img/Figure_13.41_B18726.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13.41 – The Three.js view of the cube with custom UV mapping
  prefs: []
  type: TYPE_NORMAL
- en: Using this approach, it is very easy to define exactly which parts of your mesh
    should be mapped to which part of a texture.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored how you can work together with Blender and Three.js.
    We showed how you can use the glTF format as the standard format to exchange data
    between Three.js and Blender. This works great for meshes, animations, and most
    textures. However, for advanced texture properties, you will probably need some
    fine-tuning in either Three.js or Blender. We also showed how you can bake specific
    textures such as lightmaps and ambient occlusion maps in Blender and use them
    in Three.js. This allows you to render this information once in Blender, import
    it into Three.js, and create great shadows, lights, and ambient occlusion without
    the heavy calculations that Three.js would have to do normally. Note that this,
    of course, will only work for scenes where the lighting is static, and the geometries
    and meshes don’t move around or change shape. Often, you can use this for the
    static parts of your scene. Finally, we looked a bit at how UV mapping works,
    where vertices are mapped to a position on a texture, and how you can use Blender
    to play around with this mapping. Once again, by using glTF as the exchange format,
    all the information from Blender can be easily used in Three.js.
  prefs: []
  type: TYPE_NORMAL
- en: We’re now reaching the end of this book. In the last chapter, we’re going to
    look at two additional subjects – how can you use Three.js together with React.js,
    and we’ll have a quick look at Three.js’s support for VR and AR.
  prefs: []
  type: TYPE_NORMAL
