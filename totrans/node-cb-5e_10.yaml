- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Optimizing Performance
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化性能
- en: Performance optimization is an endless activity. Further optimizations can always
    be made. The recipes in this chapter will demonstrate typical performance optimization
    workflows.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 性能优化是一项永无止境的活动。总可以进一步优化。本章中的食谱将展示典型的性能优化工作流程。
- en: The performance optimization workflow starts with establishing a baseline. Often,
    this involves benchmarking our application in some way. In the case of a web server,
    this could be measuring how many requests our server can handle per second. A
    baseline measure must be recorded for us to have evidence of any performance improvements
    that have been made.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 性能优化工作流程从建立基线开始。通常，这涉及到以某种方式对应用程序进行基准测试。在Web服务器的情况下，这可能意味着测量我们的服务器每秒可以处理多少个请求。必须记录基线度量，以便我们有证据证明任何性能改进。
- en: Once the baseline has been determined, the next step is to identify the bottleneck.
    The recipes in this chapter will cover using tools such as flame graphs and memory
    profilers to help us identify the specific bottlenecks in an application. Using
    these performance tools will ensure that our optimization efforts are invested
    in the correct place.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 确定基线后，下一步是识别瓶颈。本章中的食谱将涵盖使用火焰图和内存分析器等工具来帮助我们识别应用程序中的特定瓶颈。使用这些性能工具将确保我们的优化努力投资在正确的位置。
- en: Identifying a bottleneck is the first step to understanding where the optimization
    work should begin, and performance tools can help us determine the starting point.
    For instance, a flame graph can identify a specific function responsible for causing
    the bottleneck. After making the necessary optimizations, the changes must be
    verified by rerunning the initial baseline test. This allows us to have numerical
    evidence supporting whether the optimization has improved the application’s performance.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 识别瓶颈是理解优化工作应该从哪里开始的第一步，性能工具可以帮助我们确定起点。例如，火焰图可以识别导致瓶颈的具体函数。在进行了必要的优化之后，必须通过重新运行初始基线测试来验证这些更改。这使我们能够有数值证据来支持优化是否提高了应用程序的性能。
- en: 'This chapter will cover the following recipes:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下食谱：
- en: Benchmarking HTTP requests
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基准测试HTTP请求
- en: Interpreting flame graphs
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解读火焰图
- en: Detecting memory leaks
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测内存泄漏
- en: Optimizing synchronous functions
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化同步函数
- en: Optimizing asynchronous functions
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化异步函数
- en: Working with worker threads
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与工作线程协同工作
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You should have the latest version of Node.js 22 installed, as well as access
    to a terminal. You will also need access to an editor and browser of your choice.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该安装最新版本的Node.js 22，以及访问终端的权限。您还需要访问您选择的编辑器和浏览器。
- en: The *Optimizing synchronous functions* recipe will require the use of MongoDB.
    We’ll be using Docker to provision a containerized MongoDB instance. Please refer
    to [*Chapter 7*](B19212_07.xhtml#_idTextAnchor212) , for detailed technical setup
    information regarding how to use MongoDB via Docker.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: “优化同步函数”食谱将需要使用MongoDB。我们将使用Docker来提供容器化的MongoDB实例。请参阅[*第7章*](B19212_07.xhtml#_idTextAnchor212)，获取有关如何通过Docker使用MongoDB的详细技术设置信息。
- en: The code samples that will be used in this chapter can be found in this book’s
    GitHub repository at [https://github.com/PacktPublishing/Node.js-Cookbook-Fifth-Edition](https://github.com/PacktPublishing/Node.js-Cookbook-Fifth-Edition)
    , in the **Chapter10** directory.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将使用的代码示例可以在本书的GitHub仓库中找到，网址为[https://github.com/PacktPublishing/Node.js-Cookbook-Fifth-Edition](https://github.com/PacktPublishing/Node.js-Cookbook-Fifth-Edition)，在**第10章**目录下。
- en: Benchmarking HTTP requests
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基准测试HTTP请求
- en: As we’ve seen throughout this book, HTTP communications are the foundation of
    many Node.js applications and microservices. For these applications, the HTTP
    requests should be handled as efficiently as possible. To be able to optimize,
    we must first record a baseline measure of our application’s performance. Once
    we’ve recorded the baseline, we’ll be able to determine the impact of our optimization
    efforts.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本书中看到的，HTTP通信是许多Node.js应用程序和微服务的基础。对于这些应用程序，HTTP请求应该尽可能高效地处理。为了能够优化，我们首先必须记录我们应用程序性能的基线度量。一旦我们记录了基线，我们就能确定我们的优化努力的影响。
- en: To create a baseline, it’s necessary to simulate the load on the application
    and record how it responds. For an HTTP-based application, we must simulate HTTP
    requests being sent to the server.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建基准，有必要模拟应用程序的负载并记录其响应情况。对于基于 HTTP 的应用程序，我们必须模拟向服务器发送的 HTTP 请求。
- en: In this recipe, we’ll capture a baseline performance measure for an HTTP web
    server using a tool named **autocannon** ( [https://github.com/mcollina/autocannon](https://github.com/mcollina/autocannon)
    ), which will simulate HTTP requests.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用名为 **autocannon**（[https://github.com/mcollina/autocannon](https://github.com/mcollina/autocannon)）的工具来捕捉一个
    HTTP 网络服务器的基准性能指标，该工具将模拟 HTTP 请求。
- en: Getting ready
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备中
- en: 'In this recipe, we’ll be using the **autocannon** tool to benchmark an Express.js
    web server. Instead of creating a web server from scratch, we’ll use the Express.js
    generator to create one. The web server will return an HTML page at **http://localhost:3000**
    :'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用 **autocannon** 工具来基准测试 Express.js Web 服务器。我们不会从头创建 Web 服务器，而是使用
    Express.js 生成器来创建一个。Web 服务器将在 **http://localhost:3000** 返回一个 HTML 页面：
- en: 'Enter the following commands to use the Express.js generator to generate a
    sample web server:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下命令以使用 Express.js 生成器生成一个示例 Web 服务器：
- en: '[PRE0]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The **autocannon** tool is available on the **npm** registry. Globally install
    the **autocannon** module:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**autocannon** 工具可在 **npm** 注册表中找到。全局安装 **autocannon** 模块：'
- en: '[PRE1]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now that we’ve created a web server to test, we’re ready to start this recipe.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了一个用于测试的 Web 服务器，我们可以开始这个菜谱了。
- en: How to do it…
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In this recipe, we’ll learn how to use the **autocannon** tool to benchmark
    HTTP requests:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将学习如何使用 **autocannon** 工具来基准测试 HTTP 请求：
- en: 'Start the Express.js web server with the following command:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令启动 Express.js Web 服务器：
- en: '[PRE2]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Navigate to **http://localhost:3000** in your browser. You should see the following
    output:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的浏览器中导航到 **http://localhost:3000**。您应该看到以下输出：
- en: '![Figure 10.1 – Browser window showing the “Welcome to Express” web page](img/Figure_10.1_B19212.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.1 – 浏览器窗口显示“欢迎使用 Express”网页](img/Figure_10.1_B19212.jpg)'
- en: Figure 10.1 – Browser window showing the “Welcome to Express” web page
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 – 浏览器窗口显示“欢迎使用 Express”网页
- en: 'We’ve confirmed our server has started and is responding to requests at **http://localhost:3000**
    . Now, we can use the **autocannon** tool to benchmark our HTTP requests. Open
    a new terminal window and enter the following command to run a load test with
    **autocannon** :'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经确认服务器已启动，并且正在响应 **http://localhost:3000** 上的请求。现在，我们可以使用 **autocannon**
    工具来基准测试我们的 HTTP 请求。打开一个新的终端窗口并输入以下命令以运行 **autocannon** 的负载测试：
- en: '[PRE3]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'While the **autocannon** load test is running, switch to the terminal window
    where you started the web server. You should see a mass of incoming requests:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当 **autocannon** 负载测试运行时，切换到您启动 Web 服务器所在的终端窗口。您应该看到大量传入的请求：
- en: '![Figure 10.2 – The Express.js server receiving many HTTP GET requests](img/Figure_10.2_B19212.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.2 – Express.js 服务器接收多个 HTTP GET 请求](img/Figure_10.2_B19212.jpg)'
- en: Figure 10.2 – The Express.js server receiving many HTTP GET requests
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 – Express.js 服务器接收多个 HTTP GET 请求
- en: 'Switch back to the terminal window where you’re running the **autocannon**
    load test. Once the load test is complete, you should see an output similar to
    the following, detailing the results:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 切换回运行 **autocannon** 负载测试的终端窗口。一旦负载测试完成，您应该看到类似以下输出的结果，详细说明了结果：
- en: '![Figure 10.3 – autocannon results summary](img/Figure_10.3_B19212.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.3 – autocannon 结果摘要](img/Figure_10.3_B19212.jpg)'
- en: Figure 10.3 – autocannon results summary
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3 – autocannon 结果摘要
- en: Observe the table of results. The first table details the request latency. The
    average was recorded as **12.74** ms. The second table details the request volume.
    Here, it was recorded that our server handled an average of **7,555.2** requests
    per second, with an average throughput of **3.71** MB per second.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 观察结果表。第一个表详细说明了请求延迟。平均值为 **12.74** 毫秒。第二个表详细说明了请求量。在这里，记录了我们的服务器平均每秒处理了 **7,555.2**
    个请求，平均吞吐量为 **3.71** MB/秒。
- en: With that, we’ve learned how to use the **autocannon** tool to benchmark HTTP
    requests.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，我们已经学会了如何使用 **autocannon** 工具来基准测试 HTTP 请求。
- en: How it works…
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: The **autocannon** tool is a cross-platform HTTP benchmarking tool written in
    Node.js and published to the **npm** registry.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**autocannon** 工具是一个用 Node.js 编写的跨平台 HTTP 压测工具，并发布到 **npm** 注册表。'
- en: In this recipe, we used **autocannon** to load test our Express.js web server
    at the **http://localhost:3000** endpoint. We passed **autocannon** the **--connections
    100** flag. This flag instructs **autocannon** to allocate a pool of **100** concurrent
    connections to our server. Had we omitted this flag, **autocannon** would have
    defaulted to allocating **10** concurrent connections. The number of concurrent
    connections should be altered to best represent the anticipated load on your server
    so that you can simulate production workloads.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们使用**autocannon**在**http://localhost:3000**端点对我们的Express.js网络服务器进行负载测试。我们传递了**autocannon**的**--connections
    100**标志。此标志指示**autocannon**为我们的服务器分配一个包含**100**个并发连接的池。如果我们省略了这个标志，**autocannon**将默认分配**10**个并发连接。并发连接的数量应该调整以最好地代表您服务器预期的负载，以便您可以模拟生产工作负载。
- en: Important note
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: This recipe used the full-form command-line flags for **autocannon** for readability.
    However, as with many command-line flags, it’s possible to use an abbreviated
    form. The **--connections** flag can be abbreviated to **-c** and the **--duration**
    flag can be abbreviated to **-d** .
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方使用了**autocannon**的全格式命令行标志以提高可读性。然而，与许多命令行标志一样，也可以使用缩写形式。**--connections**标志可以缩写为**-c**，而**--duration**标志可以缩写为**-d**。
- en: 'Note that **autocannon** defaults to running the load test for **10** seconds,
    immediately sending a new request on each socket after the previous request has
    been completed. It’s possible to extend the length of the load test using the
    **--duration** flag. For example, you could use the following command to extend
    the load test shown in this recipe to **20** seconds:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，**autocannon**默认运行10秒的负载测试，在完成上一个请求后立即在每个套接字上发送新的请求。可以使用**--duration**标志扩展负载测试的长度。例如，您可以使用以下命令将本配方中显示的负载测试扩展到20秒：
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: By default, **autocannon** outputs the data from the load test in two tables.
    The first table details the request latency, while the second table details the
    request volume.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，**autocannon**以两个表格的形式输出负载测试的数据。第一个表格详细说明了请求延迟，而第二个表格详细说明了请求量。
- en: '**Request latency** is the amount of time that’s elapsed between when a request
    is made, and a response is received. The request latency table is broken down
    into various percentiles. The **2.5%** percentile records the fastest **2.5%**
    of requests, whereas the **99%** percentile records the slowest **1%** of requests.
    When benchmarking requests, it can be useful to record and consider both the best
    and worst-case scenarios. The latency table also details the average, standard
    deviation, and maximum recorded latency. Generally, the lower the latency, the
    better.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**请求延迟**是指从请求发出到收到响应所经过的时间。请求延迟表被分解成各种百分位数。**2.5%**百分位数记录了最快的**2.5%**的请求，而**99%**百分位数记录了最慢的**1%**的请求。在基准测试请求时，记录和考虑最好和最坏的情况可能是有用的。延迟表还详细说明了平均延迟、标准偏差和记录的最大延迟。一般来说，延迟越低越好。'
- en: The request volume table details the number of requests per second ( **Req/Sec**
    ) and the throughput, which is recorded as the number of bytes processed per second
    ( **Bytes/Sec** ). Again, the results are broken down into percentiles so that
    the best and worst cases can be interpreted. For these two measures, the higher
    the number, the better, as it indicates more requests were processed by the server
    in the given timeframe.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 请求量表详细说明了每秒的请求数（**Req/Sec**）和吞吐量，吞吐量以每秒处理的字节数（**Bytes/Sec**）记录。同样，结果被分解成百分位数，以便可以解释最好和最坏的情况。对于这两个指标，数值越高越好，因为它表明服务器在给定时间内处理了更多的请求。
- en: Important note
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'For more information about the available **autocannon** command-line flags,
    please refer to the *Usage* documentation on GitHub: [https://github.com/mcollina/autocannon#usage](https://github.com/mcollina/autocannon#usage)
    .'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于可用**autocannon**命令行标志的信息，请参阅GitHub上的*Usage*文档：[https://github.com/mcollina/autocannon#usage](https://github.com/mcollina/autocannon#usage)。
- en: There’s more…
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多内容…
- en: Next, we’ll cover how to use **autocannon** to benchmark HTTP **POST** requests.
    We’ll also consider how we can best replicate a production environment during
    our benchmarks and how this can change our latency and throughput.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍如何使用**autocannon**来基准测试HTTP **POST**请求。我们还将考虑如何在基准测试期间最佳地复制生产环境，以及这如何改变我们的延迟和吞吐量。
- en: Benchmarking HTTP POST requests
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基准测试HTTP POST请求
- en: In this recipe, we benchmarked an HTTP **GET** request. The **autocannon** tool
    provides allows you to send requests using other HTTP methods, such as HTTP **POST**
    .
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们测试了一个HTTP **GET** 请求。**autocannon** 工具允许你使用其他HTTP方法发送请求，例如HTTP **POST**。
- en: 'Let’s see how we can use **autocannon** to send an HTTP **POST** request with
    a JSON payload:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用 **autocannon** 发送带有JSON有效负载的HTTP **POST** 请求：
- en: 'In the same directory ( **benchmarking-http** ), create a file named **post-server.js**
    :'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在同一目录（ **benchmarking-http** ）中创建一个名为 **post-server.js** 的文件：
- en: '[PRE5]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, we need to define an endpoint on an Express.js server that will handle
    an HTTP **POST** request with a JSON payload. Add the following to **post-server.js**
    :'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要在Express.js服务器上定义一个端点，该端点将处理带有JSON有效负载的HTTP **POST** 请求。将以下内容添加到 **post-server.js**
    中：
- en: '[PRE6]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, we need to start **post-server.js** :'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要启动 **post-server.js**：
- en: '[PRE7]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In a separate terminal window, enter the following command to load test the
    HTTP **POST** request. Note that we pass **autocannon** the **--method** , **--headers**
    , and **--** **body** flags:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在另一个单独的终端窗口中，输入以下命令以对HTTP **POST** 请求进行负载测试。请注意，我们向 **autocannon** 传递了 **--method**、**--headers**
    和 **--body** 标志：
- en: '[PRE8]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As in the main recipe, **autocannon** will run the load test and output a results
    summary.
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与主示例一样，**autocannon** 将运行负载测试并输出结果摘要。
- en: This demonstrates how we can use **autocannon** to simulate other HTTP method
    requests, including requests with a payload.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了我们如何使用 **autocannon** 模拟其他HTTP方法请求，包括带有有效负载的请求。
- en: Replicating a production environment
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 复制生产环境
- en: When measuring performance, it’s important to replicate the production environment
    as closely as possible; otherwise, we may produce misleading results. The behavior
    of applications in development and production may differ, which can result in
    performance differences.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在测量性能时，尽可能复制生产环境非常重要；否则，我们可能会产生误导性的结果。开发和生产中的应用程序的行为可能不同，这可能导致性能差异。
- en: We can use an Express.js-generated application to demonstrate how performance
    results may differ, depending on the environment we’re running in.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用Express.js生成的应用程序来演示性能结果可能因运行环境的不同而有所不同。
- en: 'Use **express-generator** to generate an Express.js application in a new directory
    named **benchmarking-views** . For more information on the Express.js generator,
    please refer to the *Creating an Express.js web application* recipe in [*Chapter
    6*](B19212_06.xhtml#_idTextAnchor178) . In this example, we’ll be using the **pug**
    view engine to generate a simple HTML page:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 **express-generator** 在名为 **benchmarking-views** 的新目录中生成一个Express.js应用程序。有关Express.js生成器的更多信息，请参阅[*第6章*](B19212_06.xhtml#_idTextAnchor178)中的*创建Express.js
    Web应用程序*配方。在这个例子中，我们将使用 **pug** 视图引擎生成一个简单的HTML页面：
- en: 'Enter the following command in your terminal to generate the application:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的终端中输入以下命令以生成应用程序：
- en: '[PRE9]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Start the server with the following command:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令启动服务器：
- en: '[PRE10]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In a new terminal window, use **autocannon** to load test **http://localhost:3000**
    :'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个新的终端窗口中，使用 **autocannon** 对 **http://localhost:3000** 进行负载测试：
- en: '[PRE11]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Once the load test has been completed, **autocannon** will output the load
    test results summary:'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦负载测试完成，**autocannon** 将输出负载测试结果摘要：
- en: '![Figure 10.4 – autocannon result summary from the development mode run](img/Figure_10.4_B19212.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图10.4 – autocannon从开发模式运行的结果摘要](img/Figure_10.4_B19212.jpg)'
- en: Figure 10.4 – autocannon result summary from the development mode run
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 – autocannon从开发模式运行的结果摘要
- en: In this load test, the average number of requests per second was around 1,584,
    and the average throughput was around 632 kB per second. This is considerably
    slower than the HTTP **GET** request that we benchmarked in the main recipe.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个负载测试中，每秒的平均请求数约为1,584，平均吞吐量约为每秒632 kB。这比我们在主示例中基准测试的HTTP **GET** 请求慢得多。
- en: The reason why the requests are slower is that when in development mode, the
    pug templating engine will reload the template for every request. This is useful
    in development mode because changes to the template can be reflected without having
    to restart the server. When the mode is set to production, Express.js will no
    longer reload the template for every request. This will result in performance
    differences.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 请求较慢的原因是，在开发模式下，Pug模板引擎将为每个请求重新加载模板。这在开发模式下很有用，因为模板的更改可以在不重启服务器的情况下反映出来。当模式设置为生产时，Express.js将不再为每个请求重新加载模板。这将导致性能差异。
- en: 'Restart the Express.js server in production mode using the following command:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令以生产模式重启Express.js服务器：
- en: '[PRE12]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, in your other terminal window, rerun the same benchmark test using **autocannon**
    :'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在您的另一个终端窗口中，使用 **autocannon** 重新运行相同的基准测试：
- en: '[PRE13]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Compare the output between the two runs:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 比较两次运行的输出：
- en: '![Figure 10.5 – autocannon result summary from the production mode run](img/Figure_10.5_B19212.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.5 – 生产模式运行中的 autocannon 结果摘要](img/Figure_10.5_B19212.jpg)'
- en: Figure 10.5 – autocannon result summary from the production mode run
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.5 – 生产模式运行中的 autocannon 结果摘要
- en: In the second load test, we can see that the average number of requests per
    second has increased to approximately **8744** (up from **1584** ), and the throughput
    has increased to **3.49** MB per second (up from **632** kB). This performance
    increase is due to the template being cached when in production mode.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次负载测试中，我们可以看到每秒的平均请求数增加到约 **8744**（从 **1584** 增加），吞吐量增加到每秒 **3.49** MB（从
    **632** kB 增加）。这种性能提升是由于模板在生产模式下被缓存。
- en: This highlights the need to benchmark our application in an environment that
    best represents the expected production environment.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这强调了在最能代表预期生产环境的测试环境中基准测试我们的应用程序的必要性。
- en: See also
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Interpreting flame graphs* recipe in this chapter
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的 *解释火焰图* 菜谱
- en: The *Detecting memory leaks* recipe in this chapter
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的 *检测内存泄漏* 菜谱
- en: The *Optimizing synchronous functions* recipe in this chapter
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的 *优化同步函数* 菜谱
- en: The *Optimizing asynchronous functions* recipe in this chapter
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的 *优化异步函数* 菜谱
- en: Interpreting flame graphs
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释火焰图
- en: A flame graph is a visual tool that allows us to identify “hot code paths” within
    our application. The term “hot code path” is used to describe execution paths
    in the program that consume a relatively large amount of time, which can indicate
    a bottleneck in an application.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 火焰图是一种可视化工具，它允许我们识别应用程序中的“热点代码路径”。术语“热点代码路径”用来描述程序中消耗相对较多时间的执行路径，这可以表明应用程序中的瓶颈。
- en: Flame graphs provide a visualization of an application’s call stack during execution.
    From this visualization, it’s possible to determine which functions are spending
    the most time on the CPU while the application is running.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 火焰图提供了应用程序在执行期间的调用栈的可视化。从这个可视化中，我们可以确定在应用程序运行时哪些函数在 CPU 上花费了最多时间。
- en: In this recipe, we’re going to use the **0x** flame graph tool ( [https://github.com/davidmarkclements/0x](https://github.com/davidmarkclements/0x)
    ) to generate a flame graph for our Node.js application.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用 **0x** 火焰图工具（[https://github.com/davidmarkclements/0x](https://github.com/davidmarkclements/0x)）为我们的
    Node.js 应用程序生成火焰图。
- en: Getting ready
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We need to create an application that we can profile. **Profiling** is a type
    of program analysis that measures how frequently and for how long functions or
    methods in our program are being used. We’ll use the Express.js generator to create
    a base application. Our application will use the **pug** view engine:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要创建一个可以分析的应用程序。**分析**是一种程序分析类型，它测量我们的程序中函数或方法被使用的频率和持续时间。我们将使用 Express.js
    生成器来创建基础应用程序。我们的应用程序将使用 **pug** 视图引擎：
- en: '[PRE14]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now that we’ve generated an application, we’re ready to start generating a flame
    graph.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经生成了一个应用程序，我们准备开始生成火焰图。
- en: How to do it…
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In this recipe, we’ll be using the **0x** tool to profile our server and generate
    a flame graph. We’ll also need to use the **autocannon** tool, which we covered
    in the *Benchmarking HTTP requests* recipe of this chapter, to generate a load
    on our application:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将使用 **0x** 工具来分析我们的服务器并生成火焰图。我们还需要使用本章中介绍的 *HTTP 请求基准测试* 菜谱中的 **autocannon**
    工具，在应用程序上生成负载：
- en: 'First, we need to ensure that we have both the **autocannon** and **0x** tools
    installed globally:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要确保我们已经全局安装了 **autocannon** 和 **0x** 工具：
- en: '[PRE15]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, instead of starting our server with the **node** binary, we need to start
    it with the **0x** executable. If we open the **package.json** file, we’ll see
    that the **npm start** script is **node ./bin/www** . We need to substitute the
    **node** binary in the terminal command with **0x** :'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们不再使用 **node** 二进制文件启动服务器，而是需要使用 **0x** 可执行文件启动。如果我们打开 **package.json**
    文件，我们会看到 **npm start** 脚本是 **node ./bin/www**。我们需要在终端命令中将 **node** 二进制文件替换为 **0x**：
- en: '[PRE16]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, we need to generate some load on the server. In a new terminal window,
    use the **autocannon** benchmarking tool to generate a load by running the following
    command:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要在服务器上生成一些负载。在新的终端窗口中，使用 **autocannon** 基准测试工具通过运行以下命令来生成负载：
- en: '[PRE17]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Expect to see the following output when the **autocannon** load test has been
    completed:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当**autocannon**负载测试完成后，您将看到以下输出：
- en: '![Figure 10.6 – autocannon result summary](img/Figure_10.6_B19212.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图10.6 – autocannon结果摘要](img/Figure_10.6_B19212.jpg)'
- en: Figure 10.6 – autocannon result summary
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6 – autocannon结果摘要
- en: Note that in this load test, our server was handling **1512** requests per second
    on average.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在这个负载测试中，我们的服务器平均每秒处理**1512**个请求。
- en: Return to the terminal window where the server was started and press *Ctrl*
    + *C* . This will stop the server. At this point, **0x** will convert the captured
    stacks into a flame graph.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回启动服务器的终端窗口并按下*Ctrl* + *C*。这将停止服务器。此时，**0x**将捕获的堆栈转换为火焰图。
- en: 'Expect to see the following output after pressing *Ctrl* + *C* . This output
    details the location where **0x** has generated the flame graph. Observe that
    the **0x** tool has created a directory named **96552.0x** , where **96552** is
    the **process identifier** ( **PID** ) of the server process:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按下*Ctrl* + *C*后，您将看到以下输出。此输出详细说明了**0x**生成火焰图的位置。观察发现，**0x**工具创建了一个名为**96552.0x**的目录，其中**96552**是服务器进程的**进程标识符**（**PID**）：
- en: '![Figure 10.7 – The 0x tool generating a flame graph](img/Figure_10.7_B19212.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图10.7 – 0x工具生成火焰图](img/Figure_10.7_B19212.jpg)'
- en: Figure 10.7 – The 0x tool generating a flame graph
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7 – 0x工具生成火焰图
- en: Open the **flamegraph.html** file that’s been generated in the **flamegraph-app**
    directory with Google Chrome. You can do this by copying the path to the flame
    graph and pasting it into the Google Chrome address bar. Expect to see the generated
    flame graph and some controls.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Google Chrome打开在**flamegraph-app**目录中生成的**flamegraph.html**文件。您可以通过复制火焰图的路径并将其粘贴到Google
    Chrome地址栏中来实现这一点。您将看到生成的火焰图和一些控件。
- en: Observe that the bars in the flame graph are of different shades. A darker (redder)
    shade indicates a hot code path.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 观察到火焰图中的条形具有不同的阴影。较深（较红）的阴影表示热点代码路径。
- en: Important note
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Each generated flame graph may be slightly different, even when running the
    same load test. The flame graph that’s generated on your device is likely to look
    different from the output shown in this recipe. This is due to the non-deterministic
    nature of the profiling process, which may have subtle impacts on the flame graph’s
    output. However, generally, the flame graph’s overall results and bottlenecks
    are identified consistently.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 即使运行相同的负载测试，每个生成的火焰图也可能略有不同。在您的设备上生成的火焰图可能看起来与这个配方中显示的输出不同。这是由于分析过程的非确定性，这可能会对火焰图的输出产生微妙的影响。然而，一般来说，火焰图的整体结果和瓶颈是一致的。
- en: 'Identify one of the darker frames. In the example flame graph, we can see that
    the **readFileSync()** frame method has a darker shade – indicating that that
    function has spent a relatively large amount of time on the CPU:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别一个较暗的帧。在示例火焰图中，我们可以看到**readFileSync()**帧方法有一个较深的阴影——这表明该函数在CPU上花费了相对较多的时间：
- en: "![Figure 10.8 – \uFEFFAn overview of the 0x flame graph highlighting readFileSync()\
    \ as a hot frame](img/Figure_10.8_B19212.jpg)"
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图10.8 – 0x火焰图概览，突出显示readFileSync()作为热点帧](img/Figure_10.8_B19212.jpg)'
- en: Figure 10.8 – An overview of the 0x flame graph highlighting readFileSync()
    as a hot frame
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8 – 0x火焰图概览，突出显示readFileSync()作为热点帧
- en: 'Click on the darker frame. If it’s difficult to identify the frame, you can
    enter **readFileSync** into the **search** bar (top right), after which the frame
    will be highlighted. Upon clicking on the frame, **0x** will expand the parent
    and child stacks of the selected frame:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击较暗的帧。如果难以识别帧，您可以在右上角的**搜索**栏中输入**readFileSync**，之后该帧将被突出显示。点击帧后，**0x**将展开所选帧的父级和子级堆栈：
- en: "![Figure 10.9 – \uFEFFAn overview of the 0x flame graph showing a drilled-down\
    \ view of readFileSync()](img/Figure_10.9_B19212.jpg)"
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图10.9 – 0x火焰图概览，显示readFileSync()的钻入视图](img/Figure_10.9_B19212.jpg)'
- en: Figure 10.9 – An overview of the 0x flame graph showing a drilled-down view
    of readFileSync()
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9 – 0x火焰图概览，显示readFileSync()的钻入视图
- en: From the drilled-down view, we can see the hot code path. From the flame graph,
    we can make an educated guess about which functions it would be worthwhile to
    invest time in optimizing. In this case, we can see references to **handleTemplateCache()**
    . In the previous recipe, *Benchmarking HTTP requests* , we learned how **pug**
    reloads a template for each request when in development mode. This is the cause
    of this bottleneck. Let’s change the application so that it runs in production
    mode and see what the impact is on the load test results and flame graph.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 从钻入视图，我们可以看到热点代码路径。从火焰图中，我们可以对哪些函数值得投入时间进行优化做出明智的猜测。在这种情况下，我们可以看到对 **handleTemplateCache()**
    的引用。在之前的配方中，*HTTP 请求基准测试*，我们学习了当处于开发模式时，**pug** 如何为每个请求重新加载模板。这就是造成瓶颈的原因。让我们改变应用程序，使其以生产模式运行，并看看对负载测试结果和火焰图的影响。
- en: 'Restart the Express.js server in production mode with the following command:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令在生产模式下重新启动 Express.js 服务器：
- en: '[PRE18]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Rerun the load test using the **autocannon** tool:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 **autocannon** 工具重新运行负载测试：
- en: '[PRE19]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'From the results of the load test, we can see that our server is handling more
    requests per second. In this run, our load test reported that our server handled
    an average of around **7688** requests per second, up from around **1512** before
    we changed the Express.js server so that it runs in production mode:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从负载测试的结果中，我们可以看到我们的服务器每秒处理的请求数量增加了。在这个运行中，我们的负载测试报告说，我们的服务器平均每秒处理了大约 **7688**
    个请求，比我们更改 Express.js 服务器以使其在生产模式下运行之前的 **1512** 个请求有所增加：
- en: '![Figure 10.10 – autocannon result summary from the production mode run](img/Figure_10.10_B19212.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.10 – 生产模式运行中的 autocannon 结果摘要](img/Figure_10.10_B19212.jpg)'
- en: Figure 10.10 – autocannon result summary from the production mode run
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.10 – 生产模式运行中的 autocannon 结果摘要
- en: 'As before, once the **autocannon** load test is complete, stop your server
    using *Ctrl* + *C* . A new flame graph will be generated. Open the new flame graph
    in your browser and observe that the new flame graph is a different shape from
    the first. Observe that the second flame graph highlights a different set of darker
    frames. This is because we’ve resolved our first bottleneck. Hot code paths are
    relative. Despite having increased the performance of our application, the flame
    graph will identify the next set of hot code paths:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如前所述，一旦 **autocannon** 负载测试完成，使用 *Ctrl* + *C* 停止您的服务器。将生成一个新的火焰图。在新浏览器中打开新的火焰图，并观察新的火焰图与第一个不同。注意第二个火焰图突出显示了一组不同的较暗的帧。这是因为我们已经解决了第一个瓶颈。热点代码路径是相对的。尽管我们已经提高了应用程序的性能，但火焰图将识别下一组热点代码路径：
- en: "![Figure 10.11 – \uFEFFAn overview of the 0x flame graph from production mode](img/Figure_10.11_B19212.jpg)"
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.11 – 生产模式下的 0x 火焰图概览](img/Figure_10.11_B19212.jpg)'
- en: Figure 10.11 – An overview of the 0x flame graph from production mode
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.11 – 生产模式下的 0x 火焰图概览
- en: With that, we’ve used **0x** to generate a flame graph, which has enabled us
    to identify a bottleneck in our application.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，我们用 **0x** 生成了一张火焰图，这使得我们能够识别出应用程序中的瓶颈。
- en: How it works…
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In this recipe, we used the **0x** tool to profile and generate a flame graph
    for our application. Our application was a small, generated Express.js web server.
    The **autocannon** tool was used to add load to our web server so that we could
    produce a flame graph that’s representative of a production workload.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们使用了 **0x** 工具来分析和生成应用程序的火焰图。我们的应用程序是一个小型、生成的 Express.js 网络服务器。**autocannon**
    工具被用来向我们的网络服务器添加负载，以便我们可以生成一个代表生产工作负载的火焰图。
- en: To use the **0x** tool, we had to start our server with **0x** . When we start
    an application with **0x** , two processes are started.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 **0x** 工具，我们必须用 **0x** 启动我们的服务器。当我们用 **0x** 启动应用程序时，将启动两个进程。
- en: The first process uses the Node.js binary, **node** , to start our program.
    When **0x** starts the node process, it passes the **--perf-basic-prof** command-line
    flag to the process. This command-line flag allows C++ V8 function calls to be
    mapped to the corresponding JavaScript function calls.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个进程使用 Node.js 二进制文件 **node** 来启动我们的程序。当 **0x** 启动 node 进程时，它将 **--perf-basic-prof**
    命令行标志传递给进程。此命令行标志允许 C++ V8 函数调用映射到相应的 JavaScript 函数调用。
- en: The second process starts the local system’s stack tracing tool. On Linux, the
    **perf** tool will be invoked, whereas on macOS and SmartOS, the **dtrace** tool
    will be invoked. These tools capture the underlying C-level function calls.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个进程启动本地系统的堆栈跟踪工具。在 Linux 上，将调用 **perf** 工具，而在 macOS 和 SmartOS 上，将调用 **dtrace**
    工具。这些工具捕获底层的 C 级函数调用。
- en: The underlying system stack tracing tool will take samples. A **sample** is
    a snapshot of all the functions being executed by the CPU at the time the sample
    was taken, which will also record the parent function calls.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 基础系统堆栈跟踪工具将进行采样。**采样**是在采样时 CPU 正在执行的所有函数的快照，它还将记录父函数调用。
- en: The sampled stacks are grouped based on the call hierarchy, grouping the parent
    and child function calls together. These groups are what’s known as a **flame**
    , hence the name **flame graph** . The same function may appear in multiple flames.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 样本堆栈根据调用层次结构分组，将父函数调用和子函数调用分组在一起。这些组就是所谓的 **火焰图**，因此得名 **火焰图**。同一个函数可能出现在多个火焰图中。
- en: Each line in a flame is known as a frame. A **frame** represents a function
    call. The width of the frame corresponds to the amount of time that that function
    was observed by the profiler on the CPU. The time representation of each frame
    aggregates the time that all child functions take as well, hence the triangular
    or *flame* shape of the graph.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 火焰图中每一行都称为一个帧。**帧**代表一个函数调用。帧的宽度对应于该函数被分析器在 CPU 上观察的时间量。每个帧的时间表示汇总了所有子函数所需的时间，因此图形呈现为三角形或
    *火焰* 形状。
- en: Darker (redder) frames indicate that a function has spent more time at the top
    of the stack relative to the other functions. This means that this function is
    spending a lot of time on the CPU, which indicates a potential bottleneck.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 深色（红色）的帧表示相对于其他函数，该函数在堆栈顶部的花费时间更多。这意味着该函数在 CPU 上花费了大量的时间，这表明可能存在瓶颈。
- en: Important note
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Chrome DevTools can also be used to profile the CPU, which can help identify
    bottlenecks. Using the **--inspect** command-line flag, the Node.js process can
    be debugged and profiled using Chrome DevTools. Please refer to the *Debugging
    with Chrome DevTools* recipe in [*Chapter 12*](B19212_12.xhtml#_idTextAnchor388)
    for more information on using Chrome DevTools to debug a Node.js program.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Chrome DevTools 还可以用来分析 CPU，这有助于识别瓶颈。使用 **--inspect** 命令行标志，可以使用 Chrome DevTools
    调试和分析了 Node.js 进程。请参阅 [*第 12 章*](B19212_12.xhtml#_idTextAnchor388) 的 *使用 Chrome
    DevTools 进行调试* 菜谱以获取有关使用 Chrome DevTools 调试 Node.js 程序的更多信息。
- en: See also
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考信息
- en: The *Creating an Express.js web application* recipe in [*Chapter 6*](B19212_06.xhtml#_idTextAnchor178)
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的 *创建 Express.js 网络应用程序* 菜谱
- en: The *Benchmarking HTTP requests* recipe in this chapter
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的 *基准测试 HTTP 请求* 菜谱
- en: The *Detecting memory leaks* recipe in this chapter
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的 *检测内存泄漏* 菜谱
- en: The *Optimizing synchronous functions* recipe in this chapter
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的 *优化同步函数* 菜谱
- en: The *Optimizing asynchronous functions* recipe in this chapter
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的 *优化异步函数* 菜谱
- en: The *Debugging with Chrome DevTools* recipe in [*Chapter 12*](B19212_12.xhtml#_idTextAnchor388)
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 [*第 12 章*](B19212_12.xhtml#_idTextAnchor388) 的 *使用 Chrome DevTools 进行调试* 菜谱
- en: Detecting memory leaks
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测内存泄漏
- en: Memory leaks can drastically reduce your application’s performance and can lead
    to crashes. V8 manages objects and dynamic data in its heap, a binary tree-based
    structure designed to manage parent-child node relationships. The V8 **Garbage
    Collector** ( **GC** ) is responsible for managing the heap. It reclaims any memory
    that is no longer in use – freeing the memory so that it can be reused.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 内存泄漏会大幅降低应用程序的性能，并可能导致崩溃。V8 在其堆中管理对象和动态数据，这是一个基于二叉树的结构，用于管理父子节点关系。V8 的 **垃圾回收器**（**GC**）负责管理堆。它回收任何不再使用的内存
    – 释放内存以便可以重用。
- en: A memory leak occurs when a block of memory is never reclaimed by the GC and
    is therefore idle and inefficient. This results in pieces of unused memory remaining
    on the heap. The performance of your application can be impacted when many of
    these unused memory blocks accumulate in the heap. In the worst cases, the unused
    memory could consume all the available heap space, which, in turn, can cause your
    application to crash.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 当一块内存从未被垃圾回收器（GC）回收时，就会发生内存泄漏，因此它是闲置且低效的。这会导致未使用的内存片段留在堆上。当许多这些未使用的内存块积累在堆中时，可能会影响应用程序的性能。在最坏的情况下，未使用的内存可能会消耗所有可用的堆空间，这反过来又可能导致应用程序崩溃。
- en: In this recipe, we’ll learn how to use Chrome DevTools to profile memory, enabling
    us to detect and fix memory leaks.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将学习如何使用 Chrome DevTools 来分析内存，使我们能够检测和修复内存泄漏。
- en: Getting ready
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'This recipe will require you to have Chrome DevTools installed, which is integrated
    into the Google Chrome browser. Visit [https://www.google.com/chrome/](https://www.google.com/chrome/)
    to download Google Chrome:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方需要你安装 Chrome DevTools，它集成在 Google Chrome 浏览器中。访问 [https://www.google.com/chrome/](https://www.google.com/chrome/)
    下载 Google Chrome：
- en: 'We’ll be using the **autocannon** tool to direct load to our application. Install
    **autocannon** from the **npm** registry with the following command:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用 **autocannon** 工具将负载导向我们的应用程序。使用以下命令从 **npm** 注册表安装 **autocannon**：
- en: '[PRE20]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We also need to create a directory to work in:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还需要创建一个工作目录：
- en: '[PRE21]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Create a file named **leaky-server.js** . This HTTP server will intentionally
    contain a memory leak:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 **leaky-server.js** 的文件。这个 HTTP 服务器将故意包含一个内存泄漏：
- en: '[PRE22]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Add the following to **leaky-server.js** :'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下内容添加到 **leaky-server.js**：
- en: '[PRE23]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Now that we’ve installed the necessary tools and created a sample application
    containing a memory leak, we’re ready to move on to this recipe’s steps.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经安装了必要的工具并创建了一个包含内存泄漏的示例应用程序，我们可以继续进行本配方步骤。
- en: How to do it…
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'In this recipe, we’ll use Chrome DevTools to identify a memory leak:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将使用 Chrome DevTools 来识别内存泄漏：
- en: 'Memory leaks can get progressively worse the longer an application is running.
    Sometimes, it can take several days or weeks of an application running before
    the memory leak causes the application to crash. We can use the Node.js process
    **--max-old-space-size** command-line flag to increase or reduce the maximum V8
    old memory size (in MB). To demonstrate the presence of the memory leak, we’ll
    set this to a very small value. Start **leaky-server.js** with the following command:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 内存泄漏可能会随着应用程序运行时间的增长而逐渐恶化。有时，应用程序运行几天或几周后，内存泄漏才会导致应用程序崩溃。我们可以使用 Node.js 进程的
    **--max-old-space-size** 命令行标志来增加或减少最大 V8 旧内存大小（以 MB 为单位）。为了演示内存泄漏的存在，我们将这个值设置得非常小。使用以下命令启动
    **leaky-server.js**：
- en: '[PRE24]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In a second terminal window, use the **autocannon** tool to direct load to
    the server:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二个终端窗口中，使用 **autocannon** 工具将负载导向服务器：
- en: '[PRE25]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Back in the terminal window where you started the server, observe that the
    server crashed with **JavaScript heap out** **of memory** :'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回到你启动服务器的终端窗口，观察服务器是否因 **JavaScript 堆内存不足** 而崩溃：
- en: '![Figure 10.12 – JavaScript heap out of memory error](img/Figure_10.12_B19212.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.12 – JavaScript 堆内存不足错误](img/Figure_10.12_B19212.jpg)'
- en: Figure 10.12 – JavaScript heap out of memory error
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.12 – JavaScript 堆内存不足错误
- en: 'Now, we’ll start using Chrome DevTools to profile our application. First, we
    must restart the server with the following command:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将开始使用 Chrome DevTools 对我们的应用程序进行性能分析。首先，我们必须使用以下命令重新启动服务器：
- en: '[PRE26]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Navigate to **chrome://inspect** in Google Chrome and click **inspect** (underneath
    **leaky-server.js** ). This should open the Chrome DevTools interface.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Google Chrome 中导航到 **chrome://inspect** 并点击 **inspect**（位于 **leaky-server.js**
    下方）。这应该会打开 Chrome DevTools 界面。
- en: 'Ensure you’re on the **Memory** tab and that **Heap snapshot** is selected.
    Click **Take snapshot** :'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保你处于 **内存** 选项卡，并且已选择 **堆快照**。点击 **快照**：
- en: '![Figure 10.13 – The Chrome DevTools Memory interface](img/Figure_10.13_B19212.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.13 – Chrome DevTools 内存界面](img/Figure_10.13_B19212.jpg)'
- en: Figure 10.13 – The Chrome DevTools Memory interface
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.13 – Chrome DevTools 内存界面
- en: 'You should see **Snapshot 1** appear on the left of the interface:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在界面的左侧看到 **快照 1** 出现：
- en: '![Figure 10.14 – Chrome DevTools memory snapshot interface](img/Figure_10.14_B19212.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.14 – Chrome DevTools 内存快照界面](img/Figure_10.14_B19212.jpg)'
- en: Figure 10.14 – Chrome DevTools memory snapshot interface
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.14 – Chrome DevTools 内存快照界面
- en: 'Return to your second terminal window and rerun the **autocannon** benchmark:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回你的第二个终端窗口并重新运行 **autocannon** 基准测试：
- en: '[PRE27]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Once the load test has been completed, return to your Chrome DevTools window.
    Return to the **Profiles** interface of the **Memory** tab and take another snapshot:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦负载测试完成，返回你的 Chrome DevTools 窗口。返回 **内存** 选项卡的 **配置文件** 界面并再次进行快照：
- en: '![Figure 10.15 – Chrome DevTools memory snapshot interface](img/Figure_10.15_B19212.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.15 – Chrome DevTools 内存快照界面](img/Figure_10.15_B19212.jpg)'
- en: Figure 10.15 – Chrome DevTools memory snapshot interface
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.15 – Chrome DevTools 内存快照界面
- en: Note **MaxListenersExceededWarning** in the **Console** tab – this will be covered
    in more detail in the *There’s* *more…* section.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 **Console** 选项卡中的 **MaxListenersExceededWarning** – 这将在 *There’s* *more…*
    部分进行更详细的介绍。
- en: 'Now that we have two snapshots, we can use Chrome DevTools to compare them.
    To do this, change the drop-down window from **Summary** to **Comparison** :'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了两个快照，我们可以使用 Chrome DevTools 来比较它们。为此，将下拉窗口从 **Summary** 更改为 **Comparison**：
- en: '![Figure 10.16 – Chrome DevTools memory snapshot comparison interface](img/Figure_10.16_B19212.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.16 – Chrome DevTools 内存快照比较界面](img/Figure_10.16_B19212.jpg)'
- en: Figure 10.16 – Chrome DevTools memory snapshot comparison interface
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.16 – Chrome DevTools 内存快照比较界面
- en: 'Observe that the constructors are now sorted by delta – the difference between
    two snapshots. Expand the **(array)** constructor and the **(object elements)
    [ ]** object within it; you should see the following output:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意到构造函数现在是按 delta 排序的——两个快照之间的差异。展开 **(array)** 构造函数和其中包含的 **(object elements)
    [ ]** 对象；你应该看到以下输出：
- en: '![Figure 10.17 – Chrome DevTools memory snapshot comparison interface expanded](img/Figure_10.17_B19212.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.17 – Chrome DevTools 内存快照比较界面展开](img/Figure_10.17_B19212.jpg)'
- en: Figure 10.17 – Chrome DevTools memory snapshot comparison interface expanded
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.17 – Chrome DevTools 内存快照比较界面展开
- en: 'The expanded view indicates that there are masses of **connectionListener()**
    events stemming from *line 4* of **leaky-server.js** . If we take a look at that
    line, we’ll see that it starts on the **server.on(''connection'',...** block.
    This is our memory leak. We’re registering a listener for the connected event
    upon every request, causing our server to eventually run out of memory. We need
    to move this event listener outside of our request handler function. Create a
    new file named **server.js** :'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 展开视图表明，有大量的 **connectionListener()** 事件来自 **leaky-server.js** 的 *第 4 行*。如果我们查看该行，我们会看到它从
    **server.on('connection',...** 块开始。这是我们内存泄漏的地方。我们在每个请求上注册了连接事件的监听器，导致我们的服务器最终耗尽内存。我们需要将这个事件监听器移出我们的请求处理函数。创建一个名为
    **server.js** 的新文件：
- en: '[PRE28]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Add the following to **server.js** :'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下内容添加到 **server.js** 文件中：
- en: '[PRE29]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Close the Chrome DevTools window and then rerun the same experiment. Start
    the server with **$ node --inspect server.js** and take a snapshot. In a second
    terminal window, direct load to the server with **$ autocannon http://localhost:3000**
    and take another snapshot. Now, when we compare the two, we’ll see that the **#
    Delta** value of the **(array)** constructors has significantly reduced:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭 Chrome DevTools 窗口，然后重新运行相同的实验。使用 **$ node --inspect server.js** 启动服务器并获取快照。在第二个终端窗口中，使用
    **$ autocannon http://localhost:3000** 直接加载到服务器并获取另一个快照。现在，当我们比较这两个快照时，我们会看到 **(array)**
    构造函数的 **# Delta** 值显著降低：
- en: '![Figure 10.18 – Chrome DevTools memory snapshot comparison interface](img/Figure_10.18_B19212.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.18 – Chrome DevTools 内存快照比较界面](img/Figure_10.18_B19212.jpg)'
- en: Figure 10.18 – Chrome DevTools memory snapshot comparison interface
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.18 – Chrome DevTools 内存快照比较界面
- en: Observe that the **MaxListenersExceededWarning** warning is no longer appearing,
    indicating that we’ve fixed our memory leak.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到 **MaxListenersExceededWarning** 警告不再出现，这表明我们已经修复了内存泄漏。
- en: With that, we’ve learned how to take heap snapshots of our application, enabling
    us to diagnose a memory leak in our application.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，我们学习了如何获取我们应用程序的堆快照，使我们能够诊断我们应用程序中的内存泄漏。
- en: How it works…
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: The V8 JavaScript engine is used by both Google Chrome and Node.js. The common
    underlying engine means that we can use Chrome DevTools to debug and profile Node.js
    applications. To enable the debugging client, we must pass the **--inspect** command-line
    flag to the **node** process. Passing this flag instructs the V8 inspector to
    open a port that accepts WebSocket connections. The WebSocket connection allows
    the client and V8 inspector to interact.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: V8 JavaScript 引擎被 Google Chrome 和 Node.js 都使用。共同的底层引擎意味着我们可以使用 Chrome DevTools
    来调试和配置 Node.js 应用程序。为了启用调试客户端，我们必须将 **--inspect** 命令行标志传递给 **node** 进程。传递此标志指示
    V8 检查器打开一个接受 WebSocket 连接的端口。WebSocket 连接允许客户端和 V8 检查器进行交互。
- en: The V8 JavaScript engine retains a heap of all the objects and primitives referenced
    in our JavaScript code. The JavaScript heap can be exposed via an internal V8
    API ( **v8_inspector** ). Chrome DevTools uses this internal API to provide tooling
    interfaces, including the **Memory Profiler** interface we used in this recipe.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: V8 JavaScript 引擎保留了所有在 JavaScript 代码中引用的对象和原始数据。JavaScript 堆可以通过内部 V8 API（**v8_inspector**）暴露。Chrome
    DevTools 使用这个内部 API 提供工具界面，包括我们在本食谱中使用的 **内存分析器** 界面。
- en: We used the **Memory** interface of Chrome DevTools to take an initial heap
    snapshot of the server. This snapshot is considered our baseline. Then, we generated
    load on the server using the **autocannon** tool to simulate usage over time.
    For our server, the memory leak could be observed with the default **autocannon**
    load ( **10** connections for **10** seconds). Some memory leaks may only be observable
    under considerable load; in these cases, we’d need to simulate a more extreme
    load on the server, potentially for a longer period.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用Chrome DevTools的**Memory**接口对服务器进行了初始堆快照。这个快照被认为是我们的基线。然后，我们使用**autocannon**工具在服务器上生成负载，以模拟随时间的使用情况。对于我们的服务器，内存泄漏可以通过默认的**autocannon**负载（**10**秒内的**10**个连接）观察到。一些内存泄漏可能只有在相当大的负载下才能观察到；在这些情况下，我们需要在服务器上模拟更极端的负载，可能需要更长时间。
- en: autocannon
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: autocannon
- en: The *Benchmarking HTTP requests* recipe in this chapter goes into more detail
    about how we can simulate more extreme server loads with the **autocannon** tool.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的**Benchmarking HTTP requests**配方更详细地介绍了我们如何使用**autocannon**工具模拟更极端的服务器负载。
- en: Once we directed the load to our server, we took a second heap snapshot. This
    showed how much impact the load had on the heap size. Our second snapshot was
    much larger than the first, which is an indication of a memory leak. The heap
    snapshot **Comparison** view can be utilized to identify which constructors have
    the largest deltas.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们将负载引导到我们的服务器，我们就进行了第二个堆快照。这显示了负载对堆大小的影响。我们的第二个快照比第一个大得多，这是内存泄漏的迹象。堆快照的**比较**视图可以用来识别哪些构造函数具有最大的delta值。
- en: From inspecting and expanding the **(array)** constructor, we found a long list
    of **connection** **Listener()** events stemming from *line 4* of our **leaky-server.js**
    file. This enabled us to identify the memory leak. Note that the **(array)** constructor
    refers to an internal structure used by V8. For a JavaScript array, the constructor
    would be named **Array** .
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查和展开**（数组）**构造函数，我们发现了一个从我们的**leaky-server.js**文件的第4行开始的**connection** **Listener()**事件的长列表。这使得我们能够识别内存泄漏。请注意，**（数组）**构造函数指的是V8使用的内部结构。对于JavaScript数组，构造函数将命名为**Array**。
- en: Once the memory leak has been identified and fixed, it’s prudent to rerun the
    test and confirm that the new heap snapshot shows a reduction in deltas. The snapshot
    is still likely to be larger than the initial baseline snapshot because of the
    load. However, it shouldn’t be as drastically large as it was with our **leaky-server.js**
    file.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦内存泄漏被识别并修复，谨慎的做法是重新运行测试，并确认新的堆快照显示delta值有所减少。由于负载，快照仍然可能比初始基线快照要大，但是它不应该像我们之前的**leaky-server.js**文件那样大幅增加。
- en: There’s more…
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: 'In this recipe, when under load, **leaky-server.js** emitted **MaxListenersExceededWarning**
    before crashing:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，当处于负载下时，**leaky-server.js**在崩溃之前发出了**MaxListenersExceededWarning**：
- en: '[PRE30]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'By default, Node.js allows a maximum of **10** listeners to be registered for
    a single event. In **leaky-server.js** , we were registering a new listener for
    each request. Once our application registered the 11th request, it emitted **MaxListenersExceededWarning**
    . This is an early warning sign of a memory leak. It’s possible to change the
    maximum number of listeners. To change the threshold for an individual **EventEmitter**
    instance, we can use the **emitter.setMaxListeners()** method. For example, to
    lower the maximum number of listeners on our server to **1** , we could change
    **leaky-server.js** to the following:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Node.js 允许为单个事件注册的最大监听器数量为**10**。在**leaky-server.js**中，我们为每个请求注册一个新的监听器。一旦我们的应用程序注册了第11个请求，它就会发出**MaxListenersExceededWarning**。这是一个内存泄漏的早期警告信号。可以更改最大监听器的数量。要更改单个**EventEmitter**实例的阈值，我们可以使用**emitter.setMaxListeners()**方法。例如，要将服务器上的最大监听器数量降低到**1**，我们可以将**leaky-server.js**更改为以下内容：
- en: '[PRE31]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Then, if we were to run the same experiment, we’d see the following error after
    just two event listeners were registered:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，如果我们再次运行相同的实验，注册了两个事件监听器后，我们会看到以下错误：
- en: '[PRE32]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'It’s also possible to use the **EventEmitter.defaultMaxListeners** property
    to change the default maximum listeners for all **EventEmitter** instances. This
    should be done with caution as it will impact all **EventEmitter** instances.
    You could use the following to set the **EventEmitter.defaultMaxListeners** value:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以使用**EventEmitter.defaultMaxListeners**属性来更改所有**EventEmitter**实例的默认最大监听器数量。这应该谨慎进行，因为它将影响所有**EventEmitter**实例。您可以使用以下内容来设置**EventEmitter.defaultMaxListeners**的值：
- en: '[PRE33]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Note that **emitter.setMaxListeners()** will always take precedence over the
    global default set via **EventEmitter.defaultMaxListeners** . Before raising the
    maximum threshold of listeners, it’s worth considering whether you’re inadvertently
    masking a memory leak in your application.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，**emitter.setMaxListeners()** 将始终优先于通过 **EventEmitter.defaultMaxListeners**
    设置的全局默认值。在提高最大监听器阈值之前，考虑你是否无意中掩盖了应用程序中的内存泄漏是值得的。
- en: See also
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Interpreting flame graphs* recipe in this chapter
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的 *解释火焰图* 菜谱
- en: The *Optimizing synchronous functions* recipe in this chapter
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的 *优化同步函数* 菜谱
- en: The *Optimizing asynchronous functions* recipe in this chapter
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的 *优化异步函数* 菜谱
- en: The *Debugging with Chrome DevTools* recipe in [*Chapter 12*](B19212_12.xhtml#_idTextAnchor388)
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第12章*](B19212_12.xhtml#_idTextAnchor388) 中的 *使用 Chrome DevTools 调试* 菜谱'
- en: Optimizing synchronous functions
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化同步函数
- en: The previous recipes of this chapter covered how to detect hot code paths in
    our applications. Once a hot code path is identified, we can focus our optimization
    efforts on it to reduce the bottleneck.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 本章前面的菜谱介绍了如何在应用程序中检测热点代码路径。一旦确定了热点代码路径，我们就可以集中优化工作，以减少瓶颈。
- en: It’s important to optimize any hot code paths as any function that takes a long
    time to process can prevent I/O and other functions from executing, impacting
    the overall performance of your application.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 优化任何热点代码路径是很重要的，因为任何处理时间较长的函数都可能阻止 I/O 和其他函数的执行，影响应用程序的整体性能。
- en: This recipe will cover how to micro-benchmark and optimize a synchronous function.
    A **micro-benchmark** is a type of performance test that focuses on a small, specific
    piece of code or functionality within a larger system. We’ll use Benchmark.js
    ( [https://benchmarkjs.com/](https://benchmarkjs.com/) ) to create a micro-benchmark.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 本菜谱将介绍如何进行微基准测试和优化同步函数。**微基准测试**是一种性能测试类型，它关注于更大系统中的一个小型、特定的代码片段或功能。我们将使用 Benchmark.js
    ([https://benchmarkjs.com/](https://benchmarkjs.com/)) 来创建微基准测试。
- en: Getting ready
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In real applications, we’d use tooling such as flame graphs or profilers to
    identify slow functions in our applications. For this recipe, we’ll create a single
    slow function that we can learn how to micro-benchmark and optimize:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用中，我们会使用工具如火焰图或分析器来识别应用程序中的慢速函数。对于这个菜谱，我们将创建一个单一的慢速函数，这样我们就可以学习如何进行微基准测试和优化：
- en: 'First, create a directory for this recipe’s code and initialize the project:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，为这个菜谱的代码创建一个目录并初始化项目：
- en: '[PRE34]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We also need to install Benchmark.js:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还需要安装 Benchmark.js：
- en: '[PRE35]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Now that we’ve initialized our directory, we can start this recipe.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经初始化了目录，我们可以开始这个菜谱。
- en: How to do it…
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let’s assume that we’ve identified a bottleneck in our code base and it happens
    to be a function called **sumOfSquares()** . Our task is to make this function
    faster:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已经识别出代码库中的瓶颈，并且它恰好是一个名为 **sumOfSquares()** 的函数。我们的任务是使这个函数更快：
- en: 'First, let’s create a file named **slow.js** , which will hold our unoptimized
    function:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们创建一个名为 **slow.js** 的文件，它将包含我们的未优化函数：
- en: '[PRE36]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Add the following to **slow.js** to create the slow **sumOfSquares()** implementation.
    This uses the **Array.from()** method to generate an array of integers. The **map**
    function is used to square each number in the array, while the **reduce** function
    is used to sum the elements of the array:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下内容添加到 **slow.js** 中以创建慢速的 **sumOfSquares()** 实现。这使用了 **Array.from()** 方法来生成一个整数数组。**map**
    函数用于将数组中的每个数字平方，而 **reduce** 函数用于求和数组中的元素：
- en: '[PRE37]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now that we have a slow version of our function, let’s turn it into a module
    so that we can benchmark it with ease. If our function formed part of a larger
    script or application, it would be worthwhile trying to extract it into a standalone
    script or module to enable it to be benchmarked in isolation. Add the following
    line to the bottom of **slow.js** :'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们有了函数的慢速版本，让我们将其转换成一个模块，这样我们就可以轻松地进行基准测试。如果我们的函数是更大脚本或应用程序的一部分，尝试将其提取为独立的脚本或模块以使其能够独立进行基准测试是有意义的。将以下行添加到
    **slow.js** 的底部：
- en: '[PRE38]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now, we can write a micro-benchmark for our **sumOfSquares()** function using
    Benchmark.js. Create a file named **benchmark.js** :'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用 Benchmark.js 为我们的 **sumOfSquares()** 函数编写一个微基准测试。创建一个名为 **benchmark.js**
    的文件：
- en: '[PRE39]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Add the following code to **benchmark.js** to create a benchmark for our **sumOfSquares()**
    function:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下代码添加到 **benchmark.js** 中，为我们的 **sumOfSquares()** 函数创建一个基准测试：
- en: '[PRE40]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: This file contains the configuration of Benchmark.js, a single benchmark that
    calls our **slow.js** module, and a **printResults()** function, which outputs
    the benchmark run information.
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此文件包含Benchmark.js的配置，一个调用我们的**slow.js**模块的单个基准测试，以及一个**printResults()**函数，该函数输出基准测试运行信息。
- en: 'Now, we can run the benchmark with the following command:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用以下命令运行基准测试：
- en: '[PRE41]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Let’s generate a flame graph using the **0x** tool. A flame graph can help
    us identify which of the lines of our code are spending the most time on the CPU.
    Generate a flame graph with **0x** by using the following command:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用**0x**工具生成一个火焰图。火焰图可以帮助我们确定我们的代码中哪一行在CPU上花费了最多时间。使用以下命令通过**0x**生成火焰图：
- en: '[PRE42]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Open the flame graph in your browser. In the following example, there’s one
    pink frame, indicating a hot code path. Hover over the hotter frames to identify
    which line of the application they’re referring to:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的浏览器中打开火焰图。在以下示例中，有一个粉红色的帧，表示一个热代码路径。将鼠标悬停在更热的帧上以识别它们引用的应用程序中的哪一行：
- en: "![Figure 10.19 – \uFEFFAn overview of the 0x flame graph showing a hot frame\
    \ on line 9 of slow.js](img/Figure_10.19_B19212.jpg)"
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![图10.19 – 0x火焰图概述，显示slow.js的第9行上的热帧](img/Figure_10.19_B19212.jpg)'
- en: Figure 10.19 – An overview of the 0x flame graph showing a hot frame on line
    9 of slow.js
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.19 – 0x火焰图概述，显示slow.js的第9行上的热帧
- en: In the flame graph, we can see that the hottest function is an anonymous function
    on *line 9* of **slow.js** . If we look at our code, we’ll see that this points
    to our use of **Array.reduce()** . Note that the line number may be different
    should you have formatted this recipe’s code differently.
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在火焰图中，我们可以看到最热的函数是位于**slow.js**的**第9行**上的一个匿名函数。如果我们查看我们的代码，我们会看到这指向了我们对**Array.reduce()**的使用。请注意，如果你以不同的方式格式化此菜谱的代码，行号可能会有所不同。
- en: 'As we suspect that it’s the use of **Array.reduce()** that’s slowing our operations
    down, we should try rewriting the function in a procedural form (using a **for**
    loop) to see whether it improves the performance. Create a file named **loop.js**
    :'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们怀疑是**Array.reduce()**的使用导致我们的操作变慢，我们应该尝试以过程形式（使用**for**循环）重写该函数，以查看是否可以提高性能。创建一个名为**loop.js**的文件：
- en: '[PRE43]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Add the following to **loop.js** to create a procedural implementation of the
    **sumOfSquares()** function:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下内容添加到**loop.js**中，以创建**sumOfSquares()**函数的过程实现：
- en: '[PRE44]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now, let’s add a benchmark for the implementation of the **sumOfSquares()**
    function in **loop.js** . First, import the **loop.js** module by adding the following
    line below the **slow.js** import in **benchmark.js** :'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们为**loop.js**中**sumOfSquares()**函数的实现添加一个基准测试。首先，在**benchmark.js**中**slow.js**导入下方添加以下行以导入**loop.js**模块：
- en: '[PRE45]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Then, add a new benchmark to the suite, below the slow run:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，在慢速运行下方添加一个新的基准测试：
- en: '[PRE46]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Rerun the benchmark. This time, it will run both of our implementations and
    determine which one is fastest:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新运行基准测试。这次，它将运行我们的两个实现并确定哪个更快：
- en: '[PRE47]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: With that, we’ve confirmed that our procedural/loop implementation of the **sumOfSquares()**
    function is much faster than the original implementation.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，我们已经确认了我们的过程/循环实现的**sumOfSquares()**函数比原始实现要快得多。
- en: How it works…
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: This recipe stepped through the process of optimizing a synchronous function
    call, starting with the slow implementation of a **sumOfSquares()** function.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 此菜谱逐步展示了优化同步函数调用的过程，从**sumOfSquares()**函数的慢速实现开始。
- en: We created a micro-benchmark using Benchmark.js to create a baseline measure
    of our initial **sumOfSquares()** implementation in **slow.js** . This baseline
    measure is called a micro-benchmark. **Micro-benchmarks** are used to benchmark
    a small facet of an application. In our case, it was for the single **sumOfSquares()**
    function.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用Benchmark.js创建了一个微基准测试，以创建**slow.js**中初始**sumOfSquares()**实现的基线度量。这个基线度量被称为微基准测试。**微基准测试**用于基准测试应用程序的一个小方面。在我们的情况下，它是针对单个**sumOfSquares()**函数的。
- en: Once our micro-benchmark was created, we ran the benchmark via **0x** to generate
    a flame graph. This flame graph enabled us to identify which frames were spending
    the most time on the CPU, which provided us with an indication of which specific
    line of code within our **sumOfSquares()** function was the bottleneck.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们创建了微基准测试，我们就通过**0x**运行基准测试以生成火焰图。这个火焰图使我们能够确定哪些帧在CPU上花费了最多时间，这为我们提供了关于**sumOfSquares()**函数中哪一行代码是瓶颈的指示。
- en: From the flame graph, we determined that the use of the **map** and **reduce**
    functions of **sumOfSquares()** was slowing the operation down. Therefore, we
    created a second implementation of **sumOfSquares()** . The second implementation
    used traditional procedural code (a **for** loop). Once we had the second implementation
    of the function, in **loop.js** , we added it to our benchmarks. This allowed
    us to compare the two implementations to see which was faster.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 从火焰图中，我们确定**sumOfSquares()**函数中**map**和**reduce**函数的使用减慢了操作速度。因此，我们创建了**sumOfSquares()**的第二个实现。第二个实现使用了传统的过程式代码（一个**for**循环）。一旦我们有了函数的第二个实现，在**loop.js**中，我们将其添加到我们的基准测试中。这使我们能够比较两种实现，以查看哪种更快。
- en: Based on the number of operations that could be handled per second, **loop.js**
    was found to be significantly faster than the initial **slow.js** implementation.
    The benefit of writing a micro-benchmark is that you have evidence and confirmation
    of your optimizations.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 根据每秒可以处理的操作数量，我们发现**loop.js**比初始的**slow.js**实现显著更快。编写微基准测试的好处是，你有了优化效果的证据和确认。
- en: See also
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关内容
- en: The *Benchmarking HTTP requests* recipe in this chapter
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的*基准测试HTTP请求*菜谱
- en: The *Interpreting flame graphs* recipe in this chapter
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的*解释火焰图*菜谱
- en: The *Detecting memory leaks* recipe in this chapter
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的*检测内存泄漏*菜谱
- en: The *Optimizing asynchronous functions* recipe in this chapter
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的*优化异步函数*菜谱
- en: The *Working with worker threads* recipe in this chapter
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章的*使用工作线程*菜谱
- en: Optimizing asynchronous functions
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化异步函数
- en: The Node.js runtime was built with I/O in mind, hence its asynchronous programming
    model. In the previous recipes of this chapter, we explored how to diagnose performance
    issues within synchronous JavaScript functions.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: Node.js运行时考虑到I/O，因此具有异步编程模型。在本章的前几节菜谱中，我们探讨了如何诊断同步JavaScript函数中的性能问题。
- en: However, a performance bottleneck may occur as part of an asynchronous workflow.
    In this recipe, we’ll cover profiling and optimizing an asynchronous performance
    problem.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，性能瓶颈可能作为异步工作流的一部分出现。在这个菜谱中，我们将介绍如何分析和优化异步性能问题。
- en: Getting ready
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In this recipe, we’ll diagnose a bottleneck in an Express.js web server that
    communicates with a MongoDB database. For more information on MongoDB, please
    refer to the *Storing and retrieving data with MongoDB* recipe in [*Chapter 5*](B19212_05.xhtml#_idTextAnchor139)
    :'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将诊断一个与MongoDB数据库通信的Express.js网络服务器中的瓶颈。有关MongoDB的更多信息，请参阅[*第5章*](B19212_05.xhtml#_idTextAnchor139)中的*使用MongoDB存储和检索数据*菜谱：
- en: 'To start MongoDB, we’ll use Docker (as we did in [*Chapter 5*](B19212_05.xhtml#_idTextAnchor139)
    ). Ensuring that you have Docker running, enter the following command in your
    terminal to initialize a MongoDB database:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要启动MongoDB，我们将使用Docker（如[*第5章*](B19212_05.xhtml#_idTextAnchor139)中所述）。确保Docker正在运行，然后在您的终端中输入以下命令以初始化MongoDB数据库：
- en: '[PRE48]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Now, we need to create a directory to work in. We’ll also install the **express**
    and **mongodb** modules from **npm** :'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要创建一个工作目录。我们还将从**npm**安装**express**和**mongodb**模块：
- en: '[PRE49]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'To simulate a real application, some data needs to be present in MongoDB. Create
    a file named **values.js** :'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了模拟一个真实的应用程序，MongoDB中需要有一些数据。创建一个名为**values.js**的文件：
- en: '[PRE50]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Add the following to **values.js** . This creates a load script that will enter
    a series of numbers into our MongoDB database:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下内容添加到**values.js**中。这将创建一个加载脚本，将一系列数字输入我们的MongoDB数据库：
- en: '[PRE51]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Run the **values.js** script to populate the database for this recipe:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行**values.js**脚本以填充此菜谱的数据库：
- en: '[PRE52]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Make sure the **0x** and **autocannon** performance tools are installed globally:'
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保全局安装了**0x**和**autocannon**性能工具：
- en: '[PRE53]'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Now that our directory has been initialized and a MongoDB database is available
    with some sample data, let’s start this recipe.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经初始化了目录，并且有一个包含一些样本数据的MongoDB数据库可用，让我们开始这个菜谱。
- en: How to do it…
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In this recipe, we’re going to diagnose a bottleneck in a web application that
    communicates with a MongoDB database. We’ll build a sample application that calculates
    the average of all the values stored in the database:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将诊断一个与MongoDB数据库通信的Web应用程序中的瓶颈。我们将构建一个示例应用程序，计算数据库中存储的所有值的平均值：
- en: 'Create a file named **server.js** . This will store our server that calculates
    the average of the values in the database:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为**server.js**的文件。这将存储我们的服务器，该服务器计算数据库中值的平均值：
- en: '[PRE54]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'A dd the following code to **server.js** :'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下代码添加到**server.js**中：
- en: '[PRE55]'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Start the server by entering the following command in your terminal:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端中输入以下命令以启动服务器：
- en: '[PRE56]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Navigate to **http://localhost:3000** in your browser to check that the server
    is running. Expect to see a message printing the average of the random values
    we persisted to the database in the *Getting* *ready* section.
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在浏览器中导航到**http://localhost:3000**以检查服务器是否正在运行。你期望看到一条消息，打印出我们在*准备就绪*部分持久化到数据库的随机值的平均值。
- en: 'In a second terminal, we’ll use the **autocannon** benchmarking tool to simulate
    a load on the server:'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二个终端中，我们将使用**autocannon**基准测试工具来模拟对服务器的负载：
- en: '[PRE57]'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Expect to see the following **autocannon** result summary once the load test
    has been completed:'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦负载测试完成，你期望看到以下**autocannon**结果摘要：
- en: '![Figure 10.20 – autocannon result summary for server.js](img/Figure_10.20_B19212.jpg)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![图10.20 – autocannon结果摘要，针对server.js](img/Figure_10.20_B19212.jpg)'
- en: Figure 10.20 – autocannon result summary for server.js
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.20 – autocannon结果摘要，针对server.js
- en: This load test shows an average of around **317** requests per second.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 这个负载测试显示平均每秒大约**317**个请求。
- en: 'Now, let’s see where the bottlenecks are in our application. We’ll use the
    **0x** tool to generate a flame graph. Restart the server with the following command:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们看看我们应用中的瓶颈在哪里。我们将使用**0x**工具生成火焰图。使用以下命令重新启动服务器：
- en: '[PRE58]'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'In the second terminal, let’s simulate a load on the server again using the
    **autocannon** tool:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二个终端中，让我们再次使用**autocannon**工具模拟对服务器的负载：
- en: '[PRE59]'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Stop the server and open the generated flame graph in your browser. Expect
    a flame graph similar to the following:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 停止服务器并在浏览器中打开生成的火焰图。你期望看到一个类似于以下火焰图：
- en: "![Figure 10.21 – \uFEFFAn overview of the 0x flame graph showing deserializeObject()\
    \ hot frames](img/Figure_10.21_B19212.jpg)"
  id: totrans-336
  prefs: []
  type: TYPE_IMG
  zh: '![图10.21 – 0x火焰图概述，显示deserializeObject()热帧](img/Figure_10.21_B19212.jpg)'
- en: Figure 10.21 – An overview of the 0x flame graph showing deserializeObject()
    hot frames
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.21 – 0x火焰图概述，显示deserializeObject()热帧
- en: As we learned in the *Interpreting flame graphs* recipe of this chapter, the
    darker/more red frames can indicate bottlenecks in our application. In our example,
    the **deserializeObject()** function appears to be the hottest, meaning it was
    spending the most amount of time on the CPU. This is a commonly observed bottleneck
    in MongoDB-based applications. The bottleneck in **deserializeObject()** is related
    to the large amount of data we’re querying and receiving from our MongoDB instance.
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如我们在本章的*解释火焰图*食谱中所学，较深色/红色较重的帧可以表示我们应用中的瓶颈。在我们的例子中，**deserializeObject()**函数看起来是最热的，这意味着它在CPU上花费了最多的时间。这在基于MongoDB的应用程序中是一个常见的瓶颈。**deserializeObject()**中的瓶颈与我们从MongoDB实例查询和接收的大量数据有关。
- en: 'Let’s try and solve this bottleneck by precomputing and storing the average
    in the database. This should help by reducing the amount of data we request from
    MongoDB and removing the need to calculate the average. We’ll create a script
    called **calculate-average.js** that calculates the average and stores it in MongoDB.
    Create the **calculate-average.js** file:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们尝试通过预先计算并将平均值存储在数据库中来解决这个问题瓶颈。这应该通过减少我们从MongoDB请求的数据量以及消除计算平均值的需要来帮助。我们将创建一个名为**calculate-average.js**的脚本，该脚本计算平均值并将其存储在MongoDB中。创建**calculate-average.js**文件：
- en: '[PRE60]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Add the following code to **calculate-average.js** :'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下代码添加到**calculate-average.js**：
- en: '[PRE61]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Run the **calculate-averages.js** script to calculate and store the average
    in the database:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行**calculate-averages.js**脚本来计算并存储平均值到数据库中：
- en: '[PRE62]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Now, we can rewrite the server so that it returns the stored average, rather
    than calculating it upon each request. Create a new file named **server-no-processing.js**
    :'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以重写服务器，使其返回存储的平均值，而不是在每次请求时计算它。创建一个名为**server-no-processing.js**的新文件：
- en: '[PRE63]'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Add the following to **server-no-processing.js** :'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下内容添加到**server-no-processing.js**：
- en: '[PRE64]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Let’s rerun the **autocannon** benchmark. Start the server with **$ node server-no-process.js**
    . Then, in a second terminal window, rerun the **autocannon** load test:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们重新运行**autocannon**基准测试。使用**$ node server-no-process.js**命令启动服务器。然后在第二个终端窗口中重新运行**autocannon**负载测试：
- en: '[PRE65]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Expect to see the **autocannon** result summary once the load test has been
    completed:'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦负载测试完成，你期望看到**autocannon**结果摘要：
- en: '![Figure 10.22 – autocannon result summary for server-no-processing.js](img/Figure_10.22_B19212.jpg)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![图10.22 – autocannon结果摘要，针对server-no-processing.js](img/Figure_10.22_B19212.jpg)'
- en: Figure 10.22 – autocannon result summary for server-no-processing.js
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.22 – autocannon结果摘要，针对server-no-processing.js
- en: Here, we can see that the average number of requests per second has increased
    from around **317** in **server.js** to **6430** using the precomputed average
    in **server-no-processing.js** .
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到，每秒请求的平均数量从**server.js**中的大约**317**增加到使用预先计算的**server-no-processing.js**中的**6430**。
- en: In this recipe, we learned how obtaining and processing large amounts of data
    from MongoDB can introduce bottlenecks in our application. We solved the bottleneck
    showcased in this recipe by precomputing and storing the average.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们学习了如何从MongoDB获取和加工大量数据可能会在我们的应用程序中引入瓶颈。我们通过预先计算和存储平均值来解决这个配方中展示的瓶颈。
- en: How it works…
  id: totrans-356
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: This recipe demonstrated a bottleneck in an application that communicated with
    a MongoDB database.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方演示了一个与MongoDB数据库通信的应用程序中的瓶颈。
- en: The slowness was caused by both the large amount of data being requested and
    the calculation of the average upon each request. By using the **0x** tool to
    generate a flame graph, it was possible to diagnose the specific function that
    was causing the bottleneck.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 慢速是由请求的大量数据和每次请求计算平均值引起的。通过使用**0x**工具生成火焰图，可以诊断出导致瓶颈的具体函数。
- en: In this case, the bottleneck was solved by precomputing the average and storing
    it in the database. This meant that instead of having to query the database for
    all values and computing the average on each request, it was possible to just
    query and obtain the average directly. This showed a significant increase in performance.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个情况下，瓶颈问题通过预先计算平均值并将其存储在数据库中得到了解决。这意味着，我们不再需要为每个请求查询数据库中的所有值并计算平均值，而是可以直接查询并获取平均值。这显著提高了性能。
- en: It was worthwhile amending the data model to store the precomputed average so
    that it didn’t need to be calculated on each request. However, in a real application,
    it may not always be possible to edit the data model to store computed values.
    When building a new application, it’s worth considering what data should be stored
    in the data model to minimize computation on the live server.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 修改数据模型以存储预先计算的平均值，这样就不需要在每个请求上计算它，这是值得的。然而，在实际应用中，可能并不总是能够编辑数据模型来存储计算值。在构建新应用时，考虑应该将哪些数据存储在数据模型中，以最小化实时服务器上的计算量，这是值得考虑的。
- en: Micro-optimizations, such as precomputing an average, can enhance performance
    by reducing runtime computation. These small improvements can boost efficiency,
    especially under heavy load. However, premature optimizations can complicate code,
    making maintenance harder. As such, it’s usually recommended to prioritize optimizations
    that offer substantial performance gains for your application and end users.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 预先计算平均值这样的微优化可以通过减少运行时计算来提高性能。这些小的改进可以提升效率，尤其是在高负载下。然而，过早的优化可能会使代码复杂化，使得维护更加困难。因此，通常建议优先考虑那些为您的应用程序和最终用户提供实质性性能提升的优化。
- en: See also
  id: totrans-362
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: The *Creating an Express.js web application* recipe in [*Chapter 6*](B19212_06.xhtml#_idTextAnchor178)
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B19212_06.xhtml#_idTextAnchor178)中的*创建Express.js Web应用程序*配方'
- en: The *Storing and retrieving data with MongoDB* recipe in [*Chapter 7*](B19212_07.xhtml#_idTextAnchor212)
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第7章*](B19212_07.xhtml#_idTextAnchor212)中的*使用MongoDB存储和检索数据*配方'
- en: The *Benchmarking HTTP requests* recipe in this chapter
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的*基准测试HTTP请求*配方
- en: The *Detecting memory leaks* recipe in this chapter
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的*检测内存泄漏*配方
- en: The *Optimizing synchronous functions* recipe in this chapter
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的*优化同步函数*配方
- en: The *Working with worker threads* recipe in this chapter
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中的*与工作线程一起工作*配方
- en: Working with worker threads
  id: totrans-369
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与工作线程一起工作
- en: JavaScript is a single-threaded programming language, meaning that it executes
    one task at a time within a process. Node.js also runs on a single thread, but
    it uses an event loop to handle asynchronous operations, enabling non-blocking
    I/O calls. Despite this, the event loop processes one task at a time. As a result,
    CPU-intensive tasks can block the event loop and degrade the overall performance
    of your application.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: JavaScript是一种单线程编程语言，意味着它在一个进程内一次只执行一个任务。Node.js也是在一个线程上运行的，但它使用事件循环来处理异步操作，允许非阻塞I/O调用。尽管如此，事件循环一次只处理一个任务。因此，CPU密集型任务可能会阻塞事件循环并降低应用程序的整体性能。
- en: To handle CPU-intensive tasks in Node.js efficiently, you should consider using
    worker threads. Worker threads were declared stable in Node.js version 12 and
    later and are accessible through the core **worker_threads** core module. The
    worker threads API allows you to run JavaScript code in parallel across multiple
    threads, making it well-suited for CPU-intensive operations.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Node.js中有效地处理CPU密集型任务，你应该考虑使用工作线程。工作线程在Node.js版本12及以后被宣布为稳定，并且可以通过核心 **worker_threads**
    模块访问。工作线程API允许你在多个线程上并行运行JavaScript代码，非常适合CPU密集型操作。
- en: This tutorial will introduce the **worker_threads** module and demonstrate how
    to use it to manage CPU-intensive tasks.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将介绍 **worker_threads** 模块，并演示如何使用它来管理CPU密集型任务。
- en: Getting ready
  id: totrans-373
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'First, ensure you’re using Node.js 22. Then, create a project directory to
    work in named **worker-app** :'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，确保你正在使用Node.js 22。然后，创建一个名为 **worker-app** 的工作目录：
- en: '[PRE66]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Now that we’ve created a directory to work in, we can start this recipe.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了一个工作目录，我们可以开始这个菜谱。
- en: How to do it…
  id: totrans-377
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In this recipe, we’ll learn how to leverage worker threads to handle a CPU-intensive
    task:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们将学习如何利用工作线程来处理CPU密集型任务：
- en: 'We’ll start by creating a simplified worker that returns the **Hello <name>!**
    string. Create a file named **hello-worker.js** :'
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先创建一个简化的工作线程，它返回 **Hello <name>!** 字符串。创建一个名为 **hello-worker.js** 的文件：
- en: '[PRE67]'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'In **hello-worker.js** , we need to import the necessary class and methods:'
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **hello-worker.js** 中，我们需要导入必要的类和方法：
- en: '[PRE68]'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Now, we need to create an **if** statement using the **isMainThread()** method
    from the **worker_threads** module. Anything within the **if** block will be executed
    on the main thread. Code within the **else** block will be executed in the worker.
    Add the following to **hello-worker.js** :'
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要使用 **worker_threads** 模块的 **isMainThread()** 方法创建一个 **if** 语句。**if**
    块内的任何内容将在主线程上执行。**else** 块内的代码将在工作线程中执行。在 **hello-worker.js** 中添加以下内容：
- en: '[PRE69]'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Now, let’s populate the main thread code. First, create a new worker and pass
    the **Worker** constructor two arguments. The first argument will be the filename
    of the worker’s main script or module. In this case, we’ll use **__filename**
    to reference our current file. The second parameter will be an **options** object,
    which will specify a **workerData** property that holds the name we want to pass
    through to the worker thread. The **workerData** property is used to share values
    with the worker thread. Add the following line under the **// Main thread** **code**
    comment:'
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们填充主线程代码。首先，创建一个新的工作线程，并将两个参数传递给 **Worker** 构造函数。第一个参数将是工作线程主脚本或模块的文件名。在这种情况下，我们将使用
    **__filename** 来引用当前文件。第二个参数将是一个 **options** 对象，它将指定一个 **workerData** 属性，该属性包含我们想要传递到工作线程的名字。**workerData**
    属性用于与工作线程共享值。在 **// Main thread code** 注释下方添加以下行：
- en: '[PRE70]'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Now, expect the worker thread to pass a value back to the main thread. To capture
    this, we can create a worker message event listener. Add the following line below
    the worker initialization:'
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们期望工作线程将一个值传回主线程。为了捕获这个值，我们可以创建一个工作线程消息事件监听器。在工作线程初始化下方添加以下行：
- en: '[PRE71]'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Now, we can write the worker code that will construct the greeting. Using the
    **parentPort.postMessage()** method will return the value to our main thread.
    Add the following code below the **// Worker** **code** comment:'
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以编写工作线程代码，该代码将构建问候语。使用 **parentPort.postMessage()** 方法将值返回到主线程。在 **//
    Worker code** 注释下方添加以下代码：
- en: '[PRE72]'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Now, run the program with the following command:'
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令运行程序：
- en: '[PRE73]'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Now, let’s try something CPU-intensive and compare the behaviors when using
    and not using worker threads. First, create a file named **fibonacci.js** . This
    will contain a Fibonacci calculator program that returns the Fibonacci number
    at a given index. Create the **fibonacci.js** file:'
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们尝试一些CPU密集型任务，并比较使用和不使用工作线程时的行为。首先，创建一个名为 **fibonacci.js** 的文件。这个文件将包含一个计算给定索引的斐波那契数的程序。创建
    **fibonacci.js** 文件：
- en: '[PRE74]'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Add the following to **fibonacci.js** :'
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **fibonacci.js** 中添加以下内容：
- en: '[PRE75]'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Run the script with the following command:'
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令运行脚本：
- en: '[PRE76]'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: In this case, the **fibonacci()** function blocks the execution of **console.log("...");**
    until the **fibonacci()** function has finished running.
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个例子中，**fibonacci()** 函数会阻塞 **console.log("...");** 的执行，直到 **fibonacci()**
    函数运行完成。
- en: 'Now, let’s try writing it using worker threads to see how we can avoid blocking
    the main thread. Create a file named **fibonacci-worker.js** :'
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们尝试使用工作线程来编写它，看看我们如何避免阻塞主线程。创建一个名为 **fibonacci-worker.js** 的文件：
- en: '[PRE77]'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Start by adding the following imports to **fibonacci-worker.js** :'
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，将以下导入添加到**fibonacci-worker.js**中：
- en: '[PRE78]'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Next, as we did in **fibonacci.js** in *Step 8* , add the **Fibonacci** **calculator**
    function:'
  id: totrans-404
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，就像我们在*步骤8*中的**fibonacci.js**所做的那样，添加**斐波那契****计算器**函数：
- en: '[PRE79]'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Finally, we can implement the structure that enables us to use the **worker**
    thread. Add the following code:'
  id: totrans-406
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以实现一个结构，使我们能够使用**工作线程**。添加以下代码：
- en: '[PRE80]'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Now, run this script with the following command:'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令运行此脚本：
- en: '[PRE81]'
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: Observe that **console.log("...");** is being printed before the result of the
    **fibonacci()** function returns. The **fibonacci()** function has been offloaded
    to the worker thread, meaning work on the main thread can continue.
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意到**console.log("...");**在**fibonacci()**函数返回结果之前被打印出来。**fibonacci()**函数已经被卸载到工作线程，这意味着主线程上的工作可以继续。
- en: With that, we’ve learned how to offload tasks to a worker thread using the Node.js
    core **worker_threads** module.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，我们已经学会了如何使用Node.js核心的**worker_threads**模块将任务卸载到工作线程。
- en: How it works…
  id: totrans-412
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This recipe served as an introduction to worker threads. As we’ve seen, worker
    threads can be used to handle CPU-intensive computations. Offloading CPU-intensive
    computations to a worker thread can help avoid blocking the Node.js event loop.
    This means the application can continue to handle other work – for example, I/O
    operations – while CPU-intensive tasks are being processed.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 这个菜谱作为工作线程的介绍。正如我们所见，工作线程可以用来处理CPU密集型计算。将CPU密集型计算卸载到工作线程可以帮助避免阻塞Node.js事件循环。这意味着应用程序可以在处理CPU密集型任务的同时继续处理其他工作——例如，I/O操作。
- en: 'Worker threads are exposed via the core Node.js **worker_threads** module.
    To use a worker thread in this recipe, we imported the following four assets from
    the **worker_threads** core module:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 工作线程通过Node.js核心的**worker_threads**模块暴露。为了在这个菜谱中使用工作线程，我们从**worker_threads**核心模块导入了以下四个资产：
- en: '**Worker** : The worker thread class, which represents an independent JavaScript
    thread.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工作线程**：代表一个独立的JavaScript线程的工作线程类。'
- en: '**isMainThread** : A property that returns **true** if the code isn’t running
    in a worker thread.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**isMainThread**：一个属性，如果代码不在工作线程中运行，则返回**true**。'
- en: '**parentPort** : This is a message port that allows communication from the
    worker to the parent thread.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**parentPort**：这是一个消息端口，允许从工作线程到父线程的通信。'
- en: '**workerData** : This property clones the data that’s passed in the worker
    thread constructor. This is how the initial data from the main thread is passed
    to the worker thread.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**workerData**：这个属性克隆了传递给工作线程构造函数的数据。这是从主线程将初始数据传递到工作线程的方式。'
- en: 'In this recipe, we initialized a worker thread with the following code:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们使用以下代码初始化了一个工作线程：
- en: '[PRE82]'
  id: totrans-420
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: The **Worker** constructor requires a mandatory first argument – that is, a
    filename. This filename is the path to the worker thread’s main script or module.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: '**Worker**构造函数需要一个强制性的第一个参数——即，一个文件名。这个文件名是工作线程主脚本或模块的路径。'
- en: The second argument is an **options** object, which can accept many different
    configuration options. In **fibonacci-worker.js** , we provided just one configuration
    option, **workerData** , to pass the value of **n** to the worker thread. The
    full list of options that can be passed via the worker thread’s **options** object
    is listed in the Node.js **worker_threads** API documentation ( [https://nodejs.org/api/worker_threads.html#worker_threads_new_worker_filename_options](https://nodejs.org/api/worker_threads.html#worker_threads_new_worker_filename_options)
    ).
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个参数是一个**选项**对象，它可以接受许多不同的配置选项。在**fibonacci-worker.js**中，我们只提供了一个配置选项，**workerData**，将**n**的值传递给工作线程。可以通过工作线程的**options**对象传递的完整选项列表可以在Node.js
    **worker_threads** API文档中找到（[https://nodejs.org/api/worker_threads.html#worker_threads_new_worker_filename_options](https://nodejs.org/api/worker_threads.html#worker_threads_new_worker_filename_options)）。
- en: 'Once the worker has been initialized, we can register event listeners on it.
    In this recipe, we registered a message event listener function that executes
    every time a message is received from the worker. The following events can be
    listened for on a worker:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦初始化了工作线程，我们就可以在上面注册事件监听器。在这个菜谱中，我们注册了一个消息事件监听器函数，每次从工作线程接收到消息时都会执行。可以在工作线程上监听以下事件：
- en: '**error** : Emitted when the worker thread throws an uncaught exception'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**error**：当工作线程抛出未捕获的异常时发出。'
- en: '**exit** : Emitted once the worker thread has stopped executing code'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**exit**：当工作线程停止执行代码时发出。'
- en: '**message** : Emitted when the worker thread emits a message using **parentPort.postMessage()**'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**message**：当工作线程使用**parentPort.postMessage()**发出消息时触发'
- en: '**messagerror** : Emitted when deserializing the message fails'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**messagerror**：在反序列化消息失败时触发'
- en: '**online** : Emitted when the worker thread starts executing JavaScript code'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**online**：当工作线程开始执行JavaScript代码时触发'
- en: We use **parentPort.postMessage()** to send the value of **fibonacci(n)** back
    to the parent thread. In the parent thread, we register a message event listener
    to detect incoming messages from the worker thread.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用**parentPort.postMessage()**将**fibonacci(n)**的值发送回父线程。在父线程中，我们注册一个消息事件监听器以检测来自工作线程的传入消息。
- en: With that, we’ve introduced worker threads and showcased how they can be used
    to handle CPU-intensive tasks.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们已经介绍了工作线程，并展示了如何使用它们来处理CPU密集型任务。
