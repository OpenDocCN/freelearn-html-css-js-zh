- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Assert Wrapper – the Importance of Embedded Details
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will be writing our first assertion wrapper. Assertions
    allow us to pass or fail a test as well as add detail regarding the expected and
    actual results. WebdriverIO has at least three ways to implement assertions and
    each has its own style. First, there is the standard Jest `expect-webdriverio`
    for all examples in this book. However, a little background on how these approaches
    differ should be noted.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll cover the following main topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: expect, assert, and should
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Timeout
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hard and soft expect assertions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allure reports
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: expect, assert, and should –how did we get here?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s take a look at a brief history of JavaScript assertion libraries to understand
    why we will be making some of the choices in our custom `assert()` wrapper.
  prefs: []
  type: TYPE_NORMAL
- en: What is Jasmine?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Jasmine was first released in 2010\. It was designed to provide a simple and
    flexible way to add assertions. It provides a set of built-in assertion methods.
    Note that the interface is `expect` with chainable methods such as `.toBe`, `.toEqual`,
    and `.not`. Here is a sample assertion in Jasmine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The preceding test calls a simple function that returns the sum of two arguments
    passed to the `AddNumbers()` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a basic arithmetic assertion. If we run it, we notice the pass result
    does not report anything. Only the failure is reported. It really does not provide
    much detail when passing or failing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1: Results of a pass and intentional fail of the AddNumbers() function](img/B19395_08_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.1: Results of a pass and intentional fail of the AddNumbers() function'
  prefs: []
  type: TYPE_NORMAL
- en: In a test automation project, we would need to extract the object properties
    or values and validate that against the expected result. The detailed result may
    only report expected `[true]` actual `[false]`. To provide this output would require
    a lot of additional code to include if we had it performed at the test or feature
    file level.
  prefs: []
  type: TYPE_NORMAL
- en: What is Jest?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In 2013, Jest was released by Facebook and became widely adopted by the React
    community. It has a similar assertion syntax as Jasmine with additional features
    including snapshot testing and code coverage reporting. Note the interface is
    also `expect`. Here is the same assertion in Jest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'However, Jest on its own does not support any messages to report the details
    of the validation. The `jest-expect-message` package should be included to provide
    this functionality with `npm` or `yarn`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have added the `expect` message package for Jest, we can provide
    more descriptive results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Jest is included as part of the WebdriverIO package, but WDIO has an extended
    assertion library of its own. This allows us to pass elements directly for assertions
    rather than writing our own.
  prefs: []
  type: TYPE_NORMAL
- en: What is Chai?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Chai is a popular assertion library for JavaScript that provides three interfaces
    for making assertions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`should (BDD)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`expect (BDD)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`assert (TDD)`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these interfaces has its own pros and cons, which we will look into
    in the subsections.
  prefs: []
  type: TYPE_NORMAL
- en: Should
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `should` interface extends all objects with a `should` property that can
    be used to make assertions. Here is a Chai `should` sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: While this interface allows for readable and expressive code, it can lead to
    unexpected side effects in the way that it modifies object behaviors. For this
    reason, it will not be a part of our implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Assert
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `assert` interface provides a more classical style of making assertions,
    using traditional methods such as `assert.equal()` and `assert.notEqual()`. This
    interface is useful for developers who are already familiar with other testing
    frameworks or who prefer a more traditional style of testing. However, it can
    be less readable and expressive than the `should` or `expect` interfaces, especially
    when dealing with more complex assertions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Expect
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Chai `expect` interface provides a more flexible and chainable way of making
    assertions. This interface is designed to be easy to read and write and provides
    a fluent syntax that can be used to make complex assertions in a clear and concise
    way. Here is a Chai `should` sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Using Chai’s `expect` interface is the preferred way of making assertions.
    It provides a lot of flexibility without the side effects of `should` with a similar
    syntax to the Jest assertions. There is a problem, we don’t get all the details.
    Consider this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Sure, the tests passed, but what exactly did it do? There is no expected result,
    actual results, or any detail of what the assertion is doing. This is why we need
    wrappers to simplify our reporting of our results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us look at a failing assertion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Now we are over-reporting as we had one validation. The error was reported three
    times to the output, and that is a problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one problem – all of these assertion packages are designed to perform
    a hard expect ending the test execution, not a soft expect that will allow the
    test to perform more validations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Notice it takes 6 seconds for the validation to fail. Do we really need to wait
    that much time? We already have the `pageSync()` method consuming all the time
    needed.
  prefs: []
  type: TYPE_NORMAL
- en: Timeout – delay of game
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The default timeout for a WebdriverIO `expect` matcher is 3 seconds and the
    interval is 100 ms. That is 30 checks over 3 seconds, which is far better than
    waiting 30 seconds as is the industry standard. Remember we are using the `pageSync()`
    method to burn the time that the page uses to build. It makes sense that our assertions
    should be available almost immediately. To adjust the timeout and interval of
    the `expect-webdriverio` assertion, we can make a change in the WebdriverIO hooks
    section of the `wdio.config.ts` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This code will now change our `expect` assertions to be executed 20 times.
    The wait timeout will be 5 seconds. The check will be performed every 1/4 second:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Spec Files: 0 passed, 1 failed, 1 total (100% completed)` `in 00:00:05`'
  prefs: []
  type: TYPE_NORMAL
- en: The resulting time is now reduced to an optimal amount. It is just a second,
    but a little here and there saves minutes and hours.
  prefs: []
  type: TYPE_NORMAL
- en: What is expect-webdriverio?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the purpose of this book, we will be using `expect-webdriverio`.
  prefs: []
  type: TYPE_NORMAL
- en: 'WebdriverIO uses the `expect-webdriverio` assertion library, which is an extension
    of the Jest `expect` interface. It adds browser and element assertions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: However, all these libraries are missing the ability to execute a soft assertion.
    For that, we turn to Chai and the `soft-assert` package.
  prefs: []
  type: TYPE_NORMAL
- en: What are hard and soft expect assertions?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By default, all of the assertion packages perform a **hard expect assertion**,
    which is more commonly known as a **hard assert**. This means that when an assertion
    fails, the test ends. What kind of superhero leaves the fight after the first
    punch? This is problematic as we might have four or five values on a single page
    that we want to assert. What is the point of failing on the first assertion and
    leaving the next four out of the results? We want the power to continue the fight
    even if we take one to the chin along the way.
  prefs: []
  type: TYPE_NORMAL
- en: 'That is why we strive to add the ability of a **soft expect** (more commonly
    known as **soft assert**) into the framework. This feature is built into Java’s
    TestNG. It seems a shame that it is missing from all the popular JavaScript assertion
    libraries. If the buttons exist for navigation, the best testing frameworks will
    be able to get to the end point and have all validations executed, no matter whether
    they pass or fail. That is our ultimate dual goal: more results in our report
    and less repetitious piecemeal runs.'
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, we need to protect our identities; to accomplish this feat, we use `expect-webdriverio`,
    which extends the Chai `expect` interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now perform a failing soft assertion on our **Bogus** button and still
    allow the next assertions to execute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We have our power rings. When we smash them together, we will take on multiple
    forms, as a helper `expectAdv()` wrapper will be used to increase the flexibility
    in the amount of detail being provided in a consistent format. This section will
    take us beyond generic fail messages and detail the pass results with the least
    amount of repeated code.
  prefs: []
  type: TYPE_NORMAL
- en: The `expect-webdriverio` library supports 23 different element matcher assertions.
    Eight are substring matchers of other full-string assertions. Others, such as
    `.toBePresent`, `.toHaveChildren`, and `.toBeDisplayedInViewPort`, are in the
    lesser part of the 80/20 relevancy.
  prefs: []
  type: TYPE_NORMAL
- en: What are soft assertions and why would we need them?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An efficient test will be able to perform multiple validations on a page, but
    if the first of three assertions fail, the test will immediately end. Maybe only
    the first assertion is failing, or maybe all three. We want the full count of
    assertions, not the least. Otherwise, it becomes a piecemeal process and slows
    us down.
  prefs: []
  type: TYPE_NORMAL
- en: Note that `Expect.toBeExist`, `Expect.toBePresent`, and `Expect.toBeExisting`
    only mean the element is in the DOM. They do not explicitly mean the element is
    visible to the user, so they are, for the most part, impractical.
  prefs: []
  type: TYPE_NORMAL
- en: 'WebdriverIO provides positive and negative checks of the status of elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'It also provides two ways to check whether an element contains text or a value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'It also provides validations of IDs, elements, and attributes, which can be
    exact or string subsets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Soft asserts – allowing a test to continue after an assertion fails
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In our custom `expectAdv` wrapper, we will implement a few concepts that allow
    it to be read similarly to a plain English sentence. The first parameter, `actual`,
    is intentionally assigned the `any` type. This is because we want the flexibility
    to validate either an element or a string value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Here, `assertionType` is a string that indicates the assertion to perform. An
    element might *exist*; the element might *equal* an expected string.
  prefs: []
  type: TYPE_NORMAL
- en: The expected argument is optional as it would not be required if an element
    “is enabled”.
  prefs: []
  type: TYPE_NORMAL
- en: Quick tip
  prefs: []
  type: TYPE_NORMAL
- en: The description is required. Every validation should have some detail about
    what is being performed. Thus, if it is missing, a helpful nudge to add transparency
    to our test case is provided.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of a soft assertion, the method returns a Boolean `true` or `false`
    value. This means our test cases can be optimized with decision trees. This concept
    will be used in a later chapter when we discuss how to have steps that continue
    without failure even if the element does not exist.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Allure reports
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Allure is a powerful reporting framework that presents concise and well-organized
    reports. You can access this report template by installing the `@wdio/allure-reporter`
    and `allure-commandline` packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Allure exports reports in a standardized format called Allure results format.
    To generate comprehensive reports, you can utilize the Allure framework through
    the command-line interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The Allure Framework is a versatile and lightweight test reporting tool supporting
    multiple programming languages. It provides a succinct presentation of test results
    in HTML format, empowering all stakeholders in the development process to extract
    valuable insights from routine test executions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: By adding these Allure statements into our framework, we can provide significantly
    more detail to stakeholders in a way that is visually informative.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2: Samples of test results in Allure with historical trends](img/B19395_08_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.2: Samples of test results in Allure with historical trends'
  prefs: []
  type: TYPE_NORMAL
- en: Allure reports can organize tests into subcategories. This makes it clear whether
    related tests are failing. It also shows how the runs have been performing over
    time. This can show both an increase in test case coverage as well trends where
    results are improving or recently worsening.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3: Sample of step-by-step execution with a screen capture of the
    Login page'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B19395_08_3.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8.3: Sample of step-by-step execution with a screen capture of the Login
    page'
  prefs: []
  type: TYPE_NORMAL
- en: These reports also provide the option to add screen captures such as X-ray vision.
    This can give vital clues as to what is occurring when the test fails, particularly
    if we are running in the cloud without a direct live view into the system as it
    runs.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we talked about the history of assert, expect, and should assertions.
    We introduced the concepts of hard and soft assertions, why they are important
    distinctions, and when they should be implemented. We also introduced Allure reports
    to provide details of all events being executed and the results of whether they
    pass or fail. Allure reports will further enhance our view in the future by providing
    a historical view of tests that pass and fail. In the next chapter, we'll build
    the page object model.
  prefs: []
  type: TYPE_NORMAL
