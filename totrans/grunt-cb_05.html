<html><head></head><body><div><div><div><div><h1 class="title"><a id="ch05"/>Chapter 5. Running Automated Tests</h1></div></div></div><p>In this chapter, we will cover the following recipes:</p><div><ul class="itemizedlist"><li class="listitem">Running Jasmine tests</li><li class="listitem">Running QUnit tests</li><li class="listitem">Running NodeUnit tests</li><li class="listitem">Running Mocha client-side tests</li><li class="listitem">Running Mocha server-side tests</li><li class="listitem">Generating coverage reports for server-side code using Mocha and Blanket</li><li class="listitem">Generating coverage reports for client-side code using Mocha and Blanket</li><li class="listitem">Generating coverage reports for client-side code using QUnit and Istanbul</li></ul></div><div><div><div><div><h1 class="title"><a id="ch05lvl1sec51"/>Introduction</h1></div></div></div><p>As the size and complexity of a software unit increases, it can become quite time-consuming to ensure that it behaves according to its specifications each time it is altered. For this purpose, automated testing becomes invaluable by increasing the overall reliability and quality of a software unit, without constant manual testing.</p><p>There are various levels of testing that a project can implement, ranging from unit tests at the function or class level, up to integration tests that make use of an entire application stack. Most testing frameworks provide for this entire range, perhaps just with the addition of a few tools.</p><p>Also worth mentioning in relation to testing is the practice of test-driven development, in which a developer first creates (initially failing) a test case for a desired improvement or a new feature, and then does the minimum amount of development to make the test case pass. To finish it off, the developer will then review the written code and refactor it to acceptable standards.</p></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec52"/>Running Jasmine tests</h1></div></div></div><p>In this recipe, we'll <a id="id164" class="indexterm"/>make use of the <code class="literal">contrib-jasmine (0.7.0)</code> plugin to run our automated <strong>Jasmine</strong> tests in a <strong>PhantomJS</strong> browser environment.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec120"/>Getting ready</h2></div></div></div><p>In this example, we'll work with the basic project structure we created in the <em>Installing Grunt on a project</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>. Be sure to refer to it if you are not yet familiar with its contents.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec121"/>How to do it...</h2></div></div></div><p>The following steps take us through creating a sample code base, a few tests to run against the code base, and setting up Grunt to run them for us in a PhantomJS browser environment.</p><div><ol class="orderedlist arabic"><li class="listitem">We'll start by installing the package that contains the <code class="literal">contrib-jasmine</code> plugin by following  the instructions provided in the <em>Installing a plugin</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>.</li><li class="listitem">Then, we'll create a simple JavaScript source file in our project directory, which contains a function that we'd like to test. Let's call it <code class="literal">main.js</code> and add the following content to it:<div><pre class="programlisting">function square(x) {
  return x * x;
}</pre></div></li><li class="listitem">Now, we can write a simple suite of tests, using the Jasmine framework, to test the <code class="literal">square</code> method. Let's create a file called <code class="literal">tests.js</code> in the project directory with the following contents:<div><pre class="programlisting">describe('Square method', function() {
  it('returns 4 for 2', function () {
    expect(square(2)).toBe(4);
  });
  it('returns 9 for 3', function () {
    expect(square(3)).toBe(9);
  });
  it('returns 16 for 4', function () {
    expect(square(4)).toBe(16);
  });
});</pre></div></li><li class="listitem">With our code base and tests created, we can now add the following <code class="literal">jasmine</code> task to our configuration, which will load the code from <code class="literal">main.js</code>, and run the tests in the <code class="literal">tests.js</code> file:<div><pre class="programlisting">jasmine: {
  src: 'main.js',
  options: {
    specs: 'tests.js'
  }
}</pre></div></li><li class="listitem">We can then <a id="id165" class="indexterm"/>run the task using the <code class="literal">grunt jasmine</code> command, which should produce the following output informing us of the test results:<div><pre class="programlisting">
<strong>Running "jasmine:src" (jasmine) task</strong>
<strong>Testing jasmine specs via PhantomJS</strong>

<strong> Square method</strong>
<strong>   ✓ returns 4 for 2</strong>
<strong>   ✓ returns 9 for 3</strong>
<strong>   ✓ returns 16 for 4</strong>

<strong>3 specs in 0.015s.</strong>
<strong>&gt;&gt; 0 failures</strong>
</pre></div></li></ol><div></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec122"/>There's more...</h2></div></div></div><p>The <code class="literal">jasmine</code> task<a id="id166" class="indexterm"/> provides us with several useful options that can be used in conjunction with its basic test running feature. We'll look at how to load helpers to be used in tests, how to load libraries before running tests, how to load styles required by tests, and how to provide a custom template for the specification runner.</p><div><div><div><div><h3 class="title"><a id="ch05lvl3sec56"/>Loading helpers to be used in tests</h3></div></div></div><p>If we'd like <a id="id167" class="indexterm"/>to make use of custom equality testers or matchers, we can include them using the <code class="literal">helpers</code> option before tests are run. In the following example, we indicate that the custom helpers contained in the <code class="literal">helpers.js</code> file should be loaded before running the tests:</p><div><pre class="programlisting">jasmine: {
  src: 'main.js',
  options: {
    specs: 'tests.js',
    helpers: 'helpers.js'
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec57"/>Loading libraries before running tests</h3></div></div></div><p>In <a id="id168" class="indexterm"/>case the code we'd like to test depends on third-party libraries that you don't load in either your source, specifications or helpers, they can be loaded using the <code class="literal">vendor</code> option as shown in the following example:</p><div><pre class="programlisting">jasmine: {
  src: 'main.js',
  options: {
    specs: 'tests.js',
    vendor: ['lodash.min.js']
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec58"/>Loading styles required by tests</h3></div></div></div><p>If we have<a id="id169" class="indexterm"/> tests that depend on specific CSS styles being present in the browser, we can have them loaded using the <code class="literal">styles</code> option as shown in the following example:</p><div><pre class="programlisting">jasmine: {
  src: 'main.js',
  options: {
    specs: 'tests.js',
    styles: 'styles.css'
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec59"/>Providing a custom template for the specification runner</h3></div></div></div><p>When <a id="id170" class="indexterm"/>writing tests for source code that runs inside a browser, the need for a few HTML elements, such as fixtures, can be quite common. The simplest way to add HTML to the generated specification runner (<code class="literal">test.html</code>) is to customize the template that it's generated with.</p><p>The following steps take us through retrieving the default specification runner template, customizing it, and using it as our template:</p><div><ol class="orderedlist arabic"><li class="listitem">The default specification runner template can be retrieved from the repository of the <code class="literal">contrib-jasmine</code> plugin and saved to the <code class="literal">runner.tmpl</code> file.<div><h3 class="title"><a id="tip43"/>Tip</h3><p>At the time of<a id="id171" class="indexterm"/> writing this, the default specification runner template could be downloaded from the following link:</p><p><a class="ulink" href="https://github.com/gruntjs/grunt-contrib-jasmine/raw/master/tasks/jasmine/templates/DefaultRunner.tmpl">https://github.com/gruntjs/grunt-contrib-jasmine/raw/master/tasks/jasmine/templates/DefaultRunner.tmpl</a></p></div></li><li class="listitem">Once <a id="id172" class="indexterm"/>we have the default template saved as <code class="literal">runner.tmpl</code>, we can make some alterations to it. In the following example, we'll just add an element with some text:<div><pre class="programlisting">&lt;!doctype html&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;title&gt;Jasmine Spec Runner&lt;/title&gt;
  &lt;link rel="shortcut icon" type="image/png" href="&lt;%= temp %&gt;/jasmine_favicon.png"&gt;
  &lt;% css.forEach(function(style){ %&gt;
    &lt;link rel="stylesheet" type="text/css" href="&lt;%= style %&gt;"&gt;
  &lt;% }) %&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;% with (scripts) { %&gt;
    &lt;% [].concat(polyfills, jasmine, boot, vendor, helpers, src, specs,reporters).forEach(function(script){ %&gt;
    &lt;script src="img/&lt;%= script %&gt;"&gt;&lt;/script&gt;
    &lt;% }) %&gt;
  &lt;% }; %&gt;
  <strong>&lt;div id="test"&gt;Test&lt;/div&gt;</strong>
&lt;/body&gt;
&lt;/html&gt;</pre></div></li><li class="listitem">With the custom template ready, we'll make use of the <code class="literal">template</code> option to indicate that it should be used in the generation of the runner:<div><pre class="programlisting">jasmine: {
  src: 'main.js',
  options: {
    specs: 'tests.js',
    <strong>template: 'runner.tmpl'</strong>
  }
}</pre></div></li><li class="listitem">This will now make the <code class="literal">test</code> element available to us in our tests, allowing us to include <a id="id173" class="indexterm"/>tests similar to the following in our specifications:<div><pre class="programlisting">describe('Test element', function() {
  it('has test text', function () {
    expect(window.test.innerHTML).toBe("Test");
  });
});</pre></div></li></ol><div></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec53"/>Running QUnit tests</h1></div></div></div><p>In this recipe, we'll <a id="id174" class="indexterm"/>make use of the <code class="literal">contrib-qunit (0.5.2)</code> plugin to run our automated <strong>QUnit</strong> tests in a <strong>PhantomJS</strong> browser environment.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec123"/>Getting ready</h2></div></div></div><p>In this example, we'll work with the basic project structure we created in the <em>Installing Grunt on a project</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>. Be sure to refer to it if you are not yet familiar with its contents.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec124"/>How to do it...</h2></div></div></div><p>The following steps take us through creating a sample code base, a few tests to run against the code base, setting up a testing environment, and configuring Grunt to run them for us in a PhantomJS browser.</p><div><ol class="orderedlist arabic"><li class="listitem">We'll start by installing the package that contains the <code class="literal">contrib-qunit</code> plugin by following the instructions provided in the <em>Installing a plugin</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>.</li><li class="listitem">Then, we'll create a simple JavaScript source file in our project directory, which contains a function that we'd like to test. Let's call it <code class="literal">main.js</code> and provide it with the following contents:<div><pre class="programlisting">function square(x) {
  return x * x;
}</pre></div></li><li class="listitem">Now, we can write a simple set of tests, using the QUnit framework, for the <code class="literal">square</code> method. Let's create a file called <code class="literal">tests.js</code> in the project directory with the following contents:<div><pre class="programlisting">QUnit.test("Square method functionality", function(assert) {
  assert.equal(square(2), 4);
  assert.equal(square(3), 9);
  assert.equal(square(4), 16);
});</pre></div></li><li class="listitem">Due to the <a id="id175" class="indexterm"/>tests being run inside a browser and the <code class="literal">contrib-qunit</code> plugin not automatically including it, we'll have to download the QUnit library and style sheet into the project directory.<div><h3 class="title"><a id="tip44"/>Tip</h3><p>At the time of writing this, the QUnit library<a id="id176" class="indexterm"/> and its accompanying style sheet could be downloaded from the following links:</p><p><a class="ulink" href="http://code.jquery.com/qunit/qunit-1.15.0.js">http://code.jquery.com/qunit/qunit-1.15.0.js</a></p><p><a class="ulink" href="http://code.jquery.com/qunit/qunit-1.15.0.css">http://code.jquery.com/qunit/qunit-1.15.0.css</a></p></div></li><li class="listitem">To bring together all the parts we set up in the previous steps, we now need to create a testing environment that loads our code base, tests, and all the required libraries. Let's create the <code class="literal">test.html</code> file in our project directory with the following contents:<div><pre class="programlisting">&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset="utf-8"&gt;
    &lt;title&gt;QUnit basic example&lt;/title&gt;
    &lt;link rel="stylesheet" href="qunit-1.15.0.css"&gt;
    &lt;script src="img/qunit-1.15.0.js"&gt;&lt;/script&gt;
    &lt;script src="img/main.js"&gt;&lt;/script&gt;
    &lt;script src="img/tests.js"&gt;&lt;/script&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div id="qunit"&gt;&lt;/div&gt;
    &lt;div id="qunit-fixture"&gt;&lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre></div></li><li class="listitem">With the code base, tests, and testing environment now in place, we can add the following <code class="literal">qunit</code> task to our configuration:<div><pre class="programlisting">qunit: {
  main: {
    src: 'test.html'
  }
}</pre></div></li><li class="listitem">We can then run the task using the <code class="literal">grunt qunit</code> command, which should produce the following output informing us of the test results:<div><pre class="programlisting">
<strong>Running "qunit:main" (qunit) task</strong>
<strong>Testing test.html .OK</strong>
<strong>&gt;&gt; 3 assertions passed (18ms)</strong>
</pre></div></li></ol><div></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec125"/>There's more...</h2></div></div></div><p>The <code class="literal">qunit</code> task<a id="id177" class="indexterm"/> provides <a id="id178" class="indexterm"/>us with several useful options that can be used in conjunction with its basic test running feature. We'll look at loading tests from a web server, continuing execution after failed tests, suppressing the PhantomJS browser console output, and passing arguments to the PhantomJS instance.</p><div><div><div><div><h3 class="title"><a id="ch05lvl3sec60"/>Loading tests from a web server</h3></div></div></div><p>If we'd like <a id="id179" class="indexterm"/>to load our testing environment along with all its parts from a web server instead of straight from a file on the filesystem, we can make use of the <code class="literal">urls</code> option by providing it with the absolute URLs of the testing environments that we'd like to run.</p><p>The following example takes us through moving the required files to a directory they can be served from, setting up a basic web server that serves them, and altering our configuration to test the files from the web server.</p><div><ol class="orderedlist arabic"><li class="listitem">We'll start by installing the package that contains the <code class="literal">contrib-connect</code> plugin by following the instructions provided in the <em>Installing a plugin</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>.</li><li class="listitem">Then, we can create a directory called <code class="literal">www</code> in the project root and move the <code class="literal">main.js</code>, <code class="literal">qunit-1.15.0.css</code>, <code class="literal">qunit-1.15.0.js</code>, <code class="literal">test.html</code>, and <code class="literal">tests.js</code> files into it.</li><li class="listitem">Now, we can set up the basic web server that will serve the files from the <code class="literal">www</code> directory by adding the following <code class="literal">connect</code> task configuration:<div><pre class="programlisting">connect: {
  server: {
    options: {
      base: 'www'
    }
  }
}</pre></div></li><li class="listitem">With the server ready to serve the files required by our testing environment, we can alter the configuration of our <code class="literal">qunit</code> task to load it from the appropriate URL:<div><pre class="programlisting">qunit: {
  main: {
    options: {
      urls: ['http://localhost:8000/test.html']
    }
  }
}</pre></div></li><li class="listitem">To test <a id="id180" class="indexterm"/>our setup, we can run the <code class="literal">grunt connect qunit</code> command to start the web server and run the testing environment hosted on it. This should produce output similar to the following:<div><pre class="programlisting">
<strong>Running "connect:server" (connect) task</strong>
<strong>Started connect web server on http://0.0.0.0:8000</strong>

<strong>Running "qunit:main" (qunit) task</strong>
<strong>Testing http://localhost:8000/test.html .OK</strong>
<strong>&gt;&gt; 3 assertions passed (19ms)</strong>
</pre></div></li></ol><div></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec61"/>Continuing execution after failed tests</h3></div></div></div><p>The <a id="id181" class="indexterm"/>default behavior of the <code class="literal">qunit</code> task is to fail the entire task if a failure occurs in any one of the tests. This will in turn cause any of the tasks lined up for execution after the <code class="literal">qunit</code> task not to be executed. By setting the <code class="literal">force</code> option to <code class="literal">true</code>, as we do in the following example, we can indicate that the task itself should not fail due to test failures:</p><div><pre class="programlisting">qunit: {
  main: {
    src: 'test.html',
    options: {
      <strong>force: true</strong>
    }
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec62"/>Suppressing the PhantomJS browser console output</h3></div></div></div><p>The<a id="id182" class="indexterm"/> default behavior of the <code class="literal">qunit</code> task is to print the console output generated in the headless PhantomJS browser to the command line where the task runs. If we'd like to prevent the console output from being printed, we can set the <code class="literal">console</code> option to <code class="literal">false</code> as shown in the following example:</p><div><pre class="programlisting">qunit: {
  main: {
    src: 'test.html',
    options: {
      <strong>console: false</strong>
    }
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec63"/>Passing arguments to the PhantomJS instance</h3></div></div></div><p>In case<a id="id183" class="indexterm"/> we'd like to pass some options to the PhantomJS process when it starts, we can provide them along with the regular options just as they will be provided on the command line.</p><div><h3 class="title"><a id="tip45"/>Tip</h3><p>A list of arguments that the <a id="id184" class="indexterm"/>PhantomJS executable accepts can be found at the following URL:</p><p><a class="ulink" href="http://phantomjs.org/api/command-line.html">http://phantomjs.org/api/command-line.html</a></p></div><p>The following example disables the loading of images in the browser by setting the <code class="literal">load-images</code> option to <code class="literal">false</code>:</p><div><pre class="programlisting">qunit: {
  main: {
    src: 'test.html',
    options: {
      <strong>'--load-images': false</strong>
    }
  }
}</pre></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec54"/>Running NodeUnit tests</h1></div></div></div><p>In this <a id="id185" class="indexterm"/>recipe, we'll make use of the <code class="literal">contrib-nodeunit (0.4.1)</code> plugin to run our automated <strong>NodeUnit</strong> tests.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec126"/>Getting ready</h2></div></div></div><p>In this example, we'll work with the basic project structure we created in the <em>Installing Grunt on a project</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>. Be sure to refer to it if you are not yet familiar with its contents.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec127"/>How to do it...</h2></div></div></div><p>The following <a id="id186" class="indexterm"/>steps take us through creating a sample code base, creating a few tests to run against the code base, and configuring Grunt to run them for us.</p><div><ol class="orderedlist arabic"><li class="listitem">We'll start by installing the package that contains the <code class="literal">contrib-nodeunit</code> plugin by following per the instructions provided in the <em>Installing a plugin</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>.</li><li class="listitem">Then, we'll create a simple JavaScript source file in our project directory that contains and exports a function that we'd like to test. Let's call it <code class="literal">main.js</code> and add the following content to it:<div><pre class="programlisting">module.exports.square = function (x) {
  return x * x;
}</pre></div></li><li class="listitem">Now, we can write a simple set of tests, using the NodeUnit framework, to test the <code class="literal">square</code> method. We will also have to import the <code class="literal">square</code> method into our suite of tests, since the <code class="literal">nodeunit</code> task does not do this automatically. Let's create a file called <code class="literal">tests.js</code> in the project directory with the following contents:<div><pre class="programlisting">var square = require('./main').square;

module.exports.testSquare = {
  'Square method returns 4 for 2': function (test) {
    test.equal(square(2), 4);
    test.done();
  },
  'Square method returns 9 for 3': function (test) {
    test.equal(square(2), 4);
    test.done();
  },
  'Square method returns 16 for 4': function (test) {
    test.equal(square(2), 4);
    test.done();
  }
}</pre></div></li><li class="listitem">With our code base and tests created, we can now add the following <code class="literal">nodeunit</code> task to our configuration, which will run the tests contained in the <code class="literal">tests.js</code> file:<div><pre class="programlisting">nodeunit: {
  main: {
    src: 'tests.js'
  }
}</pre></div></li><li class="listitem">We can then run the task using the <code class="literal">grunt nodeunit</code> command, which will produce the following <a id="id187" class="indexterm"/>output informing us of the test results:<div><pre class="programlisting">
<strong>Running "nodeunit:main" (nodeunit) task</strong>
<strong>Testing tests.js...OK</strong>
<strong>&gt;&gt; 3 assertions passed (10ms)</strong>
</pre></div></li></ol><div></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec128"/>There's more...</h2></div></div></div><p>The <code class="literal">nodeunit</code> task<a id="id188" class="indexterm"/> provides us with several useful options that can be used in conjunction with its basic test-running feature. We'll look at how to use an alternative reporter and send reporter output to a file.</p><div><div><div><div><h3 class="title"><a id="ch05lvl3sec64"/>Using an alternative reporter</h3></div></div></div><p>In case<a id="id189" class="indexterm"/> we'd like to alter the way that the test results are displayed, we can make use of an alternative reporter by specifying one using the <code class="literal">reporter</code> option.</p><div><h3 class="title"><a id="tip46"/>Tip</h3><p>The default value of the <code class="literal">reporter</code> option is <code class="literal">grunt</code>, but it can be set to any one of the reporters listed in the<a id="id190" class="indexterm"/> <code class="literal">module.exports</code> object at the following URL:</p><p><a class="ulink" href="https://github.com/caolan/nodeunit/blob/master/lib/reporters/index.js">https://github.com/caolan/nodeunit/blob/master/lib/reporters/index.js</a></p></div><p>In the following example, we use the <code class="literal">reporter</code> option to indicate that we'd like the results of our tests to be reported in the HTML format:</p><div><pre class="programlisting">nodeunit: {
  main: {
    src: 'tests.js',
    options: {
      <strong>reporter: 'html'</strong>
    }
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec65"/>Sending reporter output to a file</h3></div></div></div><p>If we'd like<a id="id191" class="indexterm"/> the reported results of our tests to be stored in a file when the <code class="literal">nodeunit</code> task is run, we can indicate which file should receive it using the <code class="literal">reporterOutput</code> option, as shown in the following example:</p><div><pre class="programlisting">nodeunit: {
  main: {
    src: 'tests.js',
    options: {
      <strong>reporterOutput: 'result.txt'</strong>
    }
  }
}</pre></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec55"/>Running Mocha client-side tests</h1></div></div></div><p>In this recipe, we'll <a id="id192" class="indexterm"/>make use of the <code class="literal">mocha (0.4.11)</code> plugin to run our automated <strong>Mocha</strong> tests in a <strong>PhantomJS</strong> browser environment.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec129"/>Getting ready</h2></div></div></div><p>In this example, we'll work with the basic project structure we created in the <em>Installing Grunt on a project</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>. Be sure to refer to it if you are not yet familiar with its contents.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec130"/>How to do it...</h2></div></div></div><p>The following steps take us through creating a sample code base, creating a few tests to run against the code base, and configuring Grunt to run them for us in a PhantomJS browser environment.</p><div><ol class="orderedlist arabic"><li class="listitem">We'll start by installing the package that contains the <code class="literal">mocha</code> plugin by following the instructions provided in the <em>Installing a plugin</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>.</li><li class="listitem">Then, we'll create a simple JavaScript source file in our project directory that contains a function that we'd like to test. Let's call it <code class="literal">main.js</code> and provide it with the following contents:<div><pre class="programlisting">function square(x) {
  return x * x;
}</pre></div></li><li class="listitem">Now, we can write a simple suite of tests, using the Mocha and <strong>Expect.js</strong> frameworks, for the <code class="literal">square</code> method. Let's create a file called <code class="literal">tests.js</code> in the project directory with the following contents:<div><pre class="programlisting">describe('Square method', function() {
  it('returns 4 for 2', function () {
    expect(square(2)).to.be(4);
  });
  it('returns 9 for 3', function () {
    expect(square(3)).to.be(9);
  });
  it('returns 16 for 4', function () {
    expect(square(4)).to.be(16);
  });
});</pre></div></li><li class="listitem">Due to <a id="id193" class="indexterm"/>the tests being run inside a browser and the <code class="literal">mocha</code> plugin not automatically including it, we'll have to download the Mocha library and style sheet into the project directory.<div><h3 class="title"><a id="tip47"/>Tip</h3><p>At the time of writing this, the <a id="id194" class="indexterm"/>Mocha library and its accompanying style sheet could be downloaded from the following links:</p><p><a class="ulink" href="https://github.com/visionmedia/mocha/raw/master/mocha.js">https://github.com/visionmedia/mocha/raw/master/mocha.js</a></p><p><a class="ulink" href="https://github.com/visionmedia/mocha/raw/master/mocha.css">https://github.com/visionmedia/mocha/raw/master/mocha.css</a></p></div></li><li class="listitem">Seeing as the Mocha framework does not include the Expect.js assertion library by default, we also need to download it into our project directory.<div><h3 class="title"><a id="tip48"/>Tip</h3><p>At the time of writing this, the Expect.js library<a id="id195" class="indexterm"/> could be downloaded from the following link:</p><p><a class="ulink" href="https://github.com/LearnBoost/expect.js/raw/master/index.js">https://github.com/LearnBoost/expect.js/raw/master/index.js</a></p><p>Note that for our current example, we'll download the <code class="literal">index.js</code> file mentioned, and change its filename to <code class="literal">expect.js</code>.</p></div></li><li class="listitem">To bring together all the parts we set up, we now need to create a testing environment that loads our code base, tests, and all the required libraries. Let's create the <code class="literal">test.html</code> file in our project directory with the following contents:<div><pre class="programlisting">&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset="utf-8"&gt;
    &lt;title&gt;Mocha Tests&lt;/title&gt;
    &lt;link rel="stylesheet" href="mocha.css" /&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div id="mocha"&gt;&lt;/div&gt;
    &lt;script src="img/main.js"&gt;&lt;/script&gt;
    &lt;script src="img/expect.js"&gt;&lt;/script&gt;
    &lt;script src="img/mocha.js"&gt;&lt;/script&gt;
    &lt;script&gt;
      mocha.setup('bdd');
    &lt;/script&gt;
    &lt;script src="img/tests.js"&gt;&lt;/script&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre></div></li><li class="listitem">With our <a id="id196" class="indexterm"/>code base, tests, and testing environment ready, we can now add the following <code class="literal">mocha</code> task to our configuration:<div><pre class="programlisting">mocha: {
  main: {
    src: 'test.html',
    options: {
      run: true
    }  
  }
}</pre></div><div><h3 class="title"><a id="tip49"/>Tip</h3><p>The <code class="literal">mocha</code> task<a id="id197" class="indexterm"/> injects code into the PhantomJS browser in order to gather the results of the tests once they have finished running. The <code class="literal">mocha.run</code> method call required to start the execution of the tests contained in the environment needs to run after the injection of this code in order for the results to be captured. Setting the <code class="literal">run</code> option to <code class="literal">true</code> ensures that this method is called after the injection of the code is completed.</p></div></li><li class="listitem">We can then run the task using the <code class="literal">grunt mocha</code> command, which should produce the following output informing us of the test results:<div><pre class="programlisting">
<strong>Running "mocha:main" (mocha) task</strong>
<strong>Testing: test.html</strong>

<strong>  3 passing (105ms)</strong>
<strong>&gt;&gt; 3 passed! (0.10s)</strong>
</pre></div></li></ol><div></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec131"/>There's more...</h2></div></div></div><p>The <a id="id198" class="indexterm"/>
<code class="literal">mocha</code> task provides <a id="id199" class="indexterm"/>us with several useful options that can be used in conjunction with its basic test-running feature. We'll look at loading tests from a web server, sending reporter output to a file, displaying the PhantomJS browser's console output, displaying source errors, specifying options for the Mocha test runner, and using an alternative reporter.</p><div><div><div><div><h3 class="title"><a id="ch05lvl3sec66"/>Loading tests from a web server</h3></div></div></div><p>If we'd<a id="id200" class="indexterm"/> like to load our testing environment along with all its parts from a web server instead of straight from a file on the filesystem, we can make use of the <code class="literal">urls</code> option by passing the absolute URLs of the testing environments that we'd like to run.</p><p>The following example takes us through moving the required files to a directory they can be served from, setting up a basic web server that serves them, and altering our configuration to test the files from the web server.</p><div><ol class="orderedlist arabic"><li class="listitem">We'll start by installing the package that contains the <code class="literal">contrib-connect</code> plugin by following the instructions provided in the <em>Installing a plugin</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>.</li><li class="listitem">Then, we can create a directory called <code class="literal">www</code> in the project root and move the <code class="literal">expect.js</code>, <code class="literal">main.js</code>, <code class="literal">mocha.css</code>, <code class="literal">mocha.js</code>, <code class="literal">test.html</code>, and <code class="literal">tests.js</code> files into it.</li><li class="listitem">Now, we can set up the basic web server, which will serve the files from the <code class="literal">www</code> directory by adding the following <code class="literal">connect</code> task configuration:<div><pre class="programlisting">connect: {
  server: {
    options: {
      base: 'www'
    }
  }
}</pre></div></li><li class="listitem">With the server ready to serve the files for the testing environment, we can now alter the configuration of our <code class="literal">mocha</code> task to load it from the appropriate URL:<div><pre class="programlisting">mocha: {
  main: {
    options: {
      run: true,
      urls: ['http://localhost:8000/test.html']
    }  
  }
}</pre></div></li><li class="listitem">To test <a id="id201" class="indexterm"/>our setup, we can run the <code class="literal">grunt connect qunit</code> command to start the web server and run the testing environment hosted on it. This should produce output similar to the following:<div><pre class="programlisting">
<strong>Running "connect:server" (connect) task</strong>
<strong>Started connect web server on http://0.0.0.0:8000</strong>

<strong>Running "mocha:main" (mocha) task</strong>
<strong>Testing: http://localhost:8000/test.html</strong>

<strong>  3 passing (110ms)</strong>
<strong>&gt;&gt; 3 passed! (0.11s)</strong>
</pre></div></li></ol><div></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec67"/>Sending reporter output to a file</h3></div></div></div><p>If we'd like <a id="id202" class="indexterm"/>the reported results of our tests to be stored in a file when the <code class="literal">mocha</code> task is run, we can indicate which file should receive it using the <code class="literal">dest</code> option as shown in the following example:</p><div><pre class="programlisting">mocha: {
  main: {
    src: 'test.html',
    <strong>dest: 'result.txt',</strong>
    options: {
      run: true
    }
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec68"/>Displaying the PhantomJS browser's console output</h3></div></div></div><p>By default, the <a id="id203" class="indexterm"/>output from the Phantom JS browser's console will not be displayed in the command-line output when the <code class="literal">mocha</code> task runs. If we'd like to display the output, we can set the <code class="literal">log</code> option to <code class="literal">true</code> as <a id="id204" class="indexterm"/>shown in the following example:</p><div><pre class="programlisting">mocha: {
  main: {
    src: 'test.html',
    options: {
      run: true,
      <strong>log: true</strong>
    }  
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec69"/>Displaying source errors</h3></div></div></div><p>The <a id="id205" class="indexterm"/>default behavior for the <code class="literal">mocha</code> task is to ignore syntax errors encountered in the source files that the tests will run against. If an error is encountered, the source will simply not load, and probably cause all the tests to fail without a useful error message.</p><p>If we'd like to be informed of the errors encountered in the source, we can set the <code class="literal">logErrors</code> option to <code class="literal">true</code> as shown in the following example:</p><div><pre class="programlisting">mocha: {
  main: {
    src: 'test.html',
    options: {
      run: true,
      <strong>logErrors: true</strong>
    }  
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec70"/>Specifying options for the Mocha test runner</h3></div></div></div><p>In case<a id="id206" class="indexterm"/> we'd like to specify some options directly to the Mocha test runner that runs behind the scenes of the <code class="literal">mocha</code> task, we can provide them using the <code class="literal">mocha</code> option. The following example uses the <code class="literal">grep</code> option to indicate that only tests that contain the string <code class="literal">'2'</code> in their description should be run:</p><div><pre class="programlisting">mocha: {
  main: {
    src: 'test.html',
    options: {
      run: true,
      <strong>mocha: {</strong>
<strong>        grep: '2'</strong>
<strong>      }</strong>
    }  
  }
}</pre></div><div><h3 class="title"><a id="tip50"/>Tip</h3><p>A list of the available options along with their explanations can be found at the following URL:</p><p><a class="ulink" href="http://mochajs.org/#usage">http://mochajs.org/#usage</a></p></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec71"/>Using an alternative reporter</h3></div></div></div><p>In the case<a id="id207" class="indexterm"/> that we'd like to alter the way that the test results are displayed, we can make use of an alternative reporter by specifying one using the <code class="literal">reporter</code> option.</p><div><h3 class="title"><a id="tip51"/>Tip</h3><p>The default value of the <a id="id208" class="indexterm"/>
<code class="literal">reporter</code> option is <code class="literal">dot</code> but it can be set to any one of the reporters listed at the following URL:</p><p><a class="ulink" href="http://mochajs.org/#reporters">http://mochajs.org/#reporters</a></p><p>Note that the names of the various reporters as they are listed at the mentioned URL will, for the most part, have to be capitalized when indicating them with the <code class="literal">reporter</code> option.</p></div><p>In the following example, we use the <code class="literal">reporter</code> option to indicate that we'd like the results of our tests to be reported in the JSON format:</p><div><pre class="programlisting">mocha: {
  main: {
    src: 'test.html',
    options: {
      run: true,
      <strong>reporter: 'JSON'</strong>
    }  
  }
}</pre></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec56"/>Running Mocha server-side tests</h1></div></div></div><p>In this recipe, we'll <a id="id209" class="indexterm"/>make use of the <code class="literal">mocha-test (0.11.0)</code> plugin to run our automated <strong>Mocha</strong> tests.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec132"/>Getting ready</h2></div></div></div><p>In this example, we'll work with the basic project structure we created in the <em>Installing Grunt on a project</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>. Be sure to refer to it if you are not yet familiar with its contents.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec133"/>How to do it...</h2></div></div></div><p>The following steps take us through creating a sample code base, creating a few tests to run against the code base, and configuring Grunt to run them for us.</p><div><ol class="orderedlist arabic"><li class="listitem">We'll start by installing the package that contains the <code class="literal">mocha-test</code> plugin by following the instructions provided in the <em>Installing a plugin</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>.</li><li class="listitem">Then, we can create a JavaScript source file in our project directory that contains and exports a function that we'd like to have tested. Let's call it <code class="literal">main.js</code> and add the following content to it:<div><pre class="programlisting">module.exports.square = function (x) {
  return x * x;
}</pre></div></li><li class="listitem">Now, we can write a simple set of tests, using the Mocha framework, to test the <code class="literal">square</code> method. We would also have to import the <code class="literal">square</code> method and the <code class="literal">assert</code> library into our suite of tests, since the <code class="literal">mochaTest</code> task does not do this automatically. Let's create a file called <code class="literal">tests.js</code> in the project directory with the following contents:<div><pre class="programlisting">var assert = require('assert');
var square = require('./main').square;

describe('Square method', function() {
  it('returns 4 for 2', function () {
    assert.equal(square(2), 4);
  });
  it('returns 9 for 3', function () {
    assert.equal(square(3), 9);
  });
  it('returns 16 for 4', function () {
    assert.equal(square(4), 16);
  });
});</pre></div></li><li class="listitem">With our code base and tests created, we can now add the following <code class="literal">mochaTest</code> task to our configuration, which will run the tests contained in the <code class="literal">tests.js</code> file:<div><pre class="programlisting">mochaTest: {
  main: {
    src: 'tests.js'
  }
}</pre></div></li><li class="listitem">We can <a id="id210" class="indexterm"/>then run the task using the <code class="literal">grunt mochaTest</code> command, which should produce output informing us of the test results, similar to the following:<div><pre class="programlisting">
<strong>Running "mochaTest:main" (mochaTest) task</strong>

<strong>  3 passing (6ms)</strong>
</pre></div></li></ol><div></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec134"/>There's more...</h2></div></div></div><p>The <code class="literal">mochaTest</code> task<a id="id211" class="indexterm"/> provides us with several useful options that can be used in conjunction with its basic test running feature. We'll look at how to use an alternative reporter, select tests using a regular expression, check for global variable leaks, send reporter output to a file, and load extra modules into the testing environment.</p><div><div><div><div><h3 class="title"><a id="ch05lvl3sec72"/>Using an alternative reporter</h3></div></div></div><p>In the case <a id="id212" class="indexterm"/>that we'd like to alter the way that the test results are displayed, we can make use of an alternative reporter by specifying one using the <code class="literal">reporter</code> option.</p><div><h3 class="title"><a id="tip52"/>Tip</h3><p>The default value of the <code class="literal">reporter</code> option is <code class="literal">dot</code> but it can be set to any one of the reporters listed at the following URL:</p><p><a class="ulink" href="http://mochajs.org/#reporters">http://mochajs.org/#reporters</a></p><p>Note that the names of the various reporters as they are listed at the mentioned URL should all be written in lowercase when referring to them with this plugin.</p></div><p>In the following example, we use the <code class="literal">reporter</code> option to indicate that we'd like the results of our tests to be reported in the JSON format:</p><div><pre class="programlisting">mochaTest: {
  main: {
    src: 'tests.js',
    options: {
      <strong>reporter: 'json'</strong>
    }
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec73"/>Selecting tests using a regular expression</h3></div></div></div><p>Quite often, we'd<a id="id213" class="indexterm"/> like to test only a subset of the tests available in our testing suite. We can target specific tests by providing a <strong>regular expression</strong><a id="id214" class="indexterm"/> to the <code class="literal">grep</code> option, which will be matched against the description of the tests in our suite.</p><p>In the following example, we indicate that we only want to run tests that have a description that contains the <code class="literal">'2'</code> string:</p><div><pre class="programlisting">mochaTest: {
  main: {
    src: 'tests.js',
    options: {
      <strong>grep: '2'</strong>
    }
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec74"/>Checking for global variable leaks</h3></div></div></div><p>It's generally<a id="id215" class="indexterm"/> considered bad practice to make use of global variables in JavaScript, as collisions can easily occur between variable names used by various libraries, or implied by the JavaScript environment.</p><p>If we'd like to receive warnings whenever global variables are encountered in either the source or test code, we can set the <code class="literal">ignoreLeaks</code> option to <code class="literal">false</code>. In addition to that, we can also make use of the <code class="literal">globals</code> option to indicate the variable names that should be ignored when defined as <code class="literal">globals</code>.</p><p>The following example turns global leak detection on, and also indicates that the <code class="literal">allowedGlobal</code> variable name should be ignored if it is defined globally.</p><div><pre class="programlisting">mochaTest: {
  main: {
    src: 'tests.js',
    options: {
      <strong>ignoreLeaks: false,</strong>
<strong>      globals: ['allowedGlobal']</strong>
    }
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec75"/>Sending reporter output to a file</h3></div></div></div><p>If we'd like<a id="id216" class="indexterm"/> the reported results of our tests to be stored in a file when the <code class="literal">mochaTest</code> task is run, we can indicate which file should receive it using the <code class="literal">captureFile</code> option as shown in the following example:</p><div><pre class="programlisting">mochaTest: {
  main: {
    src: 'tests.js',
    options: {
      <strong>captureFile: 'result.txt'</strong>
    }
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec76"/>Loading extra modules into the testing environment</h3></div></div></div><p>The <code class="literal">require</code> option<a id="id217" class="indexterm"/> can be used to load modules into our testing environment before the tests are run. This allows us to make use of libraries without having to import them into each of our test suites.</p><p>In the following example, we load the <code class="literal">should.js</code> module so that we can make use of the <strong>Should.js</strong> library<a id="id218" class="indexterm"/> in our tests:</p><div><pre class="programlisting">mochaTest: {
  main: {
    src: 'tests.js',
    options: {
      <strong>require: ['should']</strong>
    }
  }
}</pre></div><div><h3 class="title"><a id="tip53"/>Tip</h3><p>Note that for this example to work, the <code class="literal">should</code> package needs to be installed either locally or globally.</p></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec57"/>Generating coverage reports for server-side code using Mocha and Blanket</h1></div></div></div><p>In this recipe, we'll <a id="id219" class="indexterm"/>make use of the <code class="literal">blanket (0.0.8)</code>, <code class="literal">mocha-test (0.11.0)</code>, and <code class="literal">contrib-copy (0.5.0)</code> plugins to run our automated <strong>Mocha</strong> tests, while at the same time, generating <strong>coverage reports</strong> for the source code they run against.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec135"/>Getting ready</h2></div></div></div><p>In this example, we'll work with the basic project structure we created in the <em>Installing Grunt on a project</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>. Be sure to refer to it if you are not yet familiar with its contents.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec136"/>How to do it...</h2></div></div></div><p>The following steps take us through creating a sample code base, creating a few tests to run against the code base, and configuring Grunt to generate coverage reports while running the tests.</p><div><ol class="orderedlist arabic"><li class="listitem">We'll start by installing the packages that contain the <code class="literal">blanket</code>, <code class="literal">mocha-test</code>, and <code class="literal">contrib-copy</code> plugins by following the instructions provided in the <em>Installing a plugin</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>.</li><li class="listitem">Then, we can create a JavaScript source file that contains and exports two functions, only one of which we'll be testing. Let's create the file <code class="literal">src/main.js</code> in our project directory with the following contents:<div><pre class="programlisting">module.exports = {
  square: function (x) {
    return x * x;
  },
  cube: function (x) {
    return x * x * x;
  }
}</pre></div></li><li class="listitem">Now, we can write a simple set of tests, using the Mocha framework, to test the <code class="literal">square</code> method. We will also have to import the <code class="literal">square</code> method and the <code class="literal">assert</code> library into our suite of tests, since the <code class="literal">mochaTest</code> task does not do this automatically. Let's create the file <code class="literal">tests/main.js</code> in the project directory with the following contents:<div><pre class="programlisting">var assert = require('assert');
var square = require('../src/main').square;

describe('Square method', function() {
  it('returns 4 for 2', function () {
    assert.equal(square(2), 4);
  });
  it('returns 9 for 3', function () {
    assert.equal(square(3), 9);
  });
  it('returns 16 for 4', function () {
    assert.equal(square(4), 16);
  });
});</pre></div></li><li class="listitem">With <a id="id220" class="indexterm"/>our code base now in place, we can set up its <strong>instrumentation</strong><a id="id221" class="indexterm"/> by adding the following <code class="literal">blanket</code> task to our configuration:<div><pre class="programlisting">blanket: {
  main: {
    src: 'src/',
    dest: 'coverage/src/'
  }
}</pre></div></li><li class="listitem">In order for our tests to make use of the instrumented version of our code base, we should now also add the following <code class="literal">copy</code> task to our configuration, which will copy the tests to a position where it can access the instrumented code base, just as it would have accessed the regular code base:<div><pre class="programlisting">
<strong>copy: {</strong>
<strong>  tests: {</strong>
<strong>    src: 'tests/main.js',</strong>
<strong>    dest: 'coverage/tests/main.js'</strong>
<strong>  }</strong>
<strong>}</strong>
</pre></div></li><li class="listitem">To tie it all together, we add the following <code class="literal">mochaTest</code> task to our configuration, which will run the tests in the position where they have access to the instrumented code base, indicating that it should report the results in the <code class="literal">html-cov</code> format, and finally save it into the <code class="literal">result.html</code> file:<div><pre class="programlisting">mochaTest: {
  main: {
    options: {
      quiet: true,
      reporter: 'html-cov',
      captureFile: 'result.html'
    },
    src: 'coverage/tests/main.js'
  }
}</pre></div></li><li class="listitem">We can <a id="id222" class="indexterm"/>now test our setup by running the <code class="literal">grunt blanket copy mochaTest</code> command, which should produce a file called <code class="literal">result.html</code> in our project directory that looks like this:<div><img src="img/image00273.jpeg" alt="How to do it..."/></div><p style="clear:both; height: 1em;"> </p></li></ol><div></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec137"/>There's more...</h2></div></div></div><p>The combination of the plugins discussed in this recipe can result in a myriad of configurations, so we'll just focus on the most common requirement of reporting results in the <strong>LCOV</strong> format.</p><div><div><div><div><h3 class="title"><a id="ch05lvl3sec77"/>Outputting coverage results in the LCOV format</h3></div></div></div><p>The LCOV format <a id="id223" class="indexterm"/>for code <a id="id224" class="indexterm"/>coverage results is quite popular among services that consume them for reporting and analysis purposes.</p><div><h3 class="title"><a id="tip54"/>Tip</h3><p>The <a id="id225" class="indexterm"/>
<strong>Coveralls</strong> service is a good example of a service to which you can send your produced LCOV results to keep track of its history and provide a more graphical representation of them.</p><p>For more <a id="id226" class="indexterm"/>information refer to <a class="ulink" href="http://coveralls.io/">http://coveralls.io/</a>.</p></div><p>The following steps take us through installing a LCOV reporter for Mocha and altering our configuration to make use of it.</p><div><ol class="orderedlist arabic"><li class="listitem">We'll start by installing the package that contains the <code class="literal">mocha-lcov-reporter</code> plugin by following the instructions provided in the <em>Installing a plugin</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>.</li><li class="listitem">Now, we can alter the configuration of our <code class="literal">mochaTest</code> task to output the results using the newly installed reporter:<div><pre class="programlisting">mochaTest: {
  main: {
    options: {
      quiet: true,
      <strong>reporter: 'mocha-lcov-reporter',</strong>
<strong>      captureFile: 'result.lcov'</strong>
    },
    src: 'coverage/tests/main.js'
  }
}</pre></div></li><li class="listitem">We can now test our setup by running the <code class="literal">grunt blanket copy mochaTest</code> command. This should produce a file called <code class="literal">result.lcov</code> in our project directory, which is ready to be provided to one of the many available services.</li></ol><div></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec58"/>Generating coverage reports for client-side code using Mocha and Blanket</h1></div></div></div><p>In this recipe, we'll <a id="id227" class="indexterm"/>make use of the <code class="literal">blanket-mocha (0.4.1)</code> plugin to run our automated <strong>Mocha</strong> tests in a <strong>PhantomJS</strong> environment, generating <strong>coverage reports</strong> for the source code they run<a id="id228" class="indexterm"/> against using the <a id="id229" class="indexterm"/>
<strong>Blanket.js</strong> library, and comparing the results against a specified threshold.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec138"/>Getting ready</h2></div></div></div><p>In this example, we'll work with the basic project structure we created in the <em>Installing Grunt on a project</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>. Be sure to refer to it if you are not yet familiar with its contents.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec139"/>How to do it...</h2></div></div></div><p>The following steps take us through creating a sample code base, creating some tests to run against it, and configuring Grunt to generate coverage reports and compare the results against a threshold.</p><div><ol class="orderedlist arabic"><li class="listitem">We'll start by installing the package that contains the <code class="literal">blanket-mocha</code> plugin by following the instructions provided in the <em>Installing a plugin</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>.</li><li class="listitem">Then, we'll create a simple JavaScript source file in our project directory, which contains two functions, one of which we'll be testing. Let's call it <code class="literal">main.js</code> and add the following content to it:<div><pre class="programlisting">function square(x) {
  return x * x;
}
function cube(x) {
  return x * x * x;
}</pre></div></li><li class="listitem">Now, we can write a simple suite of tests, using the Mocha and Expect.js frameworks, for the <code class="literal">square</code> method. Let's create a file called <code class="literal">tests.js</code> in the project directory with the following contents:<div><pre class="programlisting">describe('Square method', function() {
  it('returns 4 for 2', function () {
    expect(square(2)).to.be(4);
  });
  it('returns 9 for 3', function () {
    expect(square(3)).to.be(9);
  });
  it('returns 16 for 4', function () {
    expect(square(4)).to.be(16);
  });
});</pre></div></li><li class="listitem">Due to the tests being run inside a browser and the <code class="literal">blanket_mocha</code> plugin not <a id="id230" class="indexterm"/>automatically including it, we'll have to download the Mocha library and style sheet into the project directory.<div><h3 class="title"><a id="tip55"/>Tip</h3><p>At the time of writing this, the Mocha library and its accompanying style sheet could be downloaded from the following links:</p><p><a class="ulink" href="https://github.com/visionmedia/mocha/raw/master/mocha.js">https://github.com/visionmedia/mocha/raw/master/mocha.js</a></p><p><a class="ulink" href="https://github.com/visionmedia/mocha/raw/master/mocha.css">https://github.com/visionmedia/mocha/raw/master/mocha.css</a></p></div></li><li class="listitem">Seeing as the Mocha framework does not include the Expect.js assertion library by default, we also need to download it into our project directory.<div><h3 class="title"><a id="tip56"/>Tip</h3><p>At the time of writing this, the Expect.js library could be downloaded from the following link:</p><p><a class="ulink" href="https://github.com/LearnBoost/expect.js/raw/master/index.js">https://github.com/LearnBoost/expect.js/raw/master/index.js</a></p><p>Note that for our current example, we'll download the <code class="literal">index.js</code> file mentioned, and change its filename to <code class="literal">expect.js</code>.</p></div></li><li class="listitem">We'll also have to manually include the Blanket.js client-side library in our testing setup, which means that we'll have to download it into our project directory.<div><h3 class="title"><a id="tip57"/>Tip</h3><p>At the time of writing this, the Blanket.js client-side library could be downloaded from the following link:</p><p><a class="ulink" href="https://github.com/alex-seville/blanket/raw/master/dist/qunit/blanket.js">https://github.com/alex-seville/blanket/raw/master/dist/qunit/blanket.js</a></p></div></li><li class="listitem">In order to tie the Mocha and Blanket.js libraries together, we'll also have to include an adapter, which should also be downloaded into our project directory.<div><h3 class="title"><a id="tip58"/>Tip</h3><p>At the time of writing this, the  Mocha-to-Blanket.js adapter could be downloaded from the following link:</p><p><a class="ulink" href="https://github.com/ModelN/grunt-blanket-mocha/raw/master/support/mocha-blanket.js">https://github.com/ModelN/grunt-blanket-mocha/raw/master/support/mocha-blanket.js</a></p></div></li><li class="listitem">Due to the fact that the <code class="literal">blanket_mocha</code> task requires the Blanket.js results to be fed back into Grunt, we need to download the appropriate reporter into our project directory.<div><h3 class="title"><a id="tip59"/>Tip</h3><p>At the time of writing this, the appropriate Blanket.js reporter could be downloaded from the following link:</p><p><a class="ulink" href="https://github.com/ModelN/grunt-blanket-mocha/raw/master/support/grunt-reporter.js">https://github.com/ModelN/grunt-blanket-mocha/raw/master/support/grunt-reporter.js</a></p></div></li><li class="listitem">To bring <a id="id231" class="indexterm"/>together all the parts we set up, we now need to create a testing environment that loads our code base, tests, and all the required libraries. Let's create the <code class="literal">test.html</code> file in our project directory with the following contents:<div><pre class="programlisting">&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset="utf-8"&gt;
    &lt;title&gt;Mocha Tests&lt;/title&gt;
    &lt;link rel="stylesheet" href="mocha.css" /&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div id="mocha"&gt;&lt;/div&gt;
    &lt;script src="img/expect.js"&gt;&lt;/script&gt;
    &lt;script src="img/mocha.js"&gt;&lt;/script&gt;
    &lt;script src="img/main.js" data-cover&gt;&lt;/script&gt;
    &lt;script src="img/blanket.js"&gt;&lt;/script&gt;
    &lt;script src="img/mocha-blanket.js"&gt;&lt;/script&gt;
    &lt;script&gt;
      mocha.setup('bdd');
      if (window.PHANTOMJS) {
        blanket.options('reporter', 'grunt-reporter.js');
      }
    &lt;/script&gt;
    &lt;script src="img/tests.js"&gt;&lt;/script&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre></div><div><h3 class="title"><a id="tip60"/>Tip</h3><p>Note that the <code class="literal">data-cover</code> attribute provided in the <code class="literal">script</code> tag imports the <code class="literal">main.js</code> code base. This attribute should be included in every script tag that imports a file for which coverage reports should be generated.</p></div></li><li class="listitem">With our code base, tests, and testing environment ready, we can now add the following <code class="literal">blanket_mocha</code> task to our configuration:<div><pre class="programlisting">blanket_mocha: {
  main: {
    src: ['test.html'],
    options: {
      threshold: 70
    }
  }
}</pre></div><div><h3 class="title"><a id="tip61"/>Tip</h3><p>We make use of the <code class="literal">threshold</code> option here to indicate the minimum code coverage percentage that should be achieved for each file. If the final percentage is lower than this threshold, the task will return with a failure.</p></div></li><li class="listitem">We <a id="id232" class="indexterm"/>can then run the task using the <code class="literal">grunt blanket_mocha</code> command, which will produce output informing us of the test and coverage results, similar to the following:<div><pre class="programlisting">
<strong>Running "blanket_mocha:main" (blanket_mocha) task</strong>
<strong>Testing: test.html</strong>

<strong>  3 passing (3ms)</strong>

<strong>Per-File Coverage Results: (70% minimum)</strong>
<strong>PASS : 1 files passed coverage</strong>

<strong>Unit Test Results: 3 specs passed! (0.00s)</strong>
<strong>&gt;&gt; No issues found.</strong>
</pre></div></li></ol><div></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec140"/>There's more...</h2></div></div></div><p>The <code class="literal">blanket-mocha</code> task<a id="id233" class="indexterm"/> provides us with several useful options that can be used in conjunction with its basic test running and coverage reporting features. We'll look at specifying a success threshold for the global average, specifying success thresholds for particular files, and specifying success thresholds for particular modules.</p><div><div><div><div><h3 class="title"><a id="ch05lvl3sec78"/>Specifying a success threshold for the global average</h3></div></div></div><p>If we'd like <a id="id234" class="indexterm"/>to set a threshold that the average coverage percentage among all the files in the targeted source code should surpass, we can do so using the <code class="literal">globalThreshold</code> option as shown in the following example:</p><div><pre class="programlisting">blanket_mocha: {
  main: {
    src: ['test.html'],
    options: {
      threshold: 70,
      <strong>globalThreshold: 70</strong>
    }
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec79"/>Specifying success thresholds for particular files</h3></div></div></div><p>There's<a id="id235" class="indexterm"/> also the option of specifying the thresholds that particular files should adhere to using the <code class="literal">customThreshold</code> option as shown in the following example:</p><div><pre class="programlisting">blanket_mocha: {
  main: {
    src: ['test.html'],
    options: {
      threshold: 70,
      <strong>customThreshold: {</strong>
<strong>        'main.js': 70</strong>
<strong>      }</strong>
    }
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec80"/>Specifying success thresholds for particular modules</h3></div></div></div><p>In case <a id="id236" class="indexterm"/>we'd like to specify a threshold for the average coverage percentage that modules should adhere to, we can make use of the <code class="literal">modulePattern,</code> <code class="literal">moduleThreshold</code>, and <code class="literal">customModuleThreshold</code> options.</p><p>The <code class="literal">modulePattern</code> option takes a <strong>regular expression</strong> of<a id="id237" class="indexterm"/> which the first grouping will be used to determine the names of modules. The <code class="literal">moduleThreshold</code> option is used to indicate the average threshold that all identified modules should adhere to and the <code class="literal">customModuleThreshold</code> option can be used to specify the threshold of each particular module.</p><p>The following<a id="id238" class="indexterm"/> example identifies modules by the first directory name after the <code class="literal">src</code> directory in the filename checks whether the average code coverage percentage of all the modules is above <code class="literal">70</code> and that the code coverage percentage of the <code class="literal">one</code> module is above <code class="literal">60</code>:</p><div><pre class="programlisting">blanket_mocha: {
  main: {
    src: ['test.html'],
    options: {
      threshold: 70,
      <strong>modulePattern: './src/(.*?)/',</strong>
<strong>      moduleThreshold: 70,</strong>
<strong>      customModuleThreshold: {</strong>
<strong>        one: 60</strong>
<strong>      }</strong>
    }
  }
}</pre></div></div></div></div>
<div><div><div><div><h1 class="title"><a id="ch05lvl1sec59"/>Generating coverage reports for client-side code using QUnit and Istanbul</h1></div></div></div><p>In this <a id="id239" class="indexterm"/>recipe, we'll make use of the <code class="literal">qunit-istanbul (0.4.5)</code> plugin to run our automated <strong>QUnit</strong> tests<a id="id240" class="indexterm"/> in a <strong>PhantomJS</strong> environment, generating <strong>coverage reports</strong> for the source code they run against using the <a id="id241" class="indexterm"/>
<strong>Istanbul</strong> library, and comparing the results against a specified threshold.</p><div><div><div><div><h2 class="title"><a id="ch05lvl2sec141"/>Getting ready</h2></div></div></div><p>In this example, we'll work with the basic project structure we created in the <em>Installing Grunt on a project</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>. Be sure to refer to it if you are not yet familiar with its contents.</p></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec142"/>How to do it...</h2></div></div></div><p>The following steps take us through creating a sample code base, creating a few tests to run against it, and <a id="id242" class="indexterm"/>configuring Grunt to generate coverage reports and compare the results to a threshold.</p><div><ol class="orderedlist arabic"><li class="listitem">We'll start by installing the package that contains the <code class="literal">qunit-istanbul</code> plugin by following the instructions provided in the <em>Installing a plugin</em> recipe in <a class="link" title="Chapter 1. Getting Started with Grunt" href="part0015.xhtml#aid-E9OE1">Chapter 1</a>, <em>Getting Started with Grunt</em>.</li><li class="listitem">Then, we'll create a simple JavaScript source file in our project directory that contains two functions, one of which we'll be testing. Let's call it <code class="literal">main.js</code> and provide it with the following contents:<div><pre class="programlisting">function square(x) {
  return x * x;
}
function cube(x) {
  return x * x * x;
}</pre></div></li><li class="listitem">Now, we can write a simple set of tests, using the QUnit framework, for the <code class="literal">square</code> method. Let's create a file called <code class="literal">tests.js</code> in the project directory with the following contents:<div><pre class="programlisting">QUnit.test("Square method functionality", function(assert) {
  assert.equal(square(2), 4);
  assert.equal(square(3), 9);
  assert.equal(square(4), 16);
});</pre></div></li><li class="listitem">Due to the tests being run inside a browser and the <code class="literal">qunit-istanbul</code> plugin not automatically including it, we'll have to download the QUnit library and style sheet into the project directory.<div><h3 class="title"><a id="tip62"/>Tip</h3><p>At the time of writing this, the<a id="id243" class="indexterm"/> QUnit library and its accompanying style sheet can be found at the following links:</p><p><a class="ulink" href="http://code.jquery.com/qunit/qunit-1.15.0.js">http://code.jquery.com/qunit/qunit-1.15.0.js</a></p><p><a class="ulink" href="http://code.jquery.com/qunit/qunit-1.15.0.css">http://code.jquery.com/qunit/qunit-1.15.0.css</a></p></div></li><li class="listitem">To bring together all the parts we set up in the previous steps, we now need to create a testing environment that loads our code base, tests, and all the required libraries. Let's create the <code class="literal">test.html</code> file in our project directory with the following contents:<div><pre class="programlisting">&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset="utf-8"&gt;
    &lt;title&gt;QUnit basic example&lt;/title&gt;
    &lt;link rel="stylesheet" href="qunit-1.15.0.css"&gt;
    &lt;script src="img/qunit-1.15.0.js"&gt;&lt;/script&gt;
    &lt;script src="img/main.js"&gt;&lt;/script&gt;
    &lt;script src="img/tests.js"&gt;&lt;/script&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div id="qunit"&gt;&lt;/div&gt;
    &lt;div id="qunit-fixture"&gt;&lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre></div></li><li class="listitem">With the <a id="id244" class="indexterm"/>code base, tests, and testing environment now in place, we can add the following <code class="literal">qunit</code> task to our configuration:<div><pre class="programlisting">qunit: {
  main: {
    options: {
      coverage: {
        src: 'main.js',
        instrumentedFiles: 'temp/'
      }
    },
    src: 'test.html'
  }
}</pre></div><div><h3 class="title"><a id="tip63"/>Tip</h3><p>Note that all the options provided by the <code class="literal">qunit</code> task can be used in the <code class="literal">options</code> object of the <code class="literal">istanbul</code> task. Only the options contained in the <code class="literal">coverage</code> part of the <code class="literal">options</code> object are used to indicate the behavior unique to this plugin.</p><p>The <code class="literal">src</code> option is used to indicate the source files that we'd like to cover in our coverage report. This option can also be set to an array to indicate more files and can also make use of the standard Grunt globbing patterns.</p><p>The <code class="literal">instrumentedFiles</code> option is used to indicate the temporary directory that will contain the instrumented files during the time that the tests are run. Note that this directory is automatically created and destroyed.</p></div></li><li class="listitem">We can then run the task using the <code class="literal">grunt qunit</code> command, which should produce output informing us of the test and coverage results, similar to the following:<div><pre class="programlisting">
<strong>Running "qunit:main" (qunit) task</strong>
<strong>Testing test.html .OK</strong>
<strong>&gt;&gt; 3 assertions passed (20ms)</strong>
<strong>&gt;&gt; Coverage:</strong>
<strong>&gt;&gt; -  Lines: 75%</strong>
<strong>&gt;&gt; -  Statements: 75%</strong>
<strong>&gt;&gt; -  Functions: 50%</strong>
<strong>&gt;&gt; -  Branches: 100%</strong>
</pre></div></li></ol><div></div></div><div><div><div><div><h2 class="title"><a id="ch05lvl2sec143"/>There's more...</h2></div></div></div><p>The <a id="id245" class="indexterm"/>
<code class="literal">qunit-istanbul</code> task <a id="id246" class="indexterm"/>provides us with several useful options that can be used in conjunction with its basic test running and coverage reporting features. We'll look at how to specify a report output destination and coverage thresholds at various levels.</p><div><div><div><div><h3 class="title"><a id="ch05lvl3sec81"/>Specifying a report output destination</h3></div></div></div><p>If we'd like<a id="id247" class="indexterm"/> to save the coverage report results to files, we can do so by providing a directory name to any of the highlighted options in the following example, each of which saves the results in the particular format mentioned in its name:</p><div><pre class="programlisting">qunit: {
  main: {
    options: {
      coverage: {
        src: 'main.js',
        instrumentedFiles: 'temp/',
        <strong>htmlReport: 'html/',</strong>
<strong>        coberturaReport: 'corb/',</strong>
<strong>        lcovReport: 'lcov/',</strong>
<strong>        cloverReport: 'clover/'</strong>
      }
    },
    src: 'test.html'
  }
}</pre></div></div><div><div><div><div><h3 class="title"><a id="ch05lvl3sec82"/>Specifying coverage thresholds at various levels</h3></div></div></div><p>In <a id="id248" class="indexterm"/>case we'd like to specify the code coverage percentage thresholds at either the line, statement, function, or branch level, we can do so by using any of the appropriately named options highlighted in the following example:</p><div><pre class="programlisting">qunit: {
  main: {
    options: {
      coverage: {
        src: 'main.js',
        instrumentedFiles: 'temp/',
        <strong>linesThresholdPct: 50,</strong>
<strong>        statementsThresholdPct: 60,</strong>
<strong>        functionsThresholdPct: 70,</strong>
<strong>        branchesThresholdPct: 80</strong>
      }
    },
    src: 'test.html'
  }
}</pre></div></div></div></div></body></html>