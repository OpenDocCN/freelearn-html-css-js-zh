<html><head></head><body><div class="chapter" title="Chapter&#xA0;8.&#xA0;Internal Design and Performance"><div class="titlepage"><div><div><h1 class="title"><a id="ch08"/>Chapter 8. Internal Design and Performance</h1></div></div></div><p>The final chapter of this book looks at the internal design of key Lo-Dash components. All previous chapters focused on the external-facing aspects of the library. Now that we're well-versed in what's possible with Lo-Dash, it's time to see what's under the hood. This isn't an in-depth walkthrough of the Lo-Dash source code. The curious reader should by all means look at the code though. We will touch the most important pieces of the implementation of Lo-Dash. These are what make Lo-Dash perform not only fast but also predictably.</p><p>With these designs in mind, we'll spend the remaining sections of this chapter looking at some Lo-Dash code that could be improved. Understanding some of the design motivations will hopefully guide you in making your design decisions.</p><p>In this chapter, we will cover the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Design principles</li><li class="listitem" style="list-style-type: disc">Improving performance</li><li class="listitem" style="list-style-type: disc">Lazy evaluation</li><li class="listitem" style="list-style-type: disc">Caching things</li></ul></div><div class="section" title="Design principles"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec55"/>Design principles</h1></div></div></div><p>Lo-Dash had<a id="id537" class="indexterm"/> some fairly modest goals in the beginning. Underscore appealed to the masses because of the problems it solved and because its API was coherent and easy to use. Lo-Dash's creator, John-David Dalton, wanted to prove that it was possible to implement a great API, such as Underscore's, while delivering consistency and performance across browsers. Additionally, Lo-Dash has the freedom to implement new features that aren't welcomed by Underscore.</p><p>In order to prove his point, John-David had to establish some guiding design principles. Some of the founding principles are still around today, while others have morphed into something<a id="id538" class="indexterm"/> else to better support programmers who use the library and contribute to it. Lo-Dash is nothing if not adaptable to change.</p><div class="section" title="Function compilation to base functions"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec112"/>Function compilation to base functions</h2></div></div></div><p>The<a id="id539" class="indexterm"/> earlier versions <a id="id540" class="indexterm"/>of Lo-Dash utilized a technique called <span class="strong"><strong>function compilation</strong></span>. This means that there were templates of a skeleton function. Then Lo-Dash would fill them and create function instances on the fly. These were then exposed through the API. The nice thing about this approach is that it is easy to implement a ton of variability for one function without the need to implement several versions of that function. Being able to implement generic functions like this while keeping the code size small meant that Lo-Dash was able to tackle all sorts of different use cases, from both a performance perspective and a bug-fixing/consistency perspective. However, this approach was holding Lo-Dash back in two ways.</p><p>The first issue with function compilation is the readability of the code—something so dynamic isn't all that approachable by developers. This aspect of open source goes out the window—you don't get folks reviewing code by scaring them off. The second issue is that JavaScript engines are continually improving their ability to optimize JavaScript code as it runs. This is also known as <span class="strong"><strong>just-in-time</strong></span> (<span class="strong"><strong>JIT</strong></span>) optimization. So between now and the time <a id="id541" class="indexterm"/>that Lo-Dash was first conceived, browser vendors have come a long way. In such a short time, these improvements weren't being fully utilized by Lo-Dash and its approach of function compilation.</p><p>In recent versions of Lo-Dash (2.4 and 3.0 in particular), the function compilation approach <a id="id542" class="indexterm"/>has been replaced with <span class="strong"><strong>base functions</strong></span>. In other words, base functions are generic components, used by several publicly-facing functions. The earlier versions of the library shied away from abstractions due to the fear that unnecessary indirection would mean performance penalty. While it's true that abstractions do incur an overhead cost, it turns out that helping the browser perform JIT optimizations outweighs this cost.</p><p>This doesn't mean that Lo-Dash has abandoned all caution of abstraction overhead. The implementation is quite clever and readable, which solves earlier issues of comprehending the source. A given base function is probably used in several places, which reduces repetitive code. What's more important is the way the base functions are structured. A given function that's exposed through the API will do some initial work to make sense of the arguments that were passed. Essentially, this is the preparation so that more exact arguments can be passed to the base function. This results in better predictability for the JavaScript engine. The cost of calling a base function is often negated, especially when the same call is made frequently—the engine will often inline the function to where it's called.</p><p>So what's the implication here for Lo-Dash programmers? Nothing really. The way these internal base functions are structured and used should not impact your code at all. This, however, should<a id="id543" class="indexterm"/> give <a id="id544" class="indexterm"/>some insight into how Lo-Dash is able to evolve quickly, based on developer feedback and changing JavaScript technologies.</p></div><div class="section" title="Optimizing for the common case"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec113"/>Optimizing for the common case</h2></div></div></div><p>This principle, <span class="strong"><strong>optimize for the common case</strong></span>, has been with Lo-Dash from day one. Sure, subtle<a id="id545" class="indexterm"/> implementation details have evolved, but the underlying idea remains intact and this <a id="id546" class="indexterm"/>will likely always be the case. Think of this as the golden rule in Lo-Dash (the unofficial rule). Just as the Linux kernel development has a golden rule, called <span class="emphasis"><em>don't break user space</em></span>, think of <span class="emphasis"><em>optimize for the common case</em></span> as something to always strive for.</p><p>Take the base function approach that's now used in favor of function compilation. We can choose which base function to call based on the arguments the user has supplied. For example, a function that accepts a collection could use a base function that works only with arrays. It's optimized for arrays. So, when the function that accepts a collection is called, it checks whether it's dealing with an array or not. If it is, it'll use the faster base function. Here's an illustration of the pattern using pseudo-JavaScript:</p><div class="informalexample"><pre class="programlisting">function apiCollectionFunction(collection) {
    if (_.isArray(collection)) {
        return baseArray(collection);
    } else {
        return baseGeneric(collection)
    }
}</pre></div><p>The common path is the first path that's tested. The <code class="literal">baseArray()</code> function that is executed is <a id="id547" class="indexterm"/>generic enough and used frequently enough to get special treatment from the JIT. The strategy is to assume that the common case is passing an array. The assumption isn't arbitrary either; it's benchmarked against typical use cases during development. The worst case is when we're dealing with a string or when a plain object isn't slow, necessarily, it's just not optimized. So these slower calls, as infrequent as they are, will be offset by the optimized calls that happen all the time.</p><p>The common case can even be tiered. That is, your function is thrown one of several cases when called, and all of those possibilities have an order to their frequency. For example, if the most common case isn't met, what's the next most common case? And so on. The effect of this technique pushes the uncommon code down towards the bottom of the function. On its own, this doesn't have a huge impact on performance, but when every function in the library consistently follows the same common case optimization techniques, the impact is huge.</p></div><div class="section" title="Loops are simple"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec114"/>Loops are simple</h2></div></div></div><p>Lo-Dash uses<a id="id548" class="indexterm"/> a lot of loops in its code. That's because<a id="id549" class="indexterm"/> there's a lot of iterating over collections. It's also because Lo-Dash does not use certain native functions that would otherwise negate the need for a loop. This is the opposite of the stance Underscore.js takes on this matter. It prefers the native methods whenever they're available. The logic being the JavaScript library shouldn't have to worry about iteration performance. Instead, the browser vendor should improve the native method performance.</p><p>This approach makes sense, especially when the side effect is writing less code. However, Lo-Dash doesn't rely on the browser vendor to deliver performance. We can get better performance out of simple <code class="literal">while</code> loops and this will likely continue in the foreseeable future. Native methods are undoubtedly faster than unoptimized JavaScript code, but they aren't able to perform the same kind of optimizations as we're able to when using pure JavaScript.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note51"/>Note</h3><p>Lo-Dash is<a id="id550" class="indexterm"/> a strategic animal. It doesn't like to rely on certain native JavaScript methods, but it relies heavily on the JIT abilities of any given JavaScript engine for performance, cost balancing in action.</p></div></div><p>Lo-Dash also doesn't like to rely on <code class="literal">for</code> loops—<code class="literal">while</code> loops are preferred. The <code class="literal">for</code> loop is useful when used to iterate over collections, thus enhancing code readability. Under these simple circumstances, trying to use a <code class="literal">while</code> loop is just cumbersome. Even though the <code class="literal">while</code> loop does have a slight performance edge over the <code class="literal">for</code> loop, it's not really all that noticeable. The performance difference is noticeable in the case of several large collections that are frequently iterated over. This is the common case that Lo-Dash accounts for. Consider the following code:</p><div class="informalexample"><pre class="programlisting">var collection = _.range(10000000),
    length = collection.length,
    i = 0;

console.time('for');
for (; i &lt; length; i++) {
    collection[i];
}
console.timeEnd('for');

i = 0;

console.time('while');
while (++i &lt; length) {
    collection[i];
}
console.timeEnd('while');
// →
// for: 13.459ms
// while: 10.670ms</pre></div><p>The<a id="id551" class="indexterm"/> difference between the two loops is hardly<a id="id552" class="indexterm"/> perceptible. Probably a couple of years ago, the lead the <code class="literal">while</code> loop had over <code class="literal">for</code> may have been wider, which is one reason Lo-Dash is still using <code class="literal">while</code> loops everywhere. Another reason is consistency. Since the <code class="literal">while</code> loop is nearly identical wherever it's implemented in Lo-Dash, you can expect its performance to be predictable throughout. This is especially true given that there's not a mixture of <code class="literal">while</code> loops, <code class="literal">for</code> loops, and native JavaScript methods. Sometimes, predictable performance is better than <span class="emphasis"><em>sometimes it's faster, but I can never be sure</em></span>.</p></div><div class="section" title="Callbacks and function binding"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec115"/>Callbacks and function binding</h2></div></div></div><p>Callbacks <a id="id553" class="indexterm"/>are used everywhere in Lo-Dash, both internally <a id="id554" class="indexterm"/>and as arguments of API functions. So it's important that these<a id="id555" class="indexterm"/> functions get executed with as little <a id="id556" class="indexterm"/>overhead as possible. The big culprit that slows down these function calls is the <code class="literal">this</code> context, that is, the context that the function is bound to. If there's no context to consider, then there's clearly less overhead involved, especially considering that these callback functions typically get called once per iteration if the function is operating on a collection.</p><p>If there's a specific context for the callback function, then we have to use <code class="literal">call()</code> to call the function, since it allows us to set the context. Or if there are an unknown number of arguments, we<a id="id557" class="indexterm"/> use the <code class="literal">apply()</code> function, passing the context and the arguments as an array. This is especially slow if executed iteratively. To help combat these performance hurdles, Lo-Dash uses a base function to help construct callback functions.</p><p>This function is used anywhere where there's a callback function passed as an argument. The first step is to use this function to build a potentially wrapped callback function. This initial examination is worth the cost because of the potential savings when it has to be called iteratively. Here's a rough idea of how this function works:</p><div class="informalexample"><pre class="programlisting">function baseCallback(func, thisArg, argCount) {
    if (!thisArg) {
        return func;
    }

    if (alreadyBound(func)) {
        return func;
    }

    if (argCount == 1) {
        return function(collection) {
            return func.call(thisArg, collection);
        }
    }

    return function() {
        return func.apply(thisArg, arguments);
    }
}</pre></div><p>This is a<a id="id558" class="indexterm"/> gross simplification of what <code class="literal">baseCallback()</code> is <a id="id559" class="indexterm"/>really doing, but the general pattern is accurate. The most<a id="id560" class="indexterm"/> common cases that build a callback<a id="id561" class="indexterm"/> function are checked first. The uncommon, slower cases are pushed to the bottom. For example, if there's no <code class="literal">thisArg</code>, we don't have to bind the function; it can just be returned. The next case that is checked is whether or not the function has already been bound. If it has been, then the <code class="literal">thisArg</code> value is ignored and the function is returned. If neither of these checks passes and the <code class="literal">argCount</code> argument is supplied, we can use <code class="literal">call()</code>, supplying the exact number of arguments. The preceding pseudocode shows the case of only a single argument, but in reality, it checks for several exact argument counts.</p><p>The uncommon case is when <code class="literal">thisArg</code> is supplied, meaning we have to bind the function and we don't know how many arguments are there. So, we use <code class="literal">apply()</code>, the slowest scenario. Other cases <code class="literal">baseCallback()</code> is able to handle include a string or a plain object being passed as <code class="literal">func</code> instead of a function instance. For such cases, there are specific callback functions that get returned and this is also checked for early on since it's a common case.</p><p>The <code class="literal">alreadyBound()</code> function<a id="id562" class="indexterm"/> is something made up for brevity. Lo-Dash knows whether a function is already bound or not by looking at the metadata for that function. In this context, metadata refers to data that's attached to the function by Lo-Dash, but is completely transparent to the developer. For example, many callbacks will track data about the frequency with which they are called. If the function becomes <span class="emphasis"><em>hot</em></span>, Lo-Dash will treat it differently than callbacks that aren't executed frequently.</p></div></div></div>
<div class="section" title="Improving performance"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec56"/>Improving performance</h1></div></div></div><p>Just <a id="id563" class="indexterm"/>because Lo-Dash is designed from the ground up for optimal performance, it doesn't mean there are no basic modifications we can make to our Lo-Dash code to improve performance. In fact, we can sometimes borrow some Lo-Dash design principles and apply them directly to our code that utilizes Lo-Dash.</p><div class="section" title="Changing the operation order"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec116"/>Changing the operation order</h2></div></div></div><p>Using a<a id="id564" class="indexterm"/> Lo-Dash wrapper around a value, such<a id="id565" class="indexterm"/> as an array, lets us chain together many operations on that value. As we saw in <a class="link" href="ch06.html" title="Chapter 6. Application Building Blocks">Chapter 6</a>, <span class="emphasis"><em>Application Building Blocks</em></span>, a wrapper has many advantages over stitching together, piecemeal, several statements that call Lo-Dash functions. For example, the end result is often more concise and readable code. The different orders in which we call these operations in a chain can yield the same result and yet have different performance implications. Let's look at three different approaches to filtering a collection that get us the same result:</p><div class="informalexample"><pre class="programlisting">var collection = _.map(_.range(100), function(item) {
    return {
        id: item,
        enabled: !!_.random()
    };
});

var cnt = 1000;

console.time('first');
while (--cnt) {
    _(collection)
        .filter('enabled')
        .filter(function(item) {
            return item.id &gt; 75;
        })
        .value();
}
console.timeEnd('first');

cnt = 1000;

console.time('second');
while (--cnt) {
    _(collection)
        .filter(function(item) {
            return item.id &gt; 75;
        })
        .filter('enabled')
        .value();
}
console.timeEnd('second');

cnt = 1000;

console.time('third');
while (--cnt) {
    _(collection)
        .filter(function(item) {
            return item.enabled &amp;&amp; item.id &gt; 75;
        })
        .value();
}
console.timeEnd('third');
// → 
// first: 13.368ms
// second: 6.263ms
// third: 3.198ms</pre></div><p>The <code class="literal">collection</code> array is quite straightforward. It contains <code class="literal">100</code> items and each item is an object<a id="id566" class="indexterm"/> with two properties. The first is a numerical ID. The <a id="id567" class="indexterm"/>second is a random Boolean value. The goal is to filter out anything that's not <code class="literal">enabled</code> and anything with an <code class="literal">id</code> value that is less than <code class="literal">75</code>.</p><p>The first approach builds a chain consisting of two <code class="literal">filter()</code> calls. The first <code class="literal">filter()</code> call removes any disabled items. The second approach removes anything with an <code class="literal">id</code> property whose value is less than <code class="literal">75</code>. However, the ordering of these filtering operations isn't optimal. You might have noticed that there are a large number of items removed based on their <code class="literal">id</code> value. This is due to the nature of the filter and the dataset we're dealing with.</p><p>Any calls made to <code class="literal">filter()</code> mean that a linear iteration takes place over the collection. With the first approach, there are two calls made to <code class="literal">filter()</code>, which means that we'll have to iterate linearly over the collection twice. Given what we now know about the collection data and what the filter is looking for, we can optimize the ordering of the filter calls. This is a simple change. We first filter by <code class="literal">id</code> and then by the <code class="literal">enabled</code> property. The result is a noticeable boost in performance because the second call to <code class="literal">filter()</code> has to iterate over far fewer items.</p><p>The third approach takes things a step further and removes an iteration completely. Since both filter conditions are checked in the <code class="literal">filter()</code> callback function, there's no need to iterate over any collection item twice.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note52"/>Note</h3><p>Of course, the trade-off here is more complexity in the given callback function. Keep this in mind if your application does lots of filtering, because you'll want to avoid defining highly specialized callback functions that serve a single purpose. It's generally a better idea to keep your functions small and generic. The second approach strikes a good balance. These types of optimizations don't often <a id="id568" class="indexterm"/>happen upfront, so wait until the <a id="id569" class="indexterm"/>common case reveals itself before trying to optimize for it.</p></div></div></div><div class="section" title="Sorting and indexing collections"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec117"/>Sorting and indexing collections</h2></div></div></div><p>If the <a id="id570" class="indexterm"/>order of the collection is an important factor in the <a id="id571" class="indexterm"/>application you're developing, you can<a id="id572" class="indexterm"/> introduce tweaks that take advantage of its importance. These <a id="id573" class="indexterm"/>tweaks include maintaining the sort order. There's really no point in re-sorting collections every time you need to render it. Rather, it's better to sort the collection once and then maintain its order by inserting new items in the correct place. Lo-Dash has the <code class="literal">sortedIndex()</code> function, which helps find the <a id="id574" class="indexterm"/>proper insertion point for new items. In fact, it performs a binary search and is much faster than a linear search through the collection.</p><p>For faster filtering operations, we can borrow the <code class="literal">sortedIndex()</code> function. If we have a sorted collection, there's really no need to filter items using a linear search, which performs rather poorly in the worst case. Let's introduce a new <code class="literal">mixin</code> function that performs the same job as the <code class="literal">filter()</code> function but is optimized for sorted collections:</p><div class="informalexample"><pre class="programlisting">_.mixin({ sortedFilter: function(collection, value, iteratee) {
    iteratee = _.callback(iteratee);
    var index = _.sortedIndex(collection, value, iteratee),
        result = [],
        item;
    while (true) {
        item = collection[index++];
        if (_.isEqual(iteratee(item), iteratee(value))) {
            result.push(item);
        } else {
            break;
        }
    }
    return result;
}});

var collection = _.map(_.range(100), function(item) {
    return {
        id: item,
        age: _.random(50)
    };
});

var shuffled = _.shuffle(collection),
    sorted = _.sortBy(shuffled, 'age');

console.time('shuffled');
console.log(_.filter(shuffled, { age: 25 }));
console.timeEnd('shuffled');
// → 
// [
//   { id: 63, age: 25 },
//   { id: 6, age: 25 },
//   { id: 89, age: 25 }
// ]
// shuffled: 4.936ms

console.time('sorted');
console.log(_.sortedFilter(sorted, { age: 25 }, 'age'));
console.timeEnd('sorted');
// → 
// [
//   { id: 63, age: 25 },
//   { id: 6, age: 25 },
//   { id: 89, age: 25 }
// ]
// sorted: 0.831ms</pre></div><p>The new <a id="id575" class="indexterm"/>function we've introduced—<code class="literal">sortedFilter()</code>—is faster than the <code class="literal">filter()</code> function. Again, this is because we don't have to rely on<a id="id576" class="indexterm"/> a linear search, since the collection<a id="id577" class="indexterm"/> is sorted. Instead, the <code class="literal">sortedIndex()</code> function is used to find<a id="id578" class="indexterm"/> what we're looking for. It uses a binary search, which means that with larger collections, there are a large number of items that aren't checked. The end result is fewer CPU cycles and faster execution time.</p><p>Our <code class="literal">sortedFilter()</code> implementation, thanks largely to <code class="literal">sortedIndex()</code>, isn't all that complicated. The binary search gets us the insertion point to insert the new item, but we're not actually inserting anything. We're just looking for it. There could be several items that match our criteria, or there could be none. This is where we iterate over the collection, using the insertion index as a starting point. We now have to explicitly check the values using <code class="literal">isEqual()</code> and build the result array. Since the collection is sorted, we know to stop and return when items stop matching the filter criteria.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note53"/>Note</h3><p>Always take care to validate your code for correctness when improving Lo-Dash functions for performance purposes. The easiest way to do this is to set up a number of automated tests that compare the output of the Lo-Dash function with that of your faster variant. This allows you to throw all kinds of edge cases at your code before you get too excited about your newly found speed. Lo-Dash takes care of a lot of edge cases, so make sure you don't sidestep safety in favor of performance.</p></div></div><p>Another<a id="id579" class="indexterm"/> technique in speeding up filtering operations<a id="id580" class="indexterm"/> on collections is to index them. This <a id="id581" class="indexterm"/>means creating a new data structure that uses keys to look for<a id="id582" class="indexterm"/> common items in the collection. This is another way to avoid the costly linear search in large collections. Here's an example that uses <code class="literal">groupBy()</code> to index a collection for a fast search of items using common filtering criteria:</p><div class="informalexample"><pre class="programlisting">var collection = _.map(_.range(100), function(item) {
    return {
        id: item,
        age: _.random(50),
        enabled: !!_.random()
    };
});

var indexed = _.groupBy(collection, function(item) {
    return +item.enabled * item.age;
});

console.time('where');
console.log(_.where(collection, { age: 25, enabled: true }));
console.timeEnd('where');
// → 
// [
//   { id: 23, age: 25, enabled: true },
//   { id: 89, age: 25, enabled: true }
// ]
// where: 5.528ms

console.time('indexed');
console.log(indexed[25] || []);
console.timeEnd('indexed');
// → 
// [
//   { id: 23, age: 25, enabled: true },
//   { id: 89, age: 25, enabled: true }
// ]
// indexed: 0.712ms</pre></div><p>The indexed approach takes much less time than the <code class="literal">where()</code> approach to look for the same items. This approach is useful when there are several instances of the same filter throughout your application. The <code class="literal">indexed</code> variable holds the indexed version of the collection. The<a id="id583" class="indexterm"/> index is created using the <code class="literal">groupBy()</code> function. It takes an array as the input and produces an object. The index keys are the object keys, and the callback passed to <code class="literal">groupBy()</code> is responsible for generating these keys. The function returns the key value, and if the key already exists, the item is added to that key.</p><p>The idea <a id="id584" class="indexterm"/>is that we want items indexed by their <code class="literal">age</code> property<a id="id585" class="indexterm"/> value, and by whether or not they're <code class="literal">enabled</code>. We <a id="id586" class="indexterm"/>use a neat little trick here to do that. The <code class="literal">enabled</code> property is<a id="id587" class="indexterm"/> converted to a positive integer and multiplied by the <code class="literal">age</code> value. So any disabled items will be indexed under <code class="literal">0</code>, where nobody looks. Now you can see that looking for the items in the <code class="literal">indexed</code> object yields the same results as the <code class="literal">where()</code> filter. With the latter approach, we're doing a simple object access operation rather than iterating over a collection and performing several operations.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note54"/>Note</h3><p>While the speedups here are quite impressive, be sure to consider the update frequency for items in this collection. If you think about it, the indexed version is really just a cache of common filter results. So if the collection is never updated, you're good to go assuming you're okay with the one-time payment of actually indexing the collection.</p></div></div></div><div class="section" title="Bound and unbound callbacks"><div class="titlepage"><div><div><h2 class="title"><a id="ch08lvl2sec118"/>Bound and unbound callbacks</h2></div></div></div><p>Lo-Dash <a id="id588" class="indexterm"/>embraces callback functions and does a really good <a id="id589" class="indexterm"/>job of optimizing the way they're called. For example, it <a id="id590" class="indexterm"/>avoids using <code class="literal">call()</code> and <code class="literal">apply()</code> when there's no <code class="literal">this</code> context necessary, and this is for a good reason—these calls are a lot slower than<a id="id591" class="indexterm"/> unbound function calls. So when we're writing our application that utilizes Lo-Dash callback functions, we have the option to provide context to each of these callbacks as they're applied to collections. Take the time to weigh the trade-offs before coding functions in this way.</p><p>Binding our functions to a context is convenient when we want to use the same function in a different context. This isn't always necessary and it depends largely on the overall design of our code. If we have tons of objects that our callbacks need to access, the <code class="literal">this</code> context is pretty convenient. We might even have a single application object that is used to access other objects, and so on. If that's the case, we'll definitely need a way to pass this object to our callback functions. This could mean binding the <code class="literal">this</code> context, accessing the object through function closure, or creating a partial function for our callback.</p><p>None of these options are particularly performance friendly. Therefore, if we find that our callbacks are in constant need of access to some object, it might make sense to define it in a callback<a id="id592" class="indexterm"/> function, instead <a id="id593" class="indexterm"/>of <a id="id594" class="indexterm"/>defining it as a variable. The<a id="id595" class="indexterm"/> following code illustrates this idea:</p><div class="informalexample"><pre class="programlisting">function callback(item) {
    return _.extend({
        version: this.version
    }, item);
}

function unbound(item) {
    return _.extend({
        version: 2.0
    }, item);
}

var cnt = 1000,
    app = { version: 2.0 },
    boundCallback = _.callback(callback, app),
    collection = _.map(_.range(1000), function(item) {
        return { id: item };
    });

console.time('bound');
while (--cnt) {
    _.map(collection, boundCallback);
}
console.timeEnd('bound');

cnt = 1000;

console.time('unbound');
while (--cnt) {
    _.map(collection, unbound);
}
console.timeEnd('unbound');
// → 
// bound: 662.418ms
// unbound: 594.799ms</pre></div><p>We can see that the unbound callback function will generally outperform the bound callback function. What's important to note here is the approach. The <code class="literal">bound()</code> function is bound to<a id="id596" class="indexterm"/> a specific context with the call to <code class="literal">map()</code>. This is because it needs something from the application object. The <code class="literal">unbound()</code> function, instead of relying <a id="id597" class="indexterm"/>on some external instance, will declare the variable itself. So we will get what we need for the callback without the need to bind to a specific callback function.</p><p>At first, this may seem like a counterintuitive approach to defining application-level variables<a id="id598" class="indexterm"/> inside a callback function. Well, it boils down to the<a id="id599" class="indexterm"/> rest of your code. Do you have a lot of callback functions<a id="id600" class="indexterm"/> that require access to this data? If you put this callback<a id="id601" class="indexterm"/> function in an easy-to-locate place in your source tree, then it's really not all that different from modifying a variable.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note55"/>Note</h3><p>Switching from bound to unbound functions doesn't yield a huge performance gain when there are just a handful of callback functions. Even if there are lots of functions, it's fine to have several bound functions without impacting performance. The idea of this section is to keep you on the lookout for functions that are <span class="emphasis"><em>needlessly</em></span> bound to a context. Fix them where you can if they don't have a noticeable impact on your design.</p></div></div></div></div>
<div class="section" title="Lazy evaluation"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec57"/>Lazy evaluation</h1></div></div></div><p>With the <a id="id602" class="indexterm"/>introduction of Lo-Dash 3.0, some functions use a <span class="strong"><strong>lazy evaluation</strong></span> to compute their results. This simply means that the items in a given collection aren't iterated over until they're actually needed. It's figuring out when they're needed that is the tricky part. For example, just calling a single Lo-Dash function doesn't invoke any lazy evaluation mechanism. However, operations that are chained together could certainly benefit from this approach, in certain circumstances. For example, when we're only taking 10 items from the result, there's no need to iterate over the entire collection further up the chain.</p><p>To get an idea of what a lazy evaluation looks like, let's write some code to utilize it. There's nothing explicit to be done. The lazy mechanism happens transparently, behind the scenes, depending on which operations make up our chain and what order they're called in:</p><div class="informalexample"><pre class="programlisting">var collection = _.range(10);

_(collection)
    .reject(function(item) {
        console.log('checking ' + item);
        return item % 2;
    })
    .map(function(item) {
        console.log('mapping ' + item);
        return item * item;
     })
    .value();
// → 
// checking 1
// checking 2
// mapping 2
// checking 3</pre></div><p>Here, our <a id="id603" class="indexterm"/>chain is composed of two functions—<code class="literal">reject()</code> and <code class="literal">map()</code>. Since <code class="literal">reject()</code> is called first, Lo-Dash makes it a lazy wrapper. This means that when <code class="literal">value()</code> is called, things are done a bit differently. Rather than running each function to completion, the lazy functions in the chain are asked for a value. For example, <code class="literal">reject()</code> doesn't run until <code class="literal">map()</code> asks it for a value. When it does, <code class="literal">reject()</code> will run till it produces a value. We can actually see this behavior in the output. The <code class="literal">reject()</code> function<a id="id604" class="indexterm"/> is checking item <code class="literal">1</code>, which gets rejected. It then moves on to item <code class="literal">2</code>, which passes the test. This is then passed to <code class="literal">map()</code>. Then item <code class="literal">3</code> is checked, and so on.</p><p>The two function calls are interleaved and this property can extend upward through many functions in a more complicated chain. The advantage is that if these functions are too expensive to run through an entire collection, they generally don't have to. They'll execute only when asked to execute. Let's see this concept in action:</p><div class="informalexample"><pre class="programlisting">var collection = _.range(1000000).reverse();

console.time('motivated');
_.take(_.filter(collection, function(item) {
    return !(item % 10);
}), 10);
console.timeEnd('motivated');

console.time('lazy');
_(collection)
    .filter(function(item) {
        return !(item % 10);
    })
    .take(100)
    .value();
console.timeEnd('lazy');
// → 
// motivated: 8.454ms
// lazy: 0.889ms</pre></div><p>You can see that the lazy approach takes much less time than the motivated approach, even though it is taking <code class="literal">100</code> results and the latter is taking only <code class="literal">10</code>. The reason is simple—the collection is large and the entire thing is filtered using the motivated approach. The lazy approach uses far fewer iterations.</p></div>
<div class="section" title="Caching things"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec58"/>Caching things</h1></div></div></div><p>The best <a id="id605" class="indexterm"/>way to improve the performance of an operation is to not perform it—at least not twice, or worse, hundreds or thousands of times. Repeating costly computations is an unnecessary waste of CPU cycles and can be avoided by caching the <a id="id606" class="indexterm"/>results. The <code class="literal">memoize()</code> function helps us here, by caching the results of the called function for later use. However, caching has its own overheads and pitfalls to be aware of. Let's start by taking a look at idempotent functions—these always produce the same output when given the same input arguments:</p><div class="informalexample"><pre class="programlisting">function primeFactors(number) {
    var factors = [],
        divisor = 2;

    while (number &gt; 1) {
        while (number % divisor === 0) {
            factors.push(divisor);
            number /= divisor;
         }
        divisor += 1;
        if (divisor * divisor &gt; number) {
            if (number &gt; 1) {
                factors.push(number);
            }
            break;
        }
    }
    return factors;
}

var collection = _.map(_.range(10000), function() {
        return _.random(1000000, 1000010);
    }),
    primes = _.memoize(primeFactors);

console.time('primes');
_.each(collection, function(item) {
    primeFactors(item);
});
console.timeEnd('primes');

console.time('cached');
_.each(collection, function(item) {
    primes(item);
});
console.timeEnd('cached');
// → 
// primes: 17.564ms
// cached: 4.930ms</pre></div><p>The <code class="literal">primeFactors()</code> function returns an array of prime factors of the given number. It has to do a fair amount of work to compute the returned array. There is nothing that hogs the CPU for <a id="id607" class="indexterm"/>any substantial amount of time, but nonetheless, it's work—work that <a id="id608" class="indexterm"/>yields the same result for a given input. Idempotent functions such as these are good candidates for memoization. This is easy to do with the <code class="literal">memoize()</code> function and we use this function to generate the <code class="literal">primes()</code> function. Also note that the cache key is the first argument, which is nice and easy here because it's the only input we're interested in caching.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note56"/>Note</h3><p>It's important to take into consideration the amount of overhead involved with looking up cached items. It's not a lot, but it's there. Often, this overhead outweighs the value of caching the results in the first place. The preceding code is a case of testing with a relatively large collection. As that collection size shrinks, so does the performance gain.</p></div></div><p>While it's nice to cache the results of idempotent functions because you never have to worry about invalidating that cache, let's look at a more common use case:</p><div class="informalexample"><pre class="programlisting">function mapAges(collection) {
    return _.map(collection, 'age');
}

var collection = _.map(_.range(100), function(item) {
        return {
            id: item,
            age: _.random(50)
        };
    }),
    ages = _.memoize(mapAges, function(collection) {
        if (_.has(collection, 'mapAges')) {
            return collection.mapAges;
        } else {
            collection.mapAges = _.uniqueId();
        }
    }),
    cnt = 1000;

console.time('mapAges');
while (--cnt) {
    _.reduce(mapAges(collection), function(result, item) {
        return result + item;
    }) / collection.length;
}
console.timeEnd('mapAges');

cnt = 1000;

console.time('ages');
while (--cnt) {
    _.reduce(ages(collection), function(result, item) {
        return result + item;
    }) / collection.length;
}
console.timeEnd('ages');
// → 
// mapAges: 6.878ms
// ages: 3.535ms</pre></div><p>Here we're<a id="id609" class="indexterm"/> caching the result of mapping a collection to a different representation. In other words, we're mapping the <code class="literal">age</code> property. This mapping operation can be costly if it's repeated throughout the application. So we use the <code class="literal">memoize()</code> function to cache the result of mapping the age values, resulting in the <code class="literal">ages()</code> function. However, there's still the issue of looking up the cached collection—we need a key resolution function. The one we've provided is quite simple. It assigns a unique identifier to the <code class="literal">mapAges</code> property of the collection. The next time <code class="literal">ages()</code> is called, this identifier is found and the cached copy is looked up.</p><p>We can see that not having to map the collection again and again saves CPU cycles. And this is a simple mapping; other mappings with callback functions can be costlier and much more elaborate than simply plucking a value.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note57"/>Note</h3><p>Of course, this code assumes that this collection is constant and never changes. If you're building a large application with lots of moving parts, static collections like these are actually quite common. If the collection, or items in the collection for that matter, change frequently throughout its lifetime, you have to start thinking about invalidating the cache. It's probably not worth caching maps or other transformations for temperamental collections because, apart from naming things, cache invalidation is the toughest of all problems in programming.</p></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch08lvl1sec59"/>Summary</h1></div></div></div><p>In this chapter, we introduced some of the influences that guide the design and implementation of Lo-Dash. Earlier versions of the library opted for function compilation, building the functions on the fly to best handle performance and other variations from environment to environment. Recent versions have traded this approach for common base functions. Function compilation avoided some of the indirection associated with base functions. However, modern browsers have a JIT optimizer. It is better able to optimize base functions. Besides, the code is much more readable with base functions.</p><p>The golden rule of the implementation of Lo-Dash is optimization for the common case. You'll see this rule in action all over Lo-Dash, and it is the key factor in its superior performance. In any given function, the most common case is heavily optimized first, pushing the uncommon cases towards the end of the function. Callbacks are used everywhere in Lo-Dash, so it's important that they're able to perform predictably. The base callback machinery takes care of this for us and serves as a great example of optimizing for the common case.</p><p>We then looked at some techniques used to optimize our Lo-Dash code, following the design principles of Lo-Dash in most cases. Changing the order of chained operations in a Lo-Dash wrapper can eliminate needless iterations. Working with sorted collections can have a dramatic impact on filter performance. Lazy evaluation is a concept recently introduced to Lo-Dash, and it allows us to work with large collections without necessarily iterating over the entire collection. Lastly, we looked at some scenarios where caching could help boost performance, especially where the computations are expensive.</p><p>With that said, you're all set. Throughout this book, we learned and implemented concept after concept, starting with what you get out of the box in Lo-Dash, and wrapping up with how to go faster. Along the way, we looked at the most common usage patterns used to write solid Lo-Dash code. By now, it should be clear how everything in Lo-Dash relates to everything else, from the conceptual to the low-level function calls. As with any other library, there are a dozen or more ways of doing something in Lo-Dash. I hope you're now well-equipped to do it the best way.</p></div></body></html>